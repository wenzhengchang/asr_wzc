nohup: ignoring input
run.sh: init method is file:///home/wenzhengchang/wenet_wzc/examples/aishell/s0/exp/card7_conformer_embedding_out3_pinyin_0.3_out/ddp_init
total gpus is: 1
ASRModel(
  (encoder_before): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (encoder_between): ConformerEncoder(
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=16128, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList()
  )
  (embed): Embedding(4081, 256)
  (embed_py): Embedding(1132, 256)
  (sigmoid): Sigmoid()
  (linear1): Linear(in_features=256, out_features=1, bias=True)
  (linear2): Linear(in_features=256, out_features=1, bias=True)
  (encoder): ConformerEncoder(
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=16128, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(4081, 256)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (output_layer): Linear(in_features=256, out_features=4081, bias=True)
    (decoders): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (4): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (5): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=4081, bias=True)
    (ctc_loss): CTCLoss()
  )
  (ctc_py): CTC(
    (ctc_lo): Linear(in_features=256, out_features=1132, bias=True)
    (ctc_loss): CTCLoss()
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)2022-08-22 07:22:58,246 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/init.pt
2022-08-22 07:22:59,326 INFO Epoch 0 TRAIN info lr 8e-08
2022-08-22 07:22:59,332 INFO using accumulate grad, new batch size is 4 times larger than before

the number of model params: 57150544
/home/wenzhengchang/anaconda3/envs/speech/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
2022-08-22 07:23:27,136 DEBUG TRAIN Batch 0/0 loss 101.712906 loss_att 67.926216 loss_ctc 180.548492 loss_ctc_origin 108.142143 loss_ctc0 349.496643 lr 0.00000008 rank 0
2022-08-22 07:23:52,530 DEBUG TRAIN Batch 0/100 loss 134.621475 loss_att 90.199287 loss_ctc 238.273224 loss_ctc_origin 137.349701 loss_ctc0 473.761444 lr 0.00000208 rank 0
2022-08-22 07:24:19,488 DEBUG TRAIN Batch 0/200 loss 128.004288 loss_att 91.452789 loss_ctc 213.291122 loss_ctc_origin 126.765915 loss_ctc0 415.183258 lr 0.00000408 rank 0
2022-08-22 07:24:47,743 DEBUG TRAIN Batch 0/300 loss 151.820831 loss_att 131.343369 loss_ctc 199.601593 loss_ctc_origin 154.039993 loss_ctc0 305.911987 lr 0.00000608 rank 0
2022-08-22 07:25:14,152 DEBUG TRAIN Batch 0/400 loss 147.835785 loss_att 138.776443 loss_ctc 168.974228 loss_ctc_origin 155.436646 loss_ctc0 200.561935 lr 0.00000808 rank 0
2022-08-22 07:25:41,914 DEBUG TRAIN Batch 0/500 loss 63.982624 loss_att 63.342415 loss_ctc 65.476440 loss_ctc_origin 66.426552 loss_ctc0 63.259506 lr 0.00001008 rank 0
2022-08-22 07:26:10,116 DEBUG TRAIN Batch 0/600 loss 87.361931 loss_att 86.403000 loss_ctc 89.599442 loss_ctc_origin 91.695686 loss_ctc0 84.708206 lr 0.00001208 rank 0
2022-08-22 07:26:37,555 DEBUG TRAIN Batch 0/700 loss 101.275291 loss_att 99.884865 loss_ctc 104.519623 loss_ctc_origin 107.742661 loss_ctc0 96.999207 lr 0.00001408 rank 0
2022-08-22 07:27:04,698 DEBUG TRAIN Batch 0/800 loss 125.164009 loss_att 123.293625 loss_ctc 129.528244 loss_ctc_origin 133.885315 loss_ctc0 119.361755 lr 0.00001608 rank 0
2022-08-22 07:27:31,360 DEBUG TRAIN Batch 0/900 loss 133.961151 loss_att 131.693817 loss_ctc 139.251587 loss_ctc_origin 143.663666 loss_ctc0 128.956696 lr 0.00001808 rank 0
2022-08-22 07:27:58,198 DEBUG TRAIN Batch 0/1000 loss 58.348778 loss_att 57.583565 loss_ctc 60.134270 loss_ctc_origin 62.564690 loss_ctc0 54.463295 lr 0.00002008 rank 0
2022-08-22 07:28:25,345 DEBUG TRAIN Batch 0/1100 loss 76.542091 loss_att 74.674957 loss_ctc 80.898735 loss_ctc_origin 83.270233 loss_ctc0 75.365234 lr 0.00002208 rank 0
2022-08-22 07:28:51,404 DEBUG TRAIN Batch 0/1200 loss 93.120514 loss_att 90.753792 loss_ctc 98.642876 loss_ctc_origin 101.065285 loss_ctc0 92.990601 lr 0.00002408 rank 0
2022-08-22 07:29:03,647 WARNING NaN or Inf found in input tensor.
2022-08-22 07:29:19,994 DEBUG TRAIN Batch 0/1300 loss 109.554794 loss_att 106.601913 loss_ctc 116.444839 loss_ctc_origin 119.705231 loss_ctc0 108.837265 lr 0.00002608 rank 0
2022-08-22 07:29:48,302 DEBUG TRAIN Batch 0/1400 loss 126.547577 loss_att 122.566139 loss_ctc 135.837585 loss_ctc_origin 139.265396 loss_ctc0 127.839348 lr 0.00002808 rank 0
2022-08-22 07:30:20,440 DEBUG TRAIN Batch 0/1500 loss 53.772137 loss_att 52.112259 loss_ctc 57.645187 loss_ctc_origin 59.299202 loss_ctc0 53.785812 lr 0.00003008 rank 0
2022-08-22 07:30:47,954 DEBUG TRAIN Batch 0/1600 loss 76.381866 loss_att 73.936310 loss_ctc 82.088150 loss_ctc_origin 84.019424 loss_ctc0 77.581856 lr 0.00003208 rank 0
2022-08-22 07:31:15,476 DEBUG TRAIN Batch 0/1700 loss 84.451530 loss_att 81.766968 loss_ctc 90.715508 loss_ctc_origin 93.294083 loss_ctc0 84.698845 lr 0.00003408 rank 0
2022-08-22 07:31:42,248 DEBUG TRAIN Batch 0/1800 loss 101.252548 loss_att 97.555595 loss_ctc 109.878769 loss_ctc_origin 112.174957 loss_ctc0 104.520996 lr 0.00003608 rank 0
2022-08-22 07:32:10,089 DEBUG TRAIN Batch 0/1900 loss 117.249168 loss_att 112.901672 loss_ctc 127.393341 loss_ctc_origin 129.846512 loss_ctc0 121.669266 lr 0.00003808 rank 0
2022-08-22 07:32:38,937 DEBUG TRAIN Batch 0/2000 loss 47.543652 loss_att 46.021809 loss_ctc 51.094608 loss_ctc_origin 52.066986 loss_ctc0 48.825737 lr 0.00004008 rank 0
2022-08-22 07:33:06,134 DEBUG TRAIN Batch 0/2100 loss 69.510010 loss_att 67.309891 loss_ctc 74.643616 loss_ctc_origin 76.226440 loss_ctc0 70.950348 lr 0.00004208 rank 0
2022-08-22 07:33:33,428 DEBUG TRAIN Batch 0/2200 loss 80.272842 loss_att 77.603241 loss_ctc 86.501907 loss_ctc_origin 88.392868 loss_ctc0 82.089676 lr 0.00004408 rank 0
2022-08-22 07:34:01,138 DEBUG TRAIN Batch 0/2300 loss 100.476448 loss_att 97.014542 loss_ctc 108.554230 loss_ctc_origin 110.612030 loss_ctc0 103.752686 lr 0.00004608 rank 0
2022-08-22 07:34:28,017 DEBUG TRAIN Batch 0/2400 loss 113.267227 loss_att 109.205872 loss_ctc 122.743729 loss_ctc_origin 124.683426 loss_ctc0 118.217773 lr 0.00004808 rank 0
2022-08-22 07:34:54,979 DEBUG TRAIN Batch 0/2500 loss 47.804008 loss_att 46.254314 loss_ctc 51.419949 loss_ctc_origin 52.346458 loss_ctc0 49.258095 lr 0.00005008 rank 0
2022-08-22 07:35:22,336 DEBUG TRAIN Batch 0/2600 loss 72.011185 loss_att 69.541397 loss_ctc 77.774017 loss_ctc_origin 79.218857 loss_ctc0 74.402725 lr 0.00005208 rank 0
2022-08-22 07:35:49,784 DEBUG TRAIN Batch 0/2700 loss 80.838562 loss_att 78.043427 loss_ctc 87.360542 loss_ctc_origin 89.234161 loss_ctc0 82.988754 lr 0.00005408 rank 0
2022-08-22 07:36:17,169 DEBUG TRAIN Batch 0/2800 loss 103.840591 loss_att 100.286720 loss_ctc 112.132950 loss_ctc_origin 114.690742 loss_ctc0 106.164764 lr 0.00005608 rank 0
2022-08-22 07:36:45,831 DEBUG TRAIN Batch 0/2900 loss 117.150070 loss_att 112.910706 loss_ctc 127.041931 loss_ctc_origin 130.274139 loss_ctc0 119.500114 lr 0.00005808 rank 0
2022-08-22 07:37:18,849 DEBUG TRAIN Batch 0/3000 loss 47.299831 loss_att 45.726154 loss_ctc 50.971737 loss_ctc_origin 51.762009 loss_ctc0 49.127769 lr 0.00006008 rank 0
2022-08-22 07:37:47,595 DEBUG TRAIN Batch 0/3100 loss 66.654816 loss_att 64.390312 loss_ctc 71.938652 loss_ctc_origin 73.743706 loss_ctc0 67.726852 lr 0.00006208 rank 0
2022-08-22 07:38:16,163 DEBUG TRAIN Batch 0/3200 loss 71.328239 loss_att 68.541077 loss_ctc 77.831627 loss_ctc_origin 79.278870 loss_ctc0 74.454720 lr 0.00006408 rank 0
2022-08-22 07:38:44,023 DEBUG TRAIN Batch 0/3300 loss 91.604858 loss_att 87.774017 loss_ctc 100.543503 loss_ctc_origin 102.467316 loss_ctc0 96.054611 lr 0.00006608 rank 0
2022-08-22 07:39:11,792 DEBUG TRAIN Batch 0/3400 loss 107.440308 loss_att 102.773865 loss_ctc 118.328674 loss_ctc_origin 119.488991 loss_ctc0 115.621262 lr 0.00006808 rank 0
2022-08-22 07:39:40,566 DEBUG TRAIN Batch 0/3500 loss 47.249672 loss_att 45.509895 loss_ctc 51.309147 loss_ctc_origin 52.294662 loss_ctc0 49.009613 lr 0.00007008 rank 0
2022-08-22 07:40:06,592 DEBUG TRAIN Batch 0/3600 loss 65.871780 loss_att 62.645470 loss_ctc 73.399826 loss_ctc_origin 71.341179 loss_ctc0 78.203354 lr 0.00007208 rank 0
2022-08-22 07:40:33,383 DEBUG TRAIN Batch 0/3700 loss 76.378403 loss_att 72.891388 loss_ctc 84.514755 loss_ctc_origin 85.729614 loss_ctc0 81.680069 lr 0.00007408 rank 0
2022-08-22 07:40:39,209 WARNING NaN or Inf found in input tensor.
2022-08-22 07:41:00,231 DEBUG TRAIN Batch 0/3800 loss 86.664001 loss_att 82.718338 loss_ctc 95.870552 loss_ctc_origin 97.568901 loss_ctc0 91.907730 lr 0.00007608 rank 0
2022-08-22 07:41:26,798 DEBUG TRAIN Batch 0/3900 loss 112.123566 loss_att 107.022888 loss_ctc 124.025131 loss_ctc_origin 126.605713 loss_ctc0 118.003754 lr 0.00007808 rank 0
2022-08-22 07:41:54,543 DEBUG TRAIN Batch 0/4000 loss 48.772812 loss_att 47.046532 loss_ctc 52.800793 loss_ctc_origin 54.299099 loss_ctc0 49.304749 lr 0.00008008 rank 0
2022-08-22 07:42:22,463 DEBUG TRAIN Batch 0/4100 loss 71.472282 loss_att 59.677704 loss_ctc 98.992966 loss_ctc_origin 71.567429 loss_ctc0 162.985901 lr 0.00008208 rank 0
2022-08-22 07:42:50,630 DEBUG TRAIN Batch 0/4200 loss 81.384331 loss_att 77.979218 loss_ctc 89.329582 loss_ctc_origin 91.455215 loss_ctc0 84.369774 lr 0.00008408 rank 0
2022-08-22 07:43:17,538 DEBUG TRAIN Batch 0/4300 loss 95.897064 loss_att 90.231232 loss_ctc 109.117340 loss_ctc_origin 110.797821 loss_ctc0 105.196228 lr 0.00008608 rank 0
2022-08-22 07:43:44,876 DEBUG TRAIN Batch 0/4400 loss 108.036598 loss_att 102.431488 loss_ctc 121.115181 loss_ctc_origin 123.237457 loss_ctc0 116.163193 lr 0.00008808 rank 0
2022-08-22 07:44:17,852 DEBUG TRAIN Batch 0/4500 loss 51.809086 loss_att 45.850716 loss_ctc 65.711945 loss_ctc_origin 52.645920 loss_ctc0 96.199326 lr 0.00009008 rank 0
2022-08-22 07:44:45,750 DEBUG TRAIN Batch 0/4600 loss 79.279739 loss_att 63.457973 loss_ctc 116.197174 loss_ctc_origin 77.635063 loss_ctc0 206.175415 lr 0.00009208 rank 0
2022-08-22 07:45:13,131 DEBUG TRAIN Batch 0/4700 loss 75.401680 loss_att 71.116806 loss_ctc 85.399704 loss_ctc_origin 86.747498 loss_ctc0 82.254860 lr 0.00009408 rank 0
2022-08-22 07:45:41,081 DEBUG TRAIN Batch 0/4800 loss 83.338547 loss_att 77.972458 loss_ctc 95.859436 loss_ctc_origin 98.188400 loss_ctc0 90.425171 lr 0.00009608 rank 0
2022-08-22 07:46:09,149 DEBUG TRAIN Batch 0/4900 loss 100.912766 loss_att 94.371040 loss_ctc 116.176773 loss_ctc_origin 118.488419 loss_ctc0 110.782928 lr 0.00009808 rank 0
2022-08-22 07:46:37,514 DEBUG TRAIN Batch 0/5000 loss 53.042755 loss_att 42.596863 loss_ctc 77.416504 loss_ctc_origin 52.804138 loss_ctc0 134.845367 lr 0.00010008 rank 0
2022-08-22 07:46:58,138 WARNING NaN or Inf found in input tensor.
2022-08-22 07:47:04,775 DEBUG TRAIN Batch 0/5100 loss 87.140884 loss_att 60.590137 loss_ctc 149.092606 loss_ctc_origin 74.261826 loss_ctc0 323.697754 lr 0.00010208 rank 0
2022-08-22 07:47:32,135 DEBUG TRAIN Batch 0/5200 loss 77.535095 loss_att 72.682732 loss_ctc 88.857277 loss_ctc_origin 90.771179 loss_ctc0 84.391510 lr 0.00010408 rank 0
2022-08-22 07:47:50,507 WARNING NaN or Inf found in input tensor.
2022-08-22 07:47:59,952 DEBUG TRAIN Batch 0/5300 loss 96.398750 loss_att 91.270844 loss_ctc 108.363861 loss_ctc_origin 110.288712 loss_ctc0 103.872551 lr 0.00010608 rank 0
2022-08-22 07:48:27,187 DEBUG TRAIN Batch 0/5400 loss 99.700424 loss_att 91.794662 loss_ctc 118.147179 loss_ctc_origin 120.365387 loss_ctc0 112.971359 lr 0.00010808 rank 0
2022-08-22 07:48:55,290 DEBUG TRAIN Batch 0/5500 loss 46.357738 loss_att 42.659050 loss_ctc 54.988014 loss_ctc_origin 53.800350 loss_ctc0 57.759239 lr 0.00011008 rank 0
2022-08-22 07:49:24,170 DEBUG TRAIN Batch 0/5600 loss 99.288208 loss_att 62.570625 loss_ctc 184.962555 loss_ctc_origin 77.447845 loss_ctc0 435.830200 lr 0.00011208 rank 0
2022-08-22 07:49:24,873 WARNING NaN or Inf found in input tensor.
2022-08-22 07:49:47,241 DEBUG CV Batch 0/0 loss 53.606552 loss_att 41.256615 loss_ctc 82.423080 loss_ctc_origin 50.338322 loss_ctc0 157.287506 history loss 50.453226 rank 0
2022-08-22 07:49:57,383 DEBUG CV Batch 0/100 loss 73.013123 loss_att 59.361130 loss_ctc 104.867752 loss_ctc_origin 73.946274 loss_ctc0 177.017868 history loss 83.465817 rank 0
2022-08-22 07:50:07,004 DEBUG CV Batch 0/200 loss 74.447113 loss_att 69.614326 loss_ctc 85.723633 loss_ctc_origin 87.470993 loss_ctc0 81.646469 history loss 84.136638 rank 0
2022-08-22 07:50:16,472 DEBUG CV Batch 0/300 loss 87.059502 loss_att 80.847839 loss_ctc 101.553383 loss_ctc_origin 103.920334 loss_ctc0 96.030502 history loss 84.345436 rank 0
2022-08-22 07:50:26,472 DEBUG CV Batch 0/400 loss 113.631798 loss_att 106.177269 loss_ctc 131.025696 loss_ctc_origin 134.415619 loss_ctc0 123.115891 history loss 83.795434 rank 0
2022-08-22 07:50:36,868 DEBUG CV Batch 0/500 loss 59.710640 loss_att 48.420967 loss_ctc 86.053207 loss_ctc_origin 56.933548 loss_ctc0 153.999084 history loss 84.250453 rank 0
2022-08-22 07:50:47,149 DEBUG CV Batch 0/600 loss 69.100243 loss_att 59.690926 loss_ctc 91.055328 loss_ctc_origin 75.808464 loss_ctc0 126.631348 history loss 84.285559 rank 0
2022-08-22 07:50:56,762 DEBUG CV Batch 0/700 loss 75.401619 loss_att 70.439590 loss_ctc 86.979691 loss_ctc_origin 88.027832 loss_ctc0 84.534027 history loss 84.096096 rank 0
2022-08-22 07:51:06,550 DEBUG CV Batch 0/800 loss 83.483109 loss_att 77.005882 loss_ctc 98.596626 loss_ctc_origin 100.226311 loss_ctc0 94.794037 history loss 84.274853 rank 0
2022-08-22 07:51:16,387 INFO Epoch 0 CV info cv_loss 84.61910172770858
2022-08-22 07:51:16,387 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/0.pt
2022-08-22 07:51:16,817 INFO Epoch 1 TRAIN info lr 0.00011376
2022-08-22 07:51:16,820 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 07:51:43,086 DEBUG TRAIN Batch 1/0 loss 54.191357 loss_att 48.912994 loss_ctc 66.507538 loss_ctc_origin 61.191006 loss_ctc0 78.912796 lr 0.00011384 rank 0
2022-08-22 07:52:11,434 DEBUG TRAIN Batch 1/100 loss 65.452530 loss_att 60.133709 loss_ctc 77.863106 loss_ctc_origin 76.351776 loss_ctc0 81.389534 lr 0.00011584 rank 0
2022-08-22 07:52:40,764 DEBUG TRAIN Batch 1/200 loss 70.132187 loss_att 64.700554 loss_ctc 82.805984 loss_ctc_origin 84.336937 loss_ctc0 79.233765 lr 0.00011784 rank 0
2022-08-22 07:53:09,348 DEBUG TRAIN Batch 1/300 loss 87.574654 loss_att 81.805107 loss_ctc 101.036934 loss_ctc_origin 102.864029 loss_ctc0 96.773697 lr 0.00011984 rank 0
2022-08-22 07:53:37,647 DEBUG TRAIN Batch 1/400 loss 108.862137 loss_att 101.131058 loss_ctc 126.901321 loss_ctc_origin 129.629593 loss_ctc0 120.535332 lr 0.00012184 rank 0
2022-08-22 07:53:41,239 WARNING NaN or Inf found in input tensor.
2022-08-22 07:53:48,136 WARNING NaN or Inf found in input tensor.
2022-08-22 07:54:06,265 DEBUG TRAIN Batch 1/500 loss 51.017029 loss_att 45.420303 loss_ctc 64.076050 loss_ctc_origin 59.786552 loss_ctc0 74.084892 lr 0.00012384 rank 0
2022-08-22 07:54:33,612 DEBUG TRAIN Batch 1/600 loss 75.487259 loss_att 51.452606 loss_ctc 131.568130 loss_ctc_origin 66.853745 loss_ctc0 282.568359 lr 0.00012584 rank 0
2022-08-22 07:55:01,071 DEBUG TRAIN Batch 1/700 loss 74.548759 loss_att 68.615433 loss_ctc 88.393181 loss_ctc_origin 90.216629 loss_ctc0 84.138466 lr 0.00012784 rank 0
2022-08-22 07:55:27,394 DEBUG TRAIN Batch 1/800 loss 80.660034 loss_att 73.728622 loss_ctc 96.833336 loss_ctc_origin 98.859802 loss_ctc0 92.104919 lr 0.00012984 rank 0
2022-08-22 07:55:54,481 DEBUG TRAIN Batch 1/900 loss 110.182053 loss_att 102.203018 loss_ctc 128.799774 loss_ctc_origin 131.230927 loss_ctc0 123.127090 lr 0.00013184 rank 0
2022-08-22 07:56:22,794 DEBUG TRAIN Batch 1/1000 loss 42.595242 loss_att 39.882378 loss_ctc 48.925262 loss_ctc_origin 49.618725 loss_ctc0 47.307175 lr 0.00013384 rank 0
2022-08-22 07:56:43,082 WARNING NaN or Inf found in input tensor.
2022-08-22 07:56:49,586 DEBUG TRAIN Batch 1/1100 loss 99.213470 loss_att 63.146736 loss_ctc 183.369202 loss_ctc_origin 81.112434 loss_ctc0 421.968323 lr 0.00013584 rank 0
2022-08-22 07:57:17,538 DEBUG TRAIN Batch 1/1200 loss 74.265594 loss_att 69.489410 loss_ctc 85.410019 loss_ctc_origin 87.497719 loss_ctc0 80.538734 lr 0.00013784 rank 0
2022-08-22 07:57:45,550 DEBUG TRAIN Batch 1/1300 loss 85.358925 loss_att 77.034264 loss_ctc 104.783127 loss_ctc_origin 106.875854 loss_ctc0 99.900093 lr 0.00013984 rank 0
2022-08-22 07:58:14,168 DEBUG TRAIN Batch 1/1400 loss 101.919479 loss_att 93.278000 loss_ctc 122.082916 loss_ctc_origin 124.326508 loss_ctc0 116.847878 lr 0.00014184 rank 0
2022-08-22 07:58:47,595 DEBUG TRAIN Batch 1/1500 loss 58.525185 loss_att 40.927624 loss_ctc 99.586151 loss_ctc_origin 53.713425 loss_ctc0 206.622528 lr 0.00014384 rank 0
2022-08-22 07:59:16,021 DEBUG TRAIN Batch 1/1600 loss 82.948692 loss_att 51.785549 loss_ctc 155.662689 loss_ctc_origin 71.475952 loss_ctc0 352.098389 lr 0.00014584 rank 0
2022-08-22 07:59:43,711 DEBUG TRAIN Batch 1/1700 loss 73.837143 loss_att 67.887177 loss_ctc 87.720398 loss_ctc_origin 89.547119 loss_ctc0 83.458054 lr 0.00014784 rank 0
2022-08-22 08:00:11,515 DEBUG TRAIN Batch 1/1800 loss 74.296707 loss_att 64.832489 loss_ctc 96.379890 loss_ctc_origin 97.429047 loss_ctc0 93.931854 lr 0.00014984 rank 0
2022-08-22 08:00:39,135 DEBUG TRAIN Batch 1/1900 loss 106.251175 loss_att 96.675041 loss_ctc 128.595490 loss_ctc_origin 131.343887 loss_ctc0 122.182571 lr 0.00015184 rank 0
2022-08-22 08:01:07,336 DEBUG TRAIN Batch 1/2000 loss 49.565010 loss_att 44.022789 loss_ctc 62.496864 loss_ctc_origin 54.240360 loss_ctc0 81.762047 lr 0.00015384 rank 0
2022-08-22 08:01:35,350 DEBUG TRAIN Batch 1/2100 loss 81.546410 loss_att 53.376888 loss_ctc 147.275284 loss_ctc_origin 70.457245 loss_ctc0 326.517365 lr 0.00015584 rank 0
2022-08-22 08:02:01,803 DEBUG TRAIN Batch 1/2200 loss 72.932007 loss_att 67.577133 loss_ctc 85.426712 loss_ctc_origin 87.227470 loss_ctc0 81.224960 lr 0.00015784 rank 0
2022-08-22 08:02:29,473 DEBUG TRAIN Batch 1/2300 loss 86.449478 loss_att 78.966293 loss_ctc 103.910240 loss_ctc_origin 106.358948 loss_ctc0 98.196579 lr 0.00015984 rank 0
2022-08-22 08:02:57,358 DEBUG TRAIN Batch 1/2400 loss 98.115997 loss_att 88.268044 loss_ctc 121.094559 loss_ctc_origin 123.238037 loss_ctc0 116.093124 lr 0.00016184 rank 0
2022-08-22 08:03:25,019 DEBUG TRAIN Batch 1/2500 loss 50.774887 loss_att 44.091511 loss_ctc 66.369431 loss_ctc_origin 58.215034 loss_ctc0 85.396362 lr 0.00016384 rank 0
2022-08-22 08:03:52,815 DEBUG TRAIN Batch 1/2600 loss 70.679352 loss_att 56.346588 loss_ctc 104.122459 loss_ctc_origin 78.415359 loss_ctc0 164.105682 lr 0.00016584 rank 0
2022-08-22 08:04:19,697 DEBUG TRAIN Batch 1/2700 loss 69.519936 loss_att 63.789433 loss_ctc 82.891098 loss_ctc_origin 84.203445 loss_ctc0 79.828957 lr 0.00016784 rank 0
2022-08-22 08:04:47,386 DEBUG TRAIN Batch 1/2800 loss 81.161629 loss_att 73.535706 loss_ctc 98.955437 loss_ctc_origin 100.698936 loss_ctc0 94.887268 lr 0.00016984 rank 0
2022-08-22 08:05:15,262 DEBUG TRAIN Batch 1/2900 loss 91.745354 loss_att 82.715240 loss_ctc 112.815613 loss_ctc_origin 114.695045 loss_ctc0 108.430267 lr 0.00017184 rank 0
2022-08-22 08:05:48,295 DEBUG TRAIN Batch 1/3000 loss 42.424633 loss_att 38.679966 loss_ctc 51.162186 loss_ctc_origin 51.933430 loss_ctc0 49.362617 lr 0.00017384 rank 0
2022-08-22 08:06:15,846 DEBUG TRAIN Batch 1/3100 loss 61.398636 loss_att 55.642300 loss_ctc 74.830086 loss_ctc_origin 74.677170 loss_ctc0 75.186890 lr 0.00017584 rank 0
2022-08-22 08:06:41,569 WARNING NaN or Inf found in input tensor.
2022-08-22 08:06:43,258 DEBUG TRAIN Batch 1/3200 loss 71.840103 loss_att 65.211998 loss_ctc 87.305679 loss_ctc_origin 89.445801 loss_ctc0 82.312073 lr 0.00017784 rank 0
2022-08-22 08:07:10,471 DEBUG TRAIN Batch 1/3300 loss 81.576324 loss_att 72.360283 loss_ctc 103.080429 loss_ctc_origin 104.976006 loss_ctc0 98.657440 lr 0.00017984 rank 0
2022-08-22 08:07:37,219 DEBUG TRAIN Batch 1/3400 loss 98.207191 loss_att 87.690269 loss_ctc 122.746674 loss_ctc_origin 124.593445 loss_ctc0 118.437531 lr 0.00018184 rank 0
2022-08-22 08:08:05,781 DEBUG TRAIN Batch 1/3500 loss 52.188080 loss_att 42.392288 loss_ctc 75.044922 loss_ctc_origin 54.994583 loss_ctc0 121.829041 lr 0.00018384 rank 0
2022-08-22 08:08:32,829 DEBUG TRAIN Batch 1/3600 loss 64.494217 loss_att 47.766167 loss_ctc 103.526314 loss_ctc_origin 67.013611 loss_ctc0 188.722610 lr 0.00018584 rank 0
2022-08-22 08:08:59,154 DEBUG TRAIN Batch 1/3700 loss 65.097733 loss_att 59.108566 loss_ctc 79.072456 loss_ctc_origin 80.730461 loss_ctc0 75.203781 lr 0.00018784 rank 0
2022-08-22 08:09:27,308 DEBUG TRAIN Batch 1/3800 loss 78.359642 loss_att 70.907028 loss_ctc 95.749069 loss_ctc_origin 97.049469 loss_ctc0 92.714821 lr 0.00018984 rank 0
2022-08-22 08:09:54,862 DEBUG TRAIN Batch 1/3900 loss 94.259506 loss_att 84.600571 loss_ctc 116.797012 loss_ctc_origin 118.940186 loss_ctc0 111.796288 lr 0.00019184 rank 0
2022-08-22 08:10:23,585 DEBUG TRAIN Batch 1/4000 loss 49.235260 loss_att 43.802628 loss_ctc 61.911396 loss_ctc_origin 53.846367 loss_ctc0 80.729797 lr 0.00019384 rank 0
2022-08-22 08:10:50,862 DEBUG TRAIN Batch 1/4100 loss 93.304398 loss_att 55.681034 loss_ctc 181.092239 loss_ctc_origin 73.567642 loss_ctc0 431.982971 lr 0.00019584 rank 0
2022-08-22 08:11:18,053 DEBUG TRAIN Batch 1/4200 loss 76.005539 loss_att 67.857040 loss_ctc 95.018715 loss_ctc_origin 96.211769 loss_ctc0 92.234924 lr 0.00019784 rank 0
2022-08-22 08:11:28,468 WARNING NaN or Inf found in input tensor.
2022-08-22 08:11:45,049 DEBUG TRAIN Batch 1/4300 loss 82.429764 loss_att 74.138329 loss_ctc 101.776436 loss_ctc_origin 103.977081 loss_ctc0 96.641586 lr 0.00019984 rank 0
2022-08-22 08:12:11,993 DEBUG TRAIN Batch 1/4400 loss 98.453804 loss_att 87.651726 loss_ctc 123.658646 loss_ctc_origin 126.050682 loss_ctc0 118.077217 lr 0.00020184 rank 0
2022-08-22 08:12:45,414 DEBUG TRAIN Batch 1/4500 loss 47.482685 loss_att 39.518066 loss_ctc 66.066795 loss_ctc_origin 53.561398 loss_ctc0 95.246063 lr 0.00020384 rank 0
2022-08-22 08:13:12,950 DEBUG TRAIN Batch 1/4600 loss 76.561737 loss_att 51.696350 loss_ctc 134.580994 loss_ctc_origin 73.129852 loss_ctc0 277.966980 lr 0.00020584 rank 0
2022-08-22 08:13:40,863 DEBUG TRAIN Batch 1/4700 loss 67.916183 loss_att 62.172218 loss_ctc 81.318771 loss_ctc_origin 82.987938 loss_ctc0 77.424034 lr 0.00020784 rank 0
2022-08-22 08:14:08,241 DEBUG TRAIN Batch 1/4800 loss 81.376976 loss_att 73.066017 loss_ctc 100.769226 loss_ctc_origin 102.738113 loss_ctc0 96.175163 lr 0.00020984 rank 0
2022-08-22 08:14:35,448 DEBUG TRAIN Batch 1/4900 loss 101.844612 loss_att 91.681229 loss_ctc 125.559174 loss_ctc_origin 127.829773 loss_ctc0 120.261093 lr 0.00021184 rank 0
2022-08-22 08:15:03,688 DEBUG TRAIN Batch 1/5000 loss 68.653938 loss_att 42.223003 loss_ctc 130.326111 loss_ctc_origin 60.786598 loss_ctc0 292.584961 lr 0.00021384 rank 0
2022-08-22 08:15:31,078 DEBUG TRAIN Batch 1/5100 loss 86.097977 loss_att 48.498348 loss_ctc 173.830414 loss_ctc_origin 67.853889 loss_ctc0 421.108948 lr 0.00021584 rank 0
2022-08-22 08:15:50,580 WARNING NaN or Inf found in input tensor.
2022-08-22 08:15:59,308 DEBUG TRAIN Batch 1/5200 loss 73.381485 loss_att 66.160683 loss_ctc 90.230026 loss_ctc_origin 92.360474 loss_ctc0 85.258980 lr 0.00021784 rank 0
2022-08-22 08:16:26,355 DEBUG TRAIN Batch 1/5300 loss 78.867348 loss_att 69.901138 loss_ctc 99.788490 loss_ctc_origin 101.603661 loss_ctc0 95.553101 lr 0.00021984 rank 0
2022-08-22 08:16:53,739 DEBUG TRAIN Batch 1/5400 loss 99.365021 loss_att 88.423676 loss_ctc 124.894814 loss_ctc_origin 126.861282 loss_ctc0 120.306396 lr 0.00022184 rank 0
2022-08-22 08:17:21,185 DEBUG TRAIN Batch 1/5500 loss 44.625618 loss_att 40.154819 loss_ctc 55.057472 loss_ctc_origin 52.397900 loss_ctc0 61.263138 lr 0.00022384 rank 0
2022-08-22 08:17:43,003 WARNING NaN or Inf found in input tensor.
2022-08-22 08:17:50,095 DEBUG TRAIN Batch 1/5600 loss 96.800018 loss_att 57.322903 loss_ctc 188.913284 loss_ctc_origin 77.204376 loss_ctc0 449.567383 lr 0.00022584 rank 0
2022-08-22 08:18:13,466 DEBUG CV Batch 1/0 loss 37.964550 loss_att 34.140213 loss_ctc 46.888000 loss_ctc_origin 47.362312 loss_ctc0 45.781277 history loss 35.731341 rank 0
2022-08-22 08:18:23,679 DEBUG CV Batch 1/100 loss 55.677757 loss_att 48.794640 loss_ctc 71.738365 loss_ctc_origin 73.228157 loss_ctc0 68.262192 history loss 74.427566 rank 0
2022-08-22 08:18:33,199 DEBUG CV Batch 1/200 loss 68.613571 loss_att 61.493858 loss_ctc 85.226242 loss_ctc_origin 86.414070 loss_ctc0 82.454636 history loss 74.968479 rank 0
2022-08-22 08:18:42,917 DEBUG CV Batch 1/300 loss 80.106888 loss_att 71.389084 loss_ctc 100.448418 loss_ctc_origin 102.521866 loss_ctc0 95.610382 history loss 75.323887 rank 0
2022-08-22 08:18:53,187 DEBUG CV Batch 1/400 loss 106.788879 loss_att 96.913040 loss_ctc 129.832520 loss_ctc_origin 132.684235 loss_ctc0 123.178497 history loss 74.938469 rank 0
2022-08-22 08:19:03,454 DEBUG CV Batch 1/500 loss 45.214600 loss_att 40.961037 loss_ctc 55.139572 loss_ctc_origin 56.255611 loss_ctc0 52.535469 history loss 75.454532 rank 0
2022-08-22 08:19:13,834 DEBUG CV Batch 1/600 loss 57.854027 loss_att 51.502785 loss_ctc 72.673584 loss_ctc_origin 74.232475 loss_ctc0 69.036163 history loss 75.531195 rank 0
2022-08-22 08:19:23,724 DEBUG CV Batch 1/700 loss 70.081841 loss_att 63.120525 loss_ctc 86.324905 loss_ctc_origin 87.366791 loss_ctc0 83.893845 history loss 75.389652 rank 0
2022-08-22 08:19:33,801 DEBUG CV Batch 1/800 loss 77.493843 loss_att 68.903198 loss_ctc 97.538673 loss_ctc_origin 98.949493 loss_ctc0 94.246780 history loss 75.625616 rank 0
2022-08-22 08:19:43,779 INFO Epoch 1 CV info cv_loss 76.0961370467474
2022-08-22 08:19:43,779 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/1.pt
2022-08-22 08:19:44,210 INFO Epoch 2 TRAIN info lr 0.00022752
2022-08-22 08:19:44,213 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 08:20:10,843 DEBUG TRAIN Batch 2/0 loss 59.631447 loss_att 38.511036 loss_ctc 108.912399 loss_ctc_origin 55.086864 loss_ctc0 234.505310 lr 0.00022760 rank 0
2022-08-22 08:20:38,886 DEBUG TRAIN Batch 2/100 loss 92.684372 loss_att 53.933998 loss_ctc 183.101883 loss_ctc_origin 77.002243 loss_ctc0 430.667725 lr 0.00022960 rank 0
2022-08-22 08:21:07,162 DEBUG TRAIN Batch 2/200 loss 70.070854 loss_att 62.905464 loss_ctc 86.790092 loss_ctc_origin 88.587837 loss_ctc0 82.595352 lr 0.00023160 rank 0
2022-08-22 08:21:35,324 DEBUG TRAIN Batch 2/300 loss 80.704193 loss_att 70.551552 loss_ctc 104.393677 loss_ctc_origin 106.044952 loss_ctc0 100.540680 lr 0.00023360 rank 0
2022-08-22 08:22:03,227 DEBUG TRAIN Batch 2/400 loss 99.748886 loss_att 88.582184 loss_ctc 125.804520 loss_ctc_origin 128.122452 loss_ctc0 120.396004 lr 0.00023560 rank 0
2022-08-22 08:22:31,231 DEBUG TRAIN Batch 2/500 loss 52.991325 loss_att 36.205940 loss_ctc 92.157227 loss_ctc_origin 50.441391 loss_ctc0 189.494171 lr 0.00023760 rank 0
2022-08-22 08:22:31,908 WARNING NaN or Inf found in input tensor.
2022-08-22 08:22:59,663 DEBUG TRAIN Batch 2/600 loss 89.308578 loss_att 52.449203 loss_ctc 175.313782 loss_ctc_origin 76.575638 loss_ctc0 405.702789 lr 0.00023960 rank 0
2022-08-22 08:23:27,165 DEBUG TRAIN Batch 2/700 loss 62.819336 loss_att 55.242676 loss_ctc 80.498199 loss_ctc_origin 82.304428 loss_ctc0 76.283661 lr 0.00024160 rank 0
2022-08-22 08:23:55,585 DEBUG TRAIN Batch 2/800 loss 79.461220 loss_att 70.027527 loss_ctc 101.473175 loss_ctc_origin 102.991379 loss_ctc0 97.930710 lr 0.00024360 rank 0
2022-08-22 08:24:24,020 DEBUG TRAIN Batch 2/900 loss 100.668869 loss_att 90.474045 loss_ctc 124.456787 loss_ctc_origin 126.552002 loss_ctc0 119.567947 lr 0.00024560 rank 0
2022-08-22 08:24:51,280 DEBUG TRAIN Batch 2/1000 loss 59.628700 loss_att 41.612808 loss_ctc 101.665787 loss_ctc_origin 56.657333 loss_ctc0 206.685486 lr 0.00024760 rank 0
2022-08-22 08:25:19,152 WARNING NaN or Inf found in input tensor.
2022-08-22 08:25:19,192 DEBUG TRAIN Batch 2/1100 loss nan loss_att 47.336754 loss_ctc nan loss_ctc_origin 70.461609 loss_ctc0 nan lr 0.00024960 rank 0
2022-08-22 08:25:47,061 DEBUG TRAIN Batch 2/1200 loss 68.304115 loss_att 59.695923 loss_ctc 88.389900 loss_ctc_origin 89.412529 loss_ctc0 86.003769 lr 0.00025160 rank 0
2022-08-22 08:26:00,061 WARNING NaN or Inf found in input tensor.
2022-08-22 08:26:16,252 DEBUG TRAIN Batch 2/1300 loss 73.057922 loss_att 62.449139 loss_ctc 97.811760 loss_ctc_origin 99.480591 loss_ctc0 93.917824 lr 0.00025360 rank 0
2022-08-22 08:26:44,807 DEBUG TRAIN Batch 2/1400 loss 102.997208 loss_att 91.717415 loss_ctc 129.316742 loss_ctc_origin 132.159363 loss_ctc0 122.683968 lr 0.00025560 rank 0
2022-08-22 08:27:19,149 DEBUG TRAIN Batch 2/1500 loss 62.939262 loss_att 40.533646 loss_ctc 115.219025 loss_ctc_origin 55.692589 loss_ctc0 254.114044 lr 0.00025760 rank 0
2022-08-22 08:27:48,175 DEBUG TRAIN Batch 2/1600 loss 96.524612 loss_att 52.994797 loss_ctc 198.094177 loss_ctc_origin 73.540817 loss_ctc0 488.718628 lr 0.00025960 rank 0
2022-08-22 08:28:16,200 DEBUG TRAIN Batch 2/1700 loss 64.688461 loss_att 58.564758 loss_ctc 78.977097 loss_ctc_origin 80.455276 loss_ctc0 75.528008 lr 0.00026160 rank 0
2022-08-22 08:28:44,372 DEBUG TRAIN Batch 2/1800 loss 85.701981 loss_att 76.480301 loss_ctc 107.219223 loss_ctc_origin 109.329330 loss_ctc0 102.295639 lr 0.00026360 rank 0
2022-08-22 08:29:12,245 DEBUG TRAIN Batch 2/1900 loss 94.196823 loss_att 82.488976 loss_ctc 121.515137 loss_ctc_origin 123.862091 loss_ctc0 116.038910 lr 0.00026560 rank 0
2022-08-22 08:29:41,638 DEBUG TRAIN Batch 2/2000 loss 63.750179 loss_att 39.965706 loss_ctc 119.247284 loss_ctc_origin 54.076077 loss_ctc0 271.313446 lr 0.00026760 rank 0
2022-08-22 08:30:10,510 DEBUG TRAIN Batch 2/2100 loss 102.954376 loss_att 51.500061 loss_ctc 223.014435 loss_ctc_origin 75.339584 loss_ctc0 567.589111 lr 0.00026960 rank 0
2022-08-22 08:30:38,570 DEBUG TRAIN Batch 2/2200 loss 67.114182 loss_att 57.768295 loss_ctc 88.921242 loss_ctc_origin 89.826385 loss_ctc0 86.809250 lr 0.00027160 rank 0
2022-08-22 08:31:07,243 DEBUG TRAIN Batch 2/2300 loss 80.742805 loss_att 72.489395 loss_ctc 100.000763 loss_ctc_origin 101.688034 loss_ctc0 96.063774 lr 0.00027360 rank 0
2022-08-22 08:31:36,562 DEBUG TRAIN Batch 2/2400 loss 92.024765 loss_att 80.234001 loss_ctc 119.536545 loss_ctc_origin 121.164497 loss_ctc0 115.737976 lr 0.00027560 rank 0
2022-08-22 08:32:11,772 DEBUG TRAIN Batch 2/2500 loss 50.722435 loss_att 41.008354 loss_ctc 73.388634 loss_ctc_origin 54.346863 loss_ctc0 117.819427 lr 0.00027760 rank 0
2022-08-22 08:32:46,756 DEBUG TRAIN Batch 2/2600 loss 59.703564 loss_att 53.674881 loss_ctc 73.770493 loss_ctc_origin 73.729256 loss_ctc0 73.866730 lr 0.00027960 rank 0
2022-08-22 08:33:22,174 DEBUG TRAIN Batch 2/2700 loss 67.740738 loss_att 59.376099 loss_ctc 87.258224 loss_ctc_origin 88.427841 loss_ctc0 84.529121 lr 0.00028160 rank 0
2022-08-22 08:33:57,928 DEBUG TRAIN Batch 2/2800 loss 80.347641 loss_att 70.138817 loss_ctc 104.168236 loss_ctc_origin 105.330856 loss_ctc0 101.455460 lr 0.00028360 rank 0
2022-08-22 08:34:35,615 DEBUG TRAIN Batch 2/2900 loss 97.846619 loss_att 87.270920 loss_ctc 122.523262 loss_ctc_origin 124.691681 loss_ctc0 117.463623 lr 0.00028560 rank 0
2022-08-22 08:35:20,392 DEBUG TRAIN Batch 2/3000 loss 40.648270 loss_att 36.767654 loss_ctc 49.703033 loss_ctc_origin 49.747280 loss_ctc0 49.599785 lr 0.00028760 rank 0
2022-08-22 08:35:55,804 DEBUG TRAIN Batch 2/3100 loss 56.178120 loss_att 46.250160 loss_ctc 79.343361 loss_ctc_origin 65.749657 loss_ctc0 111.062012 lr 0.00028960 rank 0
2022-08-22 08:36:31,847 DEBUG TRAIN Batch 2/3200 loss 63.683388 loss_att 55.661240 loss_ctc 82.401726 loss_ctc_origin 83.442520 loss_ctc0 79.973206 lr 0.00029160 rank 0
2022-08-22 08:37:08,151 DEBUG TRAIN Batch 2/3300 loss 78.471947 loss_att 69.735001 loss_ctc 98.858162 loss_ctc_origin 100.415894 loss_ctc0 95.223465 lr 0.00029360 rank 0
2022-08-22 08:37:21,098 WARNING NaN or Inf found in input tensor.
2022-08-22 08:37:37,999 WARNING NaN or Inf found in input tensor.
2022-08-22 08:37:43,127 DEBUG TRAIN Batch 2/3400 loss 96.474861 loss_att 84.114471 loss_ctc 125.315758 loss_ctc_origin 126.988815 loss_ctc0 121.411972 lr 0.00029560 rank 0
2022-08-22 08:38:20,998 DEBUG TRAIN Batch 2/3500 loss 66.071381 loss_att 36.512985 loss_ctc 135.040955 loss_ctc_origin 50.972118 loss_ctc0 331.201569 lr 0.00029760 rank 0
2022-08-22 08:38:55,392 DEBUG TRAIN Batch 2/3600 loss 96.438805 loss_att 52.280052 loss_ctc 199.475891 loss_ctc_origin 78.727921 loss_ctc0 481.221130 lr 0.00029960 rank 0
2022-08-22 08:39:29,184 DEBUG TRAIN Batch 2/3700 loss 62.694969 loss_att 54.690941 loss_ctc 81.371040 loss_ctc_origin 82.462631 loss_ctc0 78.823997 lr 0.00030160 rank 0
2022-08-22 08:39:59,885 DEBUG TRAIN Batch 2/3800 loss 70.448318 loss_att 61.080750 loss_ctc 92.305992 loss_ctc_origin 93.095963 loss_ctc0 90.462715 lr 0.00030360 rank 0
2022-08-22 08:40:31,769 DEBUG TRAIN Batch 2/3900 loss 91.443756 loss_att 78.497253 loss_ctc 121.652252 loss_ctc_origin 123.464264 loss_ctc0 117.424225 lr 0.00030560 rank 0
2022-08-22 08:41:01,302 DEBUG TRAIN Batch 2/4000 loss 67.191254 loss_att 38.390892 loss_ctc 134.392090 loss_ctc_origin 52.523499 loss_ctc0 325.418823 lr 0.00030760 rank 0
2022-08-22 08:41:32,590 DEBUG TRAIN Batch 2/4100 loss 94.968002 loss_att 51.154198 loss_ctc 197.200195 loss_ctc_origin 77.011765 loss_ctc0 477.639832 lr 0.00030960 rank 0
2022-08-22 08:42:02,877 DEBUG TRAIN Batch 2/4200 loss 62.496880 loss_att 55.069786 loss_ctc 79.826752 loss_ctc_origin 80.631142 loss_ctc0 77.949829 lr 0.00031160 rank 0
2022-08-22 08:42:34,722 DEBUG TRAIN Batch 2/4300 loss 78.142754 loss_att 68.398712 loss_ctc 100.878860 loss_ctc_origin 102.454514 loss_ctc0 97.202362 lr 0.00031360 rank 0
2022-08-22 08:43:05,625 DEBUG TRAIN Batch 2/4400 loss 99.297913 loss_att 87.580963 loss_ctc 126.637451 loss_ctc_origin 128.790619 loss_ctc0 121.613373 lr 0.00031560 rank 0
2022-08-22 08:43:43,559 DEBUG TRAIN Batch 2/4500 loss 53.472092 loss_att 37.794533 loss_ctc 90.053055 loss_ctc_origin 51.516628 loss_ctc0 179.971375 lr 0.00031760 rank 0
2022-08-22 08:43:52,078 WARNING NaN or Inf found in input tensor.
2022-08-22 08:44:15,107 DEBUG TRAIN Batch 2/4600 loss 72.174355 loss_att 53.606571 loss_ctc 115.499168 loss_ctc_origin 78.674469 loss_ctc0 201.423462 lr 0.00031960 rank 0
2022-08-22 08:44:45,737 DEBUG TRAIN Batch 2/4700 loss 70.681549 loss_att 62.658920 loss_ctc 89.401024 loss_ctc_origin 90.644112 loss_ctc0 86.500473 lr 0.00032160 rank 0
2022-08-22 08:45:16,853 DEBUG TRAIN Batch 2/4800 loss 75.917068 loss_att 65.947784 loss_ctc 99.178734 loss_ctc_origin 100.853073 loss_ctc0 95.271935 lr 0.00032360 rank 0
2022-08-22 08:45:47,400 DEBUG TRAIN Batch 2/4900 loss 95.647423 loss_att 84.371696 loss_ctc 121.957443 loss_ctc_origin 124.170471 loss_ctc0 116.793732 lr 0.00032560 rank 0
2022-08-22 08:46:18,903 DEBUG TRAIN Batch 2/5000 loss 46.200783 loss_att 41.557541 loss_ctc 57.035011 loss_ctc_origin 55.563637 loss_ctc0 60.468212 lr 0.00032760 rank 0
2022-08-22 08:46:41,880 WARNING NaN or Inf found in input tensor.
2022-08-22 08:46:49,650 DEBUG TRAIN Batch 2/5100 loss 100.228561 loss_att 53.295029 loss_ctc 209.740143 loss_ctc_origin 71.923981 loss_ctc0 531.311157 lr 0.00032960 rank 0
2022-08-22 08:47:20,590 DEBUG TRAIN Batch 2/5200 loss 63.209717 loss_att 56.703365 loss_ctc 78.391205 loss_ctc_origin 80.072159 loss_ctc0 74.468979 lr 0.00033160 rank 0
2022-08-22 08:47:51,933 DEBUG TRAIN Batch 2/5300 loss 76.125023 loss_att 66.854141 loss_ctc 97.757080 loss_ctc_origin 98.886169 loss_ctc0 95.122543 lr 0.00033360 rank 0
2022-08-22 08:48:23,250 DEBUG TRAIN Batch 2/5400 loss 95.033035 loss_att 83.285217 loss_ctc 122.444603 loss_ctc_origin 124.039185 loss_ctc0 118.723907 lr 0.00033560 rank 0
2022-08-22 08:48:26,108 WARNING NaN or Inf found in input tensor.
2022-08-22 08:48:53,733 DEBUG TRAIN Batch 2/5500 loss 40.931316 loss_att 35.874897 loss_ctc 52.729630 loss_ctc_origin 50.666756 loss_ctc0 57.543003 lr 0.00033760 rank 0
2022-08-22 08:49:25,082 DEBUG TRAIN Batch 2/5600 loss 99.965828 loss_att 47.200951 loss_ctc 223.083878 loss_ctc_origin 72.515564 loss_ctc0 574.409912 lr 0.00033960 rank 0
2022-08-22 08:49:50,776 DEBUG CV Batch 2/0 loss 37.512360 loss_att 33.560184 loss_ctc 46.734108 loss_ctc_origin 47.013416 loss_ctc0 46.082397 history loss 35.305750 rank 0
2022-08-22 08:50:02,927 DEBUG CV Batch 2/100 loss 54.140068 loss_att 46.047718 loss_ctc 73.022209 loss_ctc_origin 74.441948 loss_ctc0 69.709480 history loss 72.611085 rank 0
2022-08-22 08:50:13,747 DEBUG CV Batch 2/200 loss 67.424881 loss_att 59.660400 loss_ctc 85.542000 loss_ctc_origin 86.387512 loss_ctc0 83.569138 history loss 73.274203 rank 0
2022-08-22 08:50:24,640 DEBUG CV Batch 2/300 loss 78.122513 loss_att 69.815079 loss_ctc 97.506516 loss_ctc_origin 98.532127 loss_ctc0 95.113419 history loss 73.637615 rank 0
2022-08-22 08:50:36,051 DEBUG CV Batch 2/400 loss 103.703880 loss_att 93.693466 loss_ctc 127.061508 loss_ctc_origin 128.960663 loss_ctc0 122.630165 history loss 73.156927 rank 0
2022-08-22 08:50:47,575 DEBUG CV Batch 2/500 loss 44.845490 loss_att 39.948311 loss_ctc 56.272232 loss_ctc_origin 57.597088 loss_ctc0 53.180893 history loss 73.649744 rank 0
2022-08-22 08:50:59,581 DEBUG CV Batch 2/600 loss 56.142403 loss_att 48.463306 loss_ctc 74.060303 loss_ctc_origin 75.971893 loss_ctc0 69.599937 history loss 73.698026 rank 0
2022-08-22 08:51:10,857 DEBUG CV Batch 2/700 loss 68.670837 loss_att 62.190086 loss_ctc 83.792587 loss_ctc_origin 83.989189 loss_ctc0 83.333862 history loss 73.552265 rank 0
2022-08-22 08:51:22,205 DEBUG CV Batch 2/800 loss 76.071014 loss_att 68.042961 loss_ctc 94.803123 loss_ctc_origin 95.334824 loss_ctc0 93.562485 history loss 73.789525 rank 0
2022-08-22 08:51:33,712 INFO Epoch 2 CV info cv_loss 74.2182849930096
2022-08-22 08:51:33,713 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/2.pt
2022-08-22 08:51:34,255 INFO Epoch 3 TRAIN info lr 0.00034128
2022-08-22 08:51:34,258 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 08:52:03,391 DEBUG TRAIN Batch 3/0 loss 70.255127 loss_att 37.521606 loss_ctc 146.633331 loss_ctc_origin 52.183472 loss_ctc0 367.016327 lr 0.00034136 rank 0
2022-08-22 08:52:34,362 DEBUG TRAIN Batch 3/100 loss 93.698151 loss_att 42.604790 loss_ctc 212.916000 loss_ctc_origin 73.740707 loss_ctc0 537.658325 lr 0.00034336 rank 0
2022-08-22 08:53:04,726 DEBUG TRAIN Batch 3/200 loss 65.499214 loss_att 56.638599 loss_ctc 86.173981 loss_ctc_origin 86.889328 loss_ctc0 84.504829 lr 0.00034536 rank 0
2022-08-22 08:53:35,901 DEBUG TRAIN Batch 3/300 loss 74.827904 loss_att 65.569763 loss_ctc 96.430222 loss_ctc_origin 97.080070 loss_ctc0 94.913925 lr 0.00034736 rank 0
2022-08-22 08:54:07,189 DEBUG TRAIN Batch 3/400 loss 90.851089 loss_att 79.524521 loss_ctc 117.279755 loss_ctc_origin 118.789383 loss_ctc0 113.757278 lr 0.00034936 rank 0
2022-08-22 08:54:40,174 DEBUG TRAIN Batch 3/500 loss 70.521202 loss_att 40.180061 loss_ctc 141.317184 loss_ctc_origin 58.473412 loss_ctc0 334.619293 lr 0.00035136 rank 0
2022-08-22 08:54:48,605 WARNING NaN or Inf found in input tensor.
2022-08-22 08:55:10,664 DEBUG TRAIN Batch 3/600 loss 93.277115 loss_att 47.896423 loss_ctc 199.165405 loss_ctc_origin 74.622185 loss_ctc0 489.766205 lr 0.00035336 rank 0
2022-08-22 08:55:41,949 DEBUG TRAIN Batch 3/700 loss 60.401340 loss_att 52.639656 loss_ctc 78.511932 loss_ctc_origin 79.325623 loss_ctc0 76.613335 lr 0.00035536 rank 0
2022-08-22 08:55:47,827 WARNING NaN or Inf found in input tensor.
2022-08-22 08:56:13,739 DEBUG TRAIN Batch 3/800 loss 79.363548 loss_att 70.861084 loss_ctc 99.202644 loss_ctc_origin 100.277718 loss_ctc0 96.694138 lr 0.00035736 rank 0
2022-08-22 08:56:45,170 DEBUG TRAIN Batch 3/900 loss 82.568451 loss_att 70.099472 loss_ctc 111.662727 loss_ctc_origin 111.800438 loss_ctc0 111.341400 lr 0.00035936 rank 0
2022-08-22 08:57:17,820 DEBUG TRAIN Batch 3/1000 loss 74.940948 loss_att 43.162121 loss_ctc 149.091553 loss_ctc_origin 61.645966 loss_ctc0 353.131226 lr 0.00036136 rank 0
2022-08-22 08:57:47,516 DEBUG TRAIN Batch 3/1100 loss 99.506226 loss_att 53.293045 loss_ctc 207.336960 loss_ctc_origin 79.956375 loss_ctc0 504.558289 lr 0.00036336 rank 0
2022-08-22 08:58:18,180 DEBUG TRAIN Batch 3/1200 loss 54.007122 loss_att 45.575096 loss_ctc 73.681847 loss_ctc_origin 73.605804 loss_ctc0 73.859268 lr 0.00036536 rank 0
2022-08-22 08:58:48,856 DEBUG TRAIN Batch 3/1300 loss 79.128365 loss_att 68.560226 loss_ctc 103.787354 loss_ctc_origin 104.867737 loss_ctc0 101.266449 lr 0.00036736 rank 0
2022-08-22 08:59:18,941 DEBUG TRAIN Batch 3/1400 loss 79.968483 loss_att 68.026947 loss_ctc 107.832062 loss_ctc_origin 108.382065 loss_ctc0 106.548721 lr 0.00036936 rank 0
2022-08-22 08:59:54,518 DEBUG TRAIN Batch 3/1500 loss 59.685589 loss_att 35.639786 loss_ctc 115.792465 loss_ctc_origin 54.172516 loss_ctc0 259.572327 lr 0.00037136 rank 0
2022-08-22 08:59:55,455 WARNING NaN or Inf found in input tensor.
2022-08-22 09:00:24,095 DEBUG TRAIN Batch 3/1600 loss 86.824829 loss_att 48.153332 loss_ctc 177.058304 loss_ctc_origin 70.234123 loss_ctc0 426.314697 lr 0.00037336 rank 0
2022-08-22 09:00:36,910 WARNING NaN or Inf found in input tensor.
2022-08-22 09:00:53,025 DEBUG TRAIN Batch 3/1700 loss 68.110130 loss_att 60.707581 loss_ctc 85.382751 loss_ctc_origin 86.534958 loss_ctc0 82.694275 lr 0.00037536 rank 0
2022-08-22 09:01:22,140 DEBUG TRAIN Batch 3/1800 loss 76.780869 loss_att 66.097702 loss_ctc 101.708260 loss_ctc_origin 102.954781 loss_ctc0 98.799713 lr 0.00037736 rank 0
2022-08-22 09:01:50,851 DEBUG TRAIN Batch 3/1900 loss 91.695587 loss_att 80.530632 loss_ctc 117.747162 loss_ctc_origin 118.880386 loss_ctc0 115.102951 lr 0.00037936 rank 0
2022-08-22 09:02:18,872 DEBUG TRAIN Batch 3/2000 loss 64.524879 loss_att 35.230930 loss_ctc 132.877426 loss_ctc_origin 57.968094 loss_ctc0 307.665863 lr 0.00038136 rank 0
2022-08-22 09:02:46,363 DEBUG TRAIN Batch 3/2100 loss 95.246063 loss_att 47.497147 loss_ctc 206.660202 loss_ctc_origin 83.324982 loss_ctc0 494.442383 lr 0.00038336 rank 0
2022-08-22 09:03:12,593 DEBUG TRAIN Batch 3/2200 loss 63.905216 loss_att 56.834408 loss_ctc 80.403770 loss_ctc_origin 81.310410 loss_ctc0 78.288284 lr 0.00038536 rank 0
2022-08-22 09:03:40,047 DEBUG TRAIN Batch 3/2300 loss 75.294624 loss_att 66.328873 loss_ctc 96.214706 loss_ctc_origin 96.503281 loss_ctc0 95.541367 lr 0.00038736 rank 0
2022-08-22 09:04:07,172 DEBUG TRAIN Batch 3/2400 loss 96.655495 loss_att 87.133591 loss_ctc 118.873276 loss_ctc_origin 120.240402 loss_ctc0 115.683304 lr 0.00038936 rank 0
2022-08-22 09:04:09,704 WARNING NaN or Inf found in input tensor.
2022-08-22 09:04:33,634 DEBUG TRAIN Batch 3/2500 loss 61.568451 loss_att 36.595795 loss_ctc 119.837990 loss_ctc_origin 54.688797 loss_ctc0 271.852753 lr 0.00039136 rank 0
2022-08-22 09:04:46,169 WARNING NaN or Inf found in input tensor.
2022-08-22 09:05:00,179 DEBUG TRAIN Batch 3/2600 loss 88.087357 loss_att 52.956818 loss_ctc 170.058609 loss_ctc_origin 80.903664 loss_ctc0 378.086823 lr 0.00039336 rank 0
2022-08-22 09:05:26,066 DEBUG TRAIN Batch 3/2700 loss 55.357315 loss_att 46.691757 loss_ctc 75.576950 loss_ctc_origin 75.278709 loss_ctc0 76.272858 lr 0.00039536 rank 0
2022-08-22 09:05:52,912 DEBUG TRAIN Batch 3/2800 loss 78.758537 loss_att 68.772232 loss_ctc 102.059914 loss_ctc_origin 103.390488 loss_ctc0 98.955261 lr 0.00039736 rank 0
2022-08-22 09:06:09,766 WARNING NaN or Inf found in input tensor.
2022-08-22 09:06:21,052 DEBUG TRAIN Batch 3/2900 loss 93.937424 loss_att 82.171059 loss_ctc 121.392273 loss_ctc_origin 122.870865 loss_ctc0 117.942238 lr 0.00039936 rank 0
2022-08-22 09:06:52,391 DEBUG TRAIN Batch 3/3000 loss 52.385811 loss_att 35.952847 loss_ctc 90.729385 loss_ctc_origin 55.632298 loss_ctc0 172.622589 lr 0.00040136 rank 0
2022-08-22 09:07:22,769 DEBUG TRAIN Batch 3/3100 loss 80.310814 loss_att 46.045792 loss_ctc 160.262527 loss_ctc_origin 75.036942 loss_ctc0 359.122192 lr 0.00040336 rank 0
2022-08-22 09:07:56,952 DEBUG TRAIN Batch 3/3200 loss 60.042595 loss_att 52.045105 loss_ctc 78.703400 loss_ctc_origin 79.087860 loss_ctc0 77.806335 lr 0.00040536 rank 0
2022-08-22 09:08:31,960 DEBUG TRAIN Batch 3/3300 loss 73.189713 loss_att 63.410282 loss_ctc 96.008377 loss_ctc_origin 96.686539 loss_ctc0 94.426025 lr 0.00040736 rank 0
2022-08-22 09:09:05,620 DEBUG TRAIN Batch 3/3400 loss 83.078743 loss_att 72.134781 loss_ctc 108.614655 loss_ctc_origin 109.194130 loss_ctc0 107.262527 lr 0.00040936 rank 0
2022-08-22 09:09:41,189 DEBUG TRAIN Batch 3/3500 loss 54.769768 loss_att 35.836651 loss_ctc 98.947044 loss_ctc_origin 55.731182 loss_ctc0 199.784058 lr 0.00041136 rank 0
2022-08-22 09:10:14,988 DEBUG TRAIN Batch 3/3600 loss 91.177338 loss_att 48.118835 loss_ctc 191.647156 loss_ctc_origin 77.655495 loss_ctc0 457.627686 lr 0.00041336 rank 0
2022-08-22 09:10:48,787 DEBUG TRAIN Batch 3/3700 loss 69.541641 loss_att 60.529114 loss_ctc 90.570862 loss_ctc_origin 91.632683 loss_ctc0 88.093292 lr 0.00041536 rank 0
2022-08-22 09:11:23,693 DEBUG TRAIN Batch 3/3800 loss 70.065948 loss_att 61.597328 loss_ctc 89.826065 loss_ctc_origin 90.895439 loss_ctc0 87.330849 lr 0.00041736 rank 0
2022-08-22 09:11:58,134 DEBUG TRAIN Batch 3/3900 loss 82.690445 loss_att 70.076782 loss_ctc 112.122330 loss_ctc_origin 112.837921 loss_ctc0 110.452621 lr 0.00041936 rank 0
2022-08-22 09:12:33,015 DEBUG TRAIN Batch 3/4000 loss 61.593254 loss_att 40.151890 loss_ctc 111.623093 loss_ctc_origin 58.652107 loss_ctc0 235.222046 lr 0.00042136 rank 0
2022-08-22 09:13:07,272 DEBUG TRAIN Batch 3/4100 loss 87.635796 loss_att 53.291168 loss_ctc 167.773254 loss_ctc_origin 86.696259 loss_ctc0 356.952911 lr 0.00042336 rank 0
2022-08-22 09:13:41,539 DEBUG TRAIN Batch 3/4200 loss 58.144127 loss_att 49.846008 loss_ctc 77.506409 loss_ctc_origin 78.631966 loss_ctc0 74.880119 lr 0.00042536 rank 0
2022-08-22 09:14:13,863 DEBUG TRAIN Batch 3/4300 loss 75.752777 loss_att 66.388687 loss_ctc 97.602310 loss_ctc_origin 98.631058 loss_ctc0 95.201889 lr 0.00042736 rank 0
2022-08-22 09:14:44,381 DEBUG TRAIN Batch 3/4400 loss 84.256210 loss_att 73.916718 loss_ctc 108.381676 loss_ctc_origin 108.713242 loss_ctc0 107.608032 lr 0.00042936 rank 0
2022-08-22 09:15:23,048 DEBUG TRAIN Batch 3/4500 loss 59.612125 loss_att 37.830009 loss_ctc 110.437057 loss_ctc_origin 58.894169 loss_ctc0 230.703796 lr 0.00043136 rank 0
2022-08-22 09:15:54,236 DEBUG TRAIN Batch 3/4600 loss 84.503723 loss_att 51.541931 loss_ctc 161.414566 loss_ctc_origin 81.436821 loss_ctc0 348.029297 lr 0.00043336 rank 0
2022-08-22 09:16:25,506 DEBUG TRAIN Batch 3/4700 loss 63.615280 loss_att 55.983994 loss_ctc 81.421616 loss_ctc_origin 82.202766 loss_ctc0 79.598930 lr 0.00043536 rank 0
2022-08-22 09:16:57,265 DEBUG TRAIN Batch 3/4800 loss 75.629128 loss_att 66.704910 loss_ctc 96.452309 loss_ctc_origin 98.262054 loss_ctc0 92.229553 lr 0.00043736 rank 0
2022-08-22 09:17:29,268 DEBUG TRAIN Batch 3/4900 loss 87.815918 loss_att 78.550713 loss_ctc 109.434746 loss_ctc_origin 111.734161 loss_ctc0 104.069443 lr 0.00043936 rank 0
2022-08-22 09:18:08,868 DEBUG TRAIN Batch 3/5000 loss 42.368229 loss_att 36.903488 loss_ctc 55.119289 loss_ctc_origin 52.838478 loss_ctc0 60.441181 lr 0.00044136 rank 0
2022-08-22 09:18:52,369 DEBUG TRAIN Batch 3/5100 loss 96.679710 loss_att 48.727448 loss_ctc 208.568329 loss_ctc_origin 74.865723 loss_ctc0 520.541077 lr 0.00044336 rank 0
2022-08-22 09:19:36,718 DEBUG TRAIN Batch 3/5200 loss 60.077290 loss_att 52.597015 loss_ctc 77.531265 loss_ctc_origin 78.271767 loss_ctc0 75.803436 lr 0.00044536 rank 0
2022-08-22 09:20:19,944 DEBUG TRAIN Batch 3/5300 loss 64.578377 loss_att 55.490166 loss_ctc 85.784187 loss_ctc_origin 86.799484 loss_ctc0 83.415146 lr 0.00044736 rank 0
2022-08-22 09:21:04,944 DEBUG TRAIN Batch 3/5400 loss 82.937263 loss_att 72.334900 loss_ctc 107.676102 loss_ctc_origin 109.661018 loss_ctc0 103.044632 lr 0.00044936 rank 0
2022-08-22 09:21:49,030 DEBUG TRAIN Batch 3/5500 loss 60.930679 loss_att 44.854660 loss_ctc 98.441391 loss_ctc_origin 63.966537 loss_ctc0 178.882706 lr 0.00045136 rank 0
2022-08-22 09:22:22,669 WARNING NaN or Inf found in input tensor.
2022-08-22 09:22:31,788 DEBUG TRAIN Batch 3/5600 loss 72.232819 loss_att 48.043465 loss_ctc 128.674652 loss_ctc_origin 80.183746 loss_ctc0 241.820099 lr 0.00045336 rank 0
2022-08-22 09:23:03,123 DEBUG CV Batch 3/0 loss 36.273155 loss_att 31.681854 loss_ctc 46.986191 loss_ctc_origin 47.527859 loss_ctc0 45.722305 history loss 34.139440 rank 0
2022-08-22 09:23:18,633 DEBUG CV Batch 3/100 loss 51.977615 loss_att 43.778137 loss_ctc 71.109734 loss_ctc_origin 71.058380 loss_ctc0 71.229568 history loss 68.048310 rank 0
2022-08-22 09:23:33,504 DEBUG CV Batch 3/200 loss 63.018143 loss_att 57.093338 loss_ctc 76.842682 loss_ctc_origin 79.195404 loss_ctc0 71.352989 history loss 68.902325 rank 0
2022-08-22 09:23:48,093 DEBUG CV Batch 3/300 loss 70.976685 loss_att 62.789825 loss_ctc 90.079369 loss_ctc_origin 91.451767 loss_ctc0 86.877106 history loss 68.979735 rank 0
2022-08-22 09:24:03,812 DEBUG CV Batch 3/400 loss 96.955048 loss_att 87.279785 loss_ctc 119.530670 loss_ctc_origin 122.255234 loss_ctc0 113.173347 history loss 68.285051 rank 0
2022-08-22 09:24:20,748 DEBUG CV Batch 3/500 loss 43.885689 loss_att 38.472591 loss_ctc 56.516251 loss_ctc_origin 57.661873 loss_ctc0 53.843136 history loss 68.681264 rank 0
2022-08-22 09:24:36,611 DEBUG CV Batch 3/600 loss 53.050827 loss_att 45.152359 loss_ctc 71.480591 loss_ctc_origin 71.940018 loss_ctc0 70.408577 history loss 68.760917 rank 0
2022-08-22 09:24:51,383 DEBUG CV Batch 3/700 loss 62.254639 loss_att 55.945255 loss_ctc 76.976532 loss_ctc_origin 77.708344 loss_ctc0 75.268982 history loss 68.593724 rank 0
2022-08-22 09:25:07,083 DEBUG CV Batch 3/800 loss 68.562965 loss_att 61.128666 loss_ctc 85.909668 loss_ctc_origin 86.849075 loss_ctc0 83.717712 history loss 68.772872 rank 0
2022-08-22 09:25:21,769 INFO Epoch 3 CV info cv_loss 69.17111989709116
2022-08-22 09:25:21,769 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/3.pt
2022-08-22 09:25:22,575 INFO Epoch 4 TRAIN info lr 0.00045504
2022-08-22 09:25:22,579 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 09:26:04,221 DEBUG TRAIN Batch 4/0 loss 50.063190 loss_att 35.172028 loss_ctc 84.809235 loss_ctc_origin 59.536125 loss_ctc0 143.779831 lr 0.00045512 rank 0
2022-08-22 09:26:48,388 DEBUG TRAIN Batch 4/100 loss 66.822983 loss_att 45.580425 loss_ctc 116.388947 loss_ctc_origin 75.608765 loss_ctc0 211.542694 lr 0.00045712 rank 0
2022-08-22 09:27:32,561 DEBUG TRAIN Batch 4/200 loss 62.600731 loss_att 53.049583 loss_ctc 84.886742 loss_ctc_origin 85.570724 loss_ctc0 83.290787 lr 0.00045912 rank 0
2022-08-22 09:28:15,606 DEBUG TRAIN Batch 4/300 loss 68.692757 loss_att 60.716766 loss_ctc 87.303391 loss_ctc_origin 88.706741 loss_ctc0 84.028900 lr 0.00046112 rank 0
2022-08-22 09:28:59,532 DEBUG TRAIN Batch 4/400 loss 78.774872 loss_att 68.414589 loss_ctc 102.948868 loss_ctc_origin 106.007027 loss_ctc0 95.813164 lr 0.00046312 rank 0
2022-08-22 09:29:43,805 DEBUG TRAIN Batch 4/500 loss 59.249123 loss_att 38.986519 loss_ctc 106.528519 loss_ctc_origin 59.168095 loss_ctc0 217.036179 lr 0.00046512 rank 0
2022-08-22 09:30:26,144 DEBUG TRAIN Batch 4/600 loss 80.358780 loss_att 50.900665 loss_ctc 149.094391 loss_ctc_origin 78.894592 loss_ctc0 312.893890 lr 0.00046712 rank 0
2022-08-22 09:31:10,258 DEBUG TRAIN Batch 4/700 loss 57.783714 loss_att 49.315521 loss_ctc 77.542831 loss_ctc_origin 79.365601 loss_ctc0 73.289719 lr 0.00046912 rank 0
2022-08-22 09:31:52,961 DEBUG TRAIN Batch 4/800 loss 70.824905 loss_att 61.531502 loss_ctc 92.509521 loss_ctc_origin 93.479790 loss_ctc0 90.245575 lr 0.00047112 rank 0
2022-08-22 09:32:29,540 DEBUG TRAIN Batch 4/900 loss 77.740440 loss_att 67.597076 loss_ctc 101.408287 loss_ctc_origin 103.665100 loss_ctc0 96.142395 lr 0.00047312 rank 0
2022-08-22 09:33:06,606 DEBUG TRAIN Batch 4/1000 loss 59.741989 loss_att 38.616566 loss_ctc 109.034653 loss_ctc_origin 60.561539 loss_ctc0 222.138596 lr 0.00047512 rank 0
2022-08-22 09:33:43,175 DEBUG TRAIN Batch 4/1100 loss 89.893517 loss_att 56.897682 loss_ctc 166.883789 loss_ctc_origin 86.354820 loss_ctc0 354.784698 lr 0.00047712 rank 0
2022-08-22 09:34:19,073 DEBUG TRAIN Batch 4/1200 loss 59.408310 loss_att 53.173470 loss_ctc 73.956268 loss_ctc_origin 75.945724 loss_ctc0 69.314217 lr 0.00047912 rank 0
2022-08-22 09:34:57,091 DEBUG TRAIN Batch 4/1300 loss 69.962433 loss_att 61.076687 loss_ctc 90.695824 loss_ctc_origin 93.064964 loss_ctc0 85.167816 lr 0.00048112 rank 0
2022-08-22 09:35:33,672 DEBUG TRAIN Batch 4/1400 loss 84.296944 loss_att 71.567764 loss_ctc 113.998352 loss_ctc_origin 116.715042 loss_ctc0 107.659393 lr 0.00048312 rank 0
2022-08-22 09:36:22,417 DEBUG TRAIN Batch 4/1500 loss 63.249725 loss_att 30.666897 loss_ctc 139.276321 loss_ctc_origin 48.967606 loss_ctc0 349.996643 lr 0.00048512 rank 0
2022-08-22 09:36:58,680 DEBUG TRAIN Batch 4/1600 loss 105.444382 loss_att 47.642677 loss_ctc 240.315033 loss_ctc_origin 85.221375 loss_ctc0 602.200195 lr 0.00048712 rank 0
2022-08-22 09:37:32,240 WARNING NaN or Inf found in input tensor.
2022-08-22 09:37:34,098 DEBUG TRAIN Batch 4/1700 loss 63.134842 loss_att 55.315617 loss_ctc 81.379700 loss_ctc_origin 84.122124 loss_ctc0 74.980698 lr 0.00048912 rank 0
2022-08-22 09:38:09,571 DEBUG TRAIN Batch 4/1800 loss 72.288887 loss_att 64.020378 loss_ctc 91.582069 loss_ctc_origin 94.065491 loss_ctc0 85.787422 lr 0.00049112 rank 0
2022-08-22 09:38:45,602 DEBUG TRAIN Batch 4/1900 loss 87.481369 loss_att 75.632233 loss_ctc 115.129333 loss_ctc_origin 118.877991 loss_ctc0 106.382477 lr 0.00049312 rank 0
2022-08-22 09:39:23,486 DEBUG TRAIN Batch 4/2000 loss 81.962502 loss_att 38.779385 loss_ctc 182.723099 loss_ctc_origin 62.787548 loss_ctc0 462.572693 lr 0.00049512 rank 0
2022-08-22 09:39:59,333 DEBUG TRAIN Batch 4/2100 loss 108.306854 loss_att 48.017792 loss_ctc 248.981308 loss_ctc_origin 87.319366 loss_ctc0 626.192505 lr 0.00049712 rank 0
2022-08-22 09:40:33,535 DEBUG TRAIN Batch 4/2200 loss 57.053680 loss_att 49.412792 loss_ctc 74.882416 loss_ctc_origin 76.167015 loss_ctc0 71.885002 lr 0.00049912 rank 0
2022-08-22 09:41:10,676 DEBUG TRAIN Batch 4/2300 loss 71.822014 loss_att 61.813637 loss_ctc 95.174881 loss_ctc_origin 98.282120 loss_ctc0 87.924637 lr 0.00050112 rank 0
2022-08-22 09:41:45,868 DEBUG TRAIN Batch 4/2400 loss 78.936928 loss_att 69.190186 loss_ctc 101.679329 loss_ctc_origin 103.241806 loss_ctc0 98.033539 lr 0.00050312 rank 0
2022-08-22 09:42:21,380 DEBUG TRAIN Batch 4/2500 loss 72.874313 loss_att 34.406693 loss_ctc 162.632095 loss_ctc_origin 56.001572 loss_ctc0 411.436646 lr 0.00050512 rank 0
2022-08-22 09:42:57,170 DEBUG TRAIN Batch 4/2600 loss 108.160332 loss_att 47.080833 loss_ctc 250.679153 loss_ctc_origin 87.739716 loss_ctc0 630.871155 lr 0.00050712 rank 0
2022-08-22 09:43:30,320 WARNING NaN or Inf found in input tensor.
2022-08-22 09:43:32,081 DEBUG TRAIN Batch 4/2700 loss 51.929184 loss_att 45.600006 loss_ctc 66.697266 loss_ctc_origin 68.195908 loss_ctc0 63.200439 lr 0.00050912 rank 0
2022-08-22 09:44:05,935 DEBUG TRAIN Batch 4/2800 loss 70.323631 loss_att 61.208565 loss_ctc 91.592133 loss_ctc_origin 93.654572 loss_ctc0 86.779778 lr 0.00051112 rank 0
2022-08-22 09:44:38,728 DEBUG TRAIN Batch 4/2900 loss 89.880280 loss_att 80.806229 loss_ctc 111.053085 loss_ctc_origin 114.503891 loss_ctc0 103.001205 lr 0.00051312 rank 0
2022-08-22 09:45:20,789 DEBUG TRAIN Batch 4/3000 loss 72.694099 loss_att 38.035934 loss_ctc 153.563156 loss_ctc_origin 58.310467 loss_ctc0 375.819427 lr 0.00051512 rank 0
2022-08-22 09:45:37,119 WARNING NaN or Inf found in input tensor.
2022-08-22 09:45:52,614 DEBUG TRAIN Batch 4/3100 loss 107.300537 loss_att 47.263393 loss_ctc 247.387207 loss_ctc_origin 84.712708 loss_ctc0 626.961060 lr 0.00051712 rank 0
2022-08-22 09:46:24,656 DEBUG TRAIN Batch 4/3200 loss 56.489098 loss_att 48.887138 loss_ctc 74.226997 loss_ctc_origin 75.734291 loss_ctc0 70.709976 lr 0.00051912 rank 0
2022-08-22 09:46:54,678 DEBUG TRAIN Batch 4/3300 loss 61.631195 loss_att 51.450966 loss_ctc 85.385056 loss_ctc_origin 87.148697 loss_ctc0 81.269897 lr 0.00052112 rank 0
2022-08-22 09:47:25,863 DEBUG TRAIN Batch 4/3400 loss 70.948540 loss_att 60.937012 loss_ctc 94.308769 loss_ctc_origin 95.785797 loss_ctc0 90.862366 lr 0.00052312 rank 0
2022-08-22 09:47:57,723 DEBUG TRAIN Batch 4/3500 loss 48.001152 loss_att 39.595482 loss_ctc 67.614380 loss_ctc_origin 58.199135 loss_ctc0 89.583282 lr 0.00052512 rank 0
2022-08-22 09:48:27,584 DEBUG TRAIN Batch 4/3600 loss 66.505486 loss_att 48.577412 loss_ctc 108.337654 loss_ctc_origin 71.936874 loss_ctc0 193.272797 lr 0.00052712 rank 0
2022-08-22 09:48:59,293 DEBUG TRAIN Batch 4/3700 loss 56.061340 loss_att 48.548691 loss_ctc 73.590866 loss_ctc_origin 75.359932 loss_ctc0 69.463028 lr 0.00052912 rank 0
2022-08-22 09:49:29,208 DEBUG TRAIN Batch 4/3800 loss 65.229942 loss_att 57.310257 loss_ctc 83.709206 loss_ctc_origin 86.556564 loss_ctc0 77.065361 lr 0.00053112 rank 0
2022-08-22 09:50:01,235 DEBUG TRAIN Batch 4/3900 loss 87.144348 loss_att 77.764778 loss_ctc 109.029999 loss_ctc_origin 112.057938 loss_ctc0 101.964828 lr 0.00053312 rank 0
2022-08-22 09:50:32,582 DEBUG TRAIN Batch 4/4000 loss 46.857822 loss_att 40.160179 loss_ctc 62.485657 loss_ctc_origin 52.187824 loss_ctc0 86.513939 lr 0.00053512 rank 0
2022-08-22 09:51:03,502 DEBUG TRAIN Batch 4/4100 loss 69.421860 loss_att 45.577324 loss_ctc 125.059105 loss_ctc_origin 69.331436 loss_ctc0 255.090317 lr 0.00053712 rank 0
2022-08-22 09:51:34,011 DEBUG TRAIN Batch 4/4200 loss 51.330265 loss_att 43.963192 loss_ctc 68.520096 loss_ctc_origin 70.754105 loss_ctc0 63.307396 lr 0.00053912 rank 0
2022-08-22 09:52:05,576 DEBUG TRAIN Batch 4/4300 loss 73.108719 loss_att 63.951244 loss_ctc 94.476173 loss_ctc_origin 97.121948 loss_ctc0 88.302704 lr 0.00054112 rank 0
2022-08-22 09:52:36,187 DEBUG TRAIN Batch 4/4400 loss 82.742287 loss_att 72.155334 loss_ctc 107.445175 loss_ctc_origin 110.415207 loss_ctc0 100.515121 lr 0.00054312 rank 0
2022-08-22 09:53:14,171 DEBUG TRAIN Batch 4/4500 loss 55.228558 loss_att 39.602974 loss_ctc 91.688248 loss_ctc_origin 58.636166 loss_ctc0 168.809784 lr 0.00054512 rank 0
2022-08-22 09:53:44,864 DEBUG TRAIN Batch 4/4600 loss 57.022804 loss_att 42.365288 loss_ctc 91.223679 loss_ctc_origin 63.336189 loss_ctc0 156.294479 lr 0.00054712 rank 0
2022-08-22 09:54:14,269 DEBUG TRAIN Batch 4/4700 loss 58.629288 loss_att 51.040478 loss_ctc 76.336517 loss_ctc_origin 77.878571 loss_ctc0 72.738396 lr 0.00054912 rank 0
2022-08-22 09:54:19,963 WARNING NaN or Inf found in input tensor.
2022-08-22 09:54:44,269 DEBUG TRAIN Batch 4/4800 loss 74.977867 loss_att 65.269676 loss_ctc 97.630310 loss_ctc_origin 99.789108 loss_ctc0 92.593124 lr 0.00055112 rank 0
2022-08-22 09:55:12,611 DEBUG TRAIN Batch 4/4900 loss 78.469826 loss_att 67.885834 loss_ctc 103.165794 loss_ctc_origin 104.459946 loss_ctc0 100.146103 lr 0.00055312 rank 0
2022-08-22 09:55:40,612 DEBUG TRAIN Batch 4/5000 loss 39.450161 loss_att 35.430725 loss_ctc 48.828846 loss_ctc_origin 48.770241 loss_ctc0 48.965588 lr 0.00055512 rank 0
2022-08-22 09:55:48,138 WARNING NaN or Inf found in input tensor.
2022-08-22 09:56:09,361 DEBUG TRAIN Batch 4/5100 loss 66.240517 loss_att 48.624825 loss_ctc 107.343796 loss_ctc_origin 75.676163 loss_ctc0 181.234955 lr 0.00055712 rank 0
2022-08-22 09:56:36,834 DEBUG TRAIN Batch 4/5200 loss 58.488281 loss_att 50.753956 loss_ctc 76.535049 loss_ctc_origin 78.383629 loss_ctc0 72.221695 lr 0.00055912 rank 0
2022-08-22 09:57:04,555 DEBUG TRAIN Batch 4/5300 loss 58.883617 loss_att 48.912903 loss_ctc 82.148613 loss_ctc_origin 83.413635 loss_ctc0 79.196892 lr 0.00056112 rank 0
2022-08-22 09:57:31,665 DEBUG TRAIN Batch 4/5400 loss 78.387909 loss_att 69.161087 loss_ctc 99.917152 loss_ctc_origin 100.924950 loss_ctc0 97.565643 lr 0.00056312 rank 0
2022-08-22 09:58:00,164 DEBUG TRAIN Batch 4/5500 loss 52.581886 loss_att 34.668236 loss_ctc 94.380394 loss_ctc_origin 55.746780 loss_ctc0 184.525482 lr 0.00056512 rank 0
2022-08-22 09:58:27,654 DEBUG TRAIN Batch 4/5600 loss 68.593216 loss_att 46.473877 loss_ctc 120.205002 loss_ctc_origin 69.612167 loss_ctc0 238.254944 lr 0.00056712 rank 0
2022-08-22 09:58:49,546 DEBUG CV Batch 4/0 loss 33.901268 loss_att 30.886452 loss_ctc 40.935837 loss_ctc_origin 41.847252 loss_ctc0 38.809204 history loss 31.907076 rank 0
2022-08-22 09:59:00,002 DEBUG CV Batch 4/100 loss 46.805447 loss_att 40.258350 loss_ctc 62.082005 loss_ctc_origin 62.960522 loss_ctc0 60.032127 history loss 62.812083 rank 0
2022-08-22 09:59:09,509 DEBUG CV Batch 4/200 loss 59.023201 loss_att 52.684372 loss_ctc 73.813812 loss_ctc_origin 76.014206 loss_ctc0 68.679550 history loss 63.867904 rank 0
2022-08-22 09:59:19,481 DEBUG CV Batch 4/300 loss 64.753624 loss_att 57.390900 loss_ctc 81.933311 loss_ctc_origin 84.410385 loss_ctc0 76.153473 history loss 63.776634 rank 0
2022-08-22 09:59:29,552 DEBUG CV Batch 4/400 loss 90.570419 loss_att 82.041397 loss_ctc 110.471466 loss_ctc_origin 114.434143 loss_ctc0 101.225220 history loss 62.874664 rank 0
2022-08-22 09:59:39,921 DEBUG CV Batch 4/500 loss 40.076828 loss_att 36.141209 loss_ctc 49.259937 loss_ctc_origin 50.211857 loss_ctc0 47.038788 history loss 63.204738 rank 0
2022-08-22 09:59:50,167 DEBUG CV Batch 4/600 loss 48.194115 loss_att 41.493103 loss_ctc 63.829815 loss_ctc_origin 64.848434 loss_ctc0 61.453041 history loss 63.244677 rank 0
2022-08-22 09:59:59,203 DEBUG CV Batch 4/700 loss 57.038975 loss_att 50.730679 loss_ctc 71.758331 loss_ctc_origin 73.524872 loss_ctc0 67.636383 history loss 63.054327 rank 0
2022-08-22 10:00:09,293 DEBUG CV Batch 4/800 loss 62.836895 loss_att 56.147881 loss_ctc 78.444595 loss_ctc_origin 80.583397 loss_ctc0 73.454048 history loss 63.213923 rank 0
2022-08-22 10:00:19,562 INFO Epoch 4 CV info cv_loss 63.55882386408407
2022-08-22 10:00:19,562 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/4.pt
2022-08-22 10:00:20,106 INFO Epoch 5 TRAIN info lr 0.0005688
2022-08-22 10:00:20,109 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 10:00:46,975 DEBUG TRAIN Batch 5/0 loss 54.504051 loss_att 40.322052 loss_ctc 87.595383 loss_ctc_origin 61.216469 loss_ctc0 149.146179 lr 0.00056888 rank 0
2022-08-22 10:01:14,910 DEBUG TRAIN Batch 5/100 loss 67.314056 loss_att 48.552719 loss_ctc 111.090485 loss_ctc_origin 70.794296 loss_ctc0 205.114899 lr 0.00057088 rank 0
2022-08-22 10:01:41,877 DEBUG TRAIN Batch 5/200 loss 62.089317 loss_att 53.883743 loss_ctc 81.235657 loss_ctc_origin 83.658974 loss_ctc0 75.581268 lr 0.00057288 rank 0
2022-08-22 10:02:08,819 DEBUG TRAIN Batch 5/300 loss 66.551010 loss_att 57.345623 loss_ctc 88.030228 loss_ctc_origin 90.090698 loss_ctc0 83.222473 lr 0.00057488 rank 0
2022-08-22 10:02:36,008 DEBUG TRAIN Batch 5/400 loss 81.313034 loss_att 71.369324 loss_ctc 104.515015 loss_ctc_origin 106.862526 loss_ctc0 99.037506 lr 0.00057688 rank 0
2022-08-22 10:02:56,030 WARNING NaN or Inf found in input tensor.
2022-08-22 10:03:03,259 DEBUG TRAIN Batch 5/500 loss 48.247593 loss_att 37.094536 loss_ctc 74.271393 loss_ctc_origin 51.791897 loss_ctc0 126.723541 lr 0.00057888 rank 0
2022-08-22 10:03:30,509 DEBUG TRAIN Batch 5/600 loss 61.834389 loss_att 39.580292 loss_ctc 113.760612 loss_ctc_origin 62.544697 loss_ctc0 233.264404 lr 0.00058088 rank 0
2022-08-22 10:03:56,685 DEBUG TRAIN Batch 5/700 loss 58.273018 loss_att 51.299568 loss_ctc 74.544403 loss_ctc_origin 76.433220 loss_ctc0 70.137146 lr 0.00058288 rank 0
2022-08-22 10:04:24,318 DEBUG TRAIN Batch 5/800 loss 65.074776 loss_att 55.662910 loss_ctc 87.035797 loss_ctc_origin 88.957809 loss_ctc0 82.551102 lr 0.00058488 rank 0
2022-08-22 10:04:52,312 DEBUG TRAIN Batch 5/900 loss 73.135468 loss_att 62.818230 loss_ctc 97.209023 loss_ctc_origin 98.370193 loss_ctc0 94.499634 lr 0.00058688 rank 0
2022-08-22 10:05:20,144 DEBUG TRAIN Batch 5/1000 loss 40.092384 loss_att 32.519737 loss_ctc 57.761902 loss_ctc_origin 44.195015 loss_ctc0 89.417961 lr 0.00058888 rank 0
2022-08-22 10:05:32,614 WARNING NaN or Inf found in input tensor.
2022-08-22 10:05:46,599 DEBUG TRAIN Batch 5/1100 loss 64.351776 loss_att 44.986694 loss_ctc 109.536972 loss_ctc_origin 72.171707 loss_ctc0 196.722580 lr 0.00059088 rank 0
2022-08-22 10:06:14,594 DEBUG TRAIN Batch 5/1200 loss 57.708763 loss_att 50.956306 loss_ctc 73.464485 loss_ctc_origin 75.788956 loss_ctc0 68.040718 lr 0.00059288 rank 0
2022-08-22 10:06:42,262 DEBUG TRAIN Batch 5/1300 loss 60.786263 loss_att 51.573788 loss_ctc 82.282043 loss_ctc_origin 85.842545 loss_ctc0 73.974197 lr 0.00059488 rank 0
2022-08-22 10:07:09,161 DEBUG TRAIN Batch 5/1400 loss 72.588203 loss_att 61.354843 loss_ctc 98.799377 loss_ctc_origin 100.962929 loss_ctc0 93.751099 lr 0.00059688 rank 0
2022-08-22 10:07:41,784 DEBUG TRAIN Batch 5/1500 loss 53.286674 loss_att 34.431030 loss_ctc 97.283173 loss_ctc_origin 50.587849 loss_ctc0 206.238907 lr 0.00059888 rank 0
2022-08-22 10:08:10,332 DEBUG TRAIN Batch 5/1600 loss 52.829876 loss_att 44.954227 loss_ctc 71.206390 loss_ctc_origin 66.708099 loss_ctc0 81.702408 lr 0.00060088 rank 0
2022-08-22 10:08:37,380 DEBUG TRAIN Batch 5/1700 loss 58.597076 loss_att 51.131008 loss_ctc 76.017891 loss_ctc_origin 76.512299 loss_ctc0 74.864273 lr 0.00060288 rank 0
2022-08-22 10:09:03,887 DEBUG TRAIN Batch 5/1800 loss 62.812248 loss_att 52.808372 loss_ctc 86.154625 loss_ctc_origin 88.733582 loss_ctc0 80.137054 lr 0.00060488 rank 0
2022-08-22 10:09:31,463 DEBUG TRAIN Batch 5/1900 loss 77.145477 loss_att 66.233284 loss_ctc 102.607254 loss_ctc_origin 106.779060 loss_ctc0 92.873047 lr 0.00060688 rank 0
2022-08-22 10:10:00,046 DEBUG TRAIN Batch 5/2000 loss 42.820827 loss_att 37.973030 loss_ctc 54.132351 loss_ctc_origin 56.458111 loss_ctc0 48.705578 lr 0.00060888 rank 0
2022-08-22 10:10:27,185 DEBUG TRAIN Batch 5/2100 loss 51.431282 loss_att 42.060608 loss_ctc 73.296188 loss_ctc_origin 62.279598 loss_ctc0 99.001572 lr 0.00061088 rank 0
2022-08-22 10:10:53,995 DEBUG TRAIN Batch 5/2200 loss 56.955841 loss_att 50.691109 loss_ctc 71.573555 loss_ctc_origin 73.690414 loss_ctc0 66.634216 lr 0.00061288 rank 0
2022-08-22 10:11:20,847 DEBUG TRAIN Batch 5/2300 loss 65.648842 loss_att 56.851318 loss_ctc 86.176407 loss_ctc_origin 87.588318 loss_ctc0 82.881935 lr 0.00061488 rank 0
2022-08-22 10:11:44,320 WARNING NaN or Inf found in input tensor.
2022-08-22 10:11:48,493 DEBUG TRAIN Batch 5/2400 loss 78.078598 loss_att 68.886963 loss_ctc 99.525742 loss_ctc_origin 101.917542 loss_ctc0 93.944885 lr 0.00061688 rank 0
2022-08-22 10:12:17,026 DEBUG TRAIN Batch 5/2500 loss 53.812054 loss_att 39.539352 loss_ctc 87.115021 loss_ctc_origin 53.672684 loss_ctc0 165.147156 lr 0.00061888 rank 0
2022-08-22 10:12:44,391 DEBUG TRAIN Batch 5/2600 loss 60.879341 loss_att 43.092438 loss_ctc 102.382111 loss_ctc_origin 65.411407 loss_ctc0 188.647095 lr 0.00062088 rank 0
2022-08-22 10:13:10,089 WARNING NaN or Inf found in input tensor.
2022-08-22 10:13:11,660 DEBUG TRAIN Batch 5/2700 loss 58.188950 loss_att 51.386299 loss_ctc 74.061798 loss_ctc_origin 75.111481 loss_ctc0 71.612518 lr 0.00062288 rank 0
2022-08-22 10:13:39,580 DEBUG TRAIN Batch 5/2800 loss 65.275040 loss_att 55.417107 loss_ctc 88.276878 loss_ctc_origin 88.073471 loss_ctc0 88.751495 lr 0.00062488 rank 0
2022-08-22 10:14:07,030 DEBUG TRAIN Batch 5/2900 loss 75.421112 loss_att 63.361866 loss_ctc 103.559357 loss_ctc_origin 105.648376 loss_ctc0 98.684967 lr 0.00062688 rank 0
2022-08-22 10:14:40,987 DEBUG TRAIN Batch 5/3000 loss 40.391029 loss_att 33.161789 loss_ctc 57.259254 loss_ctc_origin 46.370766 loss_ctc0 82.665733 lr 0.00062888 rank 0
2022-08-22 10:15:07,790 DEBUG TRAIN Batch 5/3100 loss 54.490314 loss_att 39.182808 loss_ctc 90.207825 loss_ctc_origin 63.099594 loss_ctc0 153.460342 lr 0.00063088 rank 0
2022-08-22 10:15:34,841 DEBUG TRAIN Batch 5/3200 loss 54.529587 loss_att 46.466118 loss_ctc 73.344337 loss_ctc_origin 75.007355 loss_ctc0 69.463974 lr 0.00063288 rank 0
2022-08-22 10:16:01,820 DEBUG TRAIN Batch 5/3300 loss 62.430840 loss_att 51.662201 loss_ctc 87.557663 loss_ctc_origin 88.416107 loss_ctc0 85.554642 lr 0.00063488 rank 0
2022-08-22 10:16:29,089 DEBUG TRAIN Batch 5/3400 loss 75.500931 loss_att 65.036087 loss_ctc 99.918884 loss_ctc_origin 102.702995 loss_ctc0 93.422607 lr 0.00063688 rank 0
2022-08-22 10:16:57,170 DEBUG TRAIN Batch 5/3500 loss 51.623074 loss_att 37.281204 loss_ctc 85.087433 loss_ctc_origin 50.907547 loss_ctc0 164.840515 lr 0.00063888 rank 0
2022-08-22 10:17:24,540 DEBUG TRAIN Batch 5/3600 loss 63.695503 loss_att 40.626007 loss_ctc 117.524330 loss_ctc_origin 64.051025 loss_ctc0 242.295380 lr 0.00064088 rank 0
2022-08-22 10:17:52,396 DEBUG TRAIN Batch 5/3700 loss 51.142212 loss_att 43.384506 loss_ctc 69.243515 loss_ctc_origin 69.801888 loss_ctc0 67.940636 lr 0.00064288 rank 0
2022-08-22 10:18:19,549 DEBUG TRAIN Batch 5/3800 loss 58.599472 loss_att 48.507988 loss_ctc 82.146263 loss_ctc_origin 82.708694 loss_ctc0 80.833923 lr 0.00064488 rank 0
2022-08-22 10:18:46,616 DEBUG TRAIN Batch 5/3900 loss 67.451797 loss_att 56.984093 loss_ctc 91.876434 loss_ctc_origin 93.553452 loss_ctc0 87.963417 lr 0.00064688 rank 0
2022-08-22 10:19:15,275 DEBUG TRAIN Batch 5/4000 loss 43.419937 loss_att 38.077553 loss_ctc 55.885498 loss_ctc_origin 53.055531 loss_ctc0 62.488758 lr 0.00064888 rank 0
2022-08-22 10:19:43,231 DEBUG TRAIN Batch 5/4100 loss 67.097221 loss_att 43.230652 loss_ctc 122.785881 loss_ctc_origin 67.400566 loss_ctc0 252.018280 lr 0.00065088 rank 0
2022-08-22 10:20:09,271 DEBUG TRAIN Batch 5/4200 loss 52.778831 loss_att 45.432381 loss_ctc 69.920555 loss_ctc_origin 71.755989 loss_ctc0 65.637878 lr 0.00065288 rank 0
2022-08-22 10:20:37,286 DEBUG TRAIN Batch 5/4300 loss 64.638138 loss_att 54.668121 loss_ctc 87.901520 loss_ctc_origin 89.265488 loss_ctc0 84.718918 lr 0.00065488 rank 0
2022-08-22 10:21:04,981 DEBUG TRAIN Batch 5/4400 loss 75.770554 loss_att 64.399666 loss_ctc 102.302628 loss_ctc_origin 103.707275 loss_ctc0 99.025116 lr 0.00065688 rank 0
2022-08-22 10:21:37,534 DEBUG TRAIN Batch 5/4500 loss 52.700485 loss_att 34.122627 loss_ctc 96.048813 loss_ctc_origin 52.080040 loss_ctc0 198.642593 lr 0.00065888 rank 0
2022-08-22 10:22:05,886 DEBUG TRAIN Batch 5/4600 loss 67.577858 loss_att 47.690773 loss_ctc 113.981049 loss_ctc_origin 73.027435 loss_ctc0 209.539459 lr 0.00066088 rank 0
2022-08-22 10:22:32,726 DEBUG TRAIN Batch 5/4700 loss 56.776550 loss_att 48.691704 loss_ctc 75.641205 loss_ctc_origin 77.744492 loss_ctc0 70.733536 lr 0.00066288 rank 0
2022-08-22 10:23:00,308 DEBUG TRAIN Batch 5/4800 loss 62.999630 loss_att 54.086708 loss_ctc 83.796448 loss_ctc_origin 84.119400 loss_ctc0 83.042892 lr 0.00066488 rank 0
2022-08-22 10:23:28,062 DEBUG TRAIN Batch 5/4900 loss 78.037949 loss_att 67.898766 loss_ctc 101.696030 loss_ctc_origin 103.674881 loss_ctc0 97.078690 lr 0.00066688 rank 0
2022-08-22 10:23:56,713 DEBUG TRAIN Batch 5/5000 loss 55.216805 loss_att 39.562164 loss_ctc 91.744301 loss_ctc_origin 60.809402 loss_ctc0 163.925720 lr 0.00066888 rank 0
2022-08-22 10:24:24,201 DEBUG TRAIN Batch 5/5100 loss 59.926796 loss_att 41.213051 loss_ctc 103.592209 loss_ctc_origin 63.381817 loss_ctc0 197.416443 lr 0.00067088 rank 0
2022-08-22 10:24:51,479 DEBUG TRAIN Batch 5/5200 loss 58.432495 loss_att 50.314224 loss_ctc 77.375122 loss_ctc_origin 80.063538 loss_ctc0 71.102158 lr 0.00067288 rank 0
2022-08-22 10:25:18,292 DEBUG TRAIN Batch 5/5300 loss 65.572830 loss_att 57.311054 loss_ctc 84.850311 loss_ctc_origin 86.744034 loss_ctc0 80.431625 lr 0.00067488 rank 0
2022-08-22 10:25:34,684 WARNING NaN or Inf found in input tensor.
2022-08-22 10:25:45,912 DEBUG TRAIN Batch 5/5400 loss 80.515900 loss_att 70.676041 loss_ctc 103.475555 loss_ctc_origin 104.125366 loss_ctc0 101.959335 lr 0.00067688 rank 0
2022-08-22 10:25:48,569 WARNING NaN or Inf found in input tensor.
2022-08-22 10:26:13,455 DEBUG TRAIN Batch 5/5500 loss 51.401291 loss_att 40.886974 loss_ctc 75.934692 loss_ctc_origin 60.974583 loss_ctc0 110.841599 lr 0.00067888 rank 0
2022-08-22 10:26:14,091 WARNING NaN or Inf found in input tensor.
2022-08-22 10:26:41,039 DEBUG TRAIN Batch 5/5600 loss 59.758656 loss_att 43.224533 loss_ctc 98.338272 loss_ctc_origin 65.919846 loss_ctc0 173.981277 lr 0.00068088 rank 0
2022-08-22 10:27:02,733 DEBUG CV Batch 5/0 loss 32.205086 loss_att 29.523846 loss_ctc 38.461311 loss_ctc_origin 39.164742 loss_ctc0 36.819973 history loss 30.310669 rank 0
2022-08-22 10:27:12,922 DEBUG CV Batch 5/100 loss 42.656483 loss_att 36.015686 loss_ctc 58.151676 loss_ctc_origin 58.118729 loss_ctc0 58.228554 history loss 59.096940 rank 0
2022-08-22 10:27:22,275 DEBUG CV Batch 5/200 loss 55.301491 loss_att 48.642601 loss_ctc 70.838905 loss_ctc_origin 72.436600 loss_ctc0 67.110947 history loss 60.328985 rank 0
2022-08-22 10:27:31,690 DEBUG CV Batch 5/300 loss 59.863194 loss_att 52.217720 loss_ctc 77.702637 loss_ctc_origin 78.248489 loss_ctc0 76.428993 history loss 60.063472 rank 0
2022-08-22 10:27:42,156 DEBUG CV Batch 5/400 loss 84.413406 loss_att 75.572762 loss_ctc 105.041580 loss_ctc_origin 107.250244 loss_ctc0 99.888016 history loss 59.003520 rank 0
2022-08-22 10:27:52,796 DEBUG CV Batch 5/500 loss 38.414124 loss_att 34.863243 loss_ctc 46.699505 loss_ctc_origin 47.139683 loss_ctc0 45.672424 history loss 59.183275 rank 0
2022-08-22 10:28:03,581 DEBUG CV Batch 5/600 loss 44.870140 loss_att 38.504936 loss_ctc 59.722282 loss_ctc_origin 60.251244 loss_ctc0 58.488045 history loss 59.165363 rank 0
2022-08-22 10:28:13,280 DEBUG CV Batch 5/700 loss 52.578239 loss_att 46.163315 loss_ctc 67.546402 loss_ctc_origin 67.626526 loss_ctc0 67.359467 history loss 58.932657 rank 0
2022-08-22 10:28:23,048 DEBUG CV Batch 5/800 loss 57.595901 loss_att 50.987221 loss_ctc 73.016144 loss_ctc_origin 73.015671 loss_ctc0 73.017242 history loss 59.055958 rank 0
2022-08-22 10:28:33,238 INFO Epoch 5 CV info cv_loss 59.34858956027116
2022-08-22 10:28:33,238 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/5.pt
2022-08-22 10:28:33,692 INFO Epoch 6 TRAIN info lr 0.00068256
2022-08-22 10:28:33,696 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 10:28:59,662 DEBUG TRAIN Batch 6/0 loss 43.624641 loss_att 33.735893 loss_ctc 66.698380 loss_ctc_origin 46.247108 loss_ctc0 114.418030 lr 0.00068264 rank 0
2022-08-22 10:29:27,940 WARNING NaN or Inf found in input tensor.
2022-08-22 10:29:27,986 DEBUG TRAIN Batch 6/100 loss nan loss_att 38.968498 loss_ctc nan loss_ctc_origin 58.225441 loss_ctc0 nan lr 0.00068464 rank 0
2022-08-22 10:29:55,065 DEBUG TRAIN Batch 6/200 loss 56.289661 loss_att 48.154774 loss_ctc 75.271072 loss_ctc_origin 76.937668 loss_ctc0 71.382370 lr 0.00068664 rank 0
2022-08-22 10:30:00,616 WARNING NaN or Inf found in input tensor.
2022-08-22 10:30:22,384 DEBUG TRAIN Batch 6/300 loss 54.252186 loss_att 43.913956 loss_ctc 78.374718 loss_ctc_origin 79.514328 loss_ctc0 75.715622 lr 0.00068864 rank 0
2022-08-22 10:30:33,698 WARNING NaN or Inf found in input tensor.
2022-08-22 10:30:50,679 DEBUG TRAIN Batch 6/400 loss 78.335449 loss_att 68.019997 loss_ctc 102.404846 loss_ctc_origin 103.935013 loss_ctc0 98.834442 lr 0.00069064 rank 0
2022-08-22 10:30:53,292 WARNING NaN or Inf found in input tensor.
2022-08-22 10:31:18,360 WARNING NaN or Inf found in input tensor.
2022-08-22 10:31:18,403 DEBUG TRAIN Batch 6/500 loss inf loss_att 43.599174 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00069264 rank 0
2022-08-22 10:31:45,109 DEBUG TRAIN Batch 6/600 loss 55.921516 loss_att 38.042686 loss_ctc 97.638786 loss_ctc_origin 61.847103 loss_ctc0 181.152710 lr 0.00069464 rank 0
2022-08-22 10:32:13,279 DEBUG TRAIN Batch 6/700 loss 53.792763 loss_att 46.634659 loss_ctc 70.495010 loss_ctc_origin 71.896233 loss_ctc0 67.225494 lr 0.00069664 rank 0
2022-08-22 10:32:18,832 WARNING NaN or Inf found in input tensor.
2022-08-22 10:32:40,993 DEBUG TRAIN Batch 6/800 loss 67.150589 loss_att 58.126892 loss_ctc 88.205894 loss_ctc_origin 90.130905 loss_ctc0 83.714203 lr 0.00069864 rank 0
2022-08-22 10:32:57,645 WARNING NaN or Inf found in input tensor.
2022-08-22 10:33:09,264 DEBUG TRAIN Batch 6/900 loss 69.440399 loss_att 58.565689 loss_ctc 94.814713 loss_ctc_origin 95.588249 loss_ctc0 93.009796 lr 0.00070064 rank 0
2022-08-22 10:33:36,480 DEBUG TRAIN Batch 6/1000 loss 44.454006 loss_att 37.761669 loss_ctc 60.069458 loss_ctc_origin 53.481438 loss_ctc0 75.441513 lr 0.00070264 rank 0
2022-08-22 10:34:03,962 DEBUG TRAIN Batch 6/1100 loss 52.666000 loss_att 43.360603 loss_ctc 74.378586 loss_ctc_origin 63.679974 loss_ctc0 99.342003 lr 0.00070464 rank 0
2022-08-22 10:34:28,979 DEBUG TRAIN Batch 6/1200 loss 56.510204 loss_att 47.906822 loss_ctc 76.584763 loss_ctc_origin 78.133614 loss_ctc0 72.970772 lr 0.00070664 rank 0
2022-08-22 10:34:41,524 WARNING NaN or Inf found in input tensor.
2022-08-22 10:34:58,796 DEBUG TRAIN Batch 6/1300 loss 57.964714 loss_att 47.925667 loss_ctc 81.389153 loss_ctc_origin 82.389717 loss_ctc0 79.054504 lr 0.00070864 rank 0
2022-08-22 10:35:25,967 DEBUG TRAIN Batch 6/1400 loss 60.350731 loss_att 49.620396 loss_ctc 85.388184 loss_ctc_origin 85.438522 loss_ctc0 85.270729 lr 0.00071064 rank 0
2022-08-22 10:35:58,177 DEBUG TRAIN Batch 6/1500 loss 49.994476 loss_att 37.880005 loss_ctc 78.261581 loss_ctc_origin 56.676571 loss_ctc0 128.626587 lr 0.00071264 rank 0
2022-08-22 10:36:25,617 DEBUG TRAIN Batch 6/1600 loss 53.989769 loss_att 38.996647 loss_ctc 88.973709 loss_ctc_origin 63.928814 loss_ctc0 147.411789 lr 0.00071464 rank 0
2022-08-22 10:36:53,432 DEBUG TRAIN Batch 6/1700 loss 48.461609 loss_att 39.937202 loss_ctc 68.351891 loss_ctc_origin 69.605743 loss_ctc0 65.426231 lr 0.00071664 rank 0
2022-08-22 10:37:21,228 DEBUG TRAIN Batch 6/1800 loss 60.665386 loss_att 50.752434 loss_ctc 83.795609 loss_ctc_origin 84.734367 loss_ctc0 81.605156 lr 0.00071864 rank 0
2022-08-22 10:37:44,621 WARNING NaN or Inf found in input tensor.
2022-08-22 10:37:49,050 DEBUG TRAIN Batch 6/1900 loss 81.924255 loss_att 70.068245 loss_ctc 109.588272 loss_ctc_origin 109.730759 loss_ctc0 109.255783 lr 0.00072064 rank 0
2022-08-22 10:38:17,207 DEBUG TRAIN Batch 6/2000 loss 49.500832 loss_att 37.465721 loss_ctc 77.582764 loss_ctc_origin 66.681343 loss_ctc0 103.019402 lr 0.00072264 rank 0
2022-08-22 10:38:45,327 DEBUG TRAIN Batch 6/2100 loss 53.083710 loss_att 39.497513 loss_ctc 84.784836 loss_ctc_origin 62.951778 loss_ctc0 135.728638 lr 0.00072464 rank 0
2022-08-22 10:39:13,452 DEBUG TRAIN Batch 6/2200 loss 50.137650 loss_att 42.023113 loss_ctc 69.071564 loss_ctc_origin 69.471924 loss_ctc0 68.137390 lr 0.00072664 rank 0
2022-08-22 10:39:41,047 DEBUG TRAIN Batch 6/2300 loss 57.423004 loss_att 47.619156 loss_ctc 80.298645 loss_ctc_origin 81.229263 loss_ctc0 78.127197 lr 0.00072864 rank 0
2022-08-22 10:39:57,453 WARNING NaN or Inf found in input tensor.
2022-08-22 10:40:09,389 DEBUG TRAIN Batch 6/2400 loss 75.214256 loss_att 64.245850 loss_ctc 100.807205 loss_ctc_origin 104.057571 loss_ctc0 93.223000 lr 0.00073064 rank 0
2022-08-22 10:40:36,497 DEBUG TRAIN Batch 6/2500 loss 38.546005 loss_att 31.138060 loss_ctc 55.831211 loss_ctc_origin 46.094643 loss_ctc0 78.549866 lr 0.00073264 rank 0
2022-08-22 10:41:03,114 DEBUG TRAIN Batch 6/2600 loss 55.748222 loss_att 42.935440 loss_ctc 85.644707 loss_ctc_origin 70.154755 loss_ctc0 121.787933 lr 0.00073464 rank 0
2022-08-22 10:41:31,901 DEBUG TRAIN Batch 6/2700 loss 47.790039 loss_att 40.014244 loss_ctc 65.933571 loss_ctc_origin 66.245308 loss_ctc0 65.206177 lr 0.00073664 rank 0
2022-08-22 10:41:59,924 DEBUG TRAIN Batch 6/2800 loss 69.632637 loss_att 61.153248 loss_ctc 89.417877 loss_ctc_origin 90.933182 loss_ctc0 85.882156 lr 0.00073864 rank 0
2022-08-22 10:42:28,218 DEBUG TRAIN Batch 6/2900 loss 76.586479 loss_att 64.645027 loss_ctc 104.449875 loss_ctc_origin 104.942955 loss_ctc0 103.299355 lr 0.00074064 rank 0
2022-08-22 10:43:02,976 DEBUG TRAIN Batch 6/3000 loss 40.478271 loss_att 31.999016 loss_ctc 60.263191 loss_ctc_origin 49.690170 loss_ctc0 84.933578 lr 0.00074264 rank 0
2022-08-22 10:43:30,795 DEBUG TRAIN Batch 6/3100 loss 58.822807 loss_att 47.183575 loss_ctc 85.981010 loss_ctc_origin 70.038605 loss_ctc0 123.179947 lr 0.00074464 rank 0
2022-08-22 10:43:58,559 DEBUG TRAIN Batch 6/3200 loss 50.881508 loss_att 42.866497 loss_ctc 69.583199 loss_ctc_origin 71.100677 loss_ctc0 66.042419 lr 0.00074664 rank 0
2022-08-22 10:44:26,693 DEBUG TRAIN Batch 6/3300 loss 57.289703 loss_att 48.252762 loss_ctc 78.375908 loss_ctc_origin 79.535172 loss_ctc0 75.670959 lr 0.00074864 rank 0
2022-08-22 10:44:55,529 DEBUG TRAIN Batch 6/3400 loss 76.672127 loss_att 64.922562 loss_ctc 104.087769 loss_ctc_origin 106.068619 loss_ctc0 99.465797 lr 0.00075064 rank 0
2022-08-22 10:45:23,933 DEBUG TRAIN Batch 6/3500 loss 42.630302 loss_att 36.763397 loss_ctc 56.319756 loss_ctc_origin 51.130890 loss_ctc0 68.427116 lr 0.00075264 rank 0
2022-08-22 10:45:51,578 DEBUG TRAIN Batch 6/3600 loss 52.741264 loss_att 32.950645 loss_ctc 98.919373 loss_ctc_origin 56.146667 loss_ctc0 198.722336 lr 0.00075464 rank 0
2022-08-22 10:46:20,062 DEBUG TRAIN Batch 6/3700 loss 49.806755 loss_att 41.314125 loss_ctc 69.622894 loss_ctc_origin 70.852005 loss_ctc0 66.754990 lr 0.00075664 rank 0
2022-08-22 10:46:47,989 DEBUG TRAIN Batch 6/3800 loss 56.545227 loss_att 45.887451 loss_ctc 81.413376 loss_ctc_origin 82.973129 loss_ctc0 77.773956 lr 0.00075864 rank 0
2022-08-22 10:47:15,911 DEBUG TRAIN Batch 6/3900 loss 74.530609 loss_att 62.951199 loss_ctc 101.549225 loss_ctc_origin 103.591446 loss_ctc0 96.784042 lr 0.00076064 rank 0
2022-08-22 10:47:44,855 DEBUG TRAIN Batch 6/4000 loss 43.966537 loss_att 34.405960 loss_ctc 66.274544 loss_ctc_origin 54.429306 loss_ctc0 93.913422 lr 0.00076264 rank 0
2022-08-22 10:47:58,352 WARNING NaN or Inf found in input tensor.
2022-08-22 10:48:13,153 DEBUG TRAIN Batch 6/4100 loss 56.317528 loss_att 41.353477 loss_ctc 91.233643 loss_ctc_origin 70.126480 loss_ctc0 140.483673 lr 0.00076464 rank 0
2022-08-22 10:48:41,466 DEBUG TRAIN Batch 6/4200 loss 47.252144 loss_att 39.321049 loss_ctc 65.758026 loss_ctc_origin 65.501099 loss_ctc0 66.357513 lr 0.00076664 rank 0
2022-08-22 10:48:53,119 WARNING NaN or Inf found in input tensor.
2022-08-22 10:49:09,334 DEBUG TRAIN Batch 6/4300 loss 58.359825 loss_att 48.383968 loss_ctc 81.636826 loss_ctc_origin 80.511154 loss_ctc0 84.263390 lr 0.00076864 rank 0
2022-08-22 10:49:37,745 DEBUG TRAIN Batch 6/4400 loss 77.140930 loss_att 65.429832 loss_ctc 104.466835 loss_ctc_origin 104.990860 loss_ctc0 103.244110 lr 0.00077064 rank 0
2022-08-22 10:50:11,162 DEBUG TRAIN Batch 6/4500 loss 46.980957 loss_att 35.765022 loss_ctc 73.151474 loss_ctc_origin 54.922523 loss_ctc0 115.685677 lr 0.00077264 rank 0
2022-08-22 10:50:38,836 DEBUG TRAIN Batch 6/4600 loss 60.012268 loss_att 43.619682 loss_ctc 98.261627 loss_ctc_origin 72.723587 loss_ctc0 157.850403 lr 0.00077464 rank 0
2022-08-22 10:51:06,305 DEBUG TRAIN Batch 6/4700 loss 50.499344 loss_att 43.709053 loss_ctc 66.343361 loss_ctc_origin 66.651718 loss_ctc0 65.623871 lr 0.00077664 rank 0
2022-08-22 10:51:34,050 DEBUG TRAIN Batch 6/4800 loss 55.763966 loss_att 46.589645 loss_ctc 77.170715 loss_ctc_origin 78.419975 loss_ctc0 74.255783 lr 0.00077864 rank 0
2022-08-22 10:52:01,894 DEBUG TRAIN Batch 6/4900 loss 77.615402 loss_att 66.935150 loss_ctc 102.535988 loss_ctc_origin 102.045914 loss_ctc0 103.679504 lr 0.00078064 rank 0
2022-08-22 10:52:30,289 DEBUG TRAIN Batch 6/5000 loss 41.443924 loss_att 35.230793 loss_ctc 55.941231 loss_ctc_origin 52.263130 loss_ctc0 64.523468 lr 0.00078264 rank 0
2022-08-22 10:52:57,798 DEBUG TRAIN Batch 6/5100 loss 54.596230 loss_att 38.462360 loss_ctc 92.241928 loss_ctc_origin 65.961899 loss_ctc0 153.561996 lr 0.00078464 rank 0
2022-08-22 10:53:26,392 DEBUG TRAIN Batch 6/5200 loss 48.261177 loss_att 40.848515 loss_ctc 65.557396 loss_ctc_origin 65.403519 loss_ctc0 65.916443 lr 0.00078664 rank 0
2022-08-22 10:53:54,644 DEBUG TRAIN Batch 6/5300 loss 54.858261 loss_att 46.482983 loss_ctc 74.400581 loss_ctc_origin 74.967262 loss_ctc0 73.078323 lr 0.00078864 rank 0
2022-08-22 10:54:23,606 DEBUG TRAIN Batch 6/5400 loss 70.443794 loss_att 59.886856 loss_ctc 95.076645 loss_ctc_origin 95.985947 loss_ctc0 92.954948 lr 0.00079064 rank 0
2022-08-22 10:54:26,288 WARNING NaN or Inf found in input tensor.
2022-08-22 10:54:51,453 DEBUG TRAIN Batch 6/5500 loss 49.924545 loss_att 39.517296 loss_ctc 74.208130 loss_ctc_origin 56.834938 loss_ctc0 114.745575 lr 0.00079264 rank 0
2022-08-22 10:55:20,047 DEBUG TRAIN Batch 6/5600 loss 53.462585 loss_att 43.250015 loss_ctc 77.291916 loss_ctc_origin 67.702370 loss_ctc0 99.667526 lr 0.00079464 rank 0
2022-08-22 10:55:43,324 DEBUG CV Batch 6/0 loss 30.900414 loss_att 27.966408 loss_ctc 37.746426 loss_ctc_origin 37.926865 loss_ctc0 37.325401 history loss 29.082742 rank 0
2022-08-22 10:55:54,135 DEBUG CV Batch 6/100 loss 40.567795 loss_att 33.741489 loss_ctc 56.495846 loss_ctc_origin 54.726921 loss_ctc0 60.623333 history loss 56.218037 rank 0
2022-08-22 10:56:04,081 DEBUG CV Batch 6/200 loss 52.083923 loss_att 44.637390 loss_ctc 69.459160 loss_ctc_origin 67.479675 loss_ctc0 74.077965 history loss 57.488211 rank 0
2022-08-22 10:56:13,669 DEBUG CV Batch 6/300 loss 55.299294 loss_att 47.609356 loss_ctc 73.242470 loss_ctc_origin 72.462555 loss_ctc0 75.062271 history loss 57.112245 rank 0
2022-08-22 10:56:24,417 DEBUG CV Batch 6/400 loss 78.927727 loss_att 69.983139 loss_ctc 99.798431 loss_ctc_origin 99.488800 loss_ctc0 100.520897 history loss 55.908295 rank 0
2022-08-22 10:56:35,220 DEBUG CV Batch 6/500 loss 36.764931 loss_att 32.371109 loss_ctc 47.017181 loss_ctc_origin 46.572704 loss_ctc0 48.054302 history loss 56.040067 rank 0
2022-08-22 10:56:45,560 DEBUG CV Batch 6/600 loss 43.379539 loss_att 36.241566 loss_ctc 60.034813 loss_ctc_origin 59.353016 loss_ctc0 61.625671 history loss 56.047015 rank 0
2022-08-22 10:56:55,481 DEBUG CV Batch 6/700 loss 50.083961 loss_att 44.022179 loss_ctc 64.228111 loss_ctc_origin 63.128372 loss_ctc0 66.794159 history loss 55.827048 rank 0
2022-08-22 10:57:05,499 DEBUG CV Batch 6/800 loss 53.454651 loss_att 46.352417 loss_ctc 70.026535 loss_ctc_origin 68.861191 loss_ctc0 72.745682 history loss 55.961862 rank 0
2022-08-22 10:57:15,584 INFO Epoch 6 CV info cv_loss 56.26010354322224
2022-08-22 10:57:15,584 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/6.pt
2022-08-22 10:57:16,023 INFO Epoch 7 TRAIN info lr 0.0007963199999999999
2022-08-22 10:57:16,026 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 10:57:44,451 DEBUG TRAIN Batch 7/0 loss 43.476128 loss_att 34.348602 loss_ctc 64.773682 loss_ctc_origin 51.705383 loss_ctc0 95.266380 lr 0.00079640 rank 0
2022-08-22 10:58:12,690 DEBUG TRAIN Batch 7/100 loss 54.886749 loss_att 43.697296 loss_ctc 80.995468 loss_ctc_origin 70.351059 loss_ctc0 105.832413 lr 0.00079840 rank 0
2022-08-22 10:58:42,021 DEBUG TRAIN Batch 7/200 loss 47.227978 loss_att 39.678596 loss_ctc 64.843201 loss_ctc_origin 64.332222 loss_ctc0 66.035492 lr 0.00080040 rank 0
2022-08-22 10:59:09,105 DEBUG TRAIN Batch 7/300 loss 54.258083 loss_att 46.034836 loss_ctc 73.445663 loss_ctc_origin 74.928650 loss_ctc0 69.985367 lr 0.00080240 rank 0
2022-08-22 10:59:37,685 DEBUG TRAIN Batch 7/400 loss 75.101387 loss_att 64.315605 loss_ctc 100.268204 loss_ctc_origin 101.165916 loss_ctc0 98.173538 lr 0.00080440 rank 0
2022-08-22 11:00:06,746 DEBUG TRAIN Batch 7/500 loss 47.590286 loss_att 36.494583 loss_ctc 73.480255 loss_ctc_origin 57.588600 loss_ctc0 110.560783 lr 0.00080640 rank 0
2022-08-22 11:00:34,895 DEBUG TRAIN Batch 7/600 loss 50.509117 loss_att 36.443020 loss_ctc 83.330017 loss_ctc_origin 64.685471 loss_ctc0 126.833969 lr 0.00080840 rank 0
2022-08-22 11:01:04,424 DEBUG TRAIN Batch 7/700 loss 51.623997 loss_att 42.462929 loss_ctc 72.999817 loss_ctc_origin 73.910828 loss_ctc0 70.874115 lr 0.00081040 rank 0
2022-08-22 11:01:32,644 DEBUG TRAIN Batch 7/800 loss 53.157372 loss_att 45.424252 loss_ctc 71.201324 loss_ctc_origin 69.748642 loss_ctc0 74.590912 lr 0.00081240 rank 0
2022-08-22 11:02:00,292 DEBUG TRAIN Batch 7/900 loss 68.149796 loss_att 57.254448 loss_ctc 93.572281 loss_ctc_origin 94.523193 loss_ctc0 91.353477 lr 0.00081440 rank 0
2022-08-22 11:02:29,905 DEBUG TRAIN Batch 7/1000 loss 48.795563 loss_att 36.465080 loss_ctc 77.566681 loss_ctc_origin 60.069691 loss_ctc0 118.393005 lr 0.00081640 rank 0
2022-08-22 11:02:58,513 DEBUG TRAIN Batch 7/1100 loss 64.977318 loss_att 47.649277 loss_ctc 105.409424 loss_ctc_origin 71.820824 loss_ctc0 183.782806 lr 0.00081840 rank 0
2022-08-22 11:03:27,397 DEBUG TRAIN Batch 7/1200 loss 57.426453 loss_att 49.674294 loss_ctc 75.514824 loss_ctc_origin 77.016907 loss_ctc0 72.009964 lr 0.00082040 rank 0
2022-08-22 11:03:39,367 WARNING NaN or Inf found in input tensor.
2022-08-22 11:03:55,299 DEBUG TRAIN Batch 7/1300 loss 52.242317 loss_att 44.104069 loss_ctc 71.231567 loss_ctc_origin 70.874023 loss_ctc0 72.065842 lr 0.00082240 rank 0
2022-08-22 11:04:25,286 DEBUG TRAIN Batch 7/1400 loss 70.022957 loss_att 58.993397 loss_ctc 95.758591 loss_ctc_origin 95.375252 loss_ctc0 96.653061 lr 0.00082440 rank 0
2022-08-22 11:04:33,653 WARNING NaN or Inf found in input tensor.
2022-08-22 11:04:58,878 DEBUG TRAIN Batch 7/1500 loss 47.211178 loss_att 42.538403 loss_ctc 58.114319 loss_ctc_origin 54.384949 loss_ctc0 66.816193 lr 0.00082640 rank 0
2022-08-22 11:05:13,585 WARNING NaN or Inf found in input tensor.
2022-08-22 11:05:27,683 DEBUG TRAIN Batch 7/1600 loss 55.295433 loss_att 45.222656 loss_ctc 78.798584 loss_ctc_origin 70.506340 loss_ctc0 98.147133 lr 0.00082840 rank 0
2022-08-22 11:05:57,605 DEBUG TRAIN Batch 7/1700 loss 47.351662 loss_att 39.468643 loss_ctc 65.745377 loss_ctc_origin 65.703049 loss_ctc0 65.844131 lr 0.00083040 rank 0
2022-08-22 11:06:26,553 DEBUG TRAIN Batch 7/1800 loss 58.853310 loss_att 49.305702 loss_ctc 81.131050 loss_ctc_origin 79.768227 loss_ctc0 84.310966 lr 0.00083240 rank 0
2022-08-22 11:06:55,456 DEBUG TRAIN Batch 7/1900 loss 68.347961 loss_att 58.064728 loss_ctc 92.342178 loss_ctc_origin 93.438393 loss_ctc0 89.784325 lr 0.00083440 rank 0
2022-08-22 11:07:24,478 DEBUG TRAIN Batch 7/2000 loss 40.642967 loss_att 35.109619 loss_ctc 53.554115 loss_ctc_origin 44.924622 loss_ctc0 73.689606 lr 0.00083640 rank 0
2022-08-22 11:07:31,844 WARNING NaN or Inf found in input tensor.
2022-08-22 11:07:52,963 DEBUG TRAIN Batch 7/2100 loss 56.112587 loss_att 43.001621 loss_ctc 86.704834 loss_ctc_origin 73.338379 loss_ctc0 117.893242 lr 0.00083840 rank 0
2022-08-22 11:08:21,995 DEBUG TRAIN Batch 7/2200 loss 51.039078 loss_att 42.568481 loss_ctc 70.803802 loss_ctc_origin 69.287781 loss_ctc0 74.341202 lr 0.00084040 rank 0
2022-08-22 11:08:50,855 DEBUG TRAIN Batch 7/2300 loss 59.036846 loss_att 48.948524 loss_ctc 82.576263 loss_ctc_origin 80.760818 loss_ctc0 86.812294 lr 0.00084240 rank 0
2022-08-22 11:09:18,976 DEBUG TRAIN Batch 7/2400 loss 64.339279 loss_att 54.093334 loss_ctc 88.246483 loss_ctc_origin 87.901810 loss_ctc0 89.050720 lr 0.00084440 rank 0
2022-08-22 11:09:47,602 DEBUG TRAIN Batch 7/2500 loss 43.848450 loss_att 34.203766 loss_ctc 66.352707 loss_ctc_origin 50.079590 loss_ctc0 104.323303 lr 0.00084640 rank 0
2022-08-22 11:10:16,098 DEBUG TRAIN Batch 7/2600 loss 83.588989 loss_att 47.477779 loss_ctc 167.848480 loss_ctc_origin 87.681328 loss_ctc0 354.905182 lr 0.00084840 rank 0
2022-08-22 11:10:44,570 DEBUG TRAIN Batch 7/2700 loss 51.560234 loss_att 43.562023 loss_ctc 70.222733 loss_ctc_origin 69.998947 loss_ctc0 70.744904 lr 0.00085040 rank 0
2022-08-22 11:11:15,055 DEBUG TRAIN Batch 7/2800 loss 56.398819 loss_att 47.062569 loss_ctc 78.183403 loss_ctc_origin 78.611214 loss_ctc0 77.185181 lr 0.00085240 rank 0
2022-08-22 11:11:40,384 WARNING NaN or Inf found in input tensor.
2022-08-22 11:11:44,971 DEBUG TRAIN Batch 7/2900 loss 74.257057 loss_att 62.293221 loss_ctc 102.172661 loss_ctc_origin 101.752029 loss_ctc0 103.154144 lr 0.00085440 rank 0
2022-08-22 11:12:21,522 DEBUG TRAIN Batch 7/3000 loss 54.866287 loss_att 35.029282 loss_ctc 101.152626 loss_ctc_origin 54.387558 loss_ctc0 210.271118 lr 0.00085640 rank 0
2022-08-22 11:12:50,495 DEBUG TRAIN Batch 7/3100 loss 84.404846 loss_att 51.837677 loss_ctc 160.394897 loss_ctc_origin 82.714691 loss_ctc0 341.648712 lr 0.00085840 rank 0
2022-08-22 11:13:18,177 WARNING NaN or Inf found in input tensor.
2022-08-22 11:13:19,812 DEBUG TRAIN Batch 7/3200 loss 49.303261 loss_att 40.722801 loss_ctc 69.324326 loss_ctc_origin 68.418900 loss_ctc0 71.436966 lr 0.00086040 rank 0
2022-08-22 11:13:49,356 DEBUG TRAIN Batch 7/3300 loss 55.026947 loss_att 44.328659 loss_ctc 79.989624 loss_ctc_origin 79.680832 loss_ctc0 80.710129 lr 0.00086240 rank 0
2022-08-22 11:14:18,252 DEBUG TRAIN Batch 7/3400 loss 74.982590 loss_att 63.846275 loss_ctc 100.967323 loss_ctc_origin 99.660561 loss_ctc0 104.016449 lr 0.00086440 rank 0
2022-08-22 11:14:48,350 DEBUG TRAIN Batch 7/3500 loss 63.654514 loss_att 45.173237 loss_ctc 106.777489 loss_ctc_origin 66.329407 loss_ctc0 201.156342 lr 0.00086640 rank 0
2022-08-22 11:15:17,380 DEBUG TRAIN Batch 7/3600 loss 74.540451 loss_att 47.689674 loss_ctc 137.192276 loss_ctc_origin 83.482422 loss_ctc0 262.515259 lr 0.00086840 rank 0
2022-08-22 11:15:45,926 WARNING NaN or Inf found in input tensor.
2022-08-22 11:15:47,664 DEBUG TRAIN Batch 7/3700 loss 43.207726 loss_att 36.524395 loss_ctc 58.802170 loss_ctc_origin 56.906975 loss_ctc0 63.224293 lr 0.00087040 rank 0
2022-08-22 11:16:15,438 DEBUG TRAIN Batch 7/3800 loss 53.114021 loss_att 43.177597 loss_ctc 76.299011 loss_ctc_origin 76.002472 loss_ctc0 76.990944 lr 0.00087240 rank 0
2022-08-22 11:16:41,857 WARNING NaN or Inf found in input tensor.
2022-08-22 11:16:46,614 DEBUG TRAIN Batch 7/3900 loss 60.756287 loss_att 49.123764 loss_ctc 87.898834 loss_ctc_origin 86.212555 loss_ctc0 91.833481 lr 0.00087440 rank 0
2022-08-22 11:17:16,258 DEBUG TRAIN Batch 7/4000 loss 59.981850 loss_att 40.114021 loss_ctc 106.340111 loss_ctc_origin 61.866375 loss_ctc0 210.112152 lr 0.00087640 rank 0
2022-08-22 11:17:44,146 WARNING NaN or Inf found in input tensor.
2022-08-22 11:17:44,980 DEBUG TRAIN Batch 7/4100 loss 72.128769 loss_att 45.652885 loss_ctc 133.905823 loss_ctc_origin 80.359924 loss_ctc0 258.846252 lr 0.00087840 rank 0
2022-08-22 11:18:14,280 DEBUG TRAIN Batch 7/4200 loss 44.298271 loss_att 37.337639 loss_ctc 60.539749 loss_ctc_origin 59.613197 loss_ctc0 62.701702 lr 0.00088040 rank 0
2022-08-22 11:18:43,978 DEBUG TRAIN Batch 7/4300 loss 58.675323 loss_att 47.976097 loss_ctc 83.640190 loss_ctc_origin 80.506287 loss_ctc0 90.952621 lr 0.00088240 rank 0
2022-08-22 11:19:12,803 DEBUG TRAIN Batch 7/4400 loss 62.268650 loss_att 50.258961 loss_ctc 90.291260 loss_ctc_origin 88.550064 loss_ctc0 94.354065 lr 0.00088440 rank 0
2022-08-22 11:19:47,511 DEBUG TRAIN Batch 7/4500 loss 49.324696 loss_att 36.894691 loss_ctc 78.328033 loss_ctc_origin 50.592060 loss_ctc0 143.045319 lr 0.00088640 rank 0
2022-08-22 11:20:01,970 WARNING NaN or Inf found in input tensor.
2022-08-22 11:20:17,399 DEBUG TRAIN Batch 7/4600 loss 69.945351 loss_att 46.795586 loss_ctc 123.961472 loss_ctc_origin 77.613411 loss_ctc0 232.106934 lr 0.00088840 rank 0
2022-08-22 11:20:45,571 DEBUG TRAIN Batch 7/4700 loss 44.254478 loss_att 36.948875 loss_ctc 61.300880 loss_ctc_origin 58.320187 loss_ctc0 68.255836 lr 0.00089040 rank 0
2022-08-22 11:20:50,975 WARNING NaN or Inf found in input tensor.
2022-08-22 11:21:13,759 DEBUG TRAIN Batch 7/4800 loss 55.678772 loss_att 46.968075 loss_ctc 76.003731 loss_ctc_origin 74.366043 loss_ctc0 79.824997 lr 0.00089240 rank 0
2022-08-22 11:21:24,636 WARNING NaN or Inf found in input tensor.
2022-08-22 11:21:42,316 DEBUG TRAIN Batch 7/4900 loss 58.967991 loss_att 48.482162 loss_ctc 83.434929 loss_ctc_origin 81.615669 loss_ctc0 87.679871 lr 0.00089440 rank 0
2022-08-22 11:22:11,688 DEBUG TRAIN Batch 7/5000 loss 61.416168 loss_att 45.389854 loss_ctc 98.810898 loss_ctc_origin 66.832108 loss_ctc0 173.428085 lr 0.00089640 rank 0
2022-08-22 11:22:39,249 DEBUG TRAIN Batch 7/5100 loss 70.612228 loss_att 49.086090 loss_ctc 120.839890 loss_ctc_origin 78.697289 loss_ctc0 219.172607 lr 0.00089840 rank 0
2022-08-22 11:23:07,764 DEBUG TRAIN Batch 7/5200 loss 44.795696 loss_att 36.365433 loss_ctc 64.466309 loss_ctc_origin 63.299759 loss_ctc0 67.188248 lr 0.00090040 rank 0
2022-08-22 11:23:36,460 DEBUG TRAIN Batch 7/5300 loss 56.253883 loss_att 47.007717 loss_ctc 77.828262 loss_ctc_origin 77.919174 loss_ctc0 77.616135 lr 0.00090240 rank 0
2022-08-22 11:24:05,830 DEBUG TRAIN Batch 7/5400 loss 70.524429 loss_att 59.449478 loss_ctc 96.365982 loss_ctc_origin 94.095184 loss_ctc0 101.664505 lr 0.00090440 rank 0
2022-08-22 11:24:34,091 DEBUG TRAIN Batch 7/5500 loss 55.521439 loss_att 42.215637 loss_ctc 86.568314 loss_ctc_origin 63.248779 loss_ctc0 140.980576 lr 0.00090640 rank 0
2022-08-22 11:25:02,311 DEBUG TRAIN Batch 7/5600 loss 67.032959 loss_att 45.972122 loss_ctc 116.174927 loss_ctc_origin 74.548698 loss_ctc0 213.302765 lr 0.00090840 rank 0
2022-08-22 11:25:25,282 DEBUG CV Batch 7/0 loss 28.242626 loss_att 24.597599 loss_ctc 36.747692 loss_ctc_origin 35.244102 loss_ctc0 40.256062 history loss 26.581295 rank 0
2022-08-22 11:25:35,641 DEBUG CV Batch 7/100 loss 39.414604 loss_att 32.633308 loss_ctc 55.237633 loss_ctc_origin 52.501583 loss_ctc0 61.621761 history loss 52.615285 rank 0
2022-08-22 11:25:45,431 DEBUG CV Batch 7/200 loss 49.029686 loss_att 41.756477 loss_ctc 66.000511 loss_ctc_origin 63.411087 loss_ctc0 72.042496 history loss 53.992987 rank 0
2022-08-22 11:25:55,251 DEBUG CV Batch 7/300 loss 51.094460 loss_att 42.760872 loss_ctc 70.539497 loss_ctc_origin 65.559998 loss_ctc0 82.158325 history loss 53.344929 rank 0
2022-08-22 11:26:05,492 DEBUG CV Batch 7/400 loss 73.813400 loss_att 63.668762 loss_ctc 97.484207 loss_ctc_origin 93.377884 loss_ctc0 107.065643 history loss 51.923091 rank 0
2022-08-22 11:26:15,849 DEBUG CV Batch 7/500 loss 35.146858 loss_att 30.974552 loss_ctc 44.882240 loss_ctc_origin 43.111061 loss_ctc0 49.014999 history loss 51.932019 rank 0
2022-08-22 11:26:26,305 DEBUG CV Batch 7/600 loss 39.802467 loss_att 32.724152 loss_ctc 56.318535 loss_ctc_origin 53.419281 loss_ctc0 63.083450 history loss 51.875831 rank 0
2022-08-22 11:26:36,242 DEBUG CV Batch 7/700 loss 46.370468 loss_att 40.081310 loss_ctc 61.045158 loss_ctc_origin 57.899029 loss_ctc0 68.386124 history loss 51.611070 rank 0
2022-08-22 11:26:46,605 DEBUG CV Batch 7/800 loss 48.727245 loss_att 41.127762 loss_ctc 66.459373 loss_ctc_origin 62.276287 loss_ctc0 76.219917 history loss 51.678448 rank 0
2022-08-22 11:26:56,325 INFO Epoch 7 CV info cv_loss 51.91112570550625
2022-08-22 11:26:56,326 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/7.pt
2022-08-22 11:26:56,755 INFO Epoch 8 TRAIN info lr 0.00091008
2022-08-22 11:26:56,758 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 11:27:23,161 DEBUG TRAIN Batch 8/0 loss 56.829994 loss_att 41.837463 loss_ctc 91.812553 loss_ctc_origin 63.320007 loss_ctc0 158.295151 lr 0.00091016 rank 0
2022-08-22 11:27:52,290 DEBUG TRAIN Batch 8/100 loss 67.993469 loss_att 45.243229 loss_ctc 121.077354 loss_ctc_origin 78.681839 loss_ctc0 220.000214 lr 0.00091216 rank 0
2022-08-22 11:28:20,540 DEBUG TRAIN Batch 8/200 loss 43.770691 loss_att 35.810482 loss_ctc 62.344509 loss_ctc_origin 60.507973 loss_ctc0 66.629761 lr 0.00091416 rank 0
2022-08-22 11:28:48,352 DEBUG TRAIN Batch 8/300 loss 58.869560 loss_att 48.704163 loss_ctc 82.588821 loss_ctc_origin 81.552902 loss_ctc0 85.005974 lr 0.00091616 rank 0
2022-08-22 11:29:16,255 DEBUG TRAIN Batch 8/400 loss 63.081024 loss_att 51.222263 loss_ctc 90.751457 loss_ctc_origin 90.281616 loss_ctc0 91.847740 lr 0.00091816 rank 0
2022-08-22 11:29:44,640 DEBUG TRAIN Batch 8/500 loss 44.430737 loss_att 37.210228 loss_ctc 61.278587 loss_ctc_origin 54.420021 loss_ctc0 77.281914 lr 0.00092016 rank 0
2022-08-22 11:30:12,458 DEBUG TRAIN Batch 8/600 loss 59.791252 loss_att 45.279747 loss_ctc 93.651428 loss_ctc_origin 72.336342 loss_ctc0 143.386627 lr 0.00092216 rank 0
2022-08-22 11:30:41,762 DEBUG TRAIN Batch 8/700 loss 46.937523 loss_att 38.305779 loss_ctc 67.078262 loss_ctc_origin 65.990318 loss_ctc0 69.616798 lr 0.00092416 rank 0
2022-08-22 11:31:10,553 DEBUG TRAIN Batch 8/800 loss 51.010284 loss_att 40.762215 loss_ctc 74.922447 loss_ctc_origin 72.031158 loss_ctc0 81.668793 lr 0.00092616 rank 0
2022-08-22 11:31:38,872 DEBUG TRAIN Batch 8/900 loss 69.317307 loss_att 56.956352 loss_ctc 98.159531 loss_ctc_origin 96.214508 loss_ctc0 102.697914 lr 0.00092816 rank 0
2022-08-22 11:32:08,801 DEBUG TRAIN Batch 8/1000 loss 39.283546 loss_att 34.036209 loss_ctc 51.527328 loss_ctc_origin 51.959793 loss_ctc0 50.518250 lr 0.00093016 rank 0
2022-08-22 11:32:36,208 DEBUG TRAIN Batch 8/1100 loss 44.020111 loss_att 37.651524 loss_ctc 58.880157 loss_ctc_origin 58.059166 loss_ctc0 60.795815 lr 0.00093216 rank 0
2022-08-22 11:33:03,908 DEBUG TRAIN Batch 8/1200 loss 47.538246 loss_att 38.901890 loss_ctc 67.689743 loss_ctc_origin 64.817993 loss_ctc0 74.390495 lr 0.00093416 rank 0
2022-08-22 11:33:32,327 DEBUG TRAIN Batch 8/1300 loss 55.413338 loss_att 47.085663 loss_ctc 74.844574 loss_ctc_origin 72.961983 loss_ctc0 79.237289 lr 0.00093616 rank 0
2022-08-22 11:34:00,906 DEBUG TRAIN Batch 8/1400 loss 66.263443 loss_att 54.108208 loss_ctc 94.625656 loss_ctc_origin 92.702133 loss_ctc0 99.113861 lr 0.00093816 rank 0
2022-08-22 11:34:35,583 DEBUG TRAIN Batch 8/1500 loss 48.570808 loss_att 36.838821 loss_ctc 75.945450 loss_ctc_origin 54.963356 loss_ctc0 124.903671 lr 0.00094016 rank 0
2022-08-22 11:35:03,618 DEBUG TRAIN Batch 8/1600 loss 47.694386 loss_att 34.778992 loss_ctc 77.830307 loss_ctc_origin 58.118294 loss_ctc0 123.824997 lr 0.00094216 rank 0
2022-08-22 11:35:30,568 DEBUG TRAIN Batch 8/1700 loss 48.334595 loss_att 41.275124 loss_ctc 64.806702 loss_ctc_origin 63.797989 loss_ctc0 67.160370 lr 0.00094416 rank 0
2022-08-22 11:35:58,491 DEBUG TRAIN Batch 8/1800 loss 59.138557 loss_att 49.107807 loss_ctc 82.543633 loss_ctc_origin 80.340645 loss_ctc0 87.683945 lr 0.00094616 rank 0
2022-08-22 11:36:26,861 DEBUG TRAIN Batch 8/1900 loss 69.545280 loss_att 58.598591 loss_ctc 95.087555 loss_ctc_origin 92.726959 loss_ctc0 100.595612 lr 0.00094816 rank 0
2022-08-22 11:36:56,364 DEBUG TRAIN Batch 8/2000 loss 41.872490 loss_att 35.562119 loss_ctc 56.596699 loss_ctc_origin 51.225861 loss_ctc0 69.128654 lr 0.00095016 rank 0
2022-08-22 11:37:24,162 DEBUG TRAIN Batch 8/2100 loss 45.565334 loss_att 35.864979 loss_ctc 68.199501 loss_ctc_origin 60.183949 loss_ctc0 86.902458 lr 0.00095216 rank 0
2022-08-22 11:37:52,409 DEBUG TRAIN Batch 8/2200 loss 48.712143 loss_att 40.737556 loss_ctc 67.319511 loss_ctc_origin 65.804398 loss_ctc0 70.854774 lr 0.00095416 rank 0
2022-08-22 11:38:21,606 DEBUG TRAIN Batch 8/2300 loss 59.059334 loss_att 49.106182 loss_ctc 82.283356 loss_ctc_origin 80.166298 loss_ctc0 87.223145 lr 0.00095616 rank 0
2022-08-22 11:38:50,609 DEBUG TRAIN Batch 8/2400 loss 71.326363 loss_att 60.733467 loss_ctc 96.043106 loss_ctc_origin 94.343483 loss_ctc0 100.008911 lr 0.00095816 rank 0
2022-08-22 11:39:17,815 DEBUG TRAIN Batch 8/2500 loss 38.142117 loss_att 31.016092 loss_ctc 54.769508 loss_ctc_origin 44.364567 loss_ctc0 79.047707 lr 0.00096016 rank 0
2022-08-22 11:39:45,631 DEBUG TRAIN Batch 8/2600 loss 41.898087 loss_att 32.913254 loss_ctc 62.862694 loss_ctc_origin 52.168037 loss_ctc0 87.816887 lr 0.00096216 rank 0
2022-08-22 11:40:13,839 DEBUG TRAIN Batch 8/2700 loss 43.941784 loss_att 36.165295 loss_ctc 62.086926 loss_ctc_origin 61.109898 loss_ctc0 64.366653 lr 0.00096416 rank 0
2022-08-22 11:40:43,018 DEBUG TRAIN Batch 8/2800 loss 60.313438 loss_att 50.324917 loss_ctc 83.619987 loss_ctc_origin 80.804573 loss_ctc0 90.189285 lr 0.00096616 rank 0
2022-08-22 11:41:11,095 DEBUG TRAIN Batch 8/2900 loss 60.643257 loss_att 48.301239 loss_ctc 89.441292 loss_ctc_origin 85.609726 loss_ctc0 98.381607 lr 0.00096816 rank 0
2022-08-22 11:41:46,933 DEBUG TRAIN Batch 8/3000 loss 41.398129 loss_att 33.184380 loss_ctc 60.563541 loss_ctc_origin 48.426651 loss_ctc0 88.882950 lr 0.00097016 rank 0
2022-08-22 11:42:17,341 DEBUG TRAIN Batch 8/3100 loss 49.785206 loss_att 36.442108 loss_ctc 80.919098 loss_ctc_origin 61.337585 loss_ctc0 126.609299 lr 0.00097216 rank 0
2022-08-22 11:42:44,633 DEBUG TRAIN Batch 8/3200 loss 44.820122 loss_att 37.265945 loss_ctc 62.446537 loss_ctc_origin 61.551453 loss_ctc0 64.535065 lr 0.00097416 rank 0
2022-08-22 11:43:12,912 DEBUG TRAIN Batch 8/3300 loss 57.099113 loss_att 46.735420 loss_ctc 81.281052 loss_ctc_origin 78.000702 loss_ctc0 88.935204 lr 0.00097616 rank 0
2022-08-22 11:43:40,276 DEBUG TRAIN Batch 8/3400 loss 63.595913 loss_att 51.835899 loss_ctc 91.035942 loss_ctc_origin 87.582512 loss_ctc0 99.093948 lr 0.00097816 rank 0
2022-08-22 11:44:08,930 DEBUG TRAIN Batch 8/3500 loss 33.468002 loss_att 27.635803 loss_ctc 47.076458 loss_ctc_origin 44.825630 loss_ctc0 52.328384 lr 0.00098016 rank 0
2022-08-22 11:44:16,708 WARNING NaN or Inf found in input tensor.
2022-08-22 11:44:36,638 DEBUG TRAIN Batch 8/3600 loss 59.029110 loss_att 37.092667 loss_ctc 110.214142 loss_ctc_origin 71.000031 loss_ctc0 201.713745 lr 0.00098216 rank 0
2022-08-22 11:45:05,182 DEBUG TRAIN Batch 8/3700 loss 43.611069 loss_att 35.019524 loss_ctc 63.658005 loss_ctc_origin 61.924793 loss_ctc0 67.702156 lr 0.00098416 rank 0
2022-08-22 11:45:34,186 DEBUG TRAIN Batch 8/3800 loss 59.992760 loss_att 49.580917 loss_ctc 84.287048 loss_ctc_origin 83.538635 loss_ctc0 86.033356 lr 0.00098616 rank 0
2022-08-22 11:45:57,652 WARNING NaN or Inf found in input tensor.
2022-08-22 11:46:01,801 DEBUG TRAIN Batch 8/3900 loss 61.814392 loss_att 51.059715 loss_ctc 86.908646 loss_ctc_origin 84.820877 loss_ctc0 91.780090 lr 0.00098816 rank 0
2022-08-22 11:46:29,461 DEBUG TRAIN Batch 8/4000 loss 37.922546 loss_att 32.895988 loss_ctc 49.651176 loss_ctc_origin 44.650105 loss_ctc0 61.320335 lr 0.00099016 rank 0
2022-08-22 11:46:43,165 WARNING NaN or Inf found in input tensor.
2022-08-22 11:46:57,539 DEBUG TRAIN Batch 8/4100 loss 39.660820 loss_att 29.982704 loss_ctc 62.243092 loss_ctc_origin 49.869331 loss_ctc0 91.115196 lr 0.00099216 rank 0
2022-08-22 11:47:25,145 DEBUG TRAIN Batch 8/4200 loss 43.657181 loss_att 36.205902 loss_ctc 61.043503 loss_ctc_origin 59.344154 loss_ctc0 65.008652 lr 0.00099416 rank 0
2022-08-22 11:47:53,355 DEBUG TRAIN Batch 8/4300 loss 54.618431 loss_att 44.777287 loss_ctc 77.581100 loss_ctc_origin 75.617493 loss_ctc0 82.162865 lr 0.00099616 rank 0
2022-08-22 11:48:18,073 WARNING NaN or Inf found in input tensor.
2022-08-22 11:48:22,366 DEBUG TRAIN Batch 8/4400 loss 75.908417 loss_att 64.990166 loss_ctc 101.384323 loss_ctc_origin 97.877449 loss_ctc0 109.567039 lr 0.00099816 rank 0
2022-08-22 11:48:57,209 DEBUG TRAIN Batch 8/4500 loss 42.464020 loss_att 36.290333 loss_ctc 56.869297 loss_ctc_origin 52.089218 loss_ctc0 68.022812 lr 0.00100016 rank 0
2022-08-22 11:48:58,153 WARNING NaN or Inf found in input tensor.
2022-08-22 11:49:25,660 DEBUG TRAIN Batch 8/4600 loss 43.997467 loss_att 36.742737 loss_ctc 60.925163 loss_ctc_origin 58.748138 loss_ctc0 66.004898 lr 0.00100216 rank 0
2022-08-22 11:49:54,309 DEBUG TRAIN Batch 8/4700 loss 44.557549 loss_att 37.088547 loss_ctc 61.985222 loss_ctc_origin 60.321449 loss_ctc0 65.867355 lr 0.00100416 rank 0
2022-08-22 11:50:23,633 DEBUG TRAIN Batch 8/4800 loss 53.078217 loss_att 43.070824 loss_ctc 76.428795 loss_ctc_origin 75.144936 loss_ctc0 79.424454 lr 0.00100616 rank 0
2022-08-22 11:50:53,294 DEBUG TRAIN Batch 8/4900 loss 62.711876 loss_att 52.635010 loss_ctc 86.224571 loss_ctc_origin 83.198479 loss_ctc0 93.285446 lr 0.00100816 rank 0
2022-08-22 11:51:22,536 DEBUG TRAIN Batch 8/5000 loss 42.235275 loss_att 34.182068 loss_ctc 61.026093 loss_ctc_origin 46.169632 loss_ctc0 95.691162 lr 0.00101016 rank 0
2022-08-22 11:51:30,018 WARNING NaN or Inf found in input tensor.
2022-08-22 11:51:51,601 DEBUG TRAIN Batch 8/5100 loss 44.186119 loss_att 34.033543 loss_ctc 67.875458 loss_ctc_origin 53.756062 loss_ctc0 100.820709 lr 0.00101216 rank 0
2022-08-22 11:52:21,311 DEBUG TRAIN Batch 8/5200 loss 45.128792 loss_att 37.170872 loss_ctc 63.697273 loss_ctc_origin 61.491806 loss_ctc0 68.843369 lr 0.00101416 rank 0
2022-08-22 11:52:50,505 DEBUG TRAIN Batch 8/5300 loss 50.137852 loss_att 40.716141 loss_ctc 72.121841 loss_ctc_origin 69.621521 loss_ctc0 77.955917 lr 0.00101616 rank 0
2022-08-22 11:53:19,050 DEBUG TRAIN Batch 8/5400 loss 70.537567 loss_att 59.496723 loss_ctc 96.299538 loss_ctc_origin 94.819038 loss_ctc0 99.754021 lr 0.00101816 rank 0
2022-08-22 11:53:21,648 WARNING NaN or Inf found in input tensor.
2022-08-22 11:53:48,298 DEBUG TRAIN Batch 8/5500 loss 43.395164 loss_att 30.152479 loss_ctc 74.294754 loss_ctc_origin 51.779839 loss_ctc0 126.829559 lr 0.00102016 rank 0
2022-08-22 11:54:17,020 DEBUG TRAIN Batch 8/5600 loss 53.010685 loss_att 37.615681 loss_ctc 88.932358 loss_ctc_origin 55.622860 loss_ctc0 166.654510 lr 0.00102216 rank 0
2022-08-22 11:54:40,587 DEBUG CV Batch 8/0 loss 26.947754 loss_att 21.876175 loss_ctc 38.781441 loss_ctc_origin 36.626003 loss_ctc0 43.810799 history loss 25.362592 rank 0
2022-08-22 11:54:51,207 DEBUG CV Batch 8/100 loss 38.038826 loss_att 31.344704 loss_ctc 53.658443 loss_ctc_origin 51.379990 loss_ctc0 58.974838 history loss 52.518337 rank 0
2022-08-22 11:55:01,178 DEBUG CV Batch 8/200 loss 46.666107 loss_att 40.265377 loss_ctc 61.601143 loss_ctc_origin 60.411560 loss_ctc0 64.376839 history loss 53.826685 rank 0
2022-08-22 11:55:11,221 DEBUG CV Batch 8/300 loss 49.519943 loss_att 41.754242 loss_ctc 67.639908 loss_ctc_origin 63.025928 loss_ctc0 78.405853 history loss 53.170131 rank 0
2022-08-22 11:55:22,029 DEBUG CV Batch 8/400 loss 75.492554 loss_att 67.705704 loss_ctc 93.661850 loss_ctc_origin 90.297295 loss_ctc0 101.512482 history loss 51.647039 rank 0
2022-08-22 11:55:32,965 DEBUG CV Batch 8/500 loss 32.504822 loss_att 27.305367 loss_ctc 44.636887 loss_ctc_origin 43.948044 loss_ctc0 46.244190 history loss 51.651450 rank 0
2022-08-22 11:55:43,804 DEBUG CV Batch 8/600 loss 39.855553 loss_att 33.159695 loss_ctc 55.479214 loss_ctc_origin 53.500458 loss_ctc0 60.096306 history loss 51.590090 rank 0
2022-08-22 11:55:54,000 DEBUG CV Batch 8/700 loss 44.361679 loss_att 37.603279 loss_ctc 60.131287 loss_ctc_origin 57.186569 loss_ctc0 67.002289 history loss 51.279533 rank 0
2022-08-22 11:56:04,666 DEBUG CV Batch 8/800 loss 47.154396 loss_att 40.174694 loss_ctc 63.440372 loss_ctc_origin 58.800667 loss_ctc0 74.266357 history loss 51.353716 rank 0
2022-08-22 11:56:15,462 INFO Epoch 8 CV info cv_loss 51.597886318287465
2022-08-22 11:56:15,462 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/8.pt
2022-08-22 11:56:15,979 INFO Epoch 9 TRAIN info lr 0.00102384
2022-08-22 11:56:15,982 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 11:56:43,270 DEBUG TRAIN Batch 9/0 loss 42.205544 loss_att 26.890739 loss_ctc 77.940094 loss_ctc_origin 48.661114 loss_ctc0 146.257721 lr 0.00102392 rank 0
2022-08-22 11:57:12,510 DEBUG TRAIN Batch 9/100 loss 45.842350 loss_att 31.945139 loss_ctc 78.269173 loss_ctc_origin 53.694046 loss_ctc0 135.611130 lr 0.00102592 rank 0
2022-08-22 11:57:41,533 DEBUG TRAIN Batch 9/200 loss 50.389793 loss_att 42.510689 loss_ctc 68.774361 loss_ctc_origin 67.239479 loss_ctc0 72.355759 lr 0.00102792 rank 0
2022-08-22 11:58:10,431 DEBUG TRAIN Batch 9/300 loss 55.334526 loss_att 45.735916 loss_ctc 77.731277 loss_ctc_origin 76.078468 loss_ctc0 81.587830 lr 0.00102992 rank 0
2022-08-22 11:58:38,750 DEBUG TRAIN Batch 9/400 loss 66.484268 loss_att 53.600697 loss_ctc 96.545914 loss_ctc_origin 93.908920 loss_ctc0 102.698898 lr 0.00103192 rank 0
2022-08-22 11:59:08,288 DEBUG TRAIN Batch 9/500 loss 43.548561 loss_att 32.546318 loss_ctc 69.220467 loss_ctc_origin 52.127762 loss_ctc0 109.103439 lr 0.00103392 rank 0
2022-08-22 11:59:38,687 DEBUG TRAIN Batch 9/600 loss 47.736023 loss_att 34.987724 loss_ctc 77.482040 loss_ctc_origin 56.511063 loss_ctc0 126.414307 lr 0.00103592 rank 0
2022-08-22 12:00:07,004 DEBUG TRAIN Batch 9/700 loss 49.404980 loss_att 42.162178 loss_ctc 66.304848 loss_ctc_origin 66.735977 loss_ctc0 65.298874 lr 0.00103792 rank 0
2022-08-22 12:00:35,643 DEBUG TRAIN Batch 9/800 loss 49.329006 loss_att 40.595749 loss_ctc 69.706604 loss_ctc_origin 68.701126 loss_ctc0 72.052719 lr 0.00103992 rank 0
2022-08-22 12:01:05,312 DEBUG TRAIN Batch 9/900 loss 61.684105 loss_att 47.302074 loss_ctc 95.242172 loss_ctc_origin 93.095337 loss_ctc0 100.251472 lr 0.00104192 rank 0
2022-08-22 12:01:34,747 DEBUG TRAIN Batch 9/1000 loss 51.191200 loss_att 39.226830 loss_ctc 79.108055 loss_ctc_origin 65.707260 loss_ctc0 110.376572 lr 0.00104392 rank 0
2022-08-22 12:01:56,925 WARNING NaN or Inf found in input tensor.
2022-08-22 12:02:03,911 DEBUG TRAIN Batch 9/1100 loss 52.931728 loss_att 42.753887 loss_ctc 76.680023 loss_ctc_origin 59.253193 loss_ctc0 117.342613 lr 0.00104592 rank 0
2022-08-22 12:02:34,313 DEBUG TRAIN Batch 9/1200 loss 46.278770 loss_att 37.883347 loss_ctc 65.868095 loss_ctc_origin 64.828873 loss_ctc0 68.292938 lr 0.00104792 rank 0
2022-08-22 12:02:46,488 WARNING NaN or Inf found in input tensor.
2022-08-22 12:03:04,011 DEBUG TRAIN Batch 9/1300 loss 51.232895 loss_att 41.335903 loss_ctc 74.325882 loss_ctc_origin 72.181358 loss_ctc0 79.329773 lr 0.00104992 rank 0
2022-08-22 12:03:33,544 DEBUG TRAIN Batch 9/1400 loss 61.952728 loss_att 49.762684 loss_ctc 90.396172 loss_ctc_origin 88.197113 loss_ctc0 95.527306 lr 0.00105192 rank 0
2022-08-22 12:03:43,004 WARNING NaN or Inf found in input tensor.
2022-08-22 12:04:09,765 DEBUG TRAIN Batch 9/1500 loss 45.070236 loss_att 35.641655 loss_ctc 67.070251 loss_ctc_origin 53.395569 loss_ctc0 98.977859 lr 0.00105392 rank 0
2022-08-22 12:04:11,325 WARNING NaN or Inf found in input tensor.
2022-08-22 12:04:38,720 DEBUG TRAIN Batch 9/1600 loss 48.098541 loss_att 38.534927 loss_ctc 70.413635 loss_ctc_origin 60.982155 loss_ctc0 92.420425 lr 0.00105592 rank 0
2022-08-22 12:05:06,278 WARNING NaN or Inf found in input tensor.
2022-08-22 12:05:07,964 DEBUG TRAIN Batch 9/1700 loss 40.895100 loss_att 32.574383 loss_ctc 60.310104 loss_ctc_origin 56.998573 loss_ctc0 68.037003 lr 0.00105792 rank 0
2022-08-22 12:05:36,865 DEBUG TRAIN Batch 9/1800 loss 50.441040 loss_att 40.838863 loss_ctc 72.846123 loss_ctc_origin 70.408691 loss_ctc0 78.533470 lr 0.00105992 rank 0
2022-08-22 12:06:06,582 DEBUG TRAIN Batch 9/1900 loss 56.397179 loss_att 45.080086 loss_ctc 82.803726 loss_ctc_origin 78.423004 loss_ctc0 93.025421 lr 0.00106192 rank 0
2022-08-22 12:06:36,816 DEBUG TRAIN Batch 9/2000 loss 41.643414 loss_att 33.278053 loss_ctc 61.162582 loss_ctc_origin 50.188763 loss_ctc0 86.768158 lr 0.00106392 rank 0
2022-08-22 12:07:05,755 DEBUG TRAIN Batch 9/2100 loss 45.184872 loss_att 32.869328 loss_ctc 73.921135 loss_ctc_origin 54.347080 loss_ctc0 119.593925 lr 0.00106592 rank 0
2022-08-22 12:07:35,279 DEBUG TRAIN Batch 9/2200 loss 47.504692 loss_att 40.706581 loss_ctc 63.366955 loss_ctc_origin 62.718304 loss_ctc0 64.880470 lr 0.00106792 rank 0
2022-08-22 12:08:05,035 DEBUG TRAIN Batch 9/2300 loss 50.229118 loss_att 41.154633 loss_ctc 71.402908 loss_ctc_origin 69.145065 loss_ctc0 76.671219 lr 0.00106992 rank 0
2022-08-22 12:08:23,113 WARNING NaN or Inf found in input tensor.
2022-08-22 12:08:35,323 DEBUG TRAIN Batch 9/2400 loss 61.802208 loss_att 51.737762 loss_ctc 85.285904 loss_ctc_origin 82.599121 loss_ctc0 91.555069 lr 0.00107192 rank 0
2022-08-22 12:09:04,645 DEBUG TRAIN Batch 9/2500 loss 41.944027 loss_att 35.958588 loss_ctc 55.910049 loss_ctc_origin 54.246773 loss_ctc0 59.791031 lr 0.00107392 rank 0
2022-08-22 12:09:33,125 DEBUG TRAIN Batch 9/2600 loss 44.201515 loss_att 37.386650 loss_ctc 60.102867 loss_ctc_origin 57.736809 loss_ctc0 65.623672 lr 0.00107592 rank 0
2022-08-22 12:10:02,023 DEBUG TRAIN Batch 9/2700 loss 42.937134 loss_att 34.539364 loss_ctc 62.531929 loss_ctc_origin 59.455746 loss_ctc0 69.709686 lr 0.00107792 rank 0
2022-08-22 12:10:30,955 DEBUG TRAIN Batch 9/2800 loss 57.588047 loss_att 47.277245 loss_ctc 81.646584 loss_ctc_origin 78.492264 loss_ctc0 89.006668 lr 0.00107992 rank 0
2022-08-22 12:11:00,572 DEBUG TRAIN Batch 9/2900 loss 60.722797 loss_att 48.905537 loss_ctc 88.296402 loss_ctc_origin 84.579254 loss_ctc0 96.969742 lr 0.00108192 rank 0
2022-08-22 12:11:36,094 DEBUG TRAIN Batch 9/3000 loss 57.608170 loss_att 41.401390 loss_ctc 95.423981 loss_ctc_origin 62.609589 loss_ctc0 171.990906 lr 0.00108392 rank 0
2022-08-22 12:12:05,699 DEBUG TRAIN Batch 9/3100 loss 62.057995 loss_att 37.325500 loss_ctc 119.767143 loss_ctc_origin 63.613045 loss_ctc0 250.793365 lr 0.00108592 rank 0
2022-08-22 12:12:34,366 DEBUG TRAIN Batch 9/3200 loss 43.156540 loss_att 36.892735 loss_ctc 57.772087 loss_ctc_origin 56.341473 loss_ctc0 61.110191 lr 0.00108792 rank 0
2022-08-22 12:13:04,552 DEBUG TRAIN Batch 9/3300 loss 44.145454 loss_att 35.284241 loss_ctc 64.821609 loss_ctc_origin 60.994427 loss_ctc0 73.751717 lr 0.00108992 rank 0
2022-08-22 12:13:33,565 DEBUG TRAIN Batch 9/3400 loss 58.488930 loss_att 45.514050 loss_ctc 88.763649 loss_ctc_origin 84.790710 loss_ctc0 98.033829 lr 0.00109192 rank 0
2022-08-22 12:14:03,307 DEBUG TRAIN Batch 9/3500 loss 49.280373 loss_att 36.970642 loss_ctc 78.003067 loss_ctc_origin 48.163628 loss_ctc0 147.628418 lr 0.00109392 rank 0
2022-08-22 12:14:32,147 DEBUG TRAIN Batch 9/3600 loss 49.369526 loss_att 34.011986 loss_ctc 85.203781 loss_ctc_origin 57.502930 loss_ctc0 149.839111 lr 0.00109592 rank 0
2022-08-22 12:15:00,195 WARNING NaN or Inf found in input tensor.
2022-08-22 12:15:01,901 DEBUG TRAIN Batch 9/3700 loss 41.979355 loss_att 33.818550 loss_ctc 61.021233 loss_ctc_origin 58.751827 loss_ctc0 66.316505 lr 0.00109792 rank 0
2022-08-22 12:15:31,627 DEBUG TRAIN Batch 9/3800 loss 59.171249 loss_att 49.181770 loss_ctc 82.480026 loss_ctc_origin 80.395210 loss_ctc0 87.344604 lr 0.00109992 rank 0
2022-08-22 12:15:49,221 WARNING NaN or Inf found in input tensor.
2022-08-22 12:16:00,834 DEBUG TRAIN Batch 9/3900 loss 57.096527 loss_att 46.885941 loss_ctc 80.921242 loss_ctc_origin 77.618286 loss_ctc0 88.628151 lr 0.00110192 rank 0
2022-08-22 12:16:30,222 DEBUG TRAIN Batch 9/4000 loss 48.054062 loss_att 36.792229 loss_ctc 74.331665 loss_ctc_origin 54.297928 loss_ctc0 121.077034 lr 0.00110392 rank 0
2022-08-22 12:17:00,575 DEBUG TRAIN Batch 9/4100 loss 47.855782 loss_att 32.444263 loss_ctc 83.815994 loss_ctc_origin 55.564697 loss_ctc0 149.735687 lr 0.00110592 rank 0
2022-08-22 12:17:29,411 DEBUG TRAIN Batch 9/4200 loss 44.077328 loss_att 36.071404 loss_ctc 62.757812 loss_ctc_origin 57.506054 loss_ctc0 75.011917 lr 0.00110792 rank 0
2022-08-22 12:17:58,047 DEBUG TRAIN Batch 9/4300 loss 53.154716 loss_att 43.273407 loss_ctc 76.211105 loss_ctc_origin 74.420120 loss_ctc0 80.390068 lr 0.00110992 rank 0
2022-08-22 12:18:26,909 DEBUG TRAIN Batch 9/4400 loss 51.929615 loss_att 40.548126 loss_ctc 78.486420 loss_ctc_origin 73.864922 loss_ctc0 89.269928 lr 0.00111192 rank 0
2022-08-22 12:19:02,039 DEBUG TRAIN Batch 9/4500 loss 36.220680 loss_att 29.994556 loss_ctc 50.748306 loss_ctc_origin 44.390373 loss_ctc0 65.583481 lr 0.00111392 rank 0
2022-08-22 12:19:31,102 DEBUG TRAIN Batch 9/4600 loss 43.342014 loss_att 35.221313 loss_ctc 62.290314 loss_ctc_origin 56.029121 loss_ctc0 76.899765 lr 0.00111592 rank 0
2022-08-22 12:19:59,908 DEBUG TRAIN Batch 9/4700 loss 44.619144 loss_att 36.304317 loss_ctc 64.020409 loss_ctc_origin 59.476837 loss_ctc0 74.622070 lr 0.00111792 rank 0
2022-08-22 12:20:28,172 DEBUG TRAIN Batch 9/4800 loss 53.176838 loss_att 43.602039 loss_ctc 75.518036 loss_ctc_origin 72.514801 loss_ctc0 82.525574 lr 0.00111992 rank 0
2022-08-22 12:20:56,518 DEBUG TRAIN Batch 9/4900 loss 55.107986 loss_att 43.773705 loss_ctc 81.554649 loss_ctc_origin 77.448708 loss_ctc0 91.135170 lr 0.00112192 rank 0
2022-08-22 12:21:26,391 DEBUG TRAIN Batch 9/5000 loss 51.121803 loss_att 35.226959 loss_ctc 88.209778 loss_ctc_origin 49.922298 loss_ctc0 177.547211 lr 0.00112392 rank 0
2022-08-22 12:21:34,113 WARNING NaN or Inf found in input tensor.
2022-08-22 12:21:55,499 DEBUG TRAIN Batch 9/5100 loss 48.975121 loss_att 35.040710 loss_ctc 81.488739 loss_ctc_origin 53.565514 loss_ctc0 146.642944 lr 0.00112592 rank 0
2022-08-22 12:22:24,439 DEBUG TRAIN Batch 9/5200 loss 47.920334 loss_att 39.259300 loss_ctc 68.129402 loss_ctc_origin 65.820602 loss_ctc0 73.516602 lr 0.00112792 rank 0
2022-08-22 12:22:53,463 DEBUG TRAIN Batch 9/5300 loss 57.161247 loss_att 46.000793 loss_ctc 83.202301 loss_ctc_origin 77.190086 loss_ctc0 97.230812 lr 0.00112992 rank 0
2022-08-22 12:23:22,865 DEBUG TRAIN Batch 9/5400 loss 57.184982 loss_att 46.153812 loss_ctc 82.924385 loss_ctc_origin 78.856514 loss_ctc0 92.416077 lr 0.00113192 rank 0
2022-08-22 12:23:52,301 DEBUG TRAIN Batch 9/5500 loss 41.001114 loss_att 29.580486 loss_ctc 67.649239 loss_ctc_origin 50.016781 loss_ctc0 108.791634 lr 0.00113392 rank 0
2022-08-22 12:24:21,290 DEBUG TRAIN Batch 9/5600 loss 45.885719 loss_att 35.627739 loss_ctc 69.821014 loss_ctc_origin 58.564800 loss_ctc0 96.085518 lr 0.00113592 rank 0
2022-08-22 12:24:44,196 DEBUG CV Batch 9/0 loss 26.265144 loss_att 21.640656 loss_ctc 37.055618 loss_ctc_origin 35.880669 loss_ctc0 39.797157 history loss 24.720136 rank 0
2022-08-22 12:24:55,393 DEBUG CV Batch 9/100 loss 35.304405 loss_att 28.811150 loss_ctc 50.455330 loss_ctc_origin 46.563812 loss_ctc0 59.535538 history loss 48.253605 rank 0
2022-08-22 12:25:05,438 DEBUG CV Batch 9/200 loss 44.712547 loss_att 37.610054 loss_ctc 61.285034 loss_ctc_origin 59.032578 loss_ctc0 66.540771 history loss 49.880288 rank 0
2022-08-22 12:25:15,866 DEBUG CV Batch 9/300 loss 45.127281 loss_att 37.186249 loss_ctc 63.656349 loss_ctc_origin 58.965836 loss_ctc0 74.600876 history loss 49.164826 rank 0
2022-08-22 12:25:26,686 DEBUG CV Batch 9/400 loss 69.341919 loss_att 59.918037 loss_ctc 91.330971 loss_ctc_origin 87.741913 loss_ctc0 99.705444 history loss 47.660251 rank 0
2022-08-22 12:25:37,090 DEBUG CV Batch 9/500 loss 30.064495 loss_att 24.411766 loss_ctc 43.254200 loss_ctc_origin 41.041565 loss_ctc0 48.417011 history loss 47.505577 rank 0
2022-08-22 12:25:47,997 DEBUG CV Batch 9/600 loss 35.729130 loss_att 29.093094 loss_ctc 51.213215 loss_ctc_origin 48.543587 loss_ctc0 57.442345 history loss 47.397714 rank 0
2022-08-22 12:25:57,928 DEBUG CV Batch 9/700 loss 41.086403 loss_att 34.209202 loss_ctc 57.133194 loss_ctc_origin 52.908852 loss_ctc0 66.989990 history loss 47.064076 rank 0
2022-08-22 12:26:08,302 DEBUG CV Batch 9/800 loss 43.299641 loss_att 35.950817 loss_ctc 60.446896 loss_ctc_origin 54.514122 loss_ctc0 74.290031 history loss 47.078769 rank 0
2022-08-22 12:26:18,369 INFO Epoch 9 CV info cv_loss 47.28491480391931
2022-08-22 12:26:18,369 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/9.pt
2022-08-22 12:26:18,856 INFO Epoch 10 TRAIN info lr 0.0011376
2022-08-22 12:26:18,860 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 12:26:46,174 DEBUG TRAIN Batch 10/0 loss 39.336433 loss_att 31.655167 loss_ctc 57.259392 loss_ctc_origin 48.334633 loss_ctc0 78.083824 lr 0.00113768 rank 0
2022-08-22 12:27:14,486 DEBUG TRAIN Batch 10/100 loss 43.174114 loss_att 33.932163 loss_ctc 64.738663 loss_ctc_origin 53.042599 loss_ctc0 92.029488 lr 0.00113968 rank 0
2022-08-22 12:27:43,507 DEBUG TRAIN Batch 10/200 loss 47.729595 loss_att 39.508877 loss_ctc 66.911270 loss_ctc_origin 62.792461 loss_ctc0 76.521835 lr 0.00114168 rank 0
2022-08-22 12:28:11,330 DEBUG TRAIN Batch 10/300 loss 48.372589 loss_att 38.343002 loss_ctc 71.774963 loss_ctc_origin 67.734909 loss_ctc0 81.201752 lr 0.00114368 rank 0
2022-08-22 12:28:39,068 DEBUG TRAIN Batch 10/400 loss 61.893059 loss_att 49.844872 loss_ctc 90.005493 loss_ctc_origin 84.722771 loss_ctc0 102.331841 lr 0.00114568 rank 0
2022-08-22 12:29:08,693 DEBUG TRAIN Batch 10/500 loss 37.076965 loss_att 26.623793 loss_ctc 61.467697 loss_ctc_origin 45.881340 loss_ctc0 97.835876 lr 0.00114768 rank 0
2022-08-22 12:29:36,570 DEBUG TRAIN Batch 10/600 loss 53.528915 loss_att 41.653259 loss_ctc 81.238770 loss_ctc_origin 55.157211 loss_ctc0 142.095749 lr 0.00114968 rank 0
2022-08-22 12:30:04,890 DEBUG TRAIN Batch 10/700 loss 42.482334 loss_att 34.406898 loss_ctc 61.325012 loss_ctc_origin 57.538406 loss_ctc0 70.160431 lr 0.00115168 rank 0
2022-08-22 12:30:33,975 DEBUG TRAIN Batch 10/800 loss 55.641953 loss_att 45.101276 loss_ctc 80.236855 loss_ctc_origin 74.673050 loss_ctc0 93.219070 lr 0.00115368 rank 0
2022-08-22 12:31:01,693 DEBUG TRAIN Batch 10/900 loss 62.456512 loss_att 51.773521 loss_ctc 87.383499 loss_ctc_origin 83.379196 loss_ctc0 96.726868 lr 0.00115568 rank 0
2022-08-22 12:31:31,317 DEBUG TRAIN Batch 10/1000 loss 41.065670 loss_att 29.951462 loss_ctc 66.998825 loss_ctc_origin 58.313896 loss_ctc0 87.263664 lr 0.00115768 rank 0
2022-08-22 12:32:01,110 DEBUG TRAIN Batch 10/1100 loss 39.003059 loss_att 32.212082 loss_ctc 54.848675 loss_ctc_origin 52.026489 loss_ctc0 61.433777 lr 0.00115968 rank 0
2022-08-22 12:32:29,794 DEBUG TRAIN Batch 10/1200 loss 43.932865 loss_att 35.315956 loss_ctc 64.038986 loss_ctc_origin 60.989208 loss_ctc0 71.155136 lr 0.00116168 rank 0
2022-08-22 12:32:59,071 DEBUG TRAIN Batch 10/1300 loss 66.142532 loss_att 55.197708 loss_ctc 91.680450 loss_ctc_origin 84.732391 loss_ctc0 107.892593 lr 0.00116368 rank 0
2022-08-22 12:33:29,064 DEBUG TRAIN Batch 10/1400 loss 64.368019 loss_att 50.209007 loss_ctc 97.405716 loss_ctc_origin 87.866058 loss_ctc0 119.664909 lr 0.00116568 rank 0
2022-08-22 12:34:03,967 DEBUG TRAIN Batch 10/1500 loss 37.872238 loss_att 29.253860 loss_ctc 57.981781 loss_ctc_origin 47.484177 loss_ctc0 82.476196 lr 0.00116768 rank 0
2022-08-22 12:34:32,759 DEBUG TRAIN Batch 10/1600 loss 58.897835 loss_att 37.044796 loss_ctc 109.888260 loss_ctc_origin 63.099915 loss_ctc0 219.061035 lr 0.00116968 rank 0
2022-08-22 12:35:00,172 WARNING NaN or Inf found in input tensor.
2022-08-22 12:35:01,712 DEBUG TRAIN Batch 10/1700 loss 43.752113 loss_att 35.465317 loss_ctc 63.087975 loss_ctc_origin 59.941414 loss_ctc0 70.429947 lr 0.00117168 rank 0
2022-08-22 12:35:31,947 DEBUG TRAIN Batch 10/1800 loss 47.049160 loss_att 36.519676 loss_ctc 71.617958 loss_ctc_origin 66.816338 loss_ctc0 82.821732 lr 0.00117368 rank 0
2022-08-22 12:36:01,381 DEBUG TRAIN Batch 10/1900 loss 62.388397 loss_att 52.918808 loss_ctc 84.484116 loss_ctc_origin 79.850410 loss_ctc0 95.296104 lr 0.00117568 rank 0
2022-08-22 12:36:31,360 DEBUG TRAIN Batch 10/2000 loss 42.962067 loss_att 34.121773 loss_ctc 63.589424 loss_ctc_origin 47.200386 loss_ctc0 101.830521 lr 0.00117768 rank 0
2022-08-22 12:37:01,468 DEBUG TRAIN Batch 10/2100 loss 41.458191 loss_att 34.999840 loss_ctc 56.527672 loss_ctc_origin 51.564537 loss_ctc0 68.108322 lr 0.00117968 rank 0
2022-08-22 12:37:30,688 DEBUG TRAIN Batch 10/2200 loss 43.500740 loss_att 35.503395 loss_ctc 62.161217 loss_ctc_origin 59.269745 loss_ctc0 68.907982 lr 0.00118168 rank 0
2022-08-22 12:37:58,749 DEBUG TRAIN Batch 10/2300 loss 54.991173 loss_att 43.919205 loss_ctc 80.825768 loss_ctc_origin 77.120811 loss_ctc0 89.470673 lr 0.00118368 rank 0
2022-08-22 12:38:28,544 DEBUG TRAIN Batch 10/2400 loss 54.819611 loss_att 42.225773 loss_ctc 84.205231 loss_ctc_origin 75.747818 loss_ctc0 103.939178 lr 0.00118568 rank 0
2022-08-22 12:38:57,751 DEBUG TRAIN Batch 10/2500 loss 41.009907 loss_att 33.130924 loss_ctc 59.394196 loss_ctc_origin 55.333416 loss_ctc0 68.869354 lr 0.00118768 rank 0
2022-08-22 12:39:26,709 DEBUG TRAIN Batch 10/2600 loss 49.544098 loss_att 39.452614 loss_ctc 73.090889 loss_ctc_origin 61.018692 loss_ctc0 101.259338 lr 0.00118968 rank 0
2022-08-22 12:39:54,039 DEBUG TRAIN Batch 10/2700 loss 37.247772 loss_att 29.641088 loss_ctc 54.996704 loss_ctc_origin 51.675591 loss_ctc0 62.745964 lr 0.00119168 rank 0
2022-08-22 12:40:24,948 DEBUG TRAIN Batch 10/2800 loss 49.521393 loss_att 39.668922 loss_ctc 72.510483 loss_ctc_origin 68.715988 loss_ctc0 81.364288 lr 0.00119368 rank 0
2022-08-22 12:40:53,517 DEBUG TRAIN Batch 10/2900 loss 54.406616 loss_att 44.447914 loss_ctc 77.643593 loss_ctc_origin 73.416916 loss_ctc0 87.505829 lr 0.00119568 rank 0
2022-08-22 12:41:29,175 DEBUG TRAIN Batch 10/3000 loss 35.339142 loss_att 29.637009 loss_ctc 48.644115 loss_ctc_origin 42.610329 loss_ctc0 62.722946 lr 0.00119768 rank 0
2022-08-22 12:41:44,754 WARNING NaN or Inf found in input tensor.
2022-08-22 12:41:58,117 DEBUG TRAIN Batch 10/3100 loss 34.860836 loss_att 27.187252 loss_ctc 52.765865 loss_ctc_origin 44.534874 loss_ctc0 71.971512 lr 0.00119968 rank 0
2022-08-22 12:42:27,219 DEBUG TRAIN Batch 10/3200 loss 37.795273 loss_att 30.932667 loss_ctc 53.808014 loss_ctc_origin 48.439201 loss_ctc0 66.335243 lr 0.00120168 rank 0
2022-08-22 12:42:56,258 DEBUG TRAIN Batch 10/3300 loss 40.743401 loss_att 31.768412 loss_ctc 61.685047 loss_ctc_origin 56.904999 loss_ctc0 72.838486 lr 0.00120368 rank 0
2022-08-22 12:43:24,807 DEBUG TRAIN Batch 10/3400 loss 54.774368 loss_att 43.566708 loss_ctc 80.925568 loss_ctc_origin 76.613434 loss_ctc0 90.987228 lr 0.00120568 rank 0
2022-08-22 12:43:54,993 DEBUG TRAIN Batch 10/3500 loss 45.596016 loss_att 35.776264 loss_ctc 68.508766 loss_ctc_origin 58.123322 loss_ctc0 92.741470 lr 0.00120768 rank 0
2022-08-22 12:44:23,642 DEBUG TRAIN Batch 10/3600 loss 46.551414 loss_att 33.503960 loss_ctc 76.995476 loss_ctc_origin 55.781593 loss_ctc0 126.494530 lr 0.00120968 rank 0
2022-08-22 12:44:52,566 DEBUG TRAIN Batch 10/3700 loss 48.761108 loss_att 38.299271 loss_ctc 73.172058 loss_ctc_origin 70.706543 loss_ctc0 78.924942 lr 0.00121168 rank 0
2022-08-22 12:45:21,478 DEBUG TRAIN Batch 10/3800 loss 53.709629 loss_att 42.041405 loss_ctc 80.935478 loss_ctc_origin 77.230980 loss_ctc0 89.579315 lr 0.00121368 rank 0
2022-08-22 12:45:51,207 DEBUG TRAIN Batch 10/3900 loss 60.382721 loss_att 49.048317 loss_ctc 86.829659 loss_ctc_origin 80.734589 loss_ctc0 101.051491 lr 0.00121568 rank 0
2022-08-22 12:46:20,350 DEBUG TRAIN Batch 10/4000 loss 38.511036 loss_att 29.841341 loss_ctc 58.740318 loss_ctc_origin 47.921379 loss_ctc0 83.984512 lr 0.00121768 rank 0
2022-08-22 12:46:50,032 DEBUG TRAIN Batch 10/4100 loss 51.797894 loss_att 32.950397 loss_ctc 95.775383 loss_ctc_origin 56.125343 loss_ctc0 188.292145 lr 0.00121968 rank 0
2022-08-22 12:47:18,701 DEBUG TRAIN Batch 10/4200 loss 45.688156 loss_att 36.981133 loss_ctc 66.004547 loss_ctc_origin 62.199287 loss_ctc0 74.883469 lr 0.00122168 rank 0
2022-08-22 12:47:30,318 WARNING NaN or Inf found in input tensor.
2022-08-22 12:47:47,496 DEBUG TRAIN Batch 10/4300 loss 53.241161 loss_att 42.487667 loss_ctc 78.332642 loss_ctc_origin 73.516022 loss_ctc0 89.571426 lr 0.00122368 rank 0
2022-08-22 12:48:15,876 DEBUG TRAIN Batch 10/4400 loss 61.866142 loss_att 52.099808 loss_ctc 84.654266 loss_ctc_origin 79.923950 loss_ctc0 95.691666 lr 0.00122568 rank 0
2022-08-22 12:48:53,048 DEBUG TRAIN Batch 10/4500 loss 40.471779 loss_att 32.092491 loss_ctc 60.023445 loss_ctc_origin 48.975487 loss_ctc0 85.802002 lr 0.00122768 rank 0
2022-08-22 12:49:22,060 DEBUG TRAIN Batch 10/4600 loss 44.989082 loss_att 33.317417 loss_ctc 72.222961 loss_ctc_origin 57.669716 loss_ctc0 106.180534 lr 0.00122968 rank 0
2022-08-22 12:49:51,131 DEBUG TRAIN Batch 10/4700 loss 41.545715 loss_att 34.353237 loss_ctc 58.328163 loss_ctc_origin 55.116367 loss_ctc0 65.822365 lr 0.00123168 rank 0
2022-08-22 12:50:19,954 DEBUG TRAIN Batch 10/4800 loss 51.471390 loss_att 41.988136 loss_ctc 73.598984 loss_ctc_origin 69.317001 loss_ctc0 83.590263 lr 0.00123368 rank 0
2022-08-22 12:50:48,999 DEBUG TRAIN Batch 10/4900 loss 56.922363 loss_att 45.900822 loss_ctc 82.639297 loss_ctc_origin 75.880486 loss_ctc0 98.409866 lr 0.00123568 rank 0
2022-08-22 12:51:19,390 DEBUG TRAIN Batch 10/5000 loss 52.857590 loss_att 35.270401 loss_ctc 93.894371 loss_ctc_origin 49.919464 loss_ctc0 196.502487 lr 0.00123768 rank 0
2022-08-22 12:51:48,274 DEBUG TRAIN Batch 10/5100 loss 58.401688 loss_att 36.645592 loss_ctc 109.165894 loss_ctc_origin 60.024364 loss_ctc0 223.829453 lr 0.00123968 rank 0
2022-08-22 12:52:16,642 DEBUG TRAIN Batch 10/5200 loss 39.898376 loss_att 32.135014 loss_ctc 58.012894 loss_ctc_origin 54.658340 loss_ctc0 65.840187 lr 0.00124168 rank 0
2022-08-22 12:52:45,153 DEBUG TRAIN Batch 10/5300 loss 52.948360 loss_att 42.884674 loss_ctc 76.430290 loss_ctc_origin 71.439011 loss_ctc0 88.076614 lr 0.00124368 rank 0
2022-08-22 12:53:01,528 WARNING NaN or Inf found in input tensor.
2022-08-22 12:53:12,663 DEBUG TRAIN Batch 10/5400 loss 57.320019 loss_att 47.086704 loss_ctc 81.197746 loss_ctc_origin 75.847237 loss_ctc0 93.682281 lr 0.00124568 rank 0
2022-08-22 12:53:42,103 DEBUG TRAIN Batch 10/5500 loss 32.624695 loss_att 26.932156 loss_ctc 45.907288 loss_ctc_origin 38.910412 loss_ctc0 62.233322 lr 0.00124768 rank 0
2022-08-22 12:54:10,863 DEBUG TRAIN Batch 10/5600 loss 46.485619 loss_att 34.759106 loss_ctc 73.847473 loss_ctc_origin 55.005894 loss_ctc0 117.811142 lr 0.00124968 rank 0
2022-08-22 12:54:34,819 DEBUG CV Batch 10/0 loss 26.553974 loss_att 21.074848 loss_ctc 39.338600 loss_ctc_origin 32.016766 loss_ctc0 56.422886 history loss 24.991976 rank 0
2022-08-22 12:54:45,830 DEBUG CV Batch 10/100 loss 40.956955 loss_att 30.442335 loss_ctc 65.491058 loss_ctc_origin 48.711212 loss_ctc0 104.644028 history loss 48.824271 rank 0
2022-08-22 12:54:56,296 DEBUG CV Batch 10/200 loss 47.962749 loss_att 38.672142 loss_ctc 69.640831 loss_ctc_origin 61.219032 loss_ctc0 89.291695 history loss 50.317352 rank 0
2022-08-22 12:55:06,850 DEBUG CV Batch 10/300 loss 45.795738 loss_att 37.087097 loss_ctc 66.115906 loss_ctc_origin 58.919907 loss_ctc0 82.906570 history loss 49.391894 rank 0
2022-08-22 12:55:17,635 DEBUG CV Batch 10/400 loss 65.696411 loss_att 55.126122 loss_ctc 90.360435 loss_ctc_origin 82.355858 loss_ctc0 109.037773 history loss 47.721377 rank 0
2022-08-22 12:55:28,419 DEBUG CV Batch 10/500 loss 32.970272 loss_att 25.545509 loss_ctc 50.294712 loss_ctc_origin 39.301464 loss_ctc0 75.945625 history loss 47.485870 rank 0
2022-08-22 12:55:39,274 DEBUG CV Batch 10/600 loss 35.919533 loss_att 27.394066 loss_ctc 55.812286 loss_ctc_origin 46.655411 loss_ctc0 77.178322 history loss 47.347129 rank 0
2022-08-22 12:55:49,497 DEBUG CV Batch 10/700 loss 40.349983 loss_att 32.851318 loss_ctc 57.846859 loss_ctc_origin 52.175995 loss_ctc0 71.078873 history loss 47.028565 rank 0
2022-08-22 12:55:59,954 DEBUG CV Batch 10/800 loss 43.108620 loss_att 35.324928 loss_ctc 61.270557 loss_ctc_origin 53.460224 loss_ctc0 79.494667 history loss 47.038665 rank 0
2022-08-22 12:56:10,512 INFO Epoch 10 CV info cv_loss 47.18411934163588
2022-08-22 12:56:10,512 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/10.pt
2022-08-22 12:56:10,961 INFO Epoch 11 TRAIN info lr 0.0012513600000000002
2022-08-22 12:56:10,965 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 12:56:37,901 DEBUG TRAIN Batch 11/0 loss 38.700867 loss_att 32.508984 loss_ctc 53.148594 loss_ctc_origin 44.927170 loss_ctc0 72.331917 lr 0.00125144 rank 0
2022-08-22 12:57:07,834 DEBUG TRAIN Batch 11/100 loss 47.474899 loss_att 35.138317 loss_ctc 76.260254 loss_ctc_origin 57.254505 loss_ctc0 120.606995 lr 0.00125344 rank 0
2022-08-22 12:57:37,034 DEBUG TRAIN Batch 11/200 loss 49.964249 loss_att 40.509483 loss_ctc 72.025368 loss_ctc_origin 69.033966 loss_ctc0 79.005310 lr 0.00125544 rank 0
2022-08-22 12:58:06,410 DEBUG TRAIN Batch 11/300 loss 53.262264 loss_att 41.794174 loss_ctc 80.021133 loss_ctc_origin 75.570206 loss_ctc0 90.406631 lr 0.00125744 rank 0
2022-08-22 12:58:35,417 DEBUG TRAIN Batch 11/400 loss 67.045349 loss_att 54.765396 loss_ctc 95.698563 loss_ctc_origin 91.600113 loss_ctc0 105.261612 lr 0.00125944 rank 0
2022-08-22 12:59:04,909 DEBUG TRAIN Batch 11/500 loss 37.115547 loss_att 28.154408 loss_ctc 58.024883 loss_ctc_origin 42.231140 loss_ctc0 94.876945 lr 0.00126144 rank 0
2022-08-22 12:59:33,762 DEBUG TRAIN Batch 11/600 loss 45.081066 loss_att 32.194107 loss_ctc 75.150635 loss_ctc_origin 55.040646 loss_ctc0 122.073959 lr 0.00126344 rank 0
2022-08-22 13:00:03,521 DEBUG TRAIN Batch 11/700 loss 38.084522 loss_att 29.070690 loss_ctc 59.116791 loss_ctc_origin 54.577881 loss_ctc0 69.707581 lr 0.00126544 rank 0
2022-08-22 13:00:31,806 DEBUG TRAIN Batch 11/800 loss 54.284943 loss_att 44.671265 loss_ctc 76.716850 loss_ctc_origin 70.972260 loss_ctc0 90.120903 lr 0.00126744 rank 0
2022-08-22 13:01:01,707 DEBUG TRAIN Batch 11/900 loss 60.754742 loss_att 49.256012 loss_ctc 87.585114 loss_ctc_origin 81.882721 loss_ctc0 100.890686 lr 0.00126944 rank 0
2022-08-22 13:01:29,402 DEBUG TRAIN Batch 11/1000 loss 42.595509 loss_att 33.086987 loss_ctc 64.782059 loss_ctc_origin 56.736721 loss_ctc0 83.554520 lr 0.00127144 rank 0
2022-08-22 13:01:57,301 DEBUG TRAIN Batch 11/1100 loss 46.089409 loss_att 36.872921 loss_ctc 67.594543 loss_ctc_origin 55.779938 loss_ctc0 95.161942 lr 0.00127344 rank 0
2022-08-22 13:02:25,955 DEBUG TRAIN Batch 11/1200 loss 43.229004 loss_att 34.061440 loss_ctc 64.619987 loss_ctc_origin 60.117035 loss_ctc0 75.126877 lr 0.00127544 rank 0
2022-08-22 13:02:55,159 DEBUG TRAIN Batch 11/1300 loss 49.851517 loss_att 39.724396 loss_ctc 73.481461 loss_ctc_origin 70.172684 loss_ctc0 81.201950 lr 0.00127744 rank 0
2022-08-22 13:03:23,910 DEBUG TRAIN Batch 11/1400 loss 58.676880 loss_att 47.293900 loss_ctc 85.237167 loss_ctc_origin 78.638420 loss_ctc0 100.634247 lr 0.00127944 rank 0
2022-08-22 13:03:58,893 DEBUG TRAIN Batch 11/1500 loss 39.212646 loss_att 31.258884 loss_ctc 57.771431 loss_ctc_origin 46.901993 loss_ctc0 83.133446 lr 0.00128144 rank 0
2022-08-22 13:04:27,681 DEBUG TRAIN Batch 11/1600 loss 42.131386 loss_att 29.175535 loss_ctc 72.361710 loss_ctc_origin 49.476685 loss_ctc0 125.760094 lr 0.00128344 rank 0
2022-08-22 13:04:56,670 DEBUG TRAIN Batch 11/1700 loss 47.385960 loss_att 38.662556 loss_ctc 67.740562 loss_ctc_origin 62.991451 loss_ctc0 78.821823 lr 0.00128544 rank 0
2022-08-22 13:05:24,894 DEBUG TRAIN Batch 11/1800 loss 49.465988 loss_att 40.491871 loss_ctc 70.405602 loss_ctc_origin 65.611282 loss_ctc0 81.592331 lr 0.00128744 rank 0
2022-08-22 13:05:53,766 DEBUG TRAIN Batch 11/1900 loss 65.353706 loss_att 54.616131 loss_ctc 90.408051 loss_ctc_origin 84.423248 loss_ctc0 104.372604 lr 0.00128944 rank 0
2022-08-22 13:06:22,205 DEBUG TRAIN Batch 11/2000 loss 49.471855 loss_att 31.744038 loss_ctc 90.836769 loss_ctc_origin 40.490494 loss_ctc0 208.311401 lr 0.00129144 rank 0
2022-08-22 13:06:50,755 DEBUG TRAIN Batch 11/2100 loss 60.999290 loss_att 37.632721 loss_ctc 115.521271 loss_ctc_origin 58.418278 loss_ctc0 248.761566 lr 0.00129344 rank 0
2022-08-22 13:07:19,174 DEBUG TRAIN Batch 11/2200 loss 34.047157 loss_att 26.055193 loss_ctc 52.695076 loss_ctc_origin 48.992256 loss_ctc0 61.334984 lr 0.00129544 rank 0
2022-08-22 13:07:47,901 DEBUG TRAIN Batch 11/2300 loss 40.559425 loss_att 30.736036 loss_ctc 63.480667 loss_ctc_origin 55.541531 loss_ctc0 82.005325 lr 0.00129744 rank 0
2022-08-22 13:08:16,910 DEBUG TRAIN Batch 11/2400 loss 59.915253 loss_att 49.602947 loss_ctc 83.977310 loss_ctc_origin 79.429504 loss_ctc0 94.588867 lr 0.00129944 rank 0
2022-08-22 13:08:44,647 DEBUG TRAIN Batch 11/2500 loss 37.208641 loss_att 24.724953 loss_ctc 66.337250 loss_ctc_origin 40.208755 loss_ctc0 127.303741 lr 0.00130144 rank 0
2022-08-22 13:09:14,013 DEBUG TRAIN Batch 11/2600 loss 42.240608 loss_att 32.194260 loss_ctc 65.682083 loss_ctc_origin 49.627541 loss_ctc0 103.142677 lr 0.00130344 rank 0
2022-08-22 13:09:41,963 DEBUG TRAIN Batch 11/2700 loss 46.396149 loss_att 38.954552 loss_ctc 63.759880 loss_ctc_origin 60.288269 loss_ctc0 71.860306 lr 0.00130544 rank 0
2022-08-22 13:10:09,530 DEBUG TRAIN Batch 11/2800 loss 52.080399 loss_att 41.671589 loss_ctc 76.367615 loss_ctc_origin 70.911087 loss_ctc0 89.099525 lr 0.00130744 rank 0
2022-08-22 13:10:36,676 DEBUG TRAIN Batch 11/2900 loss 54.256462 loss_att 43.120613 loss_ctc 80.240097 loss_ctc_origin 74.207077 loss_ctc0 94.317139 lr 0.00130944 rank 0
2022-08-22 13:11:10,952 DEBUG TRAIN Batch 11/3000 loss 43.748154 loss_att 29.132944 loss_ctc 77.850304 loss_ctc_origin 54.689133 loss_ctc0 131.893036 lr 0.00131144 rank 0
2022-08-22 13:11:39,383 DEBUG TRAIN Batch 11/3100 loss 46.887852 loss_att 33.304703 loss_ctc 78.581863 loss_ctc_origin 48.101902 loss_ctc0 149.701782 lr 0.00131344 rank 0
2022-08-22 13:12:07,628 DEBUG TRAIN Batch 11/3200 loss 39.645576 loss_att 32.092308 loss_ctc 57.269867 loss_ctc_origin 53.447998 loss_ctc0 66.187561 lr 0.00131544 rank 0
2022-08-22 13:12:36,072 DEBUG TRAIN Batch 11/3300 loss 45.589859 loss_att 34.459660 loss_ctc 71.560326 loss_ctc_origin 67.695976 loss_ctc0 80.577133 lr 0.00131744 rank 0
2022-08-22 13:12:46,834 WARNING NaN or Inf found in input tensor.
2022-08-22 13:12:59,400 WARNING NaN or Inf found in input tensor.
2022-08-22 13:13:03,508 DEBUG TRAIN Batch 11/3400 loss 59.373695 loss_att 46.753288 loss_ctc 88.821304 loss_ctc_origin 83.843582 loss_ctc0 100.435982 lr 0.00131944 rank 0
2022-08-22 13:13:32,456 DEBUG TRAIN Batch 11/3500 loss 39.969604 loss_att 29.763655 loss_ctc 63.783485 loss_ctc_origin 47.476067 loss_ctc0 101.834122 lr 0.00132144 rank 0
2022-08-22 13:13:59,958 DEBUG TRAIN Batch 11/3600 loss 51.306679 loss_att 35.199928 loss_ctc 88.889099 loss_ctc_origin 55.643036 loss_ctc0 166.463242 lr 0.00132344 rank 0
2022-08-22 13:14:28,958 DEBUG TRAIN Batch 11/3700 loss 47.891068 loss_att 39.369461 loss_ctc 67.774818 loss_ctc_origin 65.610382 loss_ctc0 72.825180 lr 0.00132544 rank 0
2022-08-22 13:14:58,155 DEBUG TRAIN Batch 11/3800 loss 50.897408 loss_att 41.662567 loss_ctc 72.445358 loss_ctc_origin 69.277153 loss_ctc0 79.837830 lr 0.00132744 rank 0
2022-08-22 13:15:26,130 DEBUG TRAIN Batch 11/3900 loss 57.913391 loss_att 48.116173 loss_ctc 80.773575 loss_ctc_origin 75.036110 loss_ctc0 94.160980 lr 0.00132944 rank 0
2022-08-22 13:15:55,617 DEBUG TRAIN Batch 11/4000 loss 44.495232 loss_att 32.429043 loss_ctc 72.649681 loss_ctc_origin 48.786442 loss_ctc0 128.330566 lr 0.00133144 rank 0
2022-08-22 13:16:23,297 DEBUG TRAIN Batch 11/4100 loss 47.361626 loss_att 32.410118 loss_ctc 82.248482 loss_ctc_origin 56.740036 loss_ctc0 141.768188 lr 0.00133344 rank 0
2022-08-22 13:16:51,689 DEBUG TRAIN Batch 11/4200 loss 47.398819 loss_att 39.069954 loss_ctc 66.832848 loss_ctc_origin 63.321972 loss_ctc0 75.024902 lr 0.00133544 rank 0
2022-08-22 13:17:20,642 DEBUG TRAIN Batch 11/4300 loss 50.037575 loss_att 40.189243 loss_ctc 73.017014 loss_ctc_origin 67.150612 loss_ctc0 86.705276 lr 0.00133744 rank 0
2022-08-22 13:17:49,882 DEBUG TRAIN Batch 11/4400 loss 49.289795 loss_att 37.892281 loss_ctc 75.883995 loss_ctc_origin 67.674927 loss_ctc0 95.038483 lr 0.00133944 rank 0
2022-08-22 13:18:23,955 DEBUG TRAIN Batch 11/4500 loss 36.304909 loss_att 27.813215 loss_ctc 56.118862 loss_ctc_origin 42.117073 loss_ctc0 88.789703 lr 0.00134144 rank 0
2022-08-22 13:18:53,090 DEBUG TRAIN Batch 11/4600 loss 47.396713 loss_att 34.503860 loss_ctc 77.480026 loss_ctc_origin 54.595909 loss_ctc0 130.876312 lr 0.00134344 rank 0
2022-08-22 13:19:21,886 DEBUG TRAIN Batch 11/4700 loss 35.807518 loss_att 26.376959 loss_ctc 57.812157 loss_ctc_origin 52.845619 loss_ctc0 69.400742 lr 0.00134544 rank 0
2022-08-22 13:19:49,563 DEBUG TRAIN Batch 11/4800 loss 43.102016 loss_att 33.430199 loss_ctc 65.669594 loss_ctc_origin 57.110565 loss_ctc0 85.640671 lr 0.00134744 rank 0
2022-08-22 13:20:18,334 DEBUG TRAIN Batch 11/4900 loss 47.338078 loss_att 35.454903 loss_ctc 75.065483 loss_ctc_origin 66.711761 loss_ctc0 94.557510 lr 0.00134944 rank 0
2022-08-22 13:20:46,175 DEBUG TRAIN Batch 11/5000 loss 31.457455 loss_att 28.066572 loss_ctc 39.369511 loss_ctc_origin 33.555782 loss_ctc0 52.934875 lr 0.00135144 rank 0
2022-08-22 13:21:14,646 DEBUG TRAIN Batch 11/5100 loss 44.787926 loss_att 30.634689 loss_ctc 77.812134 loss_ctc_origin 53.133823 loss_ctc0 135.394867 lr 0.00135344 rank 0
2022-08-22 13:21:43,217 DEBUG TRAIN Batch 11/5200 loss 45.201256 loss_att 36.762375 loss_ctc 64.891975 loss_ctc_origin 62.093948 loss_ctc0 71.420700 lr 0.00135544 rank 0
2022-08-22 13:22:11,445 DEBUG TRAIN Batch 11/5300 loss 58.100986 loss_att 46.170422 loss_ctc 85.938972 loss_ctc_origin 80.616974 loss_ctc0 98.356964 lr 0.00135744 rank 0
2022-08-22 13:22:38,406 DEBUG TRAIN Batch 11/5400 loss 61.652077 loss_att 50.929401 loss_ctc 86.671654 loss_ctc_origin 80.582413 loss_ctc0 100.879883 lr 0.00135944 rank 0
2022-08-22 13:23:07,603 DEBUG TRAIN Batch 11/5500 loss 44.237499 loss_att 35.430988 loss_ctc 64.786026 loss_ctc_origin 57.055031 loss_ctc0 82.825005 lr 0.00136144 rank 0
2022-08-22 13:23:36,489 DEBUG TRAIN Batch 11/5600 loss 44.130299 loss_att 32.630753 loss_ctc 70.962570 loss_ctc_origin 45.874107 loss_ctc0 129.502319 lr 0.00136344 rank 0
2022-08-22 13:23:59,643 DEBUG CV Batch 11/0 loss 31.336922 loss_att 25.452782 loss_ctc 45.066582 loss_ctc_origin 41.036381 loss_ctc0 54.470390 history loss 29.493573 rank 0
2022-08-22 13:24:10,312 DEBUG CV Batch 11/100 loss 49.803314 loss_att 40.109535 loss_ctc 72.422142 loss_ctc_origin 67.588821 loss_ctc0 83.699883 history loss 48.313761 rank 0
2022-08-22 13:24:20,147 DEBUG CV Batch 11/200 loss 41.094254 loss_att 33.763165 loss_ctc 58.200134 loss_ctc_origin 53.507225 loss_ctc0 69.150253 history loss 50.352056 rank 0
2022-08-22 13:24:30,036 DEBUG CV Batch 11/300 loss 41.853703 loss_att 33.181618 loss_ctc 62.088566 loss_ctc_origin 54.788437 loss_ctc0 79.122200 history loss 49.499517 rank 0
2022-08-22 13:24:40,868 DEBUG CV Batch 11/400 loss 62.980324 loss_att 52.672844 loss_ctc 87.031105 loss_ctc_origin 80.054352 loss_ctc0 103.310196 history loss 47.647569 rank 0
2022-08-22 13:24:51,775 DEBUG CV Batch 11/500 loss 42.589756 loss_att 35.204319 loss_ctc 59.822441 loss_ctc_origin 56.638374 loss_ctc0 67.251930 history loss 47.438233 rank 0
2022-08-22 13:25:02,613 DEBUG CV Batch 11/600 loss 41.902931 loss_att 33.422188 loss_ctc 61.691334 loss_ctc_origin 54.989307 loss_ctc0 77.329391 history loss 47.431031 rank 0
2022-08-22 13:25:13,003 DEBUG CV Batch 11/700 loss 37.164650 loss_att 30.111341 loss_ctc 53.622375 loss_ctc_origin 46.807262 loss_ctc0 69.524307 history loss 47.100534 rank 0
2022-08-22 13:25:23,354 DEBUG CV Batch 11/800 loss 39.218765 loss_att 31.531178 loss_ctc 57.156467 loss_ctc_origin 48.767574 loss_ctc0 76.730545 history loss 47.040475 rank 0
2022-08-22 13:25:33,784 INFO Epoch 11 CV info cv_loss 47.003996706811016
2022-08-22 13:25:33,784 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/11.pt
2022-08-22 13:25:34,230 INFO Epoch 12 TRAIN info lr 0.00136512
2022-08-22 13:25:34,234 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 13:26:01,116 DEBUG TRAIN Batch 12/0 loss 38.717392 loss_att 30.815199 loss_ctc 57.155838 loss_ctc_origin 47.109341 loss_ctc0 80.597656 lr 0.00136520 rank 0
2022-08-22 13:26:29,739 DEBUG TRAIN Batch 12/100 loss 44.066036 loss_att 29.221155 loss_ctc 78.704086 loss_ctc_origin 61.835045 loss_ctc0 118.065163 lr 0.00136720 rank 0
2022-08-22 13:26:58,225 DEBUG TRAIN Batch 12/200 loss 40.021282 loss_att 30.506191 loss_ctc 62.223160 loss_ctc_origin 57.397354 loss_ctc0 73.483368 lr 0.00136920 rank 0
2022-08-22 13:27:26,579 DEBUG TRAIN Batch 12/300 loss 40.987778 loss_att 29.904316 loss_ctc 66.849190 loss_ctc_origin 60.069550 loss_ctc0 82.668358 lr 0.00137120 rank 0
2022-08-22 13:27:55,222 DEBUG TRAIN Batch 12/400 loss 54.785973 loss_att 43.130127 loss_ctc 81.982948 loss_ctc_origin 74.782768 loss_ctc0 98.783356 lr 0.00137320 rank 0
2022-08-22 13:28:24,939 DEBUG TRAIN Batch 12/500 loss 43.678627 loss_att 31.882179 loss_ctc 71.203659 loss_ctc_origin 47.451920 loss_ctc0 126.624390 lr 0.00137520 rank 0
2022-08-22 13:28:52,860 DEBUG TRAIN Batch 12/600 loss 53.555000 loss_att 38.403465 loss_ctc 88.908585 loss_ctc_origin 58.516769 loss_ctc0 159.822800 lr 0.00137720 rank 0
2022-08-22 13:29:20,727 DEBUG TRAIN Batch 12/700 loss 42.573662 loss_att 33.585781 loss_ctc 63.545380 loss_ctc_origin 60.789612 loss_ctc0 69.975510 lr 0.00137920 rank 0
2022-08-22 13:29:48,850 DEBUG TRAIN Batch 12/800 loss 45.155884 loss_att 35.098061 loss_ctc 68.624146 loss_ctc_origin 62.784889 loss_ctc0 82.249084 lr 0.00138120 rank 0
2022-08-22 13:30:18,192 DEBUG TRAIN Batch 12/900 loss 57.486877 loss_att 43.784904 loss_ctc 89.458145 loss_ctc_origin 79.923042 loss_ctc0 111.706734 lr 0.00138320 rank 0
2022-08-22 13:30:46,402 DEBUG TRAIN Batch 12/1000 loss 40.405525 loss_att 31.546280 loss_ctc 61.077087 loss_ctc_origin 48.024269 loss_ctc0 91.533661 lr 0.00138520 rank 0
2022-08-22 13:31:07,642 WARNING NaN or Inf found in input tensor.
2022-08-22 13:31:14,902 DEBUG TRAIN Batch 12/1100 loss 39.751152 loss_att 31.493893 loss_ctc 59.018089 loss_ctc_origin 54.214699 loss_ctc0 70.226006 lr 0.00138720 rank 0
2022-08-22 13:31:41,421 WARNING NaN or Inf found in input tensor.
2022-08-22 13:31:42,963 DEBUG TRAIN Batch 12/1200 loss 40.593670 loss_att 31.172016 loss_ctc 62.577522 loss_ctc_origin 57.354561 loss_ctc0 74.764435 lr 0.00138920 rank 0
2022-08-22 13:32:12,669 DEBUG TRAIN Batch 12/1300 loss 54.936142 loss_att 45.706783 loss_ctc 76.471313 loss_ctc_origin 73.009026 loss_ctc0 84.550003 lr 0.00139120 rank 0
2022-08-22 13:32:36,846 WARNING NaN or Inf found in input tensor.
2022-08-22 13:32:41,507 DEBUG TRAIN Batch 12/1400 loss 60.350803 loss_att 48.984669 loss_ctc 86.871780 loss_ctc_origin 81.295799 loss_ctc0 99.882408 lr 0.00139320 rank 0
2022-08-22 13:33:15,909 DEBUG TRAIN Batch 12/1500 loss 42.937340 loss_att 31.704941 loss_ctc 69.146271 loss_ctc_origin 51.104565 loss_ctc0 111.243591 lr 0.00139520 rank 0
2022-08-22 13:33:45,186 DEBUG TRAIN Batch 12/1600 loss 53.774464 loss_att 34.510120 loss_ctc 98.724594 loss_ctc_origin 57.209499 loss_ctc0 195.593140 lr 0.00139720 rank 0
2022-08-22 13:34:13,229 DEBUG TRAIN Batch 12/1700 loss 46.115131 loss_att 38.730843 loss_ctc 63.345139 loss_ctc_origin 59.623260 loss_ctc0 72.029518 lr 0.00139920 rank 0
2022-08-22 13:34:42,325 DEBUG TRAIN Batch 12/1800 loss 50.777889 loss_att 40.860455 loss_ctc 73.918571 loss_ctc_origin 68.102997 loss_ctc0 87.488243 lr 0.00140120 rank 0
2022-08-22 13:35:11,024 DEBUG TRAIN Batch 12/1900 loss 51.560654 loss_att 39.536873 loss_ctc 79.616135 loss_ctc_origin 71.339966 loss_ctc0 98.927193 lr 0.00140320 rank 0
2022-08-22 13:35:13,793 WARNING NaN or Inf found in input tensor.
2022-08-22 13:35:39,943 DEBUG TRAIN Batch 12/2000 loss 35.913395 loss_att 24.473560 loss_ctc 62.606339 loss_ctc_origin 39.079800 loss_ctc0 117.501602 lr 0.00140520 rank 0
2022-08-22 13:35:48,034 WARNING NaN or Inf found in input tensor.
2022-08-22 13:36:07,292 DEBUG TRAIN Batch 12/2100 loss 51.390106 loss_att 36.682613 loss_ctc 85.707581 loss_ctc_origin 57.270527 loss_ctc0 152.060699 lr 0.00140720 rank 0
2022-08-22 13:36:36,104 DEBUG TRAIN Batch 12/2200 loss 46.755363 loss_att 37.547997 loss_ctc 68.239212 loss_ctc_origin 64.729904 loss_ctc0 76.427597 lr 0.00140920 rank 0
2022-08-22 13:37:04,835 DEBUG TRAIN Batch 12/2300 loss 44.239723 loss_att 34.568192 loss_ctc 66.806641 loss_ctc_origin 61.701538 loss_ctc0 78.718559 lr 0.00141120 rank 0
2022-08-22 13:37:34,369 DEBUG TRAIN Batch 12/2400 loss 52.761524 loss_att 41.886684 loss_ctc 78.136147 loss_ctc_origin 70.088463 loss_ctc0 96.914070 lr 0.00141320 rank 0
2022-08-22 13:38:03,838 DEBUG TRAIN Batch 12/2500 loss 33.109703 loss_att 25.977932 loss_ctc 49.750504 loss_ctc_origin 44.076347 loss_ctc0 62.990196 lr 0.00141520 rank 0
2022-08-22 13:38:32,927 DEBUG TRAIN Batch 12/2600 loss 41.891022 loss_att 29.913359 loss_ctc 69.838898 loss_ctc_origin 48.217758 loss_ctc0 120.288239 lr 0.00141720 rank 0
2022-08-22 13:39:01,444 DEBUG TRAIN Batch 12/2700 loss 43.913254 loss_att 33.710503 loss_ctc 67.719681 loss_ctc_origin 64.538605 loss_ctc0 75.142204 lr 0.00141920 rank 0
2022-08-22 13:39:29,909 DEBUG TRAIN Batch 12/2800 loss 46.656174 loss_att 34.353935 loss_ctc 75.361404 loss_ctc_origin 68.572411 loss_ctc0 91.202377 lr 0.00142120 rank 0
2022-08-22 13:39:58,648 DEBUG TRAIN Batch 12/2900 loss 50.943344 loss_att 39.706333 loss_ctc 77.163025 loss_ctc_origin 67.581566 loss_ctc0 99.519760 lr 0.00142320 rank 0
2022-08-22 13:40:34,137 DEBUG TRAIN Batch 12/3000 loss 28.018038 loss_att 21.043505 loss_ctc 44.291946 loss_ctc_origin 36.120560 loss_ctc0 63.358517 lr 0.00142520 rank 0
2022-08-22 13:41:02,977 DEBUG TRAIN Batch 12/3100 loss 53.684414 loss_att 36.907166 loss_ctc 92.831322 loss_ctc_origin 63.619476 loss_ctc0 160.992279 lr 0.00142720 rank 0
2022-08-22 13:41:29,592 WARNING NaN or Inf found in input tensor.
2022-08-22 13:41:31,367 DEBUG TRAIN Batch 12/3200 loss 43.821709 loss_att 35.944725 loss_ctc 62.201340 loss_ctc_origin 59.158031 loss_ctc0 69.302399 lr 0.00142920 rank 0
2022-08-22 13:41:59,580 DEBUG TRAIN Batch 12/3300 loss 47.260174 loss_att 35.488464 loss_ctc 74.727493 loss_ctc_origin 67.316742 loss_ctc0 92.019257 lr 0.00143120 rank 0
2022-08-22 13:42:28,536 DEBUG TRAIN Batch 12/3400 loss 56.882477 loss_att 44.260033 loss_ctc 86.334839 loss_ctc_origin 77.837273 loss_ctc0 106.162476 lr 0.00143320 rank 0
2022-08-22 13:42:37,779 WARNING NaN or Inf found in input tensor.
2022-08-22 13:42:57,587 DEBUG TRAIN Batch 12/3500 loss 38.355160 loss_att 28.275280 loss_ctc 61.874878 loss_ctc_origin 47.503498 loss_ctc0 95.408096 lr 0.00143520 rank 0
2022-08-22 13:43:24,933 DEBUG TRAIN Batch 12/3600 loss 45.558571 loss_att 31.924137 loss_ctc 77.372246 loss_ctc_origin 53.642551 loss_ctc0 132.741531 lr 0.00143720 rank 0
2022-08-22 13:43:53,900 DEBUG TRAIN Batch 12/3700 loss 36.171623 loss_att 27.903568 loss_ctc 55.463757 loss_ctc_origin 49.677002 loss_ctc0 68.966187 lr 0.00143920 rank 0
2022-08-22 13:44:22,586 DEBUG TRAIN Batch 12/3800 loss 52.545593 loss_att 41.630524 loss_ctc 78.014091 loss_ctc_origin 73.051117 loss_ctc0 89.594376 lr 0.00144120 rank 0
2022-08-22 13:44:51,030 DEBUG TRAIN Batch 12/3900 loss 61.591583 loss_att 49.848671 loss_ctc 88.991714 loss_ctc_origin 81.869507 loss_ctc0 105.610184 lr 0.00144320 rank 0
2022-08-22 13:44:53,805 WARNING NaN or Inf found in input tensor.
2022-08-22 13:45:19,711 DEBUG TRAIN Batch 12/4000 loss 40.411999 loss_att 31.992983 loss_ctc 60.056366 loss_ctc_origin 52.868729 loss_ctc0 76.827515 lr 0.00144520 rank 0
2022-08-22 13:45:48,434 DEBUG TRAIN Batch 12/4100 loss 50.841240 loss_att 36.097263 loss_ctc 85.243843 loss_ctc_origin 59.632896 loss_ctc0 145.002716 lr 0.00144720 rank 0
2022-08-22 13:46:15,187 WARNING NaN or Inf found in input tensor.
2022-08-22 13:46:16,734 DEBUG TRAIN Batch 12/4200 loss 44.992313 loss_att 36.076641 loss_ctc 65.795547 loss_ctc_origin 62.229328 loss_ctc0 74.116737 lr 0.00144920 rank 0
2022-08-22 13:46:28,427 WARNING NaN or Inf found in input tensor.
2022-08-22 13:46:41,351 WARNING NaN or Inf found in input tensor.
2022-08-22 13:46:44,560 DEBUG TRAIN Batch 12/4300 loss 50.460258 loss_att 39.879200 loss_ctc 75.149399 loss_ctc_origin 71.064835 loss_ctc0 84.680038 lr 0.00145120 rank 0
2022-08-22 13:47:08,490 WARNING NaN or Inf found in input tensor.
2022-08-22 13:47:12,720 DEBUG TRAIN Batch 12/4400 loss 49.659019 loss_att 39.571159 loss_ctc 73.197357 loss_ctc_origin 66.149170 loss_ctc0 89.643127 lr 0.00145320 rank 0
2022-08-22 13:47:48,215 DEBUG TRAIN Batch 12/4500 loss 35.400963 loss_att 28.806877 loss_ctc 50.787155 loss_ctc_origin 46.442673 loss_ctc0 60.924286 lr 0.00145520 rank 0
2022-08-22 13:47:55,955 WARNING NaN or Inf found in input tensor.
2022-08-22 13:48:16,143 DEBUG TRAIN Batch 12/4600 loss 55.521294 loss_att 38.004669 loss_ctc 96.393417 loss_ctc_origin 64.570763 loss_ctc0 170.646271 lr 0.00145720 rank 0
2022-08-22 13:48:42,486 WARNING NaN or Inf found in input tensor.
2022-08-22 13:48:43,993 DEBUG TRAIN Batch 12/4700 loss 40.783485 loss_att 31.529476 loss_ctc 62.376163 loss_ctc_origin 58.055435 loss_ctc0 72.457855 lr 0.00145920 rank 0
2022-08-22 13:49:12,824 DEBUG TRAIN Batch 12/4800 loss 49.899086 loss_att 39.217285 loss_ctc 74.823296 loss_ctc_origin 68.850449 loss_ctc0 88.759949 lr 0.00146120 rank 0
2022-08-22 13:49:40,555 DEBUG TRAIN Batch 12/4900 loss 61.383541 loss_att 49.717979 loss_ctc 88.603180 loss_ctc_origin 82.530586 loss_ctc0 102.772575 lr 0.00146320 rank 0
2022-08-22 13:50:02,021 WARNING NaN or Inf found in input tensor.
2022-08-22 13:50:08,894 DEBUG TRAIN Batch 12/5000 loss 37.759769 loss_att 27.297049 loss_ctc 62.172783 loss_ctc_origin 46.045174 loss_ctc0 99.803864 lr 0.00146520 rank 0
2022-08-22 13:50:16,339 WARNING NaN or Inf found in input tensor.
2022-08-22 13:50:38,069 DEBUG TRAIN Batch 12/5100 loss 43.467628 loss_att 35.637024 loss_ctc 61.739029 loss_ctc_origin 51.623127 loss_ctc0 85.342796 lr 0.00146720 rank 0
2022-08-22 13:51:06,448 DEBUG TRAIN Batch 12/5200 loss 43.039581 loss_att 33.694138 loss_ctc 64.845612 loss_ctc_origin 61.111187 loss_ctc0 73.559273 lr 0.00146920 rank 0
2022-08-22 13:51:35,467 DEBUG TRAIN Batch 12/5300 loss 48.070862 loss_att 37.685368 loss_ctc 72.303688 loss_ctc_origin 66.568024 loss_ctc0 85.686913 lr 0.00147120 rank 0
2022-08-22 13:52:04,121 DEBUG TRAIN Batch 12/5400 loss 63.459236 loss_att 50.819130 loss_ctc 92.952805 loss_ctc_origin 88.424683 loss_ctc0 103.518417 lr 0.00147320 rank 0
2022-08-22 13:52:33,297 DEBUG TRAIN Batch 12/5500 loss 41.342552 loss_att 35.425705 loss_ctc 55.148537 loss_ctc_origin 50.267532 loss_ctc0 66.537552 lr 0.00147520 rank 0
2022-08-22 13:53:00,958 DEBUG TRAIN Batch 12/5600 loss 41.947113 loss_att 30.879948 loss_ctc 67.770500 loss_ctc_origin 54.800850 loss_ctc0 98.033005 lr 0.00147720 rank 0
2022-08-22 13:53:24,040 DEBUG CV Batch 12/0 loss 26.102556 loss_att 21.507238 loss_ctc 36.824963 loss_ctc_origin 34.103271 loss_ctc0 43.175571 history loss 24.567112 rank 0
2022-08-22 13:53:35,007 DEBUG CV Batch 12/100 loss 36.701065 loss_att 29.267284 loss_ctc 54.046547 loss_ctc_origin 48.660778 loss_ctc0 66.613342 history loss 51.423694 rank 0
2022-08-22 13:53:45,007 DEBUG CV Batch 12/200 loss 47.536957 loss_att 39.439857 loss_ctc 66.430176 loss_ctc_origin 62.210400 loss_ctc0 76.276306 history loss 52.115073 rank 0
2022-08-22 13:53:55,271 DEBUG CV Batch 12/300 loss 48.274715 loss_att 38.959530 loss_ctc 70.010147 loss_ctc_origin 63.088150 loss_ctc0 86.161461 history loss 51.309615 rank 0
2022-08-22 13:54:06,115 DEBUG CV Batch 12/400 loss 71.722427 loss_att 60.416656 loss_ctc 98.102539 loss_ctc_origin 91.408234 loss_ctc0 113.722580 history loss 49.857371 rank 0
2022-08-22 13:54:17,028 DEBUG CV Batch 12/500 loss 31.146866 loss_att 25.242895 loss_ctc 44.922791 loss_ctc_origin 42.000854 loss_ctc0 51.740643 history loss 49.721402 rank 0
2022-08-22 13:54:28,244 DEBUG CV Batch 12/600 loss 37.903641 loss_att 29.752117 loss_ctc 56.923859 loss_ctc_origin 52.474628 loss_ctc0 67.305397 history loss 49.657046 rank 0
2022-08-22 13:54:38,532 DEBUG CV Batch 12/700 loss 43.643478 loss_att 35.697617 loss_ctc 62.183823 loss_ctc_origin 56.580013 loss_ctc0 75.259369 history loss 49.291801 rank 0
2022-08-22 13:54:48,785 DEBUG CV Batch 12/800 loss 45.302074 loss_att 36.656326 loss_ctc 65.475487 loss_ctc_origin 58.217937 loss_ctc0 82.409775 history loss 49.286305 rank 0
2022-08-22 13:54:58,994 INFO Epoch 12 CV info cv_loss 49.51714902787146
2022-08-22 13:54:58,994 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/12.pt
2022-08-22 13:54:59,433 INFO Epoch 13 TRAIN info lr 0.00147888
2022-08-22 13:54:59,437 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 13:55:25,765 DEBUG TRAIN Batch 13/0 loss 35.446556 loss_att 29.669365 loss_ctc 48.926674 loss_ctc_origin 45.699253 loss_ctc0 56.457314 lr 0.00147896 rank 0
2022-08-22 13:55:54,241 DEBUG TRAIN Batch 13/100 loss 43.937778 loss_att 34.262489 loss_ctc 66.513451 loss_ctc_origin 59.345390 loss_ctc0 83.238930 lr 0.00148096 rank 0
2022-08-22 13:56:07,238 WARNING NaN or Inf found in input tensor.
2022-08-22 13:56:23,524 DEBUG TRAIN Batch 13/200 loss 47.374687 loss_att 39.042671 loss_ctc 66.816055 loss_ctc_origin 64.347374 loss_ctc0 72.576309 lr 0.00148296 rank 0
2022-08-22 13:56:52,188 DEBUG TRAIN Batch 13/300 loss 50.222824 loss_att 37.945000 loss_ctc 78.871078 loss_ctc_origin 74.933075 loss_ctc0 88.059753 lr 0.00148496 rank 0
2022-08-22 13:57:20,987 DEBUG TRAIN Batch 13/400 loss 58.096054 loss_att 44.119465 loss_ctc 90.708099 loss_ctc_origin 84.352295 loss_ctc0 105.538307 lr 0.00148696 rank 0
2022-08-22 13:57:50,126 DEBUG TRAIN Batch 13/500 loss 41.587753 loss_att 35.844414 loss_ctc 54.988876 loss_ctc_origin 52.771366 loss_ctc0 60.163055 lr 0.00148896 rank 0
2022-08-22 13:57:57,599 WARNING NaN or Inf found in input tensor.
2022-08-22 13:58:17,809 DEBUG TRAIN Batch 13/600 loss 45.591911 loss_att 36.793266 loss_ctc 66.122093 loss_ctc_origin 60.293449 loss_ctc0 79.722260 lr 0.00149096 rank 0
2022-08-22 13:58:45,941 DEBUG TRAIN Batch 13/700 loss 48.868324 loss_att 39.878105 loss_ctc 69.845505 loss_ctc_origin 68.235954 loss_ctc0 73.601112 lr 0.00149296 rank 0
2022-08-22 13:59:13,487 DEBUG TRAIN Batch 13/800 loss 56.460602 loss_att 43.847633 loss_ctc 85.890869 loss_ctc_origin 83.029984 loss_ctc0 92.566277 lr 0.00149496 rank 0
2022-08-22 13:59:39,098 WARNING NaN or Inf found in input tensor.
2022-08-22 13:59:43,510 DEBUG TRAIN Batch 13/900 loss 55.934555 loss_att 42.447826 loss_ctc 87.403595 loss_ctc_origin 80.481842 loss_ctc0 103.554367 lr 0.00149696 rank 0
2022-08-22 14:00:13,046 DEBUG TRAIN Batch 13/1000 loss 35.011059 loss_att 28.901424 loss_ctc 49.266872 loss_ctc_origin 48.408787 loss_ctc0 51.269070 lr 0.00149896 rank 0
2022-08-22 14:00:42,220 DEBUG TRAIN Batch 13/1100 loss 44.448692 loss_att 30.465391 loss_ctc 77.076401 loss_ctc_origin 55.277336 loss_ctc0 127.940872 lr 0.00150096 rank 0
2022-08-22 14:01:11,117 DEBUG TRAIN Batch 13/1200 loss 46.359665 loss_att 36.091263 loss_ctc 70.319275 loss_ctc_origin 65.842621 loss_ctc0 80.764793 lr 0.00150296 rank 0
2022-08-22 14:01:40,416 DEBUG TRAIN Batch 13/1300 loss 44.235500 loss_att 32.925423 loss_ctc 70.625679 loss_ctc_origin 63.387161 loss_ctc0 87.515549 lr 0.00150496 rank 0
2022-08-22 14:02:09,508 DEBUG TRAIN Batch 13/1400 loss 67.417068 loss_att 52.955223 loss_ctc 101.161377 loss_ctc_origin 94.677948 loss_ctc0 116.289383 lr 0.00150696 rank 0
2022-08-22 14:02:43,749 DEBUG TRAIN Batch 13/1500 loss 44.788174 loss_att 31.206741 loss_ctc 76.478180 loss_ctc_origin 52.800697 loss_ctc0 131.725647 lr 0.00150896 rank 0
2022-08-22 14:03:12,425 DEBUG TRAIN Batch 13/1600 loss 51.853416 loss_att 35.996223 loss_ctc 88.853531 loss_ctc_origin 60.474648 loss_ctc0 155.070923 lr 0.00151096 rank 0
2022-08-22 14:03:40,167 DEBUG TRAIN Batch 13/1700 loss 40.468670 loss_att 29.150566 loss_ctc 66.877579 loss_ctc_origin 63.233486 loss_ctc0 75.380447 lr 0.00151296 rank 0
2022-08-22 14:03:45,340 WARNING NaN or Inf found in input tensor.
2022-08-22 14:04:09,597 DEBUG TRAIN Batch 13/1800 loss 53.829102 loss_att 42.749763 loss_ctc 79.680893 loss_ctc_origin 74.794960 loss_ctc0 91.081406 lr 0.00151496 rank 0
2022-08-22 14:04:38,001 DEBUG TRAIN Batch 13/1900 loss 58.596420 loss_att 45.001129 loss_ctc 90.318771 loss_ctc_origin 84.242813 loss_ctc0 104.496010 lr 0.00151696 rank 0
2022-08-22 14:05:07,940 DEBUG TRAIN Batch 13/2000 loss 30.944267 loss_att 23.032337 loss_ctc 49.405441 loss_ctc_origin 38.884369 loss_ctc0 73.954620 lr 0.00151896 rank 0
2022-08-22 14:05:35,829 DEBUG TRAIN Batch 13/2100 loss 40.602314 loss_att 31.188183 loss_ctc 62.568615 loss_ctc_origin 53.886559 loss_ctc0 82.826752 lr 0.00152096 rank 0
2022-08-22 14:06:05,071 DEBUG TRAIN Batch 13/2200 loss 40.192329 loss_att 30.518930 loss_ctc 62.763599 loss_ctc_origin 58.074150 loss_ctc0 73.705643 lr 0.00152296 rank 0
2022-08-22 14:06:32,868 DEBUG TRAIN Batch 13/2300 loss 55.102074 loss_att 43.678787 loss_ctc 81.756409 loss_ctc_origin 77.559189 loss_ctc0 91.549927 lr 0.00152496 rank 0
2022-08-22 14:07:02,061 DEBUG TRAIN Batch 13/2400 loss 53.441071 loss_att 41.017067 loss_ctc 82.430405 loss_ctc_origin 75.373993 loss_ctc0 98.895355 lr 0.00152696 rank 0
2022-08-22 14:07:31,149 DEBUG TRAIN Batch 13/2500 loss 36.499485 loss_att 30.775791 loss_ctc 49.854774 loss_ctc_origin 48.898830 loss_ctc0 52.085312 lr 0.00152896 rank 0
2022-08-22 14:07:59,696 DEBUG TRAIN Batch 13/2600 loss 51.400734 loss_att 36.499760 loss_ctc 86.169678 loss_ctc_origin 57.385204 loss_ctc0 153.333435 lr 0.00153096 rank 0
2022-08-22 14:08:27,775 DEBUG TRAIN Batch 13/2700 loss 44.701584 loss_att 35.834534 loss_ctc 65.391357 loss_ctc_origin 60.286674 loss_ctc0 77.302269 lr 0.00153296 rank 0
2022-08-22 14:08:56,826 DEBUG TRAIN Batch 13/2800 loss 47.521698 loss_att 35.742859 loss_ctc 75.005661 loss_ctc_origin 68.612434 loss_ctc0 89.923195 lr 0.00153496 rank 0
2022-08-22 14:09:25,369 DEBUG TRAIN Batch 13/2900 loss 57.183414 loss_att 41.799568 loss_ctc 93.079056 loss_ctc_origin 81.590942 loss_ctc0 119.884644 lr 0.00153696 rank 0
2022-08-22 14:09:58,991 DEBUG TRAIN Batch 13/3000 loss 35.411560 loss_att 29.699276 loss_ctc 48.740219 loss_ctc_origin 47.256954 loss_ctc0 52.201160 lr 0.00153896 rank 0
2022-08-22 14:10:26,928 DEBUG TRAIN Batch 13/3100 loss 45.070244 loss_att 32.472435 loss_ctc 74.465134 loss_ctc_origin 58.300819 loss_ctc0 112.181847 lr 0.00154096 rank 0
2022-08-22 14:10:53,928 WARNING NaN or Inf found in input tensor.
2022-08-22 14:10:55,441 DEBUG TRAIN Batch 13/3200 loss 47.699162 loss_att 37.754646 loss_ctc 70.903030 loss_ctc_origin 67.240356 loss_ctc0 79.449265 lr 0.00154296 rank 0
2022-08-22 14:11:24,860 DEBUG TRAIN Batch 13/3300 loss 48.577560 loss_att 37.732079 loss_ctc 73.883675 loss_ctc_origin 68.856102 loss_ctc0 85.614670 lr 0.00154496 rank 0
2022-08-22 14:11:53,024 DEBUG TRAIN Batch 13/3400 loss 58.552204 loss_att 45.000092 loss_ctc 90.173798 loss_ctc_origin 85.142281 loss_ctc0 101.914017 lr 0.00154696 rank 0
2022-08-22 14:12:21,612 DEBUG TRAIN Batch 13/3500 loss 39.898338 loss_att 32.980682 loss_ctc 56.039543 loss_ctc_origin 51.619267 loss_ctc0 66.353508 lr 0.00154896 rank 0
2022-08-22 14:12:29,594 WARNING NaN or Inf found in input tensor.
2022-08-22 14:12:51,109 DEBUG TRAIN Batch 13/3600 loss 44.343838 loss_att 32.289001 loss_ctc 72.471786 loss_ctc_origin 63.775761 loss_ctc0 92.762505 lr 0.00155096 rank 0
2022-08-22 14:13:20,639 DEBUG TRAIN Batch 13/3700 loss 44.596466 loss_att 34.441643 loss_ctc 68.291046 loss_ctc_origin 63.738510 loss_ctc0 78.913635 lr 0.00155296 rank 0
2022-08-22 14:13:49,614 DEBUG TRAIN Batch 13/3800 loss 51.170738 loss_att 41.250736 loss_ctc 74.317413 loss_ctc_origin 70.591484 loss_ctc0 83.011230 lr 0.00155496 rank 0
2022-08-22 14:14:18,734 DEBUG TRAIN Batch 13/3900 loss 52.245209 loss_att 40.627182 loss_ctc 79.353928 loss_ctc_origin 71.953690 loss_ctc0 96.621140 lr 0.00155696 rank 0
2022-08-22 14:14:48,253 DEBUG TRAIN Batch 13/4000 loss 43.039864 loss_att 34.034966 loss_ctc 64.051292 loss_ctc_origin 57.219803 loss_ctc0 79.991440 lr 0.00155896 rank 0
2022-08-22 14:15:01,528 WARNING NaN or Inf found in input tensor.
2022-08-22 14:15:16,107 DEBUG TRAIN Batch 13/4100 loss 48.457294 loss_att 36.592278 loss_ctc 76.142334 loss_ctc_origin 56.093620 loss_ctc0 122.922661 lr 0.00156096 rank 0
2022-08-22 14:15:44,926 DEBUG TRAIN Batch 13/4200 loss 48.090034 loss_att 39.314381 loss_ctc 68.566559 loss_ctc_origin 64.521286 loss_ctc0 78.005539 lr 0.00156296 rank 0
2022-08-22 14:16:14,523 DEBUG TRAIN Batch 13/4300 loss 49.206467 loss_att 37.642910 loss_ctc 76.188095 loss_ctc_origin 69.597244 loss_ctc0 91.566742 lr 0.00156496 rank 0
2022-08-22 14:16:43,209 DEBUG TRAIN Batch 13/4400 loss 58.190201 loss_att 46.679283 loss_ctc 85.048996 loss_ctc_origin 78.413254 loss_ctc0 100.532394 lr 0.00156696 rank 0
2022-08-22 14:17:19,839 DEBUG TRAIN Batch 13/4500 loss 38.750736 loss_att 32.234249 loss_ctc 53.955872 loss_ctc_origin 48.121956 loss_ctc0 67.568344 lr 0.00156896 rank 0
2022-08-22 14:17:28,127 WARNING NaN or Inf found in input tensor.
2022-08-22 14:17:49,488 DEBUG TRAIN Batch 13/4600 loss 37.026787 loss_att 28.919157 loss_ctc 55.944595 loss_ctc_origin 52.049232 loss_ctc0 65.033775 lr 0.00157096 rank 0
2022-08-22 14:18:18,822 DEBUG TRAIN Batch 13/4700 loss 42.254761 loss_att 34.494827 loss_ctc 60.361275 loss_ctc_origin 56.874290 loss_ctc0 68.497559 lr 0.00157296 rank 0
2022-08-22 14:18:48,190 DEBUG TRAIN Batch 13/4800 loss 49.581978 loss_att 38.080223 loss_ctc 76.419411 loss_ctc_origin 69.319115 loss_ctc0 92.986771 lr 0.00157496 rank 0
2022-08-22 14:19:16,747 DEBUG TRAIN Batch 13/4900 loss 57.930870 loss_att 45.528503 loss_ctc 86.869720 loss_ctc_origin 78.673439 loss_ctc0 105.994385 lr 0.00157696 rank 0
2022-08-22 14:19:19,450 WARNING NaN or Inf found in input tensor.
2022-08-22 14:19:46,923 DEBUG TRAIN Batch 13/5000 loss 34.491577 loss_att 25.616934 loss_ctc 55.199066 loss_ctc_origin 41.340118 loss_ctc0 87.536606 lr 0.00157896 rank 0
2022-08-22 14:20:15,250 DEBUG TRAIN Batch 13/5100 loss 48.533218 loss_att 34.143990 loss_ctc 82.108086 loss_ctc_origin 58.737728 loss_ctc0 136.638916 lr 0.00158096 rank 0
2022-08-22 14:20:44,387 DEBUG TRAIN Batch 13/5200 loss 44.176674 loss_att 35.558853 loss_ctc 64.284927 loss_ctc_origin 60.616142 loss_ctc0 72.845428 lr 0.00158296 rank 0
2022-08-22 14:21:12,906 DEBUG TRAIN Batch 13/5300 loss 53.326965 loss_att 41.907021 loss_ctc 79.973511 loss_ctc_origin 74.883888 loss_ctc0 91.849297 lr 0.00158496 rank 0
2022-08-22 14:21:42,434 DEBUG TRAIN Batch 13/5400 loss 62.786377 loss_att 50.506786 loss_ctc 91.438751 loss_ctc_origin 83.864250 loss_ctc0 109.112579 lr 0.00158696 rank 0
2022-08-22 14:22:03,693 WARNING NaN or Inf found in input tensor.
2022-08-22 14:22:11,068 DEBUG TRAIN Batch 13/5500 loss 42.121025 loss_att 34.112221 loss_ctc 60.808228 loss_ctc_origin 55.193775 loss_ctc0 73.908615 lr 0.00158896 rank 0
2022-08-22 14:22:39,709 DEBUG TRAIN Batch 13/5600 loss 46.081894 loss_att 34.152534 loss_ctc 73.917068 loss_ctc_origin 58.855507 loss_ctc0 109.060699 lr 0.00159096 rank 0
2022-08-22 14:23:03,369 DEBUG CV Batch 13/0 loss 25.647602 loss_att 18.780781 loss_ctc 41.670181 loss_ctc_origin 29.939383 loss_ctc0 69.042038 history loss 24.138920 rank 0
2022-08-22 14:23:14,442 DEBUG CV Batch 13/100 loss 35.584236 loss_att 27.065331 loss_ctc 55.461685 loss_ctc_origin 43.535084 loss_ctc0 83.290421 history loss 45.928494 rank 0
2022-08-22 14:23:24,486 DEBUG CV Batch 13/200 loss 40.480507 loss_att 32.991924 loss_ctc 57.953873 loss_ctc_origin 52.326294 loss_ctc0 71.084877 history loss 47.043318 rank 0
2022-08-22 14:23:34,529 DEBUG CV Batch 13/300 loss 43.878906 loss_att 34.419628 loss_ctc 65.950562 loss_ctc_origin 57.425823 loss_ctc0 85.841614 history loss 46.428864 rank 0
2022-08-22 14:23:45,262 DEBUG CV Batch 13/400 loss 64.230057 loss_att 52.824028 loss_ctc 90.844116 loss_ctc_origin 81.871185 loss_ctc0 111.780960 history loss 45.103388 rank 0
2022-08-22 14:23:56,509 DEBUG CV Batch 13/500 loss 28.694618 loss_att 22.401735 loss_ctc 43.378014 loss_ctc_origin 36.204880 loss_ctc0 60.115314 history loss 44.872863 rank 0
2022-08-22 14:24:07,723 DEBUG CV Batch 13/600 loss 36.721428 loss_att 26.996626 loss_ctc 59.412628 loss_ctc_origin 45.130692 loss_ctc0 92.737152 history loss 44.727166 rank 0
2022-08-22 14:24:18,483 DEBUG CV Batch 13/700 loss 37.960510 loss_att 30.500326 loss_ctc 55.367615 loss_ctc_origin 47.405411 loss_ctc0 73.946083 history loss 44.432990 rank 0
2022-08-22 14:24:29,336 DEBUG CV Batch 13/800 loss 40.961990 loss_att 32.566517 loss_ctc 60.551430 loss_ctc_origin 50.864716 loss_ctc0 83.153763 history loss 44.483817 rank 0
2022-08-22 14:24:40,091 INFO Epoch 13 CV info cv_loss 44.71902519924206
2022-08-22 14:24:40,091 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/13.pt
2022-08-22 14:24:40,553 INFO Epoch 14 TRAIN info lr 0.0015926399999999998
2022-08-22 14:24:40,557 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 14:25:08,122 DEBUG TRAIN Batch 14/0 loss 37.670506 loss_att 31.522747 loss_ctc 52.015274 loss_ctc_origin 48.030266 loss_ctc0 61.313622 lr 0.00159272 rank 0
2022-08-22 14:25:37,694 WARNING NaN or Inf found in input tensor.
2022-08-22 14:25:37,741 DEBUG TRAIN Batch 14/100 loss nan loss_att 34.788307 loss_ctc nan loss_ctc_origin 58.734798 loss_ctc0 nan lr 0.00159472 rank 0
2022-08-22 14:26:06,421 DEBUG TRAIN Batch 14/200 loss 42.452866 loss_att 32.383316 loss_ctc 65.948471 loss_ctc_origin 58.659767 loss_ctc0 82.955452 lr 0.00159672 rank 0
2022-08-22 14:26:35,495 DEBUG TRAIN Batch 14/300 loss 52.869446 loss_att 39.166565 loss_ctc 84.842834 loss_ctc_origin 79.185852 loss_ctc0 98.042450 lr 0.00159872 rank 0
2022-08-22 14:27:04,964 DEBUG TRAIN Batch 14/400 loss 58.545994 loss_att 43.723721 loss_ctc 93.131294 loss_ctc_origin 84.453346 loss_ctc0 113.379845 lr 0.00160072 rank 0
2022-08-22 14:27:35,200 DEBUG TRAIN Batch 14/500 loss 34.131767 loss_att 28.110258 loss_ctc 48.181950 loss_ctc_origin 46.907150 loss_ctc0 51.156487 lr 0.00160272 rank 0
2022-08-22 14:28:04,281 DEBUG TRAIN Batch 14/600 loss 42.633816 loss_att 34.179115 loss_ctc 62.361450 loss_ctc_origin 58.032753 loss_ctc0 72.461746 lr 0.00160472 rank 0
2022-08-22 14:28:32,833 DEBUG TRAIN Batch 14/700 loss 48.966442 loss_att 37.756462 loss_ctc 75.123062 loss_ctc_origin 66.471161 loss_ctc0 95.310829 lr 0.00160672 rank 0
2022-08-22 14:29:01,243 DEBUG TRAIN Batch 14/800 loss 48.311516 loss_att 36.436798 loss_ctc 76.019196 loss_ctc_origin 69.442833 loss_ctc0 91.364029 lr 0.00160872 rank 0
2022-08-22 14:29:31,591 DEBUG TRAIN Batch 14/900 loss 59.465847 loss_att 46.209957 loss_ctc 90.396255 loss_ctc_origin 82.597183 loss_ctc0 108.594086 lr 0.00161072 rank 0
2022-08-22 14:30:02,132 DEBUG TRAIN Batch 14/1000 loss 34.554844 loss_att 29.381969 loss_ctc 46.624886 loss_ctc_origin 42.325882 loss_ctc0 56.655891 lr 0.00161272 rank 0
2022-08-22 14:30:30,479 DEBUG TRAIN Batch 14/1100 loss 36.855911 loss_att 26.842304 loss_ctc 60.221001 loss_ctc_origin 49.575218 loss_ctc0 85.061157 lr 0.00161472 rank 0
2022-08-22 14:30:59,055 DEBUG TRAIN Batch 14/1200 loss 50.987518 loss_att 39.726269 loss_ctc 77.263771 loss_ctc_origin 74.234741 loss_ctc0 84.331512 lr 0.00161672 rank 0
2022-08-22 14:31:28,932 DEBUG TRAIN Batch 14/1300 loss 50.212746 loss_att 38.169071 loss_ctc 78.314651 loss_ctc_origin 73.807961 loss_ctc0 88.830261 lr 0.00161872 rank 0
2022-08-22 14:31:58,496 DEBUG TRAIN Batch 14/1400 loss 61.221115 loss_att 47.602959 loss_ctc 92.996811 loss_ctc_origin 87.344955 loss_ctc0 106.184479 lr 0.00162072 rank 0
2022-08-22 14:32:36,485 DEBUG TRAIN Batch 14/1500 loss 34.654144 loss_att 26.919422 loss_ctc 52.701820 loss_ctc_origin 47.134380 loss_ctc0 65.692520 lr 0.00162272 rank 0
2022-08-22 14:33:05,316 DEBUG TRAIN Batch 14/1600 loss 58.239990 loss_att 39.489525 loss_ctc 101.991074 loss_ctc_origin 68.189941 loss_ctc0 180.860367 lr 0.00162472 rank 0
2022-08-22 14:33:35,305 DEBUG TRAIN Batch 14/1700 loss 42.911720 loss_att 33.751953 loss_ctc 64.284500 loss_ctc_origin 61.008442 loss_ctc0 71.928635 lr 0.00162672 rank 0
2022-08-22 14:34:04,336 DEBUG TRAIN Batch 14/1800 loss 60.050064 loss_att 46.252640 loss_ctc 92.244064 loss_ctc_origin 87.974213 loss_ctc0 102.207062 lr 0.00162872 rank 0
2022-08-22 14:34:34,510 DEBUG TRAIN Batch 14/1900 loss 63.636467 loss_att 50.250298 loss_ctc 94.870850 loss_ctc_origin 90.122696 loss_ctc0 105.949860 lr 0.00163072 rank 0
2022-08-22 14:35:04,304 DEBUG TRAIN Batch 14/2000 loss 43.514244 loss_att 34.982204 loss_ctc 63.422340 loss_ctc_origin 54.140785 loss_ctc0 85.079300 lr 0.00163272 rank 0
2022-08-22 14:35:33,178 DEBUG TRAIN Batch 14/2100 loss 43.161362 loss_att 33.174725 loss_ctc 66.463516 loss_ctc_origin 59.632854 loss_ctc0 82.401733 lr 0.00163472 rank 0
2022-08-22 14:36:02,223 DEBUG TRAIN Batch 14/2200 loss 46.188156 loss_att 36.350719 loss_ctc 69.142166 loss_ctc_origin 66.168694 loss_ctc0 76.080276 lr 0.00163672 rank 0
2022-08-22 14:36:30,993 DEBUG TRAIN Batch 14/2300 loss 49.184082 loss_att 37.837898 loss_ctc 75.658516 loss_ctc_origin 69.949097 loss_ctc0 88.980492 lr 0.00163872 rank 0
2022-08-22 14:36:55,795 WARNING NaN or Inf found in input tensor.
2022-08-22 14:37:00,138 DEBUG TRAIN Batch 14/2400 loss 57.829102 loss_att 45.064831 loss_ctc 87.612389 loss_ctc_origin 81.629707 loss_ctc0 101.571976 lr 0.00164072 rank 0
2022-08-22 14:37:30,284 DEBUG TRAIN Batch 14/2500 loss 32.489399 loss_att 28.294960 loss_ctc 42.276428 loss_ctc_origin 38.544155 loss_ctc0 50.985073 lr 0.00164272 rank 0
2022-08-22 14:37:59,315 DEBUG TRAIN Batch 14/2600 loss 44.149433 loss_att 32.823860 loss_ctc 70.575768 loss_ctc_origin 61.518448 loss_ctc0 91.709511 lr 0.00164472 rank 0
2022-08-22 14:38:26,747 WARNING NaN or Inf found in input tensor.
2022-08-22 14:38:28,280 DEBUG TRAIN Batch 14/2700 loss 47.702438 loss_att 37.519958 loss_ctc 71.461555 loss_ctc_origin 68.361580 loss_ctc0 78.694839 lr 0.00164672 rank 0
2022-08-22 14:38:55,885 DEBUG TRAIN Batch 14/2800 loss 50.312916 loss_att 39.398132 loss_ctc 75.780746 loss_ctc_origin 71.031517 loss_ctc0 86.862274 lr 0.00164872 rank 0
2022-08-22 14:39:26,766 DEBUG TRAIN Batch 14/2900 loss 56.189323 loss_att 43.562225 loss_ctc 85.652542 loss_ctc_origin 79.046524 loss_ctc0 101.066582 lr 0.00165072 rank 0
2022-08-22 14:40:02,570 DEBUG TRAIN Batch 14/3000 loss 42.600357 loss_att 31.387230 loss_ctc 68.764313 loss_ctc_origin 50.835876 loss_ctc0 110.597336 lr 0.00165272 rank 0
2022-08-22 14:40:32,487 DEBUG TRAIN Batch 14/3100 loss 37.748436 loss_att 29.202353 loss_ctc 57.689297 loss_ctc_origin 46.631248 loss_ctc0 83.491409 lr 0.00165472 rank 0
2022-08-22 14:41:01,638 DEBUG TRAIN Batch 14/3200 loss 43.405441 loss_att 32.827564 loss_ctc 68.087158 loss_ctc_origin 62.738556 loss_ctc0 80.567230 lr 0.00165672 rank 0
2022-08-22 14:41:07,210 WARNING NaN or Inf found in input tensor.
2022-08-22 14:41:30,680 DEBUG TRAIN Batch 14/3300 loss 44.574028 loss_att 33.904469 loss_ctc 69.469666 loss_ctc_origin 62.943237 loss_ctc0 84.698013 lr 0.00165872 rank 0
2022-08-22 14:41:54,990 WARNING NaN or Inf found in input tensor.
2022-08-22 14:41:59,346 DEBUG TRAIN Batch 14/3400 loss 62.274696 loss_att 50.076363 loss_ctc 90.737473 loss_ctc_origin 84.834869 loss_ctc0 104.510216 lr 0.00166072 rank 0
2022-08-22 14:42:28,448 DEBUG TRAIN Batch 14/3500 loss 38.364632 loss_att 29.692234 loss_ctc 58.600220 loss_ctc_origin 45.156914 loss_ctc0 89.967941 lr 0.00166272 rank 0
2022-08-22 14:42:58,117 DEBUG TRAIN Batch 14/3600 loss 50.441200 loss_att 34.478073 loss_ctc 87.688492 loss_ctc_origin 58.674118 loss_ctc0 155.388702 lr 0.00166472 rank 0
2022-08-22 14:43:27,406 DEBUG TRAIN Batch 14/3700 loss 46.921482 loss_att 37.863503 loss_ctc 68.056763 loss_ctc_origin 64.762466 loss_ctc0 75.743454 lr 0.00166672 rank 0
2022-08-22 14:43:56,799 DEBUG TRAIN Batch 14/3800 loss 45.671822 loss_att 35.379745 loss_ctc 69.686661 loss_ctc_origin 63.845776 loss_ctc0 83.315392 lr 0.00166872 rank 0
2022-08-22 14:44:26,737 DEBUG TRAIN Batch 14/3900 loss 58.494812 loss_att 44.660534 loss_ctc 90.774796 loss_ctc_origin 83.159698 loss_ctc0 108.543365 lr 0.00167072 rank 0
2022-08-22 14:44:56,271 DEBUG TRAIN Batch 14/4000 loss 41.594635 loss_att 27.542309 loss_ctc 74.383392 loss_ctc_origin 46.372948 loss_ctc0 139.741104 lr 0.00167272 rank 0
2022-08-22 14:45:19,384 WARNING NaN or Inf found in input tensor.
2022-08-22 14:45:26,395 DEBUG TRAIN Batch 14/4100 loss 59.430740 loss_att 36.729145 loss_ctc 112.401131 loss_ctc_origin 59.127350 loss_ctc0 236.706604 lr 0.00167472 rank 0
2022-08-22 14:45:55,619 DEBUG TRAIN Batch 14/4200 loss 43.951641 loss_att 34.389614 loss_ctc 66.263039 loss_ctc_origin 62.083885 loss_ctc0 76.014397 lr 0.00167672 rank 0
2022-08-22 14:46:26,636 DEBUG TRAIN Batch 14/4300 loss 49.656754 loss_att 39.078594 loss_ctc 74.339134 loss_ctc_origin 68.772522 loss_ctc0 87.327896 lr 0.00167872 rank 0
2022-08-22 14:46:50,687 WARNING NaN or Inf found in input tensor.
2022-08-22 14:46:54,970 DEBUG TRAIN Batch 14/4400 loss 61.329201 loss_att 48.481270 loss_ctc 91.307709 loss_ctc_origin 84.457611 loss_ctc0 107.291260 lr 0.00168072 rank 0
2022-08-22 14:47:31,270 DEBUG TRAIN Batch 14/4500 loss 39.203342 loss_att 29.337017 loss_ctc 62.224766 loss_ctc_origin 50.894714 loss_ctc0 88.661545 lr 0.00168272 rank 0
2022-08-22 14:48:00,910 DEBUG TRAIN Batch 14/4600 loss 39.598869 loss_att 30.265879 loss_ctc 61.375839 loss_ctc_origin 53.727882 loss_ctc0 79.221069 lr 0.00168472 rank 0
2022-08-22 14:48:29,982 DEBUG TRAIN Batch 14/4700 loss 41.829651 loss_att 32.968327 loss_ctc 62.506073 loss_ctc_origin 57.709370 loss_ctc0 73.698380 lr 0.00168672 rank 0
2022-08-22 14:48:35,557 WARNING NaN or Inf found in input tensor.
2022-08-22 14:48:59,417 DEBUG TRAIN Batch 14/4800 loss 50.484207 loss_att 39.606747 loss_ctc 75.864944 loss_ctc_origin 70.420761 loss_ctc0 88.568047 lr 0.00168872 rank 0
2022-08-22 14:49:29,252 DEBUG TRAIN Batch 14/4900 loss 59.434532 loss_att 43.701042 loss_ctc 96.146011 loss_ctc_origin 89.611450 loss_ctc0 111.393295 lr 0.00169072 rank 0
2022-08-22 14:49:58,688 DEBUG TRAIN Batch 14/5000 loss 46.030502 loss_att 32.934990 loss_ctc 76.586700 loss_ctc_origin 53.172501 loss_ctc0 131.219818 lr 0.00169272 rank 0
2022-08-22 14:50:27,146 DEBUG TRAIN Batch 14/5100 loss 40.988762 loss_att 32.000275 loss_ctc 61.961899 loss_ctc_origin 56.160965 loss_ctc0 75.497406 lr 0.00169472 rank 0
2022-08-22 14:50:56,109 DEBUG TRAIN Batch 14/5200 loss 45.463951 loss_att 34.911789 loss_ctc 70.085670 loss_ctc_origin 66.529808 loss_ctc0 78.382675 lr 0.00169672 rank 0
2022-08-22 14:51:25,202 DEBUG TRAIN Batch 14/5300 loss 49.754562 loss_att 38.932209 loss_ctc 75.006721 loss_ctc_origin 68.283302 loss_ctc0 90.694695 lr 0.00169872 rank 0
2022-08-22 14:51:54,856 DEBUG TRAIN Batch 14/5400 loss 61.383652 loss_att 48.081966 loss_ctc 92.420921 loss_ctc_origin 80.652405 loss_ctc0 119.880783 lr 0.00170072 rank 0
2022-08-22 14:52:25,473 DEBUG TRAIN Batch 14/5500 loss 35.017715 loss_att 27.045160 loss_ctc 53.620335 loss_ctc_origin 50.351677 loss_ctc0 61.247200 lr 0.00170272 rank 0
2022-08-22 14:52:55,252 DEBUG TRAIN Batch 14/5600 loss 48.913525 loss_att 36.549023 loss_ctc 77.764023 loss_ctc_origin 57.090736 loss_ctc0 126.001701 lr 0.00170472 rank 0
2022-08-22 14:53:18,107 DEBUG CV Batch 14/0 loss 34.310936 loss_att 26.141312 loss_ctc 53.373383 loss_ctc_origin 47.901657 loss_ctc0 66.140747 history loss 32.292646 rank 0
2022-08-22 14:53:29,345 DEBUG CV Batch 14/100 loss 46.765644 loss_att 36.307880 loss_ctc 71.167091 loss_ctc_origin 62.908798 loss_ctc0 90.436440 history loss 50.715253 rank 0
2022-08-22 14:53:39,559 DEBUG CV Batch 14/200 loss 45.684006 loss_att 37.121521 loss_ctc 65.663132 loss_ctc_origin 60.276199 loss_ctc0 78.232635 history loss 52.573663 rank 0
2022-08-22 14:53:50,013 DEBUG CV Batch 14/300 loss 43.757942 loss_att 34.666542 loss_ctc 64.971214 loss_ctc_origin 56.361935 loss_ctc0 85.059525 history loss 51.589162 rank 0
2022-08-22 14:54:01,347 DEBUG CV Batch 14/400 loss 64.902626 loss_att 53.499893 loss_ctc 91.509003 loss_ctc_origin 82.809631 loss_ctc0 111.807556 history loss 49.587782 rank 0
2022-08-22 14:54:13,300 DEBUG CV Batch 14/500 loss 35.810696 loss_att 28.257839 loss_ctc 53.434029 loss_ctc_origin 50.007317 loss_ctc0 61.429703 history loss 49.080773 rank 0
2022-08-22 14:54:24,314 DEBUG CV Batch 14/600 loss 50.963326 loss_att 39.269726 loss_ctc 78.248398 loss_ctc_origin 69.606415 loss_ctc0 98.413025 history loss 48.994653 rank 0
2022-08-22 14:54:34,252 DEBUG CV Batch 14/700 loss 38.389046 loss_att 30.482298 loss_ctc 56.838131 loss_ctc_origin 48.870678 loss_ctc0 75.428856 history loss 48.584473 rank 0
2022-08-22 14:54:44,729 DEBUG CV Batch 14/800 loss 40.682297 loss_att 31.950396 loss_ctc 61.056732 loss_ctc_origin 51.006329 loss_ctc0 84.507675 history loss 48.576387 rank 0
2022-08-22 14:54:55,525 INFO Epoch 14 CV info cv_loss 48.61755664618023
2022-08-22 14:54:55,525 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/14.pt
2022-08-22 14:54:56,046 INFO Epoch 15 TRAIN info lr 0.0017063999999999998
2022-08-22 14:54:56,050 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 14:55:23,967 DEBUG TRAIN Batch 15/0 loss 44.901917 loss_att 34.546551 loss_ctc 69.064445 loss_ctc_origin 56.966545 loss_ctc0 97.292877 lr 0.00170648 rank 0
2022-08-22 14:55:52,690 DEBUG TRAIN Batch 15/100 loss 50.079704 loss_att 37.473061 loss_ctc 79.495209 loss_ctc_origin 62.413620 loss_ctc0 119.352264 lr 0.00170848 rank 0
2022-08-22 14:56:21,683 DEBUG TRAIN Batch 15/200 loss 43.804787 loss_att 34.366570 loss_ctc 65.827286 loss_ctc_origin 61.145103 loss_ctc0 76.752380 lr 0.00171048 rank 0
2022-08-22 14:56:52,534 DEBUG TRAIN Batch 15/300 loss 45.844009 loss_att 35.951221 loss_ctc 68.927185 loss_ctc_origin 62.988956 loss_ctc0 82.783051 lr 0.00171248 rank 0
2022-08-22 14:57:21,929 DEBUG TRAIN Batch 15/400 loss 53.962120 loss_att 41.008633 loss_ctc 84.186928 loss_ctc_origin 74.966408 loss_ctc0 105.701469 lr 0.00171448 rank 0
2022-08-22 14:57:52,223 DEBUG TRAIN Batch 15/500 loss 38.202339 loss_att 31.560307 loss_ctc 53.700413 loss_ctc_origin 52.081352 loss_ctc0 57.478214 lr 0.00171648 rank 0
2022-08-22 14:58:20,489 DEBUG TRAIN Batch 15/600 loss 40.849174 loss_att 33.065018 loss_ctc 59.012203 loss_ctc_origin 55.339634 loss_ctc0 67.581528 lr 0.00171848 rank 0
2022-08-22 14:58:50,431 DEBUG TRAIN Batch 15/700 loss 42.543682 loss_att 34.486595 loss_ctc 61.343552 loss_ctc_origin 56.910278 loss_ctc0 71.687859 lr 0.00172048 rank 0
2022-08-22 14:59:20,064 DEBUG TRAIN Batch 15/800 loss 55.338989 loss_att 41.409042 loss_ctc 87.842194 loss_ctc_origin 81.726761 loss_ctc0 102.111534 lr 0.00172248 rank 0
2022-08-22 14:59:49,284 DEBUG TRAIN Batch 15/900 loss 62.656738 loss_att 49.458176 loss_ctc 93.453384 loss_ctc_origin 86.408386 loss_ctc0 109.891716 lr 0.00172448 rank 0
2022-08-22 15:00:18,706 DEBUG TRAIN Batch 15/1000 loss 38.327560 loss_att 31.144535 loss_ctc 55.087944 loss_ctc_origin 48.749596 loss_ctc0 69.877411 lr 0.00172648 rank 0
2022-08-22 15:00:47,357 DEBUG TRAIN Batch 15/1100 loss 41.221550 loss_att 33.806774 loss_ctc 58.522686 loss_ctc_origin 52.183540 loss_ctc0 73.314026 lr 0.00172848 rank 0
2022-08-22 15:01:17,470 DEBUG TRAIN Batch 15/1200 loss 39.833412 loss_att 31.140324 loss_ctc 60.117294 loss_ctc_origin 55.103378 loss_ctc0 71.816437 lr 0.00173048 rank 0
2022-08-22 15:01:48,291 DEBUG TRAIN Batch 15/1300 loss 48.058113 loss_att 35.177868 loss_ctc 78.112022 loss_ctc_origin 71.694107 loss_ctc0 93.087151 lr 0.00173248 rank 0
2022-08-22 15:02:17,695 DEBUG TRAIN Batch 15/1400 loss 54.045296 loss_att 40.417240 loss_ctc 85.844086 loss_ctc_origin 77.551758 loss_ctc0 105.192841 lr 0.00173448 rank 0
2022-08-22 15:02:53,154 DEBUG TRAIN Batch 15/1500 loss 37.911942 loss_att 32.345833 loss_ctc 50.899532 loss_ctc_origin 48.708122 loss_ctc0 56.012825 lr 0.00173648 rank 0
2022-08-22 15:03:23,312 DEBUG TRAIN Batch 15/1600 loss 43.521549 loss_att 33.759308 loss_ctc 66.300110 loss_ctc_origin 55.064129 loss_ctc0 92.517395 lr 0.00173848 rank 0
2022-08-22 15:03:52,305 DEBUG TRAIN Batch 15/1700 loss 51.041355 loss_att 41.044025 loss_ctc 74.368454 loss_ctc_origin 69.932083 loss_ctc0 84.719971 lr 0.00174048 rank 0
2022-08-22 15:04:21,962 DEBUG TRAIN Batch 15/1800 loss 51.596977 loss_att 40.825821 loss_ctc 76.729675 loss_ctc_origin 71.277725 loss_ctc0 89.450905 lr 0.00174248 rank 0
2022-08-22 15:04:51,617 DEBUG TRAIN Batch 15/1900 loss 61.958626 loss_att 48.476463 loss_ctc 93.416992 loss_ctc_origin 87.115479 loss_ctc0 108.120529 lr 0.00174448 rank 0
2022-08-22 15:05:21,938 DEBUG TRAIN Batch 15/2000 loss 35.007198 loss_att 27.273674 loss_ctc 53.052086 loss_ctc_origin 41.562927 loss_ctc0 79.860123 lr 0.00174648 rank 0
2022-08-22 15:05:50,790 DEBUG TRAIN Batch 15/2100 loss 51.101620 loss_att 40.118736 loss_ctc 76.728348 loss_ctc_origin 64.421471 loss_ctc0 105.444397 lr 0.00174848 rank 0
2022-08-22 15:06:19,570 DEBUG TRAIN Batch 15/2200 loss 47.713898 loss_att 38.011116 loss_ctc 70.353729 loss_ctc_origin 67.170944 loss_ctc0 77.780228 lr 0.00175048 rank 0
2022-08-22 15:06:25,198 WARNING NaN or Inf found in input tensor.
2022-08-22 15:06:48,179 DEBUG TRAIN Batch 15/2300 loss 48.440773 loss_att 37.680580 loss_ctc 73.547890 loss_ctc_origin 68.032135 loss_ctc0 86.417992 lr 0.00175248 rank 0
2022-08-22 15:07:17,272 DEBUG TRAIN Batch 15/2400 loss 57.539780 loss_att 45.196251 loss_ctc 86.341347 loss_ctc_origin 78.300858 loss_ctc0 105.102478 lr 0.00175448 rank 0
2022-08-22 15:07:46,171 DEBUG TRAIN Batch 15/2500 loss 40.093697 loss_att 29.687716 loss_ctc 64.374313 loss_ctc_origin 48.058628 loss_ctc0 102.444229 lr 0.00175648 rank 0
2022-08-22 15:08:13,935 DEBUG TRAIN Batch 15/2600 loss 51.123123 loss_att 34.052017 loss_ctc 90.955704 loss_ctc_origin 55.491341 loss_ctc0 173.705872 lr 0.00175848 rank 0
2022-08-22 15:08:44,346 DEBUG TRAIN Batch 15/2700 loss 47.414352 loss_att 37.233757 loss_ctc 71.169083 loss_ctc_origin 68.206421 loss_ctc0 78.081955 lr 0.00176048 rank 0
2022-08-22 15:09:13,699 DEBUG TRAIN Batch 15/2800 loss 50.648148 loss_att 38.764145 loss_ctc 78.377487 loss_ctc_origin 72.453949 loss_ctc0 92.199074 lr 0.00176248 rank 0
2022-08-22 15:09:42,658 DEBUG TRAIN Batch 15/2900 loss 55.629570 loss_att 42.205414 loss_ctc 86.952606 loss_ctc_origin 81.462021 loss_ctc0 99.763954 lr 0.00176448 rank 0
2022-08-22 15:10:19,712 DEBUG TRAIN Batch 15/3000 loss 47.163208 loss_att 35.140694 loss_ctc 75.215744 loss_ctc_origin 57.675957 loss_ctc0 116.141914 lr 0.00176648 rank 0
2022-08-22 15:10:49,052 DEBUG TRAIN Batch 15/3100 loss 57.457298 loss_att 36.898865 loss_ctc 105.426979 loss_ctc_origin 63.637054 loss_ctc0 202.936798 lr 0.00176848 rank 0
2022-08-22 15:11:18,529 DEBUG TRAIN Batch 15/3200 loss 42.097672 loss_att 32.586021 loss_ctc 64.291519 loss_ctc_origin 60.524796 loss_ctc0 73.080528 lr 0.00177048 rank 0
2022-08-22 15:11:47,665 DEBUG TRAIN Batch 15/3300 loss 47.167576 loss_att 35.060951 loss_ctc 75.416367 loss_ctc_origin 70.940216 loss_ctc0 85.860718 lr 0.00177248 rank 0
2022-08-22 15:12:17,376 DEBUG TRAIN Batch 15/3400 loss 55.879074 loss_att 43.540592 loss_ctc 84.668869 loss_ctc_origin 76.817337 loss_ctc0 102.989090 lr 0.00177448 rank 0
2022-08-22 15:12:46,551 DEBUG TRAIN Batch 15/3500 loss 32.807091 loss_att 25.602743 loss_ctc 49.617233 loss_ctc_origin 43.246441 loss_ctc0 64.482422 lr 0.00177648 rank 0
2022-08-22 15:13:15,309 DEBUG TRAIN Batch 15/3600 loss 41.718830 loss_att 31.161465 loss_ctc 66.352684 loss_ctc_origin 57.174294 loss_ctc0 87.768936 lr 0.00177848 rank 0
2022-08-22 15:13:44,348 DEBUG TRAIN Batch 15/3700 loss 44.916977 loss_att 34.533127 loss_ctc 69.145958 loss_ctc_origin 63.984955 loss_ctc0 81.188309 lr 0.00178048 rank 0
2022-08-22 15:14:13,228 DEBUG TRAIN Batch 15/3800 loss 47.578621 loss_att 36.957085 loss_ctc 72.362198 loss_ctc_origin 68.695786 loss_ctc0 80.917160 lr 0.00178248 rank 0
2022-08-22 15:14:43,850 DEBUG TRAIN Batch 15/3900 loss 55.772606 loss_att 41.942532 loss_ctc 88.042786 loss_ctc_origin 79.427071 loss_ctc0 108.146118 lr 0.00178448 rank 0
2022-08-22 15:15:14,122 DEBUG TRAIN Batch 15/4000 loss 51.964172 loss_att 38.754105 loss_ctc 82.787666 loss_ctc_origin 61.635323 loss_ctc0 132.143127 lr 0.00178648 rank 0
2022-08-22 15:15:42,715 DEBUG TRAIN Batch 15/4100 loss 54.903671 loss_att 44.174202 loss_ctc 79.939095 loss_ctc_origin 68.639282 loss_ctc0 106.305313 lr 0.00178848 rank 0
2022-08-22 15:16:04,756 WARNING NaN or Inf found in input tensor.
2022-08-22 15:16:13,749 DEBUG TRAIN Batch 15/4200 loss 48.201172 loss_att 37.629677 loss_ctc 72.867996 loss_ctc_origin 68.283432 loss_ctc0 83.565315 lr 0.00179048 rank 0
2022-08-22 15:16:42,432 DEBUG TRAIN Batch 15/4300 loss 46.368607 loss_att 34.560883 loss_ctc 73.919952 loss_ctc_origin 67.889633 loss_ctc0 87.990685 lr 0.00179248 rank 0
2022-08-22 15:17:12,961 DEBUG TRAIN Batch 15/4400 loss 62.612801 loss_att 48.875240 loss_ctc 94.667107 loss_ctc_origin 89.901741 loss_ctc0 105.786285 lr 0.00179448 rank 0
2022-08-22 15:17:47,576 DEBUG TRAIN Batch 15/4500 loss 33.820694 loss_att 27.345516 loss_ctc 48.929447 loss_ctc_origin 44.040951 loss_ctc0 60.335941 lr 0.00179648 rank 0
2022-08-22 15:18:17,064 WARNING NaN or Inf found in input tensor.
2022-08-22 15:18:17,112 DEBUG TRAIN Batch 15/4600 loss nan loss_att 31.430994 loss_ctc nan loss_ctc_origin 55.408772 loss_ctc0 nan lr 0.00179848 rank 0
2022-08-22 15:18:30,960 WARNING NaN or Inf found in input tensor.
2022-08-22 15:18:46,513 DEBUG TRAIN Batch 15/4700 loss 42.920784 loss_att 31.319571 loss_ctc 69.990288 loss_ctc_origin 64.095009 loss_ctc0 83.745941 lr 0.00180048 rank 0
2022-08-22 15:19:16,640 DEBUG TRAIN Batch 15/4800 loss 48.937836 loss_att 35.302891 loss_ctc 80.752701 loss_ctc_origin 73.242188 loss_ctc0 98.277237 lr 0.00180248 rank 0
2022-08-22 15:19:20,355 WARNING NaN or Inf found in input tensor.
2022-08-22 15:19:46,092 DEBUG TRAIN Batch 15/4900 loss 75.559631 loss_att 59.701004 loss_ctc 112.563095 loss_ctc_origin 108.802330 loss_ctc0 121.338211 lr 0.00180448 rank 0
2022-08-22 15:20:16,246 DEBUG TRAIN Batch 15/5000 loss 43.024849 loss_att 34.199371 loss_ctc 63.617634 loss_ctc_origin 58.651337 loss_ctc0 75.205658 lr 0.00180648 rank 0
2022-08-22 15:20:24,287 WARNING NaN or Inf found in input tensor.
2022-08-22 15:20:45,314 DEBUG TRAIN Batch 15/5100 loss 47.587318 loss_att 38.173958 loss_ctc 69.551819 loss_ctc_origin 64.125526 loss_ctc0 82.213181 lr 0.00180848 rank 0
2022-08-22 15:21:15,096 DEBUG TRAIN Batch 15/5200 loss 46.253048 loss_att 35.224007 loss_ctc 71.987473 loss_ctc_origin 67.656036 loss_ctc0 82.094162 lr 0.00181048 rank 0
2022-08-22 15:21:45,215 DEBUG TRAIN Batch 15/5300 loss 54.894592 loss_att 41.330547 loss_ctc 86.544022 loss_ctc_origin 82.407059 loss_ctc0 96.196945 lr 0.00181248 rank 0
2022-08-22 15:22:14,755 DEBUG TRAIN Batch 15/5400 loss 71.192123 loss_att 54.489212 loss_ctc 110.165581 loss_ctc_origin 105.740265 loss_ctc0 120.491333 lr 0.00181448 rank 0
2022-08-22 15:22:43,833 DEBUG TRAIN Batch 15/5500 loss 36.575214 loss_att 29.523026 loss_ctc 53.030319 loss_ctc_origin 48.306744 loss_ctc0 64.051994 lr 0.00181648 rank 0
2022-08-22 15:23:14,422 DEBUG TRAIN Batch 15/5600 loss 53.224113 loss_att 39.400528 loss_ctc 85.479141 loss_ctc_origin 68.126099 loss_ctc0 125.969589 lr 0.00181848 rank 0
2022-08-22 15:23:38,550 DEBUG CV Batch 15/0 loss 31.045017 loss_att 25.873196 loss_ctc 43.112602 loss_ctc_origin 41.640877 loss_ctc0 46.546623 history loss 29.218840 rank 0
2022-08-22 15:23:49,736 DEBUG CV Batch 15/100 loss 43.668243 loss_att 35.767612 loss_ctc 62.103046 loss_ctc_origin 59.381241 loss_ctc0 68.453926 history loss 55.645122 rank 0
2022-08-22 15:24:00,128 DEBUG CV Batch 15/200 loss 52.783390 loss_att 43.748459 loss_ctc 73.864899 loss_ctc_origin 69.859261 loss_ctc0 83.211380 history loss 56.241963 rank 0
2022-08-22 15:24:10,525 DEBUG CV Batch 15/300 loss 55.969765 loss_att 45.140835 loss_ctc 81.237259 loss_ctc_origin 74.097092 loss_ctc0 97.897644 history loss 56.035473 rank 0
2022-08-22 15:24:21,946 DEBUG CV Batch 15/400 loss 76.198730 loss_att 62.645531 loss_ctc 107.822845 loss_ctc_origin 100.654846 loss_ctc0 124.548187 history loss 55.037959 rank 0
2022-08-22 15:24:33,373 DEBUG CV Batch 15/500 loss 36.638397 loss_att 30.828489 loss_ctc 50.194839 loss_ctc_origin 48.843418 loss_ctc0 53.348148 history loss 55.156083 rank 0
2022-08-22 15:24:43,554 DEBUG CV Batch 15/600 loss 47.028854 loss_att 38.243408 loss_ctc 67.528229 loss_ctc_origin 65.787605 loss_ctc0 71.589668 history loss 55.317487 rank 0
2022-08-22 15:24:54,180 DEBUG CV Batch 15/700 loss 50.316925 loss_att 41.323341 loss_ctc 71.301956 loss_ctc_origin 65.561241 loss_ctc0 84.696960 history loss 55.150016 rank 0
2022-08-22 15:25:05,082 DEBUG CV Batch 15/800 loss 50.974461 loss_att 41.249702 loss_ctc 73.665558 loss_ctc_origin 65.418671 loss_ctc0 92.908287 history loss 55.388985 rank 0
2022-08-22 15:25:15,811 INFO Epoch 15 CV info cv_loss 55.6383537291948
2022-08-22 15:25:15,812 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/15.pt
2022-08-22 15:25:16,275 INFO Epoch 16 TRAIN info lr 0.00182016
2022-08-22 15:25:16,279 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 15:25:44,452 WARNING NaN or Inf found in input tensor.
2022-08-22 15:25:44,533 DEBUG TRAIN Batch 16/0 loss inf loss_att 36.864624 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00182024 rank 0
2022-08-22 15:26:13,832 DEBUG TRAIN Batch 16/100 loss 44.803253 loss_att 34.938660 loss_ctc 67.820633 loss_ctc_origin 64.063873 loss_ctc0 76.586403 lr 0.00182224 rank 0
2022-08-22 15:26:44,178 DEBUG TRAIN Batch 16/200 loss 54.138447 loss_att 42.531105 loss_ctc 81.222244 loss_ctc_origin 80.034424 loss_ctc0 83.993805 lr 0.00182424 rank 0
2022-08-22 15:27:13,261 DEBUG TRAIN Batch 16/300 loss 61.965424 loss_att 47.585613 loss_ctc 95.518318 loss_ctc_origin 92.755646 loss_ctc0 101.964569 lr 0.00182624 rank 0
2022-08-22 15:27:42,852 DEBUG TRAIN Batch 16/400 loss 66.600891 loss_att 49.012936 loss_ctc 107.639435 loss_ctc_origin 104.421883 loss_ctc0 115.147079 lr 0.00182824 rank 0
2022-08-22 15:28:13,099 DEBUG TRAIN Batch 16/500 loss 37.329803 loss_att 29.291473 loss_ctc 56.085911 loss_ctc_origin 50.188789 loss_ctc0 69.845856 lr 0.00183024 rank 0
2022-08-22 15:28:21,596 WARNING NaN or Inf found in input tensor.
2022-08-22 15:28:42,434 DEBUG TRAIN Batch 16/600 loss 50.275658 loss_att 39.673702 loss_ctc 75.013550 loss_ctc_origin 70.854805 loss_ctc0 84.717285 lr 0.00183224 rank 0
2022-08-22 15:29:10,746 DEBUG TRAIN Batch 16/700 loss 47.546890 loss_att 38.985840 loss_ctc 67.522682 loss_ctc_origin 64.738007 loss_ctc0 74.020248 lr 0.00183424 rank 0
2022-08-22 15:29:40,460 DEBUG TRAIN Batch 16/800 loss 54.534885 loss_att 40.452095 loss_ctc 87.394730 loss_ctc_origin 83.972061 loss_ctc0 95.380943 lr 0.00183624 rank 0
2022-08-22 15:30:10,095 DEBUG TRAIN Batch 16/900 loss 66.555496 loss_att 50.777264 loss_ctc 103.371384 loss_ctc_origin 99.508263 loss_ctc0 112.385323 lr 0.00183824 rank 0
2022-08-22 15:30:40,089 DEBUG TRAIN Batch 16/1000 loss 45.730026 loss_att 30.858864 loss_ctc 80.429413 loss_ctc_origin 49.714119 loss_ctc0 152.098419 lr 0.00184024 rank 0
2022-08-22 15:31:10,289 DEBUG TRAIN Batch 16/1100 loss 52.459213 loss_att 36.301067 loss_ctc 90.161552 loss_ctc_origin 63.777763 loss_ctc0 151.723724 lr 0.00184224 rank 0
2022-08-22 15:31:38,400 DEBUG TRAIN Batch 16/1200 loss 48.519356 loss_att 37.667007 loss_ctc 73.841492 loss_ctc_origin 69.986916 loss_ctc0 82.835487 lr 0.00184424 rank 0
2022-08-22 15:32:09,396 DEBUG TRAIN Batch 16/1300 loss 49.559059 loss_att 37.098450 loss_ctc 78.633820 loss_ctc_origin 72.299133 loss_ctc0 93.414749 lr 0.00184624 rank 0
2022-08-22 15:32:38,742 DEBUG TRAIN Batch 16/1400 loss 67.597664 loss_att 54.588928 loss_ctc 97.951370 loss_ctc_origin 91.529884 loss_ctc0 112.934853 lr 0.00184824 rank 0
2022-08-22 15:33:13,382 DEBUG TRAIN Batch 16/1500 loss 44.417671 loss_att 35.791504 loss_ctc 64.545395 loss_ctc_origin 61.221481 loss_ctc0 72.301193 lr 0.00185024 rank 0
2022-08-22 15:33:43,414 DEBUG TRAIN Batch 16/1600 loss 48.489998 loss_att 39.334843 loss_ctc 69.852020 loss_ctc_origin 64.671822 loss_ctc0 81.939148 lr 0.00185224 rank 0
2022-08-22 15:34:12,526 DEBUG TRAIN Batch 16/1700 loss 41.338406 loss_att 31.576267 loss_ctc 64.116730 loss_ctc_origin 59.224136 loss_ctc0 75.532791 lr 0.00185424 rank 0
2022-08-22 15:34:42,775 DEBUG TRAIN Batch 16/1800 loss 55.515278 loss_att 41.901672 loss_ctc 87.280350 loss_ctc_origin 83.481491 loss_ctc0 96.144363 lr 0.00185624 rank 0
2022-08-22 15:35:12,925 DEBUG TRAIN Batch 16/1900 loss 59.141541 loss_att 44.212761 loss_ctc 93.975357 loss_ctc_origin 87.668777 loss_ctc0 108.690697 lr 0.00185824 rank 0
2022-08-22 15:35:42,791 DEBUG TRAIN Batch 16/2000 loss 39.062500 loss_att 33.024296 loss_ctc 53.151649 loss_ctc_origin 50.507843 loss_ctc0 59.320534 lr 0.00186024 rank 0
2022-08-22 15:36:12,303 DEBUG TRAIN Batch 16/2100 loss 56.100586 loss_att 36.888031 loss_ctc 100.929871 loss_ctc_origin 65.618301 loss_ctc0 183.323517 lr 0.00186224 rank 0
2022-08-22 15:36:42,845 DEBUG TRAIN Batch 16/2200 loss 49.187607 loss_att 38.642090 loss_ctc 73.793800 loss_ctc_origin 67.000198 loss_ctc0 89.645531 lr 0.00186424 rank 0
2022-08-22 15:37:12,263 DEBUG TRAIN Batch 16/2300 loss 58.317265 loss_att 44.050373 loss_ctc 91.606674 loss_ctc_origin 88.282196 loss_ctc0 99.363792 lr 0.00186624 rank 0
2022-08-22 15:37:41,581 DEBUG TRAIN Batch 16/2400 loss 70.427383 loss_att 54.581436 loss_ctc 107.401245 loss_ctc_origin 101.482468 loss_ctc0 121.211731 lr 0.00186824 rank 0
2022-08-22 15:38:11,452 DEBUG TRAIN Batch 16/2500 loss 42.603462 loss_att 34.334618 loss_ctc 61.897430 loss_ctc_origin 56.431618 loss_ctc0 74.650986 lr 0.00187024 rank 0
2022-08-22 15:38:40,493 DEBUG TRAIN Batch 16/2600 loss 44.105042 loss_att 34.884132 loss_ctc 65.620499 loss_ctc_origin 62.669319 loss_ctc0 72.506577 lr 0.00187224 rank 0
2022-08-22 15:39:08,682 WARNING NaN or Inf found in input tensor.
2022-08-22 15:39:10,293 DEBUG TRAIN Batch 16/2700 loss 52.317467 loss_att 42.575905 loss_ctc 75.047775 loss_ctc_origin 72.767693 loss_ctc0 80.367966 lr 0.00187424 rank 0
2022-08-22 15:39:38,004 DEBUG TRAIN Batch 16/2800 loss 58.192337 loss_att 46.167915 loss_ctc 86.249313 loss_ctc_origin 83.463089 loss_ctc0 92.750519 lr 0.00187624 rank 0
2022-08-22 15:40:06,505 DEBUG TRAIN Batch 16/2900 loss 67.160950 loss_att 50.402359 loss_ctc 106.264336 loss_ctc_origin 101.035118 loss_ctc0 118.465851 lr 0.00187824 rank 0
2022-08-22 15:40:41,927 DEBUG TRAIN Batch 16/3000 loss 42.324928 loss_att 32.386810 loss_ctc 65.513878 loss_ctc_origin 57.881866 loss_ctc0 83.321907 lr 0.00188024 rank 0
2022-08-22 15:41:10,404 DEBUG TRAIN Batch 16/3100 loss 50.467812 loss_att 38.997742 loss_ctc 77.231308 loss_ctc_origin 63.137547 loss_ctc0 110.116760 lr 0.00188224 rank 0
2022-08-22 15:41:39,661 DEBUG TRAIN Batch 16/3200 loss 47.996471 loss_att 38.154095 loss_ctc 70.962013 loss_ctc_origin 68.280090 loss_ctc0 77.219826 lr 0.00188424 rank 0
2022-08-22 15:42:08,793 DEBUG TRAIN Batch 16/3300 loss 56.617287 loss_att 44.465481 loss_ctc 84.971497 loss_ctc_origin 83.565323 loss_ctc0 88.252586 lr 0.00188624 rank 0
2022-08-22 15:42:33,513 WARNING NaN or Inf found in input tensor.
2022-08-22 15:42:38,039 DEBUG TRAIN Batch 16/3400 loss 70.296387 loss_att 53.537983 loss_ctc 109.399315 loss_ctc_origin 106.016556 loss_ctc0 117.292427 lr 0.00188824 rank 0
2022-08-22 15:43:08,414 DEBUG TRAIN Batch 16/3500 loss 48.308681 loss_att 35.535149 loss_ctc 78.113594 loss_ctc_origin 55.541428 loss_ctc0 130.781982 lr 0.00189024 rank 0
2022-08-22 15:43:37,070 DEBUG TRAIN Batch 16/3600 loss 56.151260 loss_att 39.650784 loss_ctc 94.652374 loss_ctc_origin 65.777756 loss_ctc0 162.026489 lr 0.00189224 rank 0
2022-08-22 15:44:04,348 DEBUG TRAIN Batch 16/3700 loss 57.623459 loss_att 44.922638 loss_ctc 87.258698 loss_ctc_origin 88.163948 loss_ctc0 85.146454 lr 0.00189424 rank 0
2022-08-22 15:44:33,568 DEBUG TRAIN Batch 16/3800 loss 71.856850 loss_att 55.226105 loss_ctc 110.661926 loss_ctc_origin 111.504959 loss_ctc0 108.694878 lr 0.00189624 rank 0
2022-08-22 15:45:01,944 DEBUG TRAIN Batch 16/3900 loss 83.389328 loss_att 66.859131 loss_ctc 121.959793 loss_ctc_origin 122.782669 loss_ctc0 120.039749 lr 0.00189824 rank 0
2022-08-22 15:45:29,338 DEBUG TRAIN Batch 16/4000 loss 40.798622 loss_att 32.034630 loss_ctc 61.247944 loss_ctc_origin 54.796455 loss_ctc0 76.301422 lr 0.00190024 rank 0
2022-08-22 15:45:58,257 DEBUG TRAIN Batch 16/4100 loss 56.610371 loss_att 46.634964 loss_ctc 79.886322 loss_ctc_origin 73.453308 loss_ctc0 94.896667 lr 0.00190224 rank 0
2022-08-22 15:46:24,930 DEBUG TRAIN Batch 16/4200 loss 58.082512 loss_att 46.218746 loss_ctc 85.764633 loss_ctc_origin 85.664917 loss_ctc0 85.997299 lr 0.00190424 rank 0
2022-08-22 15:46:53,072 DEBUG TRAIN Batch 16/4300 loss 63.132374 loss_att 47.693443 loss_ctc 99.156540 loss_ctc_origin 99.409340 loss_ctc0 98.566666 lr 0.00190624 rank 0
2022-08-22 15:47:20,646 DEBUG TRAIN Batch 16/4400 loss 84.830101 loss_att 69.853439 loss_ctc 119.775635 loss_ctc_origin 120.393402 loss_ctc0 118.334152 lr 0.00190824 rank 0
2022-08-22 15:47:53,913 DEBUG TRAIN Batch 16/4500 loss 50.033836 loss_att 36.325481 loss_ctc 82.019989 loss_ctc_origin 54.359863 loss_ctc0 146.560272 lr 0.00191024 rank 0
2022-08-22 15:48:22,082 DEBUG TRAIN Batch 16/4600 loss 58.186829 loss_att 42.544762 loss_ctc 94.684982 loss_ctc_origin 71.547089 loss_ctc0 148.673386 lr 0.00191224 rank 0
2022-08-22 15:48:49,130 DEBUG TRAIN Batch 16/4700 loss 61.083279 loss_att 52.776878 loss_ctc 80.464882 loss_ctc_origin 80.979187 loss_ctc0 79.264839 lr 0.00191424 rank 0
2022-08-22 15:49:18,214 DEBUG TRAIN Batch 16/4800 loss 68.453171 loss_att 56.049984 loss_ctc 97.393936 loss_ctc_origin 97.211441 loss_ctc0 97.819756 lr 0.00191624 rank 0
2022-08-22 15:49:46,514 DEBUG TRAIN Batch 16/4900 loss 87.726257 loss_att 68.933960 loss_ctc 131.574951 loss_ctc_origin 113.544014 loss_ctc0 173.647110 lr 0.00191824 rank 0
2022-08-22 15:50:15,801 DEBUG TRAIN Batch 16/5000 loss 42.862358 loss_att 34.714214 loss_ctc 61.874695 loss_ctc_origin 55.141422 loss_ctc0 77.585655 lr 0.00192024 rank 0
2022-08-22 15:50:43,757 DEBUG TRAIN Batch 16/5100 loss 54.813522 loss_att 43.451412 loss_ctc 81.325104 loss_ctc_origin 75.953743 loss_ctc0 93.858276 lr 0.00192224 rank 0
2022-08-22 15:51:10,712 DEBUG TRAIN Batch 16/5200 loss 55.388927 loss_att 42.961426 loss_ctc 84.386429 loss_ctc_origin 83.717239 loss_ctc0 85.947876 lr 0.00192424 rank 0
2022-08-22 15:51:38,925 DEBUG TRAIN Batch 16/5300 loss 65.929665 loss_att 52.285805 loss_ctc 97.765343 loss_ctc_origin 96.649323 loss_ctc0 100.369392 lr 0.00192624 rank 0
2022-08-22 15:52:07,156 DEBUG TRAIN Batch 16/5400 loss 79.871902 loss_att 64.530441 loss_ctc 115.668640 loss_ctc_origin 114.636047 loss_ctc0 118.078011 lr 0.00192824 rank 0
2022-08-22 15:52:34,831 DEBUG TRAIN Batch 16/5500 loss 43.104286 loss_att 34.988487 loss_ctc 62.041153 loss_ctc_origin 57.488121 loss_ctc0 72.664902 lr 0.00193024 rank 0
2022-08-22 15:53:02,507 DEBUG TRAIN Batch 16/5600 loss 49.395618 loss_att 39.459148 loss_ctc 72.580719 loss_ctc_origin 67.839989 loss_ctc0 83.642418 lr 0.00193224 rank 0
2022-08-22 15:53:26,618 DEBUG CV Batch 16/0 loss 33.424042 loss_att 28.257607 loss_ctc 45.479061 loss_ctc_origin 44.329514 loss_ctc0 48.161343 history loss 31.457922 rank 0
2022-08-22 15:53:37,634 DEBUG CV Batch 16/100 loss 49.011292 loss_att 39.856384 loss_ctc 70.372742 loss_ctc_origin 69.530930 loss_ctc0 72.336960 history loss 64.738604 rank 0
2022-08-22 15:53:47,950 DEBUG CV Batch 16/200 loss 60.634918 loss_att 51.673855 loss_ctc 81.544060 loss_ctc_origin 79.837646 loss_ctc0 85.525681 history loss 65.309418 rank 0
2022-08-22 15:53:58,689 DEBUG CV Batch 16/300 loss 66.922165 loss_att 56.373150 loss_ctc 91.536530 loss_ctc_origin 88.418015 loss_ctc0 98.813065 history loss 65.309848 rank 0
2022-08-22 15:54:09,887 DEBUG CV Batch 16/400 loss 91.742645 loss_att 78.318100 loss_ctc 123.066574 loss_ctc_origin 121.458176 loss_ctc0 126.819519 history loss 64.206215 rank 0
2022-08-22 15:54:21,431 DEBUG CV Batch 16/500 loss 38.582096 loss_att 32.414146 loss_ctc 52.973984 loss_ctc_origin 52.380470 loss_ctc0 54.358841 history loss 64.280300 rank 0
2022-08-22 15:54:32,986 DEBUG CV Batch 16/600 loss 47.814018 loss_att 39.371849 loss_ctc 67.512413 loss_ctc_origin 66.098000 loss_ctc0 70.812714 history loss 64.107594 rank 0
2022-08-22 15:54:44,012 DEBUG CV Batch 16/700 loss 59.771633 loss_att 50.219059 loss_ctc 82.060974 loss_ctc_origin 79.383789 loss_ctc0 88.307724 history loss 63.857636 rank 0
2022-08-22 15:54:55,110 DEBUG CV Batch 16/800 loss 62.131111 loss_att 51.891281 loss_ctc 86.024055 loss_ctc_origin 81.383438 loss_ctc0 96.852158 history loss 63.954533 rank 0
2022-08-22 15:55:05,772 INFO Epoch 16 CV info cv_loss 64.27521754579217
2022-08-22 15:55:05,772 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/16.pt
2022-08-22 15:55:06,224 INFO Epoch 17 TRAIN info lr 0.0019339199999999998
2022-08-22 15:55:06,227 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 15:55:34,225 DEBUG TRAIN Batch 17/0 loss 44.327774 loss_att 38.509636 loss_ctc 57.903427 loss_ctc_origin 54.159397 loss_ctc0 66.639496 lr 0.00193400 rank 0
2022-08-22 15:55:42,740 WARNING NaN or Inf found in input tensor.
2022-08-22 15:56:03,963 DEBUG TRAIN Batch 17/100 loss 50.459579 loss_att 39.166885 loss_ctc 76.809204 loss_ctc_origin 68.566467 loss_ctc0 96.042267 lr 0.00193600 rank 0
2022-08-22 15:56:32,445 DEBUG TRAIN Batch 17/200 loss 54.296654 loss_att 42.662529 loss_ctc 81.442947 loss_ctc_origin 80.640633 loss_ctc0 83.315033 lr 0.00193800 rank 0
2022-08-22 15:57:01,616 DEBUG TRAIN Batch 17/300 loss 65.179832 loss_att 52.403076 loss_ctc 94.992271 loss_ctc_origin 93.271133 loss_ctc0 99.008255 lr 0.00194000 rank 0
2022-08-22 15:57:30,749 DEBUG TRAIN Batch 17/400 loss 75.235703 loss_att 58.559811 loss_ctc 114.146095 loss_ctc_origin 113.539978 loss_ctc0 115.560379 lr 0.00194200 rank 0
2022-08-22 15:58:01,235 DEBUG TRAIN Batch 17/500 loss 44.616169 loss_att 34.809536 loss_ctc 67.498314 loss_ctc_origin 59.955910 loss_ctc0 85.097267 lr 0.00194400 rank 0
2022-08-22 15:58:30,334 DEBUG TRAIN Batch 17/600 loss 54.176491 loss_att 42.690208 loss_ctc 80.977814 loss_ctc_origin 75.581680 loss_ctc0 93.568771 lr 0.00194600 rank 0
2022-08-22 15:58:59,378 DEBUG TRAIN Batch 17/700 loss 58.884186 loss_att 48.685905 loss_ctc 82.680183 loss_ctc_origin 82.857269 loss_ctc0 82.266983 lr 0.00194800 rank 0
2022-08-22 15:59:27,409 DEBUG TRAIN Batch 17/800 loss 66.184219 loss_att 51.746712 loss_ctc 99.871735 loss_ctc_origin 99.797966 loss_ctc0 100.043854 lr 0.00195000 rank 0
2022-08-22 15:59:58,633 DEBUG TRAIN Batch 17/900 loss 80.390991 loss_att 63.396198 loss_ctc 120.045502 loss_ctc_origin 120.259758 loss_ctc0 119.545547 lr 0.00195200 rank 0
2022-08-22 16:00:21,690 WARNING NaN or Inf found in input tensor.
2022-08-22 16:00:27,400 DEBUG TRAIN Batch 17/1000 loss 44.589851 loss_att 37.732426 loss_ctc 60.590504 loss_ctc_origin 61.332451 loss_ctc0 58.859287 lr 0.00195400 rank 0
2022-08-22 16:00:56,428 DEBUG TRAIN Batch 17/1100 loss 47.186726 loss_att 35.543198 loss_ctc 74.354958 loss_ctc_origin 66.600174 loss_ctc0 92.449448 lr 0.00195600 rank 0
2022-08-22 16:01:24,041 DEBUG TRAIN Batch 17/1200 loss 57.519676 loss_att 46.028168 loss_ctc 84.333191 loss_ctc_origin 84.480103 loss_ctc0 83.990387 lr 0.00195800 rank 0
2022-08-22 16:01:52,908 DEBUG TRAIN Batch 17/1300 loss 68.971939 loss_att 54.936752 loss_ctc 101.720695 loss_ctc_origin 101.769058 loss_ctc0 101.607849 lr 0.00196000 rank 0
2022-08-22 16:02:23,238 DEBUG TRAIN Batch 17/1400 loss 86.679688 loss_att 72.200356 loss_ctc 120.464790 loss_ctc_origin 120.774246 loss_ctc0 119.742737 lr 0.00196200 rank 0
2022-08-22 16:02:58,758 DEBUG TRAIN Batch 17/1500 loss 38.054649 loss_att 30.862288 loss_ctc 54.836819 loss_ctc_origin 54.778313 loss_ctc0 54.973331 lr 0.00196400 rank 0
2022-08-22 16:03:27,313 DEBUG TRAIN Batch 17/1600 loss 56.925411 loss_att 43.192696 loss_ctc 88.968414 loss_ctc_origin 71.080429 loss_ctc0 130.707031 lr 0.00196600 rank 0
2022-08-22 16:03:56,893 DEBUG TRAIN Batch 17/1700 loss 56.150524 loss_att 43.632675 loss_ctc 85.358841 loss_ctc_origin 85.377197 loss_ctc0 85.315994 lr 0.00196800 rank 0
2022-08-22 16:04:26,481 DEBUG TRAIN Batch 17/1800 loss 71.049278 loss_att 56.545162 loss_ctc 104.892212 loss_ctc_origin 104.945816 loss_ctc0 104.767143 lr 0.00197000 rank 0
2022-08-22 16:04:55,770 DEBUG TRAIN Batch 17/1900 loss 78.320892 loss_att 62.615105 loss_ctc 114.967705 loss_ctc_origin 112.985695 loss_ctc0 119.592384 lr 0.00197200 rank 0
2022-08-22 16:05:23,659 DEBUG TRAIN Batch 17/2000 loss 42.051620 loss_att 33.376247 loss_ctc 62.294163 loss_ctc_origin 58.022980 loss_ctc0 72.260254 lr 0.00197400 rank 0
2022-08-22 16:05:51,532 DEBUG TRAIN Batch 17/2100 loss 47.694427 loss_att 37.739964 loss_ctc 70.921509 loss_ctc_origin 69.871429 loss_ctc0 73.371704 lr 0.00197600 rank 0
2022-08-22 16:06:22,526 DEBUG TRAIN Batch 17/2200 loss 55.044754 loss_att 42.582088 loss_ctc 84.124313 loss_ctc_origin 83.304474 loss_ctc0 86.037277 lr 0.00197800 rank 0
2022-08-22 16:06:50,628 DEBUG TRAIN Batch 17/2300 loss 77.177078 loss_att 64.446976 loss_ctc 106.880638 loss_ctc_origin 104.801117 loss_ctc0 111.732864 lr 0.00198000 rank 0
2022-08-22 16:07:20,249 DEBUG TRAIN Batch 17/2400 loss 77.829071 loss_att 61.385368 loss_ctc 116.197693 loss_ctc_origin 112.685913 loss_ctc0 124.391838 lr 0.00198200 rank 0
2022-08-22 16:07:49,013 DEBUG TRAIN Batch 17/2500 loss 41.395401 loss_att 33.954277 loss_ctc 58.758026 loss_ctc_origin 52.310886 loss_ctc0 73.801353 lr 0.00198400 rank 0
2022-08-22 16:08:04,275 WARNING NaN or Inf found in input tensor.
2022-08-22 16:08:18,413 DEBUG TRAIN Batch 17/2600 loss 52.251999 loss_att 43.291031 loss_ctc 73.160927 loss_ctc_origin 72.205223 loss_ctc0 75.390900 lr 0.00198600 rank 0
2022-08-22 16:08:47,032 DEBUG TRAIN Batch 17/2700 loss 57.287846 loss_att 45.457489 loss_ctc 84.892006 loss_ctc_origin 83.967392 loss_ctc0 87.049438 lr 0.00198800 rank 0
2022-08-22 16:09:16,091 DEBUG TRAIN Batch 17/2800 loss 70.460564 loss_att 55.975319 loss_ctc 104.259460 loss_ctc_origin 102.654633 loss_ctc0 108.004082 lr 0.00199000 rank 0
2022-08-22 16:09:45,857 DEBUG TRAIN Batch 17/2900 loss 79.442047 loss_att 64.925865 loss_ctc 113.313126 loss_ctc_origin 111.939705 loss_ctc0 116.517754 lr 0.00199200 rank 0
2022-08-22 16:10:21,161 DEBUG TRAIN Batch 17/3000 loss 41.229813 loss_att 34.428429 loss_ctc 57.099709 loss_ctc_origin 55.834435 loss_ctc0 60.052017 lr 0.00199400 rank 0
2022-08-22 16:10:50,654 DEBUG TRAIN Batch 17/3100 loss 55.216534 loss_att 45.620049 loss_ctc 77.608330 loss_ctc_origin 71.433548 loss_ctc0 92.016151 lr 0.00199600 rank 0
2022-08-22 16:11:18,739 DEBUG TRAIN Batch 17/3200 loss 47.848534 loss_att 38.513855 loss_ctc 69.629456 loss_ctc_origin 67.450607 loss_ctc0 74.713440 lr 0.00199800 rank 0
2022-08-22 16:11:47,514 DEBUG TRAIN Batch 17/3300 loss 64.147232 loss_att 49.700020 loss_ctc 97.857391 loss_ctc_origin 96.001060 loss_ctc0 102.188812 lr 0.00200000 rank 0
2022-08-22 16:12:16,407 DEBUG TRAIN Batch 17/3400 loss 80.132210 loss_att 64.530724 loss_ctc 116.535675 loss_ctc_origin 113.809006 loss_ctc0 122.897881 lr 0.00199900 rank 0
2022-08-22 16:12:19,036 WARNING NaN or Inf found in input tensor.
2022-08-22 16:12:46,648 DEBUG TRAIN Batch 17/3500 loss 38.057732 loss_att 33.980476 loss_ctc 47.571320 loss_ctc_origin 46.270195 loss_ctc0 50.607269 lr 0.00199800 rank 0
2022-08-22 16:13:14,547 DEBUG TRAIN Batch 17/3600 loss 58.737289 loss_att 39.231380 loss_ctc 104.251068 loss_ctc_origin 76.188629 loss_ctc0 169.730103 lr 0.00199701 rank 0
2022-08-22 16:13:43,251 DEBUG TRAIN Batch 17/3700 loss 53.380463 loss_att 42.027115 loss_ctc 79.871605 loss_ctc_origin 77.577873 loss_ctc0 85.223648 lr 0.00199601 rank 0
2022-08-22 16:14:11,731 DEBUG TRAIN Batch 17/3800 loss 66.492867 loss_att 53.445889 loss_ctc 96.935806 loss_ctc_origin 94.856812 loss_ctc0 101.786789 lr 0.00199502 rank 0
2022-08-22 16:14:41,954 DEBUG TRAIN Batch 17/3900 loss 68.453659 loss_att 52.681816 loss_ctc 105.254631 loss_ctc_origin 102.685341 loss_ctc0 111.249634 lr 0.00199403 rank 0
2022-08-22 16:15:09,867 DEBUG TRAIN Batch 17/4000 loss 47.029915 loss_att 40.607040 loss_ctc 62.016609 loss_ctc_origin 62.469658 loss_ctc0 60.959496 lr 0.00199304 rank 0
2022-08-22 16:15:39,331 DEBUG TRAIN Batch 17/4100 loss 54.929695 loss_att 41.768364 loss_ctc 85.639458 loss_ctc_origin 70.957108 loss_ctc0 119.898270 lr 0.00199205 rank 0
2022-08-22 16:16:07,909 DEBUG TRAIN Batch 17/4200 loss 52.027889 loss_att 40.764549 loss_ctc 78.309013 loss_ctc_origin 76.124832 loss_ctc0 83.405441 lr 0.00199106 rank 0
2022-08-22 16:16:38,282 DEBUG TRAIN Batch 17/4300 loss 72.486183 loss_att 59.744110 loss_ctc 102.217682 loss_ctc_origin 100.748848 loss_ctc0 105.644958 lr 0.00199007 rank 0
2022-08-22 16:17:08,051 DEBUG TRAIN Batch 17/4400 loss 86.414429 loss_att 69.137169 loss_ctc 126.728035 loss_ctc_origin 124.711861 loss_ctc0 131.432434 lr 0.00198909 rank 0
2022-08-22 16:17:43,759 DEBUG TRAIN Batch 17/4500 loss 41.259354 loss_att 32.263504 loss_ctc 62.249680 loss_ctc_origin 56.151623 loss_ctc0 76.478470 lr 0.00198811 rank 0
2022-08-22 16:18:12,810 DEBUG TRAIN Batch 17/4600 loss 48.681442 loss_att 36.377922 loss_ctc 77.389664 loss_ctc_origin 65.401672 loss_ctc0 105.361633 lr 0.00198713 rank 0
2022-08-22 16:18:41,820 DEBUG TRAIN Batch 17/4700 loss 56.933823 loss_att 45.908043 loss_ctc 82.660645 loss_ctc_origin 80.595131 loss_ctc0 87.480164 lr 0.00198615 rank 0
2022-08-22 16:19:10,695 DEBUG TRAIN Batch 17/4800 loss 60.560471 loss_att 47.143238 loss_ctc 91.867332 loss_ctc_origin 89.634216 loss_ctc0 97.077942 lr 0.00198517 rank 0
2022-08-22 16:19:40,387 DEBUG TRAIN Batch 17/4900 loss 75.265686 loss_att 60.248222 loss_ctc 110.306427 loss_ctc_origin 106.779816 loss_ctc0 118.535164 lr 0.00198419 rank 0
2022-08-22 16:20:09,582 DEBUG TRAIN Batch 17/5000 loss 46.305000 loss_att 30.858559 loss_ctc 82.346695 loss_ctc_origin 50.397099 loss_ctc0 156.895752 lr 0.00198321 rank 0
2022-08-22 16:20:38,661 DEBUG TRAIN Batch 17/5100 loss 61.184753 loss_att 41.588417 loss_ctc 106.909546 loss_ctc_origin 75.893250 loss_ctc0 179.280914 lr 0.00198224 rank 0
2022-08-22 16:21:08,471 DEBUG TRAIN Batch 17/5200 loss 51.035488 loss_att 40.067123 loss_ctc 76.628342 loss_ctc_origin 73.819061 loss_ctc0 83.183311 lr 0.00198127 rank 0
2022-08-22 16:21:37,866 DEBUG TRAIN Batch 17/5300 loss 60.906975 loss_att 48.585068 loss_ctc 89.658081 loss_ctc_origin 86.657867 loss_ctc0 96.658569 lr 0.00198030 rank 0
2022-08-22 16:22:06,589 DEBUG TRAIN Batch 17/5400 loss 76.435913 loss_att 63.031612 loss_ctc 107.712616 loss_ctc_origin 103.728897 loss_ctc0 117.007935 lr 0.00197933 rank 0
2022-08-22 16:22:36,676 DEBUG TRAIN Batch 17/5500 loss 43.067886 loss_att 31.564318 loss_ctc 69.909546 loss_ctc_origin 57.171112 loss_ctc0 99.632553 lr 0.00197836 rank 0
2022-08-22 16:23:05,883 DEBUG TRAIN Batch 17/5600 loss 60.191086 loss_att 40.203075 loss_ctc 106.829773 loss_ctc_origin 68.491837 loss_ctc0 196.284943 lr 0.00197739 rank 0
2022-08-22 16:23:29,320 DEBUG CV Batch 17/0 loss 37.019196 loss_att 30.977839 loss_ctc 51.115692 loss_ctc_origin 50.982857 loss_ctc0 51.425644 history loss 34.841596 rank 0
2022-08-22 16:23:40,378 DEBUG CV Batch 17/100 loss 54.206841 loss_att 43.734619 loss_ctc 78.642014 loss_ctc_origin 78.440804 loss_ctc0 79.111488 history loss 60.896787 rank 0
2022-08-22 16:23:50,360 DEBUG CV Batch 17/200 loss 70.221848 loss_att 59.339417 loss_ctc 95.614174 loss_ctc_origin 95.369995 loss_ctc0 96.183929 history loss 62.776922 rank 0
2022-08-22 16:24:00,559 DEBUG CV Batch 17/300 loss 57.828392 loss_att 47.165989 loss_ctc 82.707321 loss_ctc_origin 77.222656 loss_ctc0 95.504883 history loss 62.317301 rank 0
2022-08-22 16:24:11,357 DEBUG CV Batch 17/400 loss 80.123047 loss_att 67.204422 loss_ctc 110.266510 loss_ctc_origin 105.174820 loss_ctc0 122.147095 history loss 60.740476 rank 0
2022-08-22 16:24:22,798 DEBUG CV Batch 17/500 loss 43.393097 loss_att 36.051605 loss_ctc 60.523239 loss_ctc_origin 60.402321 loss_ctc0 60.805389 history loss 60.646874 rank 0
2022-08-22 16:24:33,929 DEBUG CV Batch 17/600 loss 57.010170 loss_att 46.898071 loss_ctc 80.605072 loss_ctc_origin 81.053757 loss_ctc0 79.558136 history loss 60.628683 rank 0
2022-08-22 16:24:44,315 DEBUG CV Batch 17/700 loss 50.752460 loss_att 41.624767 loss_ctc 72.050407 loss_ctc_origin 66.601929 loss_ctc0 84.763519 history loss 60.385632 rank 0
2022-08-22 16:24:55,362 DEBUG CV Batch 17/800 loss 55.283417 loss_att 45.474236 loss_ctc 78.171509 loss_ctc_origin 71.195908 loss_ctc0 94.447922 history loss 60.436278 rank 0
2022-08-22 16:25:06,025 INFO Epoch 17 CV info cv_loss 60.51692855024468
2022-08-22 16:25:06,025 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/17.pt
2022-08-22 16:25:06,481 INFO Epoch 18 TRAIN info lr 0.001976577963791167
2022-08-22 16:25:06,484 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 16:25:34,388 DEBUG TRAIN Batch 18/0 loss 48.268478 loss_att 33.473782 loss_ctc 82.789429 loss_ctc_origin 56.918236 loss_ctc0 143.155533 lr 0.00197654 rank 0
2022-08-22 16:26:04,104 DEBUG TRAIN Batch 18/100 loss 58.662247 loss_att 39.348953 loss_ctc 103.726601 loss_ctc_origin 67.811180 loss_ctc0 187.529236 lr 0.00197557 rank 0
2022-08-22 16:26:33,143 DEBUG TRAIN Batch 18/200 loss 51.402084 loss_att 42.181114 loss_ctc 72.917686 loss_ctc_origin 70.223381 loss_ctc0 79.204407 lr 0.00197461 rank 0
2022-08-22 16:27:03,187 DEBUG TRAIN Batch 18/300 loss 63.162720 loss_att 50.258949 loss_ctc 93.271523 loss_ctc_origin 89.499428 loss_ctc0 102.073074 lr 0.00197365 rank 0
2022-08-22 16:27:32,215 DEBUG TRAIN Batch 18/400 loss 70.709496 loss_att 55.400097 loss_ctc 106.431419 loss_ctc_origin 101.874352 loss_ctc0 117.064590 lr 0.00197269 rank 0
2022-08-22 16:27:34,899 WARNING NaN or Inf found in input tensor.
2022-08-22 16:28:02,170 DEBUG TRAIN Batch 18/500 loss 38.897789 loss_att 30.924673 loss_ctc 57.501724 loss_ctc_origin 47.301891 loss_ctc0 81.301338 lr 0.00197173 rank 0
2022-08-22 16:28:30,966 DEBUG TRAIN Batch 18/600 loss 69.936081 loss_att 39.173996 loss_ctc 141.714279 loss_ctc_origin 70.337036 loss_ctc0 308.261169 lr 0.00197077 rank 0
2022-08-22 16:28:59,198 DEBUG TRAIN Batch 18/700 loss 52.276913 loss_att 41.927208 loss_ctc 76.426224 loss_ctc_origin 74.889709 loss_ctc0 80.011429 lr 0.00196982 rank 0
2022-08-22 16:29:28,735 DEBUG TRAIN Batch 18/800 loss 58.802094 loss_att 45.420788 loss_ctc 90.025131 loss_ctc_origin 86.018646 loss_ctc0 99.373596 lr 0.00196886 rank 0
2022-08-22 16:29:46,722 WARNING NaN or Inf found in input tensor.
2022-08-22 16:29:54,093 WARNING NaN or Inf found in input tensor.
2022-08-22 16:29:58,539 DEBUG TRAIN Batch 18/900 loss 72.498779 loss_att 56.882244 loss_ctc 108.937370 loss_ctc_origin 104.652802 loss_ctc0 118.934708 lr 0.00196791 rank 0
2022-08-22 16:30:28,270 DEBUG TRAIN Batch 18/1000 loss 46.684059 loss_att 30.778484 loss_ctc 83.797058 loss_ctc_origin 51.510048 loss_ctc0 159.133423 lr 0.00196696 rank 0
2022-08-22 16:30:56,501 DEBUG TRAIN Batch 18/1100 loss 72.477509 loss_att 43.591366 loss_ctc 139.878494 loss_ctc_origin 71.486359 loss_ctc0 299.460144 lr 0.00196601 rank 0
2022-08-22 16:31:26,449 DEBUG TRAIN Batch 18/1200 loss 45.913651 loss_att 35.851070 loss_ctc 69.393005 loss_ctc_origin 65.153290 loss_ctc0 79.285660 lr 0.00196506 rank 0
2022-08-22 16:31:39,247 WARNING NaN or Inf found in input tensor.
2022-08-22 16:31:56,502 DEBUG TRAIN Batch 18/1300 loss 62.197811 loss_att 48.349857 loss_ctc 94.509705 loss_ctc_origin 90.142456 loss_ctc0 104.699936 lr 0.00196411 rank 0
2022-08-22 16:32:25,230 DEBUG TRAIN Batch 18/1400 loss 70.504715 loss_att 55.673210 loss_ctc 105.111549 loss_ctc_origin 99.274536 loss_ctc0 118.731255 lr 0.00196316 rank 0
2022-08-22 16:33:00,945 DEBUG TRAIN Batch 18/1500 loss 46.261143 loss_att 31.161980 loss_ctc 81.492523 loss_ctc_origin 52.231510 loss_ctc0 149.768219 lr 0.00196222 rank 0
2022-08-22 16:33:30,247 DEBUG TRAIN Batch 18/1600 loss 58.466137 loss_att 35.151073 loss_ctc 112.867950 loss_ctc_origin 63.943073 loss_ctc0 227.025986 lr 0.00196127 rank 0
2022-08-22 16:33:58,503 DEBUG TRAIN Batch 18/1700 loss 47.826462 loss_att 38.608391 loss_ctc 69.335297 loss_ctc_origin 66.407028 loss_ctc0 76.167908 lr 0.00196033 rank 0
2022-08-22 16:34:28,018 DEBUG TRAIN Batch 18/1800 loss 62.836662 loss_att 51.632469 loss_ctc 88.979790 loss_ctc_origin 84.656990 loss_ctc0 99.066315 lr 0.00195939 rank 0
2022-08-22 16:34:58,483 DEBUG TRAIN Batch 18/1900 loss 70.221855 loss_att 55.889866 loss_ctc 103.663170 loss_ctc_origin 99.282013 loss_ctc0 113.885880 lr 0.00195845 rank 0
2022-08-22 16:35:28,571 DEBUG TRAIN Batch 18/2000 loss 47.317711 loss_att 34.040062 loss_ctc 78.298889 loss_ctc_origin 54.619450 loss_ctc0 133.550903 lr 0.00195751 rank 0
2022-08-22 16:35:50,654 WARNING NaN or Inf found in input tensor.
2022-08-22 16:35:58,071 DEBUG TRAIN Batch 18/2100 loss 59.080830 loss_att 40.384758 loss_ctc 102.704994 loss_ctc_origin 64.385063 loss_ctc0 192.118164 lr 0.00195658 rank 0
2022-08-22 16:36:27,597 DEBUG TRAIN Batch 18/2200 loss 46.145020 loss_att 36.080448 loss_ctc 69.629013 loss_ctc_origin 66.259247 loss_ctc0 77.491806 lr 0.00195564 rank 0
2022-08-22 16:36:56,431 DEBUG TRAIN Batch 18/2300 loss 54.958229 loss_att 41.956673 loss_ctc 85.295181 loss_ctc_origin 79.932266 loss_ctc0 97.808640 lr 0.00195471 rank 0
2022-08-22 16:37:13,662 WARNING NaN or Inf found in input tensor.
2022-08-22 16:37:25,196 DEBUG TRAIN Batch 18/2400 loss 73.151917 loss_att 56.800522 loss_ctc 111.305161 loss_ctc_origin 105.555183 loss_ctc0 124.721771 lr 0.00195377 rank 0
2022-08-22 16:37:54,734 DEBUG TRAIN Batch 18/2500 loss 37.977642 loss_att 31.755774 loss_ctc 52.495327 loss_ctc_origin 45.442085 loss_ctc0 68.952888 lr 0.00195284 rank 0
2022-08-22 16:38:23,779 DEBUG TRAIN Batch 18/2600 loss 43.226646 loss_att 34.372360 loss_ctc 63.886642 loss_ctc_origin 56.591892 loss_ctc0 80.907730 lr 0.00195191 rank 0
2022-08-22 16:38:52,647 DEBUG TRAIN Batch 18/2700 loss 42.670349 loss_att 32.448799 loss_ctc 66.520638 loss_ctc_origin 62.522518 loss_ctc0 75.849579 lr 0.00195098 rank 0
2022-08-22 16:39:23,205 DEBUG TRAIN Batch 18/2800 loss 68.360947 loss_att 54.847603 loss_ctc 99.892067 loss_ctc_origin 96.355042 loss_ctc0 108.145134 lr 0.00195006 rank 0
2022-08-22 16:39:52,614 DEBUG TRAIN Batch 18/2900 loss 71.402054 loss_att 56.328541 loss_ctc 106.573578 loss_ctc_origin 96.931267 loss_ctc0 129.072327 lr 0.00194913 rank 0
2022-08-22 16:40:27,597 DEBUG TRAIN Batch 18/3000 loss 36.952480 loss_att 30.532370 loss_ctc 51.932739 loss_ctc_origin 51.378941 loss_ctc0 53.224926 lr 0.00194820 rank 0
2022-08-22 16:40:57,493 DEBUG TRAIN Batch 18/3100 loss 43.173508 loss_att 33.787212 loss_ctc 65.074860 loss_ctc_origin 58.688095 loss_ctc0 79.977325 lr 0.00194728 rank 0
2022-08-22 16:41:25,051 WARNING NaN or Inf found in input tensor.
2022-08-22 16:41:26,841 DEBUG TRAIN Batch 18/3200 loss 49.863846 loss_att 39.013321 loss_ctc 75.181740 loss_ctc_origin 69.265938 loss_ctc0 88.985268 lr 0.00194636 rank 0
2022-08-22 16:41:57,253 DEBUG TRAIN Batch 18/3300 loss 57.696434 loss_att 45.897751 loss_ctc 85.226700 loss_ctc_origin 80.046448 loss_ctc0 97.313965 lr 0.00194544 rank 0
2022-08-22 16:42:27,479 DEBUG TRAIN Batch 18/3400 loss 65.311157 loss_att 49.430817 loss_ctc 102.365280 loss_ctc_origin 95.298355 loss_ctc0 118.854790 lr 0.00194452 rank 0
2022-08-22 16:42:57,161 DEBUG TRAIN Batch 18/3500 loss 37.773666 loss_att 30.858017 loss_ctc 53.910187 loss_ctc_origin 49.420010 loss_ctc0 64.387268 lr 0.00194360 rank 0
2022-08-22 16:43:19,568 WARNING NaN or Inf found in input tensor.
2022-08-22 16:43:26,928 DEBUG TRAIN Batch 18/3600 loss 45.628502 loss_att 36.677902 loss_ctc 66.513229 loss_ctc_origin 63.167999 loss_ctc0 74.318756 lr 0.00194268 rank 0
2022-08-22 16:43:56,902 DEBUG TRAIN Batch 18/3700 loss 47.484116 loss_att 37.252258 loss_ctc 71.358452 loss_ctc_origin 68.128342 loss_ctc0 78.895370 lr 0.00194177 rank 0
2022-08-22 16:44:25,538 DEBUG TRAIN Batch 18/3800 loss 47.911499 loss_att 35.872665 loss_ctc 76.002121 loss_ctc_origin 68.350235 loss_ctc0 93.856522 lr 0.00194085 rank 0
2022-08-22 16:44:56,480 DEBUG TRAIN Batch 18/3900 loss 62.344585 loss_att 47.995369 loss_ctc 95.826096 loss_ctc_origin 88.002525 loss_ctc0 114.081085 lr 0.00193994 rank 0
2022-08-22 16:45:25,929 DEBUG TRAIN Batch 18/4000 loss 36.453960 loss_att 28.088749 loss_ctc 55.972786 loss_ctc_origin 50.096485 loss_ctc0 69.684151 lr 0.00193903 rank 0
2022-08-22 16:45:54,373 DEBUG TRAIN Batch 18/4100 loss 47.450211 loss_att 38.187027 loss_ctc 69.064308 loss_ctc_origin 63.305176 loss_ctc0 82.502281 lr 0.00193812 rank 0
2022-08-22 16:46:24,771 DEBUG TRAIN Batch 18/4200 loss 43.399860 loss_att 32.524139 loss_ctc 68.776543 loss_ctc_origin 63.553169 loss_ctc0 80.964424 lr 0.00193721 rank 0
2022-08-22 16:46:54,444 DEBUG TRAIN Batch 18/4300 loss 56.075443 loss_att 42.162003 loss_ctc 88.540138 loss_ctc_origin 82.810211 loss_ctc0 101.909958 lr 0.00193630 rank 0
2022-08-22 16:47:20,599 WARNING NaN or Inf found in input tensor.
2022-08-22 16:47:25,027 DEBUG TRAIN Batch 18/4400 loss 58.968979 loss_att 41.863380 loss_ctc 98.882050 loss_ctc_origin 90.591133 loss_ctc0 118.227509 lr 0.00193539 rank 0
2022-08-22 16:48:02,369 DEBUG TRAIN Batch 18/4500 loss 45.762787 loss_att 32.156197 loss_ctc 77.511490 loss_ctc_origin 53.492401 loss_ctc0 133.556030 lr 0.00193449 rank 0
2022-08-22 16:48:31,567 DEBUG TRAIN Batch 18/4600 loss 41.943687 loss_att 31.315945 loss_ctc 66.741745 loss_ctc_origin 63.338928 loss_ctc0 74.681656 lr 0.00193358 rank 0
2022-08-22 16:49:01,240 DEBUG TRAIN Batch 18/4700 loss 37.701653 loss_att 28.843250 loss_ctc 58.371246 loss_ctc_origin 51.232674 loss_ctc0 75.027924 lr 0.00193268 rank 0
2022-08-22 16:49:30,356 DEBUG TRAIN Batch 18/4800 loss 51.963963 loss_att 39.221054 loss_ctc 81.697418 loss_ctc_origin 76.327927 loss_ctc0 94.226227 lr 0.00193178 rank 0
2022-08-22 16:50:00,019 DEBUG TRAIN Batch 18/4900 loss 59.386261 loss_att 45.205620 loss_ctc 92.474426 loss_ctc_origin 85.428207 loss_ctc0 108.915619 lr 0.00193088 rank 0
2022-08-22 16:50:30,447 DEBUG TRAIN Batch 18/5000 loss 42.520393 loss_att 33.315777 loss_ctc 63.997841 loss_ctc_origin 55.031685 loss_ctc0 84.918869 lr 0.00192998 rank 0
2022-08-22 16:50:59,272 DEBUG TRAIN Batch 18/5100 loss 48.984554 loss_att 35.826004 loss_ctc 79.687836 loss_ctc_origin 68.638023 loss_ctc0 105.470734 lr 0.00192908 rank 0
2022-08-22 16:51:29,087 DEBUG TRAIN Batch 18/5200 loss 43.875534 loss_att 34.399940 loss_ctc 65.985245 loss_ctc_origin 60.884014 loss_ctc0 77.888107 lr 0.00192818 rank 0
2022-08-22 16:51:57,975 DEBUG TRAIN Batch 18/5300 loss 49.972084 loss_att 36.507027 loss_ctc 81.390549 loss_ctc_origin 75.258850 loss_ctc0 95.697830 lr 0.00192729 rank 0
2022-08-22 16:52:27,953 DEBUG TRAIN Batch 18/5400 loss 63.431240 loss_att 49.505096 loss_ctc 95.925568 loss_ctc_origin 87.568520 loss_ctc0 115.425339 lr 0.00192639 rank 0
2022-08-22 16:52:56,728 DEBUG TRAIN Batch 18/5500 loss 30.827675 loss_att 23.266735 loss_ctc 48.469864 loss_ctc_origin 43.748993 loss_ctc0 59.485237 lr 0.00192550 rank 0
2022-08-22 16:53:26,016 DEBUG TRAIN Batch 18/5600 loss 49.543701 loss_att 35.763142 loss_ctc 81.698341 loss_ctc_origin 67.349625 loss_ctc0 115.178680 lr 0.00192461 rank 0
2022-08-22 16:53:49,461 DEBUG CV Batch 18/0 loss 33.152981 loss_att 27.269480 loss_ctc 46.881149 loss_ctc_origin 45.630863 loss_ctc0 49.798473 history loss 31.202805 rank 0
2022-08-22 16:54:00,699 DEBUG CV Batch 18/100 loss 40.719765 loss_att 32.815361 loss_ctc 59.163372 loss_ctc_origin 55.509842 loss_ctc0 67.688278 history loss 50.884114 rank 0
2022-08-22 16:54:10,964 DEBUG CV Batch 18/200 loss 46.454117 loss_att 37.696892 loss_ctc 66.887650 loss_ctc_origin 61.640076 loss_ctc0 79.131973 history loss 52.766961 rank 0
2022-08-22 16:54:21,463 DEBUG CV Batch 18/300 loss 47.686005 loss_att 37.191311 loss_ctc 72.173622 loss_ctc_origin 63.443302 loss_ctc0 92.544357 history loss 52.092043 rank 0
2022-08-22 16:54:32,550 DEBUG CV Batch 18/400 loss 67.341293 loss_att 54.586681 loss_ctc 97.102036 loss_ctc_origin 87.184586 loss_ctc0 120.242752 history loss 50.555469 rank 0
2022-08-22 16:54:44,085 DEBUG CV Batch 18/500 loss 41.214676 loss_att 34.096302 loss_ctc 57.824223 loss_ctc_origin 58.615345 loss_ctc0 55.978264 history loss 50.335504 rank 0
2022-08-22 16:54:54,712 DEBUG CV Batch 18/600 loss 42.828182 loss_att 34.389877 loss_ctc 62.517555 loss_ctc_origin 58.888161 loss_ctc0 70.986145 history loss 50.293847 rank 0
2022-08-22 16:55:05,381 DEBUG CV Batch 18/700 loss 41.966721 loss_att 33.109985 loss_ctc 62.632431 loss_ctc_origin 54.349308 loss_ctc0 81.959717 history loss 50.002339 rank 0
2022-08-22 16:55:16,397 DEBUG CV Batch 18/800 loss 42.606026 loss_att 32.630150 loss_ctc 65.883064 loss_ctc_origin 55.676830 loss_ctc0 89.697609 history loss 49.900435 rank 0
2022-08-22 16:55:26,809 INFO Epoch 18 CV info cv_loss 50.004342333773074
2022-08-22 16:55:26,809 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/18.pt
2022-08-22 16:55:27,262 INFO Epoch 19 TRAIN info lr 0.0019238597175717119
2022-08-22 16:55:27,266 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 16:55:55,302 DEBUG TRAIN Batch 19/0 loss 46.620892 loss_att 35.055122 loss_ctc 73.607681 loss_ctc_origin 57.409653 loss_ctc0 111.403091 lr 0.00192382 rank 0
2022-08-22 16:56:25,127 DEBUG TRAIN Batch 19/100 loss 43.760635 loss_att 33.622322 loss_ctc 67.416695 loss_ctc_origin 62.940701 loss_ctc0 77.860672 lr 0.00192293 rank 0
2022-08-22 16:56:54,725 DEBUG TRAIN Batch 19/200 loss 46.541405 loss_att 35.026512 loss_ctc 73.409477 loss_ctc_origin 69.462479 loss_ctc0 82.619141 lr 0.00192205 rank 0
2022-08-22 16:57:24,061 DEBUG TRAIN Batch 19/300 loss 42.447449 loss_att 30.542501 loss_ctc 70.225647 loss_ctc_origin 63.014847 loss_ctc0 87.050827 lr 0.00192116 rank 0
2022-08-22 16:57:54,749 DEBUG TRAIN Batch 19/400 loss 57.785126 loss_att 42.253418 loss_ctc 94.025764 loss_ctc_origin 85.960533 loss_ctc0 112.844635 lr 0.00192027 rank 0
2022-08-22 16:58:24,171 DEBUG TRAIN Batch 19/500 loss 41.093487 loss_att 34.010201 loss_ctc 57.621155 loss_ctc_origin 52.662048 loss_ctc0 69.192398 lr 0.00191939 rank 0
2022-08-22 16:58:32,519 WARNING NaN or Inf found in input tensor.
2022-08-22 16:58:53,279 DEBUG TRAIN Batch 19/600 loss 39.715542 loss_att 30.228985 loss_ctc 61.850838 loss_ctc_origin 52.801979 loss_ctc0 82.964851 lr 0.00191851 rank 0
2022-08-22 16:59:22,795 DEBUG TRAIN Batch 19/700 loss 43.165974 loss_att 33.246082 loss_ctc 66.312386 loss_ctc_origin 60.636929 loss_ctc0 79.555115 lr 0.00191762 rank 0
2022-08-22 16:59:52,735 DEBUG TRAIN Batch 19/800 loss 47.258041 loss_att 33.627609 loss_ctc 79.062378 loss_ctc_origin 69.939850 loss_ctc0 100.348282 lr 0.00191674 rank 0
2022-08-22 17:00:22,798 DEBUG TRAIN Batch 19/900 loss 57.472561 loss_att 42.796249 loss_ctc 91.717285 loss_ctc_origin 81.872398 loss_ctc0 114.688675 lr 0.00191586 rank 0
2022-08-22 17:00:53,090 DEBUG TRAIN Batch 19/1000 loss 37.729858 loss_att 29.170214 loss_ctc 57.702366 loss_ctc_origin 51.894909 loss_ctc0 71.253098 lr 0.00191499 rank 0
2022-08-22 17:01:19,396 DEBUG TRAIN Batch 19/1100 loss 42.840023 loss_att 31.944183 loss_ctc 68.263649 loss_ctc_origin 55.466934 loss_ctc0 98.122650 lr 0.00191411 rank 0
2022-08-22 17:01:49,902 DEBUG TRAIN Batch 19/1200 loss 41.843662 loss_att 30.818554 loss_ctc 67.568916 loss_ctc_origin 62.124939 loss_ctc0 80.271530 lr 0.00191323 rank 0
2022-08-22 17:02:19,369 DEBUG TRAIN Batch 19/1300 loss 51.341160 loss_att 39.274406 loss_ctc 79.496918 loss_ctc_origin 73.891922 loss_ctc0 92.575249 lr 0.00191236 rank 0
2022-08-22 17:02:48,751 DEBUG TRAIN Batch 19/1400 loss 53.792110 loss_att 39.544540 loss_ctc 87.036438 loss_ctc_origin 78.822952 loss_ctc0 106.201218 lr 0.00191148 rank 0
2022-08-22 17:03:22,260 DEBUG TRAIN Batch 19/1500 loss 38.960957 loss_att 31.729141 loss_ctc 55.835194 loss_ctc_origin 48.471989 loss_ctc0 73.015999 lr 0.00191061 rank 0
2022-08-22 17:03:30,677 WARNING NaN or Inf found in input tensor.
2022-08-22 17:03:50,246 DEBUG TRAIN Batch 19/1600 loss 45.426620 loss_att 32.686562 loss_ctc 75.153427 loss_ctc_origin 61.382462 loss_ctc0 107.285675 lr 0.00190974 rank 0
2022-08-22 17:04:18,474 DEBUG TRAIN Batch 19/1700 loss 43.992092 loss_att 33.698750 loss_ctc 68.009888 loss_ctc_origin 62.342079 loss_ctc0 81.234772 lr 0.00190887 rank 0
2022-08-22 17:04:46,610 DEBUG TRAIN Batch 19/1800 loss 48.462418 loss_att 34.563469 loss_ctc 80.893288 loss_ctc_origin 74.454330 loss_ctc0 95.917526 lr 0.00190800 rank 0
2022-08-22 17:05:15,410 DEBUG TRAIN Batch 19/1900 loss 59.810905 loss_att 44.868858 loss_ctc 94.675674 loss_ctc_origin 87.241020 loss_ctc0 112.023209 lr 0.00190713 rank 0
2022-08-22 17:05:45,702 DEBUG TRAIN Batch 19/2000 loss 31.963434 loss_att 23.551006 loss_ctc 51.592430 loss_ctc_origin 46.991196 loss_ctc0 62.328640 lr 0.00190627 rank 0
2022-08-22 17:06:15,532 DEBUG TRAIN Batch 19/2100 loss 47.113934 loss_att 35.452988 loss_ctc 74.322807 loss_ctc_origin 64.729515 loss_ctc0 96.707153 lr 0.00190540 rank 0
2022-08-22 17:06:44,181 DEBUG TRAIN Batch 19/2200 loss 40.973923 loss_att 30.863132 loss_ctc 64.565773 loss_ctc_origin 58.779076 loss_ctc0 78.068077 lr 0.00190454 rank 0
2022-08-22 17:07:13,796 DEBUG TRAIN Batch 19/2300 loss 49.309746 loss_att 36.254509 loss_ctc 79.771957 loss_ctc_origin 71.785622 loss_ctc0 98.406723 lr 0.00190367 rank 0
2022-08-22 17:07:44,551 DEBUG TRAIN Batch 19/2400 loss 51.905334 loss_att 37.580498 loss_ctc 85.329941 loss_ctc_origin 75.728973 loss_ctc0 107.732193 lr 0.00190281 rank 0
2022-08-22 17:08:13,454 WARNING NaN or Inf found in input tensor.
2022-08-22 17:08:13,500 DEBUG TRAIN Batch 19/2500 loss inf loss_att 32.933449 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00190195 rank 0
2022-08-22 17:08:43,065 DEBUG TRAIN Batch 19/2600 loss 39.682220 loss_att 29.866987 loss_ctc 62.584435 loss_ctc_origin 59.591522 loss_ctc0 69.567902 lr 0.00190109 rank 0
2022-08-22 17:09:12,243 DEBUG TRAIN Batch 19/2700 loss 43.530579 loss_att 30.780472 loss_ctc 73.280823 loss_ctc_origin 68.422714 loss_ctc0 84.616409 lr 0.00190023 rank 0
2022-08-22 17:09:43,342 DEBUG TRAIN Batch 19/2800 loss 46.281647 loss_att 34.532066 loss_ctc 73.697334 loss_ctc_origin 66.208450 loss_ctc0 91.171410 lr 0.00189938 rank 0
2022-08-22 17:10:12,095 DEBUG TRAIN Batch 19/2900 loss 49.412716 loss_att 34.379890 loss_ctc 84.489304 loss_ctc_origin 74.008194 loss_ctc0 108.945221 lr 0.00189852 rank 0
2022-08-22 17:10:48,721 DEBUG TRAIN Batch 19/3000 loss 48.795853 loss_att 35.453991 loss_ctc 79.926865 loss_ctc_origin 62.139885 loss_ctc0 121.429802 lr 0.00189767 rank 0
2022-08-22 17:11:19,252 DEBUG TRAIN Batch 19/3100 loss 38.778816 loss_att 29.153782 loss_ctc 61.237236 loss_ctc_origin 55.826218 loss_ctc0 73.862946 lr 0.00189681 rank 0
2022-08-22 17:11:48,888 DEBUG TRAIN Batch 19/3200 loss 37.258026 loss_att 27.400536 loss_ctc 60.258835 loss_ctc_origin 54.412548 loss_ctc0 73.900177 lr 0.00189596 rank 0
2022-08-22 17:12:18,440 DEBUG TRAIN Batch 19/3300 loss 46.940475 loss_att 33.662426 loss_ctc 77.922592 loss_ctc_origin 70.019028 loss_ctc0 96.364243 lr 0.00189511 rank 0
2022-08-22 17:12:48,437 DEBUG TRAIN Batch 19/3400 loss 53.888313 loss_att 37.977798 loss_ctc 91.012840 loss_ctc_origin 78.467155 loss_ctc0 120.286095 lr 0.00189426 rank 0
2022-08-22 17:13:16,903 DEBUG TRAIN Batch 19/3500 loss 39.094406 loss_att 31.801315 loss_ctc 56.111618 loss_ctc_origin 51.766819 loss_ctc0 66.249481 lr 0.00189341 rank 0
2022-08-22 17:13:46,352 DEBUG TRAIN Batch 19/3600 loss 39.617462 loss_att 30.311306 loss_ctc 61.331814 loss_ctc_origin 53.294029 loss_ctc0 80.086639 lr 0.00189256 rank 0
2022-08-22 17:14:16,290 DEBUG TRAIN Batch 19/3700 loss 36.671616 loss_att 26.517925 loss_ctc 60.363564 loss_ctc_origin 52.686306 loss_ctc0 78.277161 lr 0.00189172 rank 0
2022-08-22 17:14:44,895 DEBUG TRAIN Batch 19/3800 loss 41.738323 loss_att 30.410309 loss_ctc 68.170357 loss_ctc_origin 59.656418 loss_ctc0 88.036224 lr 0.00189087 rank 0
2022-08-22 17:15:15,390 DEBUG TRAIN Batch 19/3900 loss 57.232285 loss_att 42.885933 loss_ctc 90.707092 loss_ctc_origin 79.243271 loss_ctc0 117.456009 lr 0.00189002 rank 0
2022-08-22 17:15:45,546 DEBUG TRAIN Batch 19/4000 loss 35.255089 loss_att 30.097672 loss_ctc 47.289062 loss_ctc_origin 45.782448 loss_ctc0 50.804489 lr 0.00188918 rank 0
2022-08-22 17:16:16,457 DEBUG TRAIN Batch 19/4100 loss 40.710785 loss_att 31.819958 loss_ctc 61.456039 loss_ctc_origin 56.429108 loss_ctc0 73.185555 lr 0.00188834 rank 0
2022-08-22 17:16:46,205 DEBUG TRAIN Batch 19/4200 loss 41.484268 loss_att 31.791931 loss_ctc 64.099731 loss_ctc_origin 57.216042 loss_ctc0 80.161690 lr 0.00188750 rank 0
2022-08-22 17:17:16,301 DEBUG TRAIN Batch 19/4300 loss 45.030853 loss_att 32.747910 loss_ctc 73.691055 loss_ctc_origin 65.372765 loss_ctc0 93.100395 lr 0.00188666 rank 0
2022-08-22 17:17:45,995 DEBUG TRAIN Batch 19/4400 loss 49.501045 loss_att 35.229263 loss_ctc 82.801865 loss_ctc_origin 71.880104 loss_ctc0 108.285965 lr 0.00188582 rank 0
2022-08-22 17:18:21,785 DEBUG TRAIN Batch 19/4500 loss 32.662617 loss_att 26.834953 loss_ctc 46.260498 loss_ctc_origin 40.236588 loss_ctc0 60.316288 lr 0.00188498 rank 0
2022-08-22 17:18:51,160 DEBUG TRAIN Batch 19/4600 loss 37.240570 loss_att 26.457708 loss_ctc 62.400589 loss_ctc_origin 55.650826 loss_ctc0 78.150040 lr 0.00188414 rank 0
2022-08-22 17:19:21,902 DEBUG TRAIN Batch 19/4700 loss 41.741081 loss_att 30.783752 loss_ctc 67.308182 loss_ctc_origin 61.341156 loss_ctc0 81.231247 lr 0.00188331 rank 0
2022-08-22 17:19:51,146 DEBUG TRAIN Batch 19/4800 loss 49.449455 loss_att 37.426479 loss_ctc 77.503059 loss_ctc_origin 69.266907 loss_ctc0 96.720734 lr 0.00188247 rank 0
2022-08-22 17:20:19,951 DEBUG TRAIN Batch 19/4900 loss 46.478912 loss_att 32.065582 loss_ctc 80.110008 loss_ctc_origin 66.328278 loss_ctc0 112.267380 lr 0.00188164 rank 0
2022-08-22 17:20:50,313 DEBUG TRAIN Batch 19/5000 loss 30.757351 loss_att 24.386940 loss_ctc 45.621643 loss_ctc_origin 41.426922 loss_ctc0 55.409332 lr 0.00188081 rank 0
2022-08-22 17:21:19,341 DEBUG TRAIN Batch 19/5100 loss 37.621773 loss_att 29.201759 loss_ctc 57.268471 loss_ctc_origin 52.070721 loss_ctc0 69.396553 lr 0.00187998 rank 0
2022-08-22 17:21:48,482 DEBUG TRAIN Batch 19/5200 loss 37.943474 loss_att 27.092913 loss_ctc 63.261444 loss_ctc_origin 56.880978 loss_ctc0 78.149193 lr 0.00187915 rank 0
2022-08-22 17:22:17,442 DEBUG TRAIN Batch 19/5300 loss 45.423725 loss_att 32.570915 loss_ctc 75.413612 loss_ctc_origin 65.545471 loss_ctc0 98.439285 lr 0.00187832 rank 0
2022-08-22 17:22:47,062 DEBUG TRAIN Batch 19/5400 loss 63.213875 loss_att 47.774445 loss_ctc 99.239212 loss_ctc_origin 87.475792 loss_ctc0 126.687195 lr 0.00187749 rank 0
2022-08-22 17:23:14,405 DEBUG TRAIN Batch 19/5500 loss 35.406395 loss_att 27.701351 loss_ctc 53.384834 loss_ctc_origin 53.183064 loss_ctc0 53.855625 lr 0.00187666 rank 0
2022-08-22 17:23:43,341 DEBUG TRAIN Batch 19/5600 loss 36.726089 loss_att 26.246670 loss_ctc 61.178062 loss_ctc_origin 51.339279 loss_ctc0 84.135208 lr 0.00187584 rank 0
2022-08-22 17:24:07,243 DEBUG CV Batch 19/0 loss 20.764809 loss_att 15.626349 loss_ctc 32.754547 loss_ctc_origin 27.756981 loss_ctc0 44.415531 history loss 19.543349 rank 0
2022-08-22 17:24:18,405 DEBUG CV Batch 19/100 loss 31.863291 loss_att 24.567188 loss_ctc 48.887531 loss_ctc_origin 41.862762 loss_ctc0 65.278656 history loss 42.140176 rank 0
2022-08-22 17:24:28,452 DEBUG CV Batch 19/200 loss 41.650925 loss_att 33.135841 loss_ctc 61.519455 loss_ctc_origin 53.874557 loss_ctc0 79.357559 history loss 43.717079 rank 0
2022-08-22 17:24:38,889 DEBUG CV Batch 19/300 loss 39.826553 loss_att 29.711586 loss_ctc 63.428143 loss_ctc_origin 50.767300 loss_ctc0 92.970108 history loss 43.019836 rank 0
2022-08-22 17:24:49,827 DEBUG CV Batch 19/400 loss 58.363785 loss_att 46.092987 loss_ctc 86.995636 loss_ctc_origin 72.869141 loss_ctc0 119.957451 history loss 41.575110 rank 0
2022-08-22 17:25:01,736 DEBUG CV Batch 19/500 loss 25.155827 loss_att 19.025034 loss_ctc 39.461006 loss_ctc_origin 34.645245 loss_ctc0 50.697781 history loss 41.245578 rank 0
2022-08-22 17:25:13,041 DEBUG CV Batch 19/600 loss 29.359880 loss_att 21.604082 loss_ctc 47.456741 loss_ctc_origin 39.703255 loss_ctc0 65.548203 history loss 41.055365 rank 0
2022-08-22 17:25:23,523 DEBUG CV Batch 19/700 loss 34.739250 loss_att 25.494783 loss_ctc 56.309669 loss_ctc_origin 45.497917 loss_ctc0 81.537094 history loss 40.721553 rank 0
2022-08-22 17:25:34,847 DEBUG CV Batch 19/800 loss 38.327675 loss_att 28.818157 loss_ctc 60.516537 loss_ctc_origin 48.014278 loss_ctc0 89.688477 history loss 40.757322 rank 0
2022-08-22 17:25:45,436 INFO Epoch 19 CV info cv_loss 40.96927594203314
2022-08-22 17:25:45,437 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/19.pt
2022-08-22 17:25:45,903 INFO Epoch 20 TRAIN info lr 0.0018751465015433733
2022-08-22 17:25:45,907 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 17:26:14,158 DEBUG TRAIN Batch 20/0 loss 29.526188 loss_att 24.513952 loss_ctc 41.221397 loss_ctc_origin 38.271591 loss_ctc0 48.104279 lr 0.00187511 rank 0
2022-08-22 17:26:43,459 DEBUG TRAIN Batch 20/100 loss 34.116264 loss_att 26.391418 loss_ctc 52.140907 loss_ctc_origin 45.970768 loss_ctc0 66.537888 lr 0.00187429 rank 0
2022-08-22 17:27:13,398 DEBUG TRAIN Batch 20/200 loss 45.454903 loss_att 33.718765 loss_ctc 72.839211 loss_ctc_origin 64.118011 loss_ctc0 93.188667 lr 0.00187347 rank 0
2022-08-22 17:27:42,203 DEBUG TRAIN Batch 20/300 loss 40.783138 loss_att 26.105995 loss_ctc 75.029800 loss_ctc_origin 60.643406 loss_ctc0 108.598038 lr 0.00187265 rank 0
2022-08-22 17:28:12,487 DEBUG TRAIN Batch 20/400 loss 53.628841 loss_att 37.912529 loss_ctc 90.300232 loss_ctc_origin 76.647202 loss_ctc0 122.157280 lr 0.00187183 rank 0
2022-08-22 17:28:42,130 DEBUG TRAIN Batch 20/500 loss 32.671490 loss_att 26.724756 loss_ctc 46.547199 loss_ctc_origin 45.079117 loss_ctc0 49.972725 lr 0.00187101 rank 0
2022-08-22 17:29:12,451 DEBUG TRAIN Batch 20/600 loss 42.346817 loss_att 30.877789 loss_ctc 69.107887 loss_ctc_origin 62.110298 loss_ctc0 85.435600 lr 0.00187019 rank 0
2022-08-22 17:29:41,661 DEBUG TRAIN Batch 20/700 loss 35.970219 loss_att 24.781456 loss_ctc 62.077332 loss_ctc_origin 54.062378 loss_ctc0 80.778885 lr 0.00186937 rank 0
2022-08-22 17:30:09,546 DEBUG TRAIN Batch 20/800 loss 45.449524 loss_att 31.754190 loss_ctc 77.405304 loss_ctc_origin 65.528046 loss_ctc0 105.118896 lr 0.00186856 rank 0
2022-08-22 17:30:37,402 DEBUG TRAIN Batch 20/900 loss 55.804485 loss_att 40.721413 loss_ctc 90.998322 loss_ctc_origin 78.911156 loss_ctc0 119.201706 lr 0.00186774 rank 0
2022-08-22 17:31:05,049 DEBUG TRAIN Batch 20/1000 loss 30.630684 loss_att 25.115265 loss_ctc 43.500000 loss_ctc_origin 40.987701 loss_ctc0 49.362034 lr 0.00186693 rank 0
2022-08-22 17:31:33,498 DEBUG TRAIN Batch 20/1100 loss 34.786774 loss_att 25.494236 loss_ctc 56.469368 loss_ctc_origin 48.032349 loss_ctc0 76.155746 lr 0.00186611 rank 0
2022-08-22 17:32:01,704 DEBUG TRAIN Batch 20/1200 loss 37.696007 loss_att 26.958851 loss_ctc 62.749367 loss_ctc_origin 55.940491 loss_ctc0 78.636734 lr 0.00186530 rank 0
2022-08-22 17:32:31,096 DEBUG TRAIN Batch 20/1300 loss 44.395767 loss_att 31.090462 loss_ctc 75.441483 loss_ctc_origin 66.128075 loss_ctc0 97.172768 lr 0.00186449 rank 0
2022-08-22 17:32:59,505 DEBUG TRAIN Batch 20/1400 loss 61.101887 loss_att 40.318981 loss_ctc 109.595337 loss_ctc_origin 86.713387 loss_ctc0 162.986557 lr 0.00186368 rank 0
2022-08-22 17:33:34,963 DEBUG TRAIN Batch 20/1500 loss 31.556957 loss_att 26.184374 loss_ctc 44.092987 loss_ctc_origin 41.217735 loss_ctc0 50.801903 lr 0.00186287 rank 0
2022-08-22 17:34:05,422 DEBUG TRAIN Batch 20/1600 loss 39.166275 loss_att 29.049938 loss_ctc 62.771065 loss_ctc_origin 51.935768 loss_ctc0 88.053421 lr 0.00186207 rank 0
2022-08-22 17:34:34,952 DEBUG TRAIN Batch 20/1700 loss 37.421803 loss_att 27.842131 loss_ctc 59.774368 loss_ctc_origin 51.920986 loss_ctc0 78.098923 lr 0.00186126 rank 0
2022-08-22 17:35:04,626 DEBUG TRAIN Batch 20/1800 loss 44.420280 loss_att 31.075485 loss_ctc 75.558136 loss_ctc_origin 65.891968 loss_ctc0 98.112518 lr 0.00186045 rank 0
2022-08-22 17:35:35,123 DEBUG TRAIN Batch 20/1900 loss 51.198555 loss_att 37.364750 loss_ctc 83.477425 loss_ctc_origin 69.977562 loss_ctc0 114.977112 lr 0.00185965 rank 0
2022-08-22 17:36:06,490 DEBUG TRAIN Batch 20/2000 loss 33.256905 loss_att 27.150272 loss_ctc 47.505718 loss_ctc_origin 45.120266 loss_ctc0 53.071770 lr 0.00185885 rank 0
2022-08-22 17:36:35,210 DEBUG TRAIN Batch 20/2100 loss 34.214588 loss_att 27.104263 loss_ctc 50.805344 loss_ctc_origin 45.288940 loss_ctc0 63.676956 lr 0.00185804 rank 0
2022-08-22 17:37:04,422 DEBUG TRAIN Batch 20/2200 loss 36.078320 loss_att 25.255814 loss_ctc 61.330833 loss_ctc_origin 53.309395 loss_ctc0 80.047531 lr 0.00185724 rank 0
2022-08-22 17:37:33,311 DEBUG TRAIN Batch 20/2300 loss 48.841110 loss_att 33.800114 loss_ctc 83.936760 loss_ctc_origin 75.228394 loss_ctc0 104.256287 lr 0.00185644 rank 0
2022-08-22 17:38:03,296 DEBUG TRAIN Batch 20/2400 loss 51.612724 loss_att 34.487461 loss_ctc 91.571678 loss_ctc_origin 74.600952 loss_ctc0 131.170044 lr 0.00185564 rank 0
2022-08-22 17:38:32,517 DEBUG TRAIN Batch 20/2500 loss 32.386101 loss_att 26.586050 loss_ctc 45.919556 loss_ctc_origin 42.398804 loss_ctc0 54.134644 lr 0.00185484 rank 0
2022-08-22 17:39:01,366 DEBUG TRAIN Batch 20/2600 loss 33.016682 loss_att 24.935652 loss_ctc 51.872414 loss_ctc_origin 44.695869 loss_ctc0 68.617691 lr 0.00185405 rank 0
2022-08-22 17:39:31,251 DEBUG TRAIN Batch 20/2700 loss 40.086929 loss_att 29.369251 loss_ctc 65.094849 loss_ctc_origin 58.611153 loss_ctc0 80.223488 lr 0.00185325 rank 0
2022-08-22 17:40:02,370 DEBUG TRAIN Batch 20/2800 loss 41.961037 loss_att 28.928844 loss_ctc 72.369492 loss_ctc_origin 61.680256 loss_ctc0 97.311050 lr 0.00185246 rank 0
2022-08-22 17:40:31,382 DEBUG TRAIN Batch 20/2900 loss 53.190754 loss_att 37.983192 loss_ctc 88.675064 loss_ctc_origin 75.142212 loss_ctc0 120.251717 lr 0.00185166 rank 0
2022-08-22 17:41:08,116 DEBUG TRAIN Batch 20/3000 loss 32.742241 loss_att 27.610075 loss_ctc 44.717285 loss_ctc_origin 42.787689 loss_ctc0 49.219669 lr 0.00185087 rank 0
2022-08-22 17:41:37,721 DEBUG TRAIN Batch 20/3100 loss 32.761639 loss_att 24.433125 loss_ctc 52.194839 loss_ctc_origin 45.928215 loss_ctc0 66.816971 lr 0.00185008 rank 0
2022-08-22 17:42:06,663 DEBUG TRAIN Batch 20/3200 loss 38.840912 loss_att 27.305809 loss_ctc 65.756157 loss_ctc_origin 58.645981 loss_ctc0 82.346573 lr 0.00184929 rank 0
2022-08-22 17:42:36,543 DEBUG TRAIN Batch 20/3300 loss 40.938828 loss_att 28.011356 loss_ctc 71.102921 loss_ctc_origin 62.857162 loss_ctc0 90.343040 lr 0.00184850 rank 0
2022-08-22 17:43:06,051 DEBUG TRAIN Batch 20/3400 loss 46.620525 loss_att 31.852375 loss_ctc 81.079544 loss_ctc_origin 70.095329 loss_ctc0 106.709366 lr 0.00184771 rank 0
2022-08-22 17:43:37,308 DEBUG TRAIN Batch 20/3500 loss 26.659582 loss_att 20.472763 loss_ctc 41.095493 loss_ctc_origin 38.808876 loss_ctc0 46.430931 lr 0.00184692 rank 0
2022-08-22 17:44:06,610 DEBUG TRAIN Batch 20/3600 loss 37.377670 loss_att 28.950975 loss_ctc 57.039963 loss_ctc_origin 51.177643 loss_ctc0 70.718719 lr 0.00184613 rank 0
2022-08-22 17:44:36,229 DEBUG TRAIN Batch 20/3700 loss 38.698975 loss_att 28.736572 loss_ctc 61.944569 loss_ctc_origin 54.402653 loss_ctc0 79.542374 lr 0.00184535 rank 0
2022-08-22 17:45:05,390 DEBUG TRAIN Batch 20/3800 loss 43.233772 loss_att 31.401464 loss_ctc 70.842484 loss_ctc_origin 61.112755 loss_ctc0 93.545189 lr 0.00184456 rank 0
2022-08-22 17:45:35,334 DEBUG TRAIN Batch 20/3900 loss 50.104507 loss_att 36.158051 loss_ctc 82.646248 loss_ctc_origin 73.109406 loss_ctc0 104.898888 lr 0.00184378 rank 0
2022-08-22 17:46:03,693 DEBUG TRAIN Batch 20/4000 loss 37.478271 loss_att 29.526421 loss_ctc 56.032597 loss_ctc_origin 50.184273 loss_ctc0 69.678688 lr 0.00184299 rank 0
2022-08-22 17:46:33,011 DEBUG TRAIN Batch 20/4100 loss 40.643017 loss_att 31.398277 loss_ctc 62.214073 loss_ctc_origin 56.184708 loss_ctc0 76.282593 lr 0.00184221 rank 0
2022-08-22 17:47:01,194 DEBUG TRAIN Batch 20/4200 loss 39.479828 loss_att 30.316467 loss_ctc 60.860992 loss_ctc_origin 53.972553 loss_ctc0 76.934006 lr 0.00184143 rank 0
2022-08-22 17:47:32,356 DEBUG TRAIN Batch 20/4300 loss 47.864487 loss_att 34.353539 loss_ctc 79.390038 loss_ctc_origin 71.554626 loss_ctc0 97.672661 lr 0.00184065 rank 0
2022-08-22 17:48:02,098 DEBUG TRAIN Batch 20/4400 loss 45.925919 loss_att 32.248131 loss_ctc 77.840752 loss_ctc_origin 66.769440 loss_ctc0 103.673820 lr 0.00183987 rank 0
2022-08-22 17:48:37,426 DEBUG TRAIN Batch 20/4500 loss 40.115219 loss_att 31.522243 loss_ctc 60.165485 loss_ctc_origin 51.870552 loss_ctc0 79.520325 lr 0.00183909 rank 0
2022-08-22 17:49:06,747 DEBUG TRAIN Batch 20/4600 loss 33.897709 loss_att 26.653090 loss_ctc 50.801826 loss_ctc_origin 45.675816 loss_ctc0 62.762520 lr 0.00183832 rank 0
2022-08-22 17:49:35,684 DEBUG TRAIN Batch 20/4700 loss 40.714226 loss_att 30.536818 loss_ctc 64.461517 loss_ctc_origin 57.454109 loss_ctc0 80.812141 lr 0.00183754 rank 0
2022-08-22 17:50:06,496 DEBUG TRAIN Batch 20/4800 loss 47.374107 loss_att 34.628242 loss_ctc 77.114464 loss_ctc_origin 67.390778 loss_ctc0 99.803078 lr 0.00183676 rank 0
2022-08-22 17:50:36,203 DEBUG TRAIN Batch 20/4900 loss 48.626503 loss_att 33.694889 loss_ctc 83.466934 loss_ctc_origin 72.464722 loss_ctc0 109.138763 lr 0.00183599 rank 0
2022-08-22 17:51:07,666 DEBUG TRAIN Batch 20/5000 loss 39.189140 loss_att 30.265606 loss_ctc 60.010712 loss_ctc_origin 50.981873 loss_ctc0 81.078003 lr 0.00183522 rank 0
2022-08-22 17:51:16,019 WARNING NaN or Inf found in input tensor.
2022-08-22 17:51:37,239 DEBUG TRAIN Batch 20/5100 loss 39.793594 loss_att 28.862583 loss_ctc 65.299278 loss_ctc_origin 53.786163 loss_ctc0 92.163208 lr 0.00183445 rank 0
2022-08-22 17:52:07,070 DEBUG TRAIN Batch 20/5200 loss 40.211109 loss_att 30.570869 loss_ctc 62.705002 loss_ctc_origin 57.764416 loss_ctc0 74.233040 lr 0.00183367 rank 0
2022-08-22 17:52:37,034 DEBUG TRAIN Batch 20/5300 loss 40.426674 loss_att 28.790672 loss_ctc 67.577347 loss_ctc_origin 58.194275 loss_ctc0 89.471176 lr 0.00183290 rank 0
2022-08-22 17:53:07,857 DEBUG TRAIN Batch 20/5400 loss 56.343849 loss_att 41.227890 loss_ctc 91.614418 loss_ctc_origin 81.425217 loss_ctc0 115.389221 lr 0.00183213 rank 0
2022-08-22 17:53:37,929 DEBUG TRAIN Batch 20/5500 loss 33.132729 loss_att 26.305416 loss_ctc 49.063126 loss_ctc_origin 45.912754 loss_ctc0 56.413986 lr 0.00183137 rank 0
2022-08-22 17:54:05,511 DEBUG TRAIN Batch 20/5600 loss 43.076202 loss_att 34.503761 loss_ctc 63.078564 loss_ctc_origin 58.387321 loss_ctc0 74.024796 lr 0.00183060 rank 0
2022-08-22 17:54:29,583 DEBUG CV Batch 20/0 loss 25.016310 loss_att 18.432983 loss_ctc 40.377403 loss_ctc_origin 33.161911 loss_ctc0 57.213554 history loss 23.544762 rank 0
2022-08-22 17:54:41,952 DEBUG CV Batch 20/100 loss 37.177544 loss_att 28.269173 loss_ctc 57.963737 loss_ctc_origin 47.283852 loss_ctc0 82.883484 history loss 41.867268 rank 0
2022-08-22 17:54:51,972 DEBUG CV Batch 20/200 loss 39.603405 loss_att 31.134352 loss_ctc 59.364525 loss_ctc_origin 52.272717 loss_ctc0 75.912071 history loss 43.446175 rank 0
2022-08-22 17:55:02,484 DEBUG CV Batch 20/300 loss 40.155762 loss_att 30.379883 loss_ctc 62.966141 loss_ctc_origin 50.550499 loss_ctc0 91.935959 history loss 42.747790 rank 0
2022-08-22 17:55:13,667 DEBUG CV Batch 20/400 loss 57.175484 loss_att 45.330154 loss_ctc 84.814590 loss_ctc_origin 70.348541 loss_ctc0 118.568710 history loss 41.258678 rank 0
2022-08-22 17:55:24,286 DEBUG CV Batch 20/500 loss 28.534445 loss_att 21.629929 loss_ctc 44.644981 loss_ctc_origin 37.452934 loss_ctc0 61.426426 history loss 41.030850 rank 0
2022-08-22 17:55:35,192 DEBUG CV Batch 20/600 loss 30.313303 loss_att 22.061970 loss_ctc 49.566414 loss_ctc_origin 39.611355 loss_ctc0 72.794891 history loss 40.973181 rank 0
2022-08-22 17:55:45,587 DEBUG CV Batch 20/700 loss 33.258423 loss_att 24.835403 loss_ctc 52.912125 loss_ctc_origin 42.124031 loss_ctc0 78.084335 history loss 40.678765 rank 0
2022-08-22 17:55:56,437 DEBUG CV Batch 20/800 loss 35.655674 loss_att 26.243729 loss_ctc 57.616882 loss_ctc_origin 44.252712 loss_ctc0 88.799950 history loss 40.592644 rank 0
2022-08-22 17:56:07,220 INFO Epoch 20 CV info cv_loss 40.71512793176645
2022-08-22 17:56:07,221 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/20.pt
2022-08-22 17:56:07,727 INFO Epoch 21 TRAIN info lr 0.0018299556076453647
2022-08-22 17:56:07,730 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 17:56:35,951 DEBUG TRAIN Batch 21/0 loss 34.483978 loss_att 25.871115 loss_ctc 54.580658 loss_ctc_origin 52.462429 loss_ctc0 59.523190 lr 0.00182992 rank 0
2022-08-22 17:57:05,908 DEBUG TRAIN Batch 21/100 loss 39.076900 loss_att 26.832670 loss_ctc 67.646767 loss_ctc_origin 57.755295 loss_ctc0 90.726852 lr 0.00182916 rank 0
2022-08-22 17:57:35,004 DEBUG TRAIN Batch 21/200 loss 38.112694 loss_att 28.117147 loss_ctc 61.435627 loss_ctc_origin 53.559837 loss_ctc0 79.812469 lr 0.00182839 rank 0
2022-08-22 17:58:04,147 DEBUG TRAIN Batch 21/300 loss 35.891468 loss_att 23.648621 loss_ctc 64.458115 loss_ctc_origin 54.660107 loss_ctc0 87.320122 lr 0.00182763 rank 0
2022-08-22 17:58:35,173 DEBUG TRAIN Batch 21/400 loss 45.333153 loss_att 31.031746 loss_ctc 78.703102 loss_ctc_origin 67.367043 loss_ctc0 105.153908 lr 0.00182687 rank 0
2022-08-22 17:59:04,324 DEBUG TRAIN Batch 21/500 loss 27.714554 loss_att 22.037342 loss_ctc 40.961384 loss_ctc_origin 35.708061 loss_ctc0 53.219139 lr 0.00182611 rank 0
2022-08-22 17:59:33,018 DEBUG TRAIN Batch 21/600 loss 33.424370 loss_att 26.096693 loss_ctc 50.522282 loss_ctc_origin 43.714462 loss_ctc0 66.407196 lr 0.00182535 rank 0
2022-08-22 18:00:04,289 DEBUG TRAIN Batch 21/700 loss 34.265068 loss_att 24.742931 loss_ctc 56.483383 loss_ctc_origin 48.935913 loss_ctc0 74.094147 lr 0.00182459 rank 0
2022-08-22 18:00:10,136 WARNING NaN or Inf found in input tensor.
2022-08-22 18:00:33,930 DEBUG TRAIN Batch 21/800 loss 44.328945 loss_att 31.250183 loss_ctc 74.846054 loss_ctc_origin 66.576172 loss_ctc0 94.142448 lr 0.00182383 rank 0
2022-08-22 18:01:04,166 DEBUG TRAIN Batch 21/900 loss 45.720947 loss_att 30.327377 loss_ctc 81.639267 loss_ctc_origin 63.532276 loss_ctc0 123.888924 lr 0.00182307 rank 0
2022-08-22 18:01:33,953 DEBUG TRAIN Batch 21/1000 loss 30.759153 loss_att 25.560373 loss_ctc 42.889637 loss_ctc_origin 39.682240 loss_ctc0 50.373569 lr 0.00182231 rank 0
2022-08-22 18:02:03,328 DEBUG TRAIN Batch 21/1100 loss 42.142021 loss_att 30.286888 loss_ctc 69.804001 loss_ctc_origin 64.138405 loss_ctc0 83.023727 lr 0.00182156 rank 0
2022-08-22 18:02:34,200 DEBUG TRAIN Batch 21/1200 loss 27.386248 loss_att 17.937698 loss_ctc 49.432861 loss_ctc_origin 40.804672 loss_ctc0 69.565308 lr 0.00182080 rank 0
2022-08-22 18:03:02,778 DEBUG TRAIN Batch 21/1300 loss 39.658714 loss_att 27.224594 loss_ctc 68.671669 loss_ctc_origin 57.938583 loss_ctc0 93.715546 lr 0.00182005 rank 0
2022-08-22 18:03:30,716 DEBUG TRAIN Batch 21/1400 loss 49.702831 loss_att 34.290482 loss_ctc 85.664978 loss_ctc_origin 76.082977 loss_ctc0 108.022972 lr 0.00181929 rank 0
2022-08-22 18:04:07,171 DEBUG TRAIN Batch 21/1500 loss 33.996822 loss_att 27.351654 loss_ctc 49.502216 loss_ctc_origin 48.021324 loss_ctc0 52.957630 lr 0.00181854 rank 0
2022-08-22 18:04:37,450 DEBUG TRAIN Batch 21/1600 loss 33.469402 loss_att 26.439842 loss_ctc 49.871712 loss_ctc_origin 43.934204 loss_ctc0 63.725891 lr 0.00181779 rank 0
2022-08-22 18:05:07,501 DEBUG TRAIN Batch 21/1700 loss 32.978989 loss_att 23.659668 loss_ctc 54.724075 loss_ctc_origin 46.924568 loss_ctc0 72.922913 lr 0.00181704 rank 0
2022-08-22 18:05:37,128 DEBUG TRAIN Batch 21/1800 loss 49.106453 loss_att 35.348011 loss_ctc 81.209488 loss_ctc_origin 67.699287 loss_ctc0 112.733307 lr 0.00181629 rank 0
2022-08-22 18:06:07,015 DEBUG TRAIN Batch 21/1900 loss 50.826130 loss_att 34.185192 loss_ctc 89.654984 loss_ctc_origin 71.561531 loss_ctc0 131.873047 lr 0.00181554 rank 0
2022-08-22 18:06:35,896 DEBUG TRAIN Batch 21/2000 loss 29.060863 loss_att 21.940502 loss_ctc 45.675034 loss_ctc_origin 43.142590 loss_ctc0 51.584072 lr 0.00181480 rank 0
2022-08-22 18:07:05,261 DEBUG TRAIN Batch 21/2100 loss 32.099861 loss_att 22.650270 loss_ctc 54.148903 loss_ctc_origin 46.724548 loss_ctc0 71.472397 lr 0.00181405 rank 0
2022-08-22 18:07:35,451 DEBUG TRAIN Batch 21/2200 loss 41.184799 loss_att 29.264772 loss_ctc 68.998199 loss_ctc_origin 61.719131 loss_ctc0 85.982674 lr 0.00181330 rank 0
2022-08-22 18:08:05,359 DEBUG TRAIN Batch 21/2300 loss 37.269333 loss_att 25.648468 loss_ctc 64.384689 loss_ctc_origin 53.449043 loss_ctc0 89.901184 lr 0.00181256 rank 0
2022-08-22 18:08:35,775 DEBUG TRAIN Batch 21/2400 loss 47.794159 loss_att 33.187851 loss_ctc 81.875534 loss_ctc_origin 70.791214 loss_ctc0 107.738953 lr 0.00181181 rank 0
2022-08-22 18:09:05,954 DEBUG TRAIN Batch 21/2500 loss 35.527134 loss_att 30.165585 loss_ctc 48.037415 loss_ctc_origin 46.772530 loss_ctc0 50.988819 lr 0.00181107 rank 0
2022-08-22 18:09:35,403 DEBUG TRAIN Batch 21/2600 loss 35.208485 loss_att 27.031019 loss_ctc 54.289234 loss_ctc_origin 46.318779 loss_ctc0 72.886963 lr 0.00181033 rank 0
2022-08-22 18:10:05,580 DEBUG TRAIN Batch 21/2700 loss 37.125565 loss_att 26.430374 loss_ctc 62.081009 loss_ctc_origin 53.399063 loss_ctc0 82.338867 lr 0.00180959 rank 0
2022-08-22 18:10:35,467 DEBUG TRAIN Batch 21/2800 loss 40.219315 loss_att 27.467354 loss_ctc 69.973877 loss_ctc_origin 59.643047 loss_ctc0 94.079132 lr 0.00180885 rank 0
2022-08-22 18:11:04,121 DEBUG TRAIN Batch 21/2900 loss 55.042427 loss_att 39.620224 loss_ctc 91.027565 loss_ctc_origin 78.921021 loss_ctc0 119.276169 lr 0.00180811 rank 0
2022-08-22 18:11:41,678 DEBUG TRAIN Batch 21/3000 loss 27.507832 loss_att 23.115738 loss_ctc 37.756050 loss_ctc_origin 35.568497 loss_ctc0 42.860340 lr 0.00180737 rank 0
2022-08-22 18:12:11,996 DEBUG TRAIN Batch 21/3100 loss 34.631683 loss_att 25.363237 loss_ctc 56.258053 loss_ctc_origin 47.957771 loss_ctc0 75.625381 lr 0.00180663 rank 0
2022-08-22 18:12:41,227 DEBUG TRAIN Batch 21/3200 loss 39.877068 loss_att 29.243286 loss_ctc 64.689217 loss_ctc_origin 57.238697 loss_ctc0 82.073753 lr 0.00180590 rank 0
2022-08-22 18:13:08,645 DEBUG TRAIN Batch 21/3300 loss 41.536545 loss_att 27.960009 loss_ctc 73.215118 loss_ctc_origin 60.147789 loss_ctc0 103.705544 lr 0.00180516 rank 0
2022-08-22 18:13:37,108 DEBUG TRAIN Batch 21/3400 loss 43.175411 loss_att 28.828751 loss_ctc 76.650955 loss_ctc_origin 63.339996 loss_ctc0 107.709869 lr 0.00180443 rank 0
2022-08-22 18:14:06,465 DEBUG TRAIN Batch 21/3500 loss 39.891529 loss_att 32.113388 loss_ctc 58.040520 loss_ctc_origin 55.938133 loss_ctc0 62.946087 lr 0.00180369 rank 0
2022-08-22 18:14:35,244 DEBUG TRAIN Batch 21/3600 loss 36.128212 loss_att 25.104763 loss_ctc 61.849586 loss_ctc_origin 49.406380 loss_ctc0 90.883728 lr 0.00180296 rank 0
2022-08-22 18:15:03,003 DEBUG TRAIN Batch 21/3700 loss 37.347652 loss_att 26.199982 loss_ctc 63.358883 loss_ctc_origin 56.246006 loss_ctc0 79.955597 lr 0.00180223 rank 0
2022-08-22 18:15:32,418 DEBUG TRAIN Batch 21/3800 loss 40.788612 loss_att 28.865349 loss_ctc 68.609558 loss_ctc_origin 59.246269 loss_ctc0 90.457237 lr 0.00180149 rank 0
2022-08-22 18:16:01,199 DEBUG TRAIN Batch 21/3900 loss 50.397964 loss_att 36.416092 loss_ctc 83.022331 loss_ctc_origin 71.539886 loss_ctc0 109.814697 lr 0.00180076 rank 0
2022-08-22 18:16:31,133 DEBUG TRAIN Batch 21/4000 loss 42.538376 loss_att 33.351906 loss_ctc 63.973473 loss_ctc_origin 57.615326 loss_ctc0 78.809158 lr 0.00180003 rank 0
2022-08-22 18:17:00,767 DEBUG TRAIN Batch 21/4100 loss 39.032776 loss_att 28.262045 loss_ctc 64.164482 loss_ctc_origin 50.713844 loss_ctc0 95.549301 lr 0.00179931 rank 0
2022-08-22 18:17:27,963 WARNING NaN or Inf found in input tensor.
2022-08-22 18:17:29,652 DEBUG TRAIN Batch 21/4200 loss 40.762611 loss_att 29.386312 loss_ctc 67.307304 loss_ctc_origin 61.086117 loss_ctc0 81.823410 lr 0.00179858 rank 0
2022-08-22 18:17:58,463 DEBUG TRAIN Batch 21/4300 loss 46.121399 loss_att 32.870552 loss_ctc 77.040039 loss_ctc_origin 69.114899 loss_ctc0 95.532036 lr 0.00179785 rank 0
2022-08-22 18:18:29,174 DEBUG TRAIN Batch 21/4400 loss 45.414017 loss_att 31.593651 loss_ctc 77.661530 loss_ctc_origin 66.577614 loss_ctc0 103.524010 lr 0.00179713 rank 0
2022-08-22 18:19:04,245 DEBUG TRAIN Batch 21/4500 loss 35.899323 loss_att 29.536152 loss_ctc 50.746723 loss_ctc_origin 49.806816 loss_ctc0 52.939850 lr 0.00179640 rank 0
2022-08-22 18:19:32,855 DEBUG TRAIN Batch 21/4600 loss 39.540924 loss_att 26.634151 loss_ctc 69.656723 loss_ctc_origin 54.753647 loss_ctc0 104.430565 lr 0.00179568 rank 0
2022-08-22 18:20:02,786 DEBUG TRAIN Batch 21/4700 loss 33.047211 loss_att 23.129028 loss_ctc 56.189632 loss_ctc_origin 47.668716 loss_ctc0 76.071777 lr 0.00179495 rank 0
2022-08-22 18:20:33,782 DEBUG TRAIN Batch 21/4800 loss 41.121040 loss_att 29.099075 loss_ctc 69.172287 loss_ctc_origin 61.319359 loss_ctc0 87.495789 lr 0.00179423 rank 0
2022-08-22 18:21:03,552 DEBUG TRAIN Batch 21/4900 loss 45.761383 loss_att 30.163786 loss_ctc 82.155777 loss_ctc_origin 70.951630 loss_ctc0 108.298782 lr 0.00179351 rank 0
2022-08-22 18:21:33,628 DEBUG TRAIN Batch 21/5000 loss 33.285328 loss_att 26.664478 loss_ctc 48.733978 loss_ctc_origin 40.718071 loss_ctc0 67.437752 lr 0.00179279 rank 0
2022-08-22 18:21:42,124 WARNING NaN or Inf found in input tensor.
2022-08-22 18:22:03,284 DEBUG TRAIN Batch 21/5100 loss 40.477489 loss_att 29.645580 loss_ctc 65.751945 loss_ctc_origin 55.858055 loss_ctc0 88.837685 lr 0.00179207 rank 0
2022-08-22 18:22:33,823 DEBUG TRAIN Batch 21/5200 loss 31.854164 loss_att 21.937031 loss_ctc 54.994141 loss_ctc_origin 46.224831 loss_ctc0 75.455864 lr 0.00179135 rank 0
2022-08-22 18:23:03,574 DEBUG TRAIN Batch 21/5300 loss 41.295254 loss_att 28.276085 loss_ctc 71.673317 loss_ctc_origin 62.213215 loss_ctc0 93.746880 lr 0.00179063 rank 0
2022-08-22 18:23:33,501 DEBUG TRAIN Batch 21/5400 loss 50.222111 loss_att 35.400719 loss_ctc 84.805359 loss_ctc_origin 73.186340 loss_ctc0 111.916382 lr 0.00178991 rank 0
2022-08-22 18:24:03,350 DEBUG TRAIN Batch 21/5500 loss 33.108845 loss_att 26.940639 loss_ctc 47.501324 loss_ctc_origin 44.463799 loss_ctc0 54.588882 lr 0.00178920 rank 0
2022-08-22 18:24:32,874 DEBUG TRAIN Batch 21/5600 loss 36.904575 loss_att 26.084980 loss_ctc 62.150299 loss_ctc_origin 54.141144 loss_ctc0 80.838318 lr 0.00178848 rank 0
2022-08-22 18:24:56,992 DEBUG CV Batch 21/0 loss 29.440229 loss_att 19.722685 loss_ctc 52.114498 loss_ctc_origin 33.140709 loss_ctc0 96.386673 history loss 27.708451 rank 0
2022-08-22 18:25:08,324 DEBUG CV Batch 21/100 loss 38.566841 loss_att 28.824429 loss_ctc 61.299129 loss_ctc_origin 45.719917 loss_ctc0 97.650627 history loss 41.227707 rank 0
2022-08-22 18:25:18,665 DEBUG CV Batch 21/200 loss 37.027466 loss_att 29.389637 loss_ctc 54.849060 loss_ctc_origin 47.081589 loss_ctc0 72.973152 history loss 42.535024 rank 0
2022-08-22 18:25:29,196 DEBUG CV Batch 21/300 loss 34.459831 loss_att 25.574772 loss_ctc 55.191628 loss_ctc_origin 42.121872 loss_ctc0 85.687714 history loss 41.499389 rank 0
2022-08-22 18:25:40,460 DEBUG CV Batch 21/400 loss 53.202568 loss_att 42.139820 loss_ctc 79.015648 loss_ctc_origin 64.211472 loss_ctc0 113.558731 history loss 39.770626 rank 0
2022-08-22 18:25:52,039 DEBUG CV Batch 21/500 loss 28.877541 loss_att 20.931000 loss_ctc 47.419464 loss_ctc_origin 35.632565 loss_ctc0 74.922226 history loss 39.344870 rank 0
2022-08-22 18:26:03,588 DEBUG CV Batch 21/600 loss 32.859299 loss_att 22.461918 loss_ctc 57.119854 loss_ctc_origin 41.235622 loss_ctc0 94.183060 history loss 39.191979 rank 0
2022-08-22 18:26:14,223 DEBUG CV Batch 21/700 loss 29.959251 loss_att 21.451002 loss_ctc 49.811829 loss_ctc_origin 38.598122 loss_ctc0 75.977150 history loss 38.841579 rank 0
2022-08-22 18:26:25,336 DEBUG CV Batch 21/800 loss 32.382523 loss_att 23.643522 loss_ctc 52.773521 loss_ctc_origin 39.680252 loss_ctc0 83.324478 history loss 38.742533 rank 0
2022-08-22 18:26:36,357 INFO Epoch 21 CV info cv_loss 38.75222353796454
2022-08-22 18:26:36,358 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/21.pt
2022-08-22 18:26:36,832 INFO Epoch 22 TRAIN info lr 0.0017878820385763587
2022-08-22 18:26:36,836 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 18:27:04,540 DEBUG TRAIN Batch 22/0 loss 33.305668 loss_att 27.268621 loss_ctc 47.392105 loss_ctc_origin 42.555649 loss_ctc0 58.677166 lr 0.00178785 rank 0
2022-08-22 18:27:34,613 DEBUG TRAIN Batch 22/100 loss 32.359749 loss_att 24.205414 loss_ctc 51.386539 loss_ctc_origin 43.349335 loss_ctc0 70.140015 lr 0.00178714 rank 0
2022-08-22 18:28:05,390 DEBUG TRAIN Batch 22/200 loss 40.422089 loss_att 27.126966 loss_ctc 71.444038 loss_ctc_origin 65.333420 loss_ctc0 85.702133 lr 0.00178643 rank 0
2022-08-22 18:28:34,064 DEBUG TRAIN Batch 22/300 loss 36.438705 loss_att 23.230022 loss_ctc 67.258965 loss_ctc_origin 58.311974 loss_ctc0 88.135277 lr 0.00178571 rank 0
2022-08-22 18:29:03,088 DEBUG TRAIN Batch 22/400 loss 42.667877 loss_att 28.244020 loss_ctc 76.323532 loss_ctc_origin 64.663376 loss_ctc0 103.530548 lr 0.00178500 rank 0
2022-08-22 18:29:33,102 DEBUG TRAIN Batch 22/500 loss 36.309330 loss_att 29.599007 loss_ctc 51.966743 loss_ctc_origin 51.881878 loss_ctc0 52.164764 lr 0.00178429 rank 0
2022-08-22 18:29:54,508 WARNING NaN or Inf found in input tensor.
2022-08-22 18:30:01,514 DEBUG TRAIN Batch 22/600 loss 37.305634 loss_att 27.805168 loss_ctc 59.473381 loss_ctc_origin 45.707947 loss_ctc0 91.592728 lr 0.00178358 rank 0
2022-08-22 18:30:30,386 DEBUG TRAIN Batch 22/700 loss 30.486803 loss_att 21.358807 loss_ctc 51.785461 loss_ctc_origin 43.705666 loss_ctc0 70.638321 lr 0.00178287 rank 0
2022-08-22 18:30:58,044 DEBUG TRAIN Batch 22/800 loss 39.197308 loss_att 25.890661 loss_ctc 70.246147 loss_ctc_origin 61.190933 loss_ctc0 91.374977 lr 0.00178217 rank 0
2022-08-22 18:31:21,255 WARNING NaN or Inf found in input tensor.
2022-08-22 18:31:26,061 DEBUG TRAIN Batch 22/900 loss 42.281631 loss_att 28.169971 loss_ctc 75.208832 loss_ctc_origin 64.002159 loss_ctc0 101.357742 lr 0.00178146 rank 0
2022-08-22 18:31:54,821 DEBUG TRAIN Batch 22/1000 loss 32.892448 loss_att 24.536053 loss_ctc 52.390701 loss_ctc_origin 49.858791 loss_ctc0 58.298492 lr 0.00178075 rank 0
2022-08-22 18:32:24,740 DEBUG TRAIN Batch 22/1100 loss 39.102783 loss_att 26.754187 loss_ctc 67.916168 loss_ctc_origin 47.248573 loss_ctc0 116.140556 lr 0.00178005 rank 0
2022-08-22 18:32:54,184 DEBUG TRAIN Batch 22/1200 loss 36.879204 loss_att 26.741680 loss_ctc 60.533421 loss_ctc_origin 53.413464 loss_ctc0 77.146652 lr 0.00177934 rank 0
2022-08-22 18:33:24,934 DEBUG TRAIN Batch 22/1300 loss 39.358028 loss_att 26.662897 loss_ctc 68.979996 loss_ctc_origin 60.376682 loss_ctc0 89.054398 lr 0.00177864 rank 0
2022-08-22 18:33:49,680 WARNING NaN or Inf found in input tensor.
2022-08-22 18:33:54,293 DEBUG TRAIN Batch 22/1400 loss 43.139244 loss_att 28.760542 loss_ctc 76.689552 loss_ctc_origin 66.511589 loss_ctc0 100.438126 lr 0.00177794 rank 0
2022-08-22 18:34:30,118 DEBUG TRAIN Batch 22/1500 loss 30.792484 loss_att 24.048483 loss_ctc 46.528488 loss_ctc_origin 40.640808 loss_ctc0 60.266418 lr 0.00177723 rank 0
2022-08-22 18:35:00,390 DEBUG TRAIN Batch 22/1600 loss 36.186195 loss_att 27.871483 loss_ctc 55.587196 loss_ctc_origin 47.025543 loss_ctc0 75.564384 lr 0.00177653 rank 0
2022-08-22 18:35:27,631 WARNING NaN or Inf found in input tensor.
2022-08-22 18:35:29,535 DEBUG TRAIN Batch 22/1700 loss 37.132000 loss_att 27.053698 loss_ctc 60.648037 loss_ctc_origin 52.611511 loss_ctc0 79.399933 lr 0.00177583 rank 0
2022-08-22 18:35:58,874 DEBUG TRAIN Batch 22/1800 loss 44.073555 loss_att 31.714066 loss_ctc 72.912361 loss_ctc_origin 64.238663 loss_ctc0 93.150986 lr 0.00177513 rank 0
2022-08-22 18:36:28,693 DEBUG TRAIN Batch 22/1900 loss 47.318638 loss_att 31.509823 loss_ctc 84.205872 loss_ctc_origin 75.099625 loss_ctc0 105.453789 lr 0.00177443 rank 0
2022-08-22 18:37:00,155 DEBUG TRAIN Batch 22/2000 loss 33.561104 loss_att 26.887493 loss_ctc 49.132866 loss_ctc_origin 44.695923 loss_ctc0 59.485741 lr 0.00177374 rank 0
2022-08-22 18:37:28,368 DEBUG TRAIN Batch 22/2100 loss 40.530624 loss_att 28.157612 loss_ctc 69.400993 loss_ctc_origin 52.124916 loss_ctc0 109.711830 lr 0.00177304 rank 0
2022-08-22 18:37:58,235 DEBUG TRAIN Batch 22/2200 loss 37.128464 loss_att 28.426012 loss_ctc 57.434189 loss_ctc_origin 51.213997 loss_ctc0 71.947968 lr 0.00177234 rank 0
2022-08-22 18:38:27,358 DEBUG TRAIN Batch 22/2300 loss 41.283920 loss_att 29.178020 loss_ctc 69.531021 loss_ctc_origin 60.490318 loss_ctc0 90.625984 lr 0.00177165 rank 0
2022-08-22 18:38:57,459 DEBUG TRAIN Batch 22/2400 loss 40.121201 loss_att 27.138100 loss_ctc 70.415092 loss_ctc_origin 57.342094 loss_ctc0 100.918747 lr 0.00177095 rank 0
2022-08-22 18:39:27,950 DEBUG TRAIN Batch 22/2500 loss 28.205853 loss_att 22.149105 loss_ctc 42.338261 loss_ctc_origin 41.192680 loss_ctc0 45.011284 lr 0.00177026 rank 0
2022-08-22 18:39:43,052 WARNING NaN or Inf found in input tensor.
2022-08-22 18:39:57,597 DEBUG TRAIN Batch 22/2600 loss 31.328888 loss_att 23.211205 loss_ctc 50.270153 loss_ctc_origin 44.477844 loss_ctc0 63.785538 lr 0.00176957 rank 0
2022-08-22 18:40:27,085 DEBUG TRAIN Batch 22/2700 loss 36.662094 loss_att 27.299786 loss_ctc 58.507484 loss_ctc_origin 50.457016 loss_ctc0 77.291901 lr 0.00176887 rank 0
2022-08-22 18:40:44,821 WARNING NaN or Inf found in input tensor.
2022-08-22 18:40:54,964 DEBUG TRAIN Batch 22/2800 loss 37.931892 loss_att 24.205069 loss_ctc 69.961151 loss_ctc_origin 59.797310 loss_ctc0 93.676788 lr 0.00176818 rank 0
2022-08-22 18:41:26,302 DEBUG TRAIN Batch 22/2900 loss 42.901871 loss_att 27.466904 loss_ctc 78.916786 loss_ctc_origin 65.319031 loss_ctc0 110.644882 lr 0.00176749 rank 0
2022-08-22 18:42:01,904 DEBUG TRAIN Batch 22/3000 loss 32.571186 loss_att 23.388752 loss_ctc 53.996864 loss_ctc_origin 42.767338 loss_ctc0 80.199097 lr 0.00176680 rank 0
2022-08-22 18:42:31,678 DEBUG TRAIN Batch 22/3100 loss 43.733307 loss_att 32.673187 loss_ctc 69.540253 loss_ctc_origin 54.971664 loss_ctc0 103.533630 lr 0.00176611 rank 0
2022-08-22 18:43:00,949 DEBUG TRAIN Batch 22/3200 loss 37.912762 loss_att 27.322243 loss_ctc 62.623970 loss_ctc_origin 56.869938 loss_ctc0 76.050049 lr 0.00176542 rank 0
2022-08-22 18:43:31,466 DEBUG TRAIN Batch 22/3300 loss 37.566780 loss_att 26.684437 loss_ctc 62.958904 loss_ctc_origin 54.148468 loss_ctc0 83.516586 lr 0.00176474 rank 0
2022-08-22 18:43:43,241 WARNING NaN or Inf found in input tensor.
2022-08-22 18:44:01,134 DEBUG TRAIN Batch 22/3400 loss 45.800285 loss_att 30.933126 loss_ctc 80.490318 loss_ctc_origin 69.387512 loss_ctc0 106.396866 lr 0.00176405 rank 0
2022-08-22 18:44:30,696 DEBUG TRAIN Batch 22/3500 loss 41.409550 loss_att 34.544750 loss_ctc 57.427414 loss_ctc_origin 55.642563 loss_ctc0 61.592064 lr 0.00176336 rank 0
2022-08-22 18:45:01,091 DEBUG TRAIN Batch 22/3600 loss 39.591042 loss_att 29.737171 loss_ctc 62.583405 loss_ctc_origin 47.140980 loss_ctc0 98.615738 lr 0.00176268 rank 0
2022-08-22 18:45:29,028 WARNING NaN or Inf found in input tensor.
2022-08-22 18:45:30,680 DEBUG TRAIN Batch 22/3700 loss 33.676567 loss_att 24.553080 loss_ctc 54.964714 loss_ctc_origin 47.706818 loss_ctc0 71.899803 lr 0.00176199 rank 0
2022-08-22 18:46:00,627 DEBUG TRAIN Batch 22/3800 loss 41.905453 loss_att 29.479538 loss_ctc 70.899254 loss_ctc_origin 62.507843 loss_ctc0 90.479210 lr 0.00176131 rank 0
2022-08-22 18:46:30,255 DEBUG TRAIN Batch 22/3900 loss 43.536621 loss_att 28.651312 loss_ctc 78.269012 loss_ctc_origin 66.159103 loss_ctc0 106.525467 lr 0.00176063 rank 0
2022-08-22 18:47:00,827 DEBUG TRAIN Batch 22/4000 loss 33.662933 loss_att 28.137636 loss_ctc 46.555290 loss_ctc_origin 45.249290 loss_ctc0 49.602623 lr 0.00175995 rank 0
2022-08-22 18:47:31,266 DEBUG TRAIN Batch 22/4100 loss 37.057663 loss_att 26.050510 loss_ctc 62.741013 loss_ctc_origin 49.462128 loss_ctc0 93.725067 lr 0.00175927 rank 0
2022-08-22 18:47:58,885 DEBUG TRAIN Batch 22/4200 loss 32.449364 loss_att 22.948959 loss_ctc 54.616970 loss_ctc_origin 47.691319 loss_ctc0 70.776825 lr 0.00175859 rank 0
2022-08-22 18:48:30,292 DEBUG TRAIN Batch 22/4300 loss 41.430096 loss_att 28.138180 loss_ctc 72.444565 loss_ctc_origin 64.822792 loss_ctc0 90.228699 lr 0.00175791 rank 0
2022-08-22 18:48:59,265 DEBUG TRAIN Batch 22/4400 loss 43.511639 loss_att 28.867435 loss_ctc 77.681442 loss_ctc_origin 63.716419 loss_ctc0 110.266487 lr 0.00175723 rank 0
2022-08-22 18:49:35,616 DEBUG TRAIN Batch 22/4500 loss 32.224754 loss_att 24.546688 loss_ctc 50.140240 loss_ctc_origin 45.997795 loss_ctc0 59.805946 lr 0.00175655 rank 0
2022-08-22 18:50:05,643 DEBUG TRAIN Batch 22/4600 loss 38.928360 loss_att 28.271227 loss_ctc 63.795010 loss_ctc_origin 49.716171 loss_ctc0 96.645630 lr 0.00175587 rank 0
2022-08-22 18:50:35,172 DEBUG TRAIN Batch 22/4700 loss 39.076363 loss_att 29.165413 loss_ctc 62.201912 loss_ctc_origin 54.449017 loss_ctc0 80.291992 lr 0.00175520 rank 0
2022-08-22 18:51:04,874 DEBUG TRAIN Batch 22/4800 loss 33.537254 loss_att 21.957302 loss_ctc 60.557144 loss_ctc_origin 50.951805 loss_ctc0 82.969589 lr 0.00175452 rank 0
2022-08-22 18:51:33,599 DEBUG TRAIN Batch 22/4900 loss 39.843185 loss_att 25.827259 loss_ctc 72.547012 loss_ctc_origin 59.605751 loss_ctc0 102.743286 lr 0.00175385 rank 0
2022-08-22 18:51:36,206 WARNING NaN or Inf found in input tensor.
2022-08-22 18:52:04,537 DEBUG TRAIN Batch 22/5000 loss 25.950493 loss_att 21.215931 loss_ctc 36.997807 loss_ctc_origin 33.413662 loss_ctc0 45.360809 lr 0.00175317 rank 0
2022-08-22 18:52:33,345 DEBUG TRAIN Batch 22/5100 loss 35.481064 loss_att 27.343073 loss_ctc 54.469711 loss_ctc_origin 44.358044 loss_ctc0 78.063599 lr 0.00175250 rank 0
2022-08-22 18:53:01,687 DEBUG TRAIN Batch 22/5200 loss 34.839790 loss_att 24.400023 loss_ctc 59.199242 loss_ctc_origin 52.508438 loss_ctc0 74.811111 lr 0.00175183 rank 0
2022-08-22 18:53:32,127 DEBUG TRAIN Batch 22/5300 loss 40.256310 loss_att 27.653456 loss_ctc 69.662964 loss_ctc_origin 58.448082 loss_ctc0 95.831024 lr 0.00175116 rank 0
2022-08-22 18:54:02,363 DEBUG TRAIN Batch 22/5400 loss 43.771992 loss_att 30.645981 loss_ctc 74.399345 loss_ctc_origin 61.287064 loss_ctc0 104.994675 lr 0.00175048 rank 0
2022-08-22 18:54:31,723 DEBUG TRAIN Batch 22/5500 loss 27.180847 loss_att 21.900620 loss_ctc 39.501381 loss_ctc_origin 36.451817 loss_ctc0 46.617027 lr 0.00174981 rank 0
2022-08-22 18:55:02,838 DEBUG TRAIN Batch 22/5600 loss 32.514088 loss_att 23.212992 loss_ctc 54.216644 loss_ctc_origin 43.808914 loss_ctc0 78.501358 lr 0.00174914 rank 0
2022-08-22 18:55:27,000 DEBUG CV Batch 22/0 loss 17.686613 loss_att 13.163931 loss_ctc 28.239538 loss_ctc_origin 23.162071 loss_ctc0 40.086960 history loss 16.646224 rank 0
2022-08-22 18:55:38,235 DEBUG CV Batch 22/100 loss 28.410011 loss_att 21.910286 loss_ctc 43.576031 loss_ctc_origin 35.305458 loss_ctc0 62.874035 history loss 35.814659 rank 0
2022-08-22 18:55:48,735 DEBUG CV Batch 22/200 loss 33.613098 loss_att 26.104057 loss_ctc 51.134190 loss_ctc_origin 42.216293 loss_ctc0 71.942612 history loss 37.287479 rank 0
2022-08-22 18:55:59,409 DEBUG CV Batch 22/300 loss 33.885864 loss_att 25.042919 loss_ctc 54.519409 loss_ctc_origin 41.197540 loss_ctc0 85.603760 history loss 36.444348 rank 0
2022-08-22 18:56:10,304 DEBUG CV Batch 22/400 loss 49.837418 loss_att 39.592293 loss_ctc 73.742714 loss_ctc_origin 57.753052 loss_ctc0 111.051918 history loss 34.982735 rank 0
2022-08-22 18:56:21,769 DEBUG CV Batch 22/500 loss 22.843262 loss_att 17.298103 loss_ctc 35.781967 loss_ctc_origin 30.325520 loss_ctc0 48.513672 history loss 34.641595 rank 0
2022-08-22 18:56:32,795 DEBUG CV Batch 22/600 loss 24.976746 loss_att 18.045563 loss_ctc 41.149506 loss_ctc_origin 31.934813 loss_ctc0 62.650452 history loss 34.516408 rank 0
2022-08-22 18:56:43,257 DEBUG CV Batch 22/700 loss 28.209108 loss_att 19.897598 loss_ctc 47.602631 loss_ctc_origin 35.729797 loss_ctc0 75.305908 history loss 34.169350 rank 0
2022-08-22 18:56:54,437 DEBUG CV Batch 22/800 loss 30.957096 loss_att 22.511354 loss_ctc 50.663826 loss_ctc_origin 37.054497 loss_ctc0 82.418930 history loss 34.121638 rank 0
2022-08-22 18:57:05,128 INFO Epoch 22 CV info cv_loss 34.24546255459296
2022-08-22 18:57:05,129 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/22.pt
2022-08-22 18:57:05,627 INFO Epoch 23 TRAIN info lr 0.0017485831288441985
2022-08-22 18:57:05,632 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 18:57:34,742 DEBUG TRAIN Batch 23/0 loss 27.111839 loss_att 21.690502 loss_ctc 39.761627 loss_ctc_origin 37.280869 loss_ctc0 45.550060 lr 0.00174856 rank 0
2022-08-22 18:58:04,218 DEBUG TRAIN Batch 23/100 loss 32.725510 loss_att 24.400757 loss_ctc 52.149937 loss_ctc_origin 45.921829 loss_ctc0 66.682190 lr 0.00174789 rank 0
2022-08-22 18:58:33,396 DEBUG TRAIN Batch 23/200 loss 34.234673 loss_att 24.674963 loss_ctc 56.540649 loss_ctc_origin 48.640556 loss_ctc0 74.974197 lr 0.00174722 rank 0
2022-08-22 18:59:02,899 DEBUG TRAIN Batch 23/300 loss 36.621971 loss_att 23.910191 loss_ctc 66.282784 loss_ctc_origin 53.415741 loss_ctc0 96.305878 lr 0.00174656 rank 0
2022-08-22 18:59:33,987 DEBUG TRAIN Batch 23/400 loss 42.699135 loss_att 28.512058 loss_ctc 75.802307 loss_ctc_origin 65.075737 loss_ctc0 100.830978 lr 0.00174589 rank 0
2022-08-22 19:00:04,323 DEBUG TRAIN Batch 23/500 loss 29.243198 loss_att 23.563343 loss_ctc 42.496193 loss_ctc_origin 38.126751 loss_ctc0 52.691566 lr 0.00174522 rank 0
2022-08-22 19:00:24,478 WARNING NaN or Inf found in input tensor.
2022-08-22 19:00:31,841 DEBUG TRAIN Batch 23/600 loss 46.404861 loss_att 32.472816 loss_ctc 78.912964 loss_ctc_origin 57.858364 loss_ctc0 128.040375 lr 0.00174456 rank 0
2022-08-22 19:01:00,346 DEBUG TRAIN Batch 23/700 loss 36.454720 loss_att 26.478748 loss_ctc 59.731987 loss_ctc_origin 52.084099 loss_ctc0 77.577057 lr 0.00174390 rank 0
2022-08-22 19:01:27,342 DEBUG TRAIN Batch 23/800 loss 35.029816 loss_att 23.354801 loss_ctc 62.271515 loss_ctc_origin 50.914951 loss_ctc0 88.770172 lr 0.00174323 rank 0
2022-08-22 19:01:56,598 DEBUG TRAIN Batch 23/900 loss 48.397659 loss_att 31.216377 loss_ctc 88.487320 loss_ctc_origin 75.734055 loss_ctc0 118.244957 lr 0.00174257 rank 0
2022-08-22 19:02:25,497 DEBUG TRAIN Batch 23/1000 loss 34.299706 loss_att 25.935064 loss_ctc 53.817196 loss_ctc_origin 47.154900 loss_ctc0 69.362549 lr 0.00174191 rank 0
2022-08-22 19:02:52,515 DEBUG TRAIN Batch 23/1100 loss 36.838085 loss_att 26.514217 loss_ctc 60.927109 loss_ctc_origin 48.342861 loss_ctc0 90.290344 lr 0.00174125 rank 0
2022-08-22 19:03:20,845 DEBUG TRAIN Batch 23/1200 loss 32.195110 loss_att 22.195045 loss_ctc 55.528591 loss_ctc_origin 46.278442 loss_ctc0 77.112274 lr 0.00174059 rank 0
2022-08-22 19:03:50,448 DEBUG TRAIN Batch 23/1300 loss 38.602402 loss_att 26.182571 loss_ctc 67.582008 loss_ctc_origin 57.768234 loss_ctc0 90.480812 lr 0.00173993 rank 0
2022-08-22 19:04:18,017 DEBUG TRAIN Batch 23/1400 loss 45.994541 loss_att 30.202967 loss_ctc 82.841545 loss_ctc_origin 72.019356 loss_ctc0 108.093315 lr 0.00173928 rank 0
2022-08-22 19:04:52,594 DEBUG TRAIN Batch 23/1500 loss 28.276161 loss_att 22.106766 loss_ctc 42.671413 loss_ctc_origin 40.545631 loss_ctc0 47.631573 lr 0.00173862 rank 0
2022-08-22 19:05:00,793 WARNING NaN or Inf found in input tensor.
2022-08-22 19:05:21,445 DEBUG TRAIN Batch 23/1600 loss 40.563793 loss_att 30.684437 loss_ctc 63.615623 loss_ctc_origin 52.254143 loss_ctc0 90.125748 lr 0.00173796 rank 0
2022-08-22 19:05:48,590 WARNING NaN or Inf found in input tensor.
2022-08-22 19:05:50,367 DEBUG TRAIN Batch 23/1700 loss 31.782532 loss_att 21.749737 loss_ctc 55.192383 loss_ctc_origin 46.267860 loss_ctc0 76.016273 lr 0.00173731 rank 0
2022-08-22 19:06:18,632 DEBUG TRAIN Batch 23/1800 loss 35.635887 loss_att 23.101028 loss_ctc 64.883896 loss_ctc_origin 55.066811 loss_ctc0 87.790421 lr 0.00173665 rank 0
2022-08-22 19:06:47,589 DEBUG TRAIN Batch 23/1900 loss 45.315483 loss_att 29.728251 loss_ctc 81.685684 loss_ctc_origin 69.176468 loss_ctc0 110.873840 lr 0.00173600 rank 0
2022-08-22 19:07:19,458 DEBUG TRAIN Batch 23/2000 loss 29.320024 loss_att 22.295521 loss_ctc 45.710533 loss_ctc_origin 43.236473 loss_ctc0 51.483330 lr 0.00173534 rank 0
2022-08-22 19:07:46,503 DEBUG TRAIN Batch 23/2100 loss 36.548817 loss_att 25.548134 loss_ctc 62.217072 loss_ctc_origin 51.820190 loss_ctc0 86.476456 lr 0.00173469 rank 0
2022-08-22 19:08:14,713 DEBUG TRAIN Batch 23/2200 loss 34.792397 loss_att 23.614746 loss_ctc 60.873585 loss_ctc_origin 53.905258 loss_ctc0 77.133011 lr 0.00173404 rank 0
2022-08-22 19:08:43,705 DEBUG TRAIN Batch 23/2300 loss 36.587311 loss_att 24.546303 loss_ctc 64.682999 loss_ctc_origin 54.257000 loss_ctc0 89.010330 lr 0.00173339 rank 0
2022-08-22 19:09:10,152 DEBUG TRAIN Batch 23/2400 loss 39.727894 loss_att 26.094130 loss_ctc 71.540009 loss_ctc_origin 58.893448 loss_ctc0 101.048637 lr 0.00173274 rank 0
2022-08-22 19:09:40,009 DEBUG TRAIN Batch 23/2500 loss 25.323355 loss_att 20.026051 loss_ctc 37.683731 loss_ctc_origin 31.680758 loss_ctc0 51.690659 lr 0.00173209 rank 0
2022-08-22 19:10:06,793 DEBUG TRAIN Batch 23/2600 loss 38.453293 loss_att 27.247829 loss_ctc 64.599373 loss_ctc_origin 50.925232 loss_ctc0 96.505699 lr 0.00173144 rank 0
2022-08-22 19:10:35,897 DEBUG TRAIN Batch 23/2700 loss 35.531952 loss_att 24.908943 loss_ctc 60.318962 loss_ctc_origin 51.525925 loss_ctc0 80.836060 lr 0.00173079 rank 0
2022-08-22 19:11:05,641 DEBUG TRAIN Batch 23/2800 loss 38.031616 loss_att 26.752132 loss_ctc 64.350403 loss_ctc_origin 55.827560 loss_ctc0 84.237030 lr 0.00173014 rank 0
2022-08-22 19:11:33,199 DEBUG TRAIN Batch 23/2900 loss 41.152679 loss_att 27.148165 loss_ctc 73.829872 loss_ctc_origin 61.457291 loss_ctc0 102.699226 lr 0.00172949 rank 0
2022-08-22 19:12:07,008 DEBUG TRAIN Batch 23/3000 loss 28.882246 loss_att 21.796978 loss_ctc 45.414539 loss_ctc_origin 39.829323 loss_ctc0 58.446709 lr 0.00172885 rank 0
2022-08-22 19:12:35,625 DEBUG TRAIN Batch 23/3100 loss 32.520943 loss_att 23.103527 loss_ctc 54.494907 loss_ctc_origin 45.489792 loss_ctc0 75.506844 lr 0.00172820 rank 0
2022-08-22 19:13:04,409 DEBUG TRAIN Batch 23/3200 loss 30.355516 loss_att 21.037315 loss_ctc 52.097984 loss_ctc_origin 44.528725 loss_ctc0 69.759583 lr 0.00172756 rank 0
2022-08-22 19:13:33,022 DEBUG TRAIN Batch 23/3300 loss 35.230492 loss_att 22.729786 loss_ctc 64.398804 loss_ctc_origin 54.835724 loss_ctc0 86.712669 lr 0.00172691 rank 0
2022-08-22 19:14:00,618 DEBUG TRAIN Batch 23/3400 loss 36.685287 loss_att 24.481514 loss_ctc 65.160759 loss_ctc_origin 52.515297 loss_ctc0 94.666832 lr 0.00172627 rank 0
2022-08-22 19:14:29,935 DEBUG TRAIN Batch 23/3500 loss 26.049768 loss_att 20.921515 loss_ctc 38.015694 loss_ctc_origin 35.989624 loss_ctc0 42.743198 lr 0.00172563 rank 0
2022-08-22 19:14:58,208 DEBUG TRAIN Batch 23/3600 loss 34.843189 loss_att 24.962627 loss_ctc 57.897835 loss_ctc_origin 46.036972 loss_ctc0 85.573189 lr 0.00172498 rank 0
2022-08-22 19:15:26,910 DEBUG TRAIN Batch 23/3700 loss 31.566196 loss_att 22.226269 loss_ctc 53.359360 loss_ctc_origin 44.602875 loss_ctc0 73.791153 lr 0.00172434 rank 0
2022-08-22 19:15:56,018 DEBUG TRAIN Batch 23/3800 loss 35.543510 loss_att 23.404018 loss_ctc 63.868992 loss_ctc_origin 53.811916 loss_ctc0 87.335495 lr 0.00172370 rank 0
2022-08-22 19:16:25,021 DEBUG TRAIN Batch 23/3900 loss 41.283260 loss_att 26.683449 loss_ctc 75.349487 loss_ctc_origin 62.574898 loss_ctc0 105.156860 lr 0.00172306 rank 0
2022-08-22 19:16:52,624 DEBUG TRAIN Batch 23/4000 loss 27.799337 loss_att 21.394924 loss_ctc 42.742966 loss_ctc_origin 36.405022 loss_ctc0 57.531498 lr 0.00172242 rank 0
2022-08-22 19:17:07,631 WARNING NaN or Inf found in input tensor.
2022-08-22 19:17:22,765 DEBUG TRAIN Batch 23/4100 loss 35.221962 loss_att 26.939102 loss_ctc 54.548637 loss_ctc_origin 43.456635 loss_ctc0 80.429977 lr 0.00172179 rank 0
2022-08-22 19:17:50,725 DEBUG TRAIN Batch 23/4200 loss 32.252132 loss_att 24.062717 loss_ctc 51.360764 loss_ctc_origin 44.169052 loss_ctc0 68.141418 lr 0.00172115 rank 0
2022-08-22 19:18:20,241 DEBUG TRAIN Batch 23/4300 loss 38.086861 loss_att 25.827677 loss_ctc 66.691620 loss_ctc_origin 57.977852 loss_ctc0 87.023758 lr 0.00172051 rank 0
2022-08-22 19:18:48,518 DEBUG TRAIN Batch 23/4400 loss 42.988060 loss_att 28.262581 loss_ctc 77.347504 loss_ctc_origin 63.217991 loss_ctc0 110.316353 lr 0.00171987 rank 0
2022-08-22 19:19:23,297 DEBUG TRAIN Batch 23/4500 loss 29.982441 loss_att 23.992205 loss_ctc 43.959663 loss_ctc_origin 40.087654 loss_ctc0 52.994358 lr 0.00171924 rank 0
2022-08-22 19:19:52,142 DEBUG TRAIN Batch 23/4600 loss 31.176411 loss_att 22.569876 loss_ctc 51.258320 loss_ctc_origin 45.229584 loss_ctc0 65.325371 lr 0.00171860 rank 0
2022-08-22 19:20:21,080 DEBUG TRAIN Batch 23/4700 loss 33.649025 loss_att 24.109694 loss_ctc 55.907471 loss_ctc_origin 48.942303 loss_ctc0 72.159531 lr 0.00171797 rank 0
2022-08-22 19:20:49,323 DEBUG TRAIN Batch 23/4800 loss 38.017803 loss_att 25.423414 loss_ctc 67.404709 loss_ctc_origin 58.389584 loss_ctc0 88.440002 lr 0.00171734 rank 0
2022-08-22 19:21:17,680 DEBUG TRAIN Batch 23/4900 loss 47.202698 loss_att 32.446304 loss_ctc 81.634277 loss_ctc_origin 70.970978 loss_ctc0 106.515305 lr 0.00171670 rank 0
2022-08-22 19:21:46,018 DEBUG TRAIN Batch 23/5000 loss 34.295551 loss_att 27.859964 loss_ctc 49.311920 loss_ctc_origin 48.144306 loss_ctc0 52.036343 lr 0.00171607 rank 0
2022-08-22 19:22:13,883 DEBUG TRAIN Batch 23/5100 loss 29.625366 loss_att 20.641363 loss_ctc 50.588043 loss_ctc_origin 40.777176 loss_ctc0 73.480057 lr 0.00171544 rank 0
2022-08-22 19:22:42,671 DEBUG TRAIN Batch 23/5200 loss 38.495762 loss_att 28.056297 loss_ctc 62.854507 loss_ctc_origin 57.500923 loss_ctc0 75.346199 lr 0.00171481 rank 0
2022-08-22 19:23:10,444 DEBUG TRAIN Batch 23/5300 loss 40.190460 loss_att 27.092594 loss_ctc 70.752144 loss_ctc_origin 60.648136 loss_ctc0 94.328156 lr 0.00171418 rank 0
2022-08-22 19:23:39,461 DEBUG TRAIN Batch 23/5400 loss 48.985882 loss_att 33.679916 loss_ctc 84.699799 loss_ctc_origin 71.993683 loss_ctc0 114.347404 lr 0.00171355 rank 0
2022-08-22 19:24:09,735 DEBUG TRAIN Batch 23/5500 loss 32.277000 loss_att 25.722395 loss_ctc 47.571075 loss_ctc_origin 41.954842 loss_ctc0 60.675621 lr 0.00171292 rank 0
2022-08-22 19:24:22,779 WARNING NaN or Inf found in input tensor.
2022-08-22 19:24:37,474 DEBUG TRAIN Batch 23/5600 loss 47.262566 loss_att 33.987064 loss_ctc 78.238739 loss_ctc_origin 58.949730 loss_ctc0 123.246414 lr 0.00171229 rank 0
2022-08-22 19:25:00,581 DEBUG CV Batch 23/0 loss 27.193525 loss_att 18.291960 loss_ctc 47.963844 loss_ctc_origin 31.071308 loss_ctc0 87.379753 history loss 25.593906 rank 0
2022-08-22 19:25:11,274 DEBUG CV Batch 23/100 loss 45.431038 loss_att 30.156738 loss_ctc 81.071068 loss_ctc_origin 56.156704 loss_ctc0 139.204575 history loss 40.632266 rank 0
2022-08-22 19:25:21,088 DEBUG CV Batch 23/200 loss 33.535774 loss_att 25.721167 loss_ctc 51.769852 loss_ctc_origin 43.485146 loss_ctc0 71.100830 history loss 42.600376 rank 0
2022-08-22 19:25:30,832 DEBUG CV Batch 23/300 loss 31.329479 loss_att 22.561066 loss_ctc 51.789108 loss_ctc_origin 38.543137 loss_ctc0 82.696373 history loss 41.369694 rank 0
2022-08-22 19:25:41,413 DEBUG CV Batch 23/400 loss 49.287060 loss_att 39.553204 loss_ctc 71.999390 loss_ctc_origin 56.700073 loss_ctc0 107.697784 history loss 39.592280 rank 0
2022-08-22 19:25:51,795 DEBUG CV Batch 23/500 loss 31.937279 loss_att 22.016483 loss_ctc 55.085796 loss_ctc_origin 36.219933 loss_ctc0 99.106140 history loss 39.117549 rank 0
2022-08-22 19:26:02,313 DEBUG CV Batch 23/600 loss 41.276718 loss_att 27.180130 loss_ctc 74.168747 loss_ctc_origin 48.616219 loss_ctc0 133.791290 history loss 39.009740 rank 0
2022-08-22 19:26:12,173 DEBUG CV Batch 23/700 loss 28.208622 loss_att 20.644096 loss_ctc 45.859177 loss_ctc_origin 33.991249 loss_ctc0 73.551010 history loss 38.601508 rank 0
2022-08-22 19:26:22,292 DEBUG CV Batch 23/800 loss 28.913349 loss_att 20.681295 loss_ctc 48.121475 loss_ctc_origin 34.265301 loss_ctc0 80.452538 history loss 38.531416 rank 0
2022-08-22 19:26:32,394 INFO Epoch 23 CV info cv_loss 38.4425176227884
2022-08-22 19:26:32,394 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/23.pt
2022-08-22 19:26:32,862 INFO Epoch 24 TRAIN info lr 0.0017117667292036688
2022-08-22 19:26:32,866 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 19:26:59,565 DEBUG TRAIN Batch 24/0 loss 30.925802 loss_att 24.203699 loss_ctc 46.610710 loss_ctc_origin 40.585220 loss_ctc0 60.670177 lr 0.00171174 rank 0
2022-08-22 19:27:00,324 WARNING NaN or Inf found in input tensor.
2022-08-22 19:27:07,409 WARNING NaN or Inf found in input tensor.
2022-08-22 19:27:28,077 DEBUG TRAIN Batch 24/100 loss 37.249420 loss_att 24.637863 loss_ctc 66.676376 loss_ctc_origin 49.061203 loss_ctc0 107.778458 lr 0.00171112 rank 0
2022-08-22 19:27:55,911 DEBUG TRAIN Batch 24/200 loss 32.158260 loss_att 22.714388 loss_ctc 54.193958 loss_ctc_origin 44.963295 loss_ctc0 75.732170 lr 0.00171049 rank 0
2022-08-22 19:28:24,059 DEBUG TRAIN Batch 24/300 loss 33.752384 loss_att 21.375238 loss_ctc 62.632393 loss_ctc_origin 51.436653 loss_ctc0 88.755775 lr 0.00170986 rank 0
2022-08-22 19:28:47,733 WARNING NaN or Inf found in input tensor.
2022-08-22 19:28:52,432 DEBUG TRAIN Batch 24/400 loss 41.279175 loss_att 26.245132 loss_ctc 76.358612 loss_ctc_origin 64.860199 loss_ctc0 103.188232 lr 0.00170924 rank 0
2022-08-22 19:29:21,987 DEBUG TRAIN Batch 24/500 loss 28.519089 loss_att 22.610624 loss_ctc 42.305504 loss_ctc_origin 38.313850 loss_ctc0 51.619370 lr 0.00170862 rank 0
2022-08-22 19:29:50,435 DEBUG TRAIN Batch 24/600 loss 32.949226 loss_att 24.563679 loss_ctc 52.515511 loss_ctc_origin 45.240105 loss_ctc0 69.491463 lr 0.00170799 rank 0
2022-08-22 19:30:17,994 DEBUG TRAIN Batch 24/700 loss 32.388699 loss_att 20.815697 loss_ctc 59.392365 loss_ctc_origin 52.502544 loss_ctc0 75.468605 lr 0.00170737 rank 0
2022-08-22 19:30:45,297 DEBUG TRAIN Batch 24/800 loss 39.315430 loss_att 26.197617 loss_ctc 69.923668 loss_ctc_origin 61.653362 loss_ctc0 89.221054 lr 0.00170675 rank 0
2022-08-22 19:31:13,957 DEBUG TRAIN Batch 24/900 loss 44.125542 loss_att 30.882812 loss_ctc 75.025238 loss_ctc_origin 63.831478 loss_ctc0 101.143997 lr 0.00170613 rank 0
2022-08-22 19:31:41,084 DEBUG TRAIN Batch 24/1000 loss 28.753283 loss_att 22.225286 loss_ctc 43.985271 loss_ctc_origin 41.606892 loss_ctc0 49.534824 lr 0.00170551 rank 0
2022-08-22 19:32:07,984 DEBUG TRAIN Batch 24/1100 loss 36.574684 loss_att 26.960176 loss_ctc 59.008537 loss_ctc_origin 50.518650 loss_ctc0 78.818268 lr 0.00170489 rank 0
2022-08-22 19:32:36,076 DEBUG TRAIN Batch 24/1200 loss 28.932201 loss_att 19.281902 loss_ctc 51.449566 loss_ctc_origin 42.763851 loss_ctc0 71.716232 lr 0.00170427 rank 0
2022-08-22 19:33:04,399 DEBUG TRAIN Batch 24/1300 loss 36.897602 loss_att 23.849306 loss_ctc 67.343628 loss_ctc_origin 56.741276 loss_ctc0 92.082458 lr 0.00170365 rank 0
2022-08-22 19:33:28,448 WARNING NaN or Inf found in input tensor.
2022-08-22 19:33:32,888 DEBUG TRAIN Batch 24/1400 loss 38.113083 loss_att 24.242157 loss_ctc 70.478577 loss_ctc_origin 56.634750 loss_ctc0 102.780838 lr 0.00170303 rank 0
2022-08-22 19:34:07,612 DEBUG TRAIN Batch 24/1500 loss 30.577656 loss_att 25.003710 loss_ctc 43.583534 loss_ctc_origin 39.628834 loss_ctc0 52.811165 lr 0.00170241 rank 0
2022-08-22 19:34:08,443 WARNING NaN or Inf found in input tensor.
2022-08-22 19:34:15,230 WARNING NaN or Inf found in input tensor.
2022-08-22 19:34:36,137 DEBUG TRAIN Batch 24/1600 loss 39.072464 loss_att 26.896185 loss_ctc 67.483772 loss_ctc_origin 57.807983 loss_ctc0 90.060616 lr 0.00170180 rank 0
2022-08-22 19:35:02,282 WARNING NaN or Inf found in input tensor.
2022-08-22 19:35:03,826 DEBUG TRAIN Batch 24/1700 loss 26.989017 loss_att 16.603823 loss_ctc 51.221138 loss_ctc_origin 42.404644 loss_ctc0 71.792961 lr 0.00170118 rank 0
2022-08-22 19:35:33,419 DEBUG TRAIN Batch 24/1800 loss 33.071121 loss_att 21.685938 loss_ctc 59.636539 loss_ctc_origin 50.804806 loss_ctc0 80.243919 lr 0.00170057 rank 0
2022-08-22 19:36:01,138 DEBUG TRAIN Batch 24/1900 loss 46.106266 loss_att 30.662491 loss_ctc 82.141739 loss_ctc_origin 70.392143 loss_ctc0 109.557465 lr 0.00169995 rank 0
2022-08-22 19:36:29,494 DEBUG TRAIN Batch 24/2000 loss 38.423805 loss_att 31.709328 loss_ctc 54.090916 loss_ctc_origin 49.187832 loss_ctc0 65.531448 lr 0.00169934 rank 0
2022-08-22 19:36:57,221 DEBUG TRAIN Batch 24/2100 loss 34.692024 loss_att 24.118326 loss_ctc 59.363983 loss_ctc_origin 45.337296 loss_ctc0 92.092911 lr 0.00169873 rank 0
2022-08-22 19:37:25,041 DEBUG TRAIN Batch 24/2200 loss 34.459049 loss_att 24.507034 loss_ctc 57.680416 loss_ctc_origin 51.704597 loss_ctc0 71.623993 lr 0.00169811 rank 0
2022-08-22 19:37:53,094 DEBUG TRAIN Batch 24/2300 loss 33.528744 loss_att 21.425507 loss_ctc 61.769630 loss_ctc_origin 51.594292 loss_ctc0 85.512085 lr 0.00169750 rank 0
2022-08-22 19:38:21,743 DEBUG TRAIN Batch 24/2400 loss 44.592964 loss_att 30.224546 loss_ctc 78.119263 loss_ctc_origin 65.585167 loss_ctc0 107.365486 lr 0.00169689 rank 0
2022-08-22 19:38:49,249 DEBUG TRAIN Batch 24/2500 loss 32.260109 loss_att 26.244164 loss_ctc 46.297314 loss_ctc_origin 41.734447 loss_ctc0 56.944000 lr 0.00169628 rank 0
2022-08-22 19:39:18,112 DEBUG TRAIN Batch 24/2600 loss 34.494301 loss_att 24.150957 loss_ctc 58.628761 loss_ctc_origin 44.563438 loss_ctc0 91.447845 lr 0.00169567 rank 0
2022-08-22 19:39:46,573 DEBUG TRAIN Batch 24/2700 loss 30.806290 loss_att 22.057096 loss_ctc 51.221077 loss_ctc_origin 42.864838 loss_ctc0 70.718964 lr 0.00169506 rank 0
2022-08-22 19:40:16,293 DEBUG TRAIN Batch 24/2800 loss 35.579350 loss_att 23.284698 loss_ctc 64.266869 loss_ctc_origin 52.902637 loss_ctc0 90.783401 lr 0.00169445 rank 0
2022-08-22 19:40:40,317 WARNING NaN or Inf found in input tensor.
2022-08-22 19:40:44,662 DEBUG TRAIN Batch 24/2900 loss 38.385735 loss_att 24.795685 loss_ctc 70.095848 loss_ctc_origin 58.224602 loss_ctc0 97.795410 lr 0.00169385 rank 0
2022-08-22 19:40:53,109 WARNING NaN or Inf found in input tensor.
2022-08-22 19:41:18,437 DEBUG TRAIN Batch 24/3000 loss 32.197060 loss_att 26.508221 loss_ctc 45.471016 loss_ctc_origin 43.521660 loss_ctc0 50.019508 lr 0.00169324 rank 0
2022-08-22 19:41:46,777 DEBUG TRAIN Batch 24/3100 loss 42.880096 loss_att 32.712521 loss_ctc 66.604431 loss_ctc_origin 57.586582 loss_ctc0 87.646088 lr 0.00169263 rank 0
2022-08-22 19:42:15,649 DEBUG TRAIN Batch 24/3200 loss 30.262115 loss_att 21.336637 loss_ctc 51.088234 loss_ctc_origin 40.880768 loss_ctc0 74.905655 lr 0.00169203 rank 0
2022-08-22 19:42:43,340 DEBUG TRAIN Batch 24/3300 loss 36.874142 loss_att 24.681505 loss_ctc 65.323624 loss_ctc_origin 54.261028 loss_ctc0 91.136337 lr 0.00169142 rank 0
2022-08-22 19:43:12,257 DEBUG TRAIN Batch 24/3400 loss 36.612267 loss_att 23.080170 loss_ctc 68.187149 loss_ctc_origin 54.917770 loss_ctc0 99.149033 lr 0.00169082 rank 0
2022-08-22 19:43:40,835 DEBUG TRAIN Batch 24/3500 loss 24.041027 loss_att 17.719231 loss_ctc 38.791885 loss_ctc_origin 33.260223 loss_ctc0 51.699097 lr 0.00169021 rank 0
2022-08-22 19:44:08,638 DEBUG TRAIN Batch 24/3600 loss 30.470863 loss_att 21.596710 loss_ctc 51.177216 loss_ctc_origin 42.372414 loss_ctc0 71.721764 lr 0.00168961 rank 0
2022-08-22 19:44:38,229 DEBUG TRAIN Batch 24/3700 loss 31.893208 loss_att 21.355484 loss_ctc 56.481224 loss_ctc_origin 48.902248 loss_ctc0 74.165497 lr 0.00168901 rank 0
2022-08-22 19:45:05,960 DEBUG TRAIN Batch 24/3800 loss 37.385750 loss_att 25.921261 loss_ctc 64.136215 loss_ctc_origin 54.815361 loss_ctc0 85.884888 lr 0.00168840 rank 0
2022-08-22 19:45:34,821 DEBUG TRAIN Batch 24/3900 loss 43.141270 loss_att 28.552122 loss_ctc 77.182617 loss_ctc_origin 64.147507 loss_ctc0 107.597885 lr 0.00168780 rank 0
2022-08-22 19:46:02,497 DEBUG TRAIN Batch 24/4000 loss 29.941666 loss_att 23.795918 loss_ctc 44.281746 loss_ctc_origin 41.367088 loss_ctc0 51.082615 lr 0.00168720 rank 0
2022-08-22 19:46:29,358 DEBUG TRAIN Batch 24/4100 loss 40.585510 loss_att 29.083351 loss_ctc 67.423889 loss_ctc_origin 53.427139 loss_ctc0 100.082977 lr 0.00168660 rank 0
2022-08-22 19:46:57,200 DEBUG TRAIN Batch 24/4200 loss 29.863934 loss_att 20.777493 loss_ctc 51.065628 loss_ctc_origin 42.373146 loss_ctc0 71.348091 lr 0.00168600 rank 0
2022-08-22 19:47:25,240 DEBUG TRAIN Batch 24/4300 loss 35.868462 loss_att 25.086063 loss_ctc 61.027390 loss_ctc_origin 52.501312 loss_ctc0 80.921555 lr 0.00168540 rank 0
2022-08-22 19:47:54,209 DEBUG TRAIN Batch 24/4400 loss 35.713551 loss_att 21.939516 loss_ctc 67.852966 loss_ctc_origin 55.495071 loss_ctc0 96.688042 lr 0.00168481 rank 0
2022-08-22 19:48:27,293 DEBUG TRAIN Batch 24/4500 loss 31.923979 loss_att 26.012342 loss_ctc 45.717796 loss_ctc_origin 42.208580 loss_ctc0 53.905968 lr 0.00168421 rank 0
2022-08-22 19:48:55,093 DEBUG TRAIN Batch 24/4600 loss 39.208069 loss_att 27.527946 loss_ctc 66.461693 loss_ctc_origin 51.592712 loss_ctc0 101.155983 lr 0.00168361 rank 0
2022-08-22 19:49:22,605 DEBUG TRAIN Batch 24/4700 loss 37.906570 loss_att 27.217525 loss_ctc 62.847679 loss_ctc_origin 56.016014 loss_ctc0 78.788239 lr 0.00168302 rank 0
2022-08-22 19:49:28,285 WARNING NaN or Inf found in input tensor.
2022-08-22 19:49:50,114 DEBUG TRAIN Batch 24/4800 loss 36.970081 loss_att 24.465694 loss_ctc 66.146980 loss_ctc_origin 55.098595 loss_ctc0 91.926552 lr 0.00168242 rank 0
2022-08-22 19:50:18,101 DEBUG TRAIN Batch 24/4900 loss 45.210854 loss_att 30.425985 loss_ctc 79.708878 loss_ctc_origin 65.278931 loss_ctc0 113.378746 lr 0.00168182 rank 0
2022-08-22 19:50:45,793 DEBUG TRAIN Batch 24/5000 loss 28.718100 loss_att 23.222433 loss_ctc 41.541321 loss_ctc_origin 38.068687 loss_ctc0 49.644135 lr 0.00168123 rank 0
2022-08-22 19:51:13,097 DEBUG TRAIN Batch 24/5100 loss 29.682190 loss_att 20.886293 loss_ctc 50.205948 loss_ctc_origin 40.676422 loss_ctc0 72.441498 lr 0.00168064 rank 0
2022-08-22 19:51:40,406 DEBUG TRAIN Batch 24/5200 loss 31.284760 loss_att 21.846493 loss_ctc 53.307384 loss_ctc_origin 46.753845 loss_ctc0 68.598976 lr 0.00168004 rank 0
2022-08-22 19:52:08,131 DEBUG TRAIN Batch 24/5300 loss 36.017921 loss_att 25.439369 loss_ctc 60.701210 loss_ctc_origin 50.683701 loss_ctc0 84.075394 lr 0.00167945 rank 0
2022-08-22 19:52:37,277 DEBUG TRAIN Batch 24/5400 loss 40.596420 loss_att 26.737499 loss_ctc 72.933907 loss_ctc_origin 60.923927 loss_ctc0 100.957184 lr 0.00167886 rank 0
2022-08-22 19:53:05,153 DEBUG TRAIN Batch 24/5500 loss 31.369907 loss_att 25.277576 loss_ctc 45.585342 loss_ctc_origin 41.970650 loss_ctc0 54.019623 lr 0.00167827 rank 0
2022-08-22 19:53:32,022 DEBUG TRAIN Batch 24/5600 loss 37.375771 loss_att 28.859150 loss_ctc 57.247883 loss_ctc_origin 49.495777 loss_ctc0 75.336121 lr 0.00167768 rank 0
2022-08-22 19:53:54,725 DEBUG CV Batch 24/0 loss 20.201424 loss_att 15.437506 loss_ctc 31.317230 loss_ctc_origin 24.667439 loss_ctc0 46.833412 history loss 19.013105 rank 0
2022-08-22 19:54:05,116 DEBUG CV Batch 24/100 loss 32.803249 loss_att 25.917040 loss_ctc 48.871071 loss_ctc_origin 40.438080 loss_ctc0 68.548050 history loss 35.574149 rank 0
2022-08-22 19:54:15,700 DEBUG CV Batch 24/200 loss 31.768303 loss_att 24.781910 loss_ctc 48.069893 loss_ctc_origin 39.511772 loss_ctc0 68.038849 history loss 36.861069 rank 0
2022-08-22 19:54:26,626 DEBUG CV Batch 24/300 loss 30.896809 loss_att 22.347500 loss_ctc 50.845200 loss_ctc_origin 37.430759 loss_ctc0 82.145554 history loss 35.933156 rank 0
2022-08-22 19:54:35,713 DEBUG CV Batch 24/400 loss 47.573669 loss_att 37.753983 loss_ctc 70.486267 loss_ctc_origin 54.861900 loss_ctc0 106.943138 history loss 34.254953 rank 0
2022-08-22 19:54:45,841 DEBUG CV Batch 24/500 loss 23.577589 loss_att 17.288628 loss_ctc 38.251831 loss_ctc_origin 30.951277 loss_ctc0 55.286453 history loss 33.879563 rank 0
2022-08-22 19:54:56,695 DEBUG CV Batch 24/600 loss 28.348461 loss_att 21.096685 loss_ctc 45.269272 loss_ctc_origin 37.246269 loss_ctc0 63.989609 history loss 33.732903 rank 0
2022-08-22 19:55:06,892 DEBUG CV Batch 24/700 loss 26.459423 loss_att 18.848640 loss_ctc 44.217918 loss_ctc_origin 31.894882 loss_ctc0 72.971664 history loss 33.412675 rank 0
2022-08-22 19:55:17,276 DEBUG CV Batch 24/800 loss 28.646755 loss_att 20.766563 loss_ctc 47.033867 loss_ctc_origin 32.928963 loss_ctc0 79.945312 history loss 33.356518 rank 0
2022-08-22 19:55:27,661 INFO Epoch 24 CV info cv_loss 33.44586802237846
2022-08-22 19:55:27,662 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/24.pt
2022-08-22 19:55:28,182 INFO Epoch 25 TRAIN info lr 0.0016771820180887587
2022-08-22 19:55:28,186 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 19:55:54,946 DEBUG TRAIN Batch 25/0 loss 28.194389 loss_att 22.456959 loss_ctc 41.581730 loss_ctc_origin 38.884605 loss_ctc0 47.875023 lr 0.00167716 rank 0
2022-08-22 19:56:02,575 WARNING NaN or Inf found in input tensor.
2022-08-22 19:56:24,435 DEBUG TRAIN Batch 25/100 loss 38.880196 loss_att 29.655781 loss_ctc 60.403831 loss_ctc_origin 52.564682 loss_ctc0 78.695175 lr 0.00167657 rank 0
2022-08-22 19:56:53,523 DEBUG TRAIN Batch 25/200 loss 35.038136 loss_att 25.018780 loss_ctc 58.416630 loss_ctc_origin 51.582726 loss_ctc0 74.362411 lr 0.00167598 rank 0
2022-08-22 19:57:22,927 DEBUG TRAIN Batch 25/300 loss 33.579094 loss_att 20.993912 loss_ctc 62.944511 loss_ctc_origin 50.925949 loss_ctc0 90.987816 lr 0.00167539 rank 0
2022-08-22 19:57:52,653 DEBUG TRAIN Batch 25/400 loss 36.980339 loss_att 22.926912 loss_ctc 69.771660 loss_ctc_origin 55.447945 loss_ctc0 103.193665 lr 0.00167480 rank 0
2022-08-22 19:58:22,640 DEBUG TRAIN Batch 25/500 loss 33.155617 loss_att 28.825069 loss_ctc 43.260223 loss_ctc_origin 41.680672 loss_ctc0 46.945843 lr 0.00167422 rank 0
2022-08-22 19:58:30,566 WARNING NaN or Inf found in input tensor.
2022-08-22 19:58:52,404 DEBUG TRAIN Batch 25/600 loss 47.860245 loss_att 33.052410 loss_ctc 82.411865 loss_ctc_origin 66.877144 loss_ctc0 118.659561 lr 0.00167363 rank 0
2022-08-22 19:59:22,579 DEBUG TRAIN Batch 25/700 loss 35.326607 loss_att 25.469952 loss_ctc 58.325462 loss_ctc_origin 51.904297 loss_ctc0 73.308174 lr 0.00167305 rank 0
2022-08-22 19:59:50,951 DEBUG TRAIN Batch 25/800 loss 30.601704 loss_att 19.544025 loss_ctc 56.402946 loss_ctc_origin 46.939762 loss_ctc0 78.483704 lr 0.00167246 rank 0
2022-08-22 20:00:21,267 DEBUG TRAIN Batch 25/900 loss 44.766342 loss_att 30.765305 loss_ctc 77.435425 loss_ctc_origin 64.584930 loss_ctc0 107.419922 lr 0.00167188 rank 0
2022-08-22 20:00:51,136 DEBUG TRAIN Batch 25/1000 loss 29.858551 loss_att 22.538570 loss_ctc 46.938507 loss_ctc_origin 44.053921 loss_ctc0 53.669201 lr 0.00167129 rank 0
2022-08-22 20:01:21,153 DEBUG TRAIN Batch 25/1100 loss 44.331223 loss_att 33.422634 loss_ctc 69.784592 loss_ctc_origin 62.941460 loss_ctc0 85.751884 lr 0.00167071 rank 0
2022-08-22 20:01:49,493 WARNING NaN or Inf found in input tensor.
2022-08-22 20:01:51,123 DEBUG TRAIN Batch 25/1200 loss 29.035027 loss_att 19.803955 loss_ctc 50.574196 loss_ctc_origin 41.597542 loss_ctc0 71.519722 lr 0.00167013 rank 0
2022-08-22 20:02:18,503 DEBUG TRAIN Batch 25/1300 loss 39.834377 loss_att 25.868477 loss_ctc 72.421478 loss_ctc_origin 62.127102 loss_ctc0 96.441673 lr 0.00166954 rank 0
2022-08-22 20:02:49,608 DEBUG TRAIN Batch 25/1400 loss 44.815643 loss_att 27.896566 loss_ctc 84.293495 loss_ctc_origin 70.658936 loss_ctc0 116.107468 lr 0.00166896 rank 0
2022-08-22 20:03:25,498 DEBUG TRAIN Batch 25/1500 loss 32.890423 loss_att 24.474689 loss_ctc 52.527138 loss_ctc_origin 48.314728 loss_ctc0 62.356094 lr 0.00166838 rank 0
2022-08-22 20:03:26,317 WARNING NaN or Inf found in input tensor.
2022-08-22 20:03:33,285 WARNING NaN or Inf found in input tensor.
2022-08-22 20:03:54,678 DEBUG TRAIN Batch 25/1600 loss 58.729797 loss_att 38.316513 loss_ctc 106.360794 loss_ctc_origin 74.235260 loss_ctc0 181.320389 lr 0.00166780 rank 0
2022-08-22 20:04:23,925 DEBUG TRAIN Batch 25/1700 loss 34.273811 loss_att 23.160339 loss_ctc 60.205254 loss_ctc_origin 53.671631 loss_ctc0 75.450371 lr 0.00166722 rank 0
2022-08-22 20:04:53,857 DEBUG TRAIN Batch 25/1800 loss 24.888283 loss_att 14.523402 loss_ctc 49.073006 loss_ctc_origin 36.479652 loss_ctc0 78.457489 lr 0.00166664 rank 0
2022-08-22 20:05:24,271 DEBUG TRAIN Batch 25/1900 loss 41.029289 loss_att 26.029474 loss_ctc 76.028854 loss_ctc_origin 62.942158 loss_ctc0 106.564468 lr 0.00166607 rank 0
2022-08-22 20:05:54,517 DEBUG TRAIN Batch 25/2000 loss 30.602621 loss_att 24.703707 loss_ctc 44.366753 loss_ctc_origin 42.864594 loss_ctc0 47.871796 lr 0.00166549 rank 0
2022-08-22 20:06:24,173 DEBUG TRAIN Batch 25/2100 loss 45.389313 loss_att 32.430374 loss_ctc 75.626839 loss_ctc_origin 56.885361 loss_ctc0 119.356949 lr 0.00166491 rank 0
2022-08-22 20:06:54,229 DEBUG TRAIN Batch 25/2200 loss 34.164291 loss_att 24.963795 loss_ctc 55.632114 loss_ctc_origin 48.582848 loss_ctc0 72.080406 lr 0.00166433 rank 0
2022-08-22 20:07:23,580 DEBUG TRAIN Batch 25/2300 loss 36.291805 loss_att 23.715902 loss_ctc 65.635574 loss_ctc_origin 55.171688 loss_ctc0 90.051315 lr 0.00166376 rank 0
2022-08-22 20:07:53,974 DEBUG TRAIN Batch 25/2400 loss 37.204811 loss_att 22.930809 loss_ctc 70.510826 loss_ctc_origin 56.373188 loss_ctc0 103.498642 lr 0.00166318 rank 0
2022-08-22 20:08:25,064 DEBUG TRAIN Batch 25/2500 loss 31.353825 loss_att 26.263851 loss_ctc 43.230431 loss_ctc_origin 43.210102 loss_ctc0 43.277863 lr 0.00166261 rank 0
2022-08-22 20:08:53,420 DEBUG TRAIN Batch 25/2600 loss 49.973495 loss_att 39.737808 loss_ctc 73.856766 loss_ctc_origin 68.300972 loss_ctc0 86.820274 lr 0.00166203 rank 0
2022-08-22 20:09:22,259 DEBUG TRAIN Batch 25/2700 loss 32.505211 loss_att 20.623659 loss_ctc 60.228828 loss_ctc_origin 50.412354 loss_ctc0 83.133926 lr 0.00166146 rank 0
2022-08-22 20:09:51,416 DEBUG TRAIN Batch 25/2800 loss 31.976696 loss_att 20.321995 loss_ctc 59.170998 loss_ctc_origin 50.156116 loss_ctc0 80.205719 lr 0.00166089 rank 0
2022-08-22 20:10:22,114 DEBUG TRAIN Batch 25/2900 loss 44.556480 loss_att 29.725231 loss_ctc 79.162727 loss_ctc_origin 66.181480 loss_ctc0 109.452309 lr 0.00166031 rank 0
2022-08-22 20:10:59,630 DEBUG TRAIN Batch 25/3000 loss 43.518055 loss_att 33.911407 loss_ctc 65.933563 loss_ctc_origin 58.858128 loss_ctc0 82.442917 lr 0.00165974 rank 0
2022-08-22 20:11:00,495 WARNING NaN or Inf found in input tensor.
2022-08-22 20:11:29,113 DEBUG TRAIN Batch 25/3100 loss 50.625206 loss_att 38.537468 loss_ctc 78.829926 loss_ctc_origin 71.784012 loss_ctc0 95.270401 lr 0.00165917 rank 0
2022-08-22 20:11:58,412 DEBUG TRAIN Batch 25/3200 loss 36.298290 loss_att 26.051659 loss_ctc 60.207100 loss_ctc_origin 52.722229 loss_ctc0 77.671791 lr 0.00165860 rank 0
2022-08-22 20:12:28,148 DEBUG TRAIN Batch 25/3300 loss 31.254379 loss_att 20.015419 loss_ctc 57.478615 loss_ctc_origin 47.037849 loss_ctc0 81.840393 lr 0.00165803 rank 0
2022-08-22 20:12:59,124 DEBUG TRAIN Batch 25/3400 loss 33.468727 loss_att 19.791008 loss_ctc 65.383400 loss_ctc_origin 52.211765 loss_ctc0 96.117210 lr 0.00165746 rank 0
2022-08-22 20:13:29,146 DEBUG TRAIN Batch 25/3500 loss 32.115707 loss_att 27.436443 loss_ctc 43.033997 loss_ctc_origin 40.832428 loss_ctc0 48.170990 lr 0.00165689 rank 0
2022-08-22 20:13:58,299 DEBUG TRAIN Batch 25/3600 loss 41.653267 loss_att 31.229965 loss_ctc 65.974297 loss_ctc_origin 59.270897 loss_ctc0 81.615555 lr 0.00165632 rank 0
2022-08-22 20:14:25,184 WARNING NaN or Inf found in input tensor.
2022-08-22 20:14:26,834 DEBUG TRAIN Batch 25/3700 loss 31.256500 loss_att 21.661449 loss_ctc 53.644955 loss_ctc_origin 45.026321 loss_ctc0 73.755096 lr 0.00165576 rank 0
2022-08-22 20:14:56,263 DEBUG TRAIN Batch 25/3800 loss 33.652702 loss_att 21.563656 loss_ctc 61.860474 loss_ctc_origin 52.851192 loss_ctc0 82.882118 lr 0.00165519 rank 0
2022-08-22 20:15:27,517 DEBUG TRAIN Batch 25/3900 loss 48.223907 loss_att 32.839890 loss_ctc 84.119942 loss_ctc_origin 71.502068 loss_ctc0 113.561646 lr 0.00165462 rank 0
2022-08-22 20:15:57,112 DEBUG TRAIN Batch 25/4000 loss 33.904991 loss_att 26.934883 loss_ctc 50.168571 loss_ctc_origin 48.391163 loss_ctc0 54.315865 lr 0.00165406 rank 0
2022-08-22 20:16:26,130 DEBUG TRAIN Batch 25/4100 loss 38.872688 loss_att 30.092308 loss_ctc 59.360241 loss_ctc_origin 55.065201 loss_ctc0 69.382004 lr 0.00165349 rank 0
2022-08-22 20:16:56,574 DEBUG TRAIN Batch 25/4200 loss 32.049644 loss_att 20.964239 loss_ctc 57.915588 loss_ctc_origin 51.089634 loss_ctc0 73.842804 lr 0.00165293 rank 0
2022-08-22 20:17:26,614 DEBUG TRAIN Batch 25/4300 loss 28.964008 loss_att 18.793079 loss_ctc 52.696175 loss_ctc_origin 41.929199 loss_ctc0 77.819122 lr 0.00165236 rank 0
2022-08-22 20:17:55,416 DEBUG TRAIN Batch 25/4400 loss 39.960602 loss_att 26.322441 loss_ctc 71.782967 loss_ctc_origin 59.341293 loss_ctc0 100.813522 lr 0.00165180 rank 0
2022-08-22 20:18:32,241 DEBUG TRAIN Batch 25/4500 loss 34.845001 loss_att 28.733356 loss_ctc 49.105503 loss_ctc_origin 44.739738 loss_ctc0 59.292290 lr 0.00165124 rank 0
2022-08-22 20:19:01,639 DEBUG TRAIN Batch 25/4600 loss 38.838028 loss_att 27.562965 loss_ctc 65.146515 loss_ctc_origin 53.069256 loss_ctc0 93.326782 lr 0.00165067 rank 0
2022-08-22 20:19:31,352 DEBUG TRAIN Batch 25/4700 loss 32.623299 loss_att 21.502117 loss_ctc 58.572716 loss_ctc_origin 50.911453 loss_ctc0 76.449005 lr 0.00165011 rank 0
2022-08-22 20:20:01,334 DEBUG TRAIN Batch 25/4800 loss 35.276398 loss_att 23.166920 loss_ctc 63.531845 loss_ctc_origin 53.181129 loss_ctc0 87.683510 lr 0.00164955 rank 0
2022-08-22 20:20:31,805 DEBUG TRAIN Batch 25/4900 loss 39.475685 loss_att 25.451748 loss_ctc 72.198196 loss_ctc_origin 58.425751 loss_ctc0 104.333900 lr 0.00164899 rank 0
2022-08-22 20:21:02,338 DEBUG TRAIN Batch 25/5000 loss 36.034309 loss_att 29.908913 loss_ctc 50.326893 loss_ctc_origin 46.670696 loss_ctc0 58.858017 lr 0.00164843 rank 0
2022-08-22 20:21:30,321 DEBUG TRAIN Batch 25/5100 loss 52.567291 loss_att 37.951416 loss_ctc 86.671005 loss_ctc_origin 70.185318 loss_ctc0 125.137611 lr 0.00164787 rank 0
2022-08-22 20:21:58,383 DEBUG TRAIN Batch 25/5200 loss 31.825026 loss_att 22.665771 loss_ctc 53.196617 loss_ctc_origin 44.479233 loss_ctc0 73.537186 lr 0.00164731 rank 0
2022-08-22 20:22:26,935 DEBUG TRAIN Batch 25/5300 loss 30.092609 loss_att 18.234165 loss_ctc 57.762314 loss_ctc_origin 46.910343 loss_ctc0 83.083572 lr 0.00164675 rank 0
2022-08-22 20:22:57,454 DEBUG TRAIN Batch 25/5400 loss 38.083805 loss_att 21.988876 loss_ctc 75.638641 loss_ctc_origin 61.156075 loss_ctc0 109.431305 lr 0.00164619 rank 0
2022-08-22 20:23:28,536 DEBUG TRAIN Batch 25/5500 loss 31.623499 loss_att 26.125263 loss_ctc 44.452717 loss_ctc_origin 42.824440 loss_ctc0 48.252029 lr 0.00164564 rank 0
2022-08-22 20:23:58,139 DEBUG TRAIN Batch 25/5600 loss 32.683685 loss_att 24.751532 loss_ctc 51.192043 loss_ctc_origin 43.159145 loss_ctc0 69.935471 lr 0.00164508 rank 0
2022-08-22 20:24:21,344 DEBUG CV Batch 25/0 loss 17.941835 loss_att 13.301090 loss_ctc 28.770239 loss_ctc_origin 24.155869 loss_ctc0 39.537106 history loss 16.886433 rank 0
2022-08-22 20:24:31,388 DEBUG CV Batch 25/100 loss 29.139910 loss_att 22.218433 loss_ctc 45.290020 loss_ctc_origin 37.222267 loss_ctc0 64.114777 history loss 34.767711 rank 0
2022-08-22 20:24:40,603 DEBUG CV Batch 25/200 loss 31.584217 loss_att 23.799278 loss_ctc 49.749069 loss_ctc_origin 41.279305 loss_ctc0 69.511841 history loss 36.102353 rank 0
2022-08-22 20:24:50,357 DEBUG CV Batch 25/300 loss 31.528875 loss_att 22.762535 loss_ctc 51.983669 loss_ctc_origin 38.671089 loss_ctc0 83.046356 history loss 35.094332 rank 0
2022-08-22 20:25:00,779 DEBUG CV Batch 25/400 loss 47.662369 loss_att 37.136513 loss_ctc 72.222702 loss_ctc_origin 56.882477 loss_ctc0 108.016541 history loss 33.544702 rank 0
2022-08-22 20:25:10,463 DEBUG CV Batch 25/500 loss 23.848688 loss_att 18.060310 loss_ctc 37.354904 loss_ctc_origin 31.129444 loss_ctc0 51.880974 history loss 33.216652 rank 0
2022-08-22 20:25:20,703 DEBUG CV Batch 25/600 loss 24.326569 loss_att 17.291365 loss_ctc 40.742043 loss_ctc_origin 32.238731 loss_ctc0 60.583092 history loss 33.114494 rank 0
2022-08-22 20:25:30,305 DEBUG CV Batch 25/700 loss 26.626987 loss_att 18.891802 loss_ctc 44.675755 loss_ctc_origin 32.228043 loss_ctc0 73.720413 history loss 32.758412 rank 0
2022-08-22 20:25:40,334 DEBUG CV Batch 25/800 loss 28.391581 loss_att 20.294426 loss_ctc 47.284943 loss_ctc_origin 33.220036 loss_ctc0 80.103058 history loss 32.709368 rank 0
2022-08-22 20:25:50,254 INFO Epoch 25 CV info cv_loss 32.79773849974027
2022-08-22 20:25:50,255 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/25.pt
2022-08-22 20:25:50,695 INFO Epoch 26 TRAIN info lr 0.001644612276554136
2022-08-22 20:25:50,699 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 20:26:19,100 DEBUG TRAIN Batch 26/0 loss 33.416092 loss_att 27.422920 loss_ctc 47.400154 loss_ctc_origin 44.349625 loss_ctc0 54.518051 lr 0.00164459 rank 0
2022-08-22 20:26:49,459 DEBUG TRAIN Batch 26/100 loss 29.434086 loss_att 21.787132 loss_ctc 47.276978 loss_ctc_origin 39.940529 loss_ctc0 64.395355 lr 0.00164403 rank 0
2022-08-22 20:27:17,462 DEBUG TRAIN Batch 26/200 loss 34.049107 loss_att 24.648750 loss_ctc 55.983269 loss_ctc_origin 49.298576 loss_ctc0 71.580887 lr 0.00164348 rank 0
2022-08-22 20:27:48,069 DEBUG TRAIN Batch 26/300 loss 36.171707 loss_att 21.643028 loss_ctc 70.071960 loss_ctc_origin 58.572224 loss_ctc0 96.904663 lr 0.00164292 rank 0
2022-08-22 20:28:15,369 DEBUG TRAIN Batch 26/400 loss 43.975647 loss_att 27.256710 loss_ctc 82.986496 loss_ctc_origin 67.872391 loss_ctc0 118.252724 lr 0.00164237 rank 0
2022-08-22 20:28:44,985 DEBUG TRAIN Batch 26/500 loss 27.320431 loss_att 21.428307 loss_ctc 41.068722 loss_ctc_origin 38.838078 loss_ctc0 46.273560 lr 0.00164182 rank 0
2022-08-22 20:29:14,492 DEBUG TRAIN Batch 26/600 loss 25.331173 loss_att 18.350439 loss_ctc 41.619553 loss_ctc_origin 32.344505 loss_ctc0 63.261337 lr 0.00164126 rank 0
2022-08-22 20:29:44,019 DEBUG TRAIN Batch 26/700 loss 30.786476 loss_att 19.871452 loss_ctc 56.254868 loss_ctc_origin 45.987350 loss_ctc0 80.212418 lr 0.00164071 rank 0
2022-08-22 20:30:13,312 DEBUG TRAIN Batch 26/800 loss 38.340027 loss_att 24.478069 loss_ctc 70.684601 loss_ctc_origin 60.676960 loss_ctc0 94.035759 lr 0.00164016 rank 0
2022-08-22 20:30:45,670 DEBUG TRAIN Batch 26/900 loss 42.638191 loss_att 26.409994 loss_ctc 80.503983 loss_ctc_origin 64.171700 loss_ctc0 118.612633 lr 0.00163961 rank 0
2022-08-22 20:31:15,547 DEBUG TRAIN Batch 26/1000 loss 25.754044 loss_att 19.314255 loss_ctc 40.780212 loss_ctc_origin 36.971008 loss_ctc0 49.668358 lr 0.00163906 rank 0
2022-08-22 20:31:44,227 DEBUG TRAIN Batch 26/1100 loss 30.902946 loss_att 23.367458 loss_ctc 48.485752 loss_ctc_origin 42.743942 loss_ctc0 61.883308 lr 0.00163851 rank 0
2022-08-22 20:32:12,888 DEBUG TRAIN Batch 26/1200 loss 29.954971 loss_att 21.576721 loss_ctc 49.504223 loss_ctc_origin 42.025440 loss_ctc0 66.954712 lr 0.00163796 rank 0
2022-08-22 20:32:31,809 WARNING NaN or Inf found in input tensor.
2022-08-22 20:32:42,182 DEBUG TRAIN Batch 26/1300 loss 35.822960 loss_att 22.923111 loss_ctc 65.922607 loss_ctc_origin 55.923695 loss_ctc0 89.253410 lr 0.00163741 rank 0
2022-08-22 20:33:12,119 DEBUG TRAIN Batch 26/1400 loss 40.041862 loss_att 26.910044 loss_ctc 70.682770 loss_ctc_origin 57.066689 loss_ctc0 102.453629 lr 0.00163686 rank 0
2022-08-22 20:33:47,811 DEBUG TRAIN Batch 26/1500 loss 33.145203 loss_att 28.824095 loss_ctc 43.227791 loss_ctc_origin 41.410191 loss_ctc0 47.468857 lr 0.00163631 rank 0
2022-08-22 20:34:16,902 DEBUG TRAIN Batch 26/1600 loss 31.741329 loss_att 25.106030 loss_ctc 47.223694 loss_ctc_origin 40.773544 loss_ctc0 62.274033 lr 0.00163577 rank 0
2022-08-22 20:34:46,788 DEBUG TRAIN Batch 26/1700 loss 32.975895 loss_att 22.340683 loss_ctc 57.791382 loss_ctc_origin 49.812981 loss_ctc0 76.407646 lr 0.00163522 rank 0
2022-08-22 20:35:16,234 DEBUG TRAIN Batch 26/1800 loss 33.387814 loss_att 21.709267 loss_ctc 60.637749 loss_ctc_origin 50.421036 loss_ctc0 84.476746 lr 0.00163467 rank 0
2022-08-22 20:35:40,658 WARNING NaN or Inf found in input tensor.
2022-08-22 20:35:45,257 DEBUG TRAIN Batch 26/1900 loss 34.110428 loss_att 21.416431 loss_ctc 63.729752 loss_ctc_origin 50.479134 loss_ctc0 94.647858 lr 0.00163413 rank 0
2022-08-22 20:36:14,602 DEBUG TRAIN Batch 26/2000 loss 30.456017 loss_att 24.771679 loss_ctc 43.719467 loss_ctc_origin 42.691662 loss_ctc0 46.117683 lr 0.00163358 rank 0
2022-08-22 20:36:44,388 DEBUG TRAIN Batch 26/2100 loss 35.329742 loss_att 24.568703 loss_ctc 60.438835 loss_ctc_origin 45.556530 loss_ctc0 95.164215 lr 0.00163304 rank 0
2022-08-22 20:37:13,259 DEBUG TRAIN Batch 26/2200 loss 28.610348 loss_att 18.900827 loss_ctc 51.265892 loss_ctc_origin 41.658768 loss_ctc0 73.682510 lr 0.00163249 rank 0
2022-08-22 20:37:43,293 DEBUG TRAIN Batch 26/2300 loss 31.205688 loss_att 19.157251 loss_ctc 59.318703 loss_ctc_origin 47.618206 loss_ctc0 86.619858 lr 0.00163195 rank 0
2022-08-22 20:38:13,505 DEBUG TRAIN Batch 26/2400 loss 44.208664 loss_att 29.547115 loss_ctc 78.418953 loss_ctc_origin 67.429726 loss_ctc0 104.060478 lr 0.00163141 rank 0
2022-08-22 20:38:43,782 DEBUG TRAIN Batch 26/2500 loss 26.259338 loss_att 20.151585 loss_ctc 40.510765 loss_ctc_origin 38.013741 loss_ctc0 46.337151 lr 0.00163086 rank 0
2022-08-22 20:39:13,821 DEBUG TRAIN Batch 26/2600 loss 31.727160 loss_att 25.086901 loss_ctc 47.221092 loss_ctc_origin 39.802292 loss_ctc0 64.531631 lr 0.00163032 rank 0
2022-08-22 20:39:42,743 DEBUG TRAIN Batch 26/2700 loss 38.411579 loss_att 25.822256 loss_ctc 67.786667 loss_ctc_origin 60.912937 loss_ctc0 83.825363 lr 0.00162978 rank 0
2022-08-22 20:40:11,086 DEBUG TRAIN Batch 26/2800 loss 32.009396 loss_att 19.890324 loss_ctc 60.287231 loss_ctc_origin 48.959679 loss_ctc0 86.718185 lr 0.00162924 rank 0
2022-08-22 20:40:40,198 DEBUG TRAIN Batch 26/2900 loss 40.132736 loss_att 25.513771 loss_ctc 74.243660 loss_ctc_origin 60.657864 loss_ctc0 105.943848 lr 0.00162870 rank 0
2022-08-22 20:41:14,664 DEBUG TRAIN Batch 26/3000 loss 31.883522 loss_att 26.756119 loss_ctc 43.847462 loss_ctc_origin 40.477203 loss_ctc0 51.711399 lr 0.00162816 rank 0
2022-08-22 20:41:44,490 DEBUG TRAIN Batch 26/3100 loss 28.590950 loss_att 19.922001 loss_ctc 48.818497 loss_ctc_origin 41.285110 loss_ctc0 66.396408 lr 0.00162762 rank 0
2022-08-22 20:41:58,203 WARNING NaN or Inf found in input tensor.
2022-08-22 20:42:14,470 DEBUG TRAIN Batch 26/3200 loss 28.404202 loss_att 20.129372 loss_ctc 47.712135 loss_ctc_origin 40.311119 loss_ctc0 64.981171 lr 0.00162708 rank 0
2022-08-22 20:42:44,436 DEBUG TRAIN Batch 26/3300 loss 35.656982 loss_att 21.088230 loss_ctc 69.650734 loss_ctc_origin 59.922680 loss_ctc0 92.349510 lr 0.00162654 rank 0
2022-08-22 20:43:14,016 DEBUG TRAIN Batch 26/3400 loss 36.357159 loss_att 22.776678 loss_ctc 68.044945 loss_ctc_origin 52.507545 loss_ctc0 104.298874 lr 0.00162601 rank 0
2022-08-22 20:43:44,179 DEBUG TRAIN Batch 26/3500 loss 35.385994 loss_att 30.093973 loss_ctc 47.734035 loss_ctc_origin 45.199467 loss_ctc0 53.648033 lr 0.00162547 rank 0
2022-08-22 20:44:14,652 DEBUG TRAIN Batch 26/3600 loss 28.593349 loss_att 20.592276 loss_ctc 47.262520 loss_ctc_origin 39.875587 loss_ctc0 64.498703 lr 0.00162493 rank 0
2022-08-22 20:44:44,495 DEBUG TRAIN Batch 26/3700 loss 35.519047 loss_att 24.793411 loss_ctc 60.545532 loss_ctc_origin 51.336205 loss_ctc0 82.033966 lr 0.00162440 rank 0
2022-08-22 20:45:14,271 DEBUG TRAIN Batch 26/3800 loss 33.172195 loss_att 20.792358 loss_ctc 62.058487 loss_ctc_origin 51.940529 loss_ctc0 85.667053 lr 0.00162386 rank 0
2022-08-22 20:45:44,035 DEBUG TRAIN Batch 26/3900 loss 41.602348 loss_att 26.891979 loss_ctc 75.926544 loss_ctc_origin 59.098476 loss_ctc0 115.192017 lr 0.00162333 rank 0
2022-08-22 20:46:13,184 DEBUG TRAIN Batch 26/4000 loss 23.161442 loss_att 17.636898 loss_ctc 36.052040 loss_ctc_origin 31.844786 loss_ctc0 45.868965 lr 0.00162279 rank 0
2022-08-22 20:46:41,331 DEBUG TRAIN Batch 26/4100 loss 30.087944 loss_att 22.159489 loss_ctc 48.587669 loss_ctc_origin 42.730858 loss_ctc0 62.253563 lr 0.00162226 rank 0
2022-08-22 20:47:11,182 DEBUG TRAIN Batch 26/4200 loss 33.927452 loss_att 23.456537 loss_ctc 58.359573 loss_ctc_origin 50.260044 loss_ctc0 77.258484 lr 0.00162172 rank 0
2022-08-22 20:47:41,411 DEBUG TRAIN Batch 26/4300 loss 35.663048 loss_att 22.331902 loss_ctc 66.769051 loss_ctc_origin 54.816387 loss_ctc0 94.658600 lr 0.00162119 rank 0
2022-08-22 20:48:10,328 DEBUG TRAIN Batch 26/4400 loss 34.160473 loss_att 21.055231 loss_ctc 64.739365 loss_ctc_origin 50.941708 loss_ctc0 96.933899 lr 0.00162066 rank 0
2022-08-22 20:48:47,784 DEBUG TRAIN Batch 26/4500 loss 31.084272 loss_att 24.818958 loss_ctc 45.703339 loss_ctc_origin 44.982864 loss_ctc0 47.384445 lr 0.00162013 rank 0
2022-08-22 20:49:17,185 DEBUG TRAIN Batch 26/4600 loss 36.492439 loss_att 28.956329 loss_ctc 54.076691 loss_ctc_origin 45.646557 loss_ctc0 73.747009 lr 0.00161960 rank 0
2022-08-22 20:49:47,882 DEBUG TRAIN Batch 26/4700 loss 32.132168 loss_att 22.565147 loss_ctc 54.455215 loss_ctc_origin 45.211876 loss_ctc0 76.022995 lr 0.00161906 rank 0
2022-08-22 20:50:16,906 DEBUG TRAIN Batch 26/4800 loss 30.847399 loss_att 19.203268 loss_ctc 58.017036 loss_ctc_origin 46.342739 loss_ctc0 85.257057 lr 0.00161853 rank 0
2022-08-22 20:50:46,768 DEBUG TRAIN Batch 26/4900 loss 44.692844 loss_att 30.205395 loss_ctc 78.496895 loss_ctc_origin 66.072746 loss_ctc0 107.486572 lr 0.00161800 rank 0
2022-08-22 20:51:17,260 DEBUG TRAIN Batch 26/5000 loss 28.426847 loss_att 22.875607 loss_ctc 41.379742 loss_ctc_origin 37.043617 loss_ctc0 51.497360 lr 0.00161748 rank 0
2022-08-22 20:51:46,897 DEBUG TRAIN Batch 26/5100 loss 35.865555 loss_att 26.596992 loss_ctc 57.492191 loss_ctc_origin 49.986763 loss_ctc0 75.004852 lr 0.00161695 rank 0
2022-08-22 20:52:16,165 DEBUG TRAIN Batch 26/5200 loss 31.572062 loss_att 23.054958 loss_ctc 51.445305 loss_ctc_origin 43.315811 loss_ctc0 70.414124 lr 0.00161642 rank 0
2022-08-22 20:52:45,256 DEBUG TRAIN Batch 26/5300 loss 35.879597 loss_att 23.365429 loss_ctc 65.079315 loss_ctc_origin 54.350685 loss_ctc0 90.112778 lr 0.00161589 rank 0
2022-08-22 20:53:15,524 DEBUG TRAIN Batch 26/5400 loss 41.733345 loss_att 26.550369 loss_ctc 77.160294 loss_ctc_origin 64.671677 loss_ctc0 106.300415 lr 0.00161536 rank 0
2022-08-22 20:53:45,129 DEBUG TRAIN Batch 26/5500 loss 27.497265 loss_att 21.238483 loss_ctc 42.101082 loss_ctc_origin 37.776131 loss_ctc0 52.192635 lr 0.00161484 rank 0
2022-08-22 20:54:14,949 DEBUG TRAIN Batch 26/5600 loss 34.071014 loss_att 26.916348 loss_ctc 50.765232 loss_ctc_origin 42.143181 loss_ctc0 70.883347 lr 0.00161431 rank 0
2022-08-22 20:54:39,318 DEBUG CV Batch 26/0 loss 23.864508 loss_att 16.431978 loss_ctc 41.207077 loss_ctc_origin 29.765577 loss_ctc0 67.903915 history loss 22.460713 rank 0
2022-08-22 20:54:49,586 DEBUG CV Batch 26/100 loss 32.529457 loss_att 24.292221 loss_ctc 51.749672 loss_ctc_origin 41.622078 loss_ctc0 75.380722 history loss 36.327836 rank 0
2022-08-22 20:54:59,459 DEBUG CV Batch 26/200 loss 30.391285 loss_att 22.918533 loss_ctc 47.827705 loss_ctc_origin 39.270714 loss_ctc0 67.794006 history loss 38.005255 rank 0
2022-08-22 20:55:09,635 DEBUG CV Batch 26/300 loss 30.672588 loss_att 22.704927 loss_ctc 49.263794 loss_ctc_origin 35.491566 loss_ctc0 81.398994 history loss 36.824452 rank 0
2022-08-22 20:55:19,810 DEBUG CV Batch 26/400 loss 46.097122 loss_att 36.177296 loss_ctc 69.243393 loss_ctc_origin 53.568600 loss_ctc0 105.817902 history loss 35.022212 rank 0
2022-08-22 20:55:31,192 DEBUG CV Batch 26/500 loss 31.628866 loss_att 22.755810 loss_ctc 52.332664 loss_ctc_origin 40.600471 loss_ctc0 79.707771 history loss 34.586716 rank 0
2022-08-22 20:55:41,901 DEBUG CV Batch 26/600 loss 22.855324 loss_att 16.343578 loss_ctc 38.049393 loss_ctc_origin 29.147966 loss_ctc0 58.819386 history loss 34.543093 rank 0
2022-08-22 20:55:52,133 DEBUG CV Batch 26/700 loss 26.473818 loss_att 19.116392 loss_ctc 43.641144 loss_ctc_origin 31.655888 loss_ctc0 71.606750 history loss 34.204517 rank 0
2022-08-22 20:56:02,619 DEBUG CV Batch 26/800 loss 27.461876 loss_att 19.778683 loss_ctc 45.389328 loss_ctc_origin 31.124727 loss_ctc0 78.673401 history loss 34.088738 rank 0
2022-08-22 20:56:13,175 INFO Epoch 26 CV info cv_loss 34.076799683588504
2022-08-22 20:56:13,175 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/26.pt
2022-08-22 20:56:13,678 INFO Epoch 27 TRAIN info lr 0.0016138691493725744
2022-08-22 20:56:13,682 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 20:56:41,785 DEBUG TRAIN Batch 27/0 loss 35.993843 loss_att 30.577995 loss_ctc 48.630821 loss_ctc_origin 46.099274 loss_ctc0 54.537769 lr 0.00161385 rank 0
2022-08-22 20:56:42,666 WARNING NaN or Inf found in input tensor.
2022-08-22 20:57:11,695 DEBUG TRAIN Batch 27/100 loss 31.897348 loss_att 23.055939 loss_ctc 52.527306 loss_ctc_origin 43.516212 loss_ctc0 73.553200 lr 0.00161332 rank 0
2022-08-22 20:57:41,782 DEBUG TRAIN Batch 27/200 loss 33.649712 loss_att 23.699007 loss_ctc 56.868027 loss_ctc_origin 50.192661 loss_ctc0 72.443878 lr 0.00161280 rank 0
2022-08-22 20:58:12,469 DEBUG TRAIN Batch 27/300 loss 35.613068 loss_att 21.907782 loss_ctc 67.592064 loss_ctc_origin 56.249119 loss_ctc0 94.058945 lr 0.00161227 rank 0
2022-08-22 20:58:36,782 WARNING NaN or Inf found in input tensor.
2022-08-22 20:58:41,498 DEBUG TRAIN Batch 27/400 loss 33.372719 loss_att 19.560114 loss_ctc 65.602119 loss_ctc_origin 49.547157 loss_ctc0 103.063698 lr 0.00161175 rank 0
2022-08-22 20:59:11,045 DEBUG TRAIN Batch 27/500 loss 35.912476 loss_att 26.874069 loss_ctc 57.002090 loss_ctc_origin 51.025932 loss_ctc0 70.946457 lr 0.00161123 rank 0
2022-08-22 20:59:31,485 WARNING NaN or Inf found in input tensor.
2022-08-22 20:59:38,811 DEBUG TRAIN Batch 27/600 loss 36.037529 loss_att 25.734062 loss_ctc 60.078941 loss_ctc_origin 49.573963 loss_ctc0 84.590561 lr 0.00161070 rank 0
2022-08-22 21:00:07,709 DEBUG TRAIN Batch 27/700 loss 28.819874 loss_att 20.009672 loss_ctc 49.377010 loss_ctc_origin 40.424133 loss_ctc0 70.267059 lr 0.00161018 rank 0
2022-08-22 21:00:38,103 DEBUG TRAIN Batch 27/800 loss 35.162300 loss_att 21.618418 loss_ctc 66.764687 loss_ctc_origin 57.976593 loss_ctc0 87.270233 lr 0.00160966 rank 0
2022-08-22 21:01:07,996 DEBUG TRAIN Batch 27/900 loss 35.737617 loss_att 21.205231 loss_ctc 69.646523 loss_ctc_origin 56.175209 loss_ctc0 101.079590 lr 0.00160914 rank 0
2022-08-22 21:01:36,129 DEBUG TRAIN Batch 27/1000 loss 27.621866 loss_att 22.637600 loss_ctc 39.251820 loss_ctc_origin 35.420006 loss_ctc0 48.192711 lr 0.00160862 rank 0
2022-08-22 21:02:05,295 DEBUG TRAIN Batch 27/1100 loss 30.521782 loss_att 22.807789 loss_ctc 48.521095 loss_ctc_origin 42.308914 loss_ctc0 63.016174 lr 0.00160810 rank 0
2022-08-22 21:02:32,361 DEBUG TRAIN Batch 27/1200 loss 34.150009 loss_att 23.864868 loss_ctc 58.148674 loss_ctc_origin 50.701824 loss_ctc0 75.524658 lr 0.00160758 rank 0
2022-08-22 21:03:00,927 DEBUG TRAIN Batch 27/1300 loss 32.351715 loss_att 20.597164 loss_ctc 59.778992 loss_ctc_origin 48.733276 loss_ctc0 85.552322 lr 0.00160706 rank 0
2022-08-22 21:03:24,096 WARNING NaN or Inf found in input tensor.
2022-08-22 21:03:28,821 DEBUG TRAIN Batch 27/1400 loss 32.198612 loss_att 19.384762 loss_ctc 62.097599 loss_ctc_origin 49.194290 loss_ctc0 92.205322 lr 0.00160654 rank 0
2022-08-22 21:04:01,746 DEBUG TRAIN Batch 27/1500 loss 28.023832 loss_att 22.897350 loss_ctc 39.985622 loss_ctc_origin 39.474869 loss_ctc0 41.177380 lr 0.00160602 rank 0
2022-08-22 21:04:30,439 DEBUG TRAIN Batch 27/1600 loss 33.044712 loss_att 25.244051 loss_ctc 51.246254 loss_ctc_origin 44.899048 loss_ctc0 66.056396 lr 0.00160551 rank 0
2022-08-22 21:04:57,949 DEBUG TRAIN Batch 27/1700 loss 27.286480 loss_att 17.067791 loss_ctc 51.130089 loss_ctc_origin 41.777084 loss_ctc0 72.953766 lr 0.00160499 rank 0
2022-08-22 21:05:25,830 DEBUG TRAIN Batch 27/1800 loss 32.553017 loss_att 20.732548 loss_ctc 60.134109 loss_ctc_origin 48.999367 loss_ctc0 86.115173 lr 0.00160447 rank 0
2022-08-22 21:05:53,018 DEBUG TRAIN Batch 27/1900 loss 37.882439 loss_att 23.449150 loss_ctc 71.560120 loss_ctc_origin 60.424271 loss_ctc0 97.543777 lr 0.00160396 rank 0
2022-08-22 21:06:21,360 DEBUG TRAIN Batch 27/2000 loss 42.777542 loss_att 34.986580 loss_ctc 60.956459 loss_ctc_origin 53.175713 loss_ctc0 79.111526 lr 0.00160344 rank 0
2022-08-22 21:06:48,893 DEBUG TRAIN Batch 27/2100 loss 60.759964 loss_att 38.039848 loss_ctc 113.773567 loss_ctc_origin 76.679550 loss_ctc0 200.326263 lr 0.00160293 rank 0
2022-08-22 21:07:15,492 WARNING NaN or Inf found in input tensor.
2022-08-22 21:07:17,196 DEBUG TRAIN Batch 27/2200 loss 28.909756 loss_att 19.361893 loss_ctc 51.188103 loss_ctc_origin 41.847137 loss_ctc0 72.983688 lr 0.00160241 rank 0
2022-08-22 21:07:45,530 DEBUG TRAIN Batch 27/2300 loss 34.627888 loss_att 22.019241 loss_ctc 64.048065 loss_ctc_origin 52.822563 loss_ctc0 90.240921 lr 0.00160190 rank 0
2022-08-22 21:08:14,014 DEBUG TRAIN Batch 27/2400 loss 35.857697 loss_att 22.597006 loss_ctc 66.799301 loss_ctc_origin 54.223465 loss_ctc0 96.142914 lr 0.00160138 rank 0
2022-08-22 21:08:41,616 DEBUG TRAIN Batch 27/2500 loss 34.280151 loss_att 27.827003 loss_ctc 49.337498 loss_ctc_origin 44.662556 loss_ctc0 60.245693 lr 0.00160087 rank 0
2022-08-22 21:08:53,559 WARNING NaN or Inf found in input tensor.
2022-08-22 21:09:08,256 DEBUG TRAIN Batch 27/2600 loss 40.294853 loss_att 30.149521 loss_ctc 63.967300 loss_ctc_origin 57.423050 loss_ctc0 79.237221 lr 0.00160036 rank 0
2022-08-22 21:09:35,881 DEBUG TRAIN Batch 27/2700 loss 29.568592 loss_att 18.740280 loss_ctc 54.834656 loss_ctc_origin 45.860771 loss_ctc0 75.773727 lr 0.00159985 rank 0
2022-08-22 21:10:04,150 DEBUG TRAIN Batch 27/2800 loss 34.038113 loss_att 21.774313 loss_ctc 62.653641 loss_ctc_origin 51.547760 loss_ctc0 88.567360 lr 0.00159933 rank 0
2022-08-22 21:10:19,148 WARNING NaN or Inf found in input tensor.
2022-08-22 21:10:26,594 WARNING NaN or Inf found in input tensor.
2022-08-22 21:10:31,241 DEBUG TRAIN Batch 27/2900 loss 33.170097 loss_att 20.912281 loss_ctc 61.771667 loss_ctc_origin 48.293167 loss_ctc0 93.221497 lr 0.00159882 rank 0
2022-08-22 21:11:05,334 DEBUG TRAIN Batch 27/3000 loss 38.958336 loss_att 32.690094 loss_ctc 53.584236 loss_ctc_origin 51.150681 loss_ctc0 59.262520 lr 0.00159831 rank 0
2022-08-22 21:11:33,280 DEBUG TRAIN Batch 27/3100 loss 34.869164 loss_att 25.505863 loss_ctc 56.716869 loss_ctc_origin 42.772064 loss_ctc0 89.254745 lr 0.00159780 rank 0
2022-08-22 21:12:01,397 DEBUG TRAIN Batch 27/3200 loss 32.825520 loss_att 22.770927 loss_ctc 56.286232 loss_ctc_origin 48.660713 loss_ctc0 74.079102 lr 0.00159729 rank 0
2022-08-22 21:12:29,334 DEBUG TRAIN Batch 27/3300 loss 27.397558 loss_att 16.083736 loss_ctc 53.796474 loss_ctc_origin 42.778633 loss_ctc0 79.504768 lr 0.00159678 rank 0
2022-08-22 21:12:57,308 DEBUG TRAIN Batch 27/3400 loss 37.822285 loss_att 24.217690 loss_ctc 69.566338 loss_ctc_origin 55.691959 loss_ctc0 101.939880 lr 0.00159628 rank 0
2022-08-22 21:13:25,193 DEBUG TRAIN Batch 27/3500 loss 34.251461 loss_att 30.329279 loss_ctc 43.403217 loss_ctc_origin 42.972172 loss_ctc0 44.408989 lr 0.00159577 rank 0
2022-08-22 21:13:33,003 WARNING NaN or Inf found in input tensor.
2022-08-22 21:13:52,222 DEBUG TRAIN Batch 27/3600 loss 39.724289 loss_att 25.764507 loss_ctc 72.297119 loss_ctc_origin 50.797821 loss_ctc0 122.462158 lr 0.00159526 rank 0
2022-08-22 21:14:19,903 DEBUG TRAIN Batch 27/3700 loss 30.571047 loss_att 21.895699 loss_ctc 50.813522 loss_ctc_origin 41.962654 loss_ctc0 71.465538 lr 0.00159475 rank 0
2022-08-22 21:14:47,948 DEBUG TRAIN Batch 27/3800 loss 33.367149 loss_att 21.144222 loss_ctc 61.887306 loss_ctc_origin 51.103439 loss_ctc0 87.049667 lr 0.00159425 rank 0
2022-08-22 21:15:17,015 DEBUG TRAIN Batch 27/3900 loss 35.444778 loss_att 21.526257 loss_ctc 67.921333 loss_ctc_origin 52.619949 loss_ctc0 103.624557 lr 0.00159374 rank 0
2022-08-22 21:15:45,106 DEBUG TRAIN Batch 27/4000 loss 27.302917 loss_att 20.421906 loss_ctc 43.358612 loss_ctc_origin 39.533333 loss_ctc0 52.284271 lr 0.00159323 rank 0
2022-08-22 21:15:59,085 WARNING NaN or Inf found in input tensor.
2022-08-22 21:16:13,264 DEBUG TRAIN Batch 27/4100 loss 33.438911 loss_att 24.208469 loss_ctc 54.976608 loss_ctc_origin 45.966022 loss_ctc0 76.001305 lr 0.00159273 rank 0
2022-08-22 21:16:41,320 DEBUG TRAIN Batch 27/4200 loss 34.150002 loss_att 25.197725 loss_ctc 55.038651 loss_ctc_origin 47.141560 loss_ctc0 73.465195 lr 0.00159222 rank 0
2022-08-22 21:17:10,564 DEBUG TRAIN Batch 27/4300 loss 31.452433 loss_att 20.350264 loss_ctc 57.357491 loss_ctc_origin 46.071342 loss_ctc0 83.691826 lr 0.00159172 rank 0
2022-08-22 21:17:37,988 DEBUG TRAIN Batch 27/4400 loss 38.057320 loss_att 23.715256 loss_ctc 71.522141 loss_ctc_origin 56.167259 loss_ctc0 107.350189 lr 0.00159122 rank 0
2022-08-22 21:18:10,600 DEBUG TRAIN Batch 27/4500 loss 27.477047 loss_att 21.746029 loss_ctc 40.849419 loss_ctc_origin 39.501366 loss_ctc0 43.994873 lr 0.00159071 rank 0
2022-08-22 21:18:39,525 DEBUG TRAIN Batch 27/4600 loss 29.217314 loss_att 21.710011 loss_ctc 46.734352 loss_ctc_origin 38.252853 loss_ctc0 66.524521 lr 0.00159021 rank 0
2022-08-22 21:19:07,762 DEBUG TRAIN Batch 27/4700 loss 31.810612 loss_att 21.396511 loss_ctc 56.110176 loss_ctc_origin 48.187599 loss_ctc0 74.596191 lr 0.00158971 rank 0
2022-08-22 21:19:35,669 DEBUG TRAIN Batch 27/4800 loss 35.445541 loss_att 21.978607 loss_ctc 66.868378 loss_ctc_origin 53.183105 loss_ctc0 98.800690 lr 0.00158920 rank 0
2022-08-22 21:20:03,439 DEBUG TRAIN Batch 27/4900 loss 34.442902 loss_att 21.530392 loss_ctc 64.572083 loss_ctc_origin 48.871468 loss_ctc0 101.206863 lr 0.00158870 rank 0
2022-08-22 21:20:33,766 DEBUG TRAIN Batch 27/5000 loss 35.225159 loss_att 27.885916 loss_ctc 52.350052 loss_ctc_origin 48.763905 loss_ctc0 60.717724 lr 0.00158820 rank 0
2022-08-22 21:21:00,832 DEBUG TRAIN Batch 27/5100 loss 31.427444 loss_att 24.093269 loss_ctc 48.540524 loss_ctc_origin 42.018787 loss_ctc0 63.757904 lr 0.00158770 rank 0
2022-08-22 21:21:29,021 DEBUG TRAIN Batch 27/5200 loss 35.162819 loss_att 25.318979 loss_ctc 58.131779 loss_ctc_origin 48.560337 loss_ctc0 80.465134 lr 0.00158720 rank 0
2022-08-22 21:21:45,058 WARNING NaN or Inf found in input tensor.
2022-08-22 21:21:55,501 DEBUG TRAIN Batch 27/5300 loss 32.737598 loss_att 21.842903 loss_ctc 58.158546 loss_ctc_origin 46.890755 loss_ctc0 84.450058 lr 0.00158670 rank 0
2022-08-22 21:22:24,371 DEBUG TRAIN Batch 27/5400 loss 34.095993 loss_att 20.600445 loss_ctc 65.585609 loss_ctc_origin 52.346397 loss_ctc0 96.477104 lr 0.00158620 rank 0
2022-08-22 21:22:52,036 DEBUG TRAIN Batch 27/5500 loss 33.022469 loss_att 26.689829 loss_ctc 47.798622 loss_ctc_origin 47.275963 loss_ctc0 49.018166 lr 0.00158570 rank 0
2022-08-22 21:23:20,046 DEBUG TRAIN Batch 27/5600 loss 31.295351 loss_att 23.173038 loss_ctc 50.247414 loss_ctc_origin 41.502640 loss_ctc0 70.651878 lr 0.00158521 rank 0
2022-08-22 21:23:43,738 DEBUG CV Batch 27/0 loss 26.119217 loss_att 19.141705 loss_ctc 42.400078 loss_ctc_origin 36.023483 loss_ctc0 57.278797 history loss 24.582792 rank 0
2022-08-22 21:23:53,902 DEBUG CV Batch 27/100 loss 25.711531 loss_att 19.092648 loss_ctc 41.155590 loss_ctc_origin 31.827263 loss_ctc0 62.921688 history loss 35.037941 rank 0
2022-08-22 21:24:03,206 DEBUG CV Batch 27/200 loss 33.465874 loss_att 25.970493 loss_ctc 50.955093 loss_ctc_origin 42.660908 loss_ctc0 70.308197 history loss 36.357075 rank 0
2022-08-22 21:24:12,947 DEBUG CV Batch 27/300 loss 29.434507 loss_att 21.041899 loss_ctc 49.017258 loss_ctc_origin 34.409134 loss_ctc0 83.102875 history loss 35.415806 rank 0
2022-08-22 21:24:23,509 DEBUG CV Batch 27/400 loss 45.043728 loss_att 34.672508 loss_ctc 69.243240 loss_ctc_origin 52.405586 loss_ctc0 108.531082 history loss 33.790854 rank 0
2022-08-22 21:24:33,543 DEBUG CV Batch 27/500 loss 34.378891 loss_att 25.938026 loss_ctc 54.074234 loss_ctc_origin 47.030579 loss_ctc0 70.509430 history loss 33.448514 rank 0
2022-08-22 21:24:43,998 DEBUG CV Batch 27/600 loss 22.023424 loss_att 15.215961 loss_ctc 37.907505 loss_ctc_origin 27.757458 loss_ctc0 61.590946 history loss 33.345689 rank 0
2022-08-22 21:24:53,968 DEBUG CV Batch 27/700 loss 26.931274 loss_att 19.062334 loss_ctc 45.292130 loss_ctc_origin 33.122116 loss_ctc0 73.688828 history loss 33.030687 rank 0
2022-08-22 21:25:04,179 DEBUG CV Batch 27/800 loss 27.000631 loss_att 19.334187 loss_ctc 44.889000 loss_ctc_origin 29.809320 loss_ctc0 80.074913 history loss 32.954299 rank 0
2022-08-22 21:25:14,335 INFO Epoch 27 CV info cv_loss 32.992776712702636
2022-08-22 21:25:14,335 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/27.pt
2022-08-22 21:25:14,827 INFO Epoch 28 TRAIN info lr 0.0015847880440186747
2022-08-22 21:25:14,830 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 21:25:42,751 WARNING NaN or Inf found in input tensor.
2022-08-22 21:25:42,812 DEBUG TRAIN Batch 28/0 loss inf loss_att 28.413475 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00158477 rank 0
2022-08-22 21:26:11,294 DEBUG TRAIN Batch 28/100 loss 31.921400 loss_att 22.245546 loss_ctc 54.498390 loss_ctc_origin 47.894543 loss_ctc0 69.907356 lr 0.00158427 rank 0
2022-08-22 21:26:39,560 DEBUG TRAIN Batch 28/200 loss 28.138973 loss_att 18.383440 loss_ctc 50.901878 loss_ctc_origin 42.573948 loss_ctc0 70.333717 lr 0.00158377 rank 0
2022-08-22 21:27:08,294 DEBUG TRAIN Batch 28/300 loss 40.410076 loss_att 26.163902 loss_ctc 73.651146 loss_ctc_origin 64.151421 loss_ctc0 95.817169 lr 0.00158328 rank 0
2022-08-22 21:27:37,167 DEBUG TRAIN Batch 28/400 loss 33.628632 loss_att 19.730877 loss_ctc 66.056717 loss_ctc_origin 53.656143 loss_ctc0 94.991394 lr 0.00158278 rank 0
2022-08-22 21:28:05,955 DEBUG TRAIN Batch 28/500 loss 33.354523 loss_att 25.674612 loss_ctc 51.274307 loss_ctc_origin 41.998192 loss_ctc0 72.918571 lr 0.00158229 rank 0
2022-08-22 21:28:34,621 DEBUG TRAIN Batch 28/600 loss 31.556381 loss_att 24.925041 loss_ctc 47.029510 loss_ctc_origin 39.263924 loss_ctc0 65.149200 lr 0.00158179 rank 0
2022-08-22 21:29:02,484 DEBUG TRAIN Batch 28/700 loss 32.268253 loss_att 21.900097 loss_ctc 56.460613 loss_ctc_origin 48.280373 loss_ctc0 75.547836 lr 0.00158130 rank 0
2022-08-22 21:29:07,759 WARNING NaN or Inf found in input tensor.
2022-08-22 21:29:31,043 DEBUG TRAIN Batch 28/800 loss 34.290985 loss_att 21.405060 loss_ctc 64.358139 loss_ctc_origin 52.744385 loss_ctc0 91.456894 lr 0.00158080 rank 0
2022-08-22 21:29:54,120 WARNING NaN or Inf found in input tensor.
2022-08-22 21:29:58,711 DEBUG TRAIN Batch 28/900 loss 48.659882 loss_att 31.090790 loss_ctc 89.654427 loss_ctc_origin 78.796852 loss_ctc0 114.988762 lr 0.00158031 rank 0
2022-08-22 21:30:26,745 DEBUG TRAIN Batch 28/1000 loss 32.508217 loss_att 26.269199 loss_ctc 47.065926 loss_ctc_origin 45.275688 loss_ctc0 51.243141 lr 0.00157982 rank 0
2022-08-22 21:30:55,064 DEBUG TRAIN Batch 28/1100 loss 34.720520 loss_att 26.639059 loss_ctc 53.577267 loss_ctc_origin 47.889977 loss_ctc0 66.847610 lr 0.00157932 rank 0
2022-08-22 21:31:22,683 DEBUG TRAIN Batch 28/1200 loss 29.796616 loss_att 19.433418 loss_ctc 53.977402 loss_ctc_origin 45.745773 loss_ctc0 73.184540 lr 0.00157883 rank 0
2022-08-22 21:31:51,327 DEBUG TRAIN Batch 28/1300 loss 31.299557 loss_att 18.776011 loss_ctc 60.521164 loss_ctc_origin 48.788349 loss_ctc0 87.897736 lr 0.00157834 rank 0
2022-08-22 21:32:18,057 DEBUG TRAIN Batch 28/1400 loss 37.010368 loss_att 22.274517 loss_ctc 71.394020 loss_ctc_origin 58.214653 loss_ctc0 102.145874 lr 0.00157785 rank 0
2022-08-22 21:32:51,608 DEBUG TRAIN Batch 28/1500 loss 31.391369 loss_att 25.251087 loss_ctc 45.718693 loss_ctc_origin 44.396523 loss_ctc0 48.803749 lr 0.00157736 rank 0
2022-08-22 21:33:19,450 DEBUG TRAIN Batch 28/1600 loss 33.986874 loss_att 25.390556 loss_ctc 54.044945 loss_ctc_origin 49.161148 loss_ctc0 65.440475 lr 0.00157687 rank 0
2022-08-22 21:33:46,716 DEBUG TRAIN Batch 28/1700 loss 29.849297 loss_att 19.512619 loss_ctc 53.968208 loss_ctc_origin 45.104179 loss_ctc0 74.650948 lr 0.00157638 rank 0
2022-08-22 21:34:14,842 DEBUG TRAIN Batch 28/1800 loss 34.963905 loss_att 21.317463 loss_ctc 66.805603 loss_ctc_origin 55.778069 loss_ctc0 92.536530 lr 0.00157589 rank 0
2022-08-22 21:34:42,583 DEBUG TRAIN Batch 28/1900 loss 38.161121 loss_att 22.956234 loss_ctc 73.639191 loss_ctc_origin 60.309998 loss_ctc0 104.740639 lr 0.00157540 rank 0
2022-08-22 21:35:11,038 DEBUG TRAIN Batch 28/2000 loss 31.429998 loss_att 25.571783 loss_ctc 45.099167 loss_ctc_origin 43.890930 loss_ctc0 47.918388 lr 0.00157491 rank 0
2022-08-22 21:35:39,570 DEBUG TRAIN Batch 28/2100 loss 32.442932 loss_att 24.216423 loss_ctc 51.638119 loss_ctc_origin 45.078880 loss_ctc0 66.943008 lr 0.00157442 rank 0
2022-08-22 21:36:06,145 DEBUG TRAIN Batch 28/2200 loss 30.566914 loss_att 20.841824 loss_ctc 53.258785 loss_ctc_origin 43.704468 loss_ctc0 75.552193 lr 0.00157393 rank 0
2022-08-22 21:36:11,596 WARNING NaN or Inf found in input tensor.
2022-08-22 21:36:34,290 DEBUG TRAIN Batch 28/2300 loss 35.028442 loss_att 23.214661 loss_ctc 62.593933 loss_ctc_origin 53.163872 loss_ctc0 84.597412 lr 0.00157345 rank 0
2022-08-22 21:36:51,152 WARNING NaN or Inf found in input tensor.
2022-08-22 21:37:02,653 DEBUG TRAIN Batch 28/2400 loss 40.067219 loss_att 25.762020 loss_ctc 73.446014 loss_ctc_origin 60.338104 loss_ctc0 104.031128 lr 0.00157296 rank 0
2022-08-22 21:37:31,233 DEBUG TRAIN Batch 28/2500 loss 28.815512 loss_att 22.760313 loss_ctc 42.944309 loss_ctc_origin 38.712082 loss_ctc0 52.819504 lr 0.00157247 rank 0
2022-08-22 21:37:59,113 DEBUG TRAIN Batch 28/2600 loss 33.608555 loss_att 24.129940 loss_ctc 55.725327 loss_ctc_origin 46.307480 loss_ctc0 77.700302 lr 0.00157199 rank 0
2022-08-22 21:38:26,944 DEBUG TRAIN Batch 28/2700 loss 36.391262 loss_att 23.999756 loss_ctc 65.304771 loss_ctc_origin 57.190426 loss_ctc0 84.238235 lr 0.00157150 rank 0
2022-08-22 21:38:55,244 DEBUG TRAIN Batch 28/2800 loss 29.398006 loss_att 18.122627 loss_ctc 55.707226 loss_ctc_origin 43.270432 loss_ctc0 84.726410 lr 0.00157102 rank 0
2022-08-22 21:39:24,495 DEBUG TRAIN Batch 28/2900 loss 38.923897 loss_att 22.944151 loss_ctc 76.209969 loss_ctc_origin 63.261127 loss_ctc0 106.423935 lr 0.00157053 rank 0
2022-08-22 21:39:57,962 DEBUG TRAIN Batch 28/3000 loss 35.640266 loss_att 27.810015 loss_ctc 53.910851 loss_ctc_origin 50.340160 loss_ctc0 62.242451 lr 0.00157005 rank 0
2022-08-22 21:40:25,721 DEBUG TRAIN Batch 28/3100 loss 30.940155 loss_att 23.115738 loss_ctc 49.197128 loss_ctc_origin 42.864685 loss_ctc0 63.972824 lr 0.00156957 rank 0
2022-08-22 21:40:53,026 DEBUG TRAIN Batch 28/3200 loss 30.912771 loss_att 21.415922 loss_ctc 53.072086 loss_ctc_origin 43.943436 loss_ctc0 74.372269 lr 0.00156908 rank 0
2022-08-22 21:41:20,267 DEBUG TRAIN Batch 28/3300 loss 34.781197 loss_att 22.580666 loss_ctc 63.249104 loss_ctc_origin 53.905933 loss_ctc0 85.049828 lr 0.00156860 rank 0
2022-08-22 21:41:48,720 DEBUG TRAIN Batch 28/3400 loss 39.143227 loss_att 24.462412 loss_ctc 73.398453 loss_ctc_origin 61.288338 loss_ctc0 101.655373 lr 0.00156812 rank 0
2022-08-22 21:42:16,414 DEBUG TRAIN Batch 28/3500 loss 32.089478 loss_att 24.321400 loss_ctc 50.214989 loss_ctc_origin 43.761131 loss_ctc0 65.273987 lr 0.00156764 rank 0
2022-08-22 21:42:44,242 DEBUG TRAIN Batch 28/3600 loss 55.512299 loss_att 35.997658 loss_ctc 101.046448 loss_ctc_origin 69.987411 loss_ctc0 173.517517 lr 0.00156716 rank 0
2022-08-22 21:43:12,130 DEBUG TRAIN Batch 28/3700 loss 34.152630 loss_att 24.979031 loss_ctc 55.557693 loss_ctc_origin 47.146492 loss_ctc0 75.183823 lr 0.00156667 rank 0
2022-08-22 21:43:39,586 DEBUG TRAIN Batch 28/3800 loss 29.926708 loss_att 17.919853 loss_ctc 57.942703 loss_ctc_origin 47.523987 loss_ctc0 82.253052 lr 0.00156619 rank 0
2022-08-22 21:44:07,702 DEBUG TRAIN Batch 28/3900 loss 38.934784 loss_att 23.534275 loss_ctc 74.869308 loss_ctc_origin 61.412918 loss_ctc0 106.267548 lr 0.00156571 rank 0
2022-08-22 21:44:35,657 DEBUG TRAIN Batch 28/4000 loss 24.480141 loss_att 20.011023 loss_ctc 34.908081 loss_ctc_origin 30.972034 loss_ctc0 44.092186 lr 0.00156523 rank 0
2022-08-22 21:45:02,511 DEBUG TRAIN Batch 28/4100 loss 35.180275 loss_att 25.165318 loss_ctc 58.548512 loss_ctc_origin 49.921715 loss_ctc0 78.677711 lr 0.00156476 rank 0
2022-08-22 21:45:31,476 DEBUG TRAIN Batch 28/4200 loss 31.649727 loss_att 22.142445 loss_ctc 53.833385 loss_ctc_origin 44.991684 loss_ctc0 74.464020 lr 0.00156428 rank 0
2022-08-22 21:45:58,918 DEBUG TRAIN Batch 28/4300 loss 38.188576 loss_att 24.637281 loss_ctc 69.808266 loss_ctc_origin 59.499260 loss_ctc0 93.862602 lr 0.00156380 rank 0
2022-08-22 21:46:27,320 DEBUG TRAIN Batch 28/4400 loss 38.949966 loss_att 24.559208 loss_ctc 72.528404 loss_ctc_origin 58.360786 loss_ctc0 105.586182 lr 0.00156332 rank 0
2022-08-22 21:47:01,008 DEBUG TRAIN Batch 28/4500 loss 28.935204 loss_att 21.475452 loss_ctc 46.341286 loss_ctc_origin 38.499619 loss_ctc0 64.638519 lr 0.00156284 rank 0
2022-08-22 21:47:29,792 DEBUG TRAIN Batch 28/4600 loss 37.278244 loss_att 24.407652 loss_ctc 67.309631 loss_ctc_origin 47.631233 loss_ctc0 113.225891 lr 0.00156237 rank 0
2022-08-22 21:47:58,169 DEBUG TRAIN Batch 28/4700 loss 31.796612 loss_att 21.921244 loss_ctc 54.839138 loss_ctc_origin 46.291950 loss_ctc0 74.782570 lr 0.00156189 rank 0
2022-08-22 21:48:25,447 DEBUG TRAIN Batch 28/4800 loss 38.647308 loss_att 26.126728 loss_ctc 67.862000 loss_ctc_origin 57.989098 loss_ctc0 90.898758 lr 0.00156141 rank 0
2022-08-22 21:48:54,862 DEBUG TRAIN Batch 28/4900 loss 38.897247 loss_att 23.949375 loss_ctc 73.775620 loss_ctc_origin 60.119354 loss_ctc0 105.640228 lr 0.00156094 rank 0
2022-08-22 21:49:22,951 DEBUG TRAIN Batch 28/5000 loss 33.951958 loss_att 26.265116 loss_ctc 51.887917 loss_ctc_origin 42.473423 loss_ctc0 73.855072 lr 0.00156046 rank 0
2022-08-22 21:49:49,531 DEBUG TRAIN Batch 28/5100 loss 37.942627 loss_att 26.280239 loss_ctc 65.154869 loss_ctc_origin 53.563602 loss_ctc0 92.201149 lr 0.00155999 rank 0
2022-08-22 21:50:16,693 DEBUG TRAIN Batch 28/5200 loss 29.821621 loss_att 19.760765 loss_ctc 53.296947 loss_ctc_origin 43.525410 loss_ctc0 76.097198 lr 0.00155951 rank 0
2022-08-22 21:50:46,434 DEBUG TRAIN Batch 28/5300 loss 31.874592 loss_att 20.647137 loss_ctc 58.071983 loss_ctc_origin 47.586800 loss_ctc0 82.537399 lr 0.00155904 rank 0
2022-08-22 21:51:14,140 DEBUG TRAIN Batch 28/5400 loss 36.805061 loss_att 23.419710 loss_ctc 68.037552 loss_ctc_origin 54.587360 loss_ctc0 99.421326 lr 0.00155857 rank 0
2022-08-22 21:51:42,828 DEBUG TRAIN Batch 28/5500 loss 29.431885 loss_att 23.733442 loss_ctc 42.728249 loss_ctc_origin 39.750046 loss_ctc0 49.677391 lr 0.00155809 rank 0
2022-08-22 21:52:10,084 DEBUG TRAIN Batch 28/5600 loss 35.766445 loss_att 22.640160 loss_ctc 66.394440 loss_ctc_origin 45.246128 loss_ctc0 115.740501 lr 0.00155762 rank 0
2022-08-22 21:52:33,481 DEBUG CV Batch 28/0 loss 28.913355 loss_att 18.576195 loss_ctc 53.033394 loss_ctc_origin 30.398788 loss_ctc0 105.847466 history loss 27.212569 rank 0
2022-08-22 21:52:44,459 DEBUG CV Batch 28/100 loss 32.711662 loss_att 21.546200 loss_ctc 58.764404 loss_ctc_origin 37.665009 loss_ctc0 107.996323 history loss 36.675822 rank 0
2022-08-22 21:52:53,959 DEBUG CV Batch 28/200 loss 32.548424 loss_att 25.332920 loss_ctc 49.384605 loss_ctc_origin 41.519207 loss_ctc0 67.737198 history loss 38.726792 rank 0
2022-08-22 21:53:03,579 DEBUG CV Batch 28/300 loss 30.444424 loss_att 22.419834 loss_ctc 49.168468 loss_ctc_origin 35.547962 loss_ctc0 80.949646 history loss 37.196578 rank 0
2022-08-22 21:53:13,585 DEBUG CV Batch 28/400 loss 45.548256 loss_att 35.927658 loss_ctc 67.996315 loss_ctc_origin 52.325470 loss_ctc0 104.561615 history loss 35.262351 rank 0
2022-08-22 21:53:23,803 DEBUG CV Batch 28/500 loss 28.258764 loss_att 19.053371 loss_ctc 49.738014 loss_ctc_origin 32.910446 loss_ctc0 89.002335 history loss 34.787879 rank 0
2022-08-22 21:53:33,899 DEBUG CV Batch 28/600 loss 26.211452 loss_att 17.499386 loss_ctc 46.539604 loss_ctc_origin 31.828020 loss_ctc0 80.866623 history loss 34.681823 rank 0
2022-08-22 21:53:43,700 DEBUG CV Batch 28/700 loss 25.623629 loss_att 18.245802 loss_ctc 42.838554 loss_ctc_origin 31.184612 loss_ctc0 70.031082 history loss 34.222086 rank 0
2022-08-22 21:53:54,004 DEBUG CV Batch 28/800 loss 26.337440 loss_att 18.970911 loss_ctc 43.526009 loss_ctc_origin 29.237377 loss_ctc0 76.866150 history loss 34.122010 rank 0
2022-08-22 21:54:04,205 INFO Epoch 28 CV info cv_loss 34.04587491455419
2022-08-22 21:54:04,205 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/28.pt
2022-08-22 21:54:04,689 INFO Epoch 29 TRAIN info lr 0.0015572244101673116
2022-08-22 21:54:04,693 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 21:54:33,291 DEBUG TRAIN Batch 29/0 loss 35.236786 loss_att 24.366009 loss_ctc 60.601929 loss_ctc_origin 40.294319 loss_ctc0 107.986359 lr 0.00155721 rank 0
2022-08-22 21:55:03,348 DEBUG TRAIN Batch 29/100 loss 44.820683 loss_att 29.563660 loss_ctc 80.420403 loss_ctc_origin 50.832993 loss_ctc0 149.457687 lr 0.00155673 rank 0
2022-08-22 21:55:33,635 DEBUG TRAIN Batch 29/200 loss 31.334423 loss_att 20.670527 loss_ctc 56.216846 loss_ctc_origin 47.856400 loss_ctc0 75.724564 lr 0.00155626 rank 0
2022-08-22 21:56:04,204 DEBUG TRAIN Batch 29/300 loss 33.417091 loss_att 20.436398 loss_ctc 63.705376 loss_ctc_origin 52.241661 loss_ctc0 90.454041 lr 0.00155579 rank 0
2022-08-22 21:56:15,605 WARNING NaN or Inf found in input tensor.
2022-08-22 21:56:34,325 DEBUG TRAIN Batch 29/400 loss 43.705719 loss_att 25.870457 loss_ctc 85.321335 loss_ctc_origin 72.859222 loss_ctc0 114.399597 lr 0.00155532 rank 0
2022-08-22 21:57:04,178 DEBUG TRAIN Batch 29/500 loss 43.746712 loss_att 30.364441 loss_ctc 74.972015 loss_ctc_origin 51.606262 loss_ctc0 129.492096 lr 0.00155485 rank 0
2022-08-22 21:57:33,683 DEBUG TRAIN Batch 29/600 loss 44.442158 loss_att 27.254181 loss_ctc 84.547432 loss_ctc_origin 53.402504 loss_ctc0 157.218933 lr 0.00155438 rank 0
2022-08-22 21:58:04,254 DEBUG TRAIN Batch 29/700 loss 29.187160 loss_att 20.621296 loss_ctc 49.174179 loss_ctc_origin 41.223343 loss_ctc0 67.726120 lr 0.00155391 rank 0
2022-08-22 21:58:09,828 WARNING NaN or Inf found in input tensor.
2022-08-22 21:58:33,821 DEBUG TRAIN Batch 29/800 loss 37.083473 loss_att 23.386337 loss_ctc 69.043457 loss_ctc_origin 58.352036 loss_ctc0 93.990097 lr 0.00155344 rank 0
2022-08-22 21:59:02,890 DEBUG TRAIN Batch 29/900 loss 29.774281 loss_att 16.909954 loss_ctc 59.791039 loss_ctc_origin 42.700928 loss_ctc0 99.667953 lr 0.00155297 rank 0
2022-08-22 21:59:31,486 DEBUG TRAIN Batch 29/1000 loss 28.737389 loss_att 24.519476 loss_ctc 38.579182 loss_ctc_origin 36.101959 loss_ctc0 44.359360 lr 0.00155251 rank 0
2022-08-22 22:00:02,393 DEBUG TRAIN Batch 29/1100 loss 45.401585 loss_att 33.297714 loss_ctc 73.643951 loss_ctc_origin 53.691311 loss_ctc0 120.200119 lr 0.00155204 rank 0
2022-08-22 22:00:31,097 DEBUG TRAIN Batch 29/1200 loss 28.984226 loss_att 19.254921 loss_ctc 51.685936 loss_ctc_origin 42.623497 loss_ctc0 72.831627 lr 0.00155157 rank 0
2022-08-22 22:01:01,340 DEBUG TRAIN Batch 29/1300 loss 31.231356 loss_att 18.713486 loss_ctc 60.439720 loss_ctc_origin 46.575787 loss_ctc0 92.788902 lr 0.00155111 rank 0
2022-08-22 22:01:30,745 DEBUG TRAIN Batch 29/1400 loss 38.701256 loss_att 24.123192 loss_ctc 72.716743 loss_ctc_origin 58.908730 loss_ctc0 104.935432 lr 0.00155064 rank 0
2022-08-22 22:01:40,098 WARNING NaN or Inf found in input tensor.
2022-08-22 22:02:07,616 DEBUG TRAIN Batch 29/1500 loss 26.342361 loss_att 21.708519 loss_ctc 37.154663 loss_ctc_origin 33.630627 loss_ctc0 45.377411 lr 0.00155017 rank 0
2022-08-22 22:02:38,781 WARNING NaN or Inf found in input tensor.
2022-08-22 22:02:38,829 DEBUG TRAIN Batch 29/1600 loss nan loss_att 25.260561 loss_ctc nan loss_ctc_origin 38.254978 loss_ctc0 nan lr 0.00154971 rank 0
2022-08-22 22:03:08,489 DEBUG TRAIN Batch 29/1700 loss 29.977491 loss_att 20.845680 loss_ctc 51.285049 loss_ctc_origin 43.100796 loss_ctc0 70.381638 lr 0.00154924 rank 0
2022-08-22 22:03:38,068 DEBUG TRAIN Batch 29/1800 loss 31.594084 loss_att 19.536547 loss_ctc 59.728336 loss_ctc_origin 50.073116 loss_ctc0 82.257179 lr 0.00154878 rank 0
2022-08-22 22:04:08,186 DEBUG TRAIN Batch 29/1900 loss 36.090439 loss_att 22.775681 loss_ctc 67.158203 loss_ctc_origin 53.295708 loss_ctc0 99.504013 lr 0.00154831 rank 0
2022-08-22 22:04:38,190 DEBUG TRAIN Batch 29/2000 loss 35.241478 loss_att 25.910660 loss_ctc 57.013397 loss_ctc_origin 54.949245 loss_ctc0 61.829754 lr 0.00154785 rank 0
2022-08-22 22:05:00,326 WARNING NaN or Inf found in input tensor.
2022-08-22 22:05:07,512 DEBUG TRAIN Batch 29/2100 loss 34.525124 loss_att 24.729536 loss_ctc 57.381485 loss_ctc_origin 43.016991 loss_ctc0 90.898636 lr 0.00154739 rank 0
2022-08-22 22:05:13,956 WARNING NaN or Inf found in input tensor.
2022-08-22 22:05:35,880 DEBUG TRAIN Batch 29/2200 loss 30.964260 loss_att 22.020651 loss_ctc 51.832680 loss_ctc_origin 44.089203 loss_ctc0 69.900787 lr 0.00154692 rank 0
2022-08-22 22:06:07,350 DEBUG TRAIN Batch 29/2300 loss 37.805889 loss_att 24.788288 loss_ctc 68.180290 loss_ctc_origin 59.964951 loss_ctc0 87.349419 lr 0.00154646 rank 0
2022-08-22 22:06:36,185 DEBUG TRAIN Batch 29/2400 loss 32.937607 loss_att 20.075260 loss_ctc 62.949745 loss_ctc_origin 48.805138 loss_ctc0 95.953819 lr 0.00154600 rank 0
2022-08-22 22:07:06,422 DEBUG TRAIN Batch 29/2500 loss 39.311813 loss_att 30.783562 loss_ctc 59.211071 loss_ctc_origin 48.617901 loss_ctc0 83.928459 lr 0.00154554 rank 0
2022-08-22 22:07:34,557 DEBUG TRAIN Batch 29/2600 loss 34.428574 loss_att 23.583502 loss_ctc 59.733746 loss_ctc_origin 45.139095 loss_ctc0 93.787926 lr 0.00154508 rank 0
2022-08-22 22:08:05,188 DEBUG TRAIN Batch 29/2700 loss 31.981693 loss_att 23.470985 loss_ctc 51.840012 loss_ctc_origin 43.189392 loss_ctc0 72.024796 lr 0.00154462 rank 0
2022-08-22 22:08:33,899 DEBUG TRAIN Batch 29/2800 loss 30.482456 loss_att 18.109934 loss_ctc 59.351669 loss_ctc_origin 47.503315 loss_ctc0 86.997833 lr 0.00154416 rank 0
2022-08-22 22:08:58,483 WARNING NaN or Inf found in input tensor.
2022-08-22 22:09:02,916 DEBUG TRAIN Batch 29/2900 loss 34.106510 loss_att 20.192829 loss_ctc 66.571770 loss_ctc_origin 50.755623 loss_ctc0 103.476120 lr 0.00154370 rank 0
2022-08-22 22:09:41,039 DEBUG TRAIN Batch 29/3000 loss 28.514130 loss_att 22.889000 loss_ctc 41.639439 loss_ctc_origin 40.121788 loss_ctc0 45.180622 lr 0.00154324 rank 0
2022-08-22 22:10:10,978 DEBUG TRAIN Batch 29/3100 loss 39.068928 loss_att 27.059361 loss_ctc 67.091255 loss_ctc_origin 51.540764 loss_ctc0 103.375732 lr 0.00154278 rank 0
2022-08-22 22:10:40,834 DEBUG TRAIN Batch 29/3200 loss 29.899342 loss_att 20.675011 loss_ctc 51.422775 loss_ctc_origin 42.582706 loss_ctc0 72.049606 lr 0.00154232 rank 0
2022-08-22 22:10:46,182 WARNING NaN or Inf found in input tensor.
2022-08-22 22:11:10,033 DEBUG TRAIN Batch 29/3300 loss 32.939194 loss_att 21.378693 loss_ctc 59.913689 loss_ctc_origin 48.685135 loss_ctc0 86.113640 lr 0.00154186 rank 0
2022-08-22 22:11:39,582 DEBUG TRAIN Batch 29/3400 loss 41.768322 loss_att 27.850899 loss_ctc 74.242310 loss_ctc_origin 62.929401 loss_ctc0 100.639107 lr 0.00154140 rank 0
2022-08-22 22:12:10,115 DEBUG TRAIN Batch 29/3500 loss 24.674730 loss_att 20.022793 loss_ctc 35.529251 loss_ctc_origin 31.804283 loss_ctc0 44.220840 lr 0.00154094 rank 0
2022-08-22 22:12:32,170 WARNING NaN or Inf found in input tensor.
2022-08-22 22:12:39,624 DEBUG TRAIN Batch 29/3600 loss 38.103111 loss_att 26.654940 loss_ctc 64.815514 loss_ctc_origin 50.175602 loss_ctc0 98.975311 lr 0.00154049 rank 0
2022-08-22 22:13:08,637 DEBUG TRAIN Batch 29/3700 loss 28.422684 loss_att 17.689102 loss_ctc 53.467705 loss_ctc_origin 44.553680 loss_ctc0 74.267090 lr 0.00154003 rank 0
2022-08-22 22:13:38,199 DEBUG TRAIN Batch 29/3800 loss 31.316986 loss_att 18.188963 loss_ctc 61.949043 loss_ctc_origin 49.460129 loss_ctc0 91.089844 lr 0.00153957 rank 0
2022-08-22 22:14:08,851 DEBUG TRAIN Batch 29/3900 loss 37.778679 loss_att 23.841742 loss_ctc 70.298195 loss_ctc_origin 55.250748 loss_ctc0 105.408905 lr 0.00153912 rank 0
2022-08-22 22:14:38,215 DEBUG TRAIN Batch 29/4000 loss 26.540363 loss_att 20.375978 loss_ctc 40.923923 loss_ctc_origin 34.256016 loss_ctc0 56.482376 lr 0.00153866 rank 0
2022-08-22 22:14:53,897 WARNING NaN or Inf found in input tensor.
2022-08-22 22:15:08,770 DEBUG TRAIN Batch 29/4100 loss 41.428902 loss_att 31.194933 loss_ctc 65.308159 loss_ctc_origin 48.510529 loss_ctc0 104.502632 lr 0.00153821 rank 0
2022-08-22 22:15:37,420 DEBUG TRAIN Batch 29/4200 loss 28.333557 loss_att 19.644979 loss_ctc 48.606907 loss_ctc_origin 38.507065 loss_ctc0 72.173203 lr 0.00153775 rank 0
2022-08-22 22:15:50,804 WARNING NaN or Inf found in input tensor.
2022-08-22 22:16:08,926 DEBUG TRAIN Batch 29/4300 loss 33.974754 loss_att 23.600121 loss_ctc 58.182236 loss_ctc_origin 48.282391 loss_ctc0 81.281868 lr 0.00153730 rank 0
2022-08-22 22:16:37,816 DEBUG TRAIN Batch 29/4400 loss 36.561573 loss_att 21.624313 loss_ctc 71.415176 loss_ctc_origin 55.721157 loss_ctc0 108.034561 lr 0.00153684 rank 0
2022-08-22 22:17:14,731 DEBUG TRAIN Batch 29/4500 loss 30.728903 loss_att 24.766060 loss_ctc 44.642204 loss_ctc_origin 42.336700 loss_ctc0 50.021706 lr 0.00153639 rank 0
2022-08-22 22:17:45,101 DEBUG TRAIN Batch 29/4600 loss 33.551006 loss_att 24.745707 loss_ctc 54.096703 loss_ctc_origin 46.457844 loss_ctc0 71.920715 lr 0.00153594 rank 0
2022-08-22 22:18:13,208 WARNING NaN or Inf found in input tensor.
2022-08-22 22:18:14,848 DEBUG TRAIN Batch 29/4700 loss 31.011166 loss_att 21.114582 loss_ctc 54.103195 loss_ctc_origin 44.450844 loss_ctc0 76.625351 lr 0.00153548 rank 0
2022-08-22 22:18:44,460 DEBUG TRAIN Batch 29/4800 loss 39.124889 loss_att 23.753738 loss_ctc 74.990906 loss_ctc_origin 64.631790 loss_ctc0 99.162170 lr 0.00153503 rank 0
2022-08-22 22:19:14,143 DEBUG TRAIN Batch 29/4900 loss 40.096817 loss_att 26.947870 loss_ctc 70.777695 loss_ctc_origin 57.526588 loss_ctc0 101.696930 lr 0.00153458 rank 0
2022-08-22 22:19:43,636 DEBUG TRAIN Batch 29/5000 loss 28.490456 loss_att 20.898815 loss_ctc 46.204285 loss_ctc_origin 45.683090 loss_ctc0 47.420403 lr 0.00153413 rank 0
2022-08-22 22:20:13,581 DEBUG TRAIN Batch 29/5100 loss 36.528053 loss_att 25.135994 loss_ctc 63.109520 loss_ctc_origin 46.492306 loss_ctc0 101.883011 lr 0.00153368 rank 0
2022-08-22 22:20:42,867 DEBUG TRAIN Batch 29/5200 loss 29.155584 loss_att 19.588219 loss_ctc 51.479435 loss_ctc_origin 43.203503 loss_ctc0 70.789948 lr 0.00153323 rank 0
2022-08-22 22:21:11,117 DEBUG TRAIN Batch 29/5300 loss 33.766937 loss_att 20.750601 loss_ctc 64.138382 loss_ctc_origin 53.547745 loss_ctc0 88.849854 lr 0.00153278 rank 0
2022-08-22 22:21:41,218 DEBUG TRAIN Batch 29/5400 loss 38.888824 loss_att 24.966200 loss_ctc 71.374954 loss_ctc_origin 56.381180 loss_ctc0 106.360443 lr 0.00153233 rank 0
2022-08-22 22:22:10,035 DEBUG TRAIN Batch 29/5500 loss 39.074097 loss_att 28.771917 loss_ctc 63.112514 loss_ctc_origin 48.376766 loss_ctc0 97.495926 lr 0.00153188 rank 0
2022-08-22 22:22:31,729 WARNING NaN or Inf found in input tensor.
2022-08-22 22:22:38,829 DEBUG TRAIN Batch 29/5600 loss 35.841408 loss_att 26.078892 loss_ctc 58.620613 loss_ctc_origin 43.660240 loss_ctc0 93.528152 lr 0.00153143 rank 0
2022-08-22 22:23:02,638 DEBUG CV Batch 29/0 loss 21.362331 loss_att 13.748033 loss_ctc 39.129028 loss_ctc_origin 24.503515 loss_ctc0 73.255234 history loss 20.105724 rank 0
2022-08-22 22:23:13,871 DEBUG CV Batch 29/100 loss 31.655197 loss_att 20.743570 loss_ctc 57.115662 loss_ctc_origin 35.391598 loss_ctc0 107.805145 history loss 34.833839 rank 0
2022-08-22 22:23:23,920 DEBUG CV Batch 29/200 loss 30.181274 loss_att 22.790348 loss_ctc 47.426769 loss_ctc_origin 37.705585 loss_ctc0 70.109528 history loss 36.418451 rank 0
2022-08-22 22:23:34,649 DEBUG CV Batch 29/300 loss 29.001991 loss_att 21.486099 loss_ctc 46.539074 loss_ctc_origin 32.523270 loss_ctc0 79.242615 history loss 35.305983 rank 0
2022-08-22 22:23:45,749 DEBUG CV Batch 29/400 loss 44.918114 loss_att 35.358643 loss_ctc 67.223541 loss_ctc_origin 51.282089 loss_ctc0 104.420273 history loss 33.382340 rank 0
2022-08-22 22:23:57,123 DEBUG CV Batch 29/500 loss 30.747845 loss_att 20.268150 loss_ctc 55.200459 loss_ctc_origin 35.558907 loss_ctc0 101.030746 history loss 32.933910 rank 0
2022-08-22 22:24:08,454 DEBUG CV Batch 29/600 loss 25.406643 loss_att 16.409372 loss_ctc 46.400269 loss_ctc_origin 31.005821 loss_ctc0 82.320633 history loss 32.815029 rank 0
2022-08-22 22:24:19,203 DEBUG CV Batch 29/700 loss 25.052515 loss_att 17.971199 loss_ctc 41.575584 loss_ctc_origin 29.229174 loss_ctc0 70.383881 history loss 32.422842 rank 0
2022-08-22 22:24:30,101 DEBUG CV Batch 29/800 loss 26.035763 loss_att 18.602692 loss_ctc 43.379593 loss_ctc_origin 29.021948 loss_ctc0 76.880760 history loss 32.413450 rank 0
2022-08-22 22:24:40,880 INFO Epoch 29 CV info cv_loss 32.38431707070546
2022-08-22 22:24:40,880 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/29.pt
2022-08-22 22:24:41,355 INFO Epoch 30 TRAIN info lr 0.001531050707248751
2022-08-22 22:24:41,358 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 22:25:08,760 DEBUG TRAIN Batch 30/0 loss 27.253307 loss_att 21.634718 loss_ctc 40.363350 loss_ctc_origin 34.000732 loss_ctc0 55.209450 lr 0.00153103 rank 0
2022-08-22 22:25:37,717 DEBUG TRAIN Batch 30/100 loss 32.544109 loss_att 23.895254 loss_ctc 52.724770 loss_ctc_origin 41.310078 loss_ctc0 79.359055 lr 0.00153058 rank 0
2022-08-22 22:26:07,655 DEBUG TRAIN Batch 30/200 loss 29.119106 loss_att 19.863432 loss_ctc 50.715675 loss_ctc_origin 41.490192 loss_ctc0 72.241806 lr 0.00153014 rank 0
2022-08-22 22:26:37,942 DEBUG TRAIN Batch 30/300 loss 32.339806 loss_att 19.566246 loss_ctc 62.144775 loss_ctc_origin 50.739521 loss_ctc0 88.757019 lr 0.00152969 rank 0
2022-08-22 22:27:07,357 DEBUG TRAIN Batch 30/400 loss 33.913986 loss_att 20.012297 loss_ctc 66.351250 loss_ctc_origin 51.515553 loss_ctc0 100.967865 lr 0.00152924 rank 0
2022-08-22 22:27:36,772 DEBUG TRAIN Batch 30/500 loss 27.595343 loss_att 21.059525 loss_ctc 42.845585 loss_ctc_origin 39.164589 loss_ctc0 51.434574 lr 0.00152879 rank 0
2022-08-22 22:28:06,716 DEBUG TRAIN Batch 30/600 loss 29.963636 loss_att 21.164463 loss_ctc 50.495041 loss_ctc_origin 41.307785 loss_ctc0 71.931976 lr 0.00152835 rank 0
2022-08-22 22:28:36,471 DEBUG TRAIN Batch 30/700 loss 29.368477 loss_att 20.915222 loss_ctc 49.092739 loss_ctc_origin 40.026501 loss_ctc0 70.247292 lr 0.00152790 rank 0
2022-08-22 22:29:06,267 DEBUG TRAIN Batch 30/800 loss 31.367558 loss_att 19.168648 loss_ctc 59.831680 loss_ctc_origin 46.344482 loss_ctc0 91.301804 lr 0.00152746 rank 0
2022-08-22 22:29:35,593 DEBUG TRAIN Batch 30/900 loss 34.420990 loss_att 19.710854 loss_ctc 68.744644 loss_ctc_origin 53.284561 loss_ctc0 104.818176 lr 0.00152701 rank 0
2022-08-22 22:30:06,113 DEBUG TRAIN Batch 30/1000 loss 29.081760 loss_att 21.704552 loss_ctc 46.295242 loss_ctc_origin 38.536583 loss_ctc0 64.398781 lr 0.00152657 rank 0
2022-08-22 22:30:19,453 WARNING NaN or Inf found in input tensor.
2022-08-22 22:30:33,581 DEBUG TRAIN Batch 30/1100 loss 35.648369 loss_att 25.314629 loss_ctc 59.760429 loss_ctc_origin 47.742546 loss_ctc0 87.802155 lr 0.00152612 rank 0
2022-08-22 22:31:04,019 DEBUG TRAIN Batch 30/1200 loss 30.046116 loss_att 17.809284 loss_ctc 58.598724 loss_ctc_origin 49.619705 loss_ctc0 79.549774 lr 0.00152568 rank 0
2022-08-22 22:31:35,034 DEBUG TRAIN Batch 30/1300 loss 28.819618 loss_att 17.161310 loss_ctc 56.022339 loss_ctc_origin 44.132828 loss_ctc0 83.764526 lr 0.00152523 rank 0
2022-08-22 22:31:45,672 WARNING NaN or Inf found in input tensor.
2022-08-22 22:32:04,724 DEBUG TRAIN Batch 30/1400 loss 36.113487 loss_att 21.410751 loss_ctc 70.419861 loss_ctc_origin 56.494026 loss_ctc0 102.913475 lr 0.00152479 rank 0
2022-08-22 22:32:41,114 DEBUG TRAIN Batch 30/1500 loss 32.686344 loss_att 27.836975 loss_ctc 44.001537 loss_ctc_origin 42.691750 loss_ctc0 47.057713 lr 0.00152435 rank 0
2022-08-22 22:33:10,194 DEBUG TRAIN Batch 30/1600 loss 34.000446 loss_att 24.383101 loss_ctc 56.440918 loss_ctc_origin 43.626717 loss_ctc0 86.340721 lr 0.00152391 rank 0
2022-08-22 22:33:38,833 DEBUG TRAIN Batch 30/1700 loss 31.201805 loss_att 21.686661 loss_ctc 53.403809 loss_ctc_origin 44.036808 loss_ctc0 75.260132 lr 0.00152346 rank 0
2022-08-22 22:33:44,723 WARNING NaN or Inf found in input tensor.
2022-08-22 22:34:08,741 DEBUG TRAIN Batch 30/1800 loss 28.495367 loss_att 17.432968 loss_ctc 54.307629 loss_ctc_origin 41.618668 loss_ctc0 83.915207 lr 0.00152302 rank 0
2022-08-22 22:34:33,044 WARNING NaN or Inf found in input tensor.
2022-08-22 22:34:37,304 DEBUG TRAIN Batch 30/1900 loss 33.846550 loss_att 20.997778 loss_ctc 63.827011 loss_ctc_origin 49.827869 loss_ctc0 96.491669 lr 0.00152258 rank 0
2022-08-22 22:34:39,873 WARNING NaN or Inf found in input tensor.
2022-08-22 22:35:07,862 DEBUG TRAIN Batch 30/2000 loss 32.673588 loss_att 22.898571 loss_ctc 55.481956 loss_ctc_origin 45.923717 loss_ctc0 77.784515 lr 0.00152214 rank 0
2022-08-22 22:35:35,755 DEBUG TRAIN Batch 30/2100 loss 43.766006 loss_att 29.511383 loss_ctc 77.026787 loss_ctc_origin 45.604408 loss_ctc0 150.345657 lr 0.00152170 rank 0
2022-08-22 22:36:05,114 DEBUG TRAIN Batch 30/2200 loss 28.526756 loss_att 17.475119 loss_ctc 54.313904 loss_ctc_origin 45.793488 loss_ctc0 74.194885 lr 0.00152126 rank 0
2022-08-22 22:36:34,106 DEBUG TRAIN Batch 30/2300 loss 32.652718 loss_att 19.934185 loss_ctc 62.329292 loss_ctc_origin 51.850273 loss_ctc0 86.780334 lr 0.00152082 rank 0
2022-08-22 22:36:59,118 WARNING NaN or Inf found in input tensor.
2022-08-22 22:37:03,930 DEBUG TRAIN Batch 30/2400 loss 31.801943 loss_att 18.988997 loss_ctc 61.698814 loss_ctc_origin 48.916161 loss_ctc0 91.525009 lr 0.00152038 rank 0
2022-08-22 22:37:34,044 DEBUG TRAIN Batch 30/2500 loss 35.721928 loss_att 25.941334 loss_ctc 58.543308 loss_ctc_origin 46.598507 loss_ctc0 86.414513 lr 0.00151994 rank 0
2022-08-22 22:38:03,961 DEBUG TRAIN Batch 30/2600 loss 39.197235 loss_att 26.660629 loss_ctc 68.449310 loss_ctc_origin 50.049809 loss_ctc0 111.381485 lr 0.00151950 rank 0
2022-08-22 22:38:31,443 DEBUG TRAIN Batch 30/2700 loss 26.870857 loss_att 17.372347 loss_ctc 49.034042 loss_ctc_origin 41.021461 loss_ctc0 67.730064 lr 0.00151906 rank 0
2022-08-22 22:39:01,645 DEBUG TRAIN Batch 30/2800 loss 33.985321 loss_att 21.482964 loss_ctc 63.157482 loss_ctc_origin 52.149490 loss_ctc0 88.842796 lr 0.00151862 rank 0
2022-08-22 22:39:29,978 DEBUG TRAIN Batch 30/2900 loss 38.727898 loss_att 22.551987 loss_ctc 76.471680 loss_ctc_origin 62.192230 loss_ctc0 109.790375 lr 0.00151819 rank 0
2022-08-22 22:40:06,156 DEBUG TRAIN Batch 30/3000 loss 29.451958 loss_att 21.135738 loss_ctc 48.856468 loss_ctc_origin 42.600410 loss_ctc0 63.453941 lr 0.00151775 rank 0
2022-08-22 22:40:35,798 DEBUG TRAIN Batch 30/3100 loss 34.037086 loss_att 23.150681 loss_ctc 59.438705 loss_ctc_origin 44.682014 loss_ctc0 93.870987 lr 0.00151731 rank 0
2022-08-22 22:41:03,715 WARNING NaN or Inf found in input tensor.
2022-08-22 22:41:05,411 DEBUG TRAIN Batch 30/3200 loss 24.077393 loss_att 16.382076 loss_ctc 42.033134 loss_ctc_origin 33.121174 loss_ctc0 62.827705 lr 0.00151688 rank 0
2022-08-22 22:41:35,152 DEBUG TRAIN Batch 30/3300 loss 33.435169 loss_att 21.232759 loss_ctc 61.907463 loss_ctc_origin 51.617661 loss_ctc0 85.917007 lr 0.00151644 rank 0
2022-08-22 22:42:04,190 DEBUG TRAIN Batch 30/3400 loss 35.523632 loss_att 22.172529 loss_ctc 66.676208 loss_ctc_origin 53.220451 loss_ctc0 98.072983 lr 0.00151600 rank 0
2022-08-22 22:42:33,727 DEBUG TRAIN Batch 30/3500 loss 26.150681 loss_att 21.081793 loss_ctc 37.978085 loss_ctc_origin 32.952431 loss_ctc0 49.704609 lr 0.00151557 rank 0
2022-08-22 22:43:02,946 DEBUG TRAIN Batch 30/3600 loss 33.316021 loss_att 23.261221 loss_ctc 56.777218 loss_ctc_origin 46.990780 loss_ctc0 79.612236 lr 0.00151513 rank 0
2022-08-22 22:43:32,934 DEBUG TRAIN Batch 30/3700 loss 27.336279 loss_att 17.702137 loss_ctc 49.815941 loss_ctc_origin 39.416916 loss_ctc0 74.080338 lr 0.00151470 rank 0
2022-08-22 22:44:02,796 DEBUG TRAIN Batch 30/3800 loss 35.395927 loss_att 23.016548 loss_ctc 64.281143 loss_ctc_origin 53.684738 loss_ctc0 89.006088 lr 0.00151427 rank 0
2022-08-22 22:44:31,809 DEBUG TRAIN Batch 30/3900 loss 33.015648 loss_att 19.070021 loss_ctc 65.555435 loss_ctc_origin 50.167435 loss_ctc0 101.460770 lr 0.00151383 rank 0
2022-08-22 22:45:02,033 DEBUG TRAIN Batch 30/4000 loss 27.356140 loss_att 18.920893 loss_ctc 47.038383 loss_ctc_origin 36.809525 loss_ctc0 70.905716 lr 0.00151340 rank 0
2022-08-22 22:45:02,754 WARNING NaN or Inf found in input tensor.
2022-08-22 22:45:30,974 DEBUG TRAIN Batch 30/4100 loss 38.943878 loss_att 26.383673 loss_ctc 68.251022 loss_ctc_origin 43.648918 loss_ctc0 125.655930 lr 0.00151296 rank 0
2022-08-22 22:46:00,106 DEBUG TRAIN Batch 30/4200 loss 27.404194 loss_att 18.095524 loss_ctc 49.124428 loss_ctc_origin 40.085300 loss_ctc0 70.215729 lr 0.00151253 rank 0
2022-08-22 22:46:29,723 DEBUG TRAIN Batch 30/4300 loss 33.554321 loss_att 21.372852 loss_ctc 61.977741 loss_ctc_origin 50.961792 loss_ctc0 87.681625 lr 0.00151210 rank 0
2022-08-22 22:46:58,508 DEBUG TRAIN Batch 30/4400 loss 36.696945 loss_att 23.377338 loss_ctc 67.776031 loss_ctc_origin 54.208004 loss_ctc0 99.434769 lr 0.00151167 rank 0
2022-08-22 22:47:35,402 DEBUG TRAIN Batch 30/4500 loss 26.104515 loss_att 20.973995 loss_ctc 38.075729 loss_ctc_origin 35.619347 loss_ctc0 43.807281 lr 0.00151124 rank 0
2022-08-22 22:48:04,624 DEBUG TRAIN Batch 30/4600 loss 38.208237 loss_att 25.297493 loss_ctc 68.333298 loss_ctc_origin 49.910606 loss_ctc0 111.319580 lr 0.00151081 rank 0
2022-08-22 22:48:34,088 DEBUG TRAIN Batch 30/4700 loss 32.185089 loss_att 22.546305 loss_ctc 54.675583 loss_ctc_origin 46.074802 loss_ctc0 74.744064 lr 0.00151037 rank 0
2022-08-22 22:49:03,255 DEBUG TRAIN Batch 30/4800 loss 32.425484 loss_att 20.544472 loss_ctc 60.147846 loss_ctc_origin 50.140053 loss_ctc0 83.499359 lr 0.00150994 rank 0
2022-08-22 22:49:32,576 DEBUG TRAIN Batch 30/4900 loss 37.714760 loss_att 23.818020 loss_ctc 70.140495 loss_ctc_origin 57.886497 loss_ctc0 98.733162 lr 0.00150951 rank 0
2022-08-22 22:50:01,787 DEBUG TRAIN Batch 30/5000 loss 37.324795 loss_att 31.354473 loss_ctc 51.255547 loss_ctc_origin 47.235477 loss_ctc0 60.635696 lr 0.00150908 rank 0
2022-08-22 22:50:30,967 DEBUG TRAIN Batch 30/5100 loss 34.977032 loss_att 23.593662 loss_ctc 61.538223 loss_ctc_origin 47.957115 loss_ctc0 93.227478 lr 0.00150865 rank 0
2022-08-22 22:51:00,127 DEBUG TRAIN Batch 30/5200 loss 26.202106 loss_att 16.839285 loss_ctc 48.048691 loss_ctc_origin 40.759964 loss_ctc0 65.055710 lr 0.00150823 rank 0
2022-08-22 22:51:29,648 DEBUG TRAIN Batch 30/5300 loss 35.217777 loss_att 21.974400 loss_ctc 66.118988 loss_ctc_origin 54.846832 loss_ctc0 92.420685 lr 0.00150780 rank 0
2022-08-22 22:51:58,677 DEBUG TRAIN Batch 30/5400 loss 32.202293 loss_att 19.842363 loss_ctc 61.042130 loss_ctc_origin 48.209633 loss_ctc0 90.984619 lr 0.00150737 rank 0
2022-08-22 22:52:27,639 DEBUG TRAIN Batch 30/5500 loss 27.072338 loss_att 22.614616 loss_ctc 37.473690 loss_ctc_origin 34.197952 loss_ctc0 45.117081 lr 0.00150694 rank 0
2022-08-22 22:52:57,063 DEBUG TRAIN Batch 30/5600 loss 35.453476 loss_att 25.735737 loss_ctc 58.128197 loss_ctc_origin 46.937225 loss_ctc0 84.240471 lr 0.00150651 rank 0
2022-08-22 22:53:20,759 DEBUG CV Batch 30/0 loss 21.971268 loss_att 14.675393 loss_ctc 38.994980 loss_ctc_origin 24.693108 loss_ctc0 72.366005 history loss 20.678840 rank 0
2022-08-22 22:53:31,809 DEBUG CV Batch 30/100 loss 32.018250 loss_att 23.010471 loss_ctc 53.036396 loss_ctc_origin 34.349358 loss_ctc0 96.639481 history loss 34.303931 rank 0
2022-08-22 22:53:41,944 DEBUG CV Batch 30/200 loss 29.708523 loss_att 22.692461 loss_ctc 46.079330 loss_ctc_origin 37.328152 loss_ctc0 66.498741 history loss 36.043251 rank 0
2022-08-22 22:53:52,744 DEBUG CV Batch 30/300 loss 28.030800 loss_att 19.902868 loss_ctc 46.995975 loss_ctc_origin 32.949310 loss_ctc0 79.771530 history loss 35.072591 rank 0
2022-08-22 22:54:04,038 DEBUG CV Batch 30/400 loss 44.643875 loss_att 35.258007 loss_ctc 66.544235 loss_ctc_origin 50.352684 loss_ctc0 104.324524 history loss 33.352592 rank 0
2022-08-22 22:54:15,541 DEBUG CV Batch 30/500 loss 28.392849 loss_att 19.324181 loss_ctc 49.553070 loss_ctc_origin 32.039757 loss_ctc0 90.417465 history loss 33.015956 rank 0
2022-08-22 22:54:27,002 DEBUG CV Batch 30/600 loss 27.561134 loss_att 18.087429 loss_ctc 49.666443 loss_ctc_origin 32.203743 loss_ctc0 90.412743 history loss 33.023249 rank 0
2022-08-22 22:54:37,590 DEBUG CV Batch 30/700 loss 25.380709 loss_att 18.230045 loss_ctc 42.065590 loss_ctc_origin 30.285429 loss_ctc0 69.552620 history loss 32.625472 rank 0
2022-08-22 22:54:48,502 DEBUG CV Batch 30/800 loss 25.510538 loss_att 18.166903 loss_ctc 42.645687 loss_ctc_origin 28.240719 loss_ctc0 76.257278 history loss 32.580314 rank 0
2022-08-22 22:54:59,312 INFO Epoch 30 CV info cv_loss 32.563402604181434
2022-08-22 22:54:59,312 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/30.pt
2022-08-22 22:54:59,796 INFO Epoch 31 TRAIN info lr 0.0015061539145635368
2022-08-22 22:54:59,799 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 22:55:27,232 DEBUG TRAIN Batch 31/0 loss 35.702263 loss_att 26.909426 loss_ctc 56.218891 loss_ctc_origin 47.268440 loss_ctc0 77.103279 lr 0.00150614 rank 0
2022-08-22 22:55:56,666 DEBUG TRAIN Batch 31/100 loss 39.333282 loss_att 27.055416 loss_ctc 67.981628 loss_ctc_origin 51.849312 loss_ctc0 105.623688 lr 0.00150571 rank 0
2022-08-22 22:56:26,166 DEBUG TRAIN Batch 31/200 loss 30.138599 loss_att 18.553621 loss_ctc 57.170216 loss_ctc_origin 50.160168 loss_ctc0 73.526993 lr 0.00150528 rank 0
2022-08-22 22:56:55,691 DEBUG TRAIN Batch 31/300 loss 36.447346 loss_att 23.012924 loss_ctc 67.794327 loss_ctc_origin 56.187477 loss_ctc0 94.876984 lr 0.00150486 rank 0
2022-08-22 22:57:24,827 DEBUG TRAIN Batch 31/400 loss 33.564209 loss_att 21.372984 loss_ctc 62.010391 loss_ctc_origin 47.163074 loss_ctc0 96.654129 lr 0.00150443 rank 0
2022-08-22 22:57:55,603 DEBUG TRAIN Batch 31/500 loss 31.895660 loss_att 25.972889 loss_ctc 45.715454 loss_ctc_origin 42.094215 loss_ctc0 54.165016 lr 0.00150401 rank 0
2022-08-22 22:58:03,925 WARNING NaN or Inf found in input tensor.
2022-08-22 22:58:24,285 DEBUG TRAIN Batch 31/600 loss 35.133888 loss_att 27.220270 loss_ctc 53.598995 loss_ctc_origin 46.682217 loss_ctc0 69.738144 lr 0.00150358 rank 0
2022-08-22 22:58:53,650 DEBUG TRAIN Batch 31/700 loss 30.480320 loss_att 21.370106 loss_ctc 51.737488 loss_ctc_origin 44.847466 loss_ctc0 67.814209 lr 0.00150316 rank 0
2022-08-22 22:59:23,302 DEBUG TRAIN Batch 31/800 loss 28.835472 loss_att 16.693954 loss_ctc 57.165680 loss_ctc_origin 45.420982 loss_ctc0 84.569977 lr 0.00150273 rank 0
2022-08-22 22:59:53,004 DEBUG TRAIN Batch 31/900 loss 35.580338 loss_att 20.479565 loss_ctc 70.815468 loss_ctc_origin 57.407616 loss_ctc0 102.100464 lr 0.00150231 rank 0
2022-08-22 23:00:22,724 DEBUG TRAIN Batch 31/1000 loss 31.979588 loss_att 27.025009 loss_ctc 43.540272 loss_ctc_origin 41.390594 loss_ctc0 48.556187 lr 0.00150188 rank 0
2022-08-22 23:00:37,474 WARNING NaN or Inf found in input tensor.
2022-08-22 23:00:44,606 WARNING NaN or Inf found in input tensor.
2022-08-22 23:00:52,061 DEBUG TRAIN Batch 31/1100 loss 48.742928 loss_att 34.680374 loss_ctc 81.555550 loss_ctc_origin 62.270882 loss_ctc0 126.553108 lr 0.00150146 rank 0
2022-08-22 23:01:20,875 DEBUG TRAIN Batch 31/1200 loss 24.671799 loss_att 14.040831 loss_ctc 49.477394 loss_ctc_origin 41.201492 loss_ctc0 68.787842 lr 0.00150104 rank 0
2022-08-22 23:01:51,660 DEBUG TRAIN Batch 31/1300 loss 35.457794 loss_att 20.766792 loss_ctc 69.736801 loss_ctc_origin 58.790424 loss_ctc0 95.278336 lr 0.00150062 rank 0
2022-08-22 23:02:21,416 DEBUG TRAIN Batch 31/1400 loss 34.767036 loss_att 21.664284 loss_ctc 65.340126 loss_ctc_origin 50.601334 loss_ctc0 99.730637 lr 0.00150019 rank 0
2022-08-22 23:02:31,048 WARNING NaN or Inf found in input tensor.
2022-08-22 23:02:57,709 DEBUG TRAIN Batch 31/1500 loss 34.628956 loss_att 24.521477 loss_ctc 58.213070 loss_ctc_origin 42.101906 loss_ctc0 95.805779 lr 0.00149977 rank 0
2022-08-22 23:03:27,886 DEBUG TRAIN Batch 31/1600 loss 36.346321 loss_att 21.904945 loss_ctc 70.042854 loss_ctc_origin 46.019104 loss_ctc0 126.098274 lr 0.00149935 rank 0
2022-08-22 23:03:56,406 DEBUG TRAIN Batch 31/1700 loss 31.648136 loss_att 22.180355 loss_ctc 53.739624 loss_ctc_origin 44.769585 loss_ctc0 74.669716 lr 0.00149893 rank 0
2022-08-22 23:04:25,834 DEBUG TRAIN Batch 31/1800 loss 35.590004 loss_att 23.848953 loss_ctc 62.985794 loss_ctc_origin 53.913521 loss_ctc0 84.154427 lr 0.00149851 rank 0
2022-08-22 23:04:49,871 WARNING NaN or Inf found in input tensor.
2022-08-22 23:04:54,409 DEBUG TRAIN Batch 31/1900 loss 33.836842 loss_att 21.384790 loss_ctc 62.891624 loss_ctc_origin 48.876255 loss_ctc0 95.594147 lr 0.00149809 rank 0
2022-08-22 23:05:22,862 DEBUG TRAIN Batch 31/2000 loss 29.380297 loss_att 23.588737 loss_ctc 42.893936 loss_ctc_origin 42.933887 loss_ctc0 42.800713 lr 0.00149767 rank 0
2022-08-22 23:05:52,602 DEBUG TRAIN Batch 31/2100 loss 31.141726 loss_att 21.272926 loss_ctc 54.168922 loss_ctc_origin 42.928253 loss_ctc0 80.397156 lr 0.00149725 rank 0
2022-08-22 23:06:22,718 DEBUG TRAIN Batch 31/2200 loss 28.639286 loss_att 20.348858 loss_ctc 47.983620 loss_ctc_origin 39.847336 loss_ctc0 66.968277 lr 0.00149683 rank 0
2022-08-22 23:06:52,553 DEBUG TRAIN Batch 31/2300 loss 36.887463 loss_att 22.265024 loss_ctc 71.006485 loss_ctc_origin 61.034943 loss_ctc0 94.273422 lr 0.00149641 rank 0
2022-08-22 23:07:21,337 DEBUG TRAIN Batch 31/2400 loss 42.777557 loss_att 26.382969 loss_ctc 81.031601 loss_ctc_origin 65.180328 loss_ctc0 118.017899 lr 0.00149599 rank 0
2022-08-22 23:07:50,907 DEBUG TRAIN Batch 31/2500 loss 30.775986 loss_att 24.475765 loss_ctc 45.476494 loss_ctc_origin 43.371624 loss_ctc0 50.387863 lr 0.00149557 rank 0
2022-08-22 23:08:20,320 DEBUG TRAIN Batch 31/2600 loss 62.047291 loss_att 37.551571 loss_ctc 119.203964 loss_ctc_origin 71.907822 loss_ctc0 229.561615 lr 0.00149515 rank 0
2022-08-22 23:08:48,933 DEBUG TRAIN Batch 31/2700 loss 27.401920 loss_att 17.985985 loss_ctc 49.372437 loss_ctc_origin 39.645260 loss_ctc0 72.069183 lr 0.00149474 rank 0
2022-08-22 23:09:18,628 DEBUG TRAIN Batch 31/2800 loss 30.920202 loss_att 19.226257 loss_ctc 58.206070 loss_ctc_origin 47.393204 loss_ctc0 83.436081 lr 0.00149432 rank 0
2022-08-22 23:09:48,281 DEBUG TRAIN Batch 31/2900 loss 32.437786 loss_att 20.835106 loss_ctc 59.510704 loss_ctc_origin 45.370285 loss_ctc0 92.505005 lr 0.00149390 rank 0
2022-08-22 23:10:25,195 DEBUG TRAIN Batch 31/3000 loss 38.463249 loss_att 26.722490 loss_ctc 65.858345 loss_ctc_origin 49.434212 loss_ctc0 104.181320 lr 0.00149349 rank 0
2022-08-22 23:10:33,419 WARNING NaN or Inf found in input tensor.
2022-08-22 23:10:55,415 DEBUG TRAIN Batch 31/3100 loss 46.607586 loss_att 30.043421 loss_ctc 85.257301 loss_ctc_origin 58.949005 loss_ctc0 146.643326 lr 0.00149307 rank 0
2022-08-22 23:11:25,622 DEBUG TRAIN Batch 31/3200 loss 26.816612 loss_att 17.706890 loss_ctc 48.072632 loss_ctc_origin 38.351875 loss_ctc0 70.754395 lr 0.00149265 rank 0
2022-08-22 23:11:54,440 DEBUG TRAIN Batch 31/3300 loss 35.234127 loss_att 21.179340 loss_ctc 68.028625 loss_ctc_origin 57.318176 loss_ctc0 93.019684 lr 0.00149224 rank 0
2022-08-22 23:12:20,346 WARNING NaN or Inf found in input tensor.
2022-08-22 23:12:24,999 DEBUG TRAIN Batch 31/3400 loss 36.560154 loss_att 21.980072 loss_ctc 70.580345 loss_ctc_origin 56.874119 loss_ctc0 102.561539 lr 0.00149182 rank 0
2022-08-22 23:12:55,094 DEBUG TRAIN Batch 31/3500 loss 35.894886 loss_att 28.527534 loss_ctc 53.085373 loss_ctc_origin 52.036560 loss_ctc0 55.532608 lr 0.00149141 rank 0
2022-08-22 23:13:24,116 DEBUG TRAIN Batch 31/3600 loss 56.696098 loss_att 37.555916 loss_ctc 101.356514 loss_ctc_origin 71.494293 loss_ctc0 171.035019 lr 0.00149099 rank 0
2022-08-22 23:13:53,531 DEBUG TRAIN Batch 31/3700 loss 27.258785 loss_att 18.556707 loss_ctc 47.563637 loss_ctc_origin 38.410545 loss_ctc0 68.920853 lr 0.00149058 rank 0
2022-08-22 23:14:22,816 DEBUG TRAIN Batch 31/3800 loss 33.146030 loss_att 18.718554 loss_ctc 66.810143 loss_ctc_origin 54.801922 loss_ctc0 94.829330 lr 0.00149017 rank 0
2022-08-22 23:14:52,952 DEBUG TRAIN Batch 31/3900 loss 39.588821 loss_att 25.491581 loss_ctc 72.482384 loss_ctc_origin 61.375229 loss_ctc0 98.399078 lr 0.00148975 rank 0
2022-08-22 23:15:21,741 DEBUG TRAIN Batch 31/4000 loss 32.427410 loss_att 25.608368 loss_ctc 48.338505 loss_ctc_origin 47.206932 loss_ctc0 50.978836 lr 0.00148934 rank 0
2022-08-22 23:15:50,944 DEBUG TRAIN Batch 31/4100 loss 47.830963 loss_att 33.092548 loss_ctc 82.220596 loss_ctc_origin 59.029072 loss_ctc0 136.334152 lr 0.00148893 rank 0
2022-08-22 23:16:19,634 DEBUG TRAIN Batch 31/4200 loss 32.307243 loss_att 23.604088 loss_ctc 52.614601 loss_ctc_origin 44.689449 loss_ctc0 71.106628 lr 0.00148851 rank 0
2022-08-22 23:16:49,539 DEBUG TRAIN Batch 31/4300 loss 38.556622 loss_att 25.914257 loss_ctc 68.055466 loss_ctc_origin 57.781380 loss_ctc0 92.028343 lr 0.00148810 rank 0
2022-08-22 23:17:18,595 DEBUG TRAIN Batch 31/4400 loss 40.287476 loss_att 26.481426 loss_ctc 72.501595 loss_ctc_origin 60.895576 loss_ctc0 99.582291 lr 0.00148769 rank 0
2022-08-22 23:17:36,242 WARNING NaN or Inf found in input tensor.
2022-08-22 23:17:55,914 DEBUG TRAIN Batch 31/4500 loss 23.225906 loss_att 18.476454 loss_ctc 34.307961 loss_ctc_origin 30.071863 loss_ctc0 44.192188 lr 0.00148728 rank 0
2022-08-22 23:18:25,416 DEBUG TRAIN Batch 31/4600 loss 49.156555 loss_att 36.629337 loss_ctc 78.386734 loss_ctc_origin 59.689102 loss_ctc0 122.014542 lr 0.00148687 rank 0
2022-08-22 23:18:53,079 WARNING NaN or Inf found in input tensor.
2022-08-22 23:18:54,743 DEBUG TRAIN Batch 31/4700 loss 27.834209 loss_att 18.415421 loss_ctc 49.811386 loss_ctc_origin 39.130764 loss_ctc0 74.732826 lr 0.00148646 rank 0
2022-08-22 23:19:24,435 DEBUG TRAIN Batch 31/4800 loss 30.299454 loss_att 19.620319 loss_ctc 55.217438 loss_ctc_origin 44.721710 loss_ctc0 79.707458 lr 0.00148605 rank 0
2022-08-22 23:19:53,952 DEBUG TRAIN Batch 31/4900 loss 36.351273 loss_att 21.573074 loss_ctc 70.833740 loss_ctc_origin 56.765739 loss_ctc0 103.659088 lr 0.00148564 rank 0
2022-08-22 23:20:23,399 DEBUG TRAIN Batch 31/5000 loss 32.266617 loss_att 25.439529 loss_ctc 48.196487 loss_ctc_origin 43.827126 loss_ctc0 58.391670 lr 0.00148523 rank 0
2022-08-22 23:20:52,075 DEBUG TRAIN Batch 31/5100 loss 42.114731 loss_att 28.513515 loss_ctc 73.850891 loss_ctc_origin 53.166183 loss_ctc0 122.115219 lr 0.00148482 rank 0
2022-08-22 23:21:21,654 DEBUG TRAIN Batch 31/5200 loss 31.887207 loss_att 22.221741 loss_ctc 54.439957 loss_ctc_origin 46.205677 loss_ctc0 73.653267 lr 0.00148441 rank 0
2022-08-22 23:21:51,429 DEBUG TRAIN Batch 31/5300 loss 30.355978 loss_att 18.886406 loss_ctc 57.118309 loss_ctc_origin 45.919910 loss_ctc0 83.247910 lr 0.00148400 rank 0
2022-08-22 23:22:21,758 DEBUG TRAIN Batch 31/5400 loss 29.486046 loss_att 16.641605 loss_ctc 59.456406 loss_ctc_origin 45.258926 loss_ctc0 92.583855 lr 0.00148359 rank 0
2022-08-22 23:22:51,427 DEBUG TRAIN Batch 31/5500 loss 23.156200 loss_att 15.735390 loss_ctc 40.471420 loss_ctc_origin 32.089401 loss_ctc0 60.029472 lr 0.00148318 rank 0
2022-08-22 23:23:13,059 WARNING NaN or Inf found in input tensor.
2022-08-22 23:23:19,893 DEBUG TRAIN Batch 31/5600 loss 36.492981 loss_att 25.156792 loss_ctc 62.944084 loss_ctc_origin 48.107758 loss_ctc0 97.562180 lr 0.00148278 rank 0
2022-08-22 23:23:42,875 DEBUG CV Batch 31/0 loss 22.112972 loss_att 15.103167 loss_ctc 38.469185 loss_ctc_origin 26.050352 loss_ctc0 67.446457 history loss 20.812209 rank 0
2022-08-22 23:23:53,823 DEBUG CV Batch 31/100 loss 35.968704 loss_att 26.189680 loss_ctc 58.786423 loss_ctc_origin 42.529076 loss_ctc0 96.720230 history loss 34.411148 rank 0
2022-08-22 23:24:04,219 DEBUG CV Batch 31/200 loss 30.031816 loss_att 22.771235 loss_ctc 46.973171 loss_ctc_origin 38.277756 loss_ctc0 67.262474 history loss 35.972016 rank 0
2022-08-22 23:24:14,678 DEBUG CV Batch 31/300 loss 27.941093 loss_att 20.170639 loss_ctc 46.072155 loss_ctc_origin 31.945343 loss_ctc0 79.034714 history loss 35.009993 rank 0
2022-08-22 23:24:25,971 DEBUG CV Batch 31/400 loss 43.813995 loss_att 34.717907 loss_ctc 65.038208 loss_ctc_origin 48.432453 loss_ctc0 103.784958 history loss 33.249374 rank 0
2022-08-22 23:24:37,179 DEBUG CV Batch 31/500 loss 27.249731 loss_att 18.895245 loss_ctc 46.743530 loss_ctc_origin 32.365883 loss_ctc0 80.291367 history loss 32.869788 rank 0
2022-08-22 23:24:48,356 DEBUG CV Batch 31/600 loss 27.148579 loss_att 18.144344 loss_ctc 48.158455 loss_ctc_origin 33.673988 loss_ctc0 81.955551 history loss 32.828147 rank 0
2022-08-22 23:24:58,847 DEBUG CV Batch 31/700 loss 23.305164 loss_att 16.041374 loss_ctc 40.254009 loss_ctc_origin 27.717247 loss_ctc0 69.506454 history loss 32.487753 rank 0
2022-08-22 23:25:09,943 DEBUG CV Batch 31/800 loss 25.103876 loss_att 17.870289 loss_ctc 41.982246 loss_ctc_origin 27.746086 loss_ctc0 75.199959 history loss 32.447090 rank 0
2022-08-22 23:25:20,453 INFO Epoch 31 CV info cv_loss 32.426345697390836
2022-08-22 23:25:20,454 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/31.pt
2022-08-22 23:25:20,928 INFO Epoch 32 TRAIN info lr 0.0014824334728433751
2022-08-22 23:25:20,932 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 23:25:48,537 DEBUG TRAIN Batch 32/0 loss 23.680353 loss_att 17.918318 loss_ctc 37.125103 loss_ctc_origin 32.397396 loss_ctc0 48.156418 lr 0.00148242 rank 0
2022-08-22 23:26:18,468 DEBUG TRAIN Batch 32/100 loss 39.930824 loss_att 27.912169 loss_ctc 67.974350 loss_ctc_origin 48.084309 loss_ctc0 114.384453 lr 0.00148201 rank 0
2022-08-22 23:26:48,394 DEBUG TRAIN Batch 32/200 loss 27.151196 loss_att 18.707603 loss_ctc 46.852909 loss_ctc_origin 36.511372 loss_ctc0 70.983162 lr 0.00148160 rank 0
2022-08-22 23:26:53,863 WARNING NaN or Inf found in input tensor.
2022-08-22 23:27:17,745 DEBUG TRAIN Batch 32/300 loss 32.335167 loss_att 19.857559 loss_ctc 61.449577 loss_ctc_origin 52.219360 loss_ctc0 82.986755 lr 0.00148120 rank 0
2022-08-22 23:27:47,217 DEBUG TRAIN Batch 32/400 loss 35.320644 loss_att 22.554642 loss_ctc 65.107979 loss_ctc_origin 52.571945 loss_ctc0 94.358719 lr 0.00148079 rank 0
2022-08-22 23:28:16,660 DEBUG TRAIN Batch 32/500 loss 30.901470 loss_att 24.667355 loss_ctc 45.447742 loss_ctc_origin 40.807503 loss_ctc0 56.274967 lr 0.00148039 rank 0
2022-08-22 23:28:45,651 DEBUG TRAIN Batch 32/600 loss 8.167779 loss_att 24.930626 loss_ctc -30.945526 loss_ctc_origin 47.364239 loss_ctc0 -213.668304 lr 0.00147998 rank 0
2022-08-22 23:29:14,558 DEBUG TRAIN Batch 32/700 loss 27.367371 loss_att 17.955006 loss_ctc 49.329559 loss_ctc_origin 40.346851 loss_ctc0 70.289200 lr 0.00147957 rank 0
2022-08-22 23:29:20,172 WARNING NaN or Inf found in input tensor.
2022-08-22 23:29:43,598 DEBUG TRAIN Batch 32/800 loss 29.042210 loss_att 17.998093 loss_ctc 54.811821 loss_ctc_origin 43.585396 loss_ctc0 81.006813 lr 0.00147917 rank 0
2022-08-22 23:30:12,886 DEBUG TRAIN Batch 32/900 loss 37.010384 loss_att 23.224670 loss_ctc 69.177048 loss_ctc_origin 56.249199 loss_ctc0 99.342026 lr 0.00147877 rank 0
2022-08-22 23:30:15,510 WARNING NaN or Inf found in input tensor.
2022-08-22 23:30:43,507 DEBUG TRAIN Batch 32/1000 loss 25.649910 loss_att 20.269199 loss_ctc 38.204899 loss_ctc_origin 35.998756 loss_ctc0 43.352562 lr 0.00147836 rank 0
2022-08-22 23:31:11,328 DEBUG TRAIN Batch 32/1100 loss 47.367905 loss_att 29.731659 loss_ctc 88.519150 loss_ctc_origin 54.808296 loss_ctc0 167.177795 lr 0.00147796 rank 0
2022-08-22 23:31:41,610 DEBUG TRAIN Batch 32/1200 loss 29.097099 loss_att 18.784580 loss_ctc 53.159637 loss_ctc_origin 43.754288 loss_ctc0 75.105461 lr 0.00147755 rank 0
2022-08-22 23:32:09,711 DEBUG TRAIN Batch 32/1300 loss 31.008818 loss_att 19.362411 loss_ctc 58.183762 loss_ctc_origin 46.906738 loss_ctc0 84.496811 lr 0.00147715 rank 0
2022-08-22 23:32:34,931 WARNING NaN or Inf found in input tensor.
2022-08-22 23:32:39,536 DEBUG TRAIN Batch 32/1400 loss 28.917652 loss_att 16.506050 loss_ctc 57.878052 loss_ctc_origin 43.482529 loss_ctc0 91.467598 lr 0.00147675 rank 0
2022-08-22 23:33:14,385 DEBUG TRAIN Batch 32/1500 loss 36.162533 loss_att 29.520052 loss_ctc 51.661659 loss_ctc_origin 45.762886 loss_ctc0 65.425461 lr 0.00147635 rank 0
2022-08-22 23:33:43,238 DEBUG TRAIN Batch 32/1600 loss 30.070877 loss_att 20.580914 loss_ctc 52.214123 loss_ctc_origin 38.392639 loss_ctc0 84.464249 lr 0.00147594 rank 0
2022-08-22 23:34:12,125 DEBUG TRAIN Batch 32/1700 loss 24.684105 loss_att 16.076736 loss_ctc 44.767967 loss_ctc_origin 36.356636 loss_ctc0 64.394402 lr 0.00147554 rank 0
2022-08-22 23:34:41,094 DEBUG TRAIN Batch 32/1800 loss 32.495995 loss_att 19.496275 loss_ctc 62.828674 loss_ctc_origin 52.186310 loss_ctc0 87.660858 lr 0.00147514 rank 0
2022-08-22 23:35:10,691 DEBUG TRAIN Batch 32/1900 loss 31.428528 loss_att 18.969248 loss_ctc 60.500183 loss_ctc_origin 47.855858 loss_ctc0 90.003616 lr 0.00147474 rank 0
2022-08-22 23:35:39,602 DEBUG TRAIN Batch 32/2000 loss 33.364182 loss_att 26.726418 loss_ctc 48.852303 loss_ctc_origin 44.309544 loss_ctc0 59.452080 lr 0.00147434 rank 0
2022-08-22 23:36:08,779 DEBUG TRAIN Batch 32/2100 loss 48.241493 loss_att 35.499195 loss_ctc 77.973526 loss_ctc_origin 60.677109 loss_ctc0 118.331833 lr 0.00147394 rank 0
2022-08-22 23:36:37,387 DEBUG TRAIN Batch 32/2200 loss 24.056206 loss_att 16.354847 loss_ctc 42.026039 loss_ctc_origin 32.360134 loss_ctc0 64.579819 lr 0.00147354 rank 0
2022-08-22 23:37:05,748 DEBUG TRAIN Batch 32/2300 loss 30.514477 loss_att 18.312832 loss_ctc 58.984978 loss_ctc_origin 47.206005 loss_ctc0 86.469238 lr 0.00147314 rank 0
2022-08-22 23:37:35,904 DEBUG TRAIN Batch 32/2400 loss 30.775139 loss_att 17.239477 loss_ctc 62.358353 loss_ctc_origin 47.008995 loss_ctc0 98.173523 lr 0.00147274 rank 0
2022-08-22 23:38:06,489 DEBUG TRAIN Batch 32/2500 loss 33.039177 loss_att 24.599281 loss_ctc 52.732262 loss_ctc_origin 44.083092 loss_ctc0 72.913666 lr 0.00147234 rank 0
2022-08-22 23:38:35,681 DEBUG TRAIN Batch 32/2600 loss 39.206772 loss_att 27.611464 loss_ctc 66.262497 loss_ctc_origin 48.254112 loss_ctc0 108.282059 lr 0.00147194 rank 0
2022-08-22 23:39:03,244 DEBUG TRAIN Batch 32/2700 loss 29.786457 loss_att 21.724049 loss_ctc 48.598740 loss_ctc_origin 40.183441 loss_ctc0 68.234428 lr 0.00147154 rank 0
2022-08-22 23:39:32,607 DEBUG TRAIN Batch 32/2800 loss 27.637419 loss_att 14.764055 loss_ctc 57.675262 loss_ctc_origin 46.961533 loss_ctc0 82.673965 lr 0.00147115 rank 0
2022-08-22 23:40:00,990 DEBUG TRAIN Batch 32/2900 loss 37.274986 loss_att 23.289234 loss_ctc 69.908401 loss_ctc_origin 57.218937 loss_ctc0 99.517151 lr 0.00147075 rank 0
2022-08-22 23:40:38,200 DEBUG TRAIN Batch 32/3000 loss 44.629482 loss_att 31.960749 loss_ctc 74.189857 loss_ctc_origin 53.222256 loss_ctc0 123.114258 lr 0.00147035 rank 0
2022-08-22 23:41:07,433 DEBUG TRAIN Batch 32/3100 loss 52.004726 loss_att 34.533997 loss_ctc 92.769760 loss_ctc_origin 62.931503 loss_ctc0 162.392349 lr 0.00146995 rank 0
2022-08-22 23:41:34,909 WARNING NaN or Inf found in input tensor.
2022-08-22 23:41:36,619 DEBUG TRAIN Batch 32/3200 loss 31.016405 loss_att 20.004328 loss_ctc 56.711250 loss_ctc_origin 50.646374 loss_ctc0 70.862625 lr 0.00146956 rank 0
2022-08-22 23:42:05,358 DEBUG TRAIN Batch 32/3300 loss 32.758827 loss_att 21.208868 loss_ctc 59.708733 loss_ctc_origin 48.755699 loss_ctc0 85.265808 lr 0.00146916 rank 0
2022-08-22 23:42:34,825 DEBUG TRAIN Batch 32/3400 loss 39.330944 loss_att 25.471493 loss_ctc 71.669662 loss_ctc_origin 60.450256 loss_ctc0 97.848282 lr 0.00146876 rank 0
2022-08-22 23:43:04,725 DEBUG TRAIN Batch 32/3500 loss 31.939201 loss_att 25.436111 loss_ctc 47.113075 loss_ctc_origin 41.495472 loss_ctc0 60.220821 lr 0.00146837 rank 0
2022-08-22 23:43:34,261 DEBUG TRAIN Batch 32/3600 loss 40.093998 loss_att 25.394039 loss_ctc 74.393898 loss_ctc_origin 47.375992 loss_ctc0 137.435684 lr 0.00146797 rank 0
2022-08-22 23:44:04,489 DEBUG TRAIN Batch 32/3700 loss 27.329479 loss_att 17.849785 loss_ctc 49.448761 loss_ctc_origin 40.703461 loss_ctc0 69.854462 lr 0.00146758 rank 0
2022-08-22 23:44:34,258 DEBUG TRAIN Batch 32/3800 loss 31.261244 loss_att 19.675426 loss_ctc 58.294815 loss_ctc_origin 46.838802 loss_ctc0 85.025497 lr 0.00146718 rank 0
2022-08-22 23:45:02,341 DEBUG TRAIN Batch 32/3900 loss 35.060009 loss_att 22.255201 loss_ctc 64.937897 loss_ctc_origin 51.683601 loss_ctc0 95.864586 lr 0.00146679 rank 0
2022-08-22 23:45:31,422 DEBUG TRAIN Batch 32/4000 loss 33.887672 loss_att 26.889145 loss_ctc 50.217564 loss_ctc_origin 42.284069 loss_ctc0 68.729050 lr 0.00146639 rank 0
2022-08-22 23:46:00,335 DEBUG TRAIN Batch 32/4100 loss 34.648048 loss_att 25.287275 loss_ctc 56.489853 loss_ctc_origin 44.080551 loss_ctc0 85.444893 lr 0.00146600 rank 0
2022-08-22 23:46:27,912 DEBUG TRAIN Batch 32/4200 loss 32.925632 loss_att 22.662125 loss_ctc 56.873817 loss_ctc_origin 49.101013 loss_ctc0 75.010361 lr 0.00146560 rank 0
2022-08-22 23:46:54,422 WARNING NaN or Inf found in input tensor.
2022-08-22 23:46:57,083 DEBUG TRAIN Batch 32/4300 loss 32.338123 loss_att 20.399303 loss_ctc 60.195366 loss_ctc_origin 50.824783 loss_ctc0 82.060059 lr 0.00146521 rank 0
2022-08-22 23:47:25,265 DEBUG TRAIN Batch 32/4400 loss 37.362900 loss_att 23.978823 loss_ctc 68.592407 loss_ctc_origin 50.848869 loss_ctc0 109.993988 lr 0.00146482 rank 0
2022-08-22 23:47:58,105 DEBUG TRAIN Batch 32/4500 loss 27.827171 loss_att 22.362307 loss_ctc 40.578522 loss_ctc_origin 33.754749 loss_ctc0 56.500652 lr 0.00146443 rank 0
2022-08-22 23:48:26,724 DEBUG TRAIN Batch 32/4600 loss 34.667267 loss_att 24.386288 loss_ctc 58.656216 loss_ctc_origin 43.056705 loss_ctc0 95.055069 lr 0.00146403 rank 0
2022-08-22 23:48:54,869 DEBUG TRAIN Batch 32/4700 loss 27.414427 loss_att 17.308924 loss_ctc 50.993935 loss_ctc_origin 41.460907 loss_ctc0 73.237656 lr 0.00146364 rank 0
2022-08-22 23:49:23,541 DEBUG TRAIN Batch 32/4800 loss 34.943924 loss_att 21.825363 loss_ctc 65.553902 loss_ctc_origin 54.182480 loss_ctc0 92.087219 lr 0.00146325 rank 0
2022-08-22 23:49:51,418 DEBUG TRAIN Batch 32/4900 loss 31.652611 loss_att 18.937693 loss_ctc 61.320747 loss_ctc_origin 47.517807 loss_ctc0 93.527618 lr 0.00146286 rank 0
2022-08-22 23:50:19,369 DEBUG TRAIN Batch 32/5000 loss 29.699678 loss_att 23.367638 loss_ctc 44.474442 loss_ctc_origin 39.202221 loss_ctc0 56.776283 lr 0.00146247 rank 0
2022-08-22 23:50:27,024 WARNING NaN or Inf found in input tensor.
2022-08-22 23:50:47,744 DEBUG TRAIN Batch 32/5100 loss 33.080433 loss_att 22.378006 loss_ctc 58.052757 loss_ctc_origin 41.975357 loss_ctc0 95.566689 lr 0.00146208 rank 0
2022-08-22 23:51:15,535 DEBUG TRAIN Batch 32/5200 loss 29.671818 loss_att 21.127651 loss_ctc 49.608204 loss_ctc_origin 41.135445 loss_ctc0 69.377975 lr 0.00146169 rank 0
2022-08-22 23:51:43,729 DEBUG TRAIN Batch 32/5300 loss 31.148552 loss_att 19.612873 loss_ctc 58.065132 loss_ctc_origin 47.584503 loss_ctc0 82.519928 lr 0.00146130 rank 0
2022-08-22 23:52:13,620 DEBUG TRAIN Batch 32/5400 loss 31.967379 loss_att 18.952419 loss_ctc 62.335617 loss_ctc_origin 47.100121 loss_ctc0 97.885109 lr 0.00146091 rank 0
2022-08-22 23:52:40,680 DEBUG TRAIN Batch 32/5500 loss 34.470478 loss_att 28.547350 loss_ctc 48.291107 loss_ctc_origin 44.881817 loss_ctc0 56.246113 lr 0.00146052 rank 0
2022-08-22 23:53:09,093 DEBUG TRAIN Batch 32/5600 loss 36.939377 loss_att 25.143415 loss_ctc 64.463287 loss_ctc_origin 45.843910 loss_ctc0 107.908508 lr 0.00146013 rank 0
2022-08-22 23:53:32,492 DEBUG CV Batch 32/0 loss 20.560402 loss_att 13.024879 loss_ctc 38.143284 loss_ctc_origin 23.265926 loss_ctc0 72.857117 history loss 19.350967 rank 0
2022-08-22 23:53:43,550 DEBUG CV Batch 32/100 loss 31.605263 loss_att 21.994209 loss_ctc 54.031052 loss_ctc_origin 35.709557 loss_ctc0 96.781212 history loss 34.223979 rank 0
2022-08-22 23:53:53,974 DEBUG CV Batch 32/200 loss 30.596992 loss_att 23.998360 loss_ctc 45.993805 loss_ctc_origin 36.887321 loss_ctc0 67.242264 history loss 35.565132 rank 0
2022-08-22 23:54:04,606 DEBUG CV Batch 32/300 loss 28.953257 loss_att 21.243359 loss_ctc 46.943016 loss_ctc_origin 33.015324 loss_ctc0 79.440971 history loss 34.551350 rank 0
2022-08-22 23:54:15,536 DEBUG CV Batch 32/400 loss 44.649212 loss_att 35.433784 loss_ctc 66.151878 loss_ctc_origin 50.250828 loss_ctc0 103.254333 history loss 32.687751 rank 0
2022-08-22 23:54:27,064 DEBUG CV Batch 32/500 loss 25.922466 loss_att 17.019564 loss_ctc 46.695908 loss_ctc_origin 30.487442 loss_ctc0 84.515656 history loss 32.286401 rank 0
2022-08-22 23:54:38,071 DEBUG CV Batch 32/600 loss 27.564919 loss_att 17.334988 loss_ctc 51.434753 loss_ctc_origin 30.304960 loss_ctc0 100.737602 history loss 32.162399 rank 0
2022-08-22 23:54:48,737 DEBUG CV Batch 32/700 loss 24.727833 loss_att 16.990332 loss_ctc 42.781998 loss_ctc_origin 31.168001 loss_ctc0 69.881317 history loss 31.808349 rank 0
2022-08-22 23:55:00,003 DEBUG CV Batch 32/800 loss 25.842669 loss_att 18.703966 loss_ctc 42.499638 loss_ctc_origin 28.057993 loss_ctc0 76.196808 history loss 31.762305 rank 0
2022-08-22 23:55:11,059 INFO Epoch 32 CV info cv_loss 31.811618807860494
2022-08-22 23:55:11,060 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/32.pt
2022-08-22 23:55:11,533 INFO Epoch 33 TRAIN info lr 0.0014597995715996896
2022-08-22 23:55:11,537 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-22 23:55:39,144 DEBUG TRAIN Batch 33/0 loss 33.034866 loss_att 26.050404 loss_ctc 49.331936 loss_ctc_origin 40.973133 loss_ctc0 68.835808 lr 0.00145978 rank 0
2022-08-22 23:56:08,172 DEBUG TRAIN Batch 33/100 loss 34.923775 loss_att 22.244097 loss_ctc 64.509682 loss_ctc_origin 40.229164 loss_ctc0 121.164215 lr 0.00145940 rank 0
2022-08-22 23:56:37,797 DEBUG TRAIN Batch 33/200 loss 32.150650 loss_att 20.756016 loss_ctc 58.738125 loss_ctc_origin 50.550888 loss_ctc0 77.841682 lr 0.00145901 rank 0
2022-08-22 23:57:07,179 DEBUG TRAIN Batch 33/300 loss 28.706951 loss_att 15.840000 loss_ctc 58.729828 loss_ctc_origin 45.300159 loss_ctc0 90.065720 lr 0.00145862 rank 0
2022-08-22 23:57:36,882 DEBUG TRAIN Batch 33/400 loss 34.369713 loss_att 19.918243 loss_ctc 68.089806 loss_ctc_origin 56.336666 loss_ctc0 95.513794 lr 0.00145823 rank 0
2022-08-22 23:58:07,170 DEBUG TRAIN Batch 33/500 loss 26.478043 loss_att 20.791674 loss_ctc 39.746231 loss_ctc_origin 33.710907 loss_ctc0 53.828659 lr 0.00145784 rank 0
2022-08-22 23:58:36,570 DEBUG TRAIN Batch 33/600 loss 32.407078 loss_att 23.912731 loss_ctc 52.227222 loss_ctc_origin 40.431778 loss_ctc0 79.749924 lr 0.00145746 rank 0
2022-08-22 23:59:05,658 DEBUG TRAIN Batch 33/700 loss 27.387630 loss_att 16.687588 loss_ctc 52.354397 loss_ctc_origin 43.398018 loss_ctc0 73.252609 lr 0.00145707 rank 0
2022-08-22 23:59:35,692 DEBUG TRAIN Batch 33/800 loss 33.307487 loss_att 19.198662 loss_ctc 66.228073 loss_ctc_origin 55.567078 loss_ctc0 91.103714 lr 0.00145668 rank 0
2022-08-22 23:59:54,388 WARNING NaN or Inf found in input tensor.
2022-08-23 00:00:06,276 DEBUG TRAIN Batch 33/900 loss 31.384472 loss_att 17.744522 loss_ctc 63.211021 loss_ctc_origin 48.552620 loss_ctc0 97.413971 lr 0.00145630 rank 0
2022-08-23 00:00:36,451 DEBUG TRAIN Batch 33/1000 loss 29.565323 loss_att 20.732826 loss_ctc 50.174477 loss_ctc_origin 37.336418 loss_ctc0 80.129951 lr 0.00145591 rank 0
2022-08-23 00:01:05,290 DEBUG TRAIN Batch 33/1100 loss 38.862560 loss_att 25.899136 loss_ctc 69.110550 loss_ctc_origin 51.450157 loss_ctc0 110.318123 lr 0.00145553 rank 0
2022-08-23 00:01:34,530 DEBUG TRAIN Batch 33/1200 loss 24.805534 loss_att 15.603294 loss_ctc 46.277428 loss_ctc_origin 37.000778 loss_ctc0 67.922935 lr 0.00145514 rank 0
2022-08-23 00:02:04,809 DEBUG TRAIN Batch 33/1300 loss 30.700550 loss_att 18.308556 loss_ctc 59.615200 loss_ctc_origin 47.545891 loss_ctc0 87.776917 lr 0.00145476 rank 0
2022-08-23 00:02:34,194 DEBUG TRAIN Batch 33/1400 loss 35.427582 loss_att 20.899765 loss_ctc 69.325813 loss_ctc_origin 55.880695 loss_ctc0 100.697754 lr 0.00145437 rank 0
2022-08-23 00:03:10,973 DEBUG TRAIN Batch 33/1500 loss 32.440250 loss_att 23.362747 loss_ctc 53.621090 loss_ctc_origin 45.635895 loss_ctc0 72.253212 lr 0.00145399 rank 0
2022-08-23 00:03:40,929 DEBUG TRAIN Batch 33/1600 loss 34.477432 loss_att 25.629681 loss_ctc 55.122177 loss_ctc_origin 43.523727 loss_ctc0 82.185226 lr 0.00145360 rank 0
2022-08-23 00:04:10,328 DEBUG TRAIN Batch 33/1700 loss 24.168352 loss_att 14.464126 loss_ctc 46.811546 loss_ctc_origin 37.209919 loss_ctc0 69.215332 lr 0.00145322 rank 0
2022-08-23 00:04:40,866 DEBUG TRAIN Batch 33/1800 loss 33.845234 loss_att 21.089123 loss_ctc 63.609489 loss_ctc_origin 52.737022 loss_ctc0 88.978569 lr 0.00145283 rank 0
2022-08-23 00:05:10,257 DEBUG TRAIN Batch 33/1900 loss 39.317207 loss_att 24.216034 loss_ctc 74.553268 loss_ctc_origin 61.987270 loss_ctc0 103.873932 lr 0.00145245 rank 0
2022-08-23 00:05:40,577 DEBUG TRAIN Batch 33/2000 loss 28.237436 loss_att 21.911669 loss_ctc 42.997559 loss_ctc_origin 36.878929 loss_ctc0 57.274364 lr 0.00145207 rank 0
2022-08-23 00:06:10,509 DEBUG TRAIN Batch 33/2100 loss 33.998726 loss_att 24.432590 loss_ctc 56.319710 loss_ctc_origin 46.054359 loss_ctc0 80.272179 lr 0.00145169 rank 0
2022-08-23 00:06:39,223 DEBUG TRAIN Batch 33/2200 loss 27.388649 loss_att 17.175390 loss_ctc 51.219585 loss_ctc_origin 41.890015 loss_ctc0 72.988586 lr 0.00145130 rank 0
2022-08-23 00:07:09,675 DEBUG TRAIN Batch 33/2300 loss 31.314102 loss_att 17.964027 loss_ctc 62.464272 loss_ctc_origin 51.364326 loss_ctc0 88.364136 lr 0.00145092 rank 0
2022-08-23 00:07:39,549 DEBUG TRAIN Batch 33/2400 loss 42.057888 loss_att 26.808809 loss_ctc 77.639069 loss_ctc_origin 62.856400 loss_ctc0 112.131966 lr 0.00145054 rank 0
2022-08-23 00:08:08,929 DEBUG TRAIN Batch 33/2500 loss 32.559986 loss_att 26.201038 loss_ctc 47.397533 loss_ctc_origin 45.001324 loss_ctc0 52.988686 lr 0.00145016 rank 0
2022-08-23 00:08:37,679 DEBUG TRAIN Batch 33/2600 loss 43.447903 loss_att 27.316418 loss_ctc 81.088028 loss_ctc_origin 58.485657 loss_ctc0 133.826889 lr 0.00144978 rank 0
2022-08-23 00:09:05,249 WARNING NaN or Inf found in input tensor.
2022-08-23 00:09:06,780 DEBUG TRAIN Batch 33/2700 loss 28.101423 loss_att 19.051758 loss_ctc 49.217308 loss_ctc_origin 40.539688 loss_ctc0 69.465088 lr 0.00144940 rank 0
2022-08-23 00:09:37,103 DEBUG TRAIN Batch 33/2800 loss 27.295319 loss_att 15.460560 loss_ctc 54.909752 loss_ctc_origin 42.656006 loss_ctc0 83.501831 lr 0.00144902 rank 0
2022-08-23 00:10:07,932 DEBUG TRAIN Batch 33/2900 loss 41.398994 loss_att 25.870159 loss_ctc 77.632935 loss_ctc_origin 66.014130 loss_ctc0 104.743477 lr 0.00144864 rank 0
2022-08-23 00:10:43,903 DEBUG TRAIN Batch 33/3000 loss 28.796967 loss_att 22.601831 loss_ctc 43.252285 loss_ctc_origin 38.848232 loss_ctc0 53.528408 lr 0.00144826 rank 0
2022-08-23 00:11:14,235 DEBUG TRAIN Batch 33/3100 loss 30.683197 loss_att 18.336525 loss_ctc 59.492096 loss_ctc_origin 39.949284 loss_ctc0 105.091988 lr 0.00144788 rank 0
2022-08-23 00:11:44,100 DEBUG TRAIN Batch 33/3200 loss 31.829082 loss_att 23.383314 loss_ctc 51.535873 loss_ctc_origin 43.177696 loss_ctc0 71.038284 lr 0.00144750 rank 0
2022-08-23 00:12:13,767 DEBUG TRAIN Batch 33/3300 loss 30.977652 loss_att 18.585033 loss_ctc 59.893757 loss_ctc_origin 47.975075 loss_ctc0 87.704018 lr 0.00144712 rank 0
2022-08-23 00:12:43,737 DEBUG TRAIN Batch 33/3400 loss 29.024900 loss_att 16.690004 loss_ctc 57.806324 loss_ctc_origin 41.919014 loss_ctc0 94.876709 lr 0.00144674 rank 0
2022-08-23 00:13:13,933 DEBUG TRAIN Batch 33/3500 loss 28.737522 loss_att 20.847170 loss_ctc 47.148346 loss_ctc_origin 35.657364 loss_ctc0 73.960632 lr 0.00144636 rank 0
2022-08-23 00:13:43,183 DEBUG TRAIN Batch 33/3600 loss 33.358391 loss_att 23.366255 loss_ctc 56.673367 loss_ctc_origin 40.408989 loss_ctc0 94.623581 lr 0.00144598 rank 0
2022-08-23 00:14:12,288 DEBUG TRAIN Batch 33/3700 loss 29.493027 loss_att 18.347420 loss_ctc 55.499439 loss_ctc_origin 46.088856 loss_ctc0 77.457466 lr 0.00144561 rank 0
2022-08-23 00:14:41,606 DEBUG TRAIN Batch 33/3800 loss 30.407764 loss_att 18.222174 loss_ctc 58.840805 loss_ctc_origin 47.391083 loss_ctc0 85.556824 lr 0.00144523 rank 0
2022-08-23 00:15:11,606 DEBUG TRAIN Batch 33/3900 loss 33.005455 loss_att 18.515482 loss_ctc 66.815392 loss_ctc_origin 51.028442 loss_ctc0 103.651596 lr 0.00144485 rank 0
2022-08-23 00:15:40,778 DEBUG TRAIN Batch 33/4000 loss 31.397575 loss_att 25.231464 loss_ctc 45.785164 loss_ctc_origin 43.574673 loss_ctc0 50.942986 lr 0.00144447 rank 0
2022-08-23 00:16:10,952 DEBUG TRAIN Batch 33/4100 loss 33.175358 loss_att 22.558163 loss_ctc 57.948807 loss_ctc_origin 42.917530 loss_ctc0 93.021774 lr 0.00144410 rank 0
2022-08-23 00:16:40,612 DEBUG TRAIN Batch 33/4200 loss 30.193420 loss_att 20.389156 loss_ctc 53.070038 loss_ctc_origin 45.053936 loss_ctc0 71.774269 lr 0.00144372 rank 0
2022-08-23 00:17:10,953 DEBUG TRAIN Batch 33/4300 loss 29.614250 loss_att 18.822174 loss_ctc 54.795761 loss_ctc_origin 43.360020 loss_ctc0 81.479149 lr 0.00144335 rank 0
2022-08-23 00:17:40,645 DEBUG TRAIN Batch 33/4400 loss 39.564304 loss_att 24.459681 loss_ctc 74.808426 loss_ctc_origin 58.666515 loss_ctc0 112.472900 lr 0.00144297 rank 0
2022-08-23 00:18:15,373 DEBUG TRAIN Batch 33/4500 loss 37.266441 loss_att 30.554396 loss_ctc 52.927887 loss_ctc_origin 47.335182 loss_ctc0 65.977524 lr 0.00144259 rank 0
2022-08-23 00:18:44,702 DEBUG TRAIN Batch 33/4600 loss 35.895393 loss_att 23.856401 loss_ctc 63.986374 loss_ctc_origin 45.701401 loss_ctc0 106.651306 lr 0.00144222 rank 0
2022-08-23 00:19:15,122 DEBUG TRAIN Batch 33/4700 loss 28.682833 loss_att 20.567566 loss_ctc 47.618454 loss_ctc_origin 39.250748 loss_ctc0 67.143097 lr 0.00144184 rank 0
2022-08-23 00:19:44,707 DEBUG TRAIN Batch 33/4800 loss 27.739918 loss_att 17.853794 loss_ctc 50.807541 loss_ctc_origin 40.085907 loss_ctc0 75.824692 lr 0.00144147 rank 0
2022-08-23 00:20:13,714 DEBUG TRAIN Batch 33/4900 loss 36.934029 loss_att 21.993948 loss_ctc 71.794220 loss_ctc_origin 56.768185 loss_ctc0 106.854980 lr 0.00144110 rank 0
2022-08-23 00:20:43,155 DEBUG TRAIN Batch 33/5000 loss 38.623779 loss_att 27.415512 loss_ctc 64.776398 loss_ctc_origin 45.732491 loss_ctc0 109.212189 lr 0.00144072 rank 0
2022-08-23 00:21:12,227 DEBUG TRAIN Batch 33/5100 loss 42.253799 loss_att 25.291128 loss_ctc 81.833366 loss_ctc_origin 44.862068 loss_ctc0 168.099716 lr 0.00144035 rank 0
2022-08-23 00:21:40,866 DEBUG TRAIN Batch 33/5200 loss 27.392895 loss_att 17.405951 loss_ctc 50.695766 loss_ctc_origin 41.434311 loss_ctc0 72.305832 lr 0.00143997 rank 0
2022-08-23 00:22:11,263 DEBUG TRAIN Batch 33/5300 loss 27.016541 loss_att 15.670436 loss_ctc 53.490780 loss_ctc_origin 40.676331 loss_ctc0 83.391159 lr 0.00143960 rank 0
2022-08-23 00:22:29,545 WARNING NaN or Inf found in input tensor.
2022-08-23 00:22:41,306 DEBUG TRAIN Batch 33/5400 loss 31.701763 loss_att 18.738033 loss_ctc 61.950462 loss_ctc_origin 46.915638 loss_ctc0 97.031723 lr 0.00143923 rank 0
2022-08-23 00:22:44,081 WARNING NaN or Inf found in input tensor.
2022-08-23 00:23:11,050 DEBUG TRAIN Batch 33/5500 loss 35.123306 loss_att 25.108589 loss_ctc 58.490974 loss_ctc_origin 40.465305 loss_ctc0 100.550858 lr 0.00143886 rank 0
2022-08-23 00:23:32,596 WARNING NaN or Inf found in input tensor.
2022-08-23 00:23:39,995 DEBUG TRAIN Batch 33/5600 loss 38.851795 loss_att 22.712025 loss_ctc 76.511253 loss_ctc_origin 43.295216 loss_ctc0 154.015350 lr 0.00143848 rank 0
2022-08-23 00:24:03,262 DEBUG CV Batch 33/0 loss 34.475060 loss_att 18.968279 loss_ctc 70.657547 loss_ctc_origin 33.579704 loss_ctc0 157.172516 history loss 32.447115 rank 0
2022-08-23 00:24:14,422 DEBUG CV Batch 33/100 loss 51.052017 loss_att 29.759865 loss_ctc 100.733704 loss_ctc_origin 51.588326 loss_ctc0 215.406250 history loss 39.212520 rank 0
2022-08-23 00:24:24,795 DEBUG CV Batch 33/200 loss 34.155876 loss_att 24.841820 loss_ctc 55.888672 loss_ctc_origin 40.174271 loss_ctc0 92.555603 history loss 41.053029 rank 0
2022-08-23 00:24:35,272 DEBUG CV Batch 33/300 loss 28.515427 loss_att 20.464577 loss_ctc 47.300743 loss_ctc_origin 33.339531 loss_ctc0 79.876900 history loss 40.017428 rank 0
2022-08-23 00:24:46,274 DEBUG CV Batch 33/400 loss 44.411766 loss_att 34.670879 loss_ctc 67.140495 loss_ctc_origin 51.073402 loss_ctc0 104.630386 history loss 38.054809 rank 0
2022-08-23 00:24:57,418 DEBUG CV Batch 33/500 loss 42.351227 loss_att 27.110014 loss_ctc 77.914062 loss_ctc_origin 43.286774 loss_ctc0 158.711060 history loss 37.745660 rank 0
2022-08-23 00:25:08,376 DEBUG CV Batch 33/600 loss 58.856911 loss_att 33.296383 loss_ctc 118.498138 loss_ctc_origin 60.608620 loss_ctc0 253.573669 history loss 37.887144 rank 0
2022-08-23 00:25:18,762 DEBUG CV Batch 33/700 loss 23.884510 loss_att 16.580570 loss_ctc 40.927032 loss_ctc_origin 28.359188 loss_ctc0 70.251999 history loss 37.485086 rank 0
2022-08-23 00:25:29,845 DEBUG CV Batch 33/800 loss 25.556210 loss_att 18.408171 loss_ctc 42.234966 loss_ctc_origin 27.244904 loss_ctc0 77.211777 history loss 37.374098 rank 0
2022-08-23 00:25:40,700 INFO Epoch 33 CV info cv_loss 37.11826136856574
2022-08-23 00:25:40,700 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/33.pt
2022-08-23 00:25:41,174 INFO Epoch 34 TRAIN info lr 0.0014381717156433987
2022-08-23 00:25:41,177 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 00:26:09,163 DEBUG TRAIN Batch 34/0 loss 36.435677 loss_att 26.612913 loss_ctc 59.355453 loss_ctc_origin 47.723862 loss_ctc0 86.495819 lr 0.00143816 rank 0
2022-08-23 00:26:38,617 DEBUG TRAIN Batch 34/100 loss 43.366249 loss_att 27.266071 loss_ctc 80.933334 loss_ctc_origin 48.532822 loss_ctc0 156.534546 lr 0.00143779 rank 0
2022-08-23 00:27:05,832 WARNING NaN or Inf found in input tensor.
2022-08-23 00:27:07,469 DEBUG TRAIN Batch 34/200 loss 27.684151 loss_att 18.508795 loss_ctc 49.093315 loss_ctc_origin 40.295540 loss_ctc0 69.621468 lr 0.00143741 rank 0
2022-08-23 00:27:37,912 DEBUG TRAIN Batch 34/300 loss 32.638767 loss_att 18.370308 loss_ctc 65.931831 loss_ctc_origin 54.151627 loss_ctc0 93.418961 lr 0.00143704 rank 0
2022-08-23 00:28:07,332 DEBUG TRAIN Batch 34/400 loss 35.473267 loss_att 21.434120 loss_ctc 68.231277 loss_ctc_origin 54.182411 loss_ctc0 101.011948 lr 0.00143667 rank 0
2022-08-23 00:28:37,494 DEBUG TRAIN Batch 34/500 loss 27.952423 loss_att 24.347321 loss_ctc 36.364334 loss_ctc_origin 34.112103 loss_ctc0 41.619541 lr 0.00143630 rank 0
2022-08-23 00:29:05,229 WARNING NaN or Inf found in input tensor.
2022-08-23 00:29:05,270 DEBUG TRAIN Batch 34/600 loss nan loss_att 27.409969 loss_ctc nan loss_ctc_origin 44.222862 loss_ctc0 nan lr 0.00143593 rank 0
2022-08-23 00:29:35,261 DEBUG TRAIN Batch 34/700 loss 29.993862 loss_att 21.171040 loss_ctc 50.580444 loss_ctc_origin 41.588486 loss_ctc0 71.561668 lr 0.00143556 rank 0
2022-08-23 00:30:05,472 DEBUG TRAIN Batch 34/800 loss 34.505146 loss_att 20.232788 loss_ctc 67.807312 loss_ctc_origin 56.235535 loss_ctc0 94.808121 lr 0.00143519 rank 0
2022-08-23 00:30:36,869 DEBUG TRAIN Batch 34/900 loss 38.032352 loss_att 22.619980 loss_ctc 73.994560 loss_ctc_origin 59.479950 loss_ctc0 107.861984 lr 0.00143482 rank 0
2022-08-23 00:31:05,317 DEBUG TRAIN Batch 34/1000 loss 33.336464 loss_att 23.605877 loss_ctc 56.041161 loss_ctc_origin 35.957047 loss_ctc0 102.904099 lr 0.00143445 rank 0
2022-08-23 00:31:34,149 DEBUG TRAIN Batch 34/1100 loss 42.404598 loss_att 27.348377 loss_ctc 77.535782 loss_ctc_origin 52.567101 loss_ctc0 135.796051 lr 0.00143408 rank 0
2022-08-23 00:32:04,027 DEBUG TRAIN Batch 34/1200 loss 30.974312 loss_att 22.213573 loss_ctc 51.416031 loss_ctc_origin 42.683037 loss_ctc0 71.793015 lr 0.00143372 rank 0
2022-08-23 00:32:32,813 DEBUG TRAIN Batch 34/1300 loss 28.532190 loss_att 16.345932 loss_ctc 56.966789 loss_ctc_origin 46.245354 loss_ctc0 81.983467 lr 0.00143335 rank 0
2022-08-23 00:33:02,121 DEBUG TRAIN Batch 34/1400 loss 40.324100 loss_att 25.097660 loss_ctc 75.852463 loss_ctc_origin 62.437195 loss_ctc0 107.154739 lr 0.00143298 rank 0
2022-08-23 00:33:38,640 DEBUG TRAIN Batch 34/1500 loss 33.793373 loss_att 27.047106 loss_ctc 49.534668 loss_ctc_origin 33.972961 loss_ctc0 85.845306 lr 0.00143261 rank 0
2022-08-23 00:34:07,853 DEBUG TRAIN Batch 34/1600 loss 36.091278 loss_att 25.075241 loss_ctc 61.795372 loss_ctc_origin 44.084953 loss_ctc0 103.119675 lr 0.00143224 rank 0
2022-08-23 00:34:38,458 DEBUG TRAIN Batch 34/1700 loss 31.451849 loss_att 20.660259 loss_ctc 56.632225 loss_ctc_origin 47.341698 loss_ctc0 78.310120 lr 0.00143188 rank 0
2022-08-23 00:35:07,850 DEBUG TRAIN Batch 34/1800 loss 35.081650 loss_att 21.788557 loss_ctc 66.098862 loss_ctc_origin 55.766788 loss_ctc0 90.207031 lr 0.00143151 rank 0
2022-08-23 00:35:37,171 DEBUG TRAIN Batch 34/1900 loss 32.252125 loss_att 18.352158 loss_ctc 64.685379 loss_ctc_origin 50.433044 loss_ctc0 97.940819 lr 0.00143114 rank 0
2022-08-23 00:36:06,834 DEBUG TRAIN Batch 34/2000 loss 30.369936 loss_att 23.681763 loss_ctc 45.975670 loss_ctc_origin 40.342876 loss_ctc0 59.118847 lr 0.00143078 rank 0
2022-08-23 00:36:36,709 DEBUG TRAIN Batch 34/2100 loss 30.459545 loss_att 19.462767 loss_ctc 56.118690 loss_ctc_origin 39.811913 loss_ctc0 94.167831 lr 0.00143041 rank 0
2022-08-23 00:37:05,340 DEBUG TRAIN Batch 34/2200 loss 26.112148 loss_att 17.032475 loss_ctc 47.298050 loss_ctc_origin 38.352341 loss_ctc0 68.171371 lr 0.00143005 rank 0
2022-08-23 00:37:33,868 DEBUG TRAIN Batch 34/2300 loss 28.319786 loss_att 17.048340 loss_ctc 54.619827 loss_ctc_origin 43.103027 loss_ctc0 81.492363 lr 0.00142968 rank 0
2022-08-23 00:37:58,294 WARNING NaN or Inf found in input tensor.
2022-08-23 00:38:02,925 DEBUG TRAIN Batch 34/2400 loss 34.928238 loss_att 21.039333 loss_ctc 67.335678 loss_ctc_origin 52.976448 loss_ctc0 100.840553 lr 0.00142932 rank 0
2022-08-23 00:38:32,592 DEBUG TRAIN Batch 34/2500 loss 25.672955 loss_att 18.090769 loss_ctc 43.364716 loss_ctc_origin 31.399035 loss_ctc0 71.284637 lr 0.00142895 rank 0
2022-08-23 00:39:01,443 DEBUG TRAIN Batch 34/2600 loss 32.847607 loss_att 20.269035 loss_ctc 62.197609 loss_ctc_origin 42.419418 loss_ctc0 108.346718 lr 0.00142859 rank 0
2022-08-23 00:39:31,854 DEBUG TRAIN Batch 34/2700 loss 26.953468 loss_att 16.613628 loss_ctc 51.079758 loss_ctc_origin 40.097321 loss_ctc0 76.705437 lr 0.00142822 rank 0
2022-08-23 00:40:00,383 DEBUG TRAIN Batch 34/2800 loss 34.726452 loss_att 21.148163 loss_ctc 66.409126 loss_ctc_origin 55.961948 loss_ctc0 90.785881 lr 0.00142786 rank 0
2022-08-23 00:40:28,981 DEBUG TRAIN Batch 34/2900 loss 27.347044 loss_att 13.931819 loss_ctc 58.649231 loss_ctc_origin 43.300964 loss_ctc0 94.461853 lr 0.00142749 rank 0
2022-08-23 00:41:05,970 DEBUG TRAIN Batch 34/3000 loss 30.616375 loss_att 22.569103 loss_ctc 49.393341 loss_ctc_origin 40.889473 loss_ctc0 69.235695 lr 0.00142713 rank 0
2022-08-23 00:41:34,680 DEBUG TRAIN Batch 34/3100 loss 33.343254 loss_att 22.626516 loss_ctc 58.348976 loss_ctc_origin 41.253716 loss_ctc0 98.237915 lr 0.00142677 rank 0
2022-08-23 00:42:03,927 DEBUG TRAIN Batch 34/3200 loss 30.478748 loss_att 18.103399 loss_ctc 59.354561 loss_ctc_origin 51.472061 loss_ctc0 77.747063 lr 0.00142640 rank 0
2022-08-23 00:42:33,184 DEBUG TRAIN Batch 34/3300 loss 25.402882 loss_att 14.278303 loss_ctc 51.360229 loss_ctc_origin 39.860222 loss_ctc0 78.193573 lr 0.00142604 rank 0
2022-08-23 00:43:03,090 DEBUG TRAIN Batch 34/3400 loss 39.077385 loss_att 23.092121 loss_ctc 76.376343 loss_ctc_origin 62.832397 loss_ctc0 107.978867 lr 0.00142568 rank 0
2022-08-23 00:43:33,780 DEBUG TRAIN Batch 34/3500 loss 27.035366 loss_att 18.826662 loss_ctc 46.189007 loss_ctc_origin 36.224777 loss_ctc0 69.438873 lr 0.00142532 rank 0
2022-08-23 00:44:01,912 DEBUG TRAIN Batch 34/3600 loss 40.956692 loss_att 28.143917 loss_ctc 70.853165 loss_ctc_origin 49.367592 loss_ctc0 120.986183 lr 0.00142496 rank 0
2022-08-23 00:44:31,828 DEBUG TRAIN Batch 34/3700 loss 28.717400 loss_att 18.324785 loss_ctc 52.966827 loss_ctc_origin 43.675453 loss_ctc0 74.646706 lr 0.00142459 rank 0
2022-08-23 00:45:01,257 DEBUG TRAIN Batch 34/3800 loss 28.240280 loss_att 16.943344 loss_ctc 54.599800 loss_ctc_origin 42.395535 loss_ctc0 83.076416 lr 0.00142423 rank 0
2022-08-23 00:45:30,123 DEBUG TRAIN Batch 34/3900 loss 35.818752 loss_att 21.279026 loss_ctc 69.744774 loss_ctc_origin 56.369659 loss_ctc0 100.953369 lr 0.00142387 rank 0
2022-08-23 00:46:00,395 DEBUG TRAIN Batch 34/4000 loss 33.260239 loss_att 23.943874 loss_ctc 54.998413 loss_ctc_origin 47.534618 loss_ctc0 72.413933 lr 0.00142351 rank 0
2022-08-23 00:46:30,059 DEBUG TRAIN Batch 34/4100 loss 33.162331 loss_att 22.270044 loss_ctc 58.577667 loss_ctc_origin 42.409805 loss_ctc0 96.302673 lr 0.00142315 rank 0
2022-08-23 00:47:00,054 DEBUG TRAIN Batch 34/4200 loss 25.317711 loss_att 15.419492 loss_ctc 48.413551 loss_ctc_origin 38.874763 loss_ctc0 70.670723 lr 0.00142279 rank 0
2022-08-23 00:47:30,328 DEBUG TRAIN Batch 34/4300 loss 28.968756 loss_att 16.996784 loss_ctc 56.903355 loss_ctc_origin 45.215652 loss_ctc0 84.174652 lr 0.00142243 rank 0
2022-08-23 00:48:00,732 DEBUG TRAIN Batch 34/4400 loss 38.212975 loss_att 22.996759 loss_ctc 73.717476 loss_ctc_origin 59.910728 loss_ctc0 105.933228 lr 0.00142207 rank 0
2022-08-23 00:48:36,594 DEBUG TRAIN Batch 34/4500 loss 26.724915 loss_att 19.099525 loss_ctc 44.517483 loss_ctc_origin 36.181019 loss_ctc0 63.969231 lr 0.00142171 rank 0
2022-08-23 00:49:06,249 DEBUG TRAIN Batch 34/4600 loss 31.996323 loss_att 20.684071 loss_ctc 58.391575 loss_ctc_origin 43.395119 loss_ctc0 93.383301 lr 0.00142135 rank 0
2022-08-23 00:49:36,038 DEBUG TRAIN Batch 34/4700 loss 27.550694 loss_att 17.848785 loss_ctc 50.188480 loss_ctc_origin 40.559399 loss_ctc0 72.656334 lr 0.00142099 rank 0
2022-08-23 00:50:05,052 DEBUG TRAIN Batch 34/4800 loss 30.613461 loss_att 18.933998 loss_ctc 57.865536 loss_ctc_origin 47.191055 loss_ctc0 82.772659 lr 0.00142064 rank 0
2022-08-23 00:50:34,699 DEBUG TRAIN Batch 34/4900 loss 32.266045 loss_att 18.583317 loss_ctc 64.192413 loss_ctc_origin 50.194756 loss_ctc0 96.853607 lr 0.00142028 rank 0
2022-08-23 00:51:03,553 DEBUG TRAIN Batch 34/5000 loss 32.274963 loss_att 25.224880 loss_ctc 48.725151 loss_ctc_origin 42.548271 loss_ctc0 63.137867 lr 0.00141992 rank 0
2022-08-23 00:51:31,967 DEBUG TRAIN Batch 34/5100 loss 31.719587 loss_att 20.807449 loss_ctc 57.181244 loss_ctc_origin 39.748978 loss_ctc0 97.856529 lr 0.00141956 rank 0
2022-08-23 00:52:01,232 DEBUG TRAIN Batch 34/5200 loss 27.988819 loss_att 17.650120 loss_ctc 52.112453 loss_ctc_origin 43.491146 loss_ctc0 72.228836 lr 0.00141920 rank 0
2022-08-23 00:52:29,970 DEBUG TRAIN Batch 34/5300 loss 28.645134 loss_att 16.446590 loss_ctc 57.108398 loss_ctc_origin 46.015491 loss_ctc0 82.991852 lr 0.00141885 rank 0
2022-08-23 00:52:59,683 DEBUG TRAIN Batch 34/5400 loss 29.540470 loss_att 16.593739 loss_ctc 59.749508 loss_ctc_origin 43.674381 loss_ctc0 97.258133 lr 0.00141849 rank 0
2022-08-23 00:53:28,954 DEBUG TRAIN Batch 34/5500 loss 30.396538 loss_att 21.916611 loss_ctc 50.183029 loss_ctc_origin 44.479294 loss_ctc0 63.491734 lr 0.00141813 rank 0
2022-08-23 00:54:01,374 DEBUG TRAIN Batch 34/5600 loss 39.212975 loss_att 22.624245 loss_ctc 77.920013 loss_ctc_origin 47.934383 loss_ctc0 147.886475 lr 0.00141778 rank 0
2022-08-23 00:54:24,930 DEBUG CV Batch 34/0 loss 27.925901 loss_att 16.808178 loss_ctc 53.867256 loss_ctc_origin 28.812809 loss_ctc0 112.327621 history loss 26.283201 rank 0
2022-08-23 00:54:35,699 DEBUG CV Batch 34/100 loss 40.039871 loss_att 23.978287 loss_ctc 77.516899 loss_ctc_origin 40.165974 loss_ctc0 164.669052 history loss 36.422983 rank 0
2022-08-23 00:54:46,034 DEBUG CV Batch 34/200 loss 29.924870 loss_att 22.786364 loss_ctc 46.581383 loss_ctc_origin 37.793472 loss_ctc0 67.086494 history loss 38.016469 rank 0
2022-08-23 00:54:56,730 DEBUG CV Batch 34/300 loss 28.009995 loss_att 20.334389 loss_ctc 45.919739 loss_ctc_origin 32.210381 loss_ctc0 77.908249 history loss 37.046964 rank 0
2022-08-23 00:55:08,059 DEBUG CV Batch 34/400 loss 43.657784 loss_att 34.349514 loss_ctc 65.377075 loss_ctc_origin 49.278389 loss_ctc0 102.940681 history loss 35.076301 rank 0
2022-08-23 00:55:20,058 DEBUG CV Batch 34/500 loss 27.703890 loss_att 17.544498 loss_ctc 51.409134 loss_ctc_origin 28.228626 loss_ctc0 105.496979 history loss 34.682793 rank 0
2022-08-23 00:55:31,256 DEBUG CV Batch 34/600 loss 34.810131 loss_att 20.431370 loss_ctc 68.360565 loss_ctc_origin 38.808243 loss_ctc0 137.315979 history loss 34.762139 rank 0
2022-08-23 00:55:42,007 DEBUG CV Batch 34/700 loss 23.525110 loss_att 16.245674 loss_ctc 40.510460 loss_ctc_origin 28.239666 loss_ctc0 69.142311 history loss 34.375342 rank 0
2022-08-23 00:55:53,141 DEBUG CV Batch 34/800 loss 25.590946 loss_att 18.816017 loss_ctc 41.399113 loss_ctc_origin 26.689329 loss_ctc0 75.721939 history loss 34.275026 rank 0
2022-08-23 00:56:03,602 INFO Epoch 34 CV info cv_loss 34.117628657078136
2022-08-23 00:56:03,602 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/34.pt
2022-08-23 00:56:04,141 INFO Epoch 35 TRAIN info lr 0.0014174775185418743
2022-08-23 00:56:04,145 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 00:56:32,065 DEBUG TRAIN Batch 35/0 loss 36.224564 loss_att 25.944176 loss_ctc 60.212139 loss_ctc_origin 42.955994 loss_ctc0 100.476479 lr 0.00141746 rank 0
2022-08-23 00:56:32,810 WARNING NaN or Inf found in input tensor.
2022-08-23 00:57:01,816 DEBUG TRAIN Batch 35/100 loss 41.417503 loss_att 24.783096 loss_ctc 80.231125 loss_ctc_origin 49.067032 loss_ctc0 152.947357 lr 0.00141711 rank 0
2022-08-23 00:57:32,026 DEBUG TRAIN Batch 35/200 loss 22.830738 loss_att 13.233676 loss_ctc 45.223885 loss_ctc_origin 34.956764 loss_ctc0 69.180496 lr 0.00141675 rank 0
2022-08-23 00:57:37,289 WARNING NaN or Inf found in input tensor.
2022-08-23 00:58:01,417 DEBUG TRAIN Batch 35/300 loss 32.429703 loss_att 19.496325 loss_ctc 62.607582 loss_ctc_origin 52.722214 loss_ctc0 85.673447 lr 0.00141640 rank 0
2022-08-23 00:58:31,504 DEBUG TRAIN Batch 35/400 loss 36.924366 loss_att 22.373947 loss_ctc 70.875336 loss_ctc_origin 57.886795 loss_ctc0 101.181915 lr 0.00141604 rank 0
2022-08-23 00:58:34,324 WARNING NaN or Inf found in input tensor.
2022-08-23 00:59:01,584 DEBUG TRAIN Batch 35/500 loss 27.785534 loss_att 20.825897 loss_ctc 44.024681 loss_ctc_origin 32.818546 loss_ctc0 70.172318 lr 0.00141569 rank 0
2022-08-23 00:59:30,388 DEBUG TRAIN Batch 35/600 loss 29.250931 loss_att 19.087334 loss_ctc 52.965992 loss_ctc_origin 38.876564 loss_ctc0 85.841324 lr 0.00141533 rank 0
2022-08-23 00:59:59,572 DEBUG TRAIN Batch 35/700 loss 26.602551 loss_att 17.697638 loss_ctc 47.380684 loss_ctc_origin 38.947048 loss_ctc0 67.059158 lr 0.00141498 rank 0
2022-08-23 01:00:28,832 DEBUG TRAIN Batch 35/800 loss 29.955215 loss_att 18.520077 loss_ctc 56.637211 loss_ctc_origin 45.666435 loss_ctc0 82.235680 lr 0.00141462 rank 0
2022-08-23 01:00:57,991 DEBUG TRAIN Batch 35/900 loss 32.781590 loss_att 17.871538 loss_ctc 67.571709 loss_ctc_origin 53.408112 loss_ctc0 100.620102 lr 0.00141427 rank 0
2022-08-23 01:01:28,239 DEBUG TRAIN Batch 35/1000 loss 27.446274 loss_att 18.793249 loss_ctc 47.636665 loss_ctc_origin 36.423340 loss_ctc0 73.801086 lr 0.00141392 rank 0
2022-08-23 01:01:57,180 DEBUG TRAIN Batch 35/1100 loss 42.386070 loss_att 29.888950 loss_ctc 71.546013 loss_ctc_origin 51.126373 loss_ctc0 119.191833 lr 0.00141356 rank 0
2022-08-23 01:02:26,647 DEBUG TRAIN Batch 35/1200 loss 25.976418 loss_att 15.995081 loss_ctc 49.266205 loss_ctc_origin 39.353882 loss_ctc0 72.394958 lr 0.00141321 rank 0
2022-08-23 01:02:55,923 DEBUG TRAIN Batch 35/1300 loss 30.209785 loss_att 17.507427 loss_ctc 59.848621 loss_ctc_origin 49.198769 loss_ctc0 84.698280 lr 0.00141286 rank 0
2022-08-23 01:03:20,561 WARNING NaN or Inf found in input tensor.
2022-08-23 01:03:25,288 DEBUG TRAIN Batch 35/1400 loss 32.923706 loss_att 20.276773 loss_ctc 62.433212 loss_ctc_origin 47.771576 loss_ctc0 96.643692 lr 0.00141251 rank 0
2022-08-23 01:04:01,765 DEBUG TRAIN Batch 35/1500 loss 26.772379 loss_att 20.934286 loss_ctc 40.394592 loss_ctc_origin 37.446026 loss_ctc0 47.274586 lr 0.00141215 rank 0
2022-08-23 01:04:10,413 WARNING NaN or Inf found in input tensor.
2022-08-23 01:04:31,201 DEBUG TRAIN Batch 35/1600 loss 40.769321 loss_att 26.534161 loss_ctc 73.984695 loss_ctc_origin 50.048218 loss_ctc0 129.836472 lr 0.00141180 rank 0
2022-08-23 01:05:01,011 DEBUG TRAIN Batch 35/1700 loss 25.831261 loss_att 16.660818 loss_ctc 47.228958 loss_ctc_origin 37.617928 loss_ctc0 69.654701 lr 0.00141145 rank 0
2022-08-23 01:05:06,648 WARNING NaN or Inf found in input tensor.
2022-08-23 01:05:30,603 DEBUG TRAIN Batch 35/1800 loss 27.742399 loss_att 15.107221 loss_ctc 57.224480 loss_ctc_origin 45.765579 loss_ctc0 83.961914 lr 0.00141110 rank 0
2022-08-23 01:06:00,598 DEBUG TRAIN Batch 35/1900 loss 34.178249 loss_att 19.840088 loss_ctc 67.633957 loss_ctc_origin 54.459030 loss_ctc0 98.375458 lr 0.00141075 rank 0
2022-08-23 01:06:30,349 DEBUG TRAIN Batch 35/2000 loss 35.284794 loss_att 26.241936 loss_ctc 56.384796 loss_ctc_origin 48.391357 loss_ctc0 75.036148 lr 0.00141040 rank 0
2022-08-23 01:06:59,984 DEBUG TRAIN Batch 35/2100 loss 39.616474 loss_att 26.329601 loss_ctc 70.619171 loss_ctc_origin 51.614937 loss_ctc0 114.962372 lr 0.00141005 rank 0
2022-08-23 01:07:29,685 DEBUG TRAIN Batch 35/2200 loss 30.200424 loss_att 17.752888 loss_ctc 59.244675 loss_ctc_origin 50.211899 loss_ctc0 80.321159 lr 0.00140970 rank 0
2022-08-23 01:07:59,354 DEBUG TRAIN Batch 35/2300 loss 29.538662 loss_att 17.826986 loss_ctc 56.865898 loss_ctc_origin 45.994747 loss_ctc0 82.231911 lr 0.00140935 rank 0
2022-08-23 01:08:29,352 DEBUG TRAIN Batch 35/2400 loss 32.930931 loss_att 17.536276 loss_ctc 68.851784 loss_ctc_origin 53.539566 loss_ctc0 104.580284 lr 0.00140900 rank 0
2022-08-23 01:08:58,741 DEBUG TRAIN Batch 35/2500 loss 32.200607 loss_att 26.058956 loss_ctc 46.531128 loss_ctc_origin 39.156059 loss_ctc0 63.739616 lr 0.00140865 rank 0
2022-08-23 01:09:28,472 DEBUG TRAIN Batch 35/2600 loss 39.155483 loss_att 29.153593 loss_ctc 62.493225 loss_ctc_origin 48.180389 loss_ctc0 95.889832 lr 0.00140830 rank 0
2022-08-23 01:09:57,469 DEBUG TRAIN Batch 35/2700 loss 24.601683 loss_att 14.429939 loss_ctc 48.335751 loss_ctc_origin 39.206280 loss_ctc0 69.637848 lr 0.00140795 rank 0
2022-08-23 01:10:26,739 DEBUG TRAIN Batch 35/2800 loss 29.129646 loss_att 16.648520 loss_ctc 58.252274 loss_ctc_origin 45.407600 loss_ctc0 88.223175 lr 0.00140760 rank 0
2022-08-23 01:10:52,683 WARNING NaN or Inf found in input tensor.
2022-08-23 01:10:57,255 DEBUG TRAIN Batch 35/2900 loss 37.492569 loss_att 22.636580 loss_ctc 72.156548 loss_ctc_origin 59.209267 loss_ctc0 102.366867 lr 0.00140725 rank 0
2022-08-23 01:11:33,156 DEBUG TRAIN Batch 35/3000 loss 36.474430 loss_att 29.780788 loss_ctc 52.092926 loss_ctc_origin 43.735695 loss_ctc0 71.593124 lr 0.00140690 rank 0
2022-08-23 01:12:02,949 WARNING NaN or Inf found in input tensor.
2022-08-23 01:12:02,996 DEBUG TRAIN Batch 35/3100 loss nan loss_att 25.206560 loss_ctc nan loss_ctc_origin 43.784348 loss_ctc0 nan lr 0.00140655 rank 0
2022-08-23 01:12:33,327 DEBUG TRAIN Batch 35/3200 loss 30.523582 loss_att 20.050497 loss_ctc 54.960773 loss_ctc_origin 45.933617 loss_ctc0 76.024139 lr 0.00140621 rank 0
2022-08-23 01:13:03,315 DEBUG TRAIN Batch 35/3300 loss 30.463715 loss_att 17.131737 loss_ctc 61.571663 loss_ctc_origin 50.322807 loss_ctc0 87.818993 lr 0.00140586 rank 0
2022-08-23 01:13:33,498 DEBUG TRAIN Batch 35/3400 loss 36.926868 loss_att 22.503031 loss_ctc 70.582489 loss_ctc_origin 57.700470 loss_ctc0 100.640549 lr 0.00140551 rank 0
2022-08-23 01:14:02,441 DEBUG TRAIN Batch 35/3500 loss 32.708557 loss_att 23.349651 loss_ctc 54.546005 loss_ctc_origin 41.505589 loss_ctc0 84.973648 lr 0.00140517 rank 0
2022-08-23 01:14:32,151 DEBUG TRAIN Batch 35/3600 loss 34.383148 loss_att 23.068565 loss_ctc 60.783836 loss_ctc_origin 44.695572 loss_ctc0 98.323128 lr 0.00140482 rank 0
2022-08-23 01:15:01,211 DEBUG TRAIN Batch 35/3700 loss 27.117943 loss_att 16.688328 loss_ctc 51.453705 loss_ctc_origin 41.235325 loss_ctc0 75.296585 lr 0.00140447 rank 0
2022-08-23 01:15:06,850 WARNING NaN or Inf found in input tensor.
2022-08-23 01:15:30,631 DEBUG TRAIN Batch 35/3800 loss 25.976435 loss_att 14.601498 loss_ctc 52.517952 loss_ctc_origin 39.960014 loss_ctc0 81.819809 lr 0.00140413 rank 0
2022-08-23 01:15:55,929 WARNING NaN or Inf found in input tensor.
2022-08-23 01:16:00,667 DEBUG TRAIN Batch 35/3900 loss 36.126560 loss_att 22.841486 loss_ctc 67.125061 loss_ctc_origin 53.553505 loss_ctc0 98.792023 lr 0.00140378 rank 0
2022-08-23 01:16:31,075 DEBUG TRAIN Batch 35/4000 loss 34.892654 loss_att 26.332018 loss_ctc 54.867477 loss_ctc_origin 43.339630 loss_ctc0 81.765793 lr 0.00140343 rank 0
2022-08-23 01:16:45,429 WARNING NaN or Inf found in input tensor.
2022-08-23 01:16:52,970 WARNING NaN or Inf found in input tensor.
2022-08-23 01:17:00,366 DEBUG TRAIN Batch 35/4100 loss 36.941467 loss_att 25.162729 loss_ctc 64.425179 loss_ctc_origin 46.290085 loss_ctc0 106.740395 lr 0.00140309 rank 0
2022-08-23 01:17:29,255 DEBUG TRAIN Batch 35/4200 loss 33.093216 loss_att 22.787804 loss_ctc 57.139175 loss_ctc_origin 49.455700 loss_ctc0 75.067291 lr 0.00140274 rank 0
2022-08-23 01:17:41,851 WARNING NaN or Inf found in input tensor.
2022-08-23 01:17:58,669 DEBUG TRAIN Batch 35/4300 loss 33.348766 loss_att 18.317167 loss_ctc 68.422501 loss_ctc_origin 57.280891 loss_ctc0 94.419594 lr 0.00140240 rank 0
2022-08-23 01:18:23,887 WARNING NaN or Inf found in input tensor.
2022-08-23 01:18:28,136 DEBUG TRAIN Batch 35/4400 loss 34.552097 loss_att 20.448975 loss_ctc 67.459381 loss_ctc_origin 55.870956 loss_ctc0 94.499046 lr 0.00140205 rank 0
2022-08-23 01:19:04,063 DEBUG TRAIN Batch 35/4500 loss 29.933147 loss_att 22.894995 loss_ctc 46.355499 loss_ctc_origin 34.896141 loss_ctc0 73.093994 lr 0.00140171 rank 0
2022-08-23 01:19:33,933 DEBUG TRAIN Batch 35/4600 loss 42.173981 loss_att 27.801891 loss_ctc 75.708862 loss_ctc_origin 51.168633 loss_ctc0 132.969391 lr 0.00140137 rank 0
2022-08-23 01:20:03,209 DEBUG TRAIN Batch 35/4700 loss 26.976452 loss_att 17.922131 loss_ctc 48.103203 loss_ctc_origin 39.080593 loss_ctc0 69.155960 lr 0.00140102 rank 0
2022-08-23 01:20:32,544 DEBUG TRAIN Batch 35/4800 loss 31.369114 loss_att 18.449989 loss_ctc 61.513733 loss_ctc_origin 50.789505 loss_ctc0 86.536919 lr 0.00140068 rank 0
2022-08-23 01:21:01,686 DEBUG TRAIN Batch 35/4900 loss 36.052834 loss_att 21.509718 loss_ctc 69.986771 loss_ctc_origin 57.342453 loss_ctc0 99.490173 lr 0.00140034 rank 0
2022-08-23 01:21:33,473 DEBUG TRAIN Batch 35/5000 loss 28.553825 loss_att 23.863491 loss_ctc 39.497944 loss_ctc_origin 36.801929 loss_ctc0 45.788643 lr 0.00139999 rank 0
2022-08-23 01:22:01,998 DEBUG TRAIN Batch 35/5100 loss 37.095215 loss_att 23.530994 loss_ctc 68.745064 loss_ctc_origin 43.284653 loss_ctc0 128.152679 lr 0.00139965 rank 0
2022-08-23 01:22:31,757 DEBUG TRAIN Batch 35/5200 loss 28.213337 loss_att 18.387911 loss_ctc 51.139328 loss_ctc_origin 43.175674 loss_ctc0 69.721191 lr 0.00139931 rank 0
2022-08-23 01:23:01,954 DEBUG TRAIN Batch 35/5300 loss 31.467052 loss_att 19.152122 loss_ctc 60.201881 loss_ctc_origin 49.439796 loss_ctc0 85.313416 lr 0.00139896 rank 0
2022-08-23 01:23:32,369 DEBUG TRAIN Batch 35/5400 loss 31.029026 loss_att 17.815577 loss_ctc 61.860405 loss_ctc_origin 45.326813 loss_ctc0 100.438782 lr 0.00139862 rank 0
2022-08-23 01:24:01,227 DEBUG TRAIN Batch 35/5500 loss 29.747379 loss_att 21.815868 loss_ctc 48.254238 loss_ctc_origin 42.022522 loss_ctc0 62.794907 lr 0.00139828 rank 0
2022-08-23 01:24:32,352 DEBUG TRAIN Batch 35/5600 loss 32.003910 loss_att 21.964268 loss_ctc 55.429737 loss_ctc_origin 36.253479 loss_ctc0 100.174332 lr 0.00139794 rank 0
2022-08-23 01:24:56,439 DEBUG CV Batch 35/0 loss 24.665411 loss_att 14.770373 loss_ctc 47.753830 loss_ctc_origin 25.804813 loss_ctc0 98.968201 history loss 23.214504 rank 0
2022-08-23 01:25:07,417 DEBUG CV Batch 35/100 loss 30.819908 loss_att 18.274044 loss_ctc 60.093586 loss_ctc_origin 30.269106 loss_ctc0 129.684036 history loss 35.683316 rank 0
2022-08-23 01:25:17,390 DEBUG CV Batch 35/200 loss 28.770069 loss_att 21.061165 loss_ctc 46.757507 loss_ctc_origin 36.065266 loss_ctc0 71.706062 history loss 37.268689 rank 0
2022-08-23 01:25:27,711 DEBUG CV Batch 35/300 loss 29.280663 loss_att 21.674541 loss_ctc 47.028275 loss_ctc_origin 33.393448 loss_ctc0 78.842865 history loss 36.193966 rank 0
2022-08-23 01:25:39,119 DEBUG CV Batch 35/400 loss 43.004936 loss_att 33.857712 loss_ctc 64.348457 loss_ctc_origin 48.288219 loss_ctc0 101.822334 history loss 34.290005 rank 0
2022-08-23 01:25:50,781 DEBUG CV Batch 35/500 loss 30.161598 loss_att 17.304726 loss_ctc 60.160965 loss_ctc_origin 30.187128 loss_ctc0 130.099915 history loss 33.836586 rank 0
2022-08-23 01:26:01,956 DEBUG CV Batch 35/600 loss 31.457733 loss_att 17.403708 loss_ctc 64.250458 loss_ctc_origin 30.636770 loss_ctc0 142.682373 history loss 33.812400 rank 0
2022-08-23 01:26:12,970 DEBUG CV Batch 35/700 loss 23.652401 loss_att 16.410023 loss_ctc 40.551285 loss_ctc_origin 28.542301 loss_ctc0 68.572250 history loss 33.460112 rank 0
2022-08-23 01:26:24,322 DEBUG CV Batch 35/800 loss 26.442001 loss_att 19.616486 loss_ctc 42.368202 loss_ctc_origin 28.195871 loss_ctc0 75.436966 history loss 33.379973 rank 0
2022-08-23 01:26:35,175 INFO Epoch 35 CV info cv_loss 33.29575308121248
2022-08-23 01:26:35,176 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/35.pt
2022-08-23 01:26:35,650 INFO Epoch 36 TRAIN info lr 0.0013976516817406322
2022-08-23 01:26:35,654 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 01:27:04,324 DEBUG TRAIN Batch 36/0 loss 33.553043 loss_att 23.910255 loss_ctc 56.052879 loss_ctc_origin 41.994995 loss_ctc0 88.854614 lr 0.00139764 rank 0
2022-08-23 01:27:19,926 WARNING NaN or Inf found in input tensor.
2022-08-23 01:27:33,527 DEBUG TRAIN Batch 36/100 loss 34.962440 loss_att 23.276112 loss_ctc 62.230545 loss_ctc_origin 47.448574 loss_ctc0 96.721802 lr 0.00139730 rank 0
2022-08-23 01:28:03,294 DEBUG TRAIN Batch 36/200 loss 25.638630 loss_att 15.028708 loss_ctc 50.395111 loss_ctc_origin 40.368874 loss_ctc0 73.789673 lr 0.00139696 rank 0
2022-08-23 01:28:32,032 DEBUG TRAIN Batch 36/300 loss 32.186722 loss_att 18.141104 loss_ctc 64.959831 loss_ctc_origin 53.077007 loss_ctc0 92.686417 lr 0.00139662 rank 0
2022-08-23 01:28:56,036 WARNING NaN or Inf found in input tensor.
2022-08-23 01:29:00,591 DEBUG TRAIN Batch 36/400 loss 34.858814 loss_att 19.141914 loss_ctc 71.531578 loss_ctc_origin 58.268055 loss_ctc0 102.479782 lr 0.00139627 rank 0
2022-08-23 01:29:31,026 DEBUG TRAIN Batch 36/500 loss 30.097359 loss_att 22.057796 loss_ctc 48.856339 loss_ctc_origin 39.744667 loss_ctc0 70.116913 lr 0.00139593 rank 0
2022-08-23 01:30:00,501 DEBUG TRAIN Batch 36/600 loss 35.016060 loss_att 25.175402 loss_ctc 57.977585 loss_ctc_origin 41.895840 loss_ctc0 95.501648 lr 0.00139559 rank 0
2022-08-23 01:30:29,859 DEBUG TRAIN Batch 36/700 loss 25.758347 loss_att 14.339944 loss_ctc 52.401283 loss_ctc_origin 43.531754 loss_ctc0 73.096848 lr 0.00139526 rank 0
2022-08-23 01:30:59,749 DEBUG TRAIN Batch 36/800 loss 26.530155 loss_att 15.122744 loss_ctc 53.147446 loss_ctc_origin 41.318451 loss_ctc0 80.748428 lr 0.00139492 rank 0
2022-08-23 01:31:25,744 WARNING NaN or Inf found in input tensor.
2022-08-23 01:31:30,209 DEBUG TRAIN Batch 36/900 loss 33.905869 loss_att 18.564186 loss_ctc 69.703133 loss_ctc_origin 55.695721 loss_ctc0 102.387100 lr 0.00139458 rank 0
2022-08-23 01:32:00,151 DEBUG TRAIN Batch 36/1000 loss 25.354404 loss_att 19.940464 loss_ctc 37.986931 loss_ctc_origin 31.885777 loss_ctc0 52.222958 lr 0.00139424 rank 0
2022-08-23 01:32:14,705 WARNING NaN or Inf found in input tensor.
2022-08-23 01:32:28,666 DEBUG TRAIN Batch 36/1100 loss 32.367149 loss_att 19.779108 loss_ctc 61.739246 loss_ctc_origin 38.681858 loss_ctc0 115.539810 lr 0.00139390 rank 0
2022-08-23 01:32:59,627 DEBUG TRAIN Batch 36/1200 loss 25.919403 loss_att 16.539688 loss_ctc 47.805405 loss_ctc_origin 37.394024 loss_ctc0 72.098633 lr 0.00139356 rank 0
2022-08-23 01:33:29,947 DEBUG TRAIN Batch 36/1300 loss 29.892340 loss_att 16.696039 loss_ctc 60.683708 loss_ctc_origin 48.691326 loss_ctc0 88.665924 lr 0.00139322 rank 0
2022-08-23 01:33:59,973 DEBUG TRAIN Batch 36/1400 loss 33.585480 loss_att 19.073338 loss_ctc 67.447136 loss_ctc_origin 52.858765 loss_ctc0 101.486679 lr 0.00139288 rank 0
2022-08-23 01:34:37,268 DEBUG TRAIN Batch 36/1500 loss 33.763489 loss_att 24.940125 loss_ctc 54.351334 loss_ctc_origin 49.765362 loss_ctc0 65.051933 lr 0.00139255 rank 0
2022-08-23 01:35:06,602 DEBUG TRAIN Batch 36/1600 loss 37.097561 loss_att 27.297379 loss_ctc 59.964653 loss_ctc_origin 49.848103 loss_ctc0 83.569931 lr 0.00139221 rank 0
2022-08-23 01:35:36,307 DEBUG TRAIN Batch 36/1700 loss 28.032120 loss_att 18.387110 loss_ctc 50.537140 loss_ctc_origin 42.108658 loss_ctc0 70.203598 lr 0.00139187 rank 0
2022-08-23 01:36:06,058 DEBUG TRAIN Batch 36/1800 loss 28.964535 loss_att 16.663136 loss_ctc 57.667797 loss_ctc_origin 47.379116 loss_ctc0 81.674713 lr 0.00139154 rank 0
2022-08-23 01:36:35,528 DEBUG TRAIN Batch 36/1900 loss 34.846062 loss_att 22.336418 loss_ctc 64.035225 loss_ctc_origin 52.413712 loss_ctc0 91.152084 lr 0.00139120 rank 0
2022-08-23 01:37:05,549 DEBUG TRAIN Batch 36/2000 loss 29.211201 loss_att 22.327312 loss_ctc 45.273605 loss_ctc_origin 38.595123 loss_ctc0 60.856720 lr 0.00139086 rank 0
2022-08-23 01:37:34,644 DEBUG TRAIN Batch 36/2100 loss 54.117741 loss_att 32.566177 loss_ctc 104.404716 loss_ctc_origin 64.960770 loss_ctc0 196.440582 lr 0.00139053 rank 0
2022-08-23 01:38:02,401 WARNING NaN or Inf found in input tensor.
2022-08-23 01:38:04,094 DEBUG TRAIN Batch 36/2200 loss 28.266127 loss_att 18.348305 loss_ctc 51.407711 loss_ctc_origin 40.470127 loss_ctc0 76.928741 lr 0.00139019 rank 0
2022-08-23 01:38:33,570 DEBUG TRAIN Batch 36/2300 loss 31.140377 loss_att 19.072277 loss_ctc 59.299278 loss_ctc_origin 49.264095 loss_ctc0 82.714691 lr 0.00138985 rank 0
2022-08-23 01:38:51,719 WARNING NaN or Inf found in input tensor.
2022-08-23 01:39:03,325 DEBUG TRAIN Batch 36/2400 loss 33.829548 loss_att 20.048546 loss_ctc 65.985214 loss_ctc_origin 52.620052 loss_ctc0 97.170570 lr 0.00138952 rank 0
2022-08-23 01:39:05,941 WARNING NaN or Inf found in input tensor.
2022-08-23 01:39:32,285 DEBUG TRAIN Batch 36/2500 loss 30.734707 loss_att 24.728825 loss_ctc 44.748436 loss_ctc_origin 36.222717 loss_ctc0 64.641785 lr 0.00138918 rank 0
2022-08-23 01:39:48,124 WARNING NaN or Inf found in input tensor.
2022-08-23 01:40:02,891 DEBUG TRAIN Batch 36/2600 loss 52.460869 loss_att 29.100014 loss_ctc 106.969528 loss_ctc_origin 63.757256 loss_ctc0 207.798172 lr 0.00138885 rank 0
2022-08-23 01:40:32,589 DEBUG TRAIN Batch 36/2700 loss 30.212742 loss_att 20.482822 loss_ctc 52.915886 loss_ctc_origin 43.429424 loss_ctc0 75.050964 lr 0.00138851 rank 0
2022-08-23 01:41:03,039 DEBUG TRAIN Batch 36/2800 loss 29.331116 loss_att 17.541563 loss_ctc 56.840073 loss_ctc_origin 46.214401 loss_ctc0 81.633316 lr 0.00138818 rank 0
2022-08-23 01:41:32,090 DEBUG TRAIN Batch 36/2900 loss 29.736691 loss_att 16.842852 loss_ctc 59.822311 loss_ctc_origin 47.200584 loss_ctc0 89.272995 lr 0.00138785 rank 0
2022-08-23 01:42:08,632 DEBUG TRAIN Batch 36/3000 loss 29.063082 loss_att 23.870283 loss_ctc 41.179611 loss_ctc_origin 39.359310 loss_ctc0 45.426971 lr 0.00138751 rank 0
2022-08-23 01:42:37,145 DEBUG TRAIN Batch 36/3100 loss 45.794365 loss_att 29.083822 loss_ctc 84.785637 loss_ctc_origin 50.978138 loss_ctc0 163.669800 lr 0.00138718 rank 0
2022-08-23 01:43:04,605 WARNING NaN or Inf found in input tensor.
2022-08-23 01:43:06,147 DEBUG TRAIN Batch 36/3200 loss 31.662516 loss_att 21.640549 loss_ctc 55.047104 loss_ctc_origin 46.301914 loss_ctc0 75.452545 lr 0.00138684 rank 0
2022-08-23 01:43:35,719 DEBUG TRAIN Batch 36/3300 loss 26.669693 loss_att 15.663575 loss_ctc 52.350632 loss_ctc_origin 41.932236 loss_ctc0 76.660217 lr 0.00138651 rank 0
2022-08-23 01:44:06,098 DEBUG TRAIN Batch 36/3400 loss 33.524006 loss_att 20.788065 loss_ctc 63.241199 loss_ctc_origin 49.184364 loss_ctc0 96.040482 lr 0.00138618 rank 0
2022-08-23 01:44:08,830 WARNING NaN or Inf found in input tensor.
2022-08-23 01:44:36,488 DEBUG TRAIN Batch 36/3500 loss 30.383547 loss_att 22.771761 loss_ctc 48.144379 loss_ctc_origin 36.141842 loss_ctc0 76.150299 lr 0.00138584 rank 0
2022-08-23 01:45:05,477 DEBUG TRAIN Batch 36/3600 loss 28.086037 loss_att 17.544661 loss_ctc 52.682579 loss_ctc_origin 32.142807 loss_ctc0 100.608719 lr 0.00138551 rank 0
2022-08-23 01:45:32,907 WARNING NaN or Inf found in input tensor.
2022-08-23 01:45:34,469 DEBUG TRAIN Batch 36/3700 loss 26.486469 loss_att 16.196110 loss_ctc 50.497303 loss_ctc_origin 41.231956 loss_ctc0 72.116440 lr 0.00138518 rank 0
2022-08-23 01:46:04,252 DEBUG TRAIN Batch 36/3800 loss 35.280945 loss_att 21.192314 loss_ctc 68.154419 loss_ctc_origin 58.496071 loss_ctc0 90.690544 lr 0.00138485 rank 0
2022-08-23 01:46:35,362 DEBUG TRAIN Batch 36/3900 loss 38.265972 loss_att 22.449139 loss_ctc 75.171921 loss_ctc_origin 60.107819 loss_ctc0 110.321472 lr 0.00138452 rank 0
2022-08-23 01:47:04,637 DEBUG TRAIN Batch 36/4000 loss 35.354462 loss_att 27.512230 loss_ctc 53.653008 loss_ctc_origin 46.241451 loss_ctc0 70.946648 lr 0.00138418 rank 0
2022-08-23 01:47:35,608 DEBUG TRAIN Batch 36/4100 loss 37.149742 loss_att 25.244961 loss_ctc 64.927567 loss_ctc_origin 45.787212 loss_ctc0 109.588394 lr 0.00138385 rank 0
2022-08-23 01:48:03,842 DEBUG TRAIN Batch 36/4200 loss 27.598827 loss_att 17.552050 loss_ctc 51.041313 loss_ctc_origin 41.799877 loss_ctc0 72.604652 lr 0.00138352 rank 0
2022-08-23 01:48:34,189 DEBUG TRAIN Batch 36/4300 loss 29.782875 loss_att 18.218082 loss_ctc 56.767387 loss_ctc_origin 45.364914 loss_ctc0 83.373154 lr 0.00138319 rank 0
2022-08-23 01:49:04,823 DEBUG TRAIN Batch 36/4400 loss 33.677895 loss_att 19.647440 loss_ctc 66.415619 loss_ctc_origin 51.192345 loss_ctc0 101.936584 lr 0.00138286 rank 0
2022-08-23 01:49:40,937 DEBUG TRAIN Batch 36/4500 loss 25.814283 loss_att 19.731987 loss_ctc 40.006310 loss_ctc_origin 37.410446 loss_ctc0 46.063332 lr 0.00138253 rank 0
2022-08-23 01:49:49,192 WARNING NaN or Inf found in input tensor.
2022-08-23 01:50:10,351 DEBUG TRAIN Batch 36/4600 loss 37.798386 loss_att 22.443285 loss_ctc 73.626953 loss_ctc_origin 45.835236 loss_ctc0 138.474304 lr 0.00138220 rank 0
2022-08-23 01:50:39,695 DEBUG TRAIN Batch 36/4700 loss 32.160862 loss_att 22.457977 loss_ctc 54.800926 loss_ctc_origin 47.169651 loss_ctc0 72.607224 lr 0.00138187 rank 0
2022-08-23 01:51:09,904 DEBUG TRAIN Batch 36/4800 loss 31.716789 loss_att 21.126469 loss_ctc 56.427536 loss_ctc_origin 46.896629 loss_ctc0 78.666321 lr 0.00138154 rank 0
2022-08-23 01:51:39,252 DEBUG TRAIN Batch 36/4900 loss 28.009127 loss_att 15.455017 loss_ctc 57.302048 loss_ctc_origin 42.660854 loss_ctc0 91.464828 lr 0.00138121 rank 0
2022-08-23 01:52:08,694 DEBUG TRAIN Batch 36/5000 loss 32.121155 loss_att 26.131397 loss_ctc 46.097252 loss_ctc_origin 40.067554 loss_ctc0 60.166538 lr 0.00138088 rank 0
2022-08-23 01:52:38,546 DEBUG TRAIN Batch 36/5100 loss 44.918541 loss_att 30.587381 loss_ctc 78.357910 loss_ctc_origin 50.816200 loss_ctc0 142.621918 lr 0.00138055 rank 0
2022-08-23 01:53:07,115 DEBUG TRAIN Batch 36/5200 loss 29.141684 loss_att 20.292038 loss_ctc 49.790855 loss_ctc_origin 43.113377 loss_ctc0 65.371643 lr 0.00138022 rank 0
2022-08-23 01:53:36,851 DEBUG TRAIN Batch 36/5300 loss 26.930149 loss_att 14.918201 loss_ctc 54.958023 loss_ctc_origin 43.278061 loss_ctc0 82.211273 lr 0.00137989 rank 0
2022-08-23 01:54:06,632 DEBUG TRAIN Batch 36/5400 loss 34.909515 loss_att 19.453203 loss_ctc 70.974243 loss_ctc_origin 54.522068 loss_ctc0 109.362656 lr 0.00137957 rank 0
2022-08-23 01:54:37,427 DEBUG TRAIN Batch 36/5500 loss 24.763020 loss_att 19.491493 loss_ctc 37.063248 loss_ctc_origin 30.947256 loss_ctc0 51.333889 lr 0.00137924 rank 0
2022-08-23 01:55:06,132 DEBUG TRAIN Batch 36/5600 loss 33.149319 loss_att 20.786770 loss_ctc 61.995262 loss_ctc_origin 42.941925 loss_ctc0 106.453049 lr 0.00137891 rank 0
2022-08-23 01:55:30,160 DEBUG CV Batch 36/0 loss 25.770576 loss_att 14.918542 loss_ctc 51.091988 loss_ctc_origin 23.662567 loss_ctc0 115.093964 history loss 24.254660 rank 0
2022-08-23 01:55:41,420 DEBUG CV Batch 36/100 loss 35.495098 loss_att 21.546011 loss_ctc 68.042961 loss_ctc_origin 34.363308 loss_ctc0 146.628815 history loss 35.151381 rank 0
2022-08-23 01:55:51,511 DEBUG CV Batch 36/200 loss 28.128807 loss_att 21.466600 loss_ctc 43.673958 loss_ctc_origin 34.065765 loss_ctc0 66.093079 history loss 36.462912 rank 0
2022-08-23 01:56:02,139 DEBUG CV Batch 36/300 loss 28.018772 loss_att 20.904152 loss_ctc 44.619553 loss_ctc_origin 30.550123 loss_ctc0 77.448212 history loss 35.664442 rank 0
2022-08-23 01:56:13,743 DEBUG CV Batch 36/400 loss 44.444714 loss_att 35.225723 loss_ctc 65.955688 loss_ctc_origin 49.917747 loss_ctc0 103.377563 history loss 33.944772 rank 0
2022-08-23 01:56:25,519 DEBUG CV Batch 36/500 loss 28.789091 loss_att 16.862406 loss_ctc 56.618019 loss_ctc_origin 29.427179 loss_ctc0 120.063309 history loss 33.719471 rank 0
2022-08-23 01:56:36,961 DEBUG CV Batch 36/600 loss 38.279510 loss_att 20.891621 loss_ctc 78.851250 loss_ctc_origin 38.072769 loss_ctc0 174.001022 history loss 33.752463 rank 0
2022-08-23 01:56:47,922 DEBUG CV Batch 36/700 loss 23.790714 loss_att 16.728096 loss_ctc 40.270157 loss_ctc_origin 28.253191 loss_ctc0 68.309738 history loss 33.451022 rank 0
2022-08-23 01:56:59,255 DEBUG CV Batch 36/800 loss 26.267551 loss_att 19.470318 loss_ctc 42.127762 loss_ctc_origin 27.939747 loss_ctc0 75.233131 history loss 33.392647 rank 0
2022-08-23 01:57:10,360 INFO Epoch 36 CV info cv_loss 33.371132894912584
2022-08-23 01:57:10,361 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/36.pt
2022-08-23 01:57:10,847 INFO Epoch 37 TRAIN info lr 0.001378635126502737
2022-08-23 01:57:10,850 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 01:57:38,871 DEBUG TRAIN Batch 37/0 loss 32.757317 loss_att 23.907251 loss_ctc 53.407467 loss_ctc_origin 43.445976 loss_ctc0 76.650940 lr 0.00137862 rank 0
2022-08-23 01:58:08,794 DEBUG TRAIN Batch 37/100 loss 37.212429 loss_att 19.779171 loss_ctc 77.890022 loss_ctc_origin 41.899014 loss_ctc0 161.869034 lr 0.00137829 rank 0
2022-08-23 01:58:37,986 DEBUG TRAIN Batch 37/200 loss 30.969017 loss_att 19.312569 loss_ctc 58.167389 loss_ctc_origin 49.429863 loss_ctc0 78.554947 lr 0.00137797 rank 0
2022-08-23 01:59:08,359 DEBUG TRAIN Batch 37/300 loss 27.154385 loss_att 14.872161 loss_ctc 55.812904 loss_ctc_origin 43.612408 loss_ctc0 84.280731 lr 0.00137764 rank 0
2022-08-23 01:59:38,223 DEBUG TRAIN Batch 37/400 loss 34.529892 loss_att 21.072624 loss_ctc 65.930183 loss_ctc_origin 51.151047 loss_ctc0 100.414841 lr 0.00137731 rank 0
2022-08-23 02:00:09,946 DEBUG TRAIN Batch 37/500 loss 28.874630 loss_att 23.608566 loss_ctc 41.162117 loss_ctc_origin 39.100182 loss_ctc0 45.973301 lr 0.00137699 rank 0
2022-08-23 02:00:38,408 DEBUG TRAIN Batch 37/600 loss 29.094715 loss_att 18.740980 loss_ctc 53.253426 loss_ctc_origin 39.131241 loss_ctc0 86.205185 lr 0.00137666 rank 0
2022-08-23 02:01:07,666 DEBUG TRAIN Batch 37/700 loss 31.315056 loss_att 20.535515 loss_ctc 56.467312 loss_ctc_origin 47.494896 loss_ctc0 77.402954 lr 0.00137634 rank 0
2022-08-23 02:01:36,685 DEBUG TRAIN Batch 37/800 loss 28.409420 loss_att 16.005430 loss_ctc 57.352066 loss_ctc_origin 44.691273 loss_ctc0 86.893913 lr 0.00137601 rank 0
2022-08-23 02:02:07,024 DEBUG TRAIN Batch 37/900 loss 31.787735 loss_att 18.501198 loss_ctc 62.789654 loss_ctc_origin 48.103172 loss_ctc0 97.058113 lr 0.00137568 rank 0
2022-08-23 02:02:35,773 DEBUG TRAIN Batch 37/1000 loss 23.866302 loss_att 17.620476 loss_ctc 38.439903 loss_ctc_origin 36.518154 loss_ctc0 42.923988 lr 0.00137536 rank 0
2022-08-23 02:03:05,289 DEBUG TRAIN Batch 37/1100 loss 32.348488 loss_att 20.283657 loss_ctc 60.499763 loss_ctc_origin 40.454132 loss_ctc0 107.272896 lr 0.00137503 rank 0
2022-08-23 02:03:35,747 DEBUG TRAIN Batch 37/1200 loss 34.882778 loss_att 23.689064 loss_ctc 61.001442 loss_ctc_origin 54.062454 loss_ctc0 77.192413 lr 0.00137471 rank 0
2022-08-23 02:04:06,670 DEBUG TRAIN Batch 37/1300 loss 30.386585 loss_att 16.759472 loss_ctc 62.183182 loss_ctc_origin 50.185295 loss_ctc0 90.178246 lr 0.00137438 rank 0
2022-08-23 02:04:36,416 DEBUG TRAIN Batch 37/1400 loss 35.669708 loss_att 21.418896 loss_ctc 68.921608 loss_ctc_origin 54.866688 loss_ctc0 101.716423 lr 0.00137406 rank 0
2022-08-23 02:05:13,972 DEBUG TRAIN Batch 37/1500 loss 30.741947 loss_att 24.521030 loss_ctc 45.257416 loss_ctc_origin 36.580215 loss_ctc0 65.504227 lr 0.00137374 rank 0
2022-08-23 02:05:21,998 WARNING NaN or Inf found in input tensor.
2022-08-23 02:05:43,866 DEBUG TRAIN Batch 37/1600 loss 36.836296 loss_att 25.470154 loss_ctc 63.357285 loss_ctc_origin 44.312126 loss_ctc0 107.795975 lr 0.00137341 rank 0
2022-08-23 02:06:14,110 DEBUG TRAIN Batch 37/1700 loss 27.264814 loss_att 17.523417 loss_ctc 49.994740 loss_ctc_origin 41.432377 loss_ctc0 69.973587 lr 0.00137309 rank 0
2022-08-23 02:06:43,808 DEBUG TRAIN Batch 37/1800 loss 28.245575 loss_att 16.216124 loss_ctc 56.314293 loss_ctc_origin 44.240749 loss_ctc0 84.485886 lr 0.00137276 rank 0
2022-08-23 02:07:12,999 DEBUG TRAIN Batch 37/1900 loss 34.377167 loss_att 20.255585 loss_ctc 67.327515 loss_ctc_origin 53.125549 loss_ctc0 100.465424 lr 0.00137244 rank 0
2022-08-23 02:07:43,635 DEBUG TRAIN Batch 37/2000 loss 35.183510 loss_att 28.560196 loss_ctc 50.637917 loss_ctc_origin 43.761589 loss_ctc0 66.682678 lr 0.00137212 rank 0
2022-08-23 02:08:12,906 DEBUG TRAIN Batch 37/2100 loss 34.760605 loss_att 25.035173 loss_ctc 57.453278 loss_ctc_origin 43.399754 loss_ctc0 90.244835 lr 0.00137180 rank 0
2022-08-23 02:08:39,893 WARNING NaN or Inf found in input tensor.
2022-08-23 02:08:41,621 DEBUG TRAIN Batch 37/2200 loss 32.413136 loss_att 21.779457 loss_ctc 57.225052 loss_ctc_origin 49.266594 loss_ctc0 75.794792 lr 0.00137147 rank 0
2022-08-23 02:08:59,973 WARNING NaN or Inf found in input tensor.
2022-08-23 02:09:09,909 DEBUG TRAIN Batch 37/2300 loss 24.782963 loss_att 13.864084 loss_ctc 50.260345 loss_ctc_origin 38.132595 loss_ctc0 78.558426 lr 0.00137115 rank 0
2022-08-23 02:09:35,513 WARNING NaN or Inf found in input tensor.
2022-08-23 02:09:40,021 DEBUG TRAIN Batch 37/2400 loss 33.789406 loss_att 19.146948 loss_ctc 67.955139 loss_ctc_origin 53.883137 loss_ctc0 100.789795 lr 0.00137083 rank 0
2022-08-23 02:10:09,535 DEBUG TRAIN Batch 37/2500 loss 30.072239 loss_att 22.964386 loss_ctc 46.657227 loss_ctc_origin 39.605488 loss_ctc0 63.111275 lr 0.00137051 rank 0
2022-08-23 02:10:24,273 WARNING NaN or Inf found in input tensor.
2022-08-23 02:10:38,310 DEBUG TRAIN Batch 37/2600 loss 28.446514 loss_att 18.375502 loss_ctc 51.945545 loss_ctc_origin 36.563690 loss_ctc0 87.836533 lr 0.00137018 rank 0
2022-08-23 02:11:08,267 DEBUG TRAIN Batch 37/2700 loss 31.062727 loss_att 22.309738 loss_ctc 51.486366 loss_ctc_origin 44.142082 loss_ctc0 68.623016 lr 0.00136986 rank 0
2022-08-23 02:11:27,332 WARNING NaN or Inf found in input tensor.
2022-08-23 02:11:37,215 DEBUG TRAIN Batch 37/2800 loss 28.100367 loss_att 16.193878 loss_ctc 55.882172 loss_ctc_origin 42.900009 loss_ctc0 86.173874 lr 0.00136954 rank 0
2022-08-23 02:12:03,331 WARNING NaN or Inf found in input tensor.
2022-08-23 02:12:07,644 DEBUG TRAIN Batch 37/2900 loss 32.136974 loss_att 17.603058 loss_ctc 66.049438 loss_ctc_origin 52.915009 loss_ctc0 96.696442 lr 0.00136922 rank 0
2022-08-23 02:12:43,993 DEBUG TRAIN Batch 37/3000 loss 21.299770 loss_att 17.177862 loss_ctc 30.917555 loss_ctc_origin 27.412542 loss_ctc0 39.095917 lr 0.00136890 rank 0
2022-08-23 02:13:13,188 DEBUG TRAIN Batch 37/3100 loss 39.535118 loss_att 25.101889 loss_ctc 73.212646 loss_ctc_origin 43.778641 loss_ctc0 141.891983 lr 0.00136858 rank 0
2022-08-23 02:13:42,414 DEBUG TRAIN Batch 37/3200 loss 31.137590 loss_att 21.929420 loss_ctc 52.623318 loss_ctc_origin 44.010185 loss_ctc0 72.720627 lr 0.00136826 rank 0
2022-08-23 02:14:11,173 DEBUG TRAIN Batch 37/3300 loss 29.045052 loss_att 17.320190 loss_ctc 56.403053 loss_ctc_origin 44.949417 loss_ctc0 83.128204 lr 0.00136794 rank 0
2022-08-23 02:14:35,663 WARNING NaN or Inf found in input tensor.
2022-08-23 02:14:40,145 DEBUG TRAIN Batch 37/3400 loss 30.200378 loss_att 16.910519 loss_ctc 61.210052 loss_ctc_origin 47.613689 loss_ctc0 92.934906 lr 0.00136762 rank 0
2022-08-23 02:15:10,302 DEBUG TRAIN Batch 37/3500 loss 31.492847 loss_att 24.212982 loss_ctc 48.479195 loss_ctc_origin 44.242725 loss_ctc0 58.364288 lr 0.00136730 rank 0
2022-08-23 02:15:39,477 DEBUG TRAIN Batch 37/3600 loss 32.378410 loss_att 22.697872 loss_ctc 54.966324 loss_ctc_origin 39.611504 loss_ctc0 90.794235 lr 0.00136698 rank 0
2022-08-23 02:16:07,878 WARNING NaN or Inf found in input tensor.
2022-08-23 02:16:09,476 DEBUG TRAIN Batch 37/3700 loss 29.129902 loss_att 18.665049 loss_ctc 53.547890 loss_ctc_origin 43.743710 loss_ctc0 76.424309 lr 0.00136666 rank 0
2022-08-23 02:16:38,631 DEBUG TRAIN Batch 37/3800 loss 24.648912 loss_att 15.653049 loss_ctc 45.639259 loss_ctc_origin 33.164581 loss_ctc0 74.746849 lr 0.00136634 rank 0
2022-08-23 02:17:05,177 WARNING NaN or Inf found in input tensor.
2022-08-23 02:17:09,669 DEBUG TRAIN Batch 37/3900 loss 37.797836 loss_att 23.615906 loss_ctc 70.889008 loss_ctc_origin 55.977905 loss_ctc0 105.681595 lr 0.00136602 rank 0
2022-08-23 02:17:26,163 WARNING NaN or Inf found in input tensor.
2022-08-23 02:17:39,832 DEBUG TRAIN Batch 37/4000 loss 27.767059 loss_att 20.384842 loss_ctc 44.992233 loss_ctc_origin 39.123566 loss_ctc0 58.685799 lr 0.00136570 rank 0
2022-08-23 02:18:10,063 DEBUG TRAIN Batch 37/4100 loss 26.856377 loss_att 18.451805 loss_ctc 46.467041 loss_ctc_origin 34.387466 loss_ctc0 74.652710 lr 0.00136539 rank 0
2022-08-23 02:18:40,282 DEBUG TRAIN Batch 37/4200 loss 28.199072 loss_att 18.180529 loss_ctc 51.575672 loss_ctc_origin 40.392170 loss_ctc0 77.670509 lr 0.00136507 rank 0
2022-08-23 02:19:10,276 DEBUG TRAIN Batch 37/4300 loss 26.318924 loss_att 15.214503 loss_ctc 52.229233 loss_ctc_origin 40.414570 loss_ctc0 79.796783 lr 0.00136475 rank 0
2022-08-23 02:19:40,238 DEBUG TRAIN Batch 37/4400 loss 29.589121 loss_att 17.058168 loss_ctc 58.828011 loss_ctc_origin 45.021210 loss_ctc0 91.043884 lr 0.00136443 rank 0
2022-08-23 02:20:16,039 DEBUG TRAIN Batch 37/4500 loss 25.152962 loss_att 18.941113 loss_ctc 39.647278 loss_ctc_origin 36.313370 loss_ctc0 47.426395 lr 0.00136412 rank 0
2022-08-23 02:20:45,249 DEBUG TRAIN Batch 37/4600 loss 29.118286 loss_att 20.532801 loss_ctc 49.151085 loss_ctc_origin 35.972168 loss_ctc0 79.901886 lr 0.00136380 rank 0
2022-08-23 02:21:14,579 DEBUG TRAIN Batch 37/4700 loss 27.538059 loss_att 18.075651 loss_ctc 49.617012 loss_ctc_origin 39.182243 loss_ctc0 73.964798 lr 0.00136348 rank 0
2022-08-23 02:21:44,082 DEBUG TRAIN Batch 37/4800 loss 33.500038 loss_att 19.832909 loss_ctc 65.390007 loss_ctc_origin 54.378448 loss_ctc0 91.083641 lr 0.00136316 rank 0
2022-08-23 02:22:14,549 DEBUG TRAIN Batch 37/4900 loss 32.193142 loss_att 18.690296 loss_ctc 63.699783 loss_ctc_origin 49.412560 loss_ctc0 97.036636 lr 0.00136285 rank 0
2022-08-23 02:22:44,809 DEBUG TRAIN Batch 37/5000 loss 26.891544 loss_att 21.851004 loss_ctc 38.652809 loss_ctc_origin 34.503540 loss_ctc0 48.334435 lr 0.00136253 rank 0
2022-08-23 02:23:13,932 DEBUG TRAIN Batch 37/5100 loss 28.385740 loss_att 20.547546 loss_ctc 46.674858 loss_ctc_origin 35.537449 loss_ctc0 72.662140 lr 0.00136222 rank 0
2022-08-23 02:23:43,267 DEBUG TRAIN Batch 37/5200 loss 25.517307 loss_att 16.984146 loss_ctc 45.428017 loss_ctc_origin 36.578053 loss_ctc0 66.077927 lr 0.00136190 rank 0
2022-08-23 02:24:14,254 DEBUG TRAIN Batch 37/5300 loss 28.986734 loss_att 17.442017 loss_ctc 55.924408 loss_ctc_origin 44.804249 loss_ctc0 81.871445 lr 0.00136158 rank 0
2022-08-23 02:24:39,070 WARNING NaN or Inf found in input tensor.
2022-08-23 02:24:43,316 DEBUG TRAIN Batch 37/5400 loss 29.794582 loss_att 17.285973 loss_ctc 58.981331 loss_ctc_origin 45.372391 loss_ctc0 90.735519 lr 0.00136127 rank 0
2022-08-23 02:25:13,800 DEBUG TRAIN Batch 37/5500 loss 23.527248 loss_att 18.156078 loss_ctc 36.059982 loss_ctc_origin 31.071209 loss_ctc0 47.700447 lr 0.00136095 rank 0
2022-08-23 02:25:42,413 DEBUG TRAIN Batch 37/5600 loss 64.697655 loss_att 39.174664 loss_ctc 124.251297 loss_ctc_origin 74.985947 loss_ctc0 239.203796 lr 0.00136064 rank 0
2022-08-23 02:26:05,529 DEBUG CV Batch 37/0 loss 51.401733 loss_att 28.500561 loss_ctc 104.837807 loss_ctc_origin 52.132111 loss_ctc0 227.817764 history loss 48.378102 rank 0
2022-08-23 02:26:16,955 DEBUG CV Batch 37/100 loss 78.804413 loss_att 46.612705 loss_ctc 153.918396 loss_ctc_origin 81.605766 loss_ctc0 322.647858 history loss 45.743790 rank 0
2022-08-23 02:26:27,355 DEBUG CV Batch 37/200 loss 28.854309 loss_att 21.996923 loss_ctc 44.854874 loss_ctc_origin 35.448437 loss_ctc0 66.803223 history loss 48.103606 rank 0
2022-08-23 02:26:37,641 DEBUG CV Batch 37/300 loss 27.610935 loss_att 20.216568 loss_ctc 44.864460 loss_ctc_origin 30.612747 loss_ctc0 78.118454 history loss 47.125938 rank 0
2022-08-23 02:26:48,478 DEBUG CV Batch 37/400 loss 44.407776 loss_att 35.543831 loss_ctc 65.090302 loss_ctc_origin 48.935383 loss_ctc0 102.785110 history loss 44.564804 rank 0
2022-08-23 02:26:59,854 DEBUG CV Batch 37/500 loss 53.297607 loss_att 31.607317 loss_ctc 103.908287 loss_ctc_origin 54.247734 loss_ctc0 219.782898 history loss 44.027818 rank 0
2022-08-23 02:27:11,191 DEBUG CV Batch 37/600 loss 72.686783 loss_att 42.438782 loss_ctc 143.265457 loss_ctc_origin 78.820221 loss_ctc0 293.637695 history loss 44.211069 rank 0
2022-08-23 02:27:21,986 DEBUG CV Batch 37/700 loss 22.858952 loss_att 15.726184 loss_ctc 39.502075 loss_ctc_origin 27.108845 loss_ctc0 68.419617 history loss 43.713100 rank 0
2022-08-23 02:27:32,932 DEBUG CV Batch 37/800 loss 25.775517 loss_att 18.878538 loss_ctc 41.868465 loss_ctc_origin 27.617443 loss_ctc0 75.120850 history loss 43.510236 rank 0
2022-08-23 02:27:43,838 INFO Epoch 37 CV info cv_loss 43.01184883578304
2022-08-23 02:27:43,839 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/37.pt
2022-08-23 02:27:44,332 INFO Epoch 38 TRAIN info lr 0.0013603742523465938
2022-08-23 02:27:44,336 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 02:28:11,508 DEBUG TRAIN Batch 38/0 loss 37.661938 loss_att 29.738405 loss_ctc 56.150181 loss_ctc_origin 47.900684 loss_ctc0 75.399002 lr 0.00136036 rank 0
2022-08-23 02:28:41,096 DEBUG TRAIN Batch 38/100 loss 54.456486 loss_att 31.309505 loss_ctc 108.466110 loss_ctc_origin 59.438286 loss_ctc0 222.864380 lr 0.00136005 rank 0
2022-08-23 02:29:10,884 DEBUG TRAIN Batch 38/200 loss 25.185497 loss_att 16.411259 loss_ctc 45.658718 loss_ctc_origin 37.586136 loss_ctc0 64.494743 lr 0.00135973 rank 0
2022-08-23 02:29:41,480 DEBUG TRAIN Batch 38/300 loss 28.167831 loss_att 16.215010 loss_ctc 56.057743 loss_ctc_origin 44.272812 loss_ctc0 83.555908 lr 0.00135942 rank 0
2022-08-23 02:30:12,279 DEBUG TRAIN Batch 38/400 loss 39.470711 loss_att 24.555027 loss_ctc 74.273972 loss_ctc_origin 60.613617 loss_ctc0 106.148132 lr 0.00135910 rank 0
2022-08-23 02:30:42,357 DEBUG TRAIN Batch 38/500 loss 27.861864 loss_att 22.086365 loss_ctc 41.338028 loss_ctc_origin 35.730442 loss_ctc0 54.422394 lr 0.00135879 rank 0
2022-08-23 02:31:12,054 DEBUG TRAIN Batch 38/600 loss 52.203094 loss_att 34.229855 loss_ctc 94.140656 loss_ctc_origin 61.146698 loss_ctc0 171.126556 lr 0.00135848 rank 0
2022-08-23 02:31:40,880 DEBUG TRAIN Batch 38/700 loss 27.239723 loss_att 18.421131 loss_ctc 47.816437 loss_ctc_origin 39.681541 loss_ctc0 66.797867 lr 0.00135816 rank 0
2022-08-23 02:32:11,662 DEBUG TRAIN Batch 38/800 loss 27.343754 loss_att 14.597712 loss_ctc 57.084511 loss_ctc_origin 44.538460 loss_ctc0 86.358627 lr 0.00135785 rank 0
2022-08-23 02:32:37,106 WARNING NaN or Inf found in input tensor.
2022-08-23 02:32:41,722 DEBUG TRAIN Batch 38/900 loss 35.740765 loss_att 21.823650 loss_ctc 68.214035 loss_ctc_origin 54.630081 loss_ctc0 99.909927 lr 0.00135754 rank 0
2022-08-23 02:32:44,581 WARNING NaN or Inf found in input tensor.
2022-08-23 02:33:11,372 DEBUG TRAIN Batch 38/1000 loss 37.580727 loss_att 28.515951 loss_ctc 58.731873 loss_ctc_origin 47.175522 loss_ctc0 85.696693 lr 0.00135723 rank 0
2022-08-23 02:33:40,851 DEBUG TRAIN Batch 38/1100 loss 46.326363 loss_att 29.643074 loss_ctc 85.254044 loss_ctc_origin 49.336670 loss_ctc0 169.061249 lr 0.00135691 rank 0
2022-08-23 02:34:11,806 DEBUG TRAIN Batch 38/1200 loss 30.251335 loss_att 19.978569 loss_ctc 54.221127 loss_ctc_origin 44.497696 loss_ctc0 76.909134 lr 0.00135660 rank 0
2022-08-23 02:34:41,230 DEBUG TRAIN Batch 38/1300 loss 29.163128 loss_att 15.912956 loss_ctc 60.080189 loss_ctc_origin 48.122314 loss_ctc0 87.981895 lr 0.00135629 rank 0
2022-08-23 02:35:09,793 DEBUG TRAIN Batch 38/1400 loss 32.216263 loss_att 17.733887 loss_ctc 66.008476 loss_ctc_origin 51.351410 loss_ctc0 100.208282 lr 0.00135598 rank 0
2022-08-23 02:35:47,400 DEBUG TRAIN Batch 38/1500 loss 30.569658 loss_att 25.524073 loss_ctc 42.342693 loss_ctc_origin 41.777233 loss_ctc0 43.662106 lr 0.00135567 rank 0
2022-08-23 02:36:16,664 DEBUG TRAIN Batch 38/1600 loss 38.098492 loss_att 22.717752 loss_ctc 73.986885 loss_ctc_origin 41.608547 loss_ctc0 149.536346 lr 0.00135535 rank 0
2022-08-23 02:36:46,043 DEBUG TRAIN Batch 38/1700 loss 28.838379 loss_att 18.615892 loss_ctc 52.690849 loss_ctc_origin 43.672394 loss_ctc0 73.733910 lr 0.00135504 rank 0
2022-08-23 02:37:15,971 DEBUG TRAIN Batch 38/1800 loss 31.271160 loss_att 17.080399 loss_ctc 64.382935 loss_ctc_origin 52.955231 loss_ctc0 91.047569 lr 0.00135473 rank 0
2022-08-23 02:37:41,519 WARNING NaN or Inf found in input tensor.
2022-08-23 02:37:45,834 DEBUG TRAIN Batch 38/1900 loss 37.697929 loss_att 23.110872 loss_ctc 71.734390 loss_ctc_origin 60.064911 loss_ctc0 98.963181 lr 0.00135442 rank 0
2022-08-23 02:38:16,790 DEBUG TRAIN Batch 38/2000 loss 39.953835 loss_att 33.026634 loss_ctc 56.117302 loss_ctc_origin 51.512482 loss_ctc0 66.861893 lr 0.00135411 rank 0
2022-08-23 02:38:46,238 DEBUG TRAIN Batch 38/2100 loss 35.245872 loss_att 23.574688 loss_ctc 62.478630 loss_ctc_origin 45.803741 loss_ctc0 101.386703 lr 0.00135380 rank 0
2022-08-23 02:39:16,061 DEBUG TRAIN Batch 38/2200 loss 29.166788 loss_att 17.775547 loss_ctc 55.746349 loss_ctc_origin 46.847343 loss_ctc0 76.510696 lr 0.00135349 rank 0
2022-08-23 02:39:45,249 DEBUG TRAIN Batch 38/2300 loss 31.671112 loss_att 17.798134 loss_ctc 64.041397 loss_ctc_origin 53.382320 loss_ctc0 88.912567 lr 0.00135318 rank 0
2022-08-23 02:40:14,391 DEBUG TRAIN Batch 38/2400 loss 33.243256 loss_att 19.173920 loss_ctc 66.071709 loss_ctc_origin 51.027771 loss_ctc0 101.174232 lr 0.00135287 rank 0
2022-08-23 02:40:43,862 DEBUG TRAIN Batch 38/2500 loss 29.418106 loss_att 24.363562 loss_ctc 41.212040 loss_ctc_origin 38.023460 loss_ctc0 48.652058 lr 0.00135256 rank 0
2022-08-23 02:41:13,799 DEBUG TRAIN Batch 38/2600 loss 41.614952 loss_att 24.900946 loss_ctc 80.614288 loss_ctc_origin 50.261017 loss_ctc0 151.438599 lr 0.00135225 rank 0
2022-08-23 02:41:41,018 DEBUG TRAIN Batch 38/2700 loss 21.792423 loss_att 13.107468 loss_ctc 42.057320 loss_ctc_origin 32.496578 loss_ctc0 64.365707 lr 0.00135194 rank 0
2022-08-23 02:42:10,942 DEBUG TRAIN Batch 38/2800 loss 28.641302 loss_att 17.842972 loss_ctc 53.837402 loss_ctc_origin 43.246532 loss_ctc0 78.549438 lr 0.00135164 rank 0
2022-08-23 02:42:39,860 DEBUG TRAIN Batch 38/2900 loss 34.579319 loss_att 18.935265 loss_ctc 71.082115 loss_ctc_origin 57.529800 loss_ctc0 102.704193 lr 0.00135133 rank 0
2022-08-23 02:43:16,049 DEBUG TRAIN Batch 38/3000 loss 33.570053 loss_att 24.273355 loss_ctc 55.262352 loss_ctc_origin 40.274155 loss_ctc0 90.234810 lr 0.00135102 rank 0
2022-08-23 02:43:46,285 WARNING NaN or Inf found in input tensor.
2022-08-23 02:43:46,332 DEBUG TRAIN Batch 38/3100 loss nan loss_att 27.877464 loss_ctc nan loss_ctc_origin 43.760845 loss_ctc0 nan lr 0.00135071 rank 0
2022-08-23 02:44:15,783 DEBUG TRAIN Batch 38/3200 loss 23.638382 loss_att 13.844203 loss_ctc 46.491463 loss_ctc_origin 36.243546 loss_ctc0 70.403275 lr 0.00135040 rank 0
2022-08-23 02:44:45,476 DEBUG TRAIN Batch 38/3300 loss 25.515938 loss_att 13.765615 loss_ctc 52.933357 loss_ctc_origin 41.480057 loss_ctc0 79.657730 lr 0.00135009 rank 0
2022-08-23 02:45:15,429 DEBUG TRAIN Batch 38/3400 loss 35.004532 loss_att 21.501877 loss_ctc 66.510735 loss_ctc_origin 51.489559 loss_ctc0 101.560150 lr 0.00134979 rank 0
2022-08-23 02:45:44,884 DEBUG TRAIN Batch 38/3500 loss 27.207430 loss_att 21.919010 loss_ctc 39.547077 loss_ctc_origin 36.028286 loss_ctc0 47.757591 lr 0.00134948 rank 0
2022-08-23 02:46:13,626 DEBUG TRAIN Batch 38/3600 loss 35.406391 loss_att 22.823198 loss_ctc 64.767174 loss_ctc_origin 41.154816 loss_ctc0 119.862671 lr 0.00134917 rank 0
2022-08-23 02:46:42,823 DEBUG TRAIN Batch 38/3700 loss 30.642151 loss_att 21.055248 loss_ctc 53.011593 loss_ctc_origin 46.653423 loss_ctc0 67.847328 lr 0.00134887 rank 0
2022-08-23 02:47:12,373 DEBUG TRAIN Batch 38/3800 loss 33.244438 loss_att 19.647865 loss_ctc 64.969772 loss_ctc_origin 55.262993 loss_ctc0 87.618927 lr 0.00134856 rank 0
2022-08-23 02:47:41,769 DEBUG TRAIN Batch 38/3900 loss 31.868923 loss_att 17.819012 loss_ctc 64.652054 loss_ctc_origin 51.402306 loss_ctc0 95.568146 lr 0.00134825 rank 0
2022-08-23 02:48:11,393 DEBUG TRAIN Batch 38/4000 loss 25.978249 loss_att 21.342255 loss_ctc 36.795563 loss_ctc_origin 33.737747 loss_ctc0 43.930458 lr 0.00134795 rank 0
2022-08-23 02:48:40,313 DEBUG TRAIN Batch 38/4100 loss 34.103714 loss_att 22.513111 loss_ctc 61.148453 loss_ctc_origin 43.583778 loss_ctc0 102.132690 lr 0.00134764 rank 0
2022-08-23 02:49:10,951 DEBUG TRAIN Batch 38/4200 loss 30.190369 loss_att 20.014034 loss_ctc 53.935150 loss_ctc_origin 46.080444 loss_ctc0 72.262802 lr 0.00134733 rank 0
2022-08-23 02:49:30,354 WARNING NaN or Inf found in input tensor.
2022-08-23 02:49:40,049 DEBUG TRAIN Batch 38/4300 loss 31.839033 loss_att 19.726866 loss_ctc 60.100754 loss_ctc_origin 50.213570 loss_ctc0 83.170853 lr 0.00134703 rank 0
2022-08-23 02:50:04,963 WARNING NaN or Inf found in input tensor.
2022-08-23 02:50:09,333 DEBUG TRAIN Batch 38/4400 loss 35.023827 loss_att 21.334343 loss_ctc 66.965958 loss_ctc_origin 51.318954 loss_ctc0 103.475624 lr 0.00134672 rank 0
2022-08-23 02:50:47,220 DEBUG TRAIN Batch 38/4500 loss 30.041756 loss_att 19.346615 loss_ctc 54.997078 loss_ctc_origin 40.322971 loss_ctc0 89.236664 lr 0.00134642 rank 0
2022-08-23 02:51:17,723 DEBUG TRAIN Batch 38/4600 loss 34.894226 loss_att 23.715134 loss_ctc 60.978767 loss_ctc_origin 41.091953 loss_ctc0 107.381332 lr 0.00134611 rank 0
2022-08-23 02:51:48,018 DEBUG TRAIN Batch 38/4700 loss 29.136692 loss_att 21.143349 loss_ctc 47.787827 loss_ctc_origin 40.729092 loss_ctc0 64.258209 lr 0.00134581 rank 0
2022-08-23 02:52:18,014 DEBUG TRAIN Batch 38/4800 loss 29.353905 loss_att 17.610674 loss_ctc 56.754780 loss_ctc_origin 45.602509 loss_ctc0 82.776749 lr 0.00134550 rank 0
2022-08-23 02:52:47,850 DEBUG TRAIN Batch 38/4900 loss 37.824947 loss_att 22.122887 loss_ctc 74.463089 loss_ctc_origin 59.663834 loss_ctc0 108.994682 lr 0.00134520 rank 0
2022-08-23 02:53:18,540 DEBUG TRAIN Batch 38/5000 loss 30.556507 loss_att 25.042446 loss_ctc 43.422642 loss_ctc_origin 35.550999 loss_ctc0 61.789806 lr 0.00134490 rank 0
2022-08-23 02:53:47,701 DEBUG TRAIN Batch 38/5100 loss 30.736160 loss_att 21.344692 loss_ctc 52.649590 loss_ctc_origin 37.326363 loss_ctc0 88.403786 lr 0.00134459 rank 0
2022-08-23 02:54:16,989 DEBUG TRAIN Batch 38/5200 loss 26.210812 loss_att 17.937998 loss_ctc 45.514046 loss_ctc_origin 37.741074 loss_ctc0 63.650982 lr 0.00134429 rank 0
2022-08-23 02:54:46,090 DEBUG TRAIN Batch 38/5300 loss 31.136589 loss_att 19.872326 loss_ctc 57.419865 loss_ctc_origin 46.435284 loss_ctc0 83.050545 lr 0.00134398 rank 0
2022-08-23 02:55:17,086 DEBUG TRAIN Batch 38/5400 loss 35.606712 loss_att 21.464695 loss_ctc 68.604744 loss_ctc_origin 56.619770 loss_ctc0 96.569672 lr 0.00134368 rank 0
2022-08-23 02:55:46,844 DEBUG TRAIN Batch 38/5500 loss 26.438999 loss_att 20.503328 loss_ctc 40.288898 loss_ctc_origin 36.140522 loss_ctc0 49.968449 lr 0.00134338 rank 0
2022-08-23 02:56:16,976 DEBUG TRAIN Batch 38/5600 loss 29.069832 loss_att 18.445011 loss_ctc 53.861084 loss_ctc_origin 33.383789 loss_ctc0 101.641434 lr 0.00134307 rank 0
2022-08-23 02:56:40,788 DEBUG CV Batch 38/0 loss 19.498390 loss_att 12.981901 loss_ctc 34.703526 loss_ctc_origin 22.574663 loss_ctc0 63.004208 history loss 18.351426 rank 0
2022-08-23 02:56:52,215 DEBUG CV Batch 38/100 loss 26.985039 loss_att 19.266029 loss_ctc 44.996056 loss_ctc_origin 28.706127 loss_ctc0 83.005890 history loss 32.741351 rank 0
2022-08-23 02:57:02,442 DEBUG CV Batch 38/200 loss 28.556580 loss_att 22.008520 loss_ctc 43.835381 loss_ctc_origin 34.280197 loss_ctc0 66.130798 history loss 33.973478 rank 0
2022-08-23 02:57:13,184 DEBUG CV Batch 38/300 loss 27.487679 loss_att 20.155159 loss_ctc 44.596886 loss_ctc_origin 30.254787 loss_ctc0 78.061790 history loss 33.026322 rank 0
2022-08-23 02:57:24,190 DEBUG CV Batch 38/400 loss 43.672531 loss_att 34.956123 loss_ctc 64.010818 loss_ctc_origin 47.695324 loss_ctc0 102.080307 history loss 31.256883 rank 0
2022-08-23 02:57:35,400 DEBUG CV Batch 38/500 loss 21.887280 loss_att 15.628686 loss_ctc 36.490669 loss_ctc_origin 25.727575 loss_ctc0 61.604546 history loss 30.851338 rank 0
2022-08-23 02:57:46,470 DEBUG CV Batch 38/600 loss 24.345699 loss_att 14.916946 loss_ctc 46.346123 loss_ctc_origin 27.290833 loss_ctc0 90.808472 history loss 30.733602 rank 0
2022-08-23 02:57:57,162 DEBUG CV Batch 38/700 loss 22.185772 loss_att 15.144426 loss_ctc 38.615582 loss_ctc_origin 25.949621 loss_ctc0 68.169487 history loss 30.292775 rank 0
2022-08-23 02:58:08,148 DEBUG CV Batch 38/800 loss 26.037325 loss_att 19.494230 loss_ctc 41.304546 loss_ctc_origin 26.652859 loss_ctc0 75.491814 history loss 30.231501 rank 0
2022-08-23 02:58:18,860 INFO Epoch 38 CV info cv_loss 30.284587550447835
2022-08-23 02:58:18,860 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/38.pt
2022-08-23 02:58:19,318 INFO Epoch 39 TRAIN info lr 0.0013428203007582159
2022-08-23 02:58:19,321 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 02:58:46,378 DEBUG TRAIN Batch 39/0 loss 27.050621 loss_att 21.872843 loss_ctc 39.132107 loss_ctc_origin 37.137638 loss_ctc0 43.785866 lr 0.00134281 rank 0
2022-08-23 02:59:15,237 DEBUG TRAIN Batch 39/100 loss 26.846989 loss_att 16.251347 loss_ctc 51.570152 loss_ctc_origin 35.552216 loss_ctc0 88.945328 lr 0.00134251 rank 0
2022-08-23 02:59:44,801 DEBUG TRAIN Batch 39/200 loss 26.867443 loss_att 16.748280 loss_ctc 50.478825 loss_ctc_origin 40.257160 loss_ctc0 74.329376 lr 0.00134220 rank 0
2022-08-23 02:59:50,525 WARNING NaN or Inf found in input tensor.
2022-08-23 03:00:14,456 DEBUG TRAIN Batch 39/300 loss 25.153412 loss_att 13.502512 loss_ctc 52.338844 loss_ctc_origin 39.828365 loss_ctc0 81.529953 lr 0.00134190 rank 0
2022-08-23 03:00:44,263 DEBUG TRAIN Batch 39/400 loss 28.918188 loss_att 15.840567 loss_ctc 59.432640 loss_ctc_origin 42.702507 loss_ctc0 98.469620 lr 0.00134160 rank 0
2022-08-23 03:01:14,678 DEBUG TRAIN Batch 39/500 loss 27.743858 loss_att 22.820557 loss_ctc 39.231567 loss_ctc_origin 36.358521 loss_ctc0 45.935349 lr 0.00134130 rank 0
2022-08-23 03:01:43,852 DEBUG TRAIN Batch 39/600 loss 28.106520 loss_att 19.196905 loss_ctc 48.895618 loss_ctc_origin 34.049911 loss_ctc0 83.535599 lr 0.00134100 rank 0
2022-08-23 03:02:12,963 DEBUG TRAIN Batch 39/700 loss 29.632919 loss_att 18.091419 loss_ctc 56.563084 loss_ctc_origin 47.917648 loss_ctc0 76.735764 lr 0.00134069 rank 0
2022-08-23 03:02:42,670 DEBUG TRAIN Batch 39/800 loss 30.509937 loss_att 16.697803 loss_ctc 62.738251 loss_ctc_origin 49.808262 loss_ctc0 92.908211 lr 0.00134039 rank 0
2022-08-23 03:03:13,044 DEBUG TRAIN Batch 39/900 loss 31.498697 loss_att 18.250555 loss_ctc 62.411026 loss_ctc_origin 50.195786 loss_ctc0 90.913254 lr 0.00134009 rank 0
2022-08-23 03:03:42,773 DEBUG TRAIN Batch 39/1000 loss 33.569298 loss_att 25.956131 loss_ctc 51.333351 loss_ctc_origin 42.179131 loss_ctc0 72.693192 lr 0.00133979 rank 0
2022-08-23 03:04:12,204 DEBUG TRAIN Batch 39/1100 loss 49.789757 loss_att 32.338081 loss_ctc 90.510330 loss_ctc_origin 59.541191 loss_ctc0 162.771637 lr 0.00133949 rank 0
2022-08-23 03:04:38,677 WARNING NaN or Inf found in input tensor.
2022-08-23 03:04:40,294 DEBUG TRAIN Batch 39/1200 loss 27.547304 loss_att 17.199057 loss_ctc 51.693214 loss_ctc_origin 41.693268 loss_ctc0 75.026428 lr 0.00133919 rank 0
2022-08-23 03:05:11,321 DEBUG TRAIN Batch 39/1300 loss 32.182247 loss_att 19.520468 loss_ctc 61.726395 loss_ctc_origin 51.031769 loss_ctc0 86.680527 lr 0.00133889 rank 0
2022-08-23 03:05:39,982 DEBUG TRAIN Batch 39/1400 loss 32.074059 loss_att 18.553892 loss_ctc 63.621109 loss_ctc_origin 49.187630 loss_ctc0 97.299232 lr 0.00133859 rank 0
2022-08-23 03:06:17,835 DEBUG TRAIN Batch 39/1500 loss 24.479794 loss_att 19.986206 loss_ctc 34.964832 loss_ctc_origin 31.182861 loss_ctc0 43.789425 lr 0.00133829 rank 0
2022-08-23 03:06:33,630 WARNING NaN or Inf found in input tensor.
2022-08-23 03:06:46,868 DEBUG TRAIN Batch 39/1600 loss 44.442986 loss_att 28.029993 loss_ctc 82.739960 loss_ctc_origin 54.041466 loss_ctc0 149.703125 lr 0.00133799 rank 0
2022-08-23 03:07:16,475 DEBUG TRAIN Batch 39/1700 loss 28.045353 loss_att 19.274963 loss_ctc 48.509590 loss_ctc_origin 39.325386 loss_ctc0 69.939407 lr 0.00133769 rank 0
2022-08-23 03:07:21,967 WARNING NaN or Inf found in input tensor.
2022-08-23 03:07:46,483 DEBUG TRAIN Batch 39/1800 loss 29.528980 loss_att 16.638811 loss_ctc 59.606041 loss_ctc_origin 46.574436 loss_ctc0 90.013115 lr 0.00133739 rank 0
2022-08-23 03:07:57,361 WARNING NaN or Inf found in input tensor.
2022-08-23 03:08:16,821 DEBUG TRAIN Batch 39/1900 loss 34.910957 loss_att 20.042009 loss_ctc 69.605171 loss_ctc_origin 56.782761 loss_ctc0 99.524132 lr 0.00133709 rank 0
2022-08-23 03:08:46,571 DEBUG TRAIN Batch 39/2000 loss 36.556450 loss_att 24.060440 loss_ctc 65.713806 loss_ctc_origin 46.716202 loss_ctc0 110.041565 lr 0.00133680 rank 0
2022-08-23 03:09:15,705 DEBUG TRAIN Batch 39/2100 loss 52.229225 loss_att 31.506184 loss_ctc 100.582985 loss_ctc_origin 57.786392 loss_ctc0 200.441696 lr 0.00133650 rank 0
2022-08-23 03:09:45,399 DEBUG TRAIN Batch 39/2200 loss 29.984684 loss_att 20.952883 loss_ctc 51.058887 loss_ctc_origin 42.014893 loss_ctc0 72.161537 lr 0.00133620 rank 0
2022-08-23 03:09:51,019 WARNING NaN or Inf found in input tensor.
2022-08-23 03:10:14,413 DEBUG TRAIN Batch 39/2300 loss 31.284924 loss_att 20.907646 loss_ctc 55.498566 loss_ctc_origin 44.639610 loss_ctc0 80.836136 lr 0.00133590 rank 0
2022-08-23 03:10:33,352 WARNING NaN or Inf found in input tensor.
2022-08-23 03:10:45,324 DEBUG TRAIN Batch 39/2400 loss 27.870573 loss_att 14.851184 loss_ctc 58.249146 loss_ctc_origin 41.426376 loss_ctc0 97.502281 lr 0.00133560 rank 0
2022-08-23 03:11:07,259 WARNING NaN or Inf found in input tensor.
2022-08-23 03:11:14,385 DEBUG TRAIN Batch 39/2500 loss 39.967102 loss_att 30.720989 loss_ctc 61.541367 loss_ctc_origin 49.155945 loss_ctc0 90.440681 lr 0.00133531 rank 0
2022-08-23 03:11:43,743 DEBUG TRAIN Batch 39/2600 loss 32.962006 loss_att 21.918314 loss_ctc 58.730614 loss_ctc_origin 36.229706 loss_ctc0 111.232727 lr 0.00133501 rank 0
2022-08-23 03:12:13,436 DEBUG TRAIN Batch 39/2700 loss 31.300220 loss_att 20.136143 loss_ctc 57.349739 loss_ctc_origin 49.069855 loss_ctc0 76.669479 lr 0.00133471 rank 0
2022-08-23 03:12:42,751 DEBUG TRAIN Batch 39/2800 loss 21.278688 loss_att 11.792779 loss_ctc 43.412476 loss_ctc_origin 32.409821 loss_ctc0 69.085342 lr 0.00133441 rank 0
2022-08-23 03:13:13,321 DEBUG TRAIN Batch 39/2900 loss 36.074726 loss_att 21.342064 loss_ctc 70.450935 loss_ctc_origin 56.064507 loss_ctc0 104.019257 lr 0.00133412 rank 0
2022-08-23 03:13:49,440 DEBUG TRAIN Batch 39/3000 loss 33.303860 loss_att 28.173790 loss_ctc 45.274021 loss_ctc_origin 44.133667 loss_ctc0 47.934845 lr 0.00133382 rank 0
2022-08-23 03:14:18,340 DEBUG TRAIN Batch 39/3100 loss 55.738998 loss_att 33.046894 loss_ctc 108.687241 loss_ctc_origin 61.540306 loss_ctc0 218.696732 lr 0.00133352 rank 0
2022-08-23 03:14:47,501 DEBUG TRAIN Batch 39/3200 loss 25.278488 loss_att 16.648945 loss_ctc 45.414085 loss_ctc_origin 36.369724 loss_ctc0 66.517586 lr 0.00133323 rank 0
2022-08-23 03:15:17,073 DEBUG TRAIN Batch 39/3300 loss 30.489990 loss_att 17.564472 loss_ctc 60.649532 loss_ctc_origin 50.513794 loss_ctc0 84.299591 lr 0.00133293 rank 0
2022-08-23 03:15:42,178 WARNING NaN or Inf found in input tensor.
2022-08-23 03:15:46,884 DEBUG TRAIN Batch 39/3400 loss 35.228054 loss_att 20.646587 loss_ctc 69.251472 loss_ctc_origin 55.255772 loss_ctc0 101.908112 lr 0.00133263 rank 0
2022-08-23 03:16:17,525 DEBUG TRAIN Batch 39/3500 loss 37.449043 loss_att 29.662479 loss_ctc 55.617687 loss_ctc_origin 41.759254 loss_ctc0 87.954025 lr 0.00133234 rank 0
2022-08-23 03:16:47,454 DEBUG TRAIN Batch 39/3600 loss 44.303379 loss_att 27.864483 loss_ctc 82.660797 loss_ctc_origin 54.105515 loss_ctc0 149.289780 lr 0.00133204 rank 0
2022-08-23 03:17:15,964 DEBUG TRAIN Batch 39/3700 loss 25.969397 loss_att 16.223042 loss_ctc 48.710892 loss_ctc_origin 38.698975 loss_ctc0 72.072029 lr 0.00133175 rank 0
2022-08-23 03:17:34,585 WARNING NaN or Inf found in input tensor.
2022-08-23 03:17:44,726 DEBUG TRAIN Batch 39/3800 loss 25.071938 loss_att 14.162561 loss_ctc 50.527149 loss_ctc_origin 39.056919 loss_ctc0 77.291016 lr 0.00133145 rank 0
2022-08-23 03:18:15,419 DEBUG TRAIN Batch 39/3900 loss 30.936977 loss_att 16.964811 loss_ctc 63.538692 loss_ctc_origin 46.950603 loss_ctc0 102.244232 lr 0.00133116 rank 0
2022-08-23 03:18:43,507 DEBUG TRAIN Batch 39/4000 loss 28.349918 loss_att 23.028957 loss_ctc 40.765495 loss_ctc_origin 39.179848 loss_ctc0 44.465336 lr 0.00133086 rank 0
2022-08-23 03:19:13,712 DEBUG TRAIN Batch 39/4100 loss 30.101418 loss_att 21.730618 loss_ctc 49.633286 loss_ctc_origin 39.687168 loss_ctc0 72.840897 lr 0.00133057 rank 0
2022-08-23 03:19:42,784 DEBUG TRAIN Batch 39/4200 loss 26.673641 loss_att 16.291872 loss_ctc 50.897770 loss_ctc_origin 40.152397 loss_ctc0 75.970306 lr 0.00133027 rank 0
2022-08-23 03:19:55,755 WARNING NaN or Inf found in input tensor.
2022-08-23 03:20:12,993 DEBUG TRAIN Batch 39/4300 loss 29.675392 loss_att 17.652000 loss_ctc 57.729973 loss_ctc_origin 46.602711 loss_ctc0 83.693581 lr 0.00132998 rank 0
2022-08-23 03:20:42,139 DEBUG TRAIN Batch 39/4400 loss 39.001060 loss_att 24.026978 loss_ctc 73.940582 loss_ctc_origin 59.510506 loss_ctc0 107.610764 lr 0.00132969 rank 0
2022-08-23 03:21:19,450 DEBUG TRAIN Batch 39/4500 loss 30.892532 loss_att 23.263264 loss_ctc 48.694160 loss_ctc_origin 43.808361 loss_ctc0 60.094364 lr 0.00132939 rank 0
2022-08-23 03:21:48,883 DEBUG TRAIN Batch 39/4600 loss 30.592356 loss_att 21.081787 loss_ctc 52.783680 loss_ctc_origin 41.982723 loss_ctc0 77.985916 lr 0.00132910 rank 0
2022-08-23 03:22:17,999 DEBUG TRAIN Batch 39/4700 loss 21.495251 loss_att 12.552451 loss_ctc 42.361786 loss_ctc_origin 32.375179 loss_ctc0 65.663864 lr 0.00132881 rank 0
2022-08-23 03:22:48,170 DEBUG TRAIN Batch 39/4800 loss 23.624447 loss_att 13.260321 loss_ctc 47.807404 loss_ctc_origin 37.208923 loss_ctc0 72.537186 lr 0.00132851 rank 0
2022-08-23 03:23:17,915 DEBUG TRAIN Batch 39/4900 loss 36.079613 loss_att 22.375813 loss_ctc 68.055145 loss_ctc_origin 54.194931 loss_ctc0 100.395630 lr 0.00132822 rank 0
2022-08-23 03:23:48,408 DEBUG TRAIN Batch 39/5000 loss 27.052666 loss_att 22.325558 loss_ctc 38.082581 loss_ctc_origin 36.137112 loss_ctc0 42.622005 lr 0.00132793 rank 0
2022-08-23 03:23:56,785 WARNING NaN or Inf found in input tensor.
2022-08-23 03:24:16,696 DEBUG TRAIN Batch 39/5100 loss 33.724503 loss_att 24.000191 loss_ctc 56.414566 loss_ctc_origin 44.623711 loss_ctc0 83.926552 lr 0.00132763 rank 0
2022-08-23 03:24:46,612 DEBUG TRAIN Batch 39/5200 loss 28.864969 loss_att 18.141363 loss_ctc 53.886715 loss_ctc_origin 45.019737 loss_ctc0 74.576332 lr 0.00132734 rank 0
2022-08-23 03:24:52,284 WARNING NaN or Inf found in input tensor.
2022-08-23 03:25:15,366 DEBUG TRAIN Batch 39/5300 loss 29.408386 loss_att 16.285770 loss_ctc 60.027821 loss_ctc_origin 48.551598 loss_ctc0 86.805672 lr 0.00132705 rank 0
2022-08-23 03:25:35,119 WARNING NaN or Inf found in input tensor.
2022-08-23 03:25:47,185 DEBUG TRAIN Batch 39/5400 loss 31.767954 loss_att 18.983152 loss_ctc 61.599159 loss_ctc_origin 47.708031 loss_ctc0 94.011795 lr 0.00132676 rank 0
2022-08-23 03:26:16,573 DEBUG TRAIN Batch 39/5500 loss 34.175491 loss_att 27.875847 loss_ctc 48.874657 loss_ctc_origin 41.088188 loss_ctc0 67.043076 lr 0.00132647 rank 0
2022-08-23 03:26:45,759 DEBUG TRAIN Batch 39/5600 loss 53.209618 loss_att 34.699570 loss_ctc 96.399727 loss_ctc_origin 67.297104 loss_ctc0 164.305847 lr 0.00132617 rank 0
2022-08-23 03:27:10,632 DEBUG CV Batch 39/0 loss 43.420570 loss_att 27.070564 loss_ctc 81.570580 loss_ctc_origin 41.131432 loss_ctc0 175.928574 history loss 40.866419 rank 0
2022-08-23 03:27:21,994 DEBUG CV Batch 39/100 loss 48.966324 loss_att 32.625515 loss_ctc 87.094879 loss_ctc_origin 52.893963 loss_ctc0 166.897034 history loss 38.003624 rank 0
2022-08-23 03:27:32,140 DEBUG CV Batch 39/200 loss 28.562674 loss_att 21.878351 loss_ctc 44.159424 loss_ctc_origin 34.892784 loss_ctc0 65.781578 history loss 39.887919 rank 0
2022-08-23 03:27:42,664 DEBUG CV Batch 39/300 loss 28.875471 loss_att 21.487942 loss_ctc 46.113037 loss_ctc_origin 32.124516 loss_ctc0 78.752914 history loss 39.206254 rank 0
2022-08-23 03:27:53,940 DEBUG CV Batch 39/400 loss 43.527969 loss_att 34.654209 loss_ctc 64.233414 loss_ctc_origin 47.646778 loss_ctc0 102.935547 history loss 37.144036 rank 0
2022-08-23 03:28:05,259 DEBUG CV Batch 39/500 loss 44.886898 loss_att 28.948114 loss_ctc 82.077393 loss_ctc_origin 43.475800 loss_ctc0 172.147766 history loss 36.708067 rank 0
2022-08-23 03:28:16,382 DEBUG CV Batch 39/600 loss 28.452293 loss_att 18.854414 loss_ctc 50.847340 loss_ctc_origin 31.119354 loss_ctc0 96.879303 history loss 36.750494 rank 0
2022-08-23 03:28:27,342 DEBUG CV Batch 39/700 loss 23.512794 loss_att 16.078892 loss_ctc 40.858566 loss_ctc_origin 28.455318 loss_ctc0 69.799484 history loss 36.244323 rank 0
2022-08-23 03:28:38,815 DEBUG CV Batch 39/800 loss 24.793592 loss_att 18.310179 loss_ctc 39.921555 loss_ctc_origin 25.220568 loss_ctc0 74.223846 history loss 36.014198 rank 0
2022-08-23 03:28:50,420 INFO Epoch 39 CV info cv_loss 35.81258261440903
2022-08-23 03:28:50,421 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/39.pt
2022-08-23 03:28:50,923 INFO Epoch 40 TRAIN info lr 0.00132592880695955
2022-08-23 03:28:50,927 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 03:29:19,122 DEBUG TRAIN Batch 40/0 loss 42.314423 loss_att 31.440660 loss_ctc 67.686539 loss_ctc_origin 52.256901 loss_ctc0 103.689011 lr 0.00132592 rank 0
2022-08-23 03:29:48,222 WARNING NaN or Inf found in input tensor.
2022-08-23 03:29:48,283 DEBUG TRAIN Batch 40/100 loss nan loss_att 30.004881 loss_ctc nan loss_ctc_origin 53.103138 loss_ctc0 nan lr 0.00132563 rank 0
2022-08-23 03:30:17,976 DEBUG TRAIN Batch 40/200 loss 30.148773 loss_att 18.026825 loss_ctc 58.433319 loss_ctc_origin 49.995857 loss_ctc0 78.120728 lr 0.00132533 rank 0
2022-08-23 03:30:47,070 DEBUG TRAIN Batch 40/300 loss 30.320385 loss_att 18.110130 loss_ctc 58.810982 loss_ctc_origin 46.331043 loss_ctc0 87.930832 lr 0.00132504 rank 0
2022-08-23 03:31:12,418 WARNING NaN or Inf found in input tensor.
2022-08-23 03:31:16,984 DEBUG TRAIN Batch 40/400 loss 38.606400 loss_att 23.092850 loss_ctc 74.804672 loss_ctc_origin 60.225590 loss_ctc0 108.822517 lr 0.00132475 rank 0
2022-08-23 03:31:48,286 DEBUG TRAIN Batch 40/500 loss 24.898521 loss_att 21.593685 loss_ctc 32.609806 loss_ctc_origin 30.431190 loss_ctc0 37.693241 lr 0.00132446 rank 0
2022-08-23 03:32:10,628 WARNING NaN or Inf found in input tensor.
2022-08-23 03:32:18,026 DEBUG TRAIN Batch 40/600 loss 47.925934 loss_att 31.063614 loss_ctc 87.271347 loss_ctc_origin 54.604294 loss_ctc0 163.494461 lr 0.00132417 rank 0
2022-08-23 03:32:47,489 DEBUG TRAIN Batch 40/700 loss 27.445816 loss_att 18.184578 loss_ctc 49.055374 loss_ctc_origin 40.294960 loss_ctc0 69.496330 lr 0.00132388 rank 0
2022-08-23 03:33:17,000 DEBUG TRAIN Batch 40/800 loss 29.640234 loss_att 16.643911 loss_ctc 59.964985 loss_ctc_origin 48.919228 loss_ctc0 85.738419 lr 0.00132359 rank 0
2022-08-23 03:33:47,532 DEBUG TRAIN Batch 40/900 loss 33.749065 loss_att 19.539200 loss_ctc 66.905418 loss_ctc_origin 54.630630 loss_ctc0 95.546600 lr 0.00132330 rank 0
2022-08-23 03:34:16,470 DEBUG TRAIN Batch 40/1000 loss 22.365841 loss_att 17.815325 loss_ctc 32.983707 loss_ctc_origin 30.409098 loss_ctc0 38.991131 lr 0.00132301 rank 0
2022-08-23 03:34:47,248 DEBUG TRAIN Batch 40/1100 loss 31.906244 loss_att 19.945137 loss_ctc 59.815491 loss_ctc_origin 41.226677 loss_ctc0 103.189392 lr 0.00132272 rank 0
2022-08-23 03:35:16,557 DEBUG TRAIN Batch 40/1200 loss 29.657049 loss_att 19.155426 loss_ctc 54.160835 loss_ctc_origin 45.206352 loss_ctc0 75.054626 lr 0.00132243 rank 0
2022-08-23 03:35:46,607 DEBUG TRAIN Batch 40/1300 loss 30.342901 loss_att 17.135473 loss_ctc 61.160233 loss_ctc_origin 49.865196 loss_ctc0 87.515320 lr 0.00132215 rank 0
2022-08-23 03:36:12,511 WARNING NaN or Inf found in input tensor.
2022-08-23 03:36:17,090 DEBUG TRAIN Batch 40/1400 loss 31.956966 loss_att 16.785187 loss_ctc 67.357788 loss_ctc_origin 51.651432 loss_ctc0 104.005936 lr 0.00132186 rank 0
2022-08-23 03:36:53,183 DEBUG TRAIN Batch 40/1500 loss 31.956364 loss_att 23.740894 loss_ctc 51.125790 loss_ctc_origin 37.922653 loss_ctc0 81.933105 lr 0.00132157 rank 0
2022-08-23 03:37:08,704 WARNING NaN or Inf found in input tensor.
2022-08-23 03:37:22,898 DEBUG TRAIN Batch 40/1600 loss 36.817284 loss_att 25.949421 loss_ctc 62.175629 loss_ctc_origin 43.267143 loss_ctc0 106.295418 lr 0.00132128 rank 0
2022-08-23 03:37:52,207 DEBUG TRAIN Batch 40/1700 loss 24.941093 loss_att 15.356462 loss_ctc 47.305237 loss_ctc_origin 37.315765 loss_ctc0 70.613998 lr 0.00132099 rank 0
2022-08-23 03:38:22,071 DEBUG TRAIN Batch 40/1800 loss 34.918854 loss_att 19.396322 loss_ctc 71.138100 loss_ctc_origin 61.518745 loss_ctc0 93.583252 lr 0.00132070 rank 0
2022-08-23 03:38:51,415 DEBUG TRAIN Batch 40/1900 loss 33.214050 loss_att 18.788349 loss_ctc 66.874016 loss_ctc_origin 53.307205 loss_ctc0 98.529907 lr 0.00132042 rank 0
2022-08-23 03:39:21,743 DEBUG TRAIN Batch 40/2000 loss 29.604748 loss_att 24.455492 loss_ctc 41.619675 loss_ctc_origin 39.568584 loss_ctc0 46.405548 lr 0.00132013 rank 0
2022-08-23 03:39:49,965 DEBUG TRAIN Batch 40/2100 loss 39.555256 loss_att 23.416418 loss_ctc 77.212540 loss_ctc_origin 50.868855 loss_ctc0 138.681152 lr 0.00131984 rank 0
2022-08-23 03:40:19,929 DEBUG TRAIN Batch 40/2200 loss 26.977526 loss_att 17.319893 loss_ctc 49.512001 loss_ctc_origin 39.603951 loss_ctc0 72.630791 lr 0.00131955 rank 0
2022-08-23 03:40:49,483 DEBUG TRAIN Batch 40/2300 loss 30.341881 loss_att 17.893797 loss_ctc 59.387405 loss_ctc_origin 47.992950 loss_ctc0 85.974457 lr 0.00131927 rank 0
2022-08-23 03:41:19,256 DEBUG TRAIN Batch 40/2400 loss 31.445290 loss_att 16.850994 loss_ctc 65.498642 loss_ctc_origin 51.828213 loss_ctc0 97.396317 lr 0.00131898 rank 0
2022-08-23 03:41:49,858 DEBUG TRAIN Batch 40/2500 loss 27.348806 loss_att 19.209221 loss_ctc 46.341171 loss_ctc_origin 36.771088 loss_ctc0 68.671364 lr 0.00131869 rank 0
2022-08-23 03:42:04,449 WARNING NaN or Inf found in input tensor.
2022-08-23 03:42:19,997 DEBUG TRAIN Batch 40/2600 loss 33.392239 loss_att 22.039013 loss_ctc 59.883095 loss_ctc_origin 41.334949 loss_ctc0 103.162109 lr 0.00131841 rank 0
2022-08-23 03:42:49,087 DEBUG TRAIN Batch 40/2700 loss 26.885044 loss_att 17.213821 loss_ctc 49.451233 loss_ctc_origin 39.518135 loss_ctc0 72.628456 lr 0.00131812 rank 0
2022-08-23 03:43:17,982 DEBUG TRAIN Batch 40/2800 loss 28.881741 loss_att 16.299660 loss_ctc 58.239929 loss_ctc_origin 47.463684 loss_ctc0 83.384506 lr 0.00131783 rank 0
2022-08-23 03:43:47,868 DEBUG TRAIN Batch 40/2900 loss 32.677242 loss_att 17.736698 loss_ctc 67.538513 loss_ctc_origin 52.161648 loss_ctc0 103.417877 lr 0.00131755 rank 0
2022-08-23 03:44:24,318 DEBUG TRAIN Batch 40/3000 loss 25.549141 loss_att 21.643494 loss_ctc 34.662315 loss_ctc_origin 31.463079 loss_ctc0 42.127197 lr 0.00131726 rank 0
2022-08-23 03:44:53,125 DEBUG TRAIN Batch 40/3100 loss 32.747261 loss_att 24.782486 loss_ctc 51.331730 loss_ctc_origin 42.936306 loss_ctc0 70.921051 lr 0.00131698 rank 0
2022-08-23 03:45:21,125 WARNING NaN or Inf found in input tensor.
2022-08-23 03:45:22,927 DEBUG TRAIN Batch 40/3200 loss 26.382366 loss_att 15.757782 loss_ctc 51.173058 loss_ctc_origin 41.105415 loss_ctc0 74.664215 lr 0.00131669 rank 0
2022-08-23 03:45:28,445 WARNING NaN or Inf found in input tensor.
2022-08-23 03:45:52,215 DEBUG TRAIN Batch 40/3300 loss 27.927490 loss_att 15.655024 loss_ctc 56.563248 loss_ctc_origin 44.089046 loss_ctc0 85.669708 lr 0.00131640 rank 0
2022-08-23 03:46:22,311 DEBUG TRAIN Batch 40/3400 loss 33.720444 loss_att 20.134571 loss_ctc 65.420807 loss_ctc_origin 49.798801 loss_ctc0 101.872147 lr 0.00131612 rank 0
2022-08-23 03:46:52,275 DEBUG TRAIN Batch 40/3500 loss 29.491798 loss_att 24.168133 loss_ctc 41.913685 loss_ctc_origin 39.332077 loss_ctc0 47.937431 lr 0.00131584 rank 0
2022-08-23 03:47:00,203 WARNING NaN or Inf found in input tensor.
2022-08-23 03:47:20,762 DEBUG TRAIN Batch 40/3600 loss 37.821560 loss_att 27.236382 loss_ctc 62.520309 loss_ctc_origin 47.384388 loss_ctc0 97.837463 lr 0.00131555 rank 0
2022-08-23 03:47:49,550 DEBUG TRAIN Batch 40/3700 loss 23.548534 loss_att 13.521525 loss_ctc 46.944885 loss_ctc_origin 38.790825 loss_ctc0 65.971024 lr 0.00131527 rank 0
2022-08-23 03:48:16,504 WARNING NaN or Inf found in input tensor.
2022-08-23 03:48:19,151 DEBUG TRAIN Batch 40/3800 loss 24.579432 loss_att 14.188848 loss_ctc 48.824123 loss_ctc_origin 34.966488 loss_ctc0 81.158600 lr 0.00131498 rank 0
2022-08-23 03:48:48,055 DEBUG TRAIN Batch 40/3900 loss 35.560024 loss_att 21.150719 loss_ctc 69.181732 loss_ctc_origin 54.904541 loss_ctc0 102.495178 lr 0.00131470 rank 0
2022-08-23 03:49:18,060 DEBUG TRAIN Batch 40/4000 loss 26.064220 loss_att 21.239662 loss_ctc 37.321526 loss_ctc_origin 34.849007 loss_ctc0 43.090729 lr 0.00131441 rank 0
2022-08-23 03:49:46,273 DEBUG TRAIN Batch 40/4100 loss 28.082176 loss_att 21.661013 loss_ctc 43.064892 loss_ctc_origin 34.977863 loss_ctc0 61.934620 lr 0.00131413 rank 0
2022-08-23 03:50:14,388 DEBUG TRAIN Batch 40/4200 loss 30.261713 loss_att 18.783398 loss_ctc 57.044449 loss_ctc_origin 48.635620 loss_ctc0 76.665047 lr 0.00131385 rank 0
2022-08-23 03:50:44,616 DEBUG TRAIN Batch 40/4300 loss 32.907169 loss_att 18.493675 loss_ctc 66.538651 loss_ctc_origin 55.188843 loss_ctc0 93.021523 lr 0.00131356 rank 0
2022-08-23 03:51:14,323 DEBUG TRAIN Batch 40/4400 loss 32.100990 loss_att 18.942787 loss_ctc 62.803459 loss_ctc_origin 49.980396 loss_ctc0 92.723923 lr 0.00131328 rank 0
2022-08-23 03:51:50,115 DEBUG TRAIN Batch 40/4500 loss 29.875298 loss_att 23.843647 loss_ctc 43.949154 loss_ctc_origin 39.835182 loss_ctc0 53.548424 lr 0.00131300 rank 0
2022-08-23 03:52:19,372 DEBUG TRAIN Batch 40/4600 loss 31.884457 loss_att 22.790119 loss_ctc 53.104576 loss_ctc_origin 43.761761 loss_ctc0 74.904480 lr 0.00131271 rank 0
2022-08-23 03:52:48,860 DEBUG TRAIN Batch 40/4700 loss 26.028618 loss_att 16.769897 loss_ctc 47.632294 loss_ctc_origin 39.115700 loss_ctc0 67.504341 lr 0.00131243 rank 0
2022-08-23 03:53:18,248 DEBUG TRAIN Batch 40/4800 loss 29.472958 loss_att 16.874649 loss_ctc 58.869011 loss_ctc_origin 47.776085 loss_ctc0 84.752495 lr 0.00131215 rank 0
2022-08-23 03:53:47,771 DEBUG TRAIN Batch 40/4900 loss 35.092606 loss_att 20.871258 loss_ctc 68.275742 loss_ctc_origin 53.090862 loss_ctc0 103.707123 lr 0.00131187 rank 0
2022-08-23 03:54:18,092 DEBUG TRAIN Batch 40/5000 loss 27.235813 loss_att 22.126818 loss_ctc 39.156799 loss_ctc_origin 37.967365 loss_ctc0 41.932137 lr 0.00131158 rank 0
2022-08-23 03:54:46,677 DEBUG TRAIN Batch 40/5100 loss 33.616928 loss_att 23.751156 loss_ctc 56.637054 loss_ctc_origin 46.748573 loss_ctc0 79.710190 lr 0.00131130 rank 0
2022-08-23 03:55:16,207 DEBUG TRAIN Batch 40/5200 loss 28.189682 loss_att 19.115551 loss_ctc 49.362656 loss_ctc_origin 39.964008 loss_ctc0 71.292831 lr 0.00131102 rank 0
2022-08-23 03:55:45,658 DEBUG TRAIN Batch 40/5300 loss 31.099648 loss_att 18.220402 loss_ctc 61.151222 loss_ctc_origin 48.487114 loss_ctc0 90.700806 lr 0.00131074 rank 0
2022-08-23 03:56:16,882 DEBUG TRAIN Batch 40/5400 loss 32.248367 loss_att 18.643421 loss_ctc 63.993244 loss_ctc_origin 47.137280 loss_ctc0 103.323830 lr 0.00131046 rank 0
2022-08-23 03:56:47,339 DEBUG TRAIN Batch 40/5500 loss 30.207264 loss_att 25.249916 loss_ctc 41.774410 loss_ctc_origin 40.432461 loss_ctc0 44.905624 lr 0.00131018 rank 0
2022-08-23 03:57:16,441 DEBUG TRAIN Batch 40/5600 loss 34.657654 loss_att 23.871910 loss_ctc 59.824387 loss_ctc_origin 42.026302 loss_ctc0 101.353256 lr 0.00130990 rank 0
2022-08-23 03:57:30,006 WARNING NaN or Inf found in input tensor.
2022-08-23 03:57:39,716 DEBUG CV Batch 40/0 loss 18.283455 loss_att 13.125681 loss_ctc 30.318256 loss_ctc_origin 21.627121 loss_ctc0 50.597572 history loss 17.207958 rank 0
2022-08-23 03:57:51,006 DEBUG CV Batch 40/100 loss 25.946806 loss_att 18.963633 loss_ctc 42.240875 loss_ctc_origin 30.550858 loss_ctc0 69.517593 history loss 32.212770 rank 0
2022-08-23 03:58:01,224 DEBUG CV Batch 40/200 loss 29.404133 loss_att 22.977819 loss_ctc 44.398865 loss_ctc_origin 34.476936 loss_ctc0 67.550018 history loss 33.531744 rank 0
2022-08-23 03:58:11,647 DEBUG CV Batch 40/300 loss 28.740246 loss_att 21.380070 loss_ctc 45.913994 loss_ctc_origin 31.839119 loss_ctc0 78.755379 history loss 32.583819 rank 0
2022-08-23 03:58:22,927 DEBUG CV Batch 40/400 loss 44.142654 loss_att 35.242645 loss_ctc 64.909348 loss_ctc_origin 47.991730 loss_ctc0 104.383774 history loss 30.981704 rank 0
2022-08-23 03:58:34,276 DEBUG CV Batch 40/500 loss 21.426018 loss_att 14.709946 loss_ctc 37.096855 loss_ctc_origin 24.361494 loss_ctc0 66.812698 history loss 30.634421 rank 0
2022-08-23 03:58:45,311 DEBUG CV Batch 40/600 loss 21.083443 loss_att 14.634371 loss_ctc 36.131279 loss_ctc_origin 25.385258 loss_ctc0 61.205326 history loss 30.505694 rank 0
2022-08-23 03:58:55,832 DEBUG CV Batch 40/700 loss 23.066938 loss_att 15.457482 loss_ctc 40.822334 loss_ctc_origin 28.133898 loss_ctc0 70.428680 history loss 30.146645 rank 0
2022-08-23 03:59:06,806 DEBUG CV Batch 40/800 loss 26.955122 loss_att 20.094116 loss_ctc 42.964134 loss_ctc_origin 28.226505 loss_ctc0 77.351944 history loss 30.091618 rank 0
2022-08-23 03:59:17,597 INFO Epoch 40 CV info cv_loss 30.175736741027173
2022-08-23 03:59:17,597 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/40.pt
2022-08-23 03:59:18,062 INFO Epoch 41 TRAIN info lr 0.001309659125684228
2022-08-23 03:59:18,065 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 03:59:46,186 DEBUG TRAIN Batch 41/0 loss 27.101707 loss_att 22.006519 loss_ctc 38.990479 loss_ctc_origin 35.450024 loss_ctc0 47.251534 lr 0.00130965 rank 0
2022-08-23 04:00:16,274 DEBUG TRAIN Batch 41/100 loss 32.374290 loss_att 23.904413 loss_ctc 52.137337 loss_ctc_origin 40.636131 loss_ctc0 78.973480 lr 0.00130937 rank 0
2022-08-23 04:00:45,522 DEBUG TRAIN Batch 41/200 loss 25.848579 loss_att 15.628870 loss_ctc 49.694565 loss_ctc_origin 40.678291 loss_ctc0 70.732529 lr 0.00130909 rank 0
2022-08-23 04:00:58,271 WARNING NaN or Inf found in input tensor.
2022-08-23 04:01:14,250 DEBUG TRAIN Batch 41/300 loss 29.085655 loss_att 15.990908 loss_ctc 59.640064 loss_ctc_origin 48.675591 loss_ctc0 85.223831 lr 0.00130881 rank 0
2022-08-23 04:01:39,981 WARNING NaN or Inf found in input tensor.
2022-08-23 04:01:44,581 DEBUG TRAIN Batch 41/400 loss 36.066147 loss_att 20.446491 loss_ctc 72.512016 loss_ctc_origin 59.756691 loss_ctc0 102.274445 lr 0.00130853 rank 0
2022-08-23 04:02:14,214 DEBUG TRAIN Batch 41/500 loss 26.377533 loss_att 21.378645 loss_ctc 38.041603 loss_ctc_origin 35.475384 loss_ctc0 44.029449 lr 0.00130825 rank 0
2022-08-23 04:02:44,059 DEBUG TRAIN Batch 41/600 loss 29.626070 loss_att 21.591791 loss_ctc 48.372719 loss_ctc_origin 41.796970 loss_ctc0 63.716122 lr 0.00130797 rank 0
2022-08-23 04:03:13,298 DEBUG TRAIN Batch 41/700 loss 23.089703 loss_att 14.577015 loss_ctc 42.952637 loss_ctc_origin 32.791695 loss_ctc0 66.661507 lr 0.00130769 rank 0
2022-08-23 04:03:42,635 DEBUG TRAIN Batch 41/800 loss 26.746326 loss_att 14.392467 loss_ctc 55.571995 loss_ctc_origin 41.677349 loss_ctc0 87.992828 lr 0.00130741 rank 0
2022-08-23 04:04:12,654 DEBUG TRAIN Batch 41/900 loss 30.523685 loss_att 16.470320 loss_ctc 63.314873 loss_ctc_origin 49.058578 loss_ctc0 96.579559 lr 0.00130713 rank 0
2022-08-23 04:04:42,302 DEBUG TRAIN Batch 41/1000 loss 25.348202 loss_att 21.225061 loss_ctc 34.968861 loss_ctc_origin 32.639111 loss_ctc0 40.404938 lr 0.00130685 rank 0
2022-08-23 04:05:10,961 DEBUG TRAIN Batch 41/1100 loss 30.162712 loss_att 21.715240 loss_ctc 49.873474 loss_ctc_origin 40.955833 loss_ctc0 70.681305 lr 0.00130657 rank 0
2022-08-23 04:05:41,000 DEBUG TRAIN Batch 41/1200 loss 31.081015 loss_att 21.887915 loss_ctc 52.531582 loss_ctc_origin 42.124718 loss_ctc0 76.814262 lr 0.00130629 rank 0
2022-08-23 04:06:09,825 DEBUG TRAIN Batch 41/1300 loss 26.927242 loss_att 15.304909 loss_ctc 54.046021 loss_ctc_origin 41.437141 loss_ctc0 83.466736 lr 0.00130601 rank 0
2022-08-23 04:06:40,659 DEBUG TRAIN Batch 41/1400 loss 30.674881 loss_att 16.397522 loss_ctc 63.988716 loss_ctc_origin 48.506508 loss_ctc0 100.113861 lr 0.00130573 rank 0
2022-08-23 04:07:16,448 DEBUG TRAIN Batch 41/1500 loss 33.087425 loss_att 27.025612 loss_ctc 47.231659 loss_ctc_origin 43.765427 loss_ctc0 55.319527 lr 0.00130546 rank 0
2022-08-23 04:07:46,636 DEBUG TRAIN Batch 41/1600 loss 27.386692 loss_att 18.315067 loss_ctc 48.553810 loss_ctc_origin 35.302402 loss_ctc0 79.473755 lr 0.00130518 rank 0
2022-08-23 04:08:15,939 DEBUG TRAIN Batch 41/1700 loss 27.050034 loss_att 16.874079 loss_ctc 50.793930 loss_ctc_origin 42.176552 loss_ctc0 70.901138 lr 0.00130490 rank 0
2022-08-23 04:08:45,751 DEBUG TRAIN Batch 41/1800 loss 23.706623 loss_att 12.190964 loss_ctc 50.576492 loss_ctc_origin 38.102783 loss_ctc0 79.681808 lr 0.00130462 rank 0
2022-08-23 04:09:15,144 DEBUG TRAIN Batch 41/1900 loss 34.694878 loss_att 19.912773 loss_ctc 69.186447 loss_ctc_origin 53.324635 loss_ctc0 106.197342 lr 0.00130435 rank 0
2022-08-23 04:09:46,614 DEBUG TRAIN Batch 41/2000 loss 24.854242 loss_att 20.606483 loss_ctc 34.765678 loss_ctc_origin 32.817432 loss_ctc0 39.311588 lr 0.00130407 rank 0
2022-08-23 04:10:15,507 DEBUG TRAIN Batch 41/2100 loss 36.277802 loss_att 25.476151 loss_ctc 61.481659 loss_ctc_origin 48.064644 loss_ctc0 92.788040 lr 0.00130379 rank 0
2022-08-23 04:10:45,122 DEBUG TRAIN Batch 41/2200 loss 25.965492 loss_att 15.252956 loss_ctc 50.961411 loss_ctc_origin 41.448944 loss_ctc0 73.157166 lr 0.00130351 rank 0
2022-08-23 04:11:15,058 DEBUG TRAIN Batch 41/2300 loss 30.751356 loss_att 17.302258 loss_ctc 62.132584 loss_ctc_origin 50.393150 loss_ctc0 89.524590 lr 0.00130324 rank 0
2022-08-23 04:11:45,475 DEBUG TRAIN Batch 41/2400 loss 38.893433 loss_att 22.926495 loss_ctc 76.149628 loss_ctc_origin 60.446709 loss_ctc0 112.789764 lr 0.00130296 rank 0
2022-08-23 04:11:48,199 WARNING NaN or Inf found in input tensor.
2022-08-23 04:12:14,964 DEBUG TRAIN Batch 41/2500 loss 30.387474 loss_att 23.736969 loss_ctc 45.905323 loss_ctc_origin 43.747967 loss_ctc0 50.939156 lr 0.00130268 rank 0
2022-08-23 04:12:45,149 DEBUG TRAIN Batch 41/2600 loss 29.817070 loss_att 21.942097 loss_ctc 48.192005 loss_ctc_origin 40.905586 loss_ctc0 65.193649 lr 0.00130241 rank 0
2022-08-23 04:13:14,087 DEBUG TRAIN Batch 41/2700 loss 29.649115 loss_att 20.213020 loss_ctc 51.666668 loss_ctc_origin 42.477852 loss_ctc0 73.107239 lr 0.00130213 rank 0
2022-08-23 04:13:44,104 DEBUG TRAIN Batch 41/2800 loss 30.967918 loss_att 17.274536 loss_ctc 62.919136 loss_ctc_origin 51.033646 loss_ctc0 90.651947 lr 0.00130186 rank 0
2022-08-23 04:14:14,548 DEBUG TRAIN Batch 41/2900 loss 32.430222 loss_att 17.921535 loss_ctc 66.283821 loss_ctc_origin 50.339966 loss_ctc0 103.486137 lr 0.00130158 rank 0
2022-08-23 04:14:51,292 DEBUG TRAIN Batch 41/3000 loss 31.067471 loss_att 25.360226 loss_ctc 44.384377 loss_ctc_origin 41.092094 loss_ctc0 52.066368 lr 0.00130130 rank 0
2022-08-23 04:15:20,589 DEBUG TRAIN Batch 41/3100 loss 29.784081 loss_att 22.832964 loss_ctc 46.003357 loss_ctc_origin 40.693565 loss_ctc0 58.392876 lr 0.00130103 rank 0
2022-08-23 04:15:48,944 DEBUG TRAIN Batch 41/3200 loss 27.735493 loss_att 17.640162 loss_ctc 51.291264 loss_ctc_origin 40.522491 loss_ctc0 76.418396 lr 0.00130075 rank 0
2022-08-23 04:16:18,230 DEBUG TRAIN Batch 41/3300 loss 35.273903 loss_att 20.253738 loss_ctc 70.320946 loss_ctc_origin 58.748856 loss_ctc0 97.322487 lr 0.00130048 rank 0
2022-08-23 04:16:48,862 DEBUG TRAIN Batch 41/3400 loss 33.236023 loss_att 18.811621 loss_ctc 66.892967 loss_ctc_origin 49.410645 loss_ctc0 107.685051 lr 0.00130020 rank 0
2022-08-23 04:17:19,477 DEBUG TRAIN Batch 41/3500 loss 30.096891 loss_att 24.083914 loss_ctc 44.127171 loss_ctc_origin 41.499084 loss_ctc0 50.259377 lr 0.00129993 rank 0
2022-08-23 04:17:49,356 DEBUG TRAIN Batch 41/3600 loss 29.806995 loss_att 21.986557 loss_ctc 48.054680 loss_ctc_origin 41.162472 loss_ctc0 64.136490 lr 0.00129966 rank 0
2022-08-23 04:18:18,536 DEBUG TRAIN Batch 41/3700 loss 24.112934 loss_att 15.155279 loss_ctc 45.014130 loss_ctc_origin 35.203136 loss_ctc0 67.906448 lr 0.00129938 rank 0
2022-08-23 04:18:47,572 DEBUG TRAIN Batch 41/3800 loss 31.201399 loss_att 17.924671 loss_ctc 62.180428 loss_ctc_origin 49.847553 loss_ctc0 90.957123 lr 0.00129911 rank 0
2022-08-23 04:19:16,398 DEBUG TRAIN Batch 41/3900 loss 33.694962 loss_att 19.788181 loss_ctc 66.144119 loss_ctc_origin 50.444107 loss_ctc0 102.777481 lr 0.00129883 rank 0
2022-08-23 04:19:45,768 DEBUG TRAIN Batch 41/4000 loss 26.163197 loss_att 21.119892 loss_ctc 37.930908 loss_ctc_origin 32.052277 loss_ctc0 51.647713 lr 0.00129856 rank 0
2022-08-23 04:20:14,607 DEBUG TRAIN Batch 41/4100 loss 33.181557 loss_att 24.938267 loss_ctc 52.415897 loss_ctc_origin 42.773918 loss_ctc0 74.913849 lr 0.00129829 rank 0
2022-08-23 04:20:44,430 DEBUG TRAIN Batch 41/4200 loss 31.655659 loss_att 21.600388 loss_ctc 55.117962 loss_ctc_origin 45.928162 loss_ctc0 76.560829 lr 0.00129801 rank 0
2022-08-23 04:21:14,263 DEBUG TRAIN Batch 41/4300 loss 33.026932 loss_att 18.755245 loss_ctc 66.327530 loss_ctc_origin 56.878166 loss_ctc0 88.376045 lr 0.00129774 rank 0
2022-08-23 04:21:44,277 DEBUG TRAIN Batch 41/4400 loss 38.073677 loss_att 23.596384 loss_ctc 71.854019 loss_ctc_origin 58.554626 loss_ctc0 102.885925 lr 0.00129747 rank 0
2022-08-23 04:22:19,416 DEBUG TRAIN Batch 41/4500 loss 32.979927 loss_att 23.873396 loss_ctc 54.228504 loss_ctc_origin 50.926094 loss_ctc0 61.934128 lr 0.00129719 rank 0
2022-08-23 04:22:48,642 DEBUG TRAIN Batch 41/4600 loss 31.916927 loss_att 22.902664 loss_ctc 52.950211 loss_ctc_origin 40.582100 loss_ctc0 81.809143 lr 0.00129692 rank 0
2022-08-23 04:23:17,905 DEBUG TRAIN Batch 41/4700 loss 31.159733 loss_att 19.177650 loss_ctc 59.117928 loss_ctc_origin 51.696819 loss_ctc0 76.433846 lr 0.00129665 rank 0
2022-08-23 04:23:47,340 DEBUG TRAIN Batch 41/4800 loss 27.741058 loss_att 15.249810 loss_ctc 56.887306 loss_ctc_origin 44.459278 loss_ctc0 85.886032 lr 0.00129637 rank 0
2022-08-23 04:24:12,940 WARNING NaN or Inf found in input tensor.
2022-08-23 04:24:17,667 DEBUG TRAIN Batch 41/4900 loss 41.021225 loss_att 23.903425 loss_ctc 80.962753 loss_ctc_origin 68.832657 loss_ctc0 109.266312 lr 0.00129610 rank 0
2022-08-23 04:24:47,402 DEBUG TRAIN Batch 41/5000 loss 33.280079 loss_att 26.065281 loss_ctc 50.114609 loss_ctc_origin 43.730797 loss_ctc0 65.010178 lr 0.00129583 rank 0
2022-08-23 04:25:16,209 DEBUG TRAIN Batch 41/5100 loss 41.640919 loss_att 27.937157 loss_ctc 73.616364 loss_ctc_origin 52.391865 loss_ctc0 123.140198 lr 0.00129556 rank 0
2022-08-23 04:25:46,031 DEBUG TRAIN Batch 41/5200 loss 29.542950 loss_att 19.110386 loss_ctc 53.885597 loss_ctc_origin 45.590073 loss_ctc0 73.241829 lr 0.00129529 rank 0
2022-08-23 04:26:15,710 DEBUG TRAIN Batch 41/5300 loss 28.320704 loss_att 15.865465 loss_ctc 57.382927 loss_ctc_origin 47.969452 loss_ctc0 79.347702 lr 0.00129502 rank 0
2022-08-23 04:26:46,195 DEBUG TRAIN Batch 41/5400 loss 35.175838 loss_att 20.186737 loss_ctc 70.150406 loss_ctc_origin 55.514923 loss_ctc0 104.299850 lr 0.00129474 rank 0
2022-08-23 04:27:15,173 DEBUG TRAIN Batch 41/5500 loss 23.903734 loss_att 19.828434 loss_ctc 33.412766 loss_ctc_origin 30.695644 loss_ctc0 39.752716 lr 0.00129447 rank 0
2022-08-23 04:27:44,691 DEBUG TRAIN Batch 41/5600 loss 36.238373 loss_att 25.320539 loss_ctc 61.713318 loss_ctc_origin 46.544014 loss_ctc0 97.108353 lr 0.00129420 rank 0
2022-08-23 04:28:07,896 DEBUG CV Batch 41/0 loss 17.563881 loss_att 13.241168 loss_ctc 27.650213 loss_ctc_origin 20.312523 loss_ctc0 44.771488 history loss 16.530711 rank 0
2022-08-23 04:28:19,155 DEBUG CV Batch 41/100 loss 24.981340 loss_att 19.454342 loss_ctc 37.877670 loss_ctc_origin 28.496395 loss_ctc0 59.767311 history loss 31.942778 rank 0
2022-08-23 04:28:29,462 DEBUG CV Batch 41/200 loss 29.052330 loss_att 22.434399 loss_ctc 44.494171 loss_ctc_origin 34.781693 loss_ctc0 67.156616 history loss 33.298065 rank 0
2022-08-23 04:28:39,959 DEBUG CV Batch 41/300 loss 28.433617 loss_att 21.099194 loss_ctc 45.547268 loss_ctc_origin 31.138168 loss_ctc0 79.168503 history loss 32.257374 rank 0
2022-08-23 04:28:50,857 DEBUG CV Batch 41/400 loss 44.652077 loss_att 35.721939 loss_ctc 65.489052 loss_ctc_origin 49.090576 loss_ctc0 103.752151 history loss 30.569580 rank 0
2022-08-23 04:29:02,423 DEBUG CV Batch 41/500 loss 21.492460 loss_att 15.898460 loss_ctc 34.545124 loss_ctc_origin 26.517174 loss_ctc0 53.277004 history loss 30.194716 rank 0
2022-08-23 04:29:13,550 DEBUG CV Batch 41/600 loss 20.863266 loss_att 14.599803 loss_ctc 35.478012 loss_ctc_origin 25.594805 loss_ctc0 58.538834 history loss 30.050953 rank 0
2022-08-23 04:29:24,214 DEBUG CV Batch 41/700 loss 22.763905 loss_att 15.671606 loss_ctc 39.312603 loss_ctc_origin 26.594601 loss_ctc0 68.987938 history loss 29.677088 rank 0
2022-08-23 04:29:35,153 DEBUG CV Batch 41/800 loss 28.318108 loss_att 21.880192 loss_ctc 43.339909 loss_ctc_origin 29.393471 loss_ctc0 75.881592 history loss 29.636728 rank 0
2022-08-23 04:29:45,839 INFO Epoch 41 CV info cv_loss 29.7377753860496
2022-08-23 04:29:45,840 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/41.pt
2022-08-23 04:29:46,306 INFO Epoch 42 TRAIN info lr 0.0012939740194363866
2022-08-23 04:29:46,310 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 04:30:14,522 DEBUG TRAIN Batch 42/0 loss 31.953926 loss_att 26.247562 loss_ctc 45.268772 loss_ctc_origin 44.202293 loss_ctc0 47.757225 lr 0.00129396 rank 0
2022-08-23 04:30:44,603 DEBUG TRAIN Batch 42/100 loss 31.712769 loss_att 23.487131 loss_ctc 50.905914 loss_ctc_origin 41.041531 loss_ctc0 73.922813 lr 0.00129369 rank 0
2022-08-23 04:31:14,093 DEBUG TRAIN Batch 42/200 loss 24.246891 loss_att 15.145224 loss_ctc 45.484116 loss_ctc_origin 34.611725 loss_ctc0 70.853035 lr 0.00129342 rank 0
2022-08-23 04:31:43,582 DEBUG TRAIN Batch 42/300 loss 29.955276 loss_att 17.227676 loss_ctc 59.653015 loss_ctc_origin 49.049797 loss_ctc0 84.393860 lr 0.00129315 rank 0
2022-08-23 04:32:12,552 DEBUG TRAIN Batch 42/400 loss 33.325581 loss_att 18.584978 loss_ctc 67.720322 loss_ctc_origin 52.430534 loss_ctc0 103.396477 lr 0.00129288 rank 0
2022-08-23 04:32:42,273 DEBUG TRAIN Batch 42/500 loss 32.019253 loss_att 26.360762 loss_ctc 45.222397 loss_ctc_origin 38.630825 loss_ctc0 60.602734 lr 0.00129261 rank 0
2022-08-23 04:33:11,441 DEBUG TRAIN Batch 42/600 loss 38.309063 loss_att 24.678059 loss_ctc 70.114738 loss_ctc_origin 41.033237 loss_ctc0 137.971573 lr 0.00129234 rank 0
2022-08-23 04:33:39,980 DEBUG TRAIN Batch 42/700 loss 27.426201 loss_att 18.170179 loss_ctc 49.023579 loss_ctc_origin 40.639774 loss_ctc0 68.585785 lr 0.00129207 rank 0
2022-08-23 04:34:08,978 DEBUG TRAIN Batch 42/800 loss 30.206779 loss_att 17.526974 loss_ctc 59.792992 loss_ctc_origin 49.329350 loss_ctc0 84.208145 lr 0.00129180 rank 0
2022-08-23 04:34:38,165 DEBUG TRAIN Batch 42/900 loss 32.319363 loss_att 18.434170 loss_ctc 64.718147 loss_ctc_origin 49.814484 loss_ctc0 99.493370 lr 0.00129153 rank 0
2022-08-23 04:35:06,497 DEBUG TRAIN Batch 42/1000 loss 22.242167 loss_att 18.218479 loss_ctc 31.630768 loss_ctc_origin 27.759525 loss_ctc0 40.663666 lr 0.00129126 rank 0
2022-08-23 04:35:21,800 WARNING NaN or Inf found in input tensor.
2022-08-23 04:35:36,505 DEBUG TRAIN Batch 42/1100 loss 36.194489 loss_att 21.748600 loss_ctc 69.901566 loss_ctc_origin 42.226162 loss_ctc0 134.477509 lr 0.00129099 rank 0
2022-08-23 04:36:06,002 DEBUG TRAIN Batch 42/1200 loss 30.481712 loss_att 19.688326 loss_ctc 55.666279 loss_ctc_origin 47.221947 loss_ctc0 75.369720 lr 0.00129073 rank 0
2022-08-23 04:36:34,695 DEBUG TRAIN Batch 42/1300 loss 30.816223 loss_att 16.209751 loss_ctc 64.897987 loss_ctc_origin 53.696018 loss_ctc0 91.035919 lr 0.00129046 rank 0
2022-08-23 04:37:04,254 DEBUG TRAIN Batch 42/1400 loss 36.701759 loss_att 21.616852 loss_ctc 71.899872 loss_ctc_origin 56.348858 loss_ctc0 108.185577 lr 0.00129019 rank 0
2022-08-23 04:37:39,805 DEBUG TRAIN Batch 42/1500 loss 30.627470 loss_att 24.534081 loss_ctc 44.845375 loss_ctc_origin 40.634468 loss_ctc0 54.670815 lr 0.00128992 rank 0
2022-08-23 04:38:09,082 DEBUG TRAIN Batch 42/1600 loss 45.744370 loss_att 32.144707 loss_ctc 77.476906 loss_ctc_origin 57.591957 loss_ctc0 123.875114 lr 0.00128965 rank 0
2022-08-23 04:38:38,421 DEBUG TRAIN Batch 42/1700 loss 28.578194 loss_att 18.884697 loss_ctc 51.196350 loss_ctc_origin 41.969872 loss_ctc0 72.724792 lr 0.00128938 rank 0
2022-08-23 04:39:07,642 DEBUG TRAIN Batch 42/1800 loss 26.857334 loss_att 14.673736 loss_ctc 55.285728 loss_ctc_origin 42.486732 loss_ctc0 85.150055 lr 0.00128912 rank 0
2022-08-23 04:39:36,440 DEBUG TRAIN Batch 42/1900 loss 30.631035 loss_att 16.192057 loss_ctc 64.321983 loss_ctc_origin 48.134056 loss_ctc0 102.093811 lr 0.00128885 rank 0
2022-08-23 04:40:07,269 DEBUG TRAIN Batch 42/2000 loss 32.520145 loss_att 25.665508 loss_ctc 48.514297 loss_ctc_origin 44.649734 loss_ctc0 57.531601 lr 0.00128858 rank 0
2022-08-23 04:40:35,961 DEBUG TRAIN Batch 42/2100 loss 29.804316 loss_att 21.477472 loss_ctc 49.233616 loss_ctc_origin 39.827847 loss_ctc0 71.180412 lr 0.00128831 rank 0
2022-08-23 04:41:05,590 DEBUG TRAIN Batch 42/2200 loss 32.439644 loss_att 22.988058 loss_ctc 54.493347 loss_ctc_origin 47.048859 loss_ctc0 71.863815 lr 0.00128805 rank 0
2022-08-23 04:41:35,678 DEBUG TRAIN Batch 42/2300 loss 27.310711 loss_att 15.313282 loss_ctc 55.304710 loss_ctc_origin 43.546822 loss_ctc0 82.739777 lr 0.00128778 rank 0
2022-08-23 04:42:06,355 DEBUG TRAIN Batch 42/2400 loss 30.253279 loss_att 17.396360 loss_ctc 60.252754 loss_ctc_origin 44.454865 loss_ctc0 97.114487 lr 0.00128751 rank 0
2022-08-23 04:42:35,967 DEBUG TRAIN Batch 42/2500 loss 34.750446 loss_att 27.870564 loss_ctc 50.803505 loss_ctc_origin 42.219711 loss_ctc0 70.832352 lr 0.00128725 rank 0
2022-08-23 04:43:05,937 DEBUG TRAIN Batch 42/2600 loss 27.228113 loss_att 18.919704 loss_ctc 46.614399 loss_ctc_origin 37.054688 loss_ctc0 68.920395 lr 0.00128698 rank 0
2022-08-23 04:43:35,290 DEBUG TRAIN Batch 42/2700 loss 26.461716 loss_att 16.729422 loss_ctc 49.170403 loss_ctc_origin 39.859756 loss_ctc0 70.895248 lr 0.00128671 rank 0
2022-08-23 04:44:05,017 DEBUG TRAIN Batch 42/2800 loss 33.332314 loss_att 18.467451 loss_ctc 68.016991 loss_ctc_origin 56.081017 loss_ctc0 95.867599 lr 0.00128645 rank 0
2022-08-23 04:44:30,213 WARNING NaN or Inf found in input tensor.
2022-08-23 04:44:34,510 DEBUG TRAIN Batch 42/2900 loss 32.937309 loss_att 19.546982 loss_ctc 64.181404 loss_ctc_origin 50.096645 loss_ctc0 97.045853 lr 0.00128618 rank 0
2022-08-23 04:45:11,223 DEBUG TRAIN Batch 42/3000 loss 26.637737 loss_att 19.541185 loss_ctc 43.196354 loss_ctc_origin 40.737129 loss_ctc0 48.934547 lr 0.00128591 rank 0
2022-08-23 04:45:40,674 DEBUG TRAIN Batch 42/3100 loss 33.308113 loss_att 23.371918 loss_ctc 56.492569 loss_ctc_origin 47.090725 loss_ctc0 78.430199 lr 0.00128565 rank 0
2022-08-23 04:46:10,838 DEBUG TRAIN Batch 42/3200 loss 26.468456 loss_att 16.681526 loss_ctc 49.304626 loss_ctc_origin 40.413887 loss_ctc0 70.049690 lr 0.00128538 rank 0
2022-08-23 04:46:16,561 WARNING NaN or Inf found in input tensor.
2022-08-23 04:46:39,896 DEBUG TRAIN Batch 42/3300 loss 28.352730 loss_att 15.324542 loss_ctc 58.751831 loss_ctc_origin 44.632717 loss_ctc0 91.696434 lr 0.00128512 rank 0
2022-08-23 04:47:09,737 DEBUG TRAIN Batch 42/3400 loss 35.821606 loss_att 20.597464 loss_ctc 71.344604 loss_ctc_origin 55.046917 loss_ctc0 109.372551 lr 0.00128485 rank 0
2022-08-23 04:47:39,285 DEBUG TRAIN Batch 42/3500 loss 29.817537 loss_att 25.482773 loss_ctc 39.931988 loss_ctc_origin 37.490025 loss_ctc0 45.629898 lr 0.00128459 rank 0
2022-08-23 04:48:09,449 DEBUG TRAIN Batch 42/3600 loss 29.954750 loss_att 19.783066 loss_ctc 53.688675 loss_ctc_origin 46.799603 loss_ctc0 69.763184 lr 0.00128432 rank 0
2022-08-23 04:48:39,352 DEBUG TRAIN Batch 42/3700 loss 26.138630 loss_att 17.105179 loss_ctc 47.216682 loss_ctc_origin 37.629997 loss_ctc0 69.585617 lr 0.00128406 rank 0
2022-08-23 04:49:09,524 DEBUG TRAIN Batch 42/3800 loss 24.504517 loss_att 12.744656 loss_ctc 51.944187 loss_ctc_origin 39.379150 loss_ctc0 81.262604 lr 0.00128379 rank 0
2022-08-23 04:49:39,303 DEBUG TRAIN Batch 42/3900 loss 36.035130 loss_att 19.925259 loss_ctc 73.624832 loss_ctc_origin 59.611191 loss_ctc0 106.323318 lr 0.00128353 rank 0
2022-08-23 04:50:08,955 DEBUG TRAIN Batch 42/4000 loss 31.719048 loss_att 24.101269 loss_ctc 49.493866 loss_ctc_origin 39.396942 loss_ctc0 73.053345 lr 0.00128326 rank 0
2022-08-23 04:50:38,918 DEBUG TRAIN Batch 42/4100 loss 39.123989 loss_att 24.146917 loss_ctc 74.070488 loss_ctc_origin 49.422054 loss_ctc0 131.583496 lr 0.00128300 rank 0
2022-08-23 04:50:52,648 WARNING NaN or Inf found in input tensor.
2022-08-23 04:51:07,930 DEBUG TRAIN Batch 42/4200 loss 26.206497 loss_att 17.853508 loss_ctc 45.696800 loss_ctc_origin 36.129219 loss_ctc0 68.021164 lr 0.00128274 rank 0
2022-08-23 04:51:36,832 DEBUG TRAIN Batch 42/4300 loss 30.205605 loss_att 18.107700 loss_ctc 58.434048 loss_ctc_origin 46.337952 loss_ctc0 86.658272 lr 0.00128247 rank 0
2022-08-23 04:52:06,348 DEBUG TRAIN Batch 42/4400 loss 32.431732 loss_att 18.845901 loss_ctc 64.131996 loss_ctc_origin 49.860580 loss_ctc0 97.431961 lr 0.00128221 rank 0
2022-08-23 04:52:40,808 DEBUG TRAIN Batch 42/4500 loss 36.177261 loss_att 28.152706 loss_ctc 54.901222 loss_ctc_origin 45.807999 loss_ctc0 76.118744 lr 0.00128195 rank 0
2022-08-23 04:53:10,042 DEBUG TRAIN Batch 42/4600 loss 26.339258 loss_att 16.418074 loss_ctc 49.488689 loss_ctc_origin 34.509056 loss_ctc0 84.441162 lr 0.00128168 rank 0
2022-08-23 04:53:39,701 DEBUG TRAIN Batch 42/4700 loss 29.618057 loss_att 18.233456 loss_ctc 56.182121 loss_ctc_origin 47.031342 loss_ctc0 77.533936 lr 0.00128142 rank 0
2022-08-23 04:54:09,229 DEBUG TRAIN Batch 42/4800 loss 25.816059 loss_att 13.787428 loss_ctc 53.882866 loss_ctc_origin 41.894215 loss_ctc0 81.856384 lr 0.00128116 rank 0
2022-08-23 04:54:39,786 DEBUG TRAIN Batch 42/4900 loss 36.944111 loss_att 22.223898 loss_ctc 71.291275 loss_ctc_origin 57.546276 loss_ctc0 103.362946 lr 0.00128089 rank 0
2022-08-23 04:55:09,718 DEBUG TRAIN Batch 42/5000 loss 37.411911 loss_att 29.744816 loss_ctc 55.301788 loss_ctc_origin 51.611015 loss_ctc0 63.913605 lr 0.00128063 rank 0
2022-08-23 04:55:38,730 DEBUG TRAIN Batch 42/5100 loss 28.524597 loss_att 18.238667 loss_ctc 52.525101 loss_ctc_origin 36.235329 loss_ctc0 90.534561 lr 0.00128037 rank 0
2022-08-23 04:56:07,376 DEBUG TRAIN Batch 42/5200 loss 26.071775 loss_att 15.447365 loss_ctc 50.862064 loss_ctc_origin 40.870667 loss_ctc0 74.175323 lr 0.00128011 rank 0
2022-08-23 04:56:36,617 DEBUG TRAIN Batch 42/5300 loss 28.005384 loss_att 15.929489 loss_ctc 56.182468 loss_ctc_origin 43.104797 loss_ctc0 86.697037 lr 0.00127984 rank 0
2022-08-23 04:57:05,733 DEBUG TRAIN Batch 42/5400 loss 39.158302 loss_att 23.826488 loss_ctc 74.932541 loss_ctc_origin 62.432106 loss_ctc0 104.100220 lr 0.00127958 rank 0
2022-08-23 04:57:35,666 DEBUG TRAIN Batch 42/5500 loss 24.180447 loss_att 18.969086 loss_ctc 36.340290 loss_ctc_origin 34.554924 loss_ctc0 40.506149 lr 0.00127932 rank 0
2022-08-23 04:58:05,573 DEBUG TRAIN Batch 42/5600 loss 33.951550 loss_att 23.004829 loss_ctc 59.493896 loss_ctc_origin 49.517723 loss_ctc0 82.771637 lr 0.00127906 rank 0
2022-08-23 04:58:29,789 DEBUG CV Batch 42/0 loss 21.635384 loss_att 13.577700 loss_ctc 40.436642 loss_ctc_origin 24.139019 loss_ctc0 78.464432 history loss 20.362714 rank 0
2022-08-23 04:58:41,012 DEBUG CV Batch 42/100 loss 29.893255 loss_att 20.202354 loss_ctc 52.505356 loss_ctc_origin 29.496677 loss_ctc0 106.192261 history loss 33.268576 rank 0
2022-08-23 04:58:51,186 DEBUG CV Batch 42/200 loss 32.324966 loss_att 23.723736 loss_ctc 52.394508 loss_ctc_origin 38.336483 loss_ctc0 85.196571 history loss 34.532161 rank 0
2022-08-23 04:59:02,087 DEBUG CV Batch 42/300 loss 28.651348 loss_att 21.220596 loss_ctc 45.989769 loss_ctc_origin 32.031944 loss_ctc0 78.558029 history loss 33.520980 rank 0
2022-08-23 04:59:13,086 DEBUG CV Batch 42/400 loss 42.961597 loss_att 34.053528 loss_ctc 63.747089 loss_ctc_origin 47.807011 loss_ctc0 100.940598 history loss 31.712727 rank 0
2022-08-23 04:59:24,703 DEBUG CV Batch 42/500 loss 23.852173 loss_att 16.157379 loss_ctc 41.806686 loss_ctc_origin 27.626574 loss_ctc0 74.893616 history loss 31.299930 rank 0
2022-08-23 04:59:35,922 DEBUG CV Batch 42/600 loss 25.285004 loss_att 15.142866 loss_ctc 48.949986 loss_ctc_origin 26.028404 loss_ctc0 102.433670 history loss 31.201097 rank 0
2022-08-23 04:59:46,471 DEBUG CV Batch 42/700 loss 21.979042 loss_att 15.264099 loss_ctc 37.647247 loss_ctc_origin 24.447525 loss_ctc0 68.446587 history loss 30.807866 rank 0
2022-08-23 04:59:57,673 DEBUG CV Batch 42/800 loss 26.591803 loss_att 19.667164 loss_ctc 42.749290 loss_ctc_origin 28.718821 loss_ctc0 75.487053 history loss 30.761261 rank 0
2022-08-23 05:00:08,400 INFO Epoch 42 CV info cv_loss 30.765624946748137
2022-08-23 05:00:08,400 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/42.pt
2022-08-23 05:00:08,892 INFO Epoch 43 TRAIN info lr 0.0012788392997304422
2022-08-23 05:00:08,896 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 05:00:36,694 DEBUG TRAIN Batch 43/0 loss 22.997021 loss_att 16.774889 loss_ctc 37.515327 loss_ctc_origin 29.233583 loss_ctc0 56.839394 lr 0.00127883 rank 0
2022-08-23 05:01:05,832 DEBUG TRAIN Batch 43/100 loss 32.297260 loss_att 22.921644 loss_ctc 54.173698 loss_ctc_origin 42.607559 loss_ctc0 81.161346 lr 0.00127857 rank 0
2022-08-23 05:01:34,491 DEBUG TRAIN Batch 43/200 loss 29.596722 loss_att 19.601967 loss_ctc 52.917820 loss_ctc_origin 44.160263 loss_ctc0 73.352119 lr 0.00127831 rank 0
2022-08-23 05:02:03,583 DEBUG TRAIN Batch 43/300 loss 28.275261 loss_att 16.068428 loss_ctc 56.757874 loss_ctc_origin 44.223991 loss_ctc0 86.003601 lr 0.00127805 rank 0
2022-08-23 05:02:32,090 DEBUG TRAIN Batch 43/400 loss 35.011841 loss_att 19.843672 loss_ctc 70.404228 loss_ctc_origin 56.643097 loss_ctc0 102.513535 lr 0.00127778 rank 0
2022-08-23 05:03:01,966 DEBUG TRAIN Batch 43/500 loss 33.358551 loss_att 27.129543 loss_ctc 47.892895 loss_ctc_origin 46.560875 loss_ctc0 51.000938 lr 0.00127752 rank 0
2022-08-23 05:03:30,520 WARNING NaN or Inf found in input tensor.
2022-08-23 05:03:31,337 DEBUG TRAIN Batch 43/600 loss 38.807701 loss_att 22.824326 loss_ctc 76.102242 loss_ctc_origin 44.460194 loss_ctc0 149.933685 lr 0.00127726 rank 0
2022-08-23 05:04:00,180 DEBUG TRAIN Batch 43/700 loss 27.804424 loss_att 17.382643 loss_ctc 52.121914 loss_ctc_origin 41.183224 loss_ctc0 77.645523 lr 0.00127700 rank 0
2022-08-23 05:04:05,484 WARNING NaN or Inf found in input tensor.
2022-08-23 05:04:29,805 DEBUG TRAIN Batch 43/800 loss 29.855879 loss_att 16.433735 loss_ctc 61.174210 loss_ctc_origin 50.197716 loss_ctc0 86.786034 lr 0.00127674 rank 0
2022-08-23 05:04:59,151 DEBUG TRAIN Batch 43/900 loss 32.234421 loss_att 17.735626 loss_ctc 66.064934 loss_ctc_origin 49.551460 loss_ctc0 104.596382 lr 0.00127648 rank 0
2022-08-23 05:05:27,921 DEBUG TRAIN Batch 43/1000 loss 29.813396 loss_att 23.094130 loss_ctc 45.491692 loss_ctc_origin 38.591339 loss_ctc0 61.592518 lr 0.00127622 rank 0
2022-08-23 05:05:56,281 DEBUG TRAIN Batch 43/1100 loss 40.221214 loss_att 28.023178 loss_ctc 68.683289 loss_ctc_origin 48.802204 loss_ctc0 115.072502 lr 0.00127596 rank 0
2022-08-23 05:06:24,620 DEBUG TRAIN Batch 43/1200 loss 31.772274 loss_att 21.469955 loss_ctc 55.811012 loss_ctc_origin 47.759941 loss_ctc0 74.596855 lr 0.00127570 rank 0
2022-08-23 05:06:54,690 DEBUG TRAIN Batch 43/1300 loss 24.326290 loss_att 12.264503 loss_ctc 52.470459 loss_ctc_origin 39.330734 loss_ctc0 83.129814 lr 0.00127544 rank 0
2022-08-23 05:07:18,566 WARNING NaN or Inf found in input tensor.
2022-08-23 05:07:22,906 DEBUG TRAIN Batch 43/1400 loss 32.160851 loss_att 19.469383 loss_ctc 61.774269 loss_ctc_origin 47.207397 loss_ctc0 95.763641 lr 0.00127518 rank 0
2022-08-23 05:07:57,464 DEBUG TRAIN Batch 43/1500 loss 22.745125 loss_att 17.729452 loss_ctc 34.448360 loss_ctc_origin 31.201704 loss_ctc0 42.023895 lr 0.00127493 rank 0
2022-08-23 05:08:26,734 DEBUG TRAIN Batch 43/1600 loss 40.702240 loss_att 27.376476 loss_ctc 71.795685 loss_ctc_origin 47.667641 loss_ctc0 128.094437 lr 0.00127467 rank 0
2022-08-23 05:08:55,362 DEBUG TRAIN Batch 43/1700 loss 25.533703 loss_att 17.198101 loss_ctc 44.983437 loss_ctc_origin 36.673244 loss_ctc0 64.373894 lr 0.00127441 rank 0
2022-08-23 05:09:24,916 DEBUG TRAIN Batch 43/1800 loss 30.299328 loss_att 17.019787 loss_ctc 61.284920 loss_ctc_origin 50.909660 loss_ctc0 85.493851 lr 0.00127415 rank 0
2022-08-23 05:09:49,877 WARNING NaN or Inf found in input tensor.
2022-08-23 05:09:54,562 DEBUG TRAIN Batch 43/1900 loss 30.924622 loss_att 18.542030 loss_ctc 59.817329 loss_ctc_origin 47.152958 loss_ctc0 89.367538 lr 0.00127389 rank 0
2022-08-23 05:10:23,775 DEBUG TRAIN Batch 43/2000 loss 27.685232 loss_att 22.785355 loss_ctc 39.118279 loss_ctc_origin 34.107746 loss_ctc0 50.809525 lr 0.00127363 rank 0
2022-08-23 05:10:53,193 DEBUG TRAIN Batch 43/2100 loss 42.373962 loss_att 28.353371 loss_ctc 75.088669 loss_ctc_origin 48.791016 loss_ctc0 136.449860 lr 0.00127337 rank 0
2022-08-23 05:11:22,034 WARNING NaN or Inf found in input tensor.
2022-08-23 05:11:23,757 DEBUG TRAIN Batch 43/2200 loss 28.173702 loss_att 16.924583 loss_ctc 54.421646 loss_ctc_origin 42.428211 loss_ctc0 82.406326 lr 0.00127312 rank 0
2022-08-23 05:11:53,455 DEBUG TRAIN Batch 43/2300 loss 26.906239 loss_att 14.808991 loss_ctc 55.133148 loss_ctc_origin 43.896851 loss_ctc0 81.351166 lr 0.00127286 rank 0
2022-08-23 05:12:22,614 DEBUG TRAIN Batch 43/2400 loss 34.954224 loss_att 20.450001 loss_ctc 68.797409 loss_ctc_origin 56.321831 loss_ctc0 97.907089 lr 0.00127260 rank 0
2022-08-23 05:12:52,501 DEBUG TRAIN Batch 43/2500 loss 28.872543 loss_att 22.530848 loss_ctc 43.669830 loss_ctc_origin 39.164642 loss_ctc0 54.181931 lr 0.00127234 rank 0
2022-08-23 05:13:21,483 DEBUG TRAIN Batch 43/2600 loss 36.734169 loss_att 24.713497 loss_ctc 64.782410 loss_ctc_origin 47.335163 loss_ctc0 105.492645 lr 0.00127209 rank 0
2022-08-23 05:13:51,866 DEBUG TRAIN Batch 43/2700 loss 26.778225 loss_att 16.277016 loss_ctc 51.281044 loss_ctc_origin 42.679485 loss_ctc0 71.351349 lr 0.00127183 rank 0
2022-08-23 05:14:20,972 DEBUG TRAIN Batch 43/2800 loss 28.429272 loss_att 15.528272 loss_ctc 58.531609 loss_ctc_origin 46.836548 loss_ctc0 85.820076 lr 0.00127157 rank 0
2022-08-23 05:14:48,623 DEBUG TRAIN Batch 43/2900 loss 32.518204 loss_att 18.887257 loss_ctc 64.323738 loss_ctc_origin 49.510815 loss_ctc0 98.887222 lr 0.00127131 rank 0
2022-08-23 05:15:25,160 DEBUG TRAIN Batch 43/3000 loss 31.651463 loss_att 26.132318 loss_ctc 44.529465 loss_ctc_origin 41.551617 loss_ctc0 51.477776 lr 0.00127106 rank 0
2022-08-23 05:15:40,626 WARNING NaN or Inf found in input tensor.
2022-08-23 05:15:53,713 DEBUG TRAIN Batch 43/3100 loss 54.837875 loss_att 38.572311 loss_ctc 92.790863 loss_ctc_origin 59.875908 loss_ctc0 169.592407 lr 0.00127080 rank 0
2022-08-23 05:16:22,858 DEBUG TRAIN Batch 43/3200 loss 29.638954 loss_att 19.999695 loss_ctc 52.130554 loss_ctc_origin 44.064693 loss_ctc0 70.950897 lr 0.00127054 rank 0
2022-08-23 05:16:52,182 DEBUG TRAIN Batch 43/3300 loss 29.514946 loss_att 17.601944 loss_ctc 57.311951 loss_ctc_origin 47.011436 loss_ctc0 81.346489 lr 0.00127029 rank 0
2022-08-23 05:17:20,906 DEBUG TRAIN Batch 43/3400 loss 31.128567 loss_att 17.130707 loss_ctc 63.790234 loss_ctc_origin 49.263908 loss_ctc0 97.684998 lr 0.00127003 rank 0
2022-08-23 05:17:49,876 DEBUG TRAIN Batch 43/3500 loss 34.803917 loss_att 26.410858 loss_ctc 54.387711 loss_ctc_origin 43.413933 loss_ctc0 79.993179 lr 0.00126978 rank 0
2022-08-23 05:18:18,628 DEBUG TRAIN Batch 43/3600 loss 46.871529 loss_att 32.688351 loss_ctc 79.965599 loss_ctc_origin 55.351570 loss_ctc0 137.398331 lr 0.00126952 rank 0
2022-08-23 05:18:47,950 DEBUG TRAIN Batch 43/3700 loss 25.855932 loss_att 15.529774 loss_ctc 49.950302 loss_ctc_origin 40.734123 loss_ctc0 71.454712 lr 0.00126926 rank 0
2022-08-23 05:19:12,740 WARNING NaN or Inf found in input tensor.
2022-08-23 05:19:16,116 DEBUG TRAIN Batch 43/3800 loss 28.499849 loss_att 15.361538 loss_ctc 59.155907 loss_ctc_origin 48.804424 loss_ctc0 83.309357 lr 0.00126901 rank 0
2022-08-23 05:19:45,762 DEBUG TRAIN Batch 43/3900 loss 29.159094 loss_att 15.445042 loss_ctc 61.158546 loss_ctc_origin 46.968834 loss_ctc0 94.267883 lr 0.00126875 rank 0
2022-08-23 05:20:14,504 DEBUG TRAIN Batch 43/4000 loss 31.126028 loss_att 23.690434 loss_ctc 48.475746 loss_ctc_origin 45.178844 loss_ctc0 56.168518 lr 0.00126850 rank 0
2022-08-23 05:20:43,581 DEBUG TRAIN Batch 43/4100 loss 27.926712 loss_att 18.744024 loss_ctc 49.352982 loss_ctc_origin 38.893509 loss_ctc0 73.758423 lr 0.00126824 rank 0
2022-08-23 05:21:12,798 DEBUG TRAIN Batch 43/4200 loss 27.172585 loss_att 17.801872 loss_ctc 49.037582 loss_ctc_origin 41.047729 loss_ctc0 67.680573 lr 0.00126799 rank 0
2022-08-23 05:21:42,911 DEBUG TRAIN Batch 43/4300 loss 32.224480 loss_att 18.953043 loss_ctc 63.191162 loss_ctc_origin 52.404549 loss_ctc0 88.359940 lr 0.00126773 rank 0
2022-08-23 05:22:13,289 DEBUG TRAIN Batch 43/4400 loss 33.400654 loss_att 18.237701 loss_ctc 68.780876 loss_ctc_origin 54.581139 loss_ctc0 101.913605 lr 0.00126748 rank 0
2022-08-23 05:22:49,485 DEBUG TRAIN Batch 43/4500 loss 30.734276 loss_att 24.334890 loss_ctc 45.666172 loss_ctc_origin 39.583824 loss_ctc0 59.858315 lr 0.00126722 rank 0
2022-08-23 05:22:57,756 WARNING NaN or Inf found in input tensor.
2022-08-23 05:23:18,644 DEBUG TRAIN Batch 43/4600 loss 32.049530 loss_att 22.312647 loss_ctc 54.768921 loss_ctc_origin 39.873253 loss_ctc0 89.525482 lr 0.00126697 rank 0
2022-08-23 05:23:47,963 DEBUG TRAIN Batch 43/4700 loss 27.706884 loss_att 17.665947 loss_ctc 51.135738 loss_ctc_origin 42.970901 loss_ctc0 70.187027 lr 0.00126672 rank 0
2022-08-23 05:24:17,128 DEBUG TRAIN Batch 43/4800 loss 30.345535 loss_att 18.312870 loss_ctc 58.421753 loss_ctc_origin 48.305122 loss_ctc0 82.027229 lr 0.00126646 rank 0
2022-08-23 05:24:46,059 DEBUG TRAIN Batch 43/4900 loss 34.481773 loss_att 19.873415 loss_ctc 68.567947 loss_ctc_origin 54.950226 loss_ctc0 100.342628 lr 0.00126621 rank 0
2022-08-23 05:25:16,432 DEBUG TRAIN Batch 43/5000 loss 30.330677 loss_att 25.469120 loss_ctc 41.674309 loss_ctc_origin 39.456394 loss_ctc0 46.849442 lr 0.00126595 rank 0
2022-08-23 05:25:46,464 DEBUG TRAIN Batch 43/5100 loss 29.851685 loss_att 18.657387 loss_ctc 55.971710 loss_ctc_origin 37.301525 loss_ctc0 99.535469 lr 0.00126570 rank 0
2022-08-23 05:26:14,683 WARNING NaN or Inf found in input tensor.
2022-08-23 05:26:16,326 DEBUG TRAIN Batch 43/5200 loss 28.213688 loss_att 19.177572 loss_ctc 49.297958 loss_ctc_origin 40.292488 loss_ctc0 70.310715 lr 0.00126545 rank 0
2022-08-23 05:26:44,793 DEBUG TRAIN Batch 43/5300 loss 29.144524 loss_att 16.331860 loss_ctc 59.040737 loss_ctc_origin 47.908188 loss_ctc0 85.016678 lr 0.00126519 rank 0
2022-08-23 05:27:14,912 DEBUG TRAIN Batch 43/5400 loss 30.420673 loss_att 16.981091 loss_ctc 61.779694 loss_ctc_origin 45.325916 loss_ctc0 100.171829 lr 0.00126494 rank 0
2022-08-23 05:27:44,457 DEBUG TRAIN Batch 43/5500 loss 32.641697 loss_att 24.951138 loss_ctc 50.586334 loss_ctc_origin 44.250156 loss_ctc0 65.370750 lr 0.00126469 rank 0
2022-08-23 05:27:58,981 WARNING NaN or Inf found in input tensor.
2022-08-23 05:28:13,017 DEBUG TRAIN Batch 43/5600 loss 32.305687 loss_att 21.753113 loss_ctc 56.928360 loss_ctc_origin 40.251019 loss_ctc0 95.842148 lr 0.00126444 rank 0
2022-08-23 05:28:36,757 DEBUG CV Batch 43/0 loss 18.612503 loss_att 13.043253 loss_ctc 31.607418 loss_ctc_origin 23.687172 loss_ctc0 50.087986 history loss 17.517650 rank 0
2022-08-23 05:28:47,677 DEBUG CV Batch 43/100 loss 28.059338 loss_att 18.603460 loss_ctc 50.123047 loss_ctc_origin 30.544876 loss_ctc0 95.805435 history loss 32.848595 rank 0
2022-08-23 05:28:58,116 DEBUG CV Batch 43/200 loss 30.838955 loss_att 22.595110 loss_ctc 50.074593 loss_ctc_origin 36.708313 loss_ctc0 81.262581 history loss 33.655850 rank 0
2022-08-23 05:29:08,502 DEBUG CV Batch 43/300 loss 28.678692 loss_att 21.286983 loss_ctc 45.926014 loss_ctc_origin 32.750416 loss_ctc0 76.669075 history loss 32.836579 rank 0
2022-08-23 05:29:19,475 DEBUG CV Batch 43/400 loss 43.617924 loss_att 34.387001 loss_ctc 65.156746 loss_ctc_origin 49.846313 loss_ctc0 100.881096 history loss 31.097687 rank 0
2022-08-23 05:29:30,638 DEBUG CV Batch 43/500 loss 21.599209 loss_att 15.511503 loss_ctc 35.803856 loss_ctc_origin 27.237024 loss_ctc0 55.793129 history loss 30.669373 rank 0
2022-08-23 05:29:41,536 DEBUG CV Batch 43/600 loss 23.529289 loss_att 14.179714 loss_ctc 45.344967 loss_ctc_origin 26.826069 loss_ctc0 88.555725 history loss 30.562767 rank 0
2022-08-23 05:29:51,898 DEBUG CV Batch 43/700 loss 22.733669 loss_att 15.471590 loss_ctc 39.678520 loss_ctc_origin 27.406322 loss_ctc0 68.313644 history loss 30.191091 rank 0
2022-08-23 05:30:02,912 DEBUG CV Batch 43/800 loss 26.309864 loss_att 19.396950 loss_ctc 42.439995 loss_ctc_origin 28.460293 loss_ctc0 75.059296 history loss 30.152703 rank 0
2022-08-23 05:30:13,424 INFO Epoch 43 CV info cv_loss 30.234496800858068
2022-08-23 05:30:13,424 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/43.pt
2022-08-23 05:30:13,879 INFO Epoch 44 TRAIN info lr 0.0012642235134389718
2022-08-23 05:30:13,882 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 05:30:41,137 DEBUG TRAIN Batch 44/0 loss 32.982567 loss_att 25.634361 loss_ctc 50.128380 loss_ctc_origin 44.286186 loss_ctc0 63.760166 lr 0.00126421 rank 0
2022-08-23 05:31:10,132 DEBUG TRAIN Batch 44/100 loss 30.758045 loss_att 22.090397 loss_ctc 50.982559 loss_ctc_origin 39.861473 loss_ctc0 76.931763 lr 0.00126396 rank 0
2022-08-23 05:31:39,617 DEBUG TRAIN Batch 44/200 loss 24.268471 loss_att 15.528963 loss_ctc 44.660652 loss_ctc_origin 37.492920 loss_ctc0 61.385368 lr 0.00126371 rank 0
2022-08-23 05:31:45,221 WARNING NaN or Inf found in input tensor.
2022-08-23 05:32:07,861 DEBUG TRAIN Batch 44/300 loss 27.368111 loss_att 15.037522 loss_ctc 56.139481 loss_ctc_origin 45.206543 loss_ctc0 81.649673 lr 0.00126346 rank 0
2022-08-23 05:32:36,803 DEBUG TRAIN Batch 44/400 loss 33.014214 loss_att 18.377552 loss_ctc 67.166428 loss_ctc_origin 53.037868 loss_ctc0 100.133064 lr 0.00126320 rank 0
2022-08-23 05:33:05,635 DEBUG TRAIN Batch 44/500 loss 26.050776 loss_att 21.111147 loss_ctc 37.576576 loss_ctc_origin 28.568153 loss_ctc0 58.596230 lr 0.00126295 rank 0
2022-08-23 05:33:35,135 DEBUG TRAIN Batch 44/600 loss 39.523026 loss_att 27.042679 loss_ctc 68.643837 loss_ctc_origin 52.623528 loss_ctc0 106.024567 lr 0.00126270 rank 0
2022-08-23 05:34:04,639 DEBUG TRAIN Batch 44/700 loss 29.705833 loss_att 21.261032 loss_ctc 49.410370 loss_ctc_origin 42.128395 loss_ctc0 66.401649 lr 0.00126245 rank 0
2022-08-23 05:34:34,088 DEBUG TRAIN Batch 44/800 loss 28.234814 loss_att 15.885778 loss_ctc 57.049225 loss_ctc_origin 44.560871 loss_ctc0 86.188705 lr 0.00126220 rank 0
2022-08-23 05:35:04,236 DEBUG TRAIN Batch 44/900 loss 34.408722 loss_att 19.511236 loss_ctc 69.169510 loss_ctc_origin 55.049633 loss_ctc0 102.115875 lr 0.00126195 rank 0
2022-08-23 05:35:33,854 DEBUG TRAIN Batch 44/1000 loss 26.133444 loss_att 21.174723 loss_ctc 37.703793 loss_ctc_origin 35.038311 loss_ctc0 43.923252 lr 0.00126170 rank 0
2022-08-23 05:35:47,742 WARNING NaN or Inf found in input tensor.
2022-08-23 05:36:01,609 DEBUG TRAIN Batch 44/1100 loss 36.488670 loss_att 25.059546 loss_ctc 63.156620 loss_ctc_origin 46.917313 loss_ctc0 101.048340 lr 0.00126144 rank 0
2022-08-23 05:36:23,159 WARNING NaN or Inf found in input tensor.
2022-08-23 05:36:32,032 DEBUG TRAIN Batch 44/1200 loss 27.978001 loss_att 17.605646 loss_ctc 52.180161 loss_ctc_origin 42.492168 loss_ctc0 74.785477 lr 0.00126119 rank 0
2022-08-23 05:37:02,482 DEBUG TRAIN Batch 44/1300 loss 30.686468 loss_att 16.830673 loss_ctc 63.016655 loss_ctc_origin 52.762028 loss_ctc0 86.944122 lr 0.00126094 rank 0
2022-08-23 05:37:19,977 WARNING NaN or Inf found in input tensor.
2022-08-23 05:37:31,407 DEBUG TRAIN Batch 44/1400 loss 34.743782 loss_att 19.432297 loss_ctc 70.470573 loss_ctc_origin 56.901566 loss_ctc0 102.131592 lr 0.00126069 rank 0
2022-08-23 05:38:09,117 DEBUG TRAIN Batch 44/1500 loss 27.467751 loss_att 21.956923 loss_ctc 40.326351 loss_ctc_origin 39.011745 loss_ctc0 43.393761 lr 0.00126044 rank 0
2022-08-23 05:38:38,141 DEBUG TRAIN Batch 44/1600 loss 34.724113 loss_att 23.027945 loss_ctc 62.015182 loss_ctc_origin 45.333908 loss_ctc0 100.938148 lr 0.00126019 rank 0
2022-08-23 05:39:07,396 DEBUG TRAIN Batch 44/1700 loss 30.255398 loss_att 20.488476 loss_ctc 53.044884 loss_ctc_origin 45.021854 loss_ctc0 71.765282 lr 0.00125994 rank 0
2022-08-23 05:39:37,447 DEBUG TRAIN Batch 44/1800 loss 30.978958 loss_att 17.561760 loss_ctc 62.285751 loss_ctc_origin 50.398758 loss_ctc0 90.022079 lr 0.00125969 rank 0
2022-08-23 05:40:06,390 DEBUG TRAIN Batch 44/1900 loss 31.224873 loss_att 17.948967 loss_ctc 62.201988 loss_ctc_origin 48.790310 loss_ctc0 93.495895 lr 0.00125944 rank 0
2022-08-23 05:40:28,624 WARNING NaN or Inf found in input tensor.
2022-08-23 05:40:36,251 DEBUG TRAIN Batch 44/2000 loss 30.964199 loss_att 24.891548 loss_ctc 45.133720 loss_ctc_origin 44.726730 loss_ctc0 46.083366 lr 0.00125919 rank 0
2022-08-23 05:41:04,994 DEBUG TRAIN Batch 44/2100 loss 34.790295 loss_att 22.036840 loss_ctc 64.548347 loss_ctc_origin 43.687408 loss_ctc0 113.223877 lr 0.00125894 rank 0
2022-08-23 05:41:33,797 DEBUG TRAIN Batch 44/2200 loss 34.728451 loss_att 25.154593 loss_ctc 57.067451 loss_ctc_origin 49.191025 loss_ctc0 75.445786 lr 0.00125869 rank 0
2022-08-23 05:42:04,559 DEBUG TRAIN Batch 44/2300 loss 21.905773 loss_att 10.902214 loss_ctc 47.580738 loss_ctc_origin 34.264641 loss_ctc0 78.651627 lr 0.00125844 rank 0
2022-08-23 05:42:30,410 WARNING NaN or Inf found in input tensor.
2022-08-23 05:42:35,064 DEBUG TRAIN Batch 44/2400 loss 36.171654 loss_att 21.663406 loss_ctc 70.024231 loss_ctc_origin 55.150871 loss_ctc0 104.728745 lr 0.00125820 rank 0
2022-08-23 05:43:04,829 DEBUG TRAIN Batch 44/2500 loss 23.192188 loss_att 17.712482 loss_ctc 35.978165 loss_ctc_origin 31.282949 loss_ctc0 46.933674 lr 0.00125795 rank 0
2022-08-23 05:43:33,946 DEBUG TRAIN Batch 44/2600 loss 29.609911 loss_att 19.710497 loss_ctc 52.708542 loss_ctc_origin 40.119511 loss_ctc0 82.082954 lr 0.00125770 rank 0
2022-08-23 05:44:01,838 DEBUG TRAIN Batch 44/2700 loss 29.447308 loss_att 18.830307 loss_ctc 54.220310 loss_ctc_origin 45.262383 loss_ctc0 75.122139 lr 0.00125745 rank 0
2022-08-23 05:44:32,832 DEBUG TRAIN Batch 44/2800 loss 35.349461 loss_att 20.628506 loss_ctc 69.698357 loss_ctc_origin 57.204414 loss_ctc0 98.850891 lr 0.00125720 rank 0
2022-08-23 05:45:03,524 DEBUG TRAIN Batch 44/2900 loss 33.802490 loss_att 19.808475 loss_ctc 66.455185 loss_ctc_origin 50.184105 loss_ctc0 104.421051 lr 0.00125695 rank 0
2022-08-23 05:45:39,253 DEBUG TRAIN Batch 44/3000 loss 28.225153 loss_att 21.991669 loss_ctc 42.769947 loss_ctc_origin 36.308086 loss_ctc0 57.847618 lr 0.00125670 rank 0
2022-08-23 05:46:07,953 DEBUG TRAIN Batch 44/3100 loss 35.625565 loss_att 21.377876 loss_ctc 68.870171 loss_ctc_origin 42.931061 loss_ctc0 129.394760 lr 0.00125646 rank 0
2022-08-23 05:46:37,125 DEBUG TRAIN Batch 44/3200 loss 26.729338 loss_att 17.426300 loss_ctc 48.436424 loss_ctc_origin 37.945168 loss_ctc0 72.916023 lr 0.00125621 rank 0
2022-08-23 05:47:06,556 DEBUG TRAIN Batch 44/3300 loss 34.313026 loss_att 19.261225 loss_ctc 69.433891 loss_ctc_origin 57.164356 loss_ctc0 98.062805 lr 0.00125596 rank 0
2022-08-23 05:47:35,957 DEBUG TRAIN Batch 44/3400 loss 37.911217 loss_att 21.588280 loss_ctc 75.998070 loss_ctc_origin 63.476364 loss_ctc0 105.215378 lr 0.00125571 rank 0
2022-08-23 05:48:07,033 DEBUG TRAIN Batch 44/3500 loss 25.552269 loss_att 20.554546 loss_ctc 37.213615 loss_ctc_origin 34.456898 loss_ctc0 43.645966 lr 0.00125547 rank 0
2022-08-23 05:48:36,657 DEBUG TRAIN Batch 44/3600 loss 35.980927 loss_att 23.552462 loss_ctc 64.980682 loss_ctc_origin 47.074715 loss_ctc0 106.761261 lr 0.00125522 rank 0
2022-08-23 05:49:05,942 DEBUG TRAIN Batch 44/3700 loss 33.889668 loss_att 22.145901 loss_ctc 61.291786 loss_ctc_origin 55.040970 loss_ctc0 75.877029 lr 0.00125497 rank 0
2022-08-23 05:49:33,792 DEBUG TRAIN Batch 44/3800 loss 27.949650 loss_att 15.584118 loss_ctc 56.802559 loss_ctc_origin 44.482986 loss_ctc0 85.548225 lr 0.00125472 rank 0
2022-08-23 05:49:52,380 WARNING NaN or Inf found in input tensor.
2022-08-23 05:50:04,132 DEBUG TRAIN Batch 44/3900 loss 36.298401 loss_att 19.199314 loss_ctc 76.196259 loss_ctc_origin 59.348343 loss_ctc0 115.508072 lr 0.00125448 rank 0
2022-08-23 05:50:33,428 DEBUG TRAIN Batch 44/4000 loss 29.004070 loss_att 23.084198 loss_ctc 42.817104 loss_ctc_origin 41.380829 loss_ctc0 46.168419 lr 0.00125423 rank 0
2022-08-23 05:51:02,437 DEBUG TRAIN Batch 44/4100 loss 37.487370 loss_att 24.253326 loss_ctc 68.366806 loss_ctc_origin 49.057377 loss_ctc0 113.422134 lr 0.00125398 rank 0
2022-08-23 05:51:30,580 WARNING NaN or Inf found in input tensor.
2022-08-23 05:51:32,162 DEBUG TRAIN Batch 44/4200 loss 28.197948 loss_att 17.934830 loss_ctc 52.145229 loss_ctc_origin 43.299797 loss_ctc0 72.784569 lr 0.00125374 rank 0
2022-08-23 05:52:01,807 DEBUG TRAIN Batch 44/4300 loss 30.390095 loss_att 17.138159 loss_ctc 61.311272 loss_ctc_origin 49.533218 loss_ctc0 88.793404 lr 0.00125349 rank 0
2022-08-23 05:52:19,448 WARNING NaN or Inf found in input tensor.
2022-08-23 05:52:26,475 WARNING NaN or Inf found in input tensor.
2022-08-23 05:52:30,956 DEBUG TRAIN Batch 44/4400 loss 32.314766 loss_att 17.936724 loss_ctc 65.863533 loss_ctc_origin 51.843277 loss_ctc0 98.577461 lr 0.00125325 rank 0
2022-08-23 05:53:07,291 DEBUG TRAIN Batch 44/4500 loss 35.117111 loss_att 28.196314 loss_ctc 51.265633 loss_ctc_origin 52.487396 loss_ctc0 48.414848 lr 0.00125300 rank 0
2022-08-23 05:53:36,147 DEBUG TRAIN Batch 44/4600 loss 33.344971 loss_att 22.360609 loss_ctc 58.975147 loss_ctc_origin 38.848701 loss_ctc0 105.936852 lr 0.00125275 rank 0
2022-08-23 05:54:05,296 DEBUG TRAIN Batch 44/4700 loss 35.424477 loss_att 24.853720 loss_ctc 60.089569 loss_ctc_origin 52.204021 loss_ctc0 78.489182 lr 0.00125251 rank 0
2022-08-23 05:54:34,337 DEBUG TRAIN Batch 44/4800 loss 34.909721 loss_att 19.910061 loss_ctc 69.908920 loss_ctc_origin 60.925175 loss_ctc0 90.870987 lr 0.00125226 rank 0
2022-08-23 05:55:04,533 DEBUG TRAIN Batch 44/4900 loss 35.334213 loss_att 19.927074 loss_ctc 71.284210 loss_ctc_origin 57.312386 loss_ctc0 103.885132 lr 0.00125202 rank 0
2022-08-23 05:55:34,062 DEBUG TRAIN Batch 44/5000 loss 34.914330 loss_att 27.411873 loss_ctc 52.420067 loss_ctc_origin 49.662590 loss_ctc0 58.854172 lr 0.00125177 rank 0
2022-08-23 05:55:56,402 WARNING NaN or Inf found in input tensor.
2022-08-23 05:56:03,782 DEBUG TRAIN Batch 44/5100 loss 37.555756 loss_att 25.703743 loss_ctc 65.210449 loss_ctc_origin 49.074520 loss_ctc0 102.860954 lr 0.00125153 rank 0
2022-08-23 05:56:10,170 WARNING NaN or Inf found in input tensor.
2022-08-23 05:56:33,156 DEBUG TRAIN Batch 44/5200 loss 25.819916 loss_att 15.828270 loss_ctc 49.133751 loss_ctc_origin 38.675392 loss_ctc0 73.536583 lr 0.00125128 rank 0
2022-08-23 05:57:03,130 DEBUG TRAIN Batch 44/5300 loss 27.747311 loss_att 15.961306 loss_ctc 55.247986 loss_ctc_origin 44.962063 loss_ctc0 79.248474 lr 0.00125104 rank 0
2022-08-23 05:57:32,871 DEBUG TRAIN Batch 44/5400 loss 31.827160 loss_att 18.565619 loss_ctc 62.770752 loss_ctc_origin 47.797909 loss_ctc0 97.707382 lr 0.00125079 rank 0
2022-08-23 05:58:02,043 DEBUG TRAIN Batch 44/5500 loss 33.613350 loss_att 24.907671 loss_ctc 53.926605 loss_ctc_origin 48.880745 loss_ctc0 65.700272 lr 0.00125055 rank 0
2022-08-23 05:58:31,364 DEBUG TRAIN Batch 44/5600 loss 28.513359 loss_att 19.313408 loss_ctc 49.979912 loss_ctc_origin 36.627743 loss_ctc0 81.134979 lr 0.00125030 rank 0
2022-08-23 05:58:54,250 DEBUG CV Batch 44/0 loss 17.295189 loss_att 12.338765 loss_ctc 28.860180 loss_ctc_origin 19.226101 loss_ctc0 51.339695 history loss 16.277825 rank 0
2022-08-23 05:59:05,517 DEBUG CV Batch 44/100 loss 29.508320 loss_att 21.008141 loss_ctc 49.342068 loss_ctc_origin 31.908352 loss_ctc0 90.020737 history loss 32.556119 rank 0
2022-08-23 05:59:15,999 DEBUG CV Batch 44/200 loss 29.744947 loss_att 22.793472 loss_ctc 45.965057 loss_ctc_origin 35.765621 loss_ctc0 69.763748 history loss 34.097896 rank 0
2022-08-23 05:59:26,781 DEBUG CV Batch 44/300 loss 28.392599 loss_att 21.098076 loss_ctc 45.413151 loss_ctc_origin 30.794960 loss_ctc0 79.522263 history loss 33.275320 rank 0
2022-08-23 05:59:37,874 DEBUG CV Batch 44/400 loss 44.041893 loss_att 34.522423 loss_ctc 66.253983 loss_ctc_origin 49.909691 loss_ctc0 104.390648 history loss 31.573708 rank 0
2022-08-23 05:59:49,629 DEBUG CV Batch 44/500 loss 22.504902 loss_att 16.170109 loss_ctc 37.286087 loss_ctc_origin 27.523863 loss_ctc0 60.064598 history loss 31.219050 rank 0
2022-08-23 06:00:00,647 DEBUG CV Batch 44/600 loss 26.109310 loss_att 16.968304 loss_ctc 47.438328 loss_ctc_origin 30.779484 loss_ctc0 86.308960 history loss 31.086859 rank 0
2022-08-23 06:00:10,444 DEBUG CV Batch 44/700 loss 22.863556 loss_att 15.805014 loss_ctc 39.333488 loss_ctc_origin 26.861170 loss_ctc0 68.435562 history loss 30.733552 rank 0
2022-08-23 06:00:20,950 DEBUG CV Batch 44/800 loss 26.694878 loss_att 20.103573 loss_ctc 42.074585 loss_ctc_origin 27.834633 loss_ctc0 75.301132 history loss 30.672099 rank 0
2022-08-23 06:00:31,092 INFO Epoch 44 CV info cv_loss 30.7404944784037
2022-08-23 06:00:31,092 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/44.pt
2022-08-23 06:00:31,546 INFO Epoch 45 TRAIN info lr 0.0012500976676955821
2022-08-23 06:00:31,549 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 06:00:58,751 DEBUG TRAIN Batch 45/0 loss 32.779068 loss_att 26.313900 loss_ctc 47.864464 loss_ctc_origin 43.345493 loss_ctc0 58.408733 lr 0.00125009 rank 0
2022-08-23 06:01:27,556 DEBUG TRAIN Batch 45/100 loss 39.543251 loss_att 28.380087 loss_ctc 65.590637 loss_ctc_origin 51.765938 loss_ctc0 97.848259 lr 0.00124984 rank 0
2022-08-23 06:01:57,058 DEBUG TRAIN Batch 45/200 loss 28.281742 loss_att 17.598518 loss_ctc 53.209259 loss_ctc_origin 44.183487 loss_ctc0 74.269386 lr 0.00124960 rank 0
2022-08-23 06:02:25,097 DEBUG TRAIN Batch 45/300 loss 25.304630 loss_att 13.567137 loss_ctc 52.692116 loss_ctc_origin 41.877098 loss_ctc0 77.927155 lr 0.00124936 rank 0
2022-08-23 06:02:54,517 DEBUG TRAIN Batch 45/400 loss 34.207672 loss_att 19.575981 loss_ctc 68.348282 loss_ctc_origin 52.979401 loss_ctc0 104.209015 lr 0.00124911 rank 0
2022-08-23 06:03:24,229 DEBUG TRAIN Batch 45/500 loss 25.209084 loss_att 19.066696 loss_ctc 39.541321 loss_ctc_origin 31.673849 loss_ctc0 57.898750 lr 0.00124887 rank 0
2022-08-23 06:03:52,597 DEBUG TRAIN Batch 45/600 loss 28.056423 loss_att 19.492798 loss_ctc 48.038216 loss_ctc_origin 34.709751 loss_ctc0 79.137970 lr 0.00124863 rank 0
2022-08-23 06:04:21,856 DEBUG TRAIN Batch 45/700 loss 28.943861 loss_att 19.091621 loss_ctc 51.932419 loss_ctc_origin 43.460579 loss_ctc0 71.700050 lr 0.00124838 rank 0
2022-08-23 06:04:51,023 DEBUG TRAIN Batch 45/800 loss 26.363033 loss_att 14.262648 loss_ctc 54.597260 loss_ctc_origin 41.774235 loss_ctc0 84.517639 lr 0.00124814 rank 0
2022-08-23 06:05:20,289 DEBUG TRAIN Batch 45/900 loss 32.082787 loss_att 18.451477 loss_ctc 63.889168 loss_ctc_origin 50.581944 loss_ctc0 94.939346 lr 0.00124790 rank 0
2022-08-23 06:05:49,713 DEBUG TRAIN Batch 45/1000 loss 35.082081 loss_att 29.455900 loss_ctc 48.209835 loss_ctc_origin 48.954132 loss_ctc0 46.473145 lr 0.00124765 rank 0
2022-08-23 06:06:19,313 DEBUG TRAIN Batch 45/1100 loss 32.847183 loss_att 20.550137 loss_ctc 61.540298 loss_ctc_origin 47.228203 loss_ctc0 94.935188 lr 0.00124741 rank 0
2022-08-23 06:06:49,004 DEBUG TRAIN Batch 45/1200 loss 26.480989 loss_att 17.468607 loss_ctc 47.509880 loss_ctc_origin 39.173744 loss_ctc0 66.960861 lr 0.00124717 rank 0
2022-08-23 06:07:18,741 DEBUG TRAIN Batch 45/1300 loss 25.931417 loss_att 15.019566 loss_ctc 51.392403 loss_ctc_origin 40.567867 loss_ctc0 76.649658 lr 0.00124693 rank 0
2022-08-23 06:07:36,082 WARNING NaN or Inf found in input tensor.
2022-08-23 06:07:47,809 DEBUG TRAIN Batch 45/1400 loss 32.604301 loss_att 19.119074 loss_ctc 64.069832 loss_ctc_origin 49.332951 loss_ctc0 98.455887 lr 0.00124668 rank 0
2022-08-23 06:07:56,292 WARNING NaN or Inf found in input tensor.
2022-08-23 06:08:22,766 DEBUG TRAIN Batch 45/1500 loss 26.767986 loss_att 20.204094 loss_ctc 42.083733 loss_ctc_origin 35.864086 loss_ctc0 56.596241 lr 0.00124644 rank 0
2022-08-23 06:08:51,948 DEBUG TRAIN Batch 45/1600 loss 26.558102 loss_att 17.257162 loss_ctc 48.260288 loss_ctc_origin 35.245331 loss_ctc0 78.628517 lr 0.00124620 rank 0
2022-08-23 06:09:21,179 DEBUG TRAIN Batch 45/1700 loss 22.120705 loss_att 13.952864 loss_ctc 41.178997 loss_ctc_origin 32.851990 loss_ctc0 60.608677 lr 0.00124596 rank 0
2022-08-23 06:09:50,204 DEBUG TRAIN Batch 45/1800 loss 30.113523 loss_att 17.427265 loss_ctc 59.714790 loss_ctc_origin 48.804985 loss_ctc0 85.170990 lr 0.00124572 rank 0
2022-08-23 06:10:19,494 DEBUG TRAIN Batch 45/1900 loss 30.109428 loss_att 15.934110 loss_ctc 63.185165 loss_ctc_origin 46.717098 loss_ctc0 101.610641 lr 0.00124547 rank 0
2022-08-23 06:10:50,133 DEBUG TRAIN Batch 45/2000 loss 22.638092 loss_att 17.373144 loss_ctc 34.922966 loss_ctc_origin 30.614302 loss_ctc0 44.976509 lr 0.00124523 rank 0
2022-08-23 06:11:19,138 DEBUG TRAIN Batch 45/2100 loss 34.093628 loss_att 21.825237 loss_ctc 62.719864 loss_ctc_origin 39.514824 loss_ctc0 116.864967 lr 0.00124499 rank 0
2022-08-23 06:11:39,552 WARNING NaN or Inf found in input tensor.
2022-08-23 06:11:48,030 DEBUG TRAIN Batch 45/2200 loss 27.337391 loss_att 16.957424 loss_ctc 51.557312 loss_ctc_origin 42.713844 loss_ctc0 72.192062 lr 0.00124475 rank 0
2022-08-23 06:12:19,191 DEBUG TRAIN Batch 45/2300 loss 27.935102 loss_att 14.377570 loss_ctc 59.569344 loss_ctc_origin 45.626019 loss_ctc0 92.103760 lr 0.00124451 rank 0
2022-08-23 06:12:49,242 DEBUG TRAIN Batch 45/2400 loss 30.989439 loss_att 16.748211 loss_ctc 64.218971 loss_ctc_origin 50.058170 loss_ctc0 97.260834 lr 0.00124427 rank 0
2022-08-23 06:13:18,923 DEBUG TRAIN Batch 45/2500 loss 27.864300 loss_att 21.950699 loss_ctc 41.662697 loss_ctc_origin 36.229980 loss_ctc0 54.339035 lr 0.00124403 rank 0
2022-08-23 06:13:47,716 DEBUG TRAIN Batch 45/2600 loss 47.044544 loss_att 28.956974 loss_ctc 89.248871 loss_ctc_origin 53.605400 loss_ctc0 172.416962 lr 0.00124379 rank 0
2022-08-23 06:14:14,489 WARNING NaN or Inf found in input tensor.
2022-08-23 06:14:16,049 DEBUG TRAIN Batch 45/2700 loss 29.331573 loss_att 19.276974 loss_ctc 52.792301 loss_ctc_origin 44.120152 loss_ctc0 73.027313 lr 0.00124355 rank 0
2022-08-23 06:14:45,922 DEBUG TRAIN Batch 45/2800 loss 31.759457 loss_att 18.617481 loss_ctc 62.424065 loss_ctc_origin 49.794464 loss_ctc0 91.893135 lr 0.00124331 rank 0
2022-08-23 06:15:15,120 DEBUG TRAIN Batch 45/2900 loss 33.838512 loss_att 19.564344 loss_ctc 67.144905 loss_ctc_origin 54.110809 loss_ctc0 97.557785 lr 0.00124307 rank 0
2022-08-23 06:15:50,772 DEBUG TRAIN Batch 45/3000 loss 30.688183 loss_att 24.055832 loss_ctc 46.163670 loss_ctc_origin 38.066887 loss_ctc0 65.056160 lr 0.00124283 rank 0
2022-08-23 06:16:20,141 DEBUG TRAIN Batch 45/3100 loss 38.224991 loss_att 24.811922 loss_ctc 69.522156 loss_ctc_origin 45.878529 loss_ctc0 124.690598 lr 0.00124259 rank 0
2022-08-23 06:16:49,534 DEBUG TRAIN Batch 45/3200 loss 30.684216 loss_att 21.693878 loss_ctc 51.661667 loss_ctc_origin 43.357830 loss_ctc0 71.037285 lr 0.00124235 rank 0
2022-08-23 06:17:18,738 DEBUG TRAIN Batch 45/3300 loss 28.044285 loss_att 16.191153 loss_ctc 55.701591 loss_ctc_origin 45.661255 loss_ctc0 79.129044 lr 0.00124211 rank 0
2022-08-23 06:17:48,438 DEBUG TRAIN Batch 45/3400 loss 35.060471 loss_att 19.960636 loss_ctc 70.293419 loss_ctc_origin 57.060307 loss_ctc0 101.170670 lr 0.00124187 rank 0
2022-08-23 06:18:17,886 DEBUG TRAIN Batch 45/3500 loss 34.213974 loss_att 26.689970 loss_ctc 51.769981 loss_ctc_origin 43.413475 loss_ctc0 71.268486 lr 0.00124163 rank 0
2022-08-23 06:18:39,631 WARNING NaN or Inf found in input tensor.
2022-08-23 06:18:46,916 DEBUG TRAIN Batch 45/3600 loss 46.953819 loss_att 29.659386 loss_ctc 87.307487 loss_ctc_origin 50.918827 loss_ctc0 172.214355 lr 0.00124139 rank 0
2022-08-23 06:19:15,986 DEBUG TRAIN Batch 45/3700 loss 25.242527 loss_att 16.537678 loss_ctc 45.553841 loss_ctc_origin 37.517303 loss_ctc0 64.305756 lr 0.00124115 rank 0
2022-08-23 06:19:45,668 DEBUG TRAIN Batch 45/3800 loss 30.613281 loss_att 16.896950 loss_ctc 62.618050 loss_ctc_origin 50.318756 loss_ctc0 91.316391 lr 0.00124091 rank 0
2022-08-23 06:20:10,270 WARNING NaN or Inf found in input tensor.
2022-08-23 06:20:14,574 DEBUG TRAIN Batch 45/3900 loss 33.529926 loss_att 18.791374 loss_ctc 67.919876 loss_ctc_origin 54.552490 loss_ctc0 99.110458 lr 0.00124067 rank 0
2022-08-23 06:20:44,974 DEBUG TRAIN Batch 45/4000 loss 24.444870 loss_att 19.974945 loss_ctc 34.874699 loss_ctc_origin 31.636082 loss_ctc0 42.431469 lr 0.00124043 rank 0
2022-08-23 06:21:14,437 DEBUG TRAIN Batch 45/4100 loss 41.599819 loss_att 27.647230 loss_ctc 74.155853 loss_ctc_origin 51.859444 loss_ctc0 126.180817 lr 0.00124019 rank 0
2022-08-23 06:21:43,968 DEBUG TRAIN Batch 45/4200 loss 33.460606 loss_att 22.191528 loss_ctc 59.755116 loss_ctc_origin 53.022881 loss_ctc0 75.463661 lr 0.00123996 rank 0
2022-08-23 06:22:13,298 DEBUG TRAIN Batch 45/4300 loss 33.119450 loss_att 19.734518 loss_ctc 64.350952 loss_ctc_origin 55.793163 loss_ctc0 84.319138 lr 0.00123972 rank 0
2022-08-23 06:22:38,649 WARNING NaN or Inf found in input tensor.
2022-08-23 06:22:43,058 DEBUG TRAIN Batch 45/4400 loss 38.868736 loss_att 22.348303 loss_ctc 77.416420 loss_ctc_origin 63.252449 loss_ctc0 110.465683 lr 0.00123948 rank 0
2022-08-23 06:23:17,593 DEBUG TRAIN Batch 45/4500 loss 23.996225 loss_att 18.977417 loss_ctc 35.706776 loss_ctc_origin 33.877411 loss_ctc0 39.975288 lr 0.00123924 rank 0
2022-08-23 06:23:25,659 WARNING NaN or Inf found in input tensor.
2022-08-23 06:23:46,334 WARNING NaN or Inf found in input tensor.
2022-08-23 06:23:46,412 DEBUG TRAIN Batch 45/4600 loss nan loss_att 31.145355 loss_ctc nan loss_ctc_origin 65.248314 loss_ctc0 nan lr 0.00123900 rank 0
2022-08-23 06:24:15,525 DEBUG TRAIN Batch 45/4700 loss 25.263145 loss_att 15.060734 loss_ctc 49.068771 loss_ctc_origin 40.158360 loss_ctc0 69.859734 lr 0.00123877 rank 0
2022-08-23 06:24:44,262 DEBUG TRAIN Batch 45/4800 loss 24.791248 loss_att 13.518767 loss_ctc 51.093704 loss_ctc_origin 37.410473 loss_ctc0 83.021248 lr 0.00123853 rank 0
2022-08-23 06:25:13,231 DEBUG TRAIN Batch 45/4900 loss 32.854309 loss_att 18.566109 loss_ctc 66.193436 loss_ctc_origin 52.893707 loss_ctc0 97.226151 lr 0.00123829 rank 0
2022-08-23 06:25:42,983 DEBUG TRAIN Batch 45/5000 loss 29.583755 loss_att 23.982693 loss_ctc 42.652901 loss_ctc_origin 41.110199 loss_ctc0 46.252541 lr 0.00123805 rank 0
2022-08-23 06:26:12,893 DEBUG TRAIN Batch 45/5100 loss 37.052418 loss_att 21.857632 loss_ctc 72.506912 loss_ctc_origin 46.028625 loss_ctc0 134.289581 lr 0.00123782 rank 0
2022-08-23 06:26:42,732 DEBUG TRAIN Batch 45/5200 loss 28.841312 loss_att 18.482285 loss_ctc 53.012375 loss_ctc_origin 45.558853 loss_ctc0 70.403931 lr 0.00123758 rank 0
2022-08-23 06:27:12,762 DEBUG TRAIN Batch 45/5300 loss 27.553314 loss_att 15.566709 loss_ctc 55.522060 loss_ctc_origin 42.746410 loss_ctc0 85.331909 lr 0.00123734 rank 0
2022-08-23 06:27:41,913 DEBUG TRAIN Batch 45/5400 loss 32.686661 loss_att 17.205030 loss_ctc 68.810463 loss_ctc_origin 54.854500 loss_ctc0 101.374374 lr 0.00123711 rank 0
2022-08-23 06:28:10,229 DEBUG TRAIN Batch 45/5500 loss 27.571283 loss_att 19.414326 loss_ctc 46.604183 loss_ctc_origin 42.850201 loss_ctc0 55.363472 lr 0.00123687 rank 0
2022-08-23 06:28:39,657 DEBUG TRAIN Batch 45/5600 loss 35.039539 loss_att 20.725363 loss_ctc 68.439285 loss_ctc_origin 45.992386 loss_ctc0 120.815369 lr 0.00123663 rank 0
2022-08-23 06:29:03,047 DEBUG CV Batch 45/0 loss 28.883469 loss_att 18.879101 loss_ctc 52.226990 loss_ctc_origin 32.611160 loss_ctc0 97.997246 history loss 27.184441 rank 0
2022-08-23 06:29:14,250 DEBUG CV Batch 45/100 loss 55.952370 loss_att 36.153427 loss_ctc 102.149895 loss_ctc_origin 64.996704 loss_ctc0 188.840668 history loss 37.799346 rank 0
2022-08-23 06:29:24,171 DEBUG CV Batch 45/200 loss 29.177536 loss_att 22.270243 loss_ctc 45.294552 loss_ctc_origin 35.295288 loss_ctc0 68.626167 history loss 40.002746 rank 0
2022-08-23 06:29:34,588 DEBUG CV Batch 45/300 loss 29.062006 loss_att 21.526421 loss_ctc 46.645039 loss_ctc_origin 33.045189 loss_ctc0 78.378021 history loss 39.245444 rank 0
2022-08-23 06:29:45,538 DEBUG CV Batch 45/400 loss 43.674629 loss_att 34.557793 loss_ctc 64.947243 loss_ctc_origin 48.726379 loss_ctc0 102.795929 history loss 37.161044 rank 0
2022-08-23 06:29:56,626 DEBUG CV Batch 45/500 loss 35.069580 loss_att 23.700127 loss_ctc 61.598312 loss_ctc_origin 42.175400 loss_ctc0 106.918427 history loss 36.788827 rank 0
2022-08-23 06:30:07,691 DEBUG CV Batch 45/600 loss 51.862953 loss_att 33.064945 loss_ctc 95.724960 loss_ctc_origin 60.247593 loss_ctc0 178.505493 history loss 36.851061 rank 0
2022-08-23 06:30:18,235 DEBUG CV Batch 45/700 loss 22.849594 loss_att 15.665336 loss_ctc 39.612862 loss_ctc_origin 27.002081 loss_ctc0 69.038010 history loss 36.483574 rank 0
2022-08-23 06:30:29,356 DEBUG CV Batch 45/800 loss 26.195272 loss_att 19.443998 loss_ctc 41.948242 loss_ctc_origin 28.006948 loss_ctc0 74.477928 history loss 36.346518 rank 0
2022-08-23 06:30:40,196 INFO Epoch 45 CV info cv_loss 36.141574685751806
2022-08-23 06:30:40,196 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/45.pt
2022-08-23 06:30:40,650 INFO Epoch 46 TRAIN info lr 0.0012364349878741234
2022-08-23 06:30:40,654 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 06:31:08,623 DEBUG TRAIN Batch 46/0 loss 38.352554 loss_att 27.855560 loss_ctc 62.845547 loss_ctc_origin 51.185745 loss_ctc0 90.051750 lr 0.00123643 rank 0
2022-08-23 06:31:24,432 WARNING NaN or Inf found in input tensor.
2022-08-23 06:31:38,544 DEBUG TRAIN Batch 46/100 loss 35.467613 loss_att 24.084316 loss_ctc 62.028648 loss_ctc_origin 45.280159 loss_ctc0 101.108452 lr 0.00123619 rank 0
2022-08-23 06:32:07,341 DEBUG TRAIN Batch 46/200 loss 27.677010 loss_att 18.403999 loss_ctc 49.314030 loss_ctc_origin 40.059940 loss_ctc0 70.906906 lr 0.00123595 rank 0
2022-08-23 06:32:36,322 DEBUG TRAIN Batch 46/300 loss 27.123260 loss_att 14.352440 loss_ctc 56.921844 loss_ctc_origin 44.994308 loss_ctc0 84.752762 lr 0.00123572 rank 0
2022-08-23 06:33:05,210 DEBUG TRAIN Batch 46/400 loss 29.474583 loss_att 16.630749 loss_ctc 59.443527 loss_ctc_origin 44.751289 loss_ctc0 93.725410 lr 0.00123548 rank 0
2022-08-23 06:33:35,102 DEBUG TRAIN Batch 46/500 loss 33.121983 loss_att 27.414297 loss_ctc 46.439915 loss_ctc_origin 43.523983 loss_ctc0 53.243759 lr 0.00123525 rank 0
2022-08-23 06:34:03,874 DEBUG TRAIN Batch 46/600 loss 32.394249 loss_att 21.300444 loss_ctc 58.279797 loss_ctc_origin 37.994305 loss_ctc0 105.612610 lr 0.00123501 rank 0
2022-08-23 06:34:32,429 DEBUG TRAIN Batch 46/700 loss 25.254932 loss_att 16.281155 loss_ctc 46.193748 loss_ctc_origin 37.262810 loss_ctc0 67.032593 lr 0.00123477 rank 0
2022-08-23 06:35:01,075 DEBUG TRAIN Batch 46/800 loss 26.271034 loss_att 13.783534 loss_ctc 55.408535 loss_ctc_origin 43.642876 loss_ctc0 82.861740 lr 0.00123454 rank 0
2022-08-23 06:35:31,533 DEBUG TRAIN Batch 46/900 loss 34.285858 loss_att 17.820366 loss_ctc 72.705338 loss_ctc_origin 56.052307 loss_ctc0 111.562416 lr 0.00123430 rank 0
2022-08-23 06:36:00,620 DEBUG TRAIN Batch 46/1000 loss 32.459484 loss_att 26.277634 loss_ctc 46.883801 loss_ctc_origin 45.325531 loss_ctc0 50.519760 lr 0.00123407 rank 0
2022-08-23 06:36:15,280 WARNING NaN or Inf found in input tensor.
2022-08-23 06:36:29,502 DEBUG TRAIN Batch 46/1100 loss 33.132336 loss_att 22.249002 loss_ctc 58.526772 loss_ctc_origin 45.283085 loss_ctc0 89.428711 lr 0.00123383 rank 0
2022-08-23 06:36:58,310 DEBUG TRAIN Batch 46/1200 loss 29.713037 loss_att 19.003193 loss_ctc 54.702671 loss_ctc_origin 45.582432 loss_ctc0 75.983231 lr 0.00123360 rank 0
2022-08-23 06:37:10,155 WARNING NaN or Inf found in input tensor.
2022-08-23 06:37:27,318 DEBUG TRAIN Batch 46/1300 loss 29.868279 loss_att 15.560108 loss_ctc 63.254013 loss_ctc_origin 51.694981 loss_ctc0 90.225082 lr 0.00123337 rank 0
2022-08-23 06:37:55,826 DEBUG TRAIN Batch 46/1400 loss 35.886345 loss_att 19.884470 loss_ctc 73.224052 loss_ctc_origin 59.672714 loss_ctc0 104.843842 lr 0.00123313 rank 0
2022-08-23 06:38:29,067 DEBUG TRAIN Batch 46/1500 loss 32.389408 loss_att 26.382538 loss_ctc 46.405441 loss_ctc_origin 41.615234 loss_ctc0 57.582592 lr 0.00123290 rank 0
2022-08-23 06:38:58,031 DEBUG TRAIN Batch 46/1600 loss 37.892067 loss_att 27.154518 loss_ctc 62.946350 loss_ctc_origin 46.579609 loss_ctc0 101.135422 lr 0.00123266 rank 0
2022-08-23 06:39:25,866 DEBUG TRAIN Batch 46/1700 loss 24.814390 loss_att 15.887183 loss_ctc 45.644539 loss_ctc_origin 37.479401 loss_ctc0 64.696533 lr 0.00123243 rank 0
2022-08-23 06:39:54,697 DEBUG TRAIN Batch 46/1800 loss 29.053795 loss_att 16.834980 loss_ctc 57.564362 loss_ctc_origin 47.200771 loss_ctc0 81.746078 lr 0.00123219 rank 0
2022-08-23 06:40:24,258 DEBUG TRAIN Batch 46/1900 loss 36.044472 loss_att 20.790993 loss_ctc 71.635925 loss_ctc_origin 58.439888 loss_ctc0 102.426682 lr 0.00123196 rank 0
2022-08-23 06:40:54,173 DEBUG TRAIN Batch 46/2000 loss 28.446754 loss_att 23.578123 loss_ctc 39.806892 loss_ctc_origin 37.201530 loss_ctc0 45.886063 lr 0.00123173 rank 0
2022-08-23 06:41:23,018 DEBUG TRAIN Batch 46/2100 loss 34.183147 loss_att 24.194340 loss_ctc 57.490364 loss_ctc_origin 44.191936 loss_ctc0 88.520020 lr 0.00123149 rank 0
2022-08-23 06:41:52,872 DEBUG TRAIN Batch 46/2200 loss 29.813992 loss_att 20.136427 loss_ctc 52.394974 loss_ctc_origin 45.161156 loss_ctc0 69.273880 lr 0.00123126 rank 0
2022-08-23 06:42:21,377 DEBUG TRAIN Batch 46/2300 loss 31.070332 loss_att 18.141735 loss_ctc 61.237053 loss_ctc_origin 49.984673 loss_ctc0 87.492615 lr 0.00123103 rank 0
2022-08-23 06:42:51,345 DEBUG TRAIN Batch 46/2400 loss 33.908318 loss_att 19.699362 loss_ctc 67.062553 loss_ctc_origin 54.856720 loss_ctc0 95.542831 lr 0.00123079 rank 0
2022-08-23 06:43:19,724 DEBUG TRAIN Batch 46/2500 loss 31.339582 loss_att 24.940351 loss_ctc 46.271118 loss_ctc_origin 38.797882 loss_ctc0 63.708668 lr 0.00123056 rank 0
2022-08-23 06:43:49,456 DEBUG TRAIN Batch 46/2600 loss 33.227993 loss_att 22.037636 loss_ctc 59.338821 loss_ctc_origin 46.722237 loss_ctc0 88.777512 lr 0.00123033 rank 0
2022-08-23 06:44:18,888 DEBUG TRAIN Batch 46/2700 loss 29.014130 loss_att 18.468027 loss_ctc 53.621704 loss_ctc_origin 45.408913 loss_ctc0 72.784882 lr 0.00123010 rank 0
2022-08-23 06:44:48,449 DEBUG TRAIN Batch 46/2800 loss 29.072090 loss_att 16.396107 loss_ctc 58.649380 loss_ctc_origin 46.667416 loss_ctc0 86.607292 lr 0.00122986 rank 0
2022-08-23 06:45:17,534 DEBUG TRAIN Batch 46/2900 loss 33.229332 loss_att 21.013031 loss_ctc 61.734032 loss_ctc_origin 47.939041 loss_ctc0 93.922348 lr 0.00122963 rank 0
2022-08-23 06:45:53,642 DEBUG TRAIN Batch 46/3000 loss 28.512337 loss_att 23.031057 loss_ctc 41.301987 loss_ctc_origin 39.482151 loss_ctc0 45.548279 lr 0.00122940 rank 0
2022-08-23 06:46:22,536 WARNING NaN or Inf found in input tensor.
2022-08-23 06:46:23,343 DEBUG TRAIN Batch 46/3100 loss 33.628540 loss_att 24.440922 loss_ctc 55.066315 loss_ctc_origin 41.172932 loss_ctc0 87.484207 lr 0.00122917 rank 0
2022-08-23 06:46:52,271 DEBUG TRAIN Batch 46/3200 loss 27.194063 loss_att 17.745157 loss_ctc 49.241508 loss_ctc_origin 40.213287 loss_ctc0 70.307358 lr 0.00122893 rank 0
2022-08-23 06:47:22,245 DEBUG TRAIN Batch 46/3300 loss 31.291983 loss_att 17.681667 loss_ctc 63.049385 loss_ctc_origin 51.329113 loss_ctc0 90.396683 lr 0.00122870 rank 0
2022-08-23 06:47:51,718 DEBUG TRAIN Batch 46/3400 loss 32.816055 loss_att 17.720177 loss_ctc 68.039772 loss_ctc_origin 53.303551 loss_ctc0 102.424286 lr 0.00122847 rank 0
2022-08-23 06:48:21,677 DEBUG TRAIN Batch 46/3500 loss 31.054655 loss_att 25.870596 loss_ctc 43.150791 loss_ctc_origin 39.839195 loss_ctc0 50.877853 lr 0.00122824 rank 0
2022-08-23 06:48:50,855 DEBUG TRAIN Batch 46/3600 loss 39.905388 loss_att 24.747890 loss_ctc 75.272881 loss_ctc_origin 43.054932 loss_ctc0 150.448090 lr 0.00122801 rank 0
2022-08-23 06:49:20,182 DEBUG TRAIN Batch 46/3700 loss 27.696213 loss_att 18.396727 loss_ctc 49.395012 loss_ctc_origin 39.964306 loss_ctc0 71.399994 lr 0.00122778 rank 0
2022-08-23 06:49:49,498 DEBUG TRAIN Batch 46/3800 loss 32.220108 loss_att 18.457188 loss_ctc 64.333588 loss_ctc_origin 53.359657 loss_ctc0 89.939430 lr 0.00122754 rank 0
2022-08-23 06:50:19,411 DEBUG TRAIN Batch 46/3900 loss 33.056503 loss_att 18.296478 loss_ctc 67.496567 loss_ctc_origin 52.248405 loss_ctc0 103.075600 lr 0.00122731 rank 0
2022-08-23 06:50:49,222 DEBUG TRAIN Batch 46/4000 loss 29.015388 loss_att 22.322992 loss_ctc 44.630981 loss_ctc_origin 42.380302 loss_ctc0 49.882557 lr 0.00122708 rank 0
2022-08-23 06:51:18,409 DEBUG TRAIN Batch 46/4100 loss 38.487938 loss_att 24.492170 loss_ctc 71.144730 loss_ctc_origin 45.862423 loss_ctc0 130.136780 lr 0.00122685 rank 0
2022-08-23 06:51:45,976 WARNING NaN or Inf found in input tensor.
2022-08-23 06:51:47,758 DEBUG TRAIN Batch 46/4200 loss 30.460081 loss_att 18.121885 loss_ctc 59.249199 loss_ctc_origin 49.909882 loss_ctc0 81.040932 lr 0.00122662 rank 0
2022-08-23 06:52:17,803 DEBUG TRAIN Batch 46/4300 loss 32.377182 loss_att 19.090963 loss_ctc 63.378357 loss_ctc_origin 52.643635 loss_ctc0 88.426048 lr 0.00122639 rank 0
2022-08-23 06:52:46,936 DEBUG TRAIN Batch 46/4400 loss 28.718830 loss_att 16.068329 loss_ctc 58.236664 loss_ctc_origin 44.709286 loss_ctc0 89.800545 lr 0.00122616 rank 0
2022-08-23 06:53:23,240 DEBUG TRAIN Batch 46/4500 loss 33.803524 loss_att 26.780916 loss_ctc 50.189606 loss_ctc_origin 44.215591 loss_ctc0 64.128960 lr 0.00122593 rank 0
2022-08-23 06:53:53,332 DEBUG TRAIN Batch 46/4600 loss 36.149822 loss_att 23.979935 loss_ctc 64.546227 loss_ctc_origin 41.721909 loss_ctc0 117.802963 lr 0.00122570 rank 0
2022-08-23 06:54:22,173 DEBUG TRAIN Batch 46/4700 loss 25.810806 loss_att 16.968288 loss_ctc 46.443344 loss_ctc_origin 37.688972 loss_ctc0 66.870201 lr 0.00122547 rank 0
2022-08-23 06:54:27,578 WARNING NaN or Inf found in input tensor.
2022-08-23 06:54:51,969 DEBUG TRAIN Batch 46/4800 loss 34.134407 loss_att 19.963448 loss_ctc 67.199982 loss_ctc_origin 56.777405 loss_ctc0 91.519341 lr 0.00122524 rank 0
2022-08-23 06:55:21,777 DEBUG TRAIN Batch 46/4900 loss 34.113354 loss_att 19.483824 loss_ctc 68.248924 loss_ctc_origin 52.430149 loss_ctc0 105.159393 lr 0.00122501 rank 0
2022-08-23 06:55:51,510 DEBUG TRAIN Batch 46/5000 loss 30.132257 loss_att 24.257626 loss_ctc 43.839733 loss_ctc_origin 39.264427 loss_ctc0 54.515446 lr 0.00122478 rank 0
2022-08-23 06:56:21,124 DEBUG TRAIN Batch 46/5100 loss 40.221619 loss_att 26.408810 loss_ctc 72.451508 loss_ctc_origin 46.379852 loss_ctc0 133.285370 lr 0.00122455 rank 0
2022-08-23 06:56:50,681 DEBUG TRAIN Batch 46/5200 loss 27.678253 loss_att 16.047554 loss_ctc 54.816551 loss_ctc_origin 46.192020 loss_ctc0 74.940445 lr 0.00122432 rank 0
2022-08-23 06:57:19,938 DEBUG TRAIN Batch 46/5300 loss 30.951027 loss_att 16.487103 loss_ctc 64.700180 loss_ctc_origin 51.551964 loss_ctc0 95.379356 lr 0.00122409 rank 0
2022-08-23 06:57:49,007 DEBUG TRAIN Batch 46/5400 loss 32.992382 loss_att 18.245930 loss_ctc 67.400772 loss_ctc_origin 53.610157 loss_ctc0 99.578880 lr 0.00122386 rank 0
2022-08-23 06:58:19,671 DEBUG TRAIN Batch 46/5500 loss 21.923037 loss_att 18.053972 loss_ctc 30.950853 loss_ctc_origin 28.127422 loss_ctc0 37.538857 lr 0.00122363 rank 0
2022-08-23 06:58:48,890 DEBUG TRAIN Batch 46/5600 loss 34.718491 loss_att 22.535194 loss_ctc 63.146183 loss_ctc_origin 41.196209 loss_ctc0 114.362793 lr 0.00122340 rank 0
2022-08-23 06:59:12,979 DEBUG CV Batch 46/0 loss 24.038857 loss_att 15.329081 loss_ctc 44.361664 loss_ctc_origin 25.915619 loss_ctc0 87.402435 history loss 22.624806 rank 0
2022-08-23 06:59:23,954 DEBUG CV Batch 46/100 loss 48.936386 loss_att 31.571524 loss_ctc 89.454391 loss_ctc_origin 55.095314 loss_ctc0 169.625580 history loss 35.827968 rank 0
2022-08-23 06:59:34,266 DEBUG CV Batch 46/200 loss 29.263943 loss_att 22.408165 loss_ctc 45.260754 loss_ctc_origin 35.625866 loss_ctc0 67.742157 history loss 37.338120 rank 0
2022-08-23 06:59:44,648 DEBUG CV Batch 46/300 loss 27.599274 loss_att 20.597767 loss_ctc 43.936123 loss_ctc_origin 29.526594 loss_ctc0 77.558357 history loss 36.464560 rank 0
2022-08-23 06:59:55,554 DEBUG CV Batch 46/400 loss 42.655373 loss_att 33.549088 loss_ctc 63.903370 loss_ctc_origin 48.040703 loss_ctc0 100.916260 history loss 34.415386 rank 0
2022-08-23 07:00:06,899 DEBUG CV Batch 46/500 loss 28.199032 loss_att 19.161377 loss_ctc 49.286896 loss_ctc_origin 32.166512 loss_ctc0 89.234451 history loss 33.902503 rank 0
2022-08-23 07:00:18,177 DEBUG CV Batch 46/600 loss 33.103294 loss_att 20.368931 loss_ctc 62.816811 loss_ctc_origin 37.496155 loss_ctc0 121.898346 history loss 33.804981 rank 0
2022-08-23 07:00:28,970 DEBUG CV Batch 46/700 loss 22.875217 loss_att 15.490806 loss_ctc 40.105507 loss_ctc_origin 28.349480 loss_ctc0 67.536240 history loss 33.417621 rank 0
2022-08-23 07:00:39,947 DEBUG CV Batch 46/800 loss 25.491848 loss_att 18.695299 loss_ctc 41.350464 loss_ctc_origin 27.025133 loss_ctc0 74.776230 history loss 33.294481 rank 0
2022-08-23 07:00:50,801 INFO Epoch 46 CV info cv_loss 33.198815774508226
2022-08-23 07:00:50,801 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/46.pt
2022-08-23 07:00:51,294 INFO Epoch 47 TRAIN info lr 0.001223210704044692
2022-08-23 07:00:51,298 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 07:01:19,943 DEBUG TRAIN Batch 47/0 loss 27.518410 loss_att 23.358059 loss_ctc 37.225891 loss_ctc_origin 34.846619 loss_ctc0 42.777523 lr 0.00122320 rank 0
2022-08-23 07:01:27,911 WARNING NaN or Inf found in input tensor.
2022-08-23 07:01:49,476 DEBUG TRAIN Batch 47/100 loss 36.551048 loss_att 20.969208 loss_ctc 72.908676 loss_ctc_origin 45.603218 loss_ctc0 136.621414 lr 0.00122297 rank 0
2022-08-23 07:02:16,703 WARNING NaN or Inf found in input tensor.
2022-08-23 07:02:18,355 DEBUG TRAIN Batch 47/200 loss 26.254276 loss_att 17.968266 loss_ctc 45.588299 loss_ctc_origin 37.338467 loss_ctc0 64.837906 lr 0.00122274 rank 0
2022-08-23 07:02:47,566 DEBUG TRAIN Batch 47/300 loss 31.458624 loss_att 18.494225 loss_ctc 61.708885 loss_ctc_origin 49.548302 loss_ctc0 90.083572 lr 0.00122252 rank 0
2022-08-23 07:03:16,746 DEBUG TRAIN Batch 47/400 loss 33.211323 loss_att 17.458010 loss_ctc 69.969055 loss_ctc_origin 57.069485 loss_ctc0 100.068054 lr 0.00122229 rank 0
2022-08-23 07:03:47,325 DEBUG TRAIN Batch 47/500 loss 31.149006 loss_att 22.886265 loss_ctc 50.428734 loss_ctc_origin 39.638985 loss_ctc0 75.604820 lr 0.00122206 rank 0
2022-08-23 07:04:14,627 DEBUG TRAIN Batch 47/600 loss 37.014984 loss_att 23.941238 loss_ctc 67.520386 loss_ctc_origin 42.934963 loss_ctc0 124.886368 lr 0.00122183 rank 0
2022-08-23 07:04:34,667 WARNING NaN or Inf found in input tensor.
2022-08-23 07:04:44,180 DEBUG TRAIN Batch 47/700 loss 28.613209 loss_att 17.474743 loss_ctc 54.602959 loss_ctc_origin 46.958107 loss_ctc0 72.440948 lr 0.00122160 rank 0
2022-08-23 07:05:09,987 WARNING NaN or Inf found in input tensor.
2022-08-23 07:05:13,321 DEBUG TRAIN Batch 47/800 loss 30.767731 loss_att 17.502714 loss_ctc 61.719437 loss_ctc_origin 51.001389 loss_ctc0 86.728218 lr 0.00122138 rank 0
2022-08-23 07:05:42,950 DEBUG TRAIN Batch 47/900 loss 31.617001 loss_att 16.638493 loss_ctc 66.566849 loss_ctc_origin 52.766243 loss_ctc0 98.768242 lr 0.00122115 rank 0
2022-08-23 07:06:12,440 DEBUG TRAIN Batch 47/1000 loss 29.461248 loss_att 21.796427 loss_ctc 47.345829 loss_ctc_origin 34.838707 loss_ctc0 76.529114 lr 0.00122092 rank 0
2022-08-23 07:06:13,150 WARNING NaN or Inf found in input tensor.
2022-08-23 07:06:41,163 DEBUG TRAIN Batch 47/1100 loss 33.038593 loss_att 21.996445 loss_ctc 58.803604 loss_ctc_origin 39.894363 loss_ctc0 102.925156 lr 0.00122069 rank 0
2022-08-23 07:07:10,481 DEBUG TRAIN Batch 47/1200 loss 27.803337 loss_att 18.101292 loss_ctc 50.441444 loss_ctc_origin 42.149128 loss_ctc0 69.790192 lr 0.00122047 rank 0
2022-08-23 07:07:39,989 DEBUG TRAIN Batch 47/1300 loss 30.114023 loss_att 18.144938 loss_ctc 58.041885 loss_ctc_origin 47.200436 loss_ctc0 83.338593 lr 0.00122024 rank 0
2022-08-23 07:08:10,281 DEBUG TRAIN Batch 47/1400 loss 31.728231 loss_att 16.774935 loss_ctc 66.619255 loss_ctc_origin 52.591896 loss_ctc0 99.349762 lr 0.00122001 rank 0
2022-08-23 07:08:45,899 DEBUG TRAIN Batch 47/1500 loss 30.286507 loss_att 22.198660 loss_ctc 49.158146 loss_ctc_origin 37.701035 loss_ctc0 75.891403 lr 0.00121978 rank 0
2022-08-23 07:09:14,245 DEBUG TRAIN Batch 47/1600 loss 32.025326 loss_att 20.769583 loss_ctc 58.288727 loss_ctc_origin 40.130173 loss_ctc0 100.658684 lr 0.00121956 rank 0
2022-08-23 07:09:44,406 DEBUG TRAIN Batch 47/1700 loss 24.854235 loss_att 15.425185 loss_ctc 46.855350 loss_ctc_origin 36.546776 loss_ctc0 70.908691 lr 0.00121933 rank 0
2022-08-23 07:09:49,794 WARNING NaN or Inf found in input tensor.
2022-08-23 07:10:13,282 DEBUG TRAIN Batch 47/1800 loss 28.363701 loss_att 15.969964 loss_ctc 57.282421 loss_ctc_origin 45.302422 loss_ctc0 85.235748 lr 0.00121910 rank 0
2022-08-23 07:10:43,059 DEBUG TRAIN Batch 47/1900 loss 31.396618 loss_att 16.983082 loss_ctc 65.028198 loss_ctc_origin 50.940384 loss_ctc0 97.899765 lr 0.00121888 rank 0
2022-08-23 07:10:45,694 WARNING NaN or Inf found in input tensor.
2022-08-23 07:11:13,288 DEBUG TRAIN Batch 47/2000 loss 30.472927 loss_att 26.163010 loss_ctc 40.529404 loss_ctc_origin 38.482285 loss_ctc0 45.306007 lr 0.00121865 rank 0
2022-08-23 07:11:42,240 DEBUG TRAIN Batch 47/2100 loss 33.814716 loss_att 24.456041 loss_ctc 55.651627 loss_ctc_origin 43.458954 loss_ctc0 84.101196 lr 0.00121843 rank 0
2022-08-23 07:12:10,484 WARNING NaN or Inf found in input tensor.
2022-08-23 07:12:12,066 DEBUG TRAIN Batch 47/2200 loss 29.884388 loss_att 22.195221 loss_ctc 47.825779 loss_ctc_origin 40.688774 loss_ctc0 64.478790 lr 0.00121820 rank 0
2022-08-23 07:12:41,758 DEBUG TRAIN Batch 47/2300 loss 28.733486 loss_att 15.467376 loss_ctc 59.687737 loss_ctc_origin 49.091312 loss_ctc0 84.412720 lr 0.00121797 rank 0
2022-08-23 07:13:12,367 DEBUG TRAIN Batch 47/2400 loss 34.621540 loss_att 18.631760 loss_ctc 71.931030 loss_ctc_origin 57.008575 loss_ctc0 106.750076 lr 0.00121775 rank 0
2022-08-23 07:13:41,383 DEBUG TRAIN Batch 47/2500 loss 26.238052 loss_att 20.607784 loss_ctc 39.375343 loss_ctc_origin 36.126411 loss_ctc0 46.956184 lr 0.00121752 rank 0
2022-08-23 07:14:09,996 DEBUG TRAIN Batch 47/2600 loss 30.530487 loss_att 19.653667 loss_ctc 55.909729 loss_ctc_origin 39.796516 loss_ctc0 93.507217 lr 0.00121730 rank 0
2022-08-23 07:14:40,119 DEBUG TRAIN Batch 47/2700 loss 23.522804 loss_att 14.063473 loss_ctc 45.594574 loss_ctc_origin 35.436695 loss_ctc0 69.296280 lr 0.00121707 rank 0
2022-08-23 07:15:10,399 DEBUG TRAIN Batch 47/2800 loss 24.273855 loss_att 12.966999 loss_ctc 50.656517 loss_ctc_origin 37.592403 loss_ctc0 81.139450 lr 0.00121685 rank 0
2022-08-23 07:15:20,595 WARNING NaN or Inf found in input tensor.
2022-08-23 07:15:36,438 WARNING NaN or Inf found in input tensor.
2022-08-23 07:15:41,207 DEBUG TRAIN Batch 47/2900 loss 36.867119 loss_att 23.114428 loss_ctc 68.956726 loss_ctc_origin 56.129997 loss_ctc0 98.885773 lr 0.00121662 rank 0
2022-08-23 07:16:18,147 DEBUG TRAIN Batch 47/3000 loss 32.076019 loss_att 26.726494 loss_ctc 44.558243 loss_ctc_origin 40.526772 loss_ctc0 53.965004 lr 0.00121640 rank 0
2022-08-23 07:16:47,748 DEBUG TRAIN Batch 47/3100 loss 29.287306 loss_att 20.041122 loss_ctc 50.861732 loss_ctc_origin 37.300671 loss_ctc0 82.504196 lr 0.00121617 rank 0
2022-08-23 07:17:18,203 DEBUG TRAIN Batch 47/3200 loss 27.691860 loss_att 18.302128 loss_ctc 49.601238 loss_ctc_origin 38.534874 loss_ctc0 75.422752 lr 0.00121595 rank 0
2022-08-23 07:17:48,514 DEBUG TRAIN Batch 47/3300 loss 26.857147 loss_att 14.181735 loss_ctc 56.433105 loss_ctc_origin 43.579010 loss_ctc0 86.425987 lr 0.00121572 rank 0
2022-08-23 07:18:17,994 DEBUG TRAIN Batch 47/3400 loss 25.066515 loss_att 14.414097 loss_ctc 49.922157 loss_ctc_origin 35.915733 loss_ctc0 82.603806 lr 0.00121550 rank 0
2022-08-23 07:18:47,855 DEBUG TRAIN Batch 47/3500 loss 31.675428 loss_att 26.731575 loss_ctc 43.211082 loss_ctc_origin 38.854496 loss_ctc0 53.376453 lr 0.00121527 rank 0
2022-08-23 07:19:17,429 DEBUG TRAIN Batch 47/3600 loss 34.286369 loss_att 25.392845 loss_ctc 55.037922 loss_ctc_origin 44.933987 loss_ctc0 78.613770 lr 0.00121505 rank 0
2022-08-23 07:19:45,170 DEBUG TRAIN Batch 47/3700 loss 27.792696 loss_att 18.287622 loss_ctc 49.971199 loss_ctc_origin 39.855766 loss_ctc0 73.573868 lr 0.00121482 rank 0
2022-08-23 07:20:14,886 DEBUG TRAIN Batch 47/3800 loss 25.309715 loss_att 15.395855 loss_ctc 48.442055 loss_ctc_origin 35.623993 loss_ctc0 78.350868 lr 0.00121460 rank 0
2022-08-23 07:20:45,670 DEBUG TRAIN Batch 47/3900 loss 32.082092 loss_att 17.949970 loss_ctc 65.057045 loss_ctc_origin 51.182930 loss_ctc0 97.429977 lr 0.00121438 rank 0
2022-08-23 07:21:15,596 DEBUG TRAIN Batch 47/4000 loss 27.910019 loss_att 20.949598 loss_ctc 44.151001 loss_ctc_origin 35.562984 loss_ctc0 64.189713 lr 0.00121415 rank 0
2022-08-23 07:21:36,190 WARNING NaN or Inf found in input tensor.
2022-08-23 07:21:43,368 DEBUG TRAIN Batch 47/4100 loss 37.090195 loss_att 25.471153 loss_ctc 64.201286 loss_ctc_origin 42.292114 loss_ctc0 115.322678 lr 0.00121393 rank 0
2022-08-23 07:22:11,912 DEBUG TRAIN Batch 47/4200 loss 25.436977 loss_att 16.197897 loss_ctc 46.994827 loss_ctc_origin 37.441452 loss_ctc0 69.286034 lr 0.00121370 rank 0
2022-08-23 07:22:41,427 DEBUG TRAIN Batch 47/4300 loss 31.438269 loss_att 19.057838 loss_ctc 60.325935 loss_ctc_origin 49.564659 loss_ctc0 85.435585 lr 0.00121348 rank 0
2022-08-23 07:23:10,704 DEBUG TRAIN Batch 47/4400 loss 37.503132 loss_att 22.900276 loss_ctc 71.576462 loss_ctc_origin 58.201340 loss_ctc0 102.785088 lr 0.00121326 rank 0
2022-08-23 07:23:47,761 DEBUG TRAIN Batch 47/4500 loss 34.364479 loss_att 25.911386 loss_ctc 54.088360 loss_ctc_origin 40.706589 loss_ctc0 85.312492 lr 0.00121303 rank 0
2022-08-23 07:24:17,288 DEBUG TRAIN Batch 47/4600 loss 32.444420 loss_att 21.401741 loss_ctc 58.210670 loss_ctc_origin 40.152611 loss_ctc0 100.346146 lr 0.00121281 rank 0
2022-08-23 07:24:46,611 DEBUG TRAIN Batch 47/4700 loss 26.454941 loss_att 16.037212 loss_ctc 50.762970 loss_ctc_origin 41.196423 loss_ctc0 73.084915 lr 0.00121259 rank 0
2022-08-23 07:24:52,038 WARNING NaN or Inf found in input tensor.
2022-08-23 07:25:15,781 DEBUG TRAIN Batch 47/4800 loss 29.009888 loss_att 16.260048 loss_ctc 58.759514 loss_ctc_origin 48.071774 loss_ctc0 83.697571 lr 0.00121237 rank 0
2022-08-23 07:25:44,921 DEBUG TRAIN Batch 47/4900 loss 33.305805 loss_att 18.864094 loss_ctc 67.003128 loss_ctc_origin 52.161564 loss_ctc0 101.633423 lr 0.00121214 rank 0
2022-08-23 07:26:14,806 DEBUG TRAIN Batch 47/5000 loss 23.814835 loss_att 17.659534 loss_ctc 38.177200 loss_ctc_origin 34.824444 loss_ctc0 46.000301 lr 0.00121192 rank 0
2022-08-23 07:26:44,321 DEBUG TRAIN Batch 47/5100 loss 35.170265 loss_att 22.888186 loss_ctc 63.828445 loss_ctc_origin 44.429989 loss_ctc0 109.091499 lr 0.00121170 rank 0
2022-08-23 07:27:13,508 DEBUG TRAIN Batch 47/5200 loss 28.692392 loss_att 18.762617 loss_ctc 51.861866 loss_ctc_origin 43.036930 loss_ctc0 72.453384 lr 0.00121148 rank 0
2022-08-23 07:27:42,998 DEBUG TRAIN Batch 47/5300 loss 24.299599 loss_att 13.380409 loss_ctc 49.777710 loss_ctc_origin 37.895607 loss_ctc0 77.502625 lr 0.00121125 rank 0
2022-08-23 07:28:12,501 DEBUG TRAIN Batch 47/5400 loss 32.608120 loss_att 17.422318 loss_ctc 68.041656 loss_ctc_origin 51.512001 loss_ctc0 106.610863 lr 0.00121103 rank 0
2022-08-23 07:28:41,338 DEBUG TRAIN Batch 47/5500 loss 26.645741 loss_att 19.770435 loss_ctc 42.688118 loss_ctc_origin 39.409515 loss_ctc0 50.338184 lr 0.00121081 rank 0
2022-08-23 07:29:11,776 DEBUG TRAIN Batch 47/5600 loss 31.125381 loss_att 21.069715 loss_ctc 54.588604 loss_ctc_origin 37.816284 loss_ctc0 93.724014 lr 0.00121059 rank 0
2022-08-23 07:29:35,673 DEBUG CV Batch 47/0 loss 18.432116 loss_att 12.680641 loss_ctc 31.852221 loss_ctc_origin 21.431065 loss_ctc0 56.168251 history loss 17.347873 rank 0
2022-08-23 07:29:46,970 DEBUG CV Batch 47/100 loss 26.466404 loss_att 19.282709 loss_ctc 43.228355 loss_ctc_origin 29.095181 loss_ctc0 76.205765 history loss 31.342343 rank 0
2022-08-23 07:29:57,172 DEBUG CV Batch 47/200 loss 30.217201 loss_att 23.329975 loss_ctc 46.287392 loss_ctc_origin 36.861305 loss_ctc0 68.281593 history loss 32.876749 rank 0
2022-08-23 07:30:07,685 DEBUG CV Batch 47/300 loss 28.815727 loss_att 21.817087 loss_ctc 45.145882 loss_ctc_origin 31.523174 loss_ctc0 76.932198 history loss 31.969547 rank 0
2022-08-23 07:30:18,793 DEBUG CV Batch 47/400 loss 41.475262 loss_att 32.897957 loss_ctc 61.488968 loss_ctc_origin 44.825893 loss_ctc0 100.369476 history loss 30.180294 rank 0
2022-08-23 07:30:30,128 DEBUG CV Batch 47/500 loss 20.895807 loss_att 15.307836 loss_ctc 33.934406 loss_ctc_origin 25.586466 loss_ctc0 53.412933 history loss 29.756780 rank 0
2022-08-23 07:30:41,183 DEBUG CV Batch 47/600 loss 24.809452 loss_att 15.511518 loss_ctc 46.504635 loss_ctc_origin 28.181412 loss_ctc0 89.258820 history loss 29.622527 rank 0
2022-08-23 07:30:52,065 DEBUG CV Batch 47/700 loss 21.827394 loss_att 14.813721 loss_ctc 38.192635 loss_ctc_origin 25.278755 loss_ctc0 68.325012 history loss 29.231402 rank 0
2022-08-23 07:31:02,843 DEBUG CV Batch 47/800 loss 24.990940 loss_att 18.351870 loss_ctc 40.482101 loss_ctc_origin 26.192362 loss_ctc0 73.824814 history loss 29.174220 rank 0
2022-08-23 07:31:14,669 INFO Epoch 47 CV info cv_loss 29.226327984116867
2022-08-23 07:31:14,670 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/47.pt
2022-08-23 07:31:15,167 INFO Epoch 48 TRAIN info lr 0.0012104018620294307
2022-08-23 07:31:15,171 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 07:31:43,277 DEBUG TRAIN Batch 48/0 loss 30.329094 loss_att 23.917391 loss_ctc 45.289726 loss_ctc_origin 38.641903 loss_ctc0 60.801308 lr 0.00121039 rank 0
2022-08-23 07:32:12,154 DEBUG TRAIN Batch 48/100 loss 39.895149 loss_att 30.085079 loss_ctc 62.785313 loss_ctc_origin 47.635265 loss_ctc0 98.135422 lr 0.00121017 rank 0
2022-08-23 07:32:41,472 DEBUG TRAIN Batch 48/200 loss 22.656994 loss_att 13.293894 loss_ctc 44.504230 loss_ctc_origin 34.507881 loss_ctc0 67.829048 lr 0.00120995 rank 0
2022-08-23 07:33:10,802 DEBUG TRAIN Batch 48/300 loss 28.912300 loss_att 16.396996 loss_ctc 58.114670 loss_ctc_origin 47.186703 loss_ctc0 83.613251 lr 0.00120973 rank 0
2022-08-23 07:33:41,018 DEBUG TRAIN Batch 48/400 loss 31.675629 loss_att 18.023773 loss_ctc 63.529961 loss_ctc_origin 49.364845 loss_ctc0 96.581909 lr 0.00120951 rank 0
2022-08-23 07:34:11,067 DEBUG TRAIN Batch 48/500 loss 30.920370 loss_att 24.534851 loss_ctc 45.819916 loss_ctc_origin 40.821762 loss_ctc0 57.482265 lr 0.00120929 rank 0
2022-08-23 07:34:40,590 DEBUG TRAIN Batch 48/600 loss 35.045017 loss_att 27.787033 loss_ctc 51.980316 loss_ctc_origin 44.272079 loss_ctc0 69.966202 lr 0.00120907 rank 0
2022-08-23 07:35:10,107 DEBUG TRAIN Batch 48/700 loss 25.207565 loss_att 14.476153 loss_ctc 50.247528 loss_ctc_origin 39.940590 loss_ctc0 74.297058 lr 0.00120884 rank 0
2022-08-23 07:35:39,585 DEBUG TRAIN Batch 48/800 loss 28.980125 loss_att 17.098171 loss_ctc 56.704685 loss_ctc_origin 43.892014 loss_ctc0 86.600914 lr 0.00120862 rank 0
2022-08-23 07:36:09,520 DEBUG TRAIN Batch 48/900 loss 31.601707 loss_att 17.443684 loss_ctc 64.637100 loss_ctc_origin 49.225815 loss_ctc0 100.596764 lr 0.00120840 rank 0
2022-08-23 07:36:39,308 DEBUG TRAIN Batch 48/1000 loss 30.395460 loss_att 25.346100 loss_ctc 42.177299 loss_ctc_origin 33.971153 loss_ctc0 61.324982 lr 0.00120818 rank 0
2022-08-23 07:37:09,283 DEBUG TRAIN Batch 48/1100 loss 30.320198 loss_att 21.642860 loss_ctc 50.567314 loss_ctc_origin 39.276077 loss_ctc0 76.913528 lr 0.00120796 rank 0
2022-08-23 07:37:37,966 DEBUG TRAIN Batch 48/1200 loss 27.625278 loss_att 16.394440 loss_ctc 53.830566 loss_ctc_origin 44.002556 loss_ctc0 76.762589 lr 0.00120774 rank 0
2022-08-23 07:38:07,063 DEBUG TRAIN Batch 48/1300 loss 30.684242 loss_att 16.172613 loss_ctc 64.544708 loss_ctc_origin 54.257664 loss_ctc0 88.547798 lr 0.00120752 rank 0
2022-08-23 07:38:35,661 DEBUG TRAIN Batch 48/1400 loss 31.320877 loss_att 16.937277 loss_ctc 64.882614 loss_ctc_origin 49.103294 loss_ctc0 101.701027 lr 0.00120730 rank 0
2022-08-23 07:38:45,008 WARNING NaN or Inf found in input tensor.
2022-08-23 07:39:10,869 DEBUG TRAIN Batch 48/1500 loss 26.733570 loss_att 19.694729 loss_ctc 43.157532 loss_ctc_origin 37.665077 loss_ctc0 55.973255 lr 0.00120708 rank 0
2022-08-23 07:39:41,454 DEBUG TRAIN Batch 48/1600 loss 37.154305 loss_att 28.455338 loss_ctc 57.451897 loss_ctc_origin 44.346413 loss_ctc0 88.031357 lr 0.00120686 rank 0
2022-08-23 07:40:11,826 DEBUG TRAIN Batch 48/1700 loss 27.212172 loss_att 17.791279 loss_ctc 49.194256 loss_ctc_origin 39.876762 loss_ctc0 70.935074 lr 0.00120664 rank 0
2022-08-23 07:40:41,342 DEBUG TRAIN Batch 48/1800 loss 25.865883 loss_att 14.123439 loss_ctc 53.264915 loss_ctc_origin 39.553360 loss_ctc0 85.258537 lr 0.00120642 rank 0
2022-08-23 07:41:05,678 WARNING NaN or Inf found in input tensor.
2022-08-23 07:41:10,428 DEBUG TRAIN Batch 48/1900 loss 36.321861 loss_att 21.743153 loss_ctc 70.338852 loss_ctc_origin 55.572838 loss_ctc0 104.792885 lr 0.00120620 rank 0
2022-08-23 07:41:40,708 DEBUG TRAIN Batch 48/2000 loss 34.265446 loss_att 23.088762 loss_ctc 60.344368 loss_ctc_origin 41.269814 loss_ctc0 104.851669 lr 0.00120598 rank 0
2022-08-23 07:41:41,374 WARNING NaN or Inf found in input tensor.
2022-08-23 07:42:09,547 DEBUG TRAIN Batch 48/2100 loss 36.969925 loss_att 26.130812 loss_ctc 62.261177 loss_ctc_origin 46.333633 loss_ctc0 99.425446 lr 0.00120576 rank 0
2022-08-23 07:42:39,886 DEBUG TRAIN Batch 48/2200 loss 30.676025 loss_att 19.367615 loss_ctc 57.062309 loss_ctc_origin 48.581955 loss_ctc0 76.849800 lr 0.00120555 rank 0
2022-08-23 07:43:09,071 DEBUG TRAIN Batch 48/2300 loss 28.514942 loss_att 15.903114 loss_ctc 57.942535 loss_ctc_origin 47.036457 loss_ctc0 83.390053 lr 0.00120533 rank 0
2022-08-23 07:43:38,905 DEBUG TRAIN Batch 48/2400 loss 33.209213 loss_att 19.050146 loss_ctc 66.247032 loss_ctc_origin 50.070320 loss_ctc0 103.992691 lr 0.00120511 rank 0
2022-08-23 07:44:08,576 DEBUG TRAIN Batch 48/2500 loss 29.267046 loss_att 23.621941 loss_ctc 42.438957 loss_ctc_origin 37.810074 loss_ctc0 53.239693 lr 0.00120489 rank 0
2022-08-23 07:44:36,622 DEBUG TRAIN Batch 48/2600 loss 34.409061 loss_att 24.073544 loss_ctc 58.525269 loss_ctc_origin 39.407108 loss_ctc0 103.134308 lr 0.00120467 rank 0
2022-08-23 07:45:05,779 DEBUG TRAIN Batch 48/2700 loss 31.968992 loss_att 21.046524 loss_ctc 57.454750 loss_ctc_origin 48.795471 loss_ctc0 77.659737 lr 0.00120445 rank 0
2022-08-23 07:45:36,071 DEBUG TRAIN Batch 48/2800 loss 28.784260 loss_att 16.592823 loss_ctc 57.230949 loss_ctc_origin 46.236881 loss_ctc0 82.883774 lr 0.00120423 rank 0
2022-08-23 07:46:04,356 DEBUG TRAIN Batch 48/2900 loss 31.343334 loss_att 16.762894 loss_ctc 65.364365 loss_ctc_origin 51.210976 loss_ctc0 98.388939 lr 0.00120402 rank 0
2022-08-23 07:46:41,615 DEBUG TRAIN Batch 48/3000 loss 39.023457 loss_att 31.764898 loss_ctc 55.960094 loss_ctc_origin 48.135151 loss_ctc0 74.218292 lr 0.00120380 rank 0
2022-08-23 07:47:11,225 DEBUG TRAIN Batch 48/3100 loss 35.555717 loss_att 26.191563 loss_ctc 57.405411 loss_ctc_origin 45.232376 loss_ctc0 85.809158 lr 0.00120358 rank 0
2022-08-23 07:47:40,893 DEBUG TRAIN Batch 48/3200 loss 25.567652 loss_att 16.942135 loss_ctc 45.693855 loss_ctc_origin 36.645565 loss_ctc0 66.806534 lr 0.00120336 rank 0
2022-08-23 07:47:53,867 WARNING NaN or Inf found in input tensor.
2022-08-23 07:48:10,783 DEBUG TRAIN Batch 48/3300 loss 30.165121 loss_att 15.802191 loss_ctc 63.678627 loss_ctc_origin 51.975674 loss_ctc0 90.985519 lr 0.00120314 rank 0
2022-08-23 07:48:39,910 DEBUG TRAIN Batch 48/3400 loss 29.953800 loss_att 16.538012 loss_ctc 61.257309 loss_ctc_origin 48.138535 loss_ctc0 91.867790 lr 0.00120293 rank 0
2022-08-23 07:49:09,842 DEBUG TRAIN Batch 48/3500 loss 32.880150 loss_att 25.892849 loss_ctc 49.183846 loss_ctc_origin 40.024078 loss_ctc0 70.556633 lr 0.00120271 rank 0
2022-08-23 07:49:39,231 DEBUG TRAIN Batch 48/3600 loss 32.546837 loss_att 23.573462 loss_ctc 53.484711 loss_ctc_origin 41.339264 loss_ctc0 81.824089 lr 0.00120249 rank 0
2022-08-23 07:50:08,616 DEBUG TRAIN Batch 48/3700 loss 26.694553 loss_att 15.571442 loss_ctc 52.648476 loss_ctc_origin 43.273926 loss_ctc0 74.522430 lr 0.00120227 rank 0
2022-08-23 07:50:37,811 DEBUG TRAIN Batch 48/3800 loss 25.375935 loss_att 13.295210 loss_ctc 53.564293 loss_ctc_origin 41.699558 loss_ctc0 81.248672 lr 0.00120206 rank 0
2022-08-23 07:50:56,045 WARNING NaN or Inf found in input tensor.
2022-08-23 07:51:07,991 DEBUG TRAIN Batch 48/3900 loss 29.533493 loss_att 17.118858 loss_ctc 58.500965 loss_ctc_origin 42.286060 loss_ctc0 96.335739 lr 0.00120184 rank 0
2022-08-23 07:51:35,803 DEBUG TRAIN Batch 48/4000 loss 31.640743 loss_att 24.418964 loss_ctc 48.491562 loss_ctc_origin 41.083584 loss_ctc0 65.776833 lr 0.00120162 rank 0
2022-08-23 07:51:36,486 WARNING NaN or Inf found in input tensor.
2022-08-23 07:52:02,662 DEBUG TRAIN Batch 48/4100 loss 36.971985 loss_att 25.653627 loss_ctc 63.381485 loss_ctc_origin 46.329113 loss_ctc0 103.170349 lr 0.00120141 rank 0
2022-08-23 07:52:29,265 WARNING NaN or Inf found in input tensor.
2022-08-23 07:52:30,874 DEBUG TRAIN Batch 48/4200 loss 25.827667 loss_att 17.981445 loss_ctc 44.135521 loss_ctc_origin 35.672409 loss_ctc0 63.882774 lr 0.00120119 rank 0
2022-08-23 07:52:58,751 DEBUG TRAIN Batch 48/4300 loss 28.006874 loss_att 16.029762 loss_ctc 55.953461 loss_ctc_origin 43.739944 loss_ctc0 84.451668 lr 0.00120097 rank 0
2022-08-23 07:53:27,366 DEBUG TRAIN Batch 48/4400 loss 28.310549 loss_att 15.342978 loss_ctc 58.568214 loss_ctc_origin 43.771812 loss_ctc0 93.093155 lr 0.00120076 rank 0
2022-08-23 07:54:00,007 DEBUG TRAIN Batch 48/4500 loss 33.319939 loss_att 25.601749 loss_ctc 51.329048 loss_ctc_origin 41.702847 loss_ctc0 73.790184 lr 0.00120054 rank 0
2022-08-23 07:54:16,081 WARNING NaN or Inf found in input tensor.
2022-08-23 07:54:27,963 DEBUG TRAIN Batch 48/4600 loss 30.365654 loss_att 19.032097 loss_ctc 56.810616 loss_ctc_origin 41.429703 loss_ctc0 92.699402 lr 0.00120032 rank 0
2022-08-23 07:54:56,457 DEBUG TRAIN Batch 48/4700 loss 26.064705 loss_att 15.281933 loss_ctc 51.224510 loss_ctc_origin 40.841827 loss_ctc0 75.450775 lr 0.00120011 rank 0
2022-08-23 07:55:24,613 DEBUG TRAIN Batch 48/4800 loss 26.565042 loss_att 15.427683 loss_ctc 52.552216 loss_ctc_origin 40.573284 loss_ctc0 80.503059 lr 0.00119989 rank 0
2022-08-23 07:55:52,605 DEBUG TRAIN Batch 48/4900 loss 32.703800 loss_att 17.616171 loss_ctc 67.908264 loss_ctc_origin 54.802620 loss_ctc0 98.488113 lr 0.00119968 rank 0
2022-08-23 07:56:22,101 DEBUG TRAIN Batch 48/5000 loss 25.839149 loss_att 18.671492 loss_ctc 42.563686 loss_ctc_origin 39.373192 loss_ctc0 50.008175 lr 0.00119946 rank 0
2022-08-23 07:56:50,293 DEBUG TRAIN Batch 48/5100 loss 36.602661 loss_att 23.976137 loss_ctc 66.064537 loss_ctc_origin 39.227509 loss_ctc0 128.684265 lr 0.00119924 rank 0
2022-08-23 07:57:17,968 DEBUG TRAIN Batch 48/5200 loss 25.816730 loss_att 17.333958 loss_ctc 45.609871 loss_ctc_origin 34.996780 loss_ctc0 70.373749 lr 0.00119903 rank 0
2022-08-23 07:57:46,034 DEBUG TRAIN Batch 48/5300 loss 27.350948 loss_att 14.719751 loss_ctc 56.823738 loss_ctc_origin 46.551846 loss_ctc0 80.791481 lr 0.00119881 rank 0
2022-08-23 07:58:14,641 DEBUG TRAIN Batch 48/5400 loss 33.022644 loss_att 19.888145 loss_ctc 63.669807 loss_ctc_origin 49.792870 loss_ctc0 96.049339 lr 0.00119860 rank 0
2022-08-23 07:58:42,678 DEBUG TRAIN Batch 48/5500 loss 28.227394 loss_att 22.610487 loss_ctc 41.333511 loss_ctc_origin 32.953808 loss_ctc0 60.886147 lr 0.00119838 rank 0
2022-08-23 07:59:10,125 DEBUG TRAIN Batch 48/5600 loss 42.016563 loss_att 26.646969 loss_ctc 77.878952 loss_ctc_origin 50.083755 loss_ctc0 142.734390 lr 0.00119817 rank 0
2022-08-23 07:59:33,293 DEBUG CV Batch 48/0 loss 23.821011 loss_att 15.206988 loss_ctc 43.920395 loss_ctc_origin 26.890469 loss_ctc0 83.656891 history loss 22.419775 rank 0
2022-08-23 07:59:43,500 DEBUG CV Batch 48/100 loss 33.044300 loss_att 22.396687 loss_ctc 57.888729 loss_ctc_origin 35.558521 loss_ctc0 109.992538 history loss 33.156605 rank 0
2022-08-23 07:59:52,877 DEBUG CV Batch 48/200 loss 29.794340 loss_att 22.239923 loss_ctc 47.421310 loss_ctc_origin 35.850609 loss_ctc0 74.419601 history loss 34.904787 rank 0
2022-08-23 08:00:02,214 DEBUG CV Batch 48/300 loss 27.166874 loss_att 20.240795 loss_ctc 43.327728 loss_ctc_origin 29.208752 loss_ctc0 76.272003 history loss 33.983057 rank 0
2022-08-23 08:00:12,130 DEBUG CV Batch 48/400 loss 42.168262 loss_att 33.455662 loss_ctc 62.497665 loss_ctc_origin 45.863941 loss_ctc0 101.309692 history loss 32.095437 rank 0
2022-08-23 08:00:22,102 DEBUG CV Batch 48/500 loss 29.786242 loss_att 19.863668 loss_ctc 52.938911 loss_ctc_origin 32.001286 loss_ctc0 101.793365 history loss 31.670250 rank 0
2022-08-23 08:00:32,073 DEBUG CV Batch 48/600 loss 31.790180 loss_att 19.248440 loss_ctc 61.054237 loss_ctc_origin 34.894630 loss_ctc0 122.093323 history loss 31.565182 rank 0
2022-08-23 08:00:41,821 DEBUG CV Batch 48/700 loss 21.792934 loss_att 14.824468 loss_ctc 38.052685 loss_ctc_origin 25.568348 loss_ctc0 67.182808 history loss 31.214488 rank 0
2022-08-23 08:00:51,930 DEBUG CV Batch 48/800 loss 24.566990 loss_att 18.127823 loss_ctc 39.591713 loss_ctc_origin 24.783653 loss_ctc0 74.143860 history loss 31.099244 rank 0
2022-08-23 08:01:02,047 INFO Epoch 48 CV info cv_loss 31.085418335864087
2022-08-23 08:01:02,047 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/48.pt
2022-08-23 08:01:02,522 INFO Epoch 49 TRAIN info lr 0.0011979871557776848
2022-08-23 08:01:02,526 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 08:01:30,510 DEBUG TRAIN Batch 49/0 loss 33.583958 loss_att 25.323025 loss_ctc 52.859467 loss_ctc_origin 43.702293 loss_ctc0 74.226204 lr 0.00119798 rank 0
2022-08-23 08:02:00,673 DEBUG TRAIN Batch 49/100 loss 35.722504 loss_att 23.004726 loss_ctc 65.397308 loss_ctc_origin 41.263161 loss_ctc0 121.710297 lr 0.00119776 rank 0
2022-08-23 08:02:30,197 DEBUG TRAIN Batch 49/200 loss 23.245640 loss_att 14.692528 loss_ctc 43.202904 loss_ctc_origin 32.311962 loss_ctc0 68.615097 lr 0.00119755 rank 0
2022-08-23 08:03:00,167 DEBUG TRAIN Batch 49/300 loss 21.101002 loss_att 10.360891 loss_ctc 46.161259 loss_ctc_origin 33.143356 loss_ctc0 76.536362 lr 0.00119733 rank 0
2022-08-23 08:03:30,347 DEBUG TRAIN Batch 49/400 loss 35.800163 loss_att 20.847738 loss_ctc 70.689163 loss_ctc_origin 57.343521 loss_ctc0 101.829002 lr 0.00119712 rank 0
2022-08-23 08:04:00,439 DEBUG TRAIN Batch 49/500 loss 35.225441 loss_att 27.683901 loss_ctc 52.822372 loss_ctc_origin 45.447887 loss_ctc0 70.029510 lr 0.00119691 rank 0
2022-08-23 08:04:29,800 DEBUG TRAIN Batch 49/600 loss 32.885902 loss_att 20.045731 loss_ctc 62.846306 loss_ctc_origin 43.338200 loss_ctc0 108.365219 lr 0.00119669 rank 0
2022-08-23 08:04:59,051 DEBUG TRAIN Batch 49/700 loss 26.017197 loss_att 15.917717 loss_ctc 49.582649 loss_ctc_origin 39.978947 loss_ctc0 71.991287 lr 0.00119648 rank 0
2022-08-23 08:05:29,088 DEBUG TRAIN Batch 49/800 loss 27.309948 loss_att 15.814489 loss_ctc 54.132683 loss_ctc_origin 40.705452 loss_ctc0 85.462875 lr 0.00119626 rank 0
2022-08-23 08:05:53,704 WARNING NaN or Inf found in input tensor.
2022-08-23 08:05:58,261 DEBUG TRAIN Batch 49/900 loss 30.762199 loss_att 16.144119 loss_ctc 64.871048 loss_ctc_origin 49.337135 loss_ctc0 101.116852 lr 0.00119605 rank 0
2022-08-23 08:06:00,866 WARNING NaN or Inf found in input tensor.
2022-08-23 08:06:14,635 WARNING NaN or Inf found in input tensor.
2022-08-23 08:06:27,057 DEBUG TRAIN Batch 49/1000 loss 28.818871 loss_att 22.842941 loss_ctc 42.762707 loss_ctc_origin 41.390392 loss_ctc0 45.964771 lr 0.00119584 rank 0
2022-08-23 08:06:48,959 WARNING NaN or Inf found in input tensor.
2022-08-23 08:06:56,305 DEBUG TRAIN Batch 49/1100 loss 31.327141 loss_att 21.114531 loss_ctc 55.156563 loss_ctc_origin 35.463867 loss_ctc0 101.106186 lr 0.00119562 rank 0
2022-08-23 08:07:26,755 DEBUG TRAIN Batch 49/1200 loss 30.517982 loss_att 18.785479 loss_ctc 57.893822 loss_ctc_origin 48.810730 loss_ctc0 79.087700 lr 0.00119541 rank 0
2022-08-23 08:07:56,909 DEBUG TRAIN Batch 49/1300 loss 26.649967 loss_att 13.725311 loss_ctc 56.807499 loss_ctc_origin 44.709396 loss_ctc0 85.036400 lr 0.00119519 rank 0
2022-08-23 08:08:25,803 DEBUG TRAIN Batch 49/1400 loss 33.977135 loss_att 19.028217 loss_ctc 68.857933 loss_ctc_origin 54.383141 loss_ctc0 102.632446 lr 0.00119498 rank 0
2022-08-23 08:08:34,498 WARNING NaN or Inf found in input tensor.
2022-08-23 08:09:01,878 DEBUG TRAIN Batch 49/1500 loss 33.958504 loss_att 28.501036 loss_ctc 46.692585 loss_ctc_origin 41.462891 loss_ctc0 58.895203 lr 0.00119477 rank 0
2022-08-23 08:09:31,711 DEBUG TRAIN Batch 49/1600 loss 36.859283 loss_att 24.285542 loss_ctc 66.198013 loss_ctc_origin 41.653488 loss_ctc0 123.468567 lr 0.00119455 rank 0
2022-08-23 08:09:59,272 WARNING NaN or Inf found in input tensor.
2022-08-23 08:10:00,906 DEBUG TRAIN Batch 49/1700 loss 25.914728 loss_att 16.887505 loss_ctc 46.978249 loss_ctc_origin 36.972004 loss_ctc0 70.326157 lr 0.00119434 rank 0
2022-08-23 08:10:29,048 DEBUG TRAIN Batch 49/1800 loss 27.461536 loss_att 14.379318 loss_ctc 57.986717 loss_ctc_origin 44.500404 loss_ctc0 89.454773 lr 0.00119413 rank 0
2022-08-23 08:10:53,486 WARNING NaN or Inf found in input tensor.
2022-08-23 08:10:58,024 DEBUG TRAIN Batch 49/1900 loss 28.499874 loss_att 15.104303 loss_ctc 59.756207 loss_ctc_origin 44.009228 loss_ctc0 96.499153 lr 0.00119392 rank 0
2022-08-23 08:11:27,912 DEBUG TRAIN Batch 49/2000 loss 29.840666 loss_att 21.436474 loss_ctc 49.450447 loss_ctc_origin 38.725086 loss_ctc0 74.476295 lr 0.00119370 rank 0
2022-08-23 08:11:57,366 WARNING NaN or Inf found in input tensor.
2022-08-23 08:11:57,410 DEBUG TRAIN Batch 49/2100 loss nan loss_att 24.074450 loss_ctc nan loss_ctc_origin 44.896442 loss_ctc0 nan lr 0.00119349 rank 0
2022-08-23 08:12:18,132 WARNING NaN or Inf found in input tensor.
2022-08-23 08:12:26,814 DEBUG TRAIN Batch 49/2200 loss 25.848932 loss_att 16.000374 loss_ctc 48.828903 loss_ctc_origin 39.800068 loss_ctc0 69.896194 lr 0.00119328 rank 0
2022-08-23 08:12:57,670 DEBUG TRAIN Batch 49/2300 loss 25.455202 loss_att 13.781528 loss_ctc 52.693771 loss_ctc_origin 40.333405 loss_ctc0 81.534630 lr 0.00119307 rank 0
2022-08-23 08:13:27,082 DEBUG TRAIN Batch 49/2400 loss 34.383385 loss_att 18.005356 loss_ctc 72.598785 loss_ctc_origin 59.353966 loss_ctc0 103.503372 lr 0.00119285 rank 0
2022-08-23 08:13:57,236 DEBUG TRAIN Batch 49/2500 loss 30.808426 loss_att 25.856192 loss_ctc 42.363636 loss_ctc_origin 38.101685 loss_ctc0 52.308193 lr 0.00119264 rank 0
2022-08-23 08:14:12,092 WARNING NaN or Inf found in input tensor.
2022-08-23 08:14:26,542 DEBUG TRAIN Batch 49/2600 loss 36.308640 loss_att 24.332439 loss_ctc 64.253113 loss_ctc_origin 45.110874 loss_ctc0 108.918343 lr 0.00119243 rank 0
2022-08-23 08:14:56,316 DEBUG TRAIN Batch 49/2700 loss 21.276081 loss_att 12.354864 loss_ctc 42.092255 loss_ctc_origin 31.897287 loss_ctc0 65.880516 lr 0.00119222 rank 0
2022-08-23 08:15:07,906 WARNING NaN or Inf found in input tensor.
2022-08-23 08:15:24,660 DEBUG TRAIN Batch 49/2800 loss 27.723019 loss_att 16.222466 loss_ctc 54.557640 loss_ctc_origin 43.713074 loss_ctc0 79.861633 lr 0.00119201 rank 0
2022-08-23 08:15:55,264 DEBUG TRAIN Batch 49/2900 loss 28.312801 loss_att 14.549202 loss_ctc 60.427864 loss_ctc_origin 44.305016 loss_ctc0 98.047836 lr 0.00119179 rank 0
2022-08-23 08:16:32,292 DEBUG TRAIN Batch 49/3000 loss 34.534531 loss_att 27.041563 loss_ctc 52.018112 loss_ctc_origin 39.451450 loss_ctc0 81.340317 lr 0.00119158 rank 0
2022-08-23 08:17:01,455 DEBUG TRAIN Batch 49/3100 loss 35.063423 loss_att 22.460325 loss_ctc 64.470657 loss_ctc_origin 42.403984 loss_ctc0 115.959549 lr 0.00119137 rank 0
2022-08-23 08:17:30,064 DEBUG TRAIN Batch 49/3200 loss 28.362982 loss_att 19.186049 loss_ctc 49.775826 loss_ctc_origin 39.938118 loss_ctc0 72.730484 lr 0.00119116 rank 0
2022-08-23 08:17:59,018 DEBUG TRAIN Batch 49/3300 loss 25.942463 loss_att 14.296696 loss_ctc 53.115921 loss_ctc_origin 41.464699 loss_ctc0 80.302101 lr 0.00119095 rank 0
2022-08-23 08:18:28,467 DEBUG TRAIN Batch 49/3400 loss 31.877411 loss_att 17.402111 loss_ctc 65.653107 loss_ctc_origin 50.355400 loss_ctc0 101.347740 lr 0.00119074 rank 0
2022-08-23 08:18:58,459 DEBUG TRAIN Batch 49/3500 loss 28.034382 loss_att 21.869549 loss_ctc 42.418991 loss_ctc_origin 38.291992 loss_ctc0 52.048649 lr 0.00119053 rank 0
2022-08-23 08:19:28,347 DEBUG TRAIN Batch 49/3600 loss 31.058250 loss_att 19.792801 loss_ctc 57.344292 loss_ctc_origin 40.592392 loss_ctc0 96.432045 lr 0.00119032 rank 0
2022-08-23 08:19:56,123 DEBUG TRAIN Batch 49/3700 loss 28.920185 loss_att 19.899914 loss_ctc 49.967484 loss_ctc_origin 41.200188 loss_ctc0 70.424507 lr 0.00119011 rank 0
2022-08-23 08:20:26,284 DEBUG TRAIN Batch 49/3800 loss 26.055193 loss_att 15.885926 loss_ctc 49.783478 loss_ctc_origin 38.739376 loss_ctc0 75.553040 lr 0.00118989 rank 0
2022-08-23 08:20:56,333 DEBUG TRAIN Batch 49/3900 loss 34.645351 loss_att 20.210257 loss_ctc 68.327232 loss_ctc_origin 52.485771 loss_ctc0 105.290634 lr 0.00118968 rank 0
2022-08-23 08:21:27,126 DEBUG TRAIN Batch 49/4000 loss 29.434219 loss_att 22.411865 loss_ctc 45.819710 loss_ctc_origin 39.879044 loss_ctc0 59.681267 lr 0.00118947 rank 0
2022-08-23 08:21:55,191 DEBUG TRAIN Batch 49/4100 loss 46.404068 loss_att 30.568789 loss_ctc 83.353043 loss_ctc_origin 58.672550 loss_ctc0 140.940857 lr 0.00118926 rank 0
2022-08-23 08:22:26,056 DEBUG TRAIN Batch 49/4200 loss 23.918999 loss_att 14.692541 loss_ctc 45.447395 loss_ctc_origin 35.972675 loss_ctc0 67.555069 lr 0.00118905 rank 0
2022-08-23 08:22:56,009 DEBUG TRAIN Batch 49/4300 loss 28.732319 loss_att 15.020146 loss_ctc 60.727386 loss_ctc_origin 48.293655 loss_ctc0 89.739426 lr 0.00118884 rank 0
2022-08-23 08:23:24,940 DEBUG TRAIN Batch 49/4400 loss 31.868008 loss_att 18.504463 loss_ctc 63.049614 loss_ctc_origin 48.398766 loss_ctc0 97.234924 lr 0.00118863 rank 0
2022-08-23 08:24:01,494 DEBUG TRAIN Batch 49/4500 loss 24.154137 loss_att 20.978460 loss_ctc 31.564049 loss_ctc_origin 28.997429 loss_ctc0 37.552822 lr 0.00118842 rank 0
2022-08-23 08:24:16,832 WARNING NaN or Inf found in input tensor.
2022-08-23 08:24:30,907 DEBUG TRAIN Batch 49/4600 loss 49.148083 loss_att 33.999084 loss_ctc 84.495743 loss_ctc_origin 55.872265 loss_ctc0 151.283875 lr 0.00118821 rank 0
2022-08-23 08:25:00,004 DEBUG TRAIN Batch 49/4700 loss 26.917736 loss_att 17.337671 loss_ctc 49.271217 loss_ctc_origin 40.176319 loss_ctc0 70.492645 lr 0.00118800 rank 0
2022-08-23 08:25:29,759 DEBUG TRAIN Batch 49/4800 loss 26.057293 loss_att 14.502847 loss_ctc 53.017670 loss_ctc_origin 39.122299 loss_ctc0 85.440208 lr 0.00118779 rank 0
2022-08-23 08:25:58,639 DEBUG TRAIN Batch 49/4900 loss 29.646349 loss_att 15.524837 loss_ctc 62.596542 loss_ctc_origin 47.492943 loss_ctc0 97.838280 lr 0.00118758 rank 0
2022-08-23 08:26:27,449 DEBUG TRAIN Batch 49/5000 loss 30.688602 loss_att 23.162445 loss_ctc 48.249638 loss_ctc_origin 45.594650 loss_ctc0 54.444611 lr 0.00118738 rank 0
2022-08-23 08:26:56,576 DEBUG TRAIN Batch 49/5100 loss 31.842182 loss_att 19.509413 loss_ctc 60.618637 loss_ctc_origin 39.411057 loss_ctc0 110.102974 lr 0.00118717 rank 0
2022-08-23 08:27:24,929 DEBUG TRAIN Batch 49/5200 loss 26.688286 loss_att 17.384930 loss_ctc 48.396111 loss_ctc_origin 40.763081 loss_ctc0 66.206512 lr 0.00118696 rank 0
2022-08-23 08:27:54,888 DEBUG TRAIN Batch 49/5300 loss 28.471226 loss_att 15.862528 loss_ctc 57.891518 loss_ctc_origin 44.772892 loss_ctc0 88.501640 lr 0.00118675 rank 0
2022-08-23 08:28:24,893 DEBUG TRAIN Batch 49/5400 loss 31.019079 loss_att 17.408421 loss_ctc 62.777283 loss_ctc_origin 46.644653 loss_ctc0 100.420074 lr 0.00118654 rank 0
2022-08-23 08:28:54,744 DEBUG TRAIN Batch 49/5500 loss 25.777355 loss_att 21.143169 loss_ctc 36.590458 loss_ctc_origin 35.849365 loss_ctc0 38.319675 lr 0.00118633 rank 0
2022-08-23 08:29:22,632 DEBUG TRAIN Batch 49/5600 loss 32.374062 loss_att 22.129814 loss_ctc 56.277313 loss_ctc_origin 37.956570 loss_ctc0 99.025711 lr 0.00118612 rank 0
2022-08-23 08:29:46,493 DEBUG CV Batch 49/0 loss 22.247944 loss_att 13.090731 loss_ctc 43.614777 loss_ctc_origin 22.094524 loss_ctc0 93.828697 history loss 20.939241 rank 0
2022-08-23 08:29:57,823 DEBUG CV Batch 49/100 loss 33.692856 loss_att 20.772118 loss_ctc 63.841248 loss_ctc_origin 32.242378 loss_ctc0 137.571945 history loss 32.837127 rank 0
2022-08-23 08:30:08,227 DEBUG CV Batch 49/200 loss 28.884319 loss_att 22.094625 loss_ctc 44.726936 loss_ctc_origin 35.872185 loss_ctc0 65.388023 history loss 34.296972 rank 0
2022-08-23 08:30:18,629 DEBUG CV Batch 49/300 loss 27.097933 loss_att 20.200497 loss_ctc 43.191948 loss_ctc_origin 28.942570 loss_ctc0 76.440498 history loss 33.275967 rank 0
2022-08-23 08:30:29,634 DEBUG CV Batch 49/400 loss 42.185425 loss_att 32.784431 loss_ctc 64.121071 loss_ctc_origin 48.362755 loss_ctc0 100.890480 history loss 31.468767 rank 0
2022-08-23 08:30:41,145 DEBUG CV Batch 49/500 loss 25.690056 loss_att 16.047655 loss_ctc 48.188988 loss_ctc_origin 26.464846 loss_ctc0 98.878654 history loss 31.086209 rank 0
2022-08-23 08:30:52,228 DEBUG CV Batch 49/600 loss 28.703676 loss_att 16.255436 loss_ctc 57.749569 loss_ctc_origin 29.079454 loss_ctc0 124.646500 history loss 30.980545 rank 0
2022-08-23 08:31:02,903 DEBUG CV Batch 49/700 loss 21.894382 loss_att 15.018775 loss_ctc 37.937469 loss_ctc_origin 25.274961 loss_ctc0 67.483322 history loss 30.631294 rank 0
2022-08-23 08:31:13,844 DEBUG CV Batch 49/800 loss 25.350376 loss_att 18.866188 loss_ctc 40.480145 loss_ctc_origin 26.207664 loss_ctc0 73.782593 history loss 30.529317 rank 0
2022-08-23 08:31:24,557 INFO Epoch 49 CV info cv_loss 30.538297359114825
2022-08-23 08:31:24,558 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/49.pt
2022-08-23 08:31:25,024 INFO Epoch 50 TRAIN info lr 0.0011859467782747001
2022-08-23 08:31:25,027 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 08:31:52,340 DEBUG TRAIN Batch 50/0 loss 21.808943 loss_att 17.124352 loss_ctc 32.739655 loss_ctc_origin 27.214954 loss_ctc0 45.630623 lr 0.00118594 rank 0
2022-08-23 08:32:21,325 DEBUG TRAIN Batch 50/100 loss 42.624493 loss_att 28.615170 loss_ctc 75.312912 loss_ctc_origin 54.071247 loss_ctc0 124.876808 lr 0.00118573 rank 0
2022-08-23 08:32:50,469 DEBUG TRAIN Batch 50/200 loss 27.778027 loss_att 19.471193 loss_ctc 47.160637 loss_ctc_origin 38.810364 loss_ctc0 66.644615 lr 0.00118552 rank 0
2022-08-23 08:32:56,083 WARNING NaN or Inf found in input tensor.
2022-08-23 08:33:19,203 DEBUG TRAIN Batch 50/300 loss 22.971163 loss_att 11.996552 loss_ctc 48.578587 loss_ctc_origin 35.808483 loss_ctc0 78.375496 lr 0.00118531 rank 0
2022-08-23 08:33:48,114 DEBUG TRAIN Batch 50/400 loss 29.642265 loss_att 15.797795 loss_ctc 61.946030 loss_ctc_origin 46.905277 loss_ctc0 97.041107 lr 0.00118511 rank 0
2022-08-23 08:34:17,944 DEBUG TRAIN Batch 50/500 loss 35.701836 loss_att 29.878624 loss_ctc 49.289322 loss_ctc_origin 43.668079 loss_ctc0 62.405560 lr 0.00118490 rank 0
2022-08-23 08:34:25,918 WARNING NaN or Inf found in input tensor.
2022-08-23 08:34:47,122 DEBUG TRAIN Batch 50/600 loss 31.595659 loss_att 20.683249 loss_ctc 57.057953 loss_ctc_origin 39.710358 loss_ctc0 97.535675 lr 0.00118469 rank 0
2022-08-23 08:35:16,066 DEBUG TRAIN Batch 50/700 loss 29.913982 loss_att 18.923439 loss_ctc 55.558586 loss_ctc_origin 47.013187 loss_ctc0 75.497849 lr 0.00118448 rank 0
2022-08-23 08:35:44,379 DEBUG TRAIN Batch 50/800 loss 26.310520 loss_att 14.324533 loss_ctc 54.277824 loss_ctc_origin 43.570354 loss_ctc0 79.261917 lr 0.00118427 rank 0
2022-08-23 08:36:14,337 DEBUG TRAIN Batch 50/900 loss 32.905239 loss_att 17.151947 loss_ctc 69.662918 loss_ctc_origin 56.494270 loss_ctc0 100.389755 lr 0.00118407 rank 0
2022-08-23 08:36:43,383 DEBUG TRAIN Batch 50/1000 loss 25.963938 loss_att 21.420452 loss_ctc 36.565403 loss_ctc_origin 32.413780 loss_ctc0 46.252518 lr 0.00118386 rank 0
2022-08-23 08:37:13,150 DEBUG TRAIN Batch 50/1100 loss 42.593582 loss_att 26.159035 loss_ctc 80.940865 loss_ctc_origin 52.789780 loss_ctc0 146.626724 lr 0.00118365 rank 0
2022-08-23 08:37:41,446 DEBUG TRAIN Batch 50/1200 loss 29.711184 loss_att 19.656450 loss_ctc 53.172226 loss_ctc_origin 44.831242 loss_ctc0 72.634514 lr 0.00118344 rank 0
2022-08-23 08:38:10,470 DEBUG TRAIN Batch 50/1300 loss 31.080742 loss_att 16.887558 loss_ctc 64.198166 loss_ctc_origin 52.027031 loss_ctc0 92.597488 lr 0.00118324 rank 0
2022-08-23 08:38:40,650 DEBUG TRAIN Batch 50/1400 loss 29.765022 loss_att 15.809226 loss_ctc 62.328545 loss_ctc_origin 47.459019 loss_ctc0 97.024109 lr 0.00118303 rank 0
2022-08-23 08:39:16,323 DEBUG TRAIN Batch 50/1500 loss 29.668671 loss_att 24.154221 loss_ctc 42.535725 loss_ctc_origin 39.648193 loss_ctc0 49.273296 lr 0.00118282 rank 0
2022-08-23 08:39:45,507 DEBUG TRAIN Batch 50/1600 loss 34.829140 loss_att 21.215031 loss_ctc 66.595398 loss_ctc_origin 42.379642 loss_ctc0 123.098816 lr 0.00118262 rank 0
2022-08-23 08:39:58,561 WARNING NaN or Inf found in input tensor.
2022-08-23 08:40:14,535 DEBUG TRAIN Batch 50/1700 loss 26.512129 loss_att 17.652805 loss_ctc 47.183884 loss_ctc_origin 38.056229 loss_ctc0 68.481735 lr 0.00118241 rank 0
2022-08-23 08:40:43,639 DEBUG TRAIN Batch 50/1800 loss 23.491989 loss_att 12.759311 loss_ctc 48.534904 loss_ctc_origin 37.444942 loss_ctc0 74.411476 lr 0.00118220 rank 0
2022-08-23 08:41:12,746 DEBUG TRAIN Batch 50/1900 loss 27.878399 loss_att 13.782236 loss_ctc 60.769444 loss_ctc_origin 46.338444 loss_ctc0 94.441780 lr 0.00118200 rank 0
2022-08-23 08:41:42,585 DEBUG TRAIN Batch 50/2000 loss 33.319927 loss_att 26.548523 loss_ctc 49.119869 loss_ctc_origin 43.098362 loss_ctc0 63.170052 lr 0.00118179 rank 0
2022-08-23 08:42:12,406 DEBUG TRAIN Batch 50/2100 loss 52.551102 loss_att 33.196903 loss_ctc 97.710892 loss_ctc_origin 63.783234 loss_ctc0 176.875443 lr 0.00118158 rank 0
2022-08-23 08:42:41,863 DEBUG TRAIN Batch 50/2200 loss 22.821712 loss_att 14.234945 loss_ctc 42.857498 loss_ctc_origin 34.700111 loss_ctc0 61.891403 lr 0.00118138 rank 0
2022-08-23 08:43:01,265 WARNING NaN or Inf found in input tensor.
2022-08-23 08:43:11,285 DEBUG TRAIN Batch 50/2300 loss 25.829500 loss_att 13.818858 loss_ctc 53.854328 loss_ctc_origin 41.005650 loss_ctc0 83.834572 lr 0.00118117 rank 0
2022-08-23 08:43:41,842 DEBUG TRAIN Batch 50/2400 loss 34.659367 loss_att 20.984783 loss_ctc 66.566727 loss_ctc_origin 51.766533 loss_ctc0 101.100510 lr 0.00118097 rank 0
2022-08-23 08:44:12,398 DEBUG TRAIN Batch 50/2500 loss 22.121138 loss_att 17.939335 loss_ctc 31.878677 loss_ctc_origin 28.241716 loss_ctc0 40.364922 lr 0.00118076 rank 0
2022-08-23 08:44:40,166 DEBUG TRAIN Batch 50/2600 loss 40.289124 loss_att 24.219568 loss_ctc 77.784752 loss_ctc_origin 46.440872 loss_ctc0 150.920471 lr 0.00118055 rank 0
2022-08-23 08:45:10,057 DEBUG TRAIN Batch 50/2700 loss 23.506359 loss_att 14.721767 loss_ctc 44.003738 loss_ctc_origin 35.047375 loss_ctc0 64.901924 lr 0.00118035 rank 0
2022-08-23 08:45:21,954 WARNING NaN or Inf found in input tensor.
2022-08-23 08:45:38,171 DEBUG TRAIN Batch 50/2800 loss 31.576618 loss_att 17.887199 loss_ctc 63.518593 loss_ctc_origin 53.275383 loss_ctc0 87.419418 lr 0.00118014 rank 0
2022-08-23 08:46:05,778 DEBUG TRAIN Batch 50/2900 loss 28.316917 loss_att 15.481556 loss_ctc 58.266090 loss_ctc_origin 41.933567 loss_ctc0 96.375313 lr 0.00117994 rank 0
2022-08-23 08:46:15,505 WARNING NaN or Inf found in input tensor.
2022-08-23 08:46:41,374 DEBUG TRAIN Batch 50/3000 loss 34.987885 loss_att 28.475447 loss_ctc 50.183571 loss_ctc_origin 46.852245 loss_ctc0 57.956669 lr 0.00117973 rank 0
2022-08-23 08:47:09,777 DEBUG TRAIN Batch 50/3100 loss 41.488049 loss_att 25.652182 loss_ctc 78.438400 loss_ctc_origin 51.534790 loss_ctc0 141.213486 lr 0.00117953 rank 0
2022-08-23 08:47:38,251 DEBUG TRAIN Batch 50/3200 loss 26.649044 loss_att 14.587521 loss_ctc 54.792595 loss_ctc_origin 43.837498 loss_ctc0 80.354492 lr 0.00117932 rank 0
2022-08-23 08:48:05,359 DEBUG TRAIN Batch 50/3300 loss 30.194958 loss_att 17.378239 loss_ctc 60.100632 loss_ctc_origin 46.924683 loss_ctc0 90.844498 lr 0.00117912 rank 0
2022-08-23 08:48:33,631 DEBUG TRAIN Batch 50/3400 loss 28.840172 loss_att 15.846686 loss_ctc 59.158302 loss_ctc_origin 42.030987 loss_ctc0 99.122032 lr 0.00117891 rank 0
2022-08-23 08:49:03,440 DEBUG TRAIN Batch 50/3500 loss 31.405113 loss_att 25.448952 loss_ctc 45.302818 loss_ctc_origin 41.922798 loss_ctc0 53.189526 lr 0.00117871 rank 0
2022-08-23 08:49:31,625 DEBUG TRAIN Batch 50/3600 loss 40.321491 loss_att 27.154560 loss_ctc 71.044327 loss_ctc_origin 47.460430 loss_ctc0 126.073425 lr 0.00117850 rank 0
2022-08-23 08:49:59,105 DEBUG TRAIN Batch 50/3700 loss 23.942017 loss_att 15.343626 loss_ctc 44.004929 loss_ctc_origin 34.960876 loss_ctc0 65.107712 lr 0.00117830 rank 0
2022-08-23 08:50:27,678 DEBUG TRAIN Batch 50/3800 loss 26.654551 loss_att 14.391073 loss_ctc 55.269325 loss_ctc_origin 41.700672 loss_ctc0 86.929520 lr 0.00117809 rank 0
2022-08-23 08:50:56,064 DEBUG TRAIN Batch 50/3900 loss 28.437725 loss_att 14.716164 loss_ctc 60.454697 loss_ctc_origin 43.158501 loss_ctc0 100.812485 lr 0.00117789 rank 0
2022-08-23 08:51:23,919 DEBUG TRAIN Batch 50/4000 loss 29.073093 loss_att 22.935705 loss_ctc 43.393665 loss_ctc_origin 39.810677 loss_ctc0 51.753967 lr 0.00117769 rank 0
2022-08-23 08:51:38,257 WARNING NaN or Inf found in input tensor.
2022-08-23 08:51:51,759 DEBUG TRAIN Batch 50/4100 loss 40.352600 loss_att 24.257145 loss_ctc 77.908661 loss_ctc_origin 45.083176 loss_ctc0 154.501465 lr 0.00117748 rank 0
2022-08-23 08:52:18,395 WARNING NaN or Inf found in input tensor.
2022-08-23 08:52:19,888 DEBUG TRAIN Batch 50/4200 loss 23.809494 loss_att 13.991346 loss_ctc 46.718506 loss_ctc_origin 37.413120 loss_ctc0 68.431061 lr 0.00117728 rank 0
2022-08-23 08:52:48,231 DEBUG TRAIN Batch 50/4300 loss 28.209858 loss_att 15.742382 loss_ctc 57.300632 loss_ctc_origin 44.704407 loss_ctc0 86.691818 lr 0.00117707 rank 0
2022-08-23 08:53:05,396 WARNING NaN or Inf found in input tensor.
2022-08-23 08:53:16,731 DEBUG TRAIN Batch 50/4400 loss 33.744446 loss_att 18.669371 loss_ctc 68.919617 loss_ctc_origin 56.023727 loss_ctc0 99.010025 lr 0.00117687 rank 0
2022-08-23 08:53:25,136 WARNING NaN or Inf found in input tensor.
2022-08-23 08:53:50,260 DEBUG TRAIN Batch 50/4500 loss 28.759697 loss_att 22.757248 loss_ctc 42.765411 loss_ctc_origin 39.174973 loss_ctc0 51.143097 lr 0.00117667 rank 0
2022-08-23 08:54:18,289 DEBUG TRAIN Batch 50/4600 loss 41.835030 loss_att 28.089294 loss_ctc 73.908417 loss_ctc_origin 50.344975 loss_ctc0 128.889771 lr 0.00117646 rank 0
2022-08-23 08:54:45,696 DEBUG TRAIN Batch 50/4700 loss 24.904745 loss_att 15.788347 loss_ctc 46.176338 loss_ctc_origin 37.421402 loss_ctc0 66.604515 lr 0.00117626 rank 0
2022-08-23 08:55:14,492 DEBUG TRAIN Batch 50/4800 loss 27.262756 loss_att 14.529503 loss_ctc 56.973679 loss_ctc_origin 43.637081 loss_ctc0 88.092407 lr 0.00117606 rank 0
2022-08-23 08:55:42,351 DEBUG TRAIN Batch 50/4900 loss 28.448502 loss_att 15.171661 loss_ctc 59.427795 loss_ctc_origin 42.930710 loss_ctc0 97.920998 lr 0.00117585 rank 0
2022-08-23 08:55:44,262 WARNING NaN or Inf found in input tensor.
2022-08-23 08:56:10,087 DEBUG TRAIN Batch 50/5000 loss 28.782108 loss_att 23.586218 loss_ctc 40.905853 loss_ctc_origin 39.778709 loss_ctc0 43.535847 lr 0.00117565 rank 0
2022-08-23 08:56:37,733 DEBUG TRAIN Batch 50/5100 loss 34.385536 loss_att 24.134945 loss_ctc 58.303581 loss_ctc_origin 39.359089 loss_ctc0 102.507401 lr 0.00117545 rank 0
2022-08-23 08:57:05,654 DEBUG TRAIN Batch 50/5200 loss 29.525372 loss_att 18.279572 loss_ctc 55.765572 loss_ctc_origin 47.201878 loss_ctc0 75.747520 lr 0.00117524 rank 0
2022-08-23 08:57:33,432 DEBUG TRAIN Batch 50/5300 loss 32.382301 loss_att 18.496334 loss_ctc 64.782883 loss_ctc_origin 51.282478 loss_ctc0 96.283829 lr 0.00117504 rank 0
2022-08-23 08:58:01,448 DEBUG TRAIN Batch 50/5400 loss 35.956017 loss_att 21.201754 loss_ctc 70.382629 loss_ctc_origin 56.009712 loss_ctc0 103.919434 lr 0.00117484 rank 0
2022-08-23 08:58:29,723 DEBUG TRAIN Batch 50/5500 loss 28.649483 loss_att 24.439846 loss_ctc 38.471970 loss_ctc_origin 34.757824 loss_ctc0 47.138313 lr 0.00117463 rank 0
2022-08-23 08:58:56,599 DEBUG TRAIN Batch 50/5600 loss 35.357491 loss_att 23.894621 loss_ctc 62.104179 loss_ctc_origin 47.243256 loss_ctc0 96.779671 lr 0.00117443 rank 0
2022-08-23 08:59:19,560 DEBUG CV Batch 50/0 loss 22.260256 loss_att 13.430053 loss_ctc 42.864059 loss_ctc_origin 23.752106 loss_ctc0 87.458611 history loss 20.950829 rank 0
2022-08-23 08:59:30,127 DEBUG CV Batch 50/100 loss 32.235405 loss_att 23.024174 loss_ctc 53.728287 loss_ctc_origin 33.846252 loss_ctc0 100.119698 history loss 32.434679 rank 0
2022-08-23 08:59:39,793 DEBUG CV Batch 50/200 loss 27.339142 loss_att 21.085842 loss_ctc 41.930176 loss_ctc_origin 31.822470 loss_ctc0 65.514816 history loss 33.992961 rank 0
2022-08-23 08:59:49,642 DEBUG CV Batch 50/300 loss 25.939869 loss_att 19.006742 loss_ctc 42.117157 loss_ctc_origin 27.400146 loss_ctc0 76.456848 history loss 33.070580 rank 0
2022-08-23 09:00:00,269 DEBUG CV Batch 50/400 loss 41.334198 loss_att 32.446869 loss_ctc 62.071293 loss_ctc_origin 45.347267 loss_ctc0 101.094017 history loss 31.195554 rank 0
2022-08-23 09:00:10,801 DEBUG CV Batch 50/500 loss 26.276756 loss_att 18.878319 loss_ctc 43.539776 loss_ctc_origin 27.529026 loss_ctc0 80.898193 history loss 30.768931 rank 0
2022-08-23 09:00:21,133 DEBUG CV Batch 50/600 loss 22.725670 loss_att 14.930649 loss_ctc 40.914055 loss_ctc_origin 27.061729 loss_ctc0 73.236137 history loss 30.661572 rank 0
2022-08-23 09:00:31,018 DEBUG CV Batch 50/700 loss 22.304289 loss_att 15.782992 loss_ctc 37.520645 loss_ctc_origin 24.396812 loss_ctc0 68.142914 history loss 30.333651 rank 0
2022-08-23 09:00:41,245 DEBUG CV Batch 50/800 loss 25.266159 loss_att 18.697506 loss_ctc 40.593014 loss_ctc_origin 26.246338 loss_ctc0 74.068588 history loss 30.268740 rank 0
2022-08-23 09:00:51,564 INFO Epoch 50 CV info cv_loss 30.28545852355467
2022-08-23 09:00:51,564 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/50.pt
2022-08-23 09:00:52,028 INFO Epoch 51 TRAIN info lr 0.001174262288609797
2022-08-23 09:00:52,031 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 09:01:20,417 DEBUG TRAIN Batch 51/0 loss 25.849884 loss_att 18.852100 loss_ctc 42.178040 loss_ctc_origin 40.712318 loss_ctc0 45.598061 lr 0.00117425 rank 0
2022-08-23 09:01:49,208 DEBUG TRAIN Batch 51/100 loss 30.565588 loss_att 21.077236 loss_ctc 52.705074 loss_ctc_origin 38.543678 loss_ctc0 85.748329 lr 0.00117405 rank 0
2022-08-23 09:02:18,650 DEBUG TRAIN Batch 51/200 loss 26.773495 loss_att 15.078888 loss_ctc 54.060905 loss_ctc_origin 43.646183 loss_ctc0 78.361931 lr 0.00117385 rank 0
2022-08-23 09:02:47,820 DEBUG TRAIN Batch 51/300 loss 28.191835 loss_att 14.411367 loss_ctc 60.346256 loss_ctc_origin 47.227268 loss_ctc0 90.957230 lr 0.00117365 rank 0
2022-08-23 09:03:15,871 DEBUG TRAIN Batch 51/400 loss 30.652552 loss_att 16.069616 loss_ctc 64.679398 loss_ctc_origin 50.612003 loss_ctc0 97.503311 lr 0.00117345 rank 0
2022-08-23 09:03:44,022 DEBUG TRAIN Batch 51/500 loss 31.472342 loss_att 26.395954 loss_ctc 43.317245 loss_ctc_origin 38.659397 loss_ctc0 54.185555 lr 0.00117324 rank 0
2022-08-23 09:04:12,879 DEBUG TRAIN Batch 51/600 loss 29.327314 loss_att 19.176783 loss_ctc 53.011887 loss_ctc_origin 36.739998 loss_ctc0 90.979622 lr 0.00117304 rank 0
2022-08-23 09:04:41,236 DEBUG TRAIN Batch 51/700 loss 22.991892 loss_att 12.541348 loss_ctc 47.376495 loss_ctc_origin 37.186108 loss_ctc0 71.154060 lr 0.00117284 rank 0
2022-08-23 09:05:08,664 DEBUG TRAIN Batch 51/800 loss 27.390657 loss_att 15.504210 loss_ctc 55.125698 loss_ctc_origin 42.266296 loss_ctc0 85.130966 lr 0.00117264 rank 0
2022-08-23 09:05:36,372 DEBUG TRAIN Batch 51/900 loss 30.761095 loss_att 16.950949 loss_ctc 62.984772 loss_ctc_origin 49.653740 loss_ctc0 94.090500 lr 0.00117244 rank 0
2022-08-23 09:06:06,171 DEBUG TRAIN Batch 51/1000 loss 26.825119 loss_att 21.985703 loss_ctc 38.117088 loss_ctc_origin 34.930042 loss_ctc0 45.553528 lr 0.00117224 rank 0
2022-08-23 09:06:33,482 DEBUG TRAIN Batch 51/1100 loss 26.640570 loss_att 18.729113 loss_ctc 45.100636 loss_ctc_origin 36.179840 loss_ctc0 65.915825 lr 0.00117203 rank 0
2022-08-23 09:07:01,288 DEBUG TRAIN Batch 51/1200 loss 23.052694 loss_att 14.659512 loss_ctc 42.636787 loss_ctc_origin 33.139488 loss_ctc0 64.797150 lr 0.00117183 rank 0
2022-08-23 09:07:29,762 DEBUG TRAIN Batch 51/1300 loss 27.988064 loss_att 15.610867 loss_ctc 56.868187 loss_ctc_origin 42.917053 loss_ctc0 89.420830 lr 0.00117163 rank 0
2022-08-23 09:07:57,439 DEBUG TRAIN Batch 51/1400 loss 29.179995 loss_att 15.734463 loss_ctc 60.552902 loss_ctc_origin 44.775314 loss_ctc0 97.367271 lr 0.00117143 rank 0
2022-08-23 09:08:31,222 DEBUG TRAIN Batch 51/1500 loss 28.403791 loss_att 23.284296 loss_ctc 40.349277 loss_ctc_origin 37.266106 loss_ctc0 47.543350 lr 0.00117123 rank 0
2022-08-23 09:08:46,334 WARNING NaN or Inf found in input tensor.
2022-08-23 09:09:00,318 DEBUG TRAIN Batch 51/1600 loss 34.163857 loss_att 25.168949 loss_ctc 55.151970 loss_ctc_origin 41.130737 loss_ctc0 87.868172 lr 0.00117103 rank 0
2022-08-23 09:09:29,203 DEBUG TRAIN Batch 51/1700 loss 27.006004 loss_att 18.960976 loss_ctc 45.777733 loss_ctc_origin 36.330296 loss_ctc0 67.821754 lr 0.00117083 rank 0
2022-08-23 09:09:56,176 DEBUG TRAIN Batch 51/1800 loss 28.608719 loss_att 15.350709 loss_ctc 59.544075 loss_ctc_origin 46.694298 loss_ctc0 89.526886 lr 0.00117063 rank 0
2022-08-23 09:10:23,938 DEBUG TRAIN Batch 51/1900 loss 33.070721 loss_att 18.314827 loss_ctc 67.501137 loss_ctc_origin 51.589348 loss_ctc0 104.628654 lr 0.00117043 rank 0
2022-08-23 09:10:52,730 DEBUG TRAIN Batch 51/2000 loss 26.721428 loss_att 21.655436 loss_ctc 38.542076 loss_ctc_origin 35.474678 loss_ctc0 45.699341 lr 0.00117023 rank 0
2022-08-23 09:11:21,419 DEBUG TRAIN Batch 51/2100 loss 31.156883 loss_att 20.403543 loss_ctc 56.248009 loss_ctc_origin 45.197399 loss_ctc0 82.032761 lr 0.00117003 rank 0
2022-08-23 09:11:49,629 DEBUG TRAIN Batch 51/2200 loss 23.427027 loss_att 14.295291 loss_ctc 44.734409 loss_ctc_origin 33.743828 loss_ctc0 70.379097 lr 0.00116983 rank 0
2022-08-23 09:12:07,517 WARNING NaN or Inf found in input tensor.
2022-08-23 09:12:17,239 DEBUG TRAIN Batch 51/2300 loss 26.124153 loss_att 13.874096 loss_ctc 54.707623 loss_ctc_origin 42.976395 loss_ctc0 82.080490 lr 0.00116963 rank 0
2022-08-23 09:12:46,551 DEBUG TRAIN Batch 51/2400 loss 29.454838 loss_att 14.828100 loss_ctc 63.583885 loss_ctc_origin 48.471100 loss_ctc0 98.847061 lr 0.00116943 rank 0
2022-08-23 09:13:14,940 WARNING NaN or Inf found in input tensor.
2022-08-23 09:13:14,982 DEBUG TRAIN Batch 51/2500 loss inf loss_att 28.338638 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00116923 rank 0
2022-08-23 09:13:44,025 DEBUG TRAIN Batch 51/2600 loss 32.767593 loss_att 22.673470 loss_ctc 56.320549 loss_ctc_origin 45.075626 loss_ctc0 82.558693 lr 0.00116903 rank 0
2022-08-23 09:14:12,622 DEBUG TRAIN Batch 51/2700 loss 23.993732 loss_att 14.298401 loss_ctc 46.616173 loss_ctc_origin 35.854012 loss_ctc0 71.727890 lr 0.00116883 rank 0
2022-08-23 09:14:42,291 DEBUG TRAIN Batch 51/2800 loss 28.272339 loss_att 15.968087 loss_ctc 56.982262 loss_ctc_origin 44.947388 loss_ctc0 85.063629 lr 0.00116863 rank 0
2022-08-23 09:15:10,512 DEBUG TRAIN Batch 51/2900 loss 34.929611 loss_att 18.505564 loss_ctc 73.252380 loss_ctc_origin 60.331573 loss_ctc0 103.400940 lr 0.00116843 rank 0
2022-08-23 09:15:45,082 DEBUG TRAIN Batch 51/3000 loss 25.506159 loss_att 21.571217 loss_ctc 34.687691 loss_ctc_origin 31.799078 loss_ctc0 41.427795 lr 0.00116823 rank 0
2022-08-23 09:16:13,810 DEBUG TRAIN Batch 51/3100 loss 26.119812 loss_att 18.164062 loss_ctc 44.683228 loss_ctc_origin 34.030880 loss_ctc0 69.538712 lr 0.00116803 rank 0
2022-08-23 09:16:42,642 DEBUG TRAIN Batch 51/3200 loss 27.345234 loss_att 17.734409 loss_ctc 49.770493 loss_ctc_origin 42.036377 loss_ctc0 67.816772 lr 0.00116783 rank 0
2022-08-23 09:17:11,433 DEBUG TRAIN Batch 51/3300 loss 27.991333 loss_att 14.180248 loss_ctc 60.217194 loss_ctc_origin 45.836624 loss_ctc0 93.771851 lr 0.00116763 rank 0
2022-08-23 09:17:40,219 DEBUG TRAIN Batch 51/3400 loss 37.672249 loss_att 19.878448 loss_ctc 79.191116 loss_ctc_origin 59.203430 loss_ctc0 125.829025 lr 0.00116743 rank 0
2022-08-23 09:18:09,594 DEBUG TRAIN Batch 51/3500 loss 29.052946 loss_att 24.257160 loss_ctc 40.243114 loss_ctc_origin 37.010113 loss_ctc0 47.786789 lr 0.00116723 rank 0
2022-08-23 09:18:37,333 DEBUG TRAIN Batch 51/3600 loss 26.113049 loss_att 19.166389 loss_ctc 42.321915 loss_ctc_origin 34.360203 loss_ctc0 60.899242 lr 0.00116704 rank 0
2022-08-23 09:19:06,579 DEBUG TRAIN Batch 51/3700 loss 23.953672 loss_att 15.024997 loss_ctc 44.787247 loss_ctc_origin 33.968742 loss_ctc0 70.030411 lr 0.00116684 rank 0
2022-08-23 09:19:24,586 WARNING NaN or Inf found in input tensor.
2022-08-23 09:19:34,785 DEBUG TRAIN Batch 51/3800 loss 22.041031 loss_att 11.745103 loss_ctc 46.064857 loss_ctc_origin 33.983540 loss_ctc0 74.254608 lr 0.00116664 rank 0
2022-08-23 09:20:03,591 DEBUG TRAIN Batch 51/3900 loss 29.956011 loss_att 16.220303 loss_ctc 62.005997 loss_ctc_origin 46.202271 loss_ctc0 98.881363 lr 0.00116644 rank 0
2022-08-23 09:20:32,749 DEBUG TRAIN Batch 51/4000 loss 28.631836 loss_att 23.448025 loss_ctc 40.727402 loss_ctc_origin 38.092407 loss_ctc0 46.875717 lr 0.00116624 rank 0
2022-08-23 09:21:00,531 DEBUG TRAIN Batch 51/4100 loss 28.550701 loss_att 20.860605 loss_ctc 46.494259 loss_ctc_origin 36.514282 loss_ctc0 69.780869 lr 0.00116604 rank 0
2022-08-23 09:21:28,282 DEBUG TRAIN Batch 51/4200 loss 24.373245 loss_att 13.314026 loss_ctc 50.178093 loss_ctc_origin 39.126480 loss_ctc0 75.965195 lr 0.00116584 rank 0
2022-08-23 09:21:55,602 DEBUG TRAIN Batch 51/4300 loss 24.500355 loss_att 12.899530 loss_ctc 51.568947 loss_ctc_origin 39.401180 loss_ctc0 79.960396 lr 0.00116565 rank 0
2022-08-23 09:22:23,275 DEBUG TRAIN Batch 51/4400 loss 28.692974 loss_att 14.402484 loss_ctc 62.037449 loss_ctc_origin 43.819908 loss_ctc0 104.545044 lr 0.00116545 rank 0
2022-08-23 09:22:57,920 DEBUG TRAIN Batch 51/4500 loss 32.555550 loss_att 25.866474 loss_ctc 48.163391 loss_ctc_origin 45.569107 loss_ctc0 54.216728 lr 0.00116525 rank 0
2022-08-23 09:23:27,121 DEBUG TRAIN Batch 51/4600 loss 21.271196 loss_att 14.452477 loss_ctc 37.181541 loss_ctc_origin 28.613249 loss_ctc0 57.174217 lr 0.00116505 rank 0
2022-08-23 09:23:55,710 DEBUG TRAIN Batch 51/4700 loss 25.686054 loss_att 15.468161 loss_ctc 49.527809 loss_ctc_origin 39.158192 loss_ctc0 73.723572 lr 0.00116486 rank 0
2022-08-23 09:24:25,026 DEBUG TRAIN Batch 51/4800 loss 29.658482 loss_att 16.038406 loss_ctc 61.438660 loss_ctc_origin 48.750580 loss_ctc0 91.044174 lr 0.00116466 rank 0
2022-08-23 09:24:54,046 DEBUG TRAIN Batch 51/4900 loss 29.759773 loss_att 15.395102 loss_ctc 63.277336 loss_ctc_origin 45.767193 loss_ctc0 104.134338 lr 0.00116446 rank 0
2022-08-23 09:25:23,214 DEBUG TRAIN Batch 51/5000 loss 25.094112 loss_att 19.171822 loss_ctc 38.912788 loss_ctc_origin 34.787384 loss_ctc0 48.538727 lr 0.00116426 rank 0
2022-08-23 09:25:51,502 DEBUG TRAIN Batch 51/5100 loss 24.802547 loss_att 19.011879 loss_ctc 38.314102 loss_ctc_origin 29.287445 loss_ctc0 59.376297 lr 0.00116407 rank 0
2022-08-23 09:26:20,377 DEBUG TRAIN Batch 51/5200 loss 29.183426 loss_att 18.468548 loss_ctc 54.184807 loss_ctc_origin 43.988655 loss_ctc0 77.975830 lr 0.00116387 rank 0
2022-08-23 09:26:48,637 DEBUG TRAIN Batch 51/5300 loss 21.678625 loss_att 12.358843 loss_ctc 43.424782 loss_ctc_origin 30.051195 loss_ctc0 74.629807 lr 0.00116367 rank 0
2022-08-23 09:27:18,699 DEBUG TRAIN Batch 51/5400 loss 29.369743 loss_att 15.773041 loss_ctc 61.095379 loss_ctc_origin 42.494202 loss_ctc0 104.498123 lr 0.00116348 rank 0
2022-08-23 09:27:47,585 DEBUG TRAIN Batch 51/5500 loss 31.740280 loss_att 25.617153 loss_ctc 46.027580 loss_ctc_origin 40.152630 loss_ctc0 59.735790 lr 0.00116328 rank 0
2022-08-23 09:28:16,475 DEBUG TRAIN Batch 51/5600 loss 33.465748 loss_att 25.240925 loss_ctc 52.656994 loss_ctc_origin 46.010849 loss_ctc0 68.164673 lr 0.00116308 rank 0
2022-08-23 09:28:39,720 DEBUG CV Batch 51/0 loss 14.745834 loss_att 11.069556 loss_ctc 23.323818 loss_ctc_origin 17.896021 loss_ctc0 35.988678 history loss 13.878432 rank 0
2022-08-23 09:28:50,579 DEBUG CV Batch 51/100 loss 26.630671 loss_att 19.604641 loss_ctc 43.024738 loss_ctc_origin 30.308128 loss_ctc0 72.696831 history loss 31.130926 rank 0
2022-08-23 09:29:00,378 DEBUG CV Batch 51/200 loss 28.831930 loss_att 22.456131 loss_ctc 43.708794 loss_ctc_origin 33.647331 loss_ctc0 67.185532 history loss 32.408118 rank 0
2022-08-23 09:29:10,657 DEBUG CV Batch 51/300 loss 26.400948 loss_att 19.753349 loss_ctc 41.912014 loss_ctc_origin 26.252583 loss_ctc0 78.450684 history loss 31.336444 rank 0
2022-08-23 09:29:21,583 DEBUG CV Batch 51/400 loss 41.465282 loss_att 32.680714 loss_ctc 61.962608 loss_ctc_origin 44.592999 loss_ctc0 102.491692 history loss 29.497883 rank 0
2022-08-23 09:29:32,629 DEBUG CV Batch 51/500 loss 19.567738 loss_att 14.508176 loss_ctc 31.373386 loss_ctc_origin 24.910269 loss_ctc0 46.453991 history loss 29.144885 rank 0
2022-08-23 09:29:43,294 DEBUG CV Batch 51/600 loss 19.779530 loss_att 13.341003 loss_ctc 34.802757 loss_ctc_origin 23.440031 loss_ctc0 61.315777 history loss 28.956093 rank 0
2022-08-23 09:29:53,430 DEBUG CV Batch 51/700 loss 22.116676 loss_att 15.052044 loss_ctc 38.600815 loss_ctc_origin 25.653957 loss_ctc0 68.810143 history loss 28.620698 rank 0
2022-08-23 09:30:04,189 DEBUG CV Batch 51/800 loss 26.080715 loss_att 19.673777 loss_ctc 41.030235 loss_ctc_origin 26.457260 loss_ctc0 75.033844 history loss 28.565226 rank 0
2022-08-23 09:30:14,454 INFO Epoch 51 CV info cv_loss 28.657305605306522
2022-08-23 09:30:14,454 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/51.pt
2022-08-23 09:30:14,898 INFO Epoch 52 TRAIN info lr 0.0011629164931740753
2022-08-23 09:30:14,902 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 09:30:42,075 DEBUG TRAIN Batch 52/0 loss 29.025503 loss_att 23.109381 loss_ctc 42.829784 loss_ctc_origin 39.733303 loss_ctc0 50.054909 lr 0.00116291 rank 0
2022-08-23 09:31:10,870 DEBUG TRAIN Batch 52/100 loss 29.279272 loss_att 20.509605 loss_ctc 49.741825 loss_ctc_origin 38.422173 loss_ctc0 76.154343 lr 0.00116271 rank 0
2022-08-23 09:31:39,633 DEBUG TRAIN Batch 52/200 loss 21.883045 loss_att 12.936609 loss_ctc 42.758064 loss_ctc_origin 33.235180 loss_ctc0 64.978119 lr 0.00116252 rank 0
2022-08-23 09:32:07,681 DEBUG TRAIN Batch 52/300 loss 24.805775 loss_att 12.152715 loss_ctc 54.329582 loss_ctc_origin 41.898010 loss_ctc0 83.336578 lr 0.00116232 rank 0
2022-08-23 09:32:18,802 WARNING NaN or Inf found in input tensor.
2022-08-23 09:32:36,410 DEBUG TRAIN Batch 52/400 loss 29.350109 loss_att 16.320623 loss_ctc 59.752239 loss_ctc_origin 43.492439 loss_ctc0 97.691765 lr 0.00116212 rank 0
2022-08-23 09:33:05,081 DEBUG TRAIN Batch 52/500 loss 24.091949 loss_att 17.175270 loss_ctc 40.230869 loss_ctc_origin 37.319572 loss_ctc0 47.023888 lr 0.00116193 rank 0
2022-08-23 09:33:34,222 DEBUG TRAIN Batch 52/600 loss 30.775757 loss_att 23.065989 loss_ctc 48.765217 loss_ctc_origin 41.424210 loss_ctc0 65.894234 lr 0.00116173 rank 0
2022-08-23 09:34:02,997 DEBUG TRAIN Batch 52/700 loss 16.529163 loss_att 9.416485 loss_ctc 33.125408 loss_ctc_origin 21.983227 loss_ctc0 59.123825 lr 0.00116153 rank 0
2022-08-23 09:34:31,084 DEBUG TRAIN Batch 52/800 loss 24.685329 loss_att 13.236702 loss_ctc 51.398796 loss_ctc_origin 38.202255 loss_ctc0 82.190720 lr 0.00116134 rank 0
2022-08-23 09:34:59,965 DEBUG TRAIN Batch 52/900 loss 33.137878 loss_att 17.576935 loss_ctc 69.446747 loss_ctc_origin 53.520126 loss_ctc0 106.608871 lr 0.00116114 rank 0
2022-08-23 09:35:29,900 DEBUG TRAIN Batch 52/1000 loss 27.930874 loss_att 21.814362 loss_ctc 42.202736 loss_ctc_origin 39.556999 loss_ctc0 48.376114 lr 0.00116095 rank 0
2022-08-23 09:35:58,472 DEBUG TRAIN Batch 52/1100 loss 32.020691 loss_att 21.829334 loss_ctc 55.800518 loss_ctc_origin 42.606598 loss_ctc0 86.586334 lr 0.00116075 rank 0
2022-08-23 09:36:26,446 DEBUG TRAIN Batch 52/1200 loss 25.632179 loss_att 16.987932 loss_ctc 45.802094 loss_ctc_origin 35.197060 loss_ctc0 70.547180 lr 0.00116056 rank 0
2022-08-23 09:36:55,614 DEBUG TRAIN Batch 52/1300 loss 28.655231 loss_att 15.851805 loss_ctc 58.529892 loss_ctc_origin 45.924431 loss_ctc0 87.942619 lr 0.00116036 rank 0
2022-08-23 09:37:24,275 DEBUG TRAIN Batch 52/1400 loss 29.259827 loss_att 16.502663 loss_ctc 59.026535 loss_ctc_origin 43.206009 loss_ctc0 95.941101 lr 0.00116017 rank 0
2022-08-23 09:37:59,455 DEBUG TRAIN Batch 52/1500 loss 26.075424 loss_att 21.697100 loss_ctc 36.291512 loss_ctc_origin 33.715622 loss_ctc0 42.301926 lr 0.00115997 rank 0
2022-08-23 09:38:27,745 DEBUG TRAIN Batch 52/1600 loss 27.425930 loss_att 19.331211 loss_ctc 46.313602 loss_ctc_origin 35.555851 loss_ctc0 71.415024 lr 0.00115978 rank 0
2022-08-23 09:38:56,070 DEBUG TRAIN Batch 52/1700 loss 28.958618 loss_att 18.123917 loss_ctc 54.239586 loss_ctc_origin 46.065262 loss_ctc0 73.313019 lr 0.00115958 rank 0
2022-08-23 09:39:23,897 DEBUG TRAIN Batch 52/1800 loss 27.982008 loss_att 16.236361 loss_ctc 55.388515 loss_ctc_origin 44.349915 loss_ctc0 81.145248 lr 0.00115939 rank 0
2022-08-23 09:39:52,426 DEBUG TRAIN Batch 52/1900 loss 29.854321 loss_att 15.895818 loss_ctc 62.424164 loss_ctc_origin 45.579185 loss_ctc0 101.729111 lr 0.00115919 rank 0
2022-08-23 09:40:22,457 DEBUG TRAIN Batch 52/2000 loss 26.561306 loss_att 22.259583 loss_ctc 36.598660 loss_ctc_origin 34.476940 loss_ctc0 41.549339 lr 0.00115900 rank 0
2022-08-23 09:40:51,794 DEBUG TRAIN Batch 52/2100 loss 35.327381 loss_att 21.335911 loss_ctc 67.974144 loss_ctc_origin 41.011543 loss_ctc0 130.886871 lr 0.00115880 rank 0
2022-08-23 09:41:20,742 DEBUG TRAIN Batch 52/2200 loss 25.261780 loss_att 16.339951 loss_ctc 46.079376 loss_ctc_origin 36.631187 loss_ctc0 68.125153 lr 0.00115861 rank 0
2022-08-23 09:41:45,155 WARNING NaN or Inf found in input tensor.
2022-08-23 09:41:48,403 DEBUG TRAIN Batch 52/2300 loss 28.261623 loss_att 14.652700 loss_ctc 60.015778 loss_ctc_origin 49.309391 loss_ctc0 84.997337 lr 0.00115841 rank 0
2022-08-23 09:42:17,576 DEBUG TRAIN Batch 52/2400 loss 30.282745 loss_att 17.438606 loss_ctc 60.252403 loss_ctc_origin 45.861130 loss_ctc0 93.832031 lr 0.00115822 rank 0
2022-08-23 09:42:46,176 DEBUG TRAIN Batch 52/2500 loss 38.964893 loss_att 30.576567 loss_ctc 58.537651 loss_ctc_origin 44.145580 loss_ctc0 92.119141 lr 0.00115802 rank 0
2022-08-23 09:43:14,976 DEBUG TRAIN Batch 52/2600 loss 46.630943 loss_att 30.871265 loss_ctc 83.403511 loss_ctc_origin 59.293114 loss_ctc0 139.661102 lr 0.00115783 rank 0
2022-08-23 09:43:43,192 DEBUG TRAIN Batch 52/2700 loss 27.446810 loss_att 17.866329 loss_ctc 49.801262 loss_ctc_origin 42.005096 loss_ctc0 67.992310 lr 0.00115764 rank 0
2022-08-23 09:44:11,211 DEBUG TRAIN Batch 52/2800 loss 30.425877 loss_att 17.039993 loss_ctc 61.659607 loss_ctc_origin 49.738304 loss_ctc0 89.475975 lr 0.00115744 rank 0
2022-08-23 09:44:40,911 DEBUG TRAIN Batch 52/2900 loss 31.455727 loss_att 17.439159 loss_ctc 64.161041 loss_ctc_origin 47.338673 loss_ctc0 103.413231 lr 0.00115725 rank 0
2022-08-23 09:45:17,016 DEBUG TRAIN Batch 52/3000 loss 27.077953 loss_att 21.698080 loss_ctc 39.630989 loss_ctc_origin 38.265209 loss_ctc0 42.817810 lr 0.00115706 rank 0
2022-08-23 09:45:46,397 DEBUG TRAIN Batch 52/3100 loss 38.518883 loss_att 24.836561 loss_ctc 70.444290 loss_ctc_origin 44.496254 loss_ctc0 130.989716 lr 0.00115686 rank 0
2022-08-23 09:46:14,954 DEBUG TRAIN Batch 52/3200 loss 28.121037 loss_att 16.175259 loss_ctc 55.994522 loss_ctc_origin 45.850060 loss_ctc0 79.664948 lr 0.00115667 rank 0
2022-08-23 09:46:43,369 DEBUG TRAIN Batch 52/3300 loss 23.343544 loss_att 13.261816 loss_ctc 46.867577 loss_ctc_origin 34.100060 loss_ctc0 76.658447 lr 0.00115648 rank 0
2022-08-23 09:47:11,485 DEBUG TRAIN Batch 52/3400 loss 27.096916 loss_att 13.375426 loss_ctc 59.113724 loss_ctc_origin 42.113445 loss_ctc0 98.781029 lr 0.00115628 rank 0
2022-08-23 09:47:41,496 DEBUG TRAIN Batch 52/3500 loss 25.214283 loss_att 20.655163 loss_ctc 35.852230 loss_ctc_origin 30.697985 loss_ctc0 47.878799 lr 0.00115609 rank 0
2022-08-23 09:48:09,664 DEBUG TRAIN Batch 52/3600 loss 42.205490 loss_att 27.207369 loss_ctc 77.201111 loss_ctc_origin 51.783562 loss_ctc0 136.508728 lr 0.00115590 rank 0
2022-08-23 09:48:38,604 DEBUG TRAIN Batch 52/3700 loss 23.662868 loss_att 14.586852 loss_ctc 44.840240 loss_ctc_origin 34.640663 loss_ctc0 68.639244 lr 0.00115570 rank 0
2022-08-23 09:49:06,826 DEBUG TRAIN Batch 52/3800 loss 23.794815 loss_att 13.035830 loss_ctc 48.899117 loss_ctc_origin 37.762581 loss_ctc0 74.884369 lr 0.00115551 rank 0
2022-08-23 09:49:35,286 DEBUG TRAIN Batch 52/3900 loss 28.234795 loss_att 14.462517 loss_ctc 60.370110 loss_ctc_origin 45.171654 loss_ctc0 95.833168 lr 0.00115532 rank 0
2022-08-23 09:50:03,340 DEBUG TRAIN Batch 52/4000 loss 32.073692 loss_att 27.557724 loss_ctc 42.610947 loss_ctc_origin 40.293442 loss_ctc0 48.018456 lr 0.00115512 rank 0
2022-08-23 09:50:32,187 DEBUG TRAIN Batch 52/4100 loss 33.249176 loss_att 21.971640 loss_ctc 59.563416 loss_ctc_origin 42.448341 loss_ctc0 99.498581 lr 0.00115493 rank 0
2022-08-23 09:51:00,472 DEBUG TRAIN Batch 52/4200 loss 23.559376 loss_att 14.200409 loss_ctc 45.396965 loss_ctc_origin 35.609081 loss_ctc0 68.235352 lr 0.00115474 rank 0
2022-08-23 09:51:29,755 DEBUG TRAIN Batch 52/4300 loss 28.442493 loss_att 15.316063 loss_ctc 59.070824 loss_ctc_origin 45.048988 loss_ctc0 91.788437 lr 0.00115455 rank 0
2022-08-23 09:51:58,572 DEBUG TRAIN Batch 52/4400 loss 32.052246 loss_att 17.907379 loss_ctc 65.056931 loss_ctc_origin 49.174976 loss_ctc0 102.114838 lr 0.00115435 rank 0
2022-08-23 09:52:32,752 DEBUG TRAIN Batch 52/4500 loss 31.018177 loss_att 26.046764 loss_ctc 42.618141 loss_ctc_origin 37.408684 loss_ctc0 54.773529 lr 0.00115416 rank 0
2022-08-23 09:52:40,491 WARNING NaN or Inf found in input tensor.
2022-08-23 09:53:01,711 DEBUG TRAIN Batch 52/4600 loss 43.749146 loss_att 28.719025 loss_ctc 78.819420 loss_ctc_origin 55.887505 loss_ctc0 132.327209 lr 0.00115397 rank 0
2022-08-23 09:53:30,115 DEBUG TRAIN Batch 52/4700 loss 28.169140 loss_att 19.897480 loss_ctc 47.469673 loss_ctc_origin 39.004715 loss_ctc0 67.221230 lr 0.00115378 rank 0
2022-08-23 09:53:58,113 DEBUG TRAIN Batch 52/4800 loss 24.382723 loss_att 12.701136 loss_ctc 51.639759 loss_ctc_origin 37.356895 loss_ctc0 84.966438 lr 0.00115359 rank 0
2022-08-23 09:54:21,791 WARNING NaN or Inf found in input tensor.
2022-08-23 09:54:26,335 DEBUG TRAIN Batch 52/4900 loss 32.768181 loss_att 17.736256 loss_ctc 67.842667 loss_ctc_origin 54.433533 loss_ctc0 99.130638 lr 0.00115339 rank 0
2022-08-23 09:54:55,529 DEBUG TRAIN Batch 52/5000 loss 31.058662 loss_att 22.434147 loss_ctc 51.182529 loss_ctc_origin 38.467422 loss_ctc0 80.851112 lr 0.00115320 rank 0
2022-08-23 09:55:24,483 DEBUG TRAIN Batch 52/5100 loss 34.174305 loss_att 20.493694 loss_ctc 66.095734 loss_ctc_origin 42.287117 loss_ctc0 121.649170 lr 0.00115301 rank 0
2022-08-23 09:55:53,510 DEBUG TRAIN Batch 52/5200 loss 26.609045 loss_att 15.493687 loss_ctc 52.544880 loss_ctc_origin 43.791462 loss_ctc0 72.969521 lr 0.00115282 rank 0
2022-08-23 09:56:22,663 DEBUG TRAIN Batch 52/5300 loss 26.446419 loss_att 13.685318 loss_ctc 56.222321 loss_ctc_origin 44.179535 loss_ctc0 84.322151 lr 0.00115263 rank 0
2022-08-23 09:56:51,014 DEBUG TRAIN Batch 52/5400 loss 32.162289 loss_att 18.442659 loss_ctc 64.174751 loss_ctc_origin 50.585224 loss_ctc0 95.883636 lr 0.00115244 rank 0
2022-08-23 09:57:19,817 DEBUG TRAIN Batch 52/5500 loss 31.905256 loss_att 22.670319 loss_ctc 53.453445 loss_ctc_origin 40.649384 loss_ctc0 83.329582 lr 0.00115225 rank 0
2022-08-23 09:57:47,642 DEBUG TRAIN Batch 52/5600 loss 32.508160 loss_att 21.697937 loss_ctc 57.732006 loss_ctc_origin 43.476837 loss_ctc0 90.994064 lr 0.00115205 rank 0
2022-08-23 09:58:11,027 DEBUG CV Batch 52/0 loss 23.585897 loss_att 14.513985 loss_ctc 44.753693 loss_ctc_origin 24.942398 loss_ctc0 90.980042 history loss 22.198492 rank 0
2022-08-23 09:58:22,268 DEBUG CV Batch 52/100 loss 36.058716 loss_att 23.824646 loss_ctc 64.604874 loss_ctc_origin 35.314648 loss_ctc0 132.948715 history loss 33.160395 rank 0
2022-08-23 09:58:32,142 DEBUG CV Batch 52/200 loss 30.460306 loss_att 22.949823 loss_ctc 47.984764 loss_ctc_origin 35.896858 loss_ctc0 76.189880 history loss 35.129863 rank 0
2022-08-23 09:58:42,318 DEBUG CV Batch 52/300 loss 27.689213 loss_att 20.532242 loss_ctc 44.388809 loss_ctc_origin 29.909752 loss_ctc0 78.173279 history loss 34.246184 rank 0
2022-08-23 09:58:53,400 DEBUG CV Batch 52/400 loss 41.369751 loss_att 33.036118 loss_ctc 60.814888 loss_ctc_origin 43.540562 loss_ctc0 101.121643 history loss 32.426271 rank 0
2022-08-23 09:59:04,422 DEBUG CV Batch 52/500 loss 26.270313 loss_att 17.240810 loss_ctc 47.339149 loss_ctc_origin 29.148228 loss_ctc0 89.784630 history loss 32.036089 rank 0
2022-08-23 09:59:15,700 DEBUG CV Batch 52/600 loss 31.569538 loss_att 18.490055 loss_ctc 62.088329 loss_ctc_origin 32.361652 loss_ctc0 131.450577 history loss 31.975322 rank 0
2022-08-23 09:59:26,368 DEBUG CV Batch 52/700 loss 22.463547 loss_att 15.738153 loss_ctc 38.156136 loss_ctc_origin 25.803265 loss_ctc0 66.979507 history loss 31.623771 rank 0
2022-08-23 09:59:36,511 DEBUG CV Batch 52/800 loss 24.685644 loss_att 18.267033 loss_ctc 39.662403 loss_ctc_origin 24.442825 loss_ctc0 75.174751 history loss 31.554415 rank 0
2022-08-23 09:59:48,373 INFO Epoch 52 CV info cv_loss 31.496621721994188
2022-08-23 09:59:48,373 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/52.pt
2022-08-23 09:59:48,852 INFO Epoch 53 TRAIN info lr 0.0011518933392463612
2022-08-23 09:59:48,856 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 10:00:16,215 DEBUG TRAIN Batch 53/0 loss 32.431953 loss_att 26.194529 loss_ctc 46.985943 loss_ctc_origin 41.866142 loss_ctc0 58.932144 lr 0.00115189 rank 0
2022-08-23 10:00:45,297 DEBUG TRAIN Batch 53/100 loss 33.799995 loss_att 19.399385 loss_ctc 67.401413 loss_ctc_origin 43.202747 loss_ctc0 123.864960 lr 0.00115169 rank 0
2022-08-23 10:01:13,694 DEBUG TRAIN Batch 53/200 loss 22.796736 loss_att 13.936346 loss_ctc 43.470978 loss_ctc_origin 33.051849 loss_ctc0 67.782288 lr 0.00115150 rank 0
2022-08-23 10:01:19,355 WARNING NaN or Inf found in input tensor.
2022-08-23 10:01:42,604 DEBUG TRAIN Batch 53/300 loss 24.547001 loss_att 13.472383 loss_ctc 50.387779 loss_ctc_origin 38.337143 loss_ctc0 78.505920 lr 0.00115131 rank 0
2022-08-23 10:01:53,227 WARNING NaN or Inf found in input tensor.
2022-08-23 10:02:11,296 DEBUG TRAIN Batch 53/400 loss 31.677401 loss_att 15.597303 loss_ctc 69.197624 loss_ctc_origin 54.994331 loss_ctc0 102.338638 lr 0.00115112 rank 0
2022-08-23 10:02:40,608 DEBUG TRAIN Batch 53/500 loss 27.828669 loss_att 22.614521 loss_ctc 39.995010 loss_ctc_origin 36.157524 loss_ctc0 48.949150 lr 0.00115093 rank 0
2022-08-23 10:03:08,926 DEBUG TRAIN Batch 53/600 loss 37.913422 loss_att 25.301811 loss_ctc 67.340508 loss_ctc_origin 45.412716 loss_ctc0 118.505341 lr 0.00115074 rank 0
2022-08-23 10:03:38,416 DEBUG TRAIN Batch 53/700 loss 27.290176 loss_att 16.381882 loss_ctc 52.742867 loss_ctc_origin 43.868416 loss_ctc0 73.449905 lr 0.00115055 rank 0
2022-08-23 10:04:06,746 DEBUG TRAIN Batch 53/800 loss 25.634363 loss_att 13.363890 loss_ctc 54.265465 loss_ctc_origin 40.566429 loss_ctc0 86.229881 lr 0.00115036 rank 0
2022-08-23 10:04:35,363 DEBUG TRAIN Batch 53/900 loss 33.997849 loss_att 17.303505 loss_ctc 72.951309 loss_ctc_origin 57.971283 loss_ctc0 107.904678 lr 0.00115017 rank 0
2022-08-23 10:05:04,606 DEBUG TRAIN Batch 53/1000 loss 27.252132 loss_att 21.901283 loss_ctc 39.737442 loss_ctc_origin 36.068932 loss_ctc0 48.297302 lr 0.00114998 rank 0
2022-08-23 10:05:33,945 DEBUG TRAIN Batch 53/1100 loss 39.957672 loss_att 26.603363 loss_ctc 71.117722 loss_ctc_origin 47.485062 loss_ctc0 126.260590 lr 0.00114979 rank 0
2022-08-23 10:06:01,482 WARNING NaN or Inf found in input tensor.
2022-08-23 10:06:03,202 DEBUG TRAIN Batch 53/1200 loss 26.727131 loss_att 17.404037 loss_ctc 48.481010 loss_ctc_origin 40.238644 loss_ctc0 67.713203 lr 0.00114960 rank 0
2022-08-23 10:06:32,413 DEBUG TRAIN Batch 53/1300 loss 24.006100 loss_att 12.043619 loss_ctc 51.918549 loss_ctc_origin 35.936817 loss_ctc0 89.209259 lr 0.00114941 rank 0
2022-08-23 10:07:02,826 DEBUG TRAIN Batch 53/1400 loss 34.208031 loss_att 18.903389 loss_ctc 69.918854 loss_ctc_origin 56.330391 loss_ctc0 101.625267 lr 0.00114922 rank 0
2022-08-23 10:07:37,123 DEBUG TRAIN Batch 53/1500 loss 30.093416 loss_att 24.807049 loss_ctc 42.428276 loss_ctc_origin 37.580799 loss_ctc0 53.739059 lr 0.00114903 rank 0
2022-08-23 10:08:06,322 DEBUG TRAIN Batch 53/1600 loss 33.799938 loss_att 21.846546 loss_ctc 61.691185 loss_ctc_origin 43.483772 loss_ctc0 104.175140 lr 0.00114884 rank 0
2022-08-23 10:08:34,447 DEBUG TRAIN Batch 53/1700 loss 27.140839 loss_att 16.567865 loss_ctc 51.811111 loss_ctc_origin 41.534569 loss_ctc0 75.789703 lr 0.00114865 rank 0
2022-08-23 10:09:03,987 DEBUG TRAIN Batch 53/1800 loss 22.494614 loss_att 11.019167 loss_ctc 49.270653 loss_ctc_origin 37.005928 loss_ctc0 77.888344 lr 0.00114846 rank 0
2022-08-23 10:09:33,330 DEBUG TRAIN Batch 53/1900 loss 32.700294 loss_att 18.251152 loss_ctc 66.414955 loss_ctc_origin 51.744591 loss_ctc0 100.645790 lr 0.00114827 rank 0
2022-08-23 10:10:03,266 DEBUG TRAIN Batch 53/2000 loss 31.480675 loss_att 25.727520 loss_ctc 44.904705 loss_ctc_origin 40.281075 loss_ctc0 55.693172 lr 0.00114808 rank 0
2022-08-23 10:10:32,318 DEBUG TRAIN Batch 53/2100 loss 33.255341 loss_att 24.923088 loss_ctc 52.697266 loss_ctc_origin 44.475159 loss_ctc0 71.882179 lr 0.00114789 rank 0
2022-08-23 10:11:00,893 DEBUG TRAIN Batch 53/2200 loss 25.769897 loss_att 16.068611 loss_ctc 48.406227 loss_ctc_origin 38.471802 loss_ctc0 71.586548 lr 0.00114771 rank 0
2022-08-23 10:11:29,713 DEBUG TRAIN Batch 53/2300 loss 28.466980 loss_att 16.423374 loss_ctc 56.568726 loss_ctc_origin 45.000118 loss_ctc0 83.562134 lr 0.00114752 rank 0
2022-08-23 10:11:58,708 DEBUG TRAIN Batch 53/2400 loss 29.356892 loss_att 14.975712 loss_ctc 62.912979 loss_ctc_origin 48.289089 loss_ctc0 97.035385 lr 0.00114733 rank 0
2022-08-23 10:12:28,476 DEBUG TRAIN Batch 53/2500 loss 27.610886 loss_att 21.061594 loss_ctc 42.892563 loss_ctc_origin 39.590405 loss_ctc0 50.597603 lr 0.00114714 rank 0
2022-08-23 10:12:57,018 DEBUG TRAIN Batch 53/2600 loss 38.424072 loss_att 27.520006 loss_ctc 63.866890 loss_ctc_origin 48.969860 loss_ctc0 98.626625 lr 0.00114695 rank 0
2022-08-23 10:13:25,962 DEBUG TRAIN Batch 53/2700 loss 26.547787 loss_att 18.090149 loss_ctc 46.282272 loss_ctc_origin 38.754749 loss_ctc0 63.846497 lr 0.00114676 rank 0
2022-08-23 10:13:52,921 DEBUG TRAIN Batch 53/2800 loss 26.879608 loss_att 14.325884 loss_ctc 56.171631 loss_ctc_origin 44.284607 loss_ctc0 83.908012 lr 0.00114657 rank 0
2022-08-23 10:14:21,437 DEBUG TRAIN Batch 53/2900 loss 29.828569 loss_att 15.466574 loss_ctc 63.339890 loss_ctc_origin 49.641487 loss_ctc0 95.302841 lr 0.00114639 rank 0
2022-08-23 10:14:54,921 DEBUG TRAIN Batch 53/3000 loss 27.003801 loss_att 21.879681 loss_ctc 38.960083 loss_ctc_origin 34.700378 loss_ctc0 48.899399 lr 0.00114620 rank 0
2022-08-23 10:14:55,722 WARNING NaN or Inf found in input tensor.
2022-08-23 10:15:02,661 WARNING NaN or Inf found in input tensor.
2022-08-23 10:15:22,082 DEBUG TRAIN Batch 53/3100 loss 34.700527 loss_att 24.758831 loss_ctc 57.897820 loss_ctc_origin 40.256351 loss_ctc0 99.061241 lr 0.00114601 rank 0
2022-08-23 10:15:49,020 DEBUG TRAIN Batch 53/3200 loss 27.181908 loss_att 18.367735 loss_ctc 47.748306 loss_ctc_origin 40.158619 loss_ctc0 65.457573 lr 0.00114582 rank 0
2022-08-23 10:15:54,520 WARNING NaN or Inf found in input tensor.
2022-08-23 10:16:15,643 DEBUG TRAIN Batch 53/3300 loss 26.092978 loss_att 12.740345 loss_ctc 57.249115 loss_ctc_origin 45.245556 loss_ctc0 85.257416 lr 0.00114563 rank 0
2022-08-23 10:16:44,038 DEBUG TRAIN Batch 53/3400 loss 28.610561 loss_att 15.367739 loss_ctc 59.510475 loss_ctc_origin 44.784134 loss_ctc0 93.871925 lr 0.00114544 rank 0
2022-08-23 10:16:46,736 WARNING NaN or Inf found in input tensor.
2022-08-23 10:17:13,685 DEBUG TRAIN Batch 53/3500 loss 25.811302 loss_att 19.298185 loss_ctc 41.008575 loss_ctc_origin 34.429909 loss_ctc0 56.358791 lr 0.00114526 rank 0
2022-08-23 10:17:41,616 DEBUG TRAIN Batch 53/3600 loss 32.380302 loss_att 23.750074 loss_ctc 52.517494 loss_ctc_origin 37.852020 loss_ctc0 86.736923 lr 0.00114507 rank 0
2022-08-23 10:18:09,677 DEBUG TRAIN Batch 53/3700 loss 22.532818 loss_att 14.361305 loss_ctc 41.599678 loss_ctc_origin 31.303717 loss_ctc0 65.623581 lr 0.00114488 rank 0
2022-08-23 10:18:36,986 DEBUG TRAIN Batch 53/3800 loss 28.310085 loss_att 14.980015 loss_ctc 59.413586 loss_ctc_origin 48.218204 loss_ctc0 85.536140 lr 0.00114469 rank 0
2022-08-23 10:18:59,593 WARNING NaN or Inf found in input tensor.
2022-08-23 10:19:04,028 DEBUG TRAIN Batch 53/3900 loss 34.179611 loss_att 18.761858 loss_ctc 70.154366 loss_ctc_origin 53.999996 loss_ctc0 107.847900 lr 0.00114451 rank 0
2022-08-23 10:19:31,466 DEBUG TRAIN Batch 53/4000 loss 27.023430 loss_att 21.508471 loss_ctc 39.891670 loss_ctc_origin 34.440418 loss_ctc0 52.611256 lr 0.00114432 rank 0
2022-08-23 10:19:43,747 WARNING NaN or Inf found in input tensor.
2022-08-23 10:19:58,215 DEBUG TRAIN Batch 53/4100 loss 28.947594 loss_att 20.233818 loss_ctc 49.279732 loss_ctc_origin 37.566547 loss_ctc0 76.610489 lr 0.00114413 rank 0
2022-08-23 10:20:22,716 WARNING NaN or Inf found in input tensor.
2022-08-23 10:20:24,396 DEBUG TRAIN Batch 53/4200 loss 23.860882 loss_att 14.056789 loss_ctc 46.737099 loss_ctc_origin 36.961384 loss_ctc0 69.547096 lr 0.00114394 rank 0
2022-08-23 10:20:52,257 DEBUG TRAIN Batch 53/4300 loss 25.905722 loss_att 14.372065 loss_ctc 52.817589 loss_ctc_origin 40.436501 loss_ctc0 81.706802 lr 0.00114376 rank 0
2022-08-23 10:21:19,002 DEBUG TRAIN Batch 53/4400 loss 30.061008 loss_att 16.313185 loss_ctc 62.139259 loss_ctc_origin 46.315781 loss_ctc0 99.060699 lr 0.00114357 rank 0
2022-08-23 10:21:52,721 DEBUG TRAIN Batch 53/4500 loss 27.133230 loss_att 19.870991 loss_ctc 44.078453 loss_ctc_origin 35.883682 loss_ctc0 63.199585 lr 0.00114338 rank 0
2022-08-23 10:22:21,604 DEBUG TRAIN Batch 53/4600 loss 34.374924 loss_att 22.114281 loss_ctc 62.983086 loss_ctc_origin 45.001274 loss_ctc0 104.940651 lr 0.00114320 rank 0
2022-08-23 10:22:49,004 DEBUG TRAIN Batch 53/4700 loss 22.945755 loss_att 13.344669 loss_ctc 45.348286 loss_ctc_origin 34.713364 loss_ctc0 70.163101 lr 0.00114301 rank 0
2022-08-23 10:23:16,856 DEBUG TRAIN Batch 53/4800 loss 24.116379 loss_att 13.009230 loss_ctc 50.033058 loss_ctc_origin 38.053009 loss_ctc0 77.986496 lr 0.00114282 rank 0
2022-08-23 10:23:44,836 DEBUG TRAIN Batch 53/4900 loss 31.359943 loss_att 16.126507 loss_ctc 66.904633 loss_ctc_origin 52.179489 loss_ctc0 101.263306 lr 0.00114264 rank 0
2022-08-23 10:24:11,878 DEBUG TRAIN Batch 53/5000 loss 33.238632 loss_att 25.175190 loss_ctc 52.053329 loss_ctc_origin 52.398533 loss_ctc0 51.247852 lr 0.00114245 rank 0
2022-08-23 10:24:38,881 DEBUG TRAIN Batch 53/5100 loss 37.478020 loss_att 25.863798 loss_ctc 64.577866 loss_ctc_origin 49.607964 loss_ctc0 99.507637 lr 0.00114226 rank 0
2022-08-23 10:25:04,759 WARNING NaN or Inf found in input tensor.
2022-08-23 10:25:06,348 DEBUG TRAIN Batch 53/5200 loss 22.412933 loss_att 14.300081 loss_ctc 41.342918 loss_ctc_origin 31.676037 loss_ctc0 63.898972 lr 0.00114208 rank 0
2022-08-23 10:25:34,995 DEBUG TRAIN Batch 53/5300 loss 27.033478 loss_att 15.989568 loss_ctc 52.802597 loss_ctc_origin 41.412453 loss_ctc0 79.379593 lr 0.00114189 rank 0
2022-08-23 10:26:04,145 DEBUG TRAIN Batch 53/5400 loss 34.341835 loss_att 19.870371 loss_ctc 68.108582 loss_ctc_origin 57.172523 loss_ctc0 93.626053 lr 0.00114171 rank 0
2022-08-23 10:26:33,994 DEBUG TRAIN Batch 53/5500 loss 22.611465 loss_att 18.297285 loss_ctc 32.677883 loss_ctc_origin 28.594131 loss_ctc0 42.206635 lr 0.00114152 rank 0
2022-08-23 10:27:00,994 WARNING NaN or Inf found in input tensor.
2022-08-23 10:27:01,759 DEBUG TRAIN Batch 53/5600 loss 37.892174 loss_att 24.927080 loss_ctc 68.144058 loss_ctc_origin 50.162064 loss_ctc0 110.102036 lr 0.00114133 rank 0
2022-08-23 10:27:27,449 DEBUG CV Batch 53/0 loss 21.201933 loss_att 13.289016 loss_ctc 39.665405 loss_ctc_origin 22.276260 loss_ctc0 80.240074 history loss 19.954760 rank 0
2022-08-23 10:27:37,532 DEBUG CV Batch 53/100 loss 31.801105 loss_att 21.411064 loss_ctc 56.044540 loss_ctc_origin 30.619549 loss_ctc0 115.369507 history loss 32.576934 rank 0
2022-08-23 10:27:46,668 DEBUG CV Batch 53/200 loss 30.909994 loss_att 22.330612 loss_ctc 50.928551 loss_ctc_origin 35.246586 loss_ctc0 87.519806 history loss 33.992242 rank 0
2022-08-23 10:27:56,254 DEBUG CV Batch 53/300 loss 27.410107 loss_att 20.045849 loss_ctc 44.593372 loss_ctc_origin 30.367321 loss_ctc0 77.787491 history loss 33.075791 rank 0
2022-08-23 10:28:06,185 DEBUG CV Batch 53/400 loss 41.293282 loss_att 32.517433 loss_ctc 61.770256 loss_ctc_origin 45.328232 loss_ctc0 100.134987 history loss 31.188399 rank 0
2022-08-23 10:28:16,357 DEBUG CV Batch 53/500 loss 25.847759 loss_att 17.800331 loss_ctc 44.625092 loss_ctc_origin 28.860605 loss_ctc0 81.408890 history loss 30.839133 rank 0
2022-08-23 10:28:26,427 DEBUG CV Batch 53/600 loss 25.103725 loss_att 14.106114 loss_ctc 50.764816 loss_ctc_origin 28.500942 loss_ctc0 102.713852 history loss 30.690830 rank 0
2022-08-23 10:28:35,909 DEBUG CV Batch 53/700 loss 22.573877 loss_att 16.061457 loss_ctc 37.769527 loss_ctc_origin 24.870371 loss_ctc0 67.867554 history loss 30.324455 rank 0
2022-08-23 10:28:45,750 DEBUG CV Batch 53/800 loss 25.534119 loss_att 19.398331 loss_ctc 39.850960 loss_ctc_origin 25.136284 loss_ctc0 74.185211 history loss 30.231198 rank 0
2022-08-23 10:28:55,510 INFO Epoch 53 CV info cv_loss 30.23038289734513
2022-08-23 10:28:55,511 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/53.pt
2022-08-23 10:28:55,977 INFO Epoch 54 TRAIN info lr 0.0011411778194691125
2022-08-23 10:28:55,980 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 10:29:22,889 DEBUG TRAIN Batch 54/0 loss 25.643238 loss_att 18.625988 loss_ctc 42.016823 loss_ctc_origin 35.187599 loss_ctc0 57.951675 lr 0.00114117 rank 0
2022-08-23 10:29:51,136 DEBUG TRAIN Batch 54/100 loss 33.552551 loss_att 22.553404 loss_ctc 59.217220 loss_ctc_origin 40.604137 loss_ctc0 102.647743 lr 0.00114098 rank 0
2022-08-23 10:30:20,084 DEBUG TRAIN Batch 54/200 loss 25.818756 loss_att 16.553602 loss_ctc 47.437443 loss_ctc_origin 38.918320 loss_ctc0 67.315399 lr 0.00114080 rank 0
2022-08-23 10:30:49,084 DEBUG TRAIN Batch 54/300 loss 26.725945 loss_att 14.329544 loss_ctc 55.650871 loss_ctc_origin 40.782650 loss_ctc0 90.343376 lr 0.00114061 rank 0
2022-08-23 10:31:18,047 DEBUG TRAIN Batch 54/400 loss 32.050053 loss_att 16.428354 loss_ctc 68.500679 loss_ctc_origin 52.504387 loss_ctc0 105.825363 lr 0.00114043 rank 0
2022-08-23 10:31:47,953 DEBUG TRAIN Batch 54/500 loss 29.672331 loss_att 23.986130 loss_ctc 42.940132 loss_ctc_origin 35.100693 loss_ctc0 61.232151 lr 0.00114024 rank 0
2022-08-23 10:32:16,093 DEBUG TRAIN Batch 54/600 loss 36.719391 loss_att 26.590702 loss_ctc 60.352989 loss_ctc_origin 46.288773 loss_ctc0 93.169479 lr 0.00114006 rank 0
2022-08-23 10:32:44,055 DEBUG TRAIN Batch 54/700 loss 21.457327 loss_att 12.655609 loss_ctc 41.994667 loss_ctc_origin 32.061646 loss_ctc0 65.171715 lr 0.00113987 rank 0
2022-08-23 10:33:12,684 DEBUG TRAIN Batch 54/800 loss 26.441017 loss_att 13.321346 loss_ctc 57.053585 loss_ctc_origin 43.879295 loss_ctc0 87.793594 lr 0.00113969 rank 0
2022-08-23 10:33:41,163 DEBUG TRAIN Batch 54/900 loss 23.988247 loss_att 11.176825 loss_ctc 53.881569 loss_ctc_origin 36.855766 loss_ctc0 93.608444 lr 0.00113950 rank 0
2022-08-23 10:34:09,980 DEBUG TRAIN Batch 54/1000 loss 30.652153 loss_att 23.279446 loss_ctc 47.855133 loss_ctc_origin 41.274540 loss_ctc0 63.209843 lr 0.00113932 rank 0
2022-08-23 10:34:38,129 DEBUG TRAIN Batch 54/1100 loss 30.847874 loss_att 20.523796 loss_ctc 54.937386 loss_ctc_origin 39.229904 loss_ctc0 91.588181 lr 0.00113913 rank 0
2022-08-23 10:35:07,088 DEBUG TRAIN Batch 54/1200 loss 22.888538 loss_att 14.731325 loss_ctc 41.922035 loss_ctc_origin 32.848400 loss_ctc0 63.093842 lr 0.00113895 rank 0
2022-08-23 10:35:35,975 DEBUG TRAIN Batch 54/1300 loss 26.494514 loss_att 14.662598 loss_ctc 54.102325 loss_ctc_origin 41.481110 loss_ctc0 83.551834 lr 0.00113876 rank 0
2022-08-23 10:35:52,916 WARNING NaN or Inf found in input tensor.
2022-08-23 10:36:04,168 DEBUG TRAIN Batch 54/1400 loss 30.717182 loss_att 17.625404 loss_ctc 61.264660 loss_ctc_origin 45.955242 loss_ctc0 96.986626 lr 0.00113858 rank 0
2022-08-23 10:36:40,075 DEBUG TRAIN Batch 54/1500 loss 32.597191 loss_att 23.597343 loss_ctc 53.596836 loss_ctc_origin 47.741997 loss_ctc0 67.258133 lr 0.00113839 rank 0
2022-08-23 10:37:08,242 DEBUG TRAIN Batch 54/1600 loss 33.490231 loss_att 22.649160 loss_ctc 58.786057 loss_ctc_origin 36.983055 loss_ctc0 109.659721 lr 0.00113821 rank 0
2022-08-23 10:37:36,965 DEBUG TRAIN Batch 54/1700 loss 25.196934 loss_att 15.974356 loss_ctc 46.716282 loss_ctc_origin 37.288700 loss_ctc0 68.713974 lr 0.00113803 rank 0
2022-08-23 10:38:05,446 DEBUG TRAIN Batch 54/1800 loss 24.369530 loss_att 12.558819 loss_ctc 51.927856 loss_ctc_origin 39.453766 loss_ctc0 81.034073 lr 0.00113784 rank 0
2022-08-23 10:38:34,236 DEBUG TRAIN Batch 54/1900 loss 27.818569 loss_att 13.613307 loss_ctc 60.964172 loss_ctc_origin 45.904213 loss_ctc0 96.104065 lr 0.00113766 rank 0
2022-08-23 10:39:03,645 DEBUG TRAIN Batch 54/2000 loss 34.183331 loss_att 27.391388 loss_ctc 50.031197 loss_ctc_origin 45.809689 loss_ctc0 59.881386 lr 0.00113747 rank 0
2022-08-23 10:39:32,608 DEBUG TRAIN Batch 54/2100 loss 28.472057 loss_att 17.080442 loss_ctc 55.052490 loss_ctc_origin 42.018692 loss_ctc0 85.464676 lr 0.00113729 rank 0
2022-08-23 10:40:00,667 DEBUG TRAIN Batch 54/2200 loss 29.694859 loss_att 17.780552 loss_ctc 57.494904 loss_ctc_origin 48.916473 loss_ctc0 77.511246 lr 0.00113711 rank 0
2022-08-23 10:40:29,644 DEBUG TRAIN Batch 54/2300 loss 25.321531 loss_att 14.429339 loss_ctc 50.736645 loss_ctc_origin 38.383446 loss_ctc0 79.560776 lr 0.00113692 rank 0
2022-08-23 10:40:57,737 DEBUG TRAIN Batch 54/2400 loss 33.773571 loss_att 18.215984 loss_ctc 70.074600 loss_ctc_origin 55.515938 loss_ctc0 104.044800 lr 0.00113674 rank 0
2022-08-23 10:41:26,958 DEBUG TRAIN Batch 54/2500 loss 25.871344 loss_att 19.999535 loss_ctc 39.572231 loss_ctc_origin 31.582512 loss_ctc0 58.214912 lr 0.00113655 rank 0
2022-08-23 10:41:55,585 DEBUG TRAIN Batch 54/2600 loss 40.993492 loss_att 29.000715 loss_ctc 68.976639 loss_ctc_origin 50.018902 loss_ctc0 113.211365 lr 0.00113637 rank 0
2022-08-23 10:42:24,652 DEBUG TRAIN Batch 54/2700 loss 24.826942 loss_att 15.791225 loss_ctc 45.910282 loss_ctc_origin 36.901409 loss_ctc0 66.930984 lr 0.00113619 rank 0
2022-08-23 10:42:52,928 DEBUG TRAIN Batch 54/2800 loss 27.023403 loss_att 14.768667 loss_ctc 55.617779 loss_ctc_origin 42.743244 loss_ctc0 85.658356 lr 0.00113600 rank 0
2022-08-23 10:43:21,537 DEBUG TRAIN Batch 54/2900 loss 31.440428 loss_att 17.044619 loss_ctc 65.030647 loss_ctc_origin 49.245567 loss_ctc0 101.862503 lr 0.00113582 rank 0
2022-08-23 10:43:55,814 DEBUG TRAIN Batch 54/3000 loss 35.359322 loss_att 26.453526 loss_ctc 56.139519 loss_ctc_origin 44.971073 loss_ctc0 82.199219 lr 0.00113564 rank 0
2022-08-23 10:44:24,922 DEBUG TRAIN Batch 54/3100 loss 31.577810 loss_att 20.405661 loss_ctc 57.646156 loss_ctc_origin 39.093590 loss_ctc0 100.935478 lr 0.00113545 rank 0
2022-08-23 10:44:52,994 DEBUG TRAIN Batch 54/3200 loss 27.310413 loss_att 16.842949 loss_ctc 51.734493 loss_ctc_origin 43.509190 loss_ctc0 70.926865 lr 0.00113527 rank 0
2022-08-23 10:45:21,824 DEBUG TRAIN Batch 54/3300 loss 25.909801 loss_att 13.675951 loss_ctc 54.455448 loss_ctc_origin 41.771164 loss_ctc0 84.052109 lr 0.00113509 rank 0
2022-08-23 10:45:50,394 DEBUG TRAIN Batch 54/3400 loss 35.444149 loss_att 20.308395 loss_ctc 70.760902 loss_ctc_origin 57.210697 loss_ctc0 102.378036 lr 0.00113491 rank 0
2022-08-23 10:46:20,002 DEBUG TRAIN Batch 54/3500 loss 30.639225 loss_att 25.006130 loss_ctc 43.783108 loss_ctc_origin 40.382099 loss_ctc0 51.718796 lr 0.00113472 rank 0
2022-08-23 10:46:48,358 DEBUG TRAIN Batch 54/3600 loss 33.428318 loss_att 22.431866 loss_ctc 59.086700 loss_ctc_origin 41.598015 loss_ctc0 99.893631 lr 0.00113454 rank 0
2022-08-23 10:47:16,990 DEBUG TRAIN Batch 54/3700 loss 23.686558 loss_att 14.558514 loss_ctc 44.985329 loss_ctc_origin 36.758980 loss_ctc0 64.180145 lr 0.00113436 rank 0
2022-08-23 10:47:46,625 DEBUG TRAIN Batch 54/3800 loss 28.539570 loss_att 16.819473 loss_ctc 55.886459 loss_ctc_origin 44.621597 loss_ctc0 82.171143 lr 0.00113418 rank 0
2022-08-23 10:48:15,864 DEBUG TRAIN Batch 54/3900 loss 26.794437 loss_att 13.916584 loss_ctc 56.842754 loss_ctc_origin 42.627884 loss_ctc0 90.010788 lr 0.00113399 rank 0
2022-08-23 10:48:45,558 DEBUG TRAIN Batch 54/4000 loss 35.018501 loss_att 29.580954 loss_ctc 47.706116 loss_ctc_origin 41.676178 loss_ctc0 61.775963 lr 0.00113381 rank 0
2022-08-23 10:49:14,493 DEBUG TRAIN Batch 54/4100 loss 29.856636 loss_att 22.001699 loss_ctc 48.184814 loss_ctc_origin 34.551926 loss_ctc0 79.994881 lr 0.00113363 rank 0
2022-08-23 10:49:41,727 DEBUG TRAIN Batch 54/4200 loss 22.215082 loss_att 12.167706 loss_ctc 45.658958 loss_ctc_origin 35.815025 loss_ctc0 68.628143 lr 0.00113345 rank 0
2022-08-23 10:50:11,449 DEBUG TRAIN Batch 54/4300 loss 29.409733 loss_att 16.263950 loss_ctc 60.083225 loss_ctc_origin 47.833408 loss_ctc0 88.666122 lr 0.00113327 rank 0
2022-08-23 10:50:36,389 WARNING NaN or Inf found in input tensor.
2022-08-23 10:50:40,661 DEBUG TRAIN Batch 54/4400 loss 29.096413 loss_att 16.386860 loss_ctc 58.752029 loss_ctc_origin 43.325638 loss_ctc0 94.746948 lr 0.00113308 rank 0
2022-08-23 10:51:16,287 DEBUG TRAIN Batch 54/4500 loss 27.696892 loss_att 22.579630 loss_ctc 39.637173 loss_ctc_origin 35.664307 loss_ctc0 48.907192 lr 0.00113290 rank 0
2022-08-23 10:51:31,329 WARNING NaN or Inf found in input tensor.
2022-08-23 10:51:44,395 DEBUG TRAIN Batch 54/4600 loss 34.601337 loss_att 23.806858 loss_ctc 59.788452 loss_ctc_origin 39.827553 loss_ctc0 106.363892 lr 0.00113272 rank 0
2022-08-23 10:52:12,432 DEBUG TRAIN Batch 54/4700 loss 27.905205 loss_att 18.266205 loss_ctc 50.396202 loss_ctc_origin 40.456146 loss_ctc0 73.589661 lr 0.00113254 rank 0
2022-08-23 10:52:41,819 DEBUG TRAIN Batch 54/4800 loss 23.986742 loss_att 12.852747 loss_ctc 49.966064 loss_ctc_origin 36.388458 loss_ctc0 81.647141 lr 0.00113236 rank 0
2022-08-23 10:53:10,337 DEBUG TRAIN Batch 54/4900 loss 31.871527 loss_att 17.083702 loss_ctc 66.376450 loss_ctc_origin 50.830910 loss_ctc0 102.649368 lr 0.00113218 rank 0
2022-08-23 10:53:39,034 DEBUG TRAIN Batch 54/5000 loss 29.859184 loss_att 20.773800 loss_ctc 51.058411 loss_ctc_origin 39.895287 loss_ctc0 77.105705 lr 0.00113199 rank 0
2022-08-23 10:54:07,304 DEBUG TRAIN Batch 54/5100 loss 29.925888 loss_att 19.909718 loss_ctc 53.296951 loss_ctc_origin 32.175415 loss_ctc0 102.580528 lr 0.00113181 rank 0
2022-08-23 10:54:36,707 DEBUG TRAIN Batch 54/5200 loss 29.603718 loss_att 17.720444 loss_ctc 57.331356 loss_ctc_origin 49.703018 loss_ctc0 75.130814 lr 0.00113163 rank 0
2022-08-23 10:55:04,823 DEBUG TRAIN Batch 54/5300 loss 21.788038 loss_att 11.423388 loss_ctc 45.972221 loss_ctc_origin 32.137886 loss_ctc0 78.252335 lr 0.00113145 rank 0
2022-08-23 10:55:32,878 DEBUG TRAIN Batch 54/5400 loss 28.951538 loss_att 15.108379 loss_ctc 61.252243 loss_ctc_origin 46.592388 loss_ctc0 95.458572 lr 0.00113127 rank 0
2022-08-23 10:56:01,277 DEBUG TRAIN Batch 54/5500 loss 24.758381 loss_att 17.838196 loss_ctc 40.905479 loss_ctc_origin 32.109818 loss_ctc0 61.428688 lr 0.00113109 rank 0
2022-08-23 10:56:28,615 DEBUG TRAIN Batch 54/5600 loss 31.910688 loss_att 22.002493 loss_ctc 55.029808 loss_ctc_origin 42.016045 loss_ctc0 85.395248 lr 0.00113091 rank 0
2022-08-23 10:56:50,935 DEBUG CV Batch 54/0 loss 16.281574 loss_att 11.394937 loss_ctc 27.683727 loss_ctc_origin 19.159571 loss_ctc0 47.573425 history loss 15.323835 rank 0
2022-08-23 10:57:01,493 DEBUG CV Batch 54/100 loss 24.475910 loss_att 18.175961 loss_ctc 39.175797 loss_ctc_origin 26.652309 loss_ctc0 68.397270 history loss 30.697601 rank 0
2022-08-23 10:57:11,511 DEBUG CV Batch 54/200 loss 28.371201 loss_att 20.924334 loss_ctc 45.747219 loss_ctc_origin 32.819305 loss_ctc0 75.912354 history loss 31.797529 rank 0
2022-08-23 10:57:21,601 DEBUG CV Batch 54/300 loss 26.792351 loss_att 19.366739 loss_ctc 44.118774 loss_ctc_origin 29.630756 loss_ctc0 77.924149 history loss 30.927461 rank 0
2022-08-23 10:57:32,532 DEBUG CV Batch 54/400 loss 41.761620 loss_att 33.320976 loss_ctc 61.456463 loss_ctc_origin 44.288078 loss_ctc0 101.516029 history loss 29.235864 rank 0
2022-08-23 10:57:43,568 DEBUG CV Batch 54/500 loss 19.898317 loss_att 14.623917 loss_ctc 32.205254 loss_ctc_origin 22.468367 loss_ctc0 54.924648 history loss 28.891589 rank 0
2022-08-23 10:57:54,078 DEBUG CV Batch 54/600 loss 21.042076 loss_att 13.418892 loss_ctc 38.829510 loss_ctc_origin 23.143982 loss_ctc0 75.429077 history loss 28.724134 rank 0
2022-08-23 10:58:04,308 DEBUG CV Batch 54/700 loss 22.455975 loss_att 15.803223 loss_ctc 37.979065 loss_ctc_origin 25.430565 loss_ctc0 67.258896 history loss 28.371331 rank 0
2022-08-23 10:58:14,874 DEBUG CV Batch 54/800 loss 24.383165 loss_att 17.984703 loss_ctc 39.312912 loss_ctc_origin 24.341591 loss_ctc0 74.245987 history loss 28.300284 rank 0
2022-08-23 10:58:24,915 INFO Epoch 54 CV info cv_loss 28.373887798612596
2022-08-23 10:58:24,915 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/54.pt
2022-08-23 10:58:25,388 INFO Epoch 55 TRAIN info lr 0.0011307558859212639
2022-08-23 10:58:25,392 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 10:58:53,672 DEBUG TRAIN Batch 55/0 loss 28.869957 loss_att 22.127144 loss_ctc 44.603188 loss_ctc_origin 36.660141 loss_ctc0 63.136955 lr 0.00113075 rank 0
2022-08-23 10:59:22,969 DEBUG TRAIN Batch 55/100 loss 32.827888 loss_att 23.585352 loss_ctc 54.393810 loss_ctc_origin 43.020485 loss_ctc0 80.931564 lr 0.00113057 rank 0
2022-08-23 10:59:51,902 DEBUG TRAIN Batch 55/200 loss 24.358295 loss_att 15.099058 loss_ctc 45.963181 loss_ctc_origin 36.128754 loss_ctc0 68.910179 lr 0.00113039 rank 0
2022-08-23 11:00:21,002 DEBUG TRAIN Batch 55/300 loss 26.784348 loss_att 14.623394 loss_ctc 55.159904 loss_ctc_origin 43.833519 loss_ctc0 81.588142 lr 0.00113021 rank 0
2022-08-23 11:00:49,953 DEBUG TRAIN Batch 55/400 loss 32.640213 loss_att 16.978823 loss_ctc 69.183456 loss_ctc_origin 54.103020 loss_ctc0 104.371155 lr 0.00113003 rank 0
2022-08-23 11:01:19,543 DEBUG TRAIN Batch 55/500 loss 31.737358 loss_att 25.123802 loss_ctc 47.168991 loss_ctc_origin 37.520683 loss_ctc0 69.681709 lr 0.00112985 rank 0
2022-08-23 11:01:47,688 DEBUG TRAIN Batch 55/600 loss 40.269821 loss_att 30.065172 loss_ctc 64.080666 loss_ctc_origin 50.349056 loss_ctc0 96.121086 lr 0.00112967 rank 0
2022-08-23 11:02:16,249 DEBUG TRAIN Batch 55/700 loss 28.219456 loss_att 15.856273 loss_ctc 57.066879 loss_ctc_origin 47.652069 loss_ctc0 79.034760 lr 0.00112949 rank 0
2022-08-23 11:02:45,264 DEBUG TRAIN Batch 55/800 loss 27.201210 loss_att 15.283772 loss_ctc 55.008564 loss_ctc_origin 43.367237 loss_ctc0 82.171661 lr 0.00112931 rank 0
2022-08-23 11:03:13,880 DEBUG TRAIN Batch 55/900 loss 24.041576 loss_att 12.257344 loss_ctc 51.538116 loss_ctc_origin 35.070377 loss_ctc0 89.962845 lr 0.00112913 rank 0
2022-08-23 11:03:44,063 DEBUG TRAIN Batch 55/1000 loss 27.544018 loss_att 20.281479 loss_ctc 44.489937 loss_ctc_origin 36.260597 loss_ctc0 63.691730 lr 0.00112895 rank 0
2022-08-23 11:03:44,757 WARNING NaN or Inf found in input tensor.
2022-08-23 11:04:13,333 DEBUG TRAIN Batch 55/1100 loss 31.107037 loss_att 21.870665 loss_ctc 52.658569 loss_ctc_origin 37.917595 loss_ctc0 87.054169 lr 0.00112877 rank 0
2022-08-23 11:04:41,342 DEBUG TRAIN Batch 55/1200 loss 25.262871 loss_att 14.949154 loss_ctc 49.328209 loss_ctc_origin 40.194382 loss_ctc0 70.640465 lr 0.00112859 rank 0
2022-08-23 11:05:09,423 DEBUG TRAIN Batch 55/1300 loss 23.769619 loss_att 11.813880 loss_ctc 51.666344 loss_ctc_origin 37.435703 loss_ctc0 84.871170 lr 0.00112841 rank 0
2022-08-23 11:05:37,720 DEBUG TRAIN Batch 55/1400 loss 27.253353 loss_att 13.592399 loss_ctc 59.128914 loss_ctc_origin 43.639019 loss_ctc0 95.271996 lr 0.00112823 rank 0
2022-08-23 11:06:10,924 DEBUG TRAIN Batch 55/1500 loss 25.669998 loss_att 18.703413 loss_ctc 41.925358 loss_ctc_origin 34.026730 loss_ctc0 60.355492 lr 0.00112805 rank 0
2022-08-23 11:06:40,109 DEBUG TRAIN Batch 55/1600 loss 30.307156 loss_att 21.916134 loss_ctc 49.886208 loss_ctc_origin 37.908592 loss_ctc0 77.833977 lr 0.00112787 rank 0
2022-08-23 11:07:08,440 DEBUG TRAIN Batch 55/1700 loss 21.347092 loss_att 12.407877 loss_ctc 42.205261 loss_ctc_origin 31.366781 loss_ctc0 67.495041 lr 0.00112769 rank 0
2022-08-23 11:07:37,326 DEBUG TRAIN Batch 55/1800 loss 23.368055 loss_att 11.343247 loss_ctc 51.425938 loss_ctc_origin 37.308342 loss_ctc0 84.366989 lr 0.00112751 rank 0
2022-08-23 11:08:06,329 DEBUG TRAIN Batch 55/1900 loss 28.674053 loss_att 14.075218 loss_ctc 62.737999 loss_ctc_origin 45.876411 loss_ctc0 102.081696 lr 0.00112733 rank 0
2022-08-23 11:08:35,303 DEBUG TRAIN Batch 55/2000 loss 26.693794 loss_att 19.421730 loss_ctc 43.661945 loss_ctc_origin 41.759857 loss_ctc0 48.100151 lr 0.00112715 rank 0
2022-08-23 11:08:42,749 WARNING NaN or Inf found in input tensor.
2022-08-23 11:08:56,057 WARNING NaN or Inf found in input tensor.
2022-08-23 11:09:03,018 DEBUG TRAIN Batch 55/2100 loss 34.154388 loss_att 25.112804 loss_ctc 55.251415 loss_ctc_origin 44.981216 loss_ctc0 79.215210 lr 0.00112697 rank 0
2022-08-23 11:09:31,489 DEBUG TRAIN Batch 55/2200 loss 27.008680 loss_att 16.703133 loss_ctc 51.054955 loss_ctc_origin 43.011620 loss_ctc0 69.822739 lr 0.00112679 rank 0
2022-08-23 11:09:59,956 DEBUG TRAIN Batch 55/2300 loss 29.584721 loss_att 16.339378 loss_ctc 60.490517 loss_ctc_origin 48.054535 loss_ctc0 89.507805 lr 0.00112661 rank 0
2022-08-23 11:10:28,466 DEBUG TRAIN Batch 55/2400 loss 28.805399 loss_att 15.378283 loss_ctc 60.135338 loss_ctc_origin 45.829762 loss_ctc0 93.515015 lr 0.00112644 rank 0
2022-08-23 11:10:58,937 DEBUG TRAIN Batch 55/2500 loss 25.218407 loss_att 21.557487 loss_ctc 33.760551 loss_ctc_origin 30.966301 loss_ctc0 40.280468 lr 0.00112626 rank 0
2022-08-23 11:11:25,797 WARNING NaN or Inf found in input tensor.
2022-08-23 11:11:26,558 DEBUG TRAIN Batch 55/2600 loss 35.145004 loss_att 23.909824 loss_ctc 61.360428 loss_ctc_origin 47.156750 loss_ctc0 94.502335 lr 0.00112608 rank 0
2022-08-23 11:11:55,621 DEBUG TRAIN Batch 55/2700 loss 24.281096 loss_att 14.784068 loss_ctc 46.440826 loss_ctc_origin 36.052773 loss_ctc0 70.679626 lr 0.00112590 rank 0
2022-08-23 11:12:24,125 DEBUG TRAIN Batch 55/2800 loss 26.686172 loss_att 14.198627 loss_ctc 55.823776 loss_ctc_origin 43.059998 loss_ctc0 85.605919 lr 0.00112572 rank 0
2022-08-23 11:12:53,414 DEBUG TRAIN Batch 55/2900 loss 32.411484 loss_att 17.506935 loss_ctc 67.188766 loss_ctc_origin 52.109612 loss_ctc0 102.373474 lr 0.00112554 rank 0
2022-08-23 11:13:28,224 DEBUG TRAIN Batch 55/3000 loss 28.363354 loss_att 23.211121 loss_ctc 40.385231 loss_ctc_origin 34.252625 loss_ctc0 54.694645 lr 0.00112537 rank 0
2022-08-23 11:13:56,404 DEBUG TRAIN Batch 55/3100 loss 25.281452 loss_att 18.063808 loss_ctc 42.122616 loss_ctc_origin 30.659203 loss_ctc0 68.870583 lr 0.00112519 rank 0
2022-08-23 11:14:25,585 DEBUG TRAIN Batch 55/3200 loss 24.358696 loss_att 15.016070 loss_ctc 46.158154 loss_ctc_origin 37.010544 loss_ctc0 67.502571 lr 0.00112501 rank 0
2022-08-23 11:14:54,380 DEBUG TRAIN Batch 55/3300 loss 25.525873 loss_att 13.192202 loss_ctc 54.304436 loss_ctc_origin 40.071503 loss_ctc0 87.514610 lr 0.00112483 rank 0
2022-08-23 11:15:23,087 DEBUG TRAIN Batch 55/3400 loss 31.613270 loss_att 18.462732 loss_ctc 62.297859 loss_ctc_origin 45.103683 loss_ctc0 102.417603 lr 0.00112465 rank 0
2022-08-23 11:15:52,418 DEBUG TRAIN Batch 55/3500 loss 25.428646 loss_att 20.037273 loss_ctc 38.008514 loss_ctc_origin 35.438068 loss_ctc0 44.006226 lr 0.00112448 rank 0
2022-08-23 11:16:00,214 WARNING NaN or Inf found in input tensor.
2022-08-23 11:16:21,254 DEBUG TRAIN Batch 55/3600 loss 27.257744 loss_att 19.947750 loss_ctc 44.314392 loss_ctc_origin 35.744316 loss_ctc0 64.311241 lr 0.00112430 rank 0
2022-08-23 11:16:50,461 DEBUG TRAIN Batch 55/3700 loss 23.671947 loss_att 14.509480 loss_ctc 45.051041 loss_ctc_origin 34.852547 loss_ctc0 68.847519 lr 0.00112412 rank 0
2022-08-23 11:17:18,320 DEBUG TRAIN Batch 55/3800 loss 25.410698 loss_att 14.564020 loss_ctc 50.719612 loss_ctc_origin 38.151016 loss_ctc0 80.046326 lr 0.00112394 rank 0
2022-08-23 11:17:47,101 DEBUG TRAIN Batch 55/3900 loss 30.593159 loss_att 17.031834 loss_ctc 62.236252 loss_ctc_origin 49.421871 loss_ctc0 92.136475 lr 0.00112377 rank 0
2022-08-23 11:18:16,320 DEBUG TRAIN Batch 55/4000 loss 21.567795 loss_att 16.851410 loss_ctc 32.572689 loss_ctc_origin 28.089592 loss_ctc0 43.033253 lr 0.00112359 rank 0
2022-08-23 11:18:45,003 DEBUG TRAIN Batch 55/4100 loss 29.948917 loss_att 20.879333 loss_ctc 51.111282 loss_ctc_origin 37.994568 loss_ctc0 81.716949 lr 0.00112341 rank 0
2022-08-23 11:19:13,274 DEBUG TRAIN Batch 55/4200 loss 25.189817 loss_att 15.424229 loss_ctc 47.976189 loss_ctc_origin 38.832031 loss_ctc0 69.312553 lr 0.00112323 rank 0
2022-08-23 11:19:42,046 DEBUG TRAIN Batch 55/4300 loss 26.272646 loss_att 14.423414 loss_ctc 53.920853 loss_ctc_origin 41.667969 loss_ctc0 82.510918 lr 0.00112306 rank 0
2022-08-23 11:20:11,916 DEBUG TRAIN Batch 55/4400 loss 29.461472 loss_att 14.419977 loss_ctc 64.558296 loss_ctc_origin 46.312737 loss_ctc0 107.131264 lr 0.00112288 rank 0
2022-08-23 11:20:45,135 DEBUG TRAIN Batch 55/4500 loss 29.459299 loss_att 21.923946 loss_ctc 47.041786 loss_ctc_origin 35.103409 loss_ctc0 74.898003 lr 0.00112270 rank 0
2022-08-23 11:21:13,776 DEBUG TRAIN Batch 55/4600 loss 27.487577 loss_att 17.433323 loss_ctc 50.947502 loss_ctc_origin 34.245163 loss_ctc0 89.919632 lr 0.00112253 rank 0
2022-08-23 11:21:42,598 DEBUG TRAIN Batch 55/4700 loss 26.288385 loss_att 15.568428 loss_ctc 51.301617 loss_ctc_origin 38.992676 loss_ctc0 80.022476 lr 0.00112235 rank 0
2022-08-23 11:22:08,162 WARNING NaN or Inf found in input tensor.
2022-08-23 11:22:11,626 DEBUG TRAIN Batch 55/4800 loss 24.653687 loss_att 12.838222 loss_ctc 52.223099 loss_ctc_origin 39.539680 loss_ctc0 81.817734 lr 0.00112217 rank 0
2022-08-23 11:22:40,531 DEBUG TRAIN Batch 55/4900 loss 27.881424 loss_att 14.603290 loss_ctc 58.863735 loss_ctc_origin 42.309486 loss_ctc0 97.490311 lr 0.00112200 rank 0
2022-08-23 11:23:09,168 DEBUG TRAIN Batch 55/5000 loss 30.131599 loss_att 25.570568 loss_ctc 40.774002 loss_ctc_origin 38.381252 loss_ctc0 46.357079 lr 0.00112182 rank 0
2022-08-23 11:23:38,086 DEBUG TRAIN Batch 55/5100 loss 44.901505 loss_att 27.815243 loss_ctc 84.769440 loss_ctc_origin 51.746090 loss_ctc0 161.823898 lr 0.00112164 rank 0
2022-08-23 11:24:07,146 DEBUG TRAIN Batch 55/5200 loss 23.955879 loss_att 15.867519 loss_ctc 42.828720 loss_ctc_origin 34.388779 loss_ctc0 62.521919 lr 0.00112147 rank 0
2022-08-23 11:24:35,449 DEBUG TRAIN Batch 55/5300 loss 29.279108 loss_att 15.985835 loss_ctc 60.296745 loss_ctc_origin 46.004501 loss_ctc0 93.645302 lr 0.00112129 rank 0
2022-08-23 11:25:05,448 DEBUG TRAIN Batch 55/5400 loss 29.994522 loss_att 15.961374 loss_ctc 62.738533 loss_ctc_origin 47.314705 loss_ctc0 98.727463 lr 0.00112111 rank 0
2022-08-23 11:25:34,246 DEBUG TRAIN Batch 55/5500 loss 25.388325 loss_att 20.646374 loss_ctc 36.452877 loss_ctc_origin 32.757141 loss_ctc0 45.076256 lr 0.00112094 rank 0
2022-08-23 11:25:54,930 WARNING NaN or Inf found in input tensor.
2022-08-23 11:26:01,998 DEBUG TRAIN Batch 55/5600 loss 32.170677 loss_att 23.008196 loss_ctc 53.549793 loss_ctc_origin 43.096939 loss_ctc0 77.939789 lr 0.00112076 rank 0
2022-08-23 11:26:25,151 DEBUG CV Batch 55/0 loss 20.484100 loss_att 12.767780 loss_ctc 38.488846 loss_ctc_origin 21.329193 loss_ctc0 78.528030 history loss 19.279153 rank 0
2022-08-23 11:26:35,899 DEBUG CV Batch 55/100 loss 24.286087 loss_att 18.281815 loss_ctc 38.296059 loss_ctc_origin 25.506372 loss_ctc0 68.138664 history loss 30.237851 rank 0
2022-08-23 11:26:46,146 DEBUG CV Batch 55/200 loss 26.384968 loss_att 20.294338 loss_ctc 40.596436 loss_ctc_origin 29.941246 loss_ctc0 65.458542 history loss 31.479749 rank 0
2022-08-23 11:26:55,955 DEBUG CV Batch 55/300 loss 25.324348 loss_att 18.388563 loss_ctc 41.507843 loss_ctc_origin 26.562489 loss_ctc0 76.380325 history loss 30.561574 rank 0
2022-08-23 11:27:06,906 DEBUG CV Batch 55/400 loss 40.468315 loss_att 31.672033 loss_ctc 60.992970 loss_ctc_origin 43.901142 loss_ctc0 100.873901 history loss 28.884814 rank 0
2022-08-23 11:27:17,679 DEBUG CV Batch 55/500 loss 22.700432 loss_att 15.807941 loss_ctc 38.782913 loss_ctc_origin 24.451263 loss_ctc0 72.223434 history loss 28.521869 rank 0
2022-08-23 11:27:28,524 DEBUG CV Batch 55/600 loss 19.197998 loss_att 13.104120 loss_ctc 33.417049 loss_ctc_origin 22.918861 loss_ctc0 57.912815 history loss 28.354457 rank 0
2022-08-23 11:27:39,288 DEBUG CV Batch 55/700 loss 21.611626 loss_att 14.783951 loss_ctc 37.542862 loss_ctc_origin 24.895111 loss_ctc0 67.054291 history loss 27.995170 rank 0
2022-08-23 11:27:49,811 DEBUG CV Batch 55/800 loss 23.943150 loss_att 17.695805 loss_ctc 38.520283 loss_ctc_origin 23.315716 loss_ctc0 73.997604 history loss 27.946908 rank 0
2022-08-23 11:28:01,271 INFO Epoch 55 CV info cv_loss 28.01761169763755
2022-08-23 11:28:01,272 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/55.pt
2022-08-23 11:28:01,806 INFO Epoch 56 TRAIN info lr 0.0011206143726689697
2022-08-23 11:28:01,810 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 11:28:28,450 DEBUG TRAIN Batch 56/0 loss 29.678160 loss_att 23.061085 loss_ctc 45.118000 loss_ctc_origin 42.021881 loss_ctc0 52.342281 lr 0.00112061 rank 0
2022-08-23 11:28:57,297 DEBUG TRAIN Batch 56/100 loss 24.041258 loss_att 15.462075 loss_ctc 44.059349 loss_ctc_origin 36.767544 loss_ctc0 61.073566 lr 0.00112043 rank 0
2022-08-23 11:29:25,436 DEBUG TRAIN Batch 56/200 loss 26.769093 loss_att 15.937366 loss_ctc 52.043114 loss_ctc_origin 41.461571 loss_ctc0 76.733383 lr 0.00112026 rank 0
2022-08-23 11:29:31,022 WARNING NaN or Inf found in input tensor.
2022-08-23 11:29:53,642 DEBUG TRAIN Batch 56/300 loss 30.161720 loss_att 16.048084 loss_ctc 63.093536 loss_ctc_origin 52.406242 loss_ctc0 88.030563 lr 0.00112008 rank 0
2022-08-23 11:30:22,257 DEBUG TRAIN Batch 56/400 loss 26.422815 loss_att 13.454947 loss_ctc 56.681175 loss_ctc_origin 39.532288 loss_ctc0 96.695236 lr 0.00111990 rank 0
2022-08-23 11:30:51,485 DEBUG TRAIN Batch 56/500 loss 23.740158 loss_att 18.204782 loss_ctc 36.656033 loss_ctc_origin 33.524029 loss_ctc0 43.964043 lr 0.00111973 rank 0
2022-08-23 11:31:19,255 DEBUG TRAIN Batch 56/600 loss 26.013229 loss_att 17.656834 loss_ctc 45.511486 loss_ctc_origin 32.501572 loss_ctc0 75.867950 lr 0.00111955 rank 0
2022-08-23 11:31:46,254 WARNING NaN or Inf found in input tensor.
2022-08-23 11:31:47,937 DEBUG TRAIN Batch 56/700 loss 29.082775 loss_att 16.248978 loss_ctc 59.028297 loss_ctc_origin 49.179787 loss_ctc0 82.008156 lr 0.00111938 rank 0
2022-08-23 11:32:16,486 DEBUG TRAIN Batch 56/800 loss 22.456114 loss_att 10.825706 loss_ctc 49.593731 loss_ctc_origin 38.387283 loss_ctc0 75.742111 lr 0.00111920 rank 0
2022-08-23 11:32:40,935 WARNING NaN or Inf found in input tensor.
2022-08-23 11:32:45,428 DEBUG TRAIN Batch 56/900 loss 27.264709 loss_att 13.699673 loss_ctc 58.916466 loss_ctc_origin 41.819595 loss_ctc0 98.809166 lr 0.00111903 rank 0
2022-08-23 11:33:14,449 DEBUG TRAIN Batch 56/1000 loss 32.054401 loss_att 24.562469 loss_ctc 49.535580 loss_ctc_origin 45.063454 loss_ctc0 59.970543 lr 0.00111885 rank 0
2022-08-23 11:33:41,682 DEBUG TRAIN Batch 56/1100 loss 27.917458 loss_att 18.010227 loss_ctc 51.034332 loss_ctc_origin 40.648178 loss_ctc0 75.268700 lr 0.00111868 rank 0
2022-08-23 11:34:10,364 DEBUG TRAIN Batch 56/1200 loss 24.032318 loss_att 14.816889 loss_ctc 45.534988 loss_ctc_origin 36.568726 loss_ctc0 66.456268 lr 0.00111850 rank 0
2022-08-23 11:34:21,848 WARNING NaN or Inf found in input tensor.
2022-08-23 11:34:38,697 DEBUG TRAIN Batch 56/1300 loss 24.606243 loss_att 13.183983 loss_ctc 51.258183 loss_ctc_origin 37.554150 loss_ctc0 83.234253 lr 0.00111833 rank 0
2022-08-23 11:35:07,591 DEBUG TRAIN Batch 56/1400 loss 31.049095 loss_att 16.266373 loss_ctc 65.542114 loss_ctc_origin 49.271770 loss_ctc0 103.506241 lr 0.00111815 rank 0
2022-08-23 11:35:42,127 DEBUG TRAIN Batch 56/1500 loss 29.020519 loss_att 22.390903 loss_ctc 44.489624 loss_ctc_origin 40.386208 loss_ctc0 54.064262 lr 0.00111798 rank 0
2022-08-23 11:36:10,818 DEBUG TRAIN Batch 56/1600 loss 27.832546 loss_att 19.099846 loss_ctc 48.208847 loss_ctc_origin 38.796852 loss_ctc0 70.170166 lr 0.00111780 rank 0
2022-08-23 11:36:38,216 DEBUG TRAIN Batch 56/1700 loss 25.181648 loss_att 15.121731 loss_ctc 48.654789 loss_ctc_origin 39.864758 loss_ctc0 69.164856 lr 0.00111763 rank 0
2022-08-23 11:37:06,806 DEBUG TRAIN Batch 56/1800 loss 30.119564 loss_att 16.355785 loss_ctc 62.235046 loss_ctc_origin 51.439724 loss_ctc0 87.424126 lr 0.00111745 rank 0
2022-08-23 11:37:34,758 DEBUG TRAIN Batch 56/1900 loss 32.152664 loss_att 16.670763 loss_ctc 68.277100 loss_ctc_origin 53.478161 loss_ctc0 102.807968 lr 0.00111728 rank 0
2022-08-23 11:38:03,828 DEBUG TRAIN Batch 56/2000 loss 36.130009 loss_att 26.388094 loss_ctc 58.861137 loss_ctc_origin 46.856094 loss_ctc0 86.872894 lr 0.00111711 rank 0
2022-08-23 11:38:32,096 DEBUG TRAIN Batch 56/2100 loss 39.661919 loss_att 27.959969 loss_ctc 66.966461 loss_ctc_origin 51.897404 loss_ctc0 102.127594 lr 0.00111693 rank 0
2022-08-23 11:39:00,508 DEBUG TRAIN Batch 56/2200 loss 27.536144 loss_att 18.078741 loss_ctc 49.603416 loss_ctc_origin 40.246143 loss_ctc0 71.437057 lr 0.00111676 rank 0
2022-08-23 11:39:29,912 DEBUG TRAIN Batch 56/2300 loss 24.242157 loss_att 12.537615 loss_ctc 51.552753 loss_ctc_origin 37.675491 loss_ctc0 83.933029 lr 0.00111658 rank 0
2022-08-23 11:39:58,285 DEBUG TRAIN Batch 56/2400 loss 29.560726 loss_att 15.859627 loss_ctc 61.529953 loss_ctc_origin 45.129929 loss_ctc0 99.796677 lr 0.00111641 rank 0
2022-08-23 11:40:27,709 DEBUG TRAIN Batch 56/2500 loss 35.835491 loss_att 28.969877 loss_ctc 51.855255 loss_ctc_origin 43.075462 loss_ctc0 72.341431 lr 0.00111624 rank 0
2022-08-23 11:40:28,355 WARNING NaN or Inf found in input tensor.
2022-08-23 11:40:56,701 DEBUG TRAIN Batch 56/2600 loss 35.968052 loss_att 23.716206 loss_ctc 64.555695 loss_ctc_origin 46.139889 loss_ctc0 107.525917 lr 0.00111606 rank 0
2022-08-23 11:41:24,542 DEBUG TRAIN Batch 56/2700 loss 30.052549 loss_att 19.916267 loss_ctc 53.703869 loss_ctc_origin 45.401005 loss_ctc0 73.077217 lr 0.00111589 rank 0
2022-08-23 11:41:53,520 DEBUG TRAIN Batch 56/2800 loss 26.778847 loss_att 13.817966 loss_ctc 57.020905 loss_ctc_origin 47.690132 loss_ctc0 78.792709 lr 0.00111571 rank 0
2022-08-23 11:42:02,033 WARNING NaN or Inf found in input tensor.
2022-08-23 11:42:21,073 DEBUG TRAIN Batch 56/2900 loss 35.757595 loss_att 20.298809 loss_ctc 71.828094 loss_ctc_origin 57.811798 loss_ctc0 104.532791 lr 0.00111554 rank 0
2022-08-23 11:42:56,320 DEBUG TRAIN Batch 56/3000 loss 26.272726 loss_att 22.070759 loss_ctc 36.077316 loss_ctc_origin 31.401642 loss_ctc0 46.987221 lr 0.00111537 rank 0
2022-08-23 11:43:04,202 WARNING NaN or Inf found in input tensor.
2022-08-23 11:43:25,001 DEBUG TRAIN Batch 56/3100 loss 35.120750 loss_att 23.249519 loss_ctc 62.820290 loss_ctc_origin 40.133347 loss_ctc0 115.756493 lr 0.00111519 rank 0
2022-08-23 11:43:54,625 DEBUG TRAIN Batch 56/3200 loss 25.012520 loss_att 16.143820 loss_ctc 45.706150 loss_ctc_origin 36.056225 loss_ctc0 68.222641 lr 0.00111502 rank 0
2022-08-23 11:44:22,938 DEBUG TRAIN Batch 56/3300 loss 24.799210 loss_att 11.799835 loss_ctc 55.131084 loss_ctc_origin 40.747879 loss_ctc0 88.691895 lr 0.00111485 rank 0
2022-08-23 11:44:51,654 DEBUG TRAIN Batch 56/3400 loss 24.925896 loss_att 12.128613 loss_ctc 54.786224 loss_ctc_origin 37.345032 loss_ctc0 95.482346 lr 0.00111467 rank 0
2022-08-23 11:45:20,702 DEBUG TRAIN Batch 56/3500 loss 32.915573 loss_att 26.741543 loss_ctc 47.321640 loss_ctc_origin 46.242985 loss_ctc0 49.838493 lr 0.00111450 rank 0
2022-08-23 11:45:49,014 DEBUG TRAIN Batch 56/3600 loss 30.100117 loss_att 18.319839 loss_ctc 57.587433 loss_ctc_origin 34.823811 loss_ctc0 110.702545 lr 0.00111433 rank 0
2022-08-23 11:46:17,656 DEBUG TRAIN Batch 56/3700 loss 29.545090 loss_att 17.705978 loss_ctc 57.169682 loss_ctc_origin 48.950722 loss_ctc0 76.347260 lr 0.00111416 rank 0
2022-08-23 11:46:23,244 WARNING NaN or Inf found in input tensor.
2022-08-23 11:46:45,581 DEBUG TRAIN Batch 56/3800 loss 21.609140 loss_att 9.790575 loss_ctc 49.185791 loss_ctc_origin 34.863888 loss_ctc0 82.603561 lr 0.00111398 rank 0
2022-08-23 11:47:14,282 DEBUG TRAIN Batch 56/3900 loss 33.117500 loss_att 18.402250 loss_ctc 67.453079 loss_ctc_origin 50.550869 loss_ctc0 106.891579 lr 0.00111381 rank 0
2022-08-23 11:47:42,402 DEBUG TRAIN Batch 56/4000 loss 29.900951 loss_att 23.370464 loss_ctc 45.138756 loss_ctc_origin 42.486153 loss_ctc0 51.328163 lr 0.00111364 rank 0
2022-08-23 11:48:10,995 DEBUG TRAIN Batch 56/4100 loss 34.684662 loss_att 25.157303 loss_ctc 56.915161 loss_ctc_origin 43.084648 loss_ctc0 89.186356 lr 0.00111346 rank 0
2022-08-23 11:48:40,241 DEBUG TRAIN Batch 56/4200 loss 26.272549 loss_att 17.847569 loss_ctc 45.930840 loss_ctc_origin 37.529724 loss_ctc0 65.533432 lr 0.00111329 rank 0
2022-08-23 11:49:08,645 DEBUG TRAIN Batch 56/4300 loss 24.462347 loss_att 12.426138 loss_ctc 52.546833 loss_ctc_origin 40.179039 loss_ctc0 81.405022 lr 0.00111312 rank 0
2022-08-23 11:49:35,988 DEBUG TRAIN Batch 56/4400 loss 29.496452 loss_att 15.474051 loss_ctc 62.215389 loss_ctc_origin 45.208199 loss_ctc0 101.898834 lr 0.00111295 rank 0
2022-08-23 11:50:11,110 DEBUG TRAIN Batch 56/4500 loss 31.561771 loss_att 26.078430 loss_ctc 44.356232 loss_ctc_origin 41.418068 loss_ctc0 51.211945 lr 0.00111277 rank 0
2022-08-23 11:50:18,987 WARNING NaN or Inf found in input tensor.
2022-08-23 11:50:39,258 DEBUG TRAIN Batch 56/4600 loss 38.277489 loss_att 26.521168 loss_ctc 65.708908 loss_ctc_origin 57.617657 loss_ctc0 84.588493 lr 0.00111260 rank 0
2022-08-23 11:51:08,208 DEBUG TRAIN Batch 56/4700 loss 25.609859 loss_att 14.631677 loss_ctc 51.225616 loss_ctc_origin 42.140450 loss_ctc0 72.424332 lr 0.00111243 rank 0
2022-08-23 11:51:34,026 WARNING NaN or Inf found in input tensor.
2022-08-23 11:51:36,691 DEBUG TRAIN Batch 56/4800 loss 25.433670 loss_att 14.582811 loss_ctc 50.752335 loss_ctc_origin 37.775185 loss_ctc0 81.032356 lr 0.00111226 rank 0
2022-08-23 11:52:04,900 DEBUG TRAIN Batch 56/4900 loss 26.826408 loss_att 13.310297 loss_ctc 58.363998 loss_ctc_origin 43.751259 loss_ctc0 92.460388 lr 0.00111209 rank 0
2022-08-23 11:52:34,472 DEBUG TRAIN Batch 56/5000 loss 31.340359 loss_att 25.084173 loss_ctc 45.938118 loss_ctc_origin 38.553890 loss_ctc0 63.167988 lr 0.00111191 rank 0
2022-08-23 11:53:01,864 DEBUG TRAIN Batch 56/5100 loss 38.854004 loss_att 26.399429 loss_ctc 67.914673 loss_ctc_origin 51.062054 loss_ctc0 107.237457 lr 0.00111174 rank 0
2022-08-23 11:53:30,078 DEBUG TRAIN Batch 56/5200 loss 26.845879 loss_att 17.911354 loss_ctc 47.693100 loss_ctc_origin 39.006393 loss_ctc0 67.962082 lr 0.00111157 rank 0
2022-08-23 11:53:59,359 DEBUG TRAIN Batch 56/5300 loss 25.691494 loss_att 13.464396 loss_ctc 54.221390 loss_ctc_origin 40.463856 loss_ctc0 86.322296 lr 0.00111140 rank 0
2022-08-23 11:54:27,875 DEBUG TRAIN Batch 56/5400 loss 28.506136 loss_att 15.047709 loss_ctc 59.909134 loss_ctc_origin 44.595406 loss_ctc0 95.641159 lr 0.00111123 rank 0
2022-08-23 11:54:43,576 WARNING NaN or Inf found in input tensor.
2022-08-23 11:54:56,444 DEBUG TRAIN Batch 56/5500 loss 30.394062 loss_att 22.658295 loss_ctc 48.444187 loss_ctc_origin 39.288666 loss_ctc0 69.807068 lr 0.00111106 rank 0
2022-08-23 11:55:25,488 DEBUG TRAIN Batch 56/5600 loss 26.094023 loss_att 17.537258 loss_ctc 46.059807 loss_ctc_origin 35.494667 loss_ctc0 70.711807 lr 0.00111088 rank 0
2022-08-23 11:55:48,832 DEBUG CV Batch 56/0 loss 15.963991 loss_att 11.836420 loss_ctc 25.594992 loss_ctc_origin 20.084465 loss_ctc0 38.452888 history loss 15.024933 rank 0
2022-08-23 11:55:59,992 DEBUG CV Batch 56/100 loss 22.185280 loss_att 16.850595 loss_ctc 34.632874 loss_ctc_origin 24.169781 loss_ctc0 59.046764 history loss 29.867894 rank 0
2022-08-23 11:56:10,285 DEBUG CV Batch 56/200 loss 27.930290 loss_att 21.434874 loss_ctc 43.086258 loss_ctc_origin 32.484375 loss_ctc0 67.823990 history loss 30.914244 rank 0
2022-08-23 11:56:20,808 DEBUG CV Batch 56/300 loss 25.376587 loss_att 18.565117 loss_ctc 41.270016 loss_ctc_origin 26.253155 loss_ctc0 76.309357 history loss 30.045248 rank 0
2022-08-23 11:56:30,703 DEBUG CV Batch 56/400 loss 40.460281 loss_att 31.633478 loss_ctc 61.056149 loss_ctc_origin 44.161671 loss_ctc0 100.476593 history loss 28.350186 rank 0
2022-08-23 11:56:40,929 DEBUG CV Batch 56/500 loss 19.305452 loss_att 14.257090 loss_ctc 31.084967 loss_ctc_origin 24.013237 loss_ctc0 47.585670 history loss 28.009777 rank 0
2022-08-23 11:56:51,265 DEBUG CV Batch 56/600 loss 18.987663 loss_att 12.570362 loss_ctc 33.961361 loss_ctc_origin 23.542763 loss_ctc0 58.271423 history loss 27.874560 rank 0
2022-08-23 11:57:01,050 DEBUG CV Batch 56/700 loss 20.906063 loss_att 14.296021 loss_ctc 36.329498 loss_ctc_origin 23.318863 loss_ctc0 66.687637 history loss 27.505902 rank 0
2022-08-23 11:57:10,886 DEBUG CV Batch 56/800 loss 24.263453 loss_att 18.155685 loss_ctc 38.514908 loss_ctc_origin 23.450264 loss_ctc0 73.665741 history loss 27.482502 rank 0
2022-08-23 11:57:20,957 INFO Epoch 56 CV info cv_loss 27.575429463075345
2022-08-23 11:57:20,958 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/56.pt
2022-08-23 11:57:21,447 INFO Epoch 57 TRAIN info lr 0.0011107409258231053
2022-08-23 11:57:21,451 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 11:57:48,818 DEBUG TRAIN Batch 57/0 loss 24.201550 loss_att 18.531050 loss_ctc 37.432713 loss_ctc_origin 35.277191 loss_ctc0 42.462265 lr 0.00111073 rank 0
2022-08-23 11:57:56,804 WARNING NaN or Inf found in input tensor.
2022-08-23 11:58:17,533 DEBUG TRAIN Batch 57/100 loss 26.983032 loss_att 19.076591 loss_ctc 45.431396 loss_ctc_origin 32.468575 loss_ctc0 75.677971 lr 0.00111056 rank 0
2022-08-23 11:58:46,299 DEBUG TRAIN Batch 57/200 loss 24.094616 loss_att 14.559860 loss_ctc 46.342381 loss_ctc_origin 36.634102 loss_ctc0 68.995026 lr 0.00111039 rank 0
2022-08-23 11:59:14,563 DEBUG TRAIN Batch 57/300 loss 22.581631 loss_att 11.618668 loss_ctc 48.161873 loss_ctc_origin 35.876595 loss_ctc0 76.827515 lr 0.00111022 rank 0
2022-08-23 11:59:43,232 DEBUG TRAIN Batch 57/400 loss 33.076618 loss_att 17.701481 loss_ctc 68.951935 loss_ctc_origin 54.162880 loss_ctc0 103.459709 lr 0.00111005 rank 0
2022-08-23 12:00:11,688 DEBUG TRAIN Batch 57/500 loss 28.617403 loss_att 21.763187 loss_ctc 44.610573 loss_ctc_origin 39.405960 loss_ctc0 56.754673 lr 0.00110988 rank 0
2022-08-23 12:00:39,789 WARNING NaN or Inf found in input tensor.
2022-08-23 12:00:39,837 DEBUG TRAIN Batch 57/600 loss nan loss_att 23.145607 loss_ctc nan loss_ctc_origin 39.648098 loss_ctc0 nan lr 0.00110971 rank 0
2022-08-23 12:01:07,958 DEBUG TRAIN Batch 57/700 loss 26.999161 loss_att 16.468575 loss_ctc 51.570526 loss_ctc_origin 42.370399 loss_ctc0 73.037491 lr 0.00110954 rank 0
2022-08-23 12:01:36,719 DEBUG TRAIN Batch 57/800 loss 20.878269 loss_att 10.359156 loss_ctc 45.422867 loss_ctc_origin 31.939837 loss_ctc0 76.883270 lr 0.00110937 rank 0
2022-08-23 12:02:05,795 DEBUG TRAIN Batch 57/900 loss 31.621368 loss_att 15.732010 loss_ctc 68.696541 loss_ctc_origin 53.331211 loss_ctc0 104.548981 lr 0.00110920 rank 0
2022-08-23 12:02:33,735 DEBUG TRAIN Batch 57/1000 loss 24.474752 loss_att 19.472706 loss_ctc 36.146194 loss_ctc_origin 33.334709 loss_ctc0 42.706322 lr 0.00110903 rank 0
2022-08-23 12:03:01,040 WARNING NaN or Inf found in input tensor.
2022-08-23 12:03:01,777 WARNING NaN or Inf found in input tensor.
2022-08-23 12:03:01,822 DEBUG TRAIN Batch 57/1100 loss nan loss_att 21.608181 loss_ctc nan loss_ctc_origin 43.171242 loss_ctc0 nan lr 0.00110885 rank 0
2022-08-23 12:03:31,575 DEBUG TRAIN Batch 57/1200 loss 24.776344 loss_att 14.515220 loss_ctc 48.718967 loss_ctc_origin 37.598850 loss_ctc0 74.665909 lr 0.00110868 rank 0
2022-08-23 12:04:00,913 DEBUG TRAIN Batch 57/1300 loss 23.296169 loss_att 10.714833 loss_ctc 52.652622 loss_ctc_origin 40.852131 loss_ctc0 80.187103 lr 0.00110851 rank 0
2022-08-23 12:04:30,427 DEBUG TRAIN Batch 57/1400 loss 27.036890 loss_att 13.618010 loss_ctc 58.347610 loss_ctc_origin 42.539742 loss_ctc0 95.232643 lr 0.00110834 rank 0
2022-08-23 12:05:04,763 DEBUG TRAIN Batch 57/1500 loss 34.072868 loss_att 25.386862 loss_ctc 54.340218 loss_ctc_origin 40.685249 loss_ctc0 86.201805 lr 0.00110817 rank 0
2022-08-23 12:05:34,065 DEBUG TRAIN Batch 57/1600 loss 36.839546 loss_att 24.921211 loss_ctc 64.649002 loss_ctc_origin 46.652740 loss_ctc0 106.640274 lr 0.00110800 rank 0
2022-08-23 12:06:04,077 DEBUG TRAIN Batch 57/1700 loss 22.870718 loss_att 14.117705 loss_ctc 43.294411 loss_ctc_origin 33.878448 loss_ctc0 65.264984 lr 0.00110783 rank 0
2022-08-23 12:06:33,159 DEBUG TRAIN Batch 57/1800 loss 28.284626 loss_att 14.670128 loss_ctc 60.051781 loss_ctc_origin 49.770054 loss_ctc0 84.042465 lr 0.00110766 rank 0
2022-08-23 12:07:00,980 DEBUG TRAIN Batch 57/1900 loss 27.543814 loss_att 15.008442 loss_ctc 56.793015 loss_ctc_origin 41.947388 loss_ctc0 91.432816 lr 0.00110749 rank 0
2022-08-23 12:07:30,146 DEBUG TRAIN Batch 57/2000 loss 29.103134 loss_att 23.794565 loss_ctc 41.489792 loss_ctc_origin 34.001457 loss_ctc0 58.962563 lr 0.00110732 rank 0
2022-08-23 12:07:37,965 WARNING NaN or Inf found in input tensor.
2022-08-23 12:07:58,338 DEBUG TRAIN Batch 57/2100 loss 31.242428 loss_att 20.546700 loss_ctc 56.199120 loss_ctc_origin 37.096317 loss_ctc0 100.772316 lr 0.00110715 rank 0
2022-08-23 12:08:26,460 DEBUG TRAIN Batch 57/2200 loss 21.359737 loss_att 12.246907 loss_ctc 42.623009 loss_ctc_origin 31.493626 loss_ctc0 68.591568 lr 0.00110698 rank 0
2022-08-23 12:08:55,838 DEBUG TRAIN Batch 57/2300 loss 24.484283 loss_att 12.995279 loss_ctc 51.291962 loss_ctc_origin 38.118752 loss_ctc0 82.029442 lr 0.00110682 rank 0
2022-08-23 12:09:24,393 DEBUG TRAIN Batch 57/2400 loss 31.446508 loss_att 17.637297 loss_ctc 63.667999 loss_ctc_origin 48.856468 loss_ctc0 98.228226 lr 0.00110665 rank 0
2022-08-23 12:09:53,209 DEBUG TRAIN Batch 57/2500 loss 23.767506 loss_att 18.681826 loss_ctc 35.634094 loss_ctc_origin 31.731726 loss_ctc0 44.739624 lr 0.00110648 rank 0
2022-08-23 12:10:22,246 DEBUG TRAIN Batch 57/2600 loss 31.002192 loss_att 20.426788 loss_ctc 55.678131 loss_ctc_origin 38.576416 loss_ctc0 95.582138 lr 0.00110631 rank 0
2022-08-23 12:10:51,139 DEBUG TRAIN Batch 57/2700 loss 23.829903 loss_att 14.638797 loss_ctc 45.275818 loss_ctc_origin 36.205139 loss_ctc0 66.440727 lr 0.00110614 rank 0
2022-08-23 12:11:19,950 DEBUG TRAIN Batch 57/2800 loss 25.542095 loss_att 13.230120 loss_ctc 54.270039 loss_ctc_origin 39.231953 loss_ctc0 89.358902 lr 0.00110597 rank 0
2022-08-23 12:11:49,023 DEBUG TRAIN Batch 57/2900 loss 28.423481 loss_att 14.041471 loss_ctc 61.981503 loss_ctc_origin 48.114441 loss_ctc0 94.337982 lr 0.00110580 rank 0
2022-08-23 12:12:22,346 DEBUG TRAIN Batch 57/3000 loss 27.204407 loss_att 20.527578 loss_ctc 42.783676 loss_ctc_origin 36.132820 loss_ctc0 58.302334 lr 0.00110563 rank 0
2022-08-23 12:12:51,616 DEBUG TRAIN Batch 57/3100 loss 34.623379 loss_att 24.069267 loss_ctc 59.249641 loss_ctc_origin 37.338058 loss_ctc0 110.376663 lr 0.00110546 rank 0
2022-08-23 12:13:19,966 DEBUG TRAIN Batch 57/3200 loss 24.144400 loss_att 15.465703 loss_ctc 44.394691 loss_ctc_origin 34.642460 loss_ctc0 67.149902 lr 0.00110529 rank 0
2022-08-23 12:13:49,370 DEBUG TRAIN Batch 57/3300 loss 24.532558 loss_att 13.181297 loss_ctc 51.018833 loss_ctc_origin 37.321625 loss_ctc0 82.978981 lr 0.00110512 rank 0
2022-08-23 12:14:18,183 DEBUG TRAIN Batch 57/3400 loss 27.013023 loss_att 13.213102 loss_ctc 59.212837 loss_ctc_origin 44.166740 loss_ctc0 94.320404 lr 0.00110496 rank 0
2022-08-23 12:14:47,324 DEBUG TRAIN Batch 57/3500 loss 31.547937 loss_att 24.572165 loss_ctc 47.824738 loss_ctc_origin 35.117332 loss_ctc0 77.475342 lr 0.00110479 rank 0
2022-08-23 12:15:08,592 WARNING NaN or Inf found in input tensor.
2022-08-23 12:15:16,051 DEBUG TRAIN Batch 57/3600 loss 33.111012 loss_att 21.181017 loss_ctc 60.947666 loss_ctc_origin 39.893337 loss_ctc0 110.074432 lr 0.00110462 rank 0
2022-08-23 12:15:43,000 WARNING NaN or Inf found in input tensor.
2022-08-23 12:15:44,634 DEBUG TRAIN Batch 57/3700 loss 23.781719 loss_att 12.819843 loss_ctc 49.359428 loss_ctc_origin 38.384239 loss_ctc0 74.968193 lr 0.00110445 rank 0
2022-08-23 12:16:13,219 DEBUG TRAIN Batch 57/3800 loss 26.316597 loss_att 14.069818 loss_ctc 54.892410 loss_ctc_origin 42.429054 loss_ctc0 83.973564 lr 0.00110428 rank 0
2022-08-23 12:16:42,676 DEBUG TRAIN Batch 57/3900 loss 32.365883 loss_att 17.474651 loss_ctc 67.112091 loss_ctc_origin 50.064121 loss_ctc0 106.890686 lr 0.00110411 rank 0
2022-08-23 12:17:12,140 DEBUG TRAIN Batch 57/4000 loss 28.895767 loss_att 22.785902 loss_ctc 43.152115 loss_ctc_origin 39.232121 loss_ctc0 52.298759 lr 0.00110395 rank 0
2022-08-23 12:17:39,213 WARNING NaN or Inf found in input tensor.
2022-08-23 12:17:39,970 DEBUG TRAIN Batch 57/4100 loss 33.525490 loss_att 23.408318 loss_ctc 57.132229 loss_ctc_origin 42.529987 loss_ctc0 91.204124 lr 0.00110378 rank 0
2022-08-23 12:18:08,772 DEBUG TRAIN Batch 57/4200 loss 22.709229 loss_att 14.268274 loss_ctc 42.404785 loss_ctc_origin 33.247746 loss_ctc0 63.771202 lr 0.00110361 rank 0
2022-08-23 12:18:39,098 DEBUG TRAIN Batch 57/4300 loss 29.282024 loss_att 17.057125 loss_ctc 57.806786 loss_ctc_origin 47.497452 loss_ctc0 81.861900 lr 0.00110344 rank 0
2022-08-23 12:19:06,709 DEBUG TRAIN Batch 57/4400 loss 28.261116 loss_att 13.995349 loss_ctc 61.547897 loss_ctc_origin 45.231537 loss_ctc0 99.619400 lr 0.00110327 rank 0
2022-08-23 12:19:41,590 DEBUG TRAIN Batch 57/4500 loss 29.831459 loss_att 23.988394 loss_ctc 43.465275 loss_ctc_origin 41.897541 loss_ctc0 47.123318 lr 0.00110311 rank 0
2022-08-23 12:20:10,707 DEBUG TRAIN Batch 57/4600 loss 29.337532 loss_att 17.930796 loss_ctc 55.953255 loss_ctc_origin 40.748932 loss_ctc0 91.430000 lr 0.00110294 rank 0
2022-08-23 12:20:39,687 DEBUG TRAIN Batch 57/4700 loss 20.618248 loss_att 12.247949 loss_ctc 40.148949 loss_ctc_origin 29.130913 loss_ctc0 65.857697 lr 0.00110277 rank 0
2022-08-23 12:21:07,686 DEBUG TRAIN Batch 57/4800 loss 29.714067 loss_att 17.764427 loss_ctc 57.596558 loss_ctc_origin 45.075874 loss_ctc0 86.811485 lr 0.00110260 rank 0
2022-08-23 12:21:35,710 DEBUG TRAIN Batch 57/4900 loss 29.523621 loss_att 15.748459 loss_ctc 61.665657 loss_ctc_origin 47.317715 loss_ctc0 95.144196 lr 0.00110243 rank 0
2022-08-23 12:22:05,387 DEBUG TRAIN Batch 57/5000 loss 32.247314 loss_att 24.911642 loss_ctc 49.363884 loss_ctc_origin 42.030933 loss_ctc0 66.474091 lr 0.00110227 rank 0
2022-08-23 12:22:32,633 DEBUG TRAIN Batch 57/5100 loss 31.696175 loss_att 22.773468 loss_ctc 52.515823 loss_ctc_origin 37.070713 loss_ctc0 88.554413 lr 0.00110210 rank 0
2022-08-23 12:23:00,419 DEBUG TRAIN Batch 57/5200 loss 22.945215 loss_att 13.685775 loss_ctc 44.550575 loss_ctc_origin 32.871983 loss_ctc0 71.800629 lr 0.00110193 rank 0
2022-08-23 12:23:29,526 DEBUG TRAIN Batch 57/5300 loss 23.586435 loss_att 12.005456 loss_ctc 50.608719 loss_ctc_origin 39.277031 loss_ctc0 77.049332 lr 0.00110177 rank 0
2022-08-23 12:23:58,328 DEBUG TRAIN Batch 57/5400 loss 32.117821 loss_att 18.054960 loss_ctc 64.931168 loss_ctc_origin 50.267937 loss_ctc0 99.145386 lr 0.00110160 rank 0
2022-08-23 12:24:27,652 DEBUG TRAIN Batch 57/5500 loss 29.916473 loss_att 24.104233 loss_ctc 43.478371 loss_ctc_origin 37.258553 loss_ctc0 57.991272 lr 0.00110143 rank 0
2022-08-23 12:24:42,459 WARNING NaN or Inf found in input tensor.
2022-08-23 12:24:56,672 DEBUG TRAIN Batch 57/5600 loss 45.175934 loss_att 28.030949 loss_ctc 85.180893 loss_ctc_origin 46.051407 loss_ctc0 176.483032 lr 0.00110126 rank 0
2022-08-23 12:25:20,027 DEBUG CV Batch 57/0 loss 29.556320 loss_att 17.677078 loss_ctc 57.274551 loss_ctc_origin 29.588505 loss_ctc0 121.875320 history loss 27.817713 rank 0
2022-08-23 12:25:30,944 DEBUG CV Batch 57/100 loss 52.378735 loss_att 31.926910 loss_ctc 100.099655 loss_ctc_origin 50.237045 loss_ctc0 216.445724 history loss 38.440771 rank 0
2022-08-23 12:25:40,832 DEBUG CV Batch 57/200 loss 29.869804 loss_att 23.269497 loss_ctc 45.270523 loss_ctc_origin 35.995888 loss_ctc0 66.911346 history loss 41.166054 rank 0
2022-08-23 12:25:50,973 DEBUG CV Batch 57/300 loss 27.045429 loss_att 19.668051 loss_ctc 44.259315 loss_ctc_origin 30.138845 loss_ctc0 77.207077 history loss 40.526556 rank 0
2022-08-23 12:26:01,686 DEBUG CV Batch 57/400 loss 40.574093 loss_att 31.590336 loss_ctc 61.536186 loss_ctc_origin 44.662109 loss_ctc0 100.909027 history loss 38.221062 rank 0
2022-08-23 12:26:12,691 DEBUG CV Batch 57/500 loss 36.910820 loss_att 24.253319 loss_ctc 66.444977 loss_ctc_origin 36.528061 loss_ctc0 136.251099 history loss 37.781492 rank 0
2022-08-23 12:26:23,686 DEBUG CV Batch 57/600 loss 31.519325 loss_att 18.801846 loss_ctc 61.193439 loss_ctc_origin 34.582504 loss_ctc0 123.285614 history loss 37.878257 rank 0
2022-08-23 12:26:33,884 DEBUG CV Batch 57/700 loss 22.004057 loss_att 15.188721 loss_ctc 37.906509 loss_ctc_origin 25.399616 loss_ctc0 67.089249 history loss 37.409785 rank 0
2022-08-23 12:26:44,416 DEBUG CV Batch 57/800 loss 24.872932 loss_att 18.531776 loss_ctc 39.668961 loss_ctc_origin 25.080523 loss_ctc0 73.708641 history loss 37.205659 rank 0
2022-08-23 12:26:54,824 INFO Epoch 57 CV info cv_loss 36.938508499772816
2022-08-23 12:26:54,824 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/57.pt
2022-08-23 12:26:55,291 INFO Epoch 58 TRAIN info lr 0.001101123940258528
2022-08-23 12:26:55,294 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 12:27:22,346 DEBUG TRAIN Batch 58/0 loss 24.334984 loss_att 18.951939 loss_ctc 36.895428 loss_ctc_origin 33.978813 loss_ctc0 43.700859 lr 0.00110112 rank 0
2022-08-23 12:27:51,087 DEBUG TRAIN Batch 58/100 loss 44.480015 loss_att 25.438627 loss_ctc 88.909912 loss_ctc_origin 43.658558 loss_ctc0 194.496384 lr 0.00110095 rank 0
2022-08-23 12:28:19,703 DEBUG TRAIN Batch 58/200 loss 26.076420 loss_att 17.631157 loss_ctc 45.782036 loss_ctc_origin 34.749802 loss_ctc0 71.523911 lr 0.00110078 rank 0
2022-08-23 12:28:48,926 DEBUG TRAIN Batch 58/300 loss 24.828144 loss_att 11.309258 loss_ctc 56.372211 loss_ctc_origin 44.170769 loss_ctc0 84.842239 lr 0.00110062 rank 0
2022-08-23 12:29:17,281 DEBUG TRAIN Batch 58/400 loss 29.203148 loss_att 14.592634 loss_ctc 63.294342 loss_ctc_origin 48.530460 loss_ctc0 97.743408 lr 0.00110045 rank 0
2022-08-23 12:29:19,905 WARNING NaN or Inf found in input tensor.
2022-08-23 12:29:47,118 DEBUG TRAIN Batch 58/500 loss 27.699560 loss_att 19.549206 loss_ctc 46.717052 loss_ctc_origin 35.751686 loss_ctc0 72.302902 lr 0.00110028 rank 0
2022-08-23 12:30:09,295 WARNING NaN or Inf found in input tensor.
2022-08-23 12:30:16,446 DEBUG TRAIN Batch 58/600 loss 45.318054 loss_att 27.307880 loss_ctc 87.341782 loss_ctc_origin 48.793877 loss_ctc0 177.286896 lr 0.00110012 rank 0
2022-08-23 12:30:45,570 DEBUG TRAIN Batch 58/700 loss 24.167351 loss_att 14.454988 loss_ctc 46.829529 loss_ctc_origin 36.663895 loss_ctc0 70.549347 lr 0.00109995 rank 0
2022-08-23 12:30:51,159 WARNING NaN or Inf found in input tensor.
2022-08-23 12:31:13,917 DEBUG TRAIN Batch 58/800 loss 25.988480 loss_att 12.495912 loss_ctc 57.471130 loss_ctc_origin 45.984516 loss_ctc0 84.273224 lr 0.00109978 rank 0
2022-08-23 12:31:43,639 DEBUG TRAIN Batch 58/900 loss 27.151152 loss_att 13.634197 loss_ctc 58.690712 loss_ctc_origin 42.353912 loss_ctc0 96.809914 lr 0.00109962 rank 0
2022-08-23 12:32:13,233 DEBUG TRAIN Batch 58/1000 loss 26.069498 loss_att 20.587721 loss_ctc 38.860310 loss_ctc_origin 36.962494 loss_ctc0 43.288551 lr 0.00109945 rank 0
2022-08-23 12:32:28,343 WARNING NaN or Inf found in input tensor.
2022-08-23 12:32:41,848 DEBUG TRAIN Batch 58/1100 loss 46.338871 loss_att 29.591797 loss_ctc 85.415375 loss_ctc_origin 48.917858 loss_ctc0 170.576248 lr 0.00109929 rank 0
2022-08-23 12:33:12,238 DEBUG TRAIN Batch 58/1200 loss 28.403862 loss_att 18.741684 loss_ctc 50.948944 loss_ctc_origin 42.301212 loss_ctc0 71.126991 lr 0.00109912 rank 0
2022-08-23 12:33:42,261 DEBUG TRAIN Batch 58/1300 loss 27.890760 loss_att 13.538965 loss_ctc 61.378281 loss_ctc_origin 47.158363 loss_ctc0 94.558090 lr 0.00109895 rank 0
2022-08-23 12:34:11,471 DEBUG TRAIN Batch 58/1400 loss 27.764669 loss_att 14.436918 loss_ctc 58.862755 loss_ctc_origin 41.662617 loss_ctc0 98.996414 lr 0.00109879 rank 0
2022-08-23 12:34:46,166 DEBUG TRAIN Batch 58/1500 loss 34.646301 loss_att 25.998785 loss_ctc 54.823837 loss_ctc_origin 40.644165 loss_ctc0 87.909744 lr 0.00109862 rank 0
2022-08-23 12:35:14,815 DEBUG TRAIN Batch 58/1600 loss 47.117172 loss_att 28.213791 loss_ctc 91.225052 loss_ctc_origin 52.965828 loss_ctc0 180.496552 lr 0.00109846 rank 0
2022-08-23 12:35:43,708 DEBUG TRAIN Batch 58/1700 loss 26.614601 loss_att 14.686047 loss_ctc 54.447899 loss_ctc_origin 43.538986 loss_ctc0 79.902039 lr 0.00109829 rank 0
2022-08-23 12:36:13,479 DEBUG TRAIN Batch 58/1800 loss 27.743362 loss_att 14.517328 loss_ctc 58.604111 loss_ctc_origin 47.121437 loss_ctc0 85.397018 lr 0.00109813 rank 0
2022-08-23 12:36:41,864 DEBUG TRAIN Batch 58/1900 loss 27.188778 loss_att 13.576146 loss_ctc 58.951576 loss_ctc_origin 45.450771 loss_ctc0 90.453453 lr 0.00109796 rank 0
2022-08-23 12:36:51,575 WARNING NaN or Inf found in input tensor.
2022-08-23 12:37:10,358 DEBUG TRAIN Batch 58/2000 loss 30.609566 loss_att 25.058798 loss_ctc 43.561356 loss_ctc_origin 42.289276 loss_ctc0 46.529537 lr 0.00109779 rank 0
2022-08-23 12:37:39,265 DEBUG TRAIN Batch 58/2100 loss 43.413631 loss_att 27.799698 loss_ctc 79.846146 loss_ctc_origin 45.362053 loss_ctc0 160.309021 lr 0.00109763 rank 0
2022-08-23 12:38:08,233 DEBUG TRAIN Batch 58/2200 loss 27.867840 loss_att 19.119791 loss_ctc 48.279953 loss_ctc_origin 39.877968 loss_ctc0 67.884590 lr 0.00109746 rank 0
2022-08-23 12:38:37,165 DEBUG TRAIN Batch 58/2300 loss 32.489307 loss_att 18.749413 loss_ctc 64.549057 loss_ctc_origin 52.298615 loss_ctc0 93.133415 lr 0.00109730 rank 0
2022-08-23 12:39:01,012 WARNING NaN or Inf found in input tensor.
2022-08-23 12:39:05,437 DEBUG TRAIN Batch 58/2400 loss 31.278625 loss_att 16.471050 loss_ctc 65.829628 loss_ctc_origin 51.413170 loss_ctc0 99.468033 lr 0.00109713 rank 0
2022-08-23 12:39:34,348 DEBUG TRAIN Batch 58/2500 loss 26.159885 loss_att 20.559772 loss_ctc 39.226810 loss_ctc_origin 34.446777 loss_ctc0 50.380222 lr 0.00109697 rank 0
2022-08-23 12:40:03,888 DEBUG TRAIN Batch 58/2600 loss 41.358986 loss_att 24.919914 loss_ctc 79.716827 loss_ctc_origin 45.286247 loss_ctc0 160.054840 lr 0.00109680 rank 0
2022-08-23 12:40:31,573 DEBUG TRAIN Batch 58/2700 loss 25.248783 loss_att 14.724352 loss_ctc 49.805786 loss_ctc_origin 42.315414 loss_ctc0 67.283318 lr 0.00109664 rank 0
2022-08-23 12:41:01,115 DEBUG TRAIN Batch 58/2800 loss 25.405590 loss_att 14.073774 loss_ctc 51.846489 loss_ctc_origin 40.571663 loss_ctc0 78.154411 lr 0.00109647 rank 0
2022-08-23 12:41:30,716 DEBUG TRAIN Batch 58/2900 loss 30.900337 loss_att 16.934032 loss_ctc 63.488377 loss_ctc_origin 47.866348 loss_ctc0 99.939774 lr 0.00109631 rank 0
2022-08-23 12:42:05,825 DEBUG TRAIN Batch 58/3000 loss 33.340210 loss_att 27.204357 loss_ctc 47.657204 loss_ctc_origin 39.943474 loss_ctc0 65.655907 lr 0.00109614 rank 0
2022-08-23 12:42:33,859 DEBUG TRAIN Batch 58/3100 loss 44.832962 loss_att 23.816944 loss_ctc 93.870346 loss_ctc_origin 47.243126 loss_ctc0 202.667206 lr 0.00109598 rank 0
2022-08-23 12:43:01,124 DEBUG TRAIN Batch 58/3200 loss 27.938946 loss_att 17.663055 loss_ctc 51.916019 loss_ctc_origin 43.285301 loss_ctc0 72.054359 lr 0.00109582 rank 0
2022-08-23 12:43:25,075 WARNING NaN or Inf found in input tensor.
2022-08-23 12:43:28,328 DEBUG TRAIN Batch 58/3300 loss 27.764935 loss_att 16.357159 loss_ctc 54.383072 loss_ctc_origin 40.898392 loss_ctc0 85.847328 lr 0.00109565 rank 0
2022-08-23 12:43:57,066 DEBUG TRAIN Batch 58/3400 loss 27.657249 loss_att 13.987149 loss_ctc 59.554146 loss_ctc_origin 45.718102 loss_ctc0 91.838257 lr 0.00109549 rank 0
2022-08-23 12:44:27,075 DEBUG TRAIN Batch 58/3500 loss 25.752550 loss_att 19.639288 loss_ctc 40.016827 loss_ctc_origin 34.410534 loss_ctc0 53.098179 lr 0.00109532 rank 0
2022-08-23 12:44:54,639 DEBUG TRAIN Batch 58/3600 loss 32.834213 loss_att 17.636896 loss_ctc 68.294624 loss_ctc_origin 37.332535 loss_ctc0 140.539490 lr 0.00109516 rank 0
2022-08-23 12:45:23,385 DEBUG TRAIN Batch 58/3700 loss 22.580063 loss_att 12.801552 loss_ctc 45.396591 loss_ctc_origin 35.599655 loss_ctc0 68.256104 lr 0.00109499 rank 0
2022-08-23 12:45:28,926 WARNING NaN or Inf found in input tensor.
2022-08-23 12:45:51,464 DEBUG TRAIN Batch 58/3800 loss 26.195923 loss_att 13.696898 loss_ctc 55.360313 loss_ctc_origin 43.245975 loss_ctc0 83.627098 lr 0.00109483 rank 0
2022-08-23 12:46:21,317 DEBUG TRAIN Batch 58/3900 loss 28.619442 loss_att 14.887721 loss_ctc 60.660126 loss_ctc_origin 44.639091 loss_ctc0 98.042542 lr 0.00109467 rank 0
2022-08-23 12:46:50,824 DEBUG TRAIN Batch 58/4000 loss 27.902733 loss_att 21.308704 loss_ctc 43.288795 loss_ctc_origin 36.950115 loss_ctc0 58.079048 lr 0.00109450 rank 0
2022-08-23 12:47:19,236 DEBUG TRAIN Batch 58/4100 loss 34.993690 loss_att 23.504370 loss_ctc 61.802105 loss_ctc_origin 44.800293 loss_ctc0 101.473000 lr 0.00109434 rank 0
2022-08-23 12:47:47,885 DEBUG TRAIN Batch 58/4200 loss 27.676804 loss_att 17.194283 loss_ctc 52.136017 loss_ctc_origin 42.911728 loss_ctc0 73.659363 lr 0.00109417 rank 0
2022-08-23 12:47:58,839 WARNING NaN or Inf found in input tensor.
2022-08-23 12:48:15,541 DEBUG TRAIN Batch 58/4300 loss 25.719267 loss_att 13.560865 loss_ctc 54.088867 loss_ctc_origin 41.687279 loss_ctc0 83.025909 lr 0.00109401 rank 0
2022-08-23 12:48:43,799 DEBUG TRAIN Batch 58/4400 loss 30.633011 loss_att 16.006550 loss_ctc 64.761421 loss_ctc_origin 50.692436 loss_ctc0 97.589050 lr 0.00109385 rank 0
2022-08-23 12:49:19,926 DEBUG TRAIN Batch 58/4500 loss 24.022110 loss_att 17.922531 loss_ctc 38.254459 loss_ctc_origin 34.422935 loss_ctc0 47.194679 lr 0.00109368 rank 0
2022-08-23 12:49:48,602 DEBUG TRAIN Batch 58/4600 loss 43.193756 loss_att 28.111996 loss_ctc 78.384521 loss_ctc_origin 49.988453 loss_ctc0 144.642029 lr 0.00109352 rank 0
2022-08-23 12:50:17,327 DEBUG TRAIN Batch 58/4700 loss 25.871746 loss_att 16.603352 loss_ctc 47.498001 loss_ctc_origin 38.261009 loss_ctc0 69.050980 lr 0.00109336 rank 0
2022-08-23 12:50:46,287 DEBUG TRAIN Batch 58/4800 loss 26.840298 loss_att 13.103146 loss_ctc 58.893646 loss_ctc_origin 45.381565 loss_ctc0 90.421829 lr 0.00109319 rank 0
2022-08-23 12:51:15,657 DEBUG TRAIN Batch 58/4900 loss 31.948801 loss_att 17.217159 loss_ctc 66.322632 loss_ctc_origin 52.323227 loss_ctc0 98.987915 lr 0.00109303 rank 0
2022-08-23 12:51:44,533 DEBUG TRAIN Batch 58/5000 loss 27.324362 loss_att 21.527699 loss_ctc 40.849911 loss_ctc_origin 39.283470 loss_ctc0 44.504944 lr 0.00109287 rank 0
2022-08-23 12:52:12,911 DEBUG TRAIN Batch 58/5100 loss 44.622822 loss_att 29.114571 loss_ctc 80.808739 loss_ctc_origin 50.054573 loss_ctc0 152.568451 lr 0.00109270 rank 0
2022-08-23 12:52:41,060 DEBUG TRAIN Batch 58/5200 loss 20.361826 loss_att 10.927990 loss_ctc 42.374107 loss_ctc_origin 31.152069 loss_ctc0 68.558861 lr 0.00109254 rank 0
2022-08-23 12:53:10,272 DEBUG TRAIN Batch 58/5300 loss 29.420135 loss_att 16.382858 loss_ctc 59.840446 loss_ctc_origin 48.781570 loss_ctc0 85.644485 lr 0.00109238 rank 0
2022-08-23 12:53:39,272 DEBUG TRAIN Batch 58/5400 loss 29.494244 loss_att 15.487483 loss_ctc 62.176682 loss_ctc_origin 44.764854 loss_ctc0 102.804276 lr 0.00109221 rank 0
2022-08-23 12:54:08,012 DEBUG TRAIN Batch 58/5500 loss 34.191280 loss_att 26.227448 loss_ctc 52.773552 loss_ctc_origin 40.419514 loss_ctc0 81.599640 lr 0.00109205 rank 0
2022-08-23 12:54:37,457 DEBUG TRAIN Batch 58/5600 loss 42.302113 loss_att 27.552551 loss_ctc 76.717758 loss_ctc_origin 49.569130 loss_ctc0 140.064545 lr 0.00109189 rank 0
2022-08-23 12:55:00,696 DEBUG CV Batch 58/0 loss 21.310284 loss_att 13.836457 loss_ctc 38.749207 loss_ctc_origin 21.798588 loss_ctc0 78.300644 history loss 20.056738 rank 0
2022-08-23 12:55:11,518 DEBUG CV Batch 58/100 loss 29.196598 loss_att 21.230862 loss_ctc 47.783314 loss_ctc_origin 30.207634 loss_ctc0 88.793228 history loss 32.472038 rank 0
2022-08-23 12:55:21,452 DEBUG CV Batch 58/200 loss 30.672817 loss_att 23.843678 loss_ctc 46.607475 loss_ctc_origin 37.433304 loss_ctc0 68.013878 history loss 34.520869 rank 0
2022-08-23 12:55:32,000 DEBUG CV Batch 58/300 loss 28.157717 loss_att 20.440207 loss_ctc 46.165237 loss_ctc_origin 31.351345 loss_ctc0 80.730972 history loss 33.571023 rank 0
2022-08-23 12:55:42,849 DEBUG CV Batch 58/400 loss 43.039062 loss_att 34.160267 loss_ctc 63.756252 loss_ctc_origin 47.340351 loss_ctc0 102.060020 history loss 31.685591 rank 0
2022-08-23 12:55:53,744 DEBUG CV Batch 58/500 loss 23.993076 loss_att 16.441154 loss_ctc 41.614227 loss_ctc_origin 27.320892 loss_ctc0 74.965340 history loss 31.187348 rank 0
2022-08-23 12:56:04,595 DEBUG CV Batch 58/600 loss 20.170971 loss_att 14.412069 loss_ctc 33.608406 loss_ctc_origin 23.774450 loss_ctc0 56.554298 history loss 31.022072 rank 0
2022-08-23 12:56:14,694 DEBUG CV Batch 58/700 loss 24.185184 loss_att 16.943073 loss_ctc 41.083443 loss_ctc_origin 29.279785 loss_ctc0 68.625305 history loss 30.619065 rank 0
2022-08-23 12:56:25,285 DEBUG CV Batch 58/800 loss 24.912157 loss_att 18.662914 loss_ctc 39.493721 loss_ctc_origin 23.984829 loss_ctc0 75.681137 history loss 30.529931 rank 0
2022-08-23 12:56:35,747 INFO Epoch 58 CV info cv_loss 30.529663846374117
2022-08-23 12:56:35,747 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/58.pt
2022-08-23 12:56:36,182 INFO Epoch 59 TRAIN info lr 0.0010917525022579797
2022-08-23 12:56:36,185 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 12:57:02,876 DEBUG TRAIN Batch 59/0 loss 25.240795 loss_att 19.548504 loss_ctc 38.522804 loss_ctc_origin 36.482841 loss_ctc0 43.282722 lr 0.00109175 rank 0
2022-08-23 12:57:31,720 DEBUG TRAIN Batch 59/100 loss 25.832752 loss_att 18.256668 loss_ctc 43.510277 loss_ctc_origin 35.549911 loss_ctc0 62.084465 lr 0.00109158 rank 0
2022-08-23 12:58:01,553 DEBUG TRAIN Batch 59/200 loss 22.799271 loss_att 14.619984 loss_ctc 41.884270 loss_ctc_origin 30.939398 loss_ctc0 67.422302 lr 0.00109142 rank 0
2022-08-23 12:58:30,332 DEBUG TRAIN Batch 59/300 loss 23.299377 loss_att 12.129962 loss_ctc 49.361343 loss_ctc_origin 37.407631 loss_ctc0 77.253342 lr 0.00109126 rank 0
2022-08-23 12:58:58,494 DEBUG TRAIN Batch 59/400 loss 30.636024 loss_att 15.783815 loss_ctc 65.291176 loss_ctc_origin 51.461411 loss_ctc0 97.560623 lr 0.00109110 rank 0
2022-08-23 12:59:27,533 DEBUG TRAIN Batch 59/500 loss 24.516300 loss_att 19.953255 loss_ctc 35.163403 loss_ctc_origin 31.109177 loss_ctc0 44.623260 lr 0.00109093 rank 0
2022-08-23 12:59:56,101 DEBUG TRAIN Batch 59/600 loss 35.809361 loss_att 20.129499 loss_ctc 72.395706 loss_ctc_origin 43.799572 loss_ctc0 139.120026 lr 0.00109077 rank 0
2022-08-23 13:00:24,166 DEBUG TRAIN Batch 59/700 loss 23.748335 loss_att 14.716660 loss_ctc 44.822243 loss_ctc_origin 34.776894 loss_ctc0 68.261398 lr 0.00109061 rank 0
2022-08-23 13:00:53,434 DEBUG TRAIN Batch 59/800 loss 25.739063 loss_att 13.077147 loss_ctc 55.283531 loss_ctc_origin 43.293419 loss_ctc0 83.260452 lr 0.00109045 rank 0
2022-08-23 13:01:22,281 DEBUG TRAIN Batch 59/900 loss 28.505524 loss_att 13.938218 loss_ctc 62.495899 loss_ctc_origin 47.082588 loss_ctc0 98.460297 lr 0.00109029 rank 0
2022-08-23 13:01:50,915 DEBUG TRAIN Batch 59/1000 loss 28.436409 loss_att 21.934498 loss_ctc 43.607536 loss_ctc_origin 34.766335 loss_ctc0 64.237015 lr 0.00109012 rank 0
2022-08-23 13:01:51,614 WARNING NaN or Inf found in input tensor.
2022-08-23 13:02:04,826 WARNING NaN or Inf found in input tensor.
2022-08-23 13:02:18,730 DEBUG TRAIN Batch 59/1100 loss 38.857445 loss_att 25.201092 loss_ctc 70.722260 loss_ctc_origin 47.882736 loss_ctc0 124.014481 lr 0.00108996 rank 0
2022-08-23 13:02:47,154 DEBUG TRAIN Batch 59/1200 loss 22.835640 loss_att 12.736935 loss_ctc 46.399284 loss_ctc_origin 35.560471 loss_ctc0 71.689857 lr 0.00108980 rank 0
2022-08-23 13:03:16,148 DEBUG TRAIN Batch 59/1300 loss 28.346615 loss_att 15.111900 loss_ctc 59.227615 loss_ctc_origin 47.135136 loss_ctc0 87.443390 lr 0.00108964 rank 0
2022-08-23 13:03:44,839 DEBUG TRAIN Batch 59/1400 loss 29.120815 loss_att 13.932352 loss_ctc 64.560555 loss_ctc_origin 47.730423 loss_ctc0 103.830856 lr 0.00108948 rank 0
2022-08-23 13:03:53,099 WARNING NaN or Inf found in input tensor.
2022-08-23 13:04:18,623 DEBUG TRAIN Batch 59/1500 loss 30.423283 loss_att 24.302132 loss_ctc 44.705967 loss_ctc_origin 44.301956 loss_ctc0 45.648659 lr 0.00108931 rank 0
2022-08-23 13:04:46,263 DEBUG TRAIN Batch 59/1600 loss 26.280964 loss_att 15.945213 loss_ctc 50.397713 loss_ctc_origin 32.552799 loss_ctc0 92.035835 lr 0.00108915 rank 0
2022-08-23 13:05:15,122 DEBUG TRAIN Batch 59/1700 loss 25.745243 loss_att 14.969232 loss_ctc 50.889267 loss_ctc_origin 40.741550 loss_ctc0 74.567276 lr 0.00108899 rank 0
2022-08-23 13:05:43,718 DEBUG TRAIN Batch 59/1800 loss 26.281200 loss_att 14.003879 loss_ctc 54.928280 loss_ctc_origin 42.699219 loss_ctc0 83.462753 lr 0.00108883 rank 0
2022-08-23 13:06:12,024 DEBUG TRAIN Batch 59/1900 loss 31.493118 loss_att 15.861859 loss_ctc 67.966049 loss_ctc_origin 52.596878 loss_ctc0 103.827438 lr 0.00108867 rank 0
2022-08-23 13:06:40,605 DEBUG TRAIN Batch 59/2000 loss 33.416145 loss_att 25.676281 loss_ctc 51.475834 loss_ctc_origin 40.272945 loss_ctc0 77.615906 lr 0.00108851 rank 0
2022-08-23 13:06:48,010 WARNING NaN or Inf found in input tensor.
2022-08-23 13:07:09,123 DEBUG TRAIN Batch 59/2100 loss 37.674026 loss_att 25.025263 loss_ctc 67.187805 loss_ctc_origin 45.402870 loss_ctc0 118.019333 lr 0.00108835 rank 0
2022-08-23 13:07:38,067 DEBUG TRAIN Batch 59/2200 loss 26.503841 loss_att 16.808411 loss_ctc 49.126514 loss_ctc_origin 39.773937 loss_ctc0 70.949196 lr 0.00108819 rank 0
2022-08-23 13:07:56,573 WARNING NaN or Inf found in input tensor.
2022-08-23 13:08:07,588 DEBUG TRAIN Batch 59/2300 loss 24.566713 loss_att 12.579006 loss_ctc 52.538029 loss_ctc_origin 40.207626 loss_ctc0 81.308968 lr 0.00108802 rank 0
2022-08-23 13:08:36,610 DEBUG TRAIN Batch 59/2400 loss 30.136488 loss_att 16.160213 loss_ctc 62.747791 loss_ctc_origin 48.838257 loss_ctc0 95.203369 lr 0.00108786 rank 0
2022-08-23 13:08:39,477 WARNING NaN or Inf found in input tensor.
2022-08-23 13:09:05,738 DEBUG TRAIN Batch 59/2500 loss 31.288170 loss_att 27.082653 loss_ctc 41.101044 loss_ctc_origin 40.033146 loss_ctc0 43.592800 lr 0.00108770 rank 0
2022-08-23 13:09:33,592 DEBUG TRAIN Batch 59/2600 loss 35.266853 loss_att 24.099457 loss_ctc 61.324104 loss_ctc_origin 41.799103 loss_ctc0 106.882431 lr 0.00108754 rank 0
2022-08-23 13:10:01,488 DEBUG TRAIN Batch 59/2700 loss 24.749714 loss_att 14.130970 loss_ctc 49.526783 loss_ctc_origin 40.169456 loss_ctc0 71.360542 lr 0.00108738 rank 0
2022-08-23 13:10:31,370 DEBUG TRAIN Batch 59/2800 loss 23.168739 loss_att 11.302738 loss_ctc 50.856075 loss_ctc_origin 38.080544 loss_ctc0 80.665649 lr 0.00108722 rank 0
2022-08-23 13:10:58,670 DEBUG TRAIN Batch 59/2900 loss 30.659443 loss_att 15.193653 loss_ctc 66.746284 loss_ctc_origin 50.795532 loss_ctc0 103.964706 lr 0.00108706 rank 0
2022-08-23 13:11:34,888 DEBUG TRAIN Batch 59/3000 loss 23.766479 loss_att 19.362930 loss_ctc 34.041428 loss_ctc_origin 29.246628 loss_ctc0 45.229286 lr 0.00108690 rank 0
2022-08-23 13:12:04,532 DEBUG TRAIN Batch 59/3100 loss 31.209076 loss_att 21.742083 loss_ctc 53.298729 loss_ctc_origin 44.353470 loss_ctc0 74.171005 lr 0.00108674 rank 0
2022-08-23 13:12:32,954 DEBUG TRAIN Batch 59/3200 loss 25.857430 loss_att 17.136393 loss_ctc 46.206512 loss_ctc_origin 36.494606 loss_ctc0 68.867615 lr 0.00108658 rank 0
2022-08-23 13:12:38,350 WARNING NaN or Inf found in input tensor.
2022-08-23 13:13:00,141 DEBUG TRAIN Batch 59/3300 loss 28.496931 loss_att 15.584499 loss_ctc 58.625938 loss_ctc_origin 47.710819 loss_ctc0 84.094543 lr 0.00108642 rank 0
2022-08-23 13:13:24,583 WARNING NaN or Inf found in input tensor.
2022-08-23 13:13:29,061 DEBUG TRAIN Batch 59/3400 loss 33.041870 loss_att 18.847361 loss_ctc 66.162384 loss_ctc_origin 51.685455 loss_ctc0 99.941879 lr 0.00108626 rank 0
2022-08-23 13:13:59,373 DEBUG TRAIN Batch 59/3500 loss 23.508972 loss_att 18.073839 loss_ctc 36.190948 loss_ctc_origin 28.174450 loss_ctc0 54.896114 lr 0.00108610 rank 0
2022-08-23 13:14:27,764 DEBUG TRAIN Batch 59/3600 loss 34.095654 loss_att 24.085224 loss_ctc 57.453316 loss_ctc_origin 45.506409 loss_ctc0 85.329430 lr 0.00108594 rank 0
2022-08-23 13:14:56,275 DEBUG TRAIN Batch 59/3700 loss 22.460865 loss_att 14.259237 loss_ctc 41.597992 loss_ctc_origin 31.328440 loss_ctc0 65.560272 lr 0.00108578 rank 0
2022-08-23 13:15:01,796 WARNING NaN or Inf found in input tensor.
2022-08-23 13:15:24,655 DEBUG TRAIN Batch 59/3800 loss 30.157967 loss_att 16.104942 loss_ctc 62.948349 loss_ctc_origin 51.984089 loss_ctc0 88.531609 lr 0.00108562 rank 0
2022-08-23 13:15:54,273 DEBUG TRAIN Batch 59/3900 loss 30.513365 loss_att 16.698380 loss_ctc 62.748329 loss_ctc_origin 45.270958 loss_ctc0 103.528854 lr 0.00108546 rank 0
2022-08-23 13:16:23,074 DEBUG TRAIN Batch 59/4000 loss 31.579023 loss_att 24.950981 loss_ctc 47.044453 loss_ctc_origin 46.396446 loss_ctc0 48.556465 lr 0.00108530 rank 0
2022-08-23 13:16:52,204 DEBUG TRAIN Batch 59/4100 loss 34.655361 loss_att 24.143110 loss_ctc 59.183945 loss_ctc_origin 45.699196 loss_ctc0 90.648361 lr 0.00108514 rank 0
2022-08-23 13:17:21,098 DEBUG TRAIN Batch 59/4200 loss 27.317223 loss_att 17.456652 loss_ctc 50.325218 loss_ctc_origin 40.846809 loss_ctc0 72.441513 lr 0.00108498 rank 0
2022-08-23 13:17:50,191 DEBUG TRAIN Batch 59/4300 loss 25.375908 loss_att 13.058964 loss_ctc 54.115440 loss_ctc_origin 40.265816 loss_ctc0 86.431229 lr 0.00108482 rank 0
2022-08-23 13:18:17,541 DEBUG TRAIN Batch 59/4400 loss 29.787407 loss_att 14.621464 loss_ctc 65.174606 loss_ctc_origin 48.566803 loss_ctc0 103.926132 lr 0.00108466 rank 0
2022-08-23 13:18:54,193 DEBUG TRAIN Batch 59/4500 loss 30.995453 loss_att 23.689503 loss_ctc 48.042667 loss_ctc_origin 41.247711 loss_ctc0 63.897564 lr 0.00108450 rank 0
2022-08-23 13:19:02,007 WARNING NaN or Inf found in input tensor.
2022-08-23 13:19:23,461 DEBUG TRAIN Batch 59/4600 loss 34.448505 loss_att 23.768921 loss_ctc 59.367531 loss_ctc_origin 47.914673 loss_ctc0 86.090851 lr 0.00108434 rank 0
2022-08-23 13:19:52,116 DEBUG TRAIN Batch 59/4700 loss 28.181717 loss_att 18.234146 loss_ctc 51.392715 loss_ctc_origin 42.822369 loss_ctc0 71.390190 lr 0.00108418 rank 0
2022-08-23 13:20:04,808 WARNING NaN or Inf found in input tensor.
2022-08-23 13:20:20,014 DEBUG TRAIN Batch 59/4800 loss 24.009579 loss_att 11.711594 loss_ctc 52.704872 loss_ctc_origin 39.544834 loss_ctc0 83.411621 lr 0.00108402 rank 0
2022-08-23 13:20:49,010 DEBUG TRAIN Batch 59/4900 loss 29.862282 loss_att 15.301392 loss_ctc 63.837692 loss_ctc_origin 47.077187 loss_ctc0 102.945541 lr 0.00108386 rank 0
2022-08-23 13:21:18,618 DEBUG TRAIN Batch 59/5000 loss 29.214891 loss_att 22.927608 loss_ctc 43.885216 loss_ctc_origin 38.353191 loss_ctc0 56.793282 lr 0.00108370 rank 0
2022-08-23 13:21:46,399 DEBUG TRAIN Batch 59/5100 loss 30.248604 loss_att 21.098673 loss_ctc 51.598438 loss_ctc_origin 45.796394 loss_ctc0 65.136536 lr 0.00108354 rank 0
2022-08-23 13:22:14,255 DEBUG TRAIN Batch 59/5200 loss 26.576670 loss_att 15.067267 loss_ctc 53.431938 loss_ctc_origin 45.592136 loss_ctc0 71.724815 lr 0.00108338 rank 0
2022-08-23 13:22:41,984 DEBUG TRAIN Batch 59/5300 loss 29.070267 loss_att 16.581915 loss_ctc 58.209755 loss_ctc_origin 46.009308 loss_ctc0 86.677460 lr 0.00108323 rank 0
2022-08-23 13:23:10,148 DEBUG TRAIN Batch 59/5400 loss 34.719940 loss_att 20.017979 loss_ctc 69.024521 loss_ctc_origin 56.676132 loss_ctc0 97.837418 lr 0.00108307 rank 0
2022-08-23 13:23:37,509 DEBUG TRAIN Batch 59/5500 loss 34.993027 loss_att 27.512695 loss_ctc 52.447132 loss_ctc_origin 44.315033 loss_ctc0 71.422028 lr 0.00108291 rank 0
2022-08-23 13:24:06,009 DEBUG TRAIN Batch 59/5600 loss 38.707649 loss_att 22.098431 loss_ctc 77.462494 loss_ctc_origin 50.751778 loss_ctc0 139.787491 lr 0.00108275 rank 0
2022-08-23 13:24:29,719 DEBUG CV Batch 59/0 loss 24.993975 loss_att 14.488059 loss_ctc 49.507774 loss_ctc_origin 23.461481 loss_ctc0 110.282455 history loss 23.523741 rank 0
2022-08-23 13:24:40,407 DEBUG CV Batch 59/100 loss 29.233643 loss_att 19.494610 loss_ctc 51.958046 loss_ctc_origin 30.180393 loss_ctc0 102.772560 history loss 32.918072 rank 0
2022-08-23 13:24:50,584 DEBUG CV Batch 59/200 loss 29.252178 loss_att 20.932751 loss_ctc 48.664177 loss_ctc_origin 34.237625 loss_ctc0 82.326134 history loss 34.572679 rank 0
2022-08-23 13:25:00,947 DEBUG CV Batch 59/300 loss 26.980259 loss_att 19.385405 loss_ctc 44.701584 loss_ctc_origin 30.263695 loss_ctc0 78.389999 history loss 33.715008 rank 0
2022-08-23 13:25:11,930 DEBUG CV Batch 59/400 loss 41.364067 loss_att 32.427685 loss_ctc 62.215633 loss_ctc_origin 45.399178 loss_ctc0 101.454025 history loss 31.877816 rank 0
2022-08-23 13:25:23,056 DEBUG CV Batch 59/500 loss 27.473667 loss_att 16.492702 loss_ctc 53.095913 loss_ctc_origin 27.751591 loss_ctc0 112.232666 history loss 31.444461 rank 0
2022-08-23 13:25:33,637 DEBUG CV Batch 59/600 loss 23.608429 loss_att 15.407991 loss_ctc 42.742779 loss_ctc_origin 26.054531 loss_ctc0 81.682022 history loss 31.233908 rank 0
2022-08-23 13:25:44,142 DEBUG CV Batch 59/700 loss 21.479088 loss_att 14.736025 loss_ctc 37.212906 loss_ctc_origin 24.147966 loss_ctc0 67.697762 history loss 30.863488 rank 0
2022-08-23 13:25:54,452 DEBUG CV Batch 59/800 loss 24.725681 loss_att 18.339069 loss_ctc 39.627781 loss_ctc_origin 24.852293 loss_ctc0 74.103920 history loss 30.761575 rank 0
2022-08-23 13:26:04,850 INFO Epoch 59 CV info cv_loss 30.727491290252956
2022-08-23 13:26:04,850 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/59.pt
2022-08-23 13:26:05,324 INFO Epoch 60 TRAIN info lr 0.0010826163374360515
2022-08-23 13:26:05,327 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 13:26:32,516 DEBUG TRAIN Batch 60/0 loss 27.421600 loss_att 19.947531 loss_ctc 44.861092 loss_ctc_origin 34.646572 loss_ctc0 68.694962 lr 0.00108261 rank 0
2022-08-23 13:27:00,965 DEBUG TRAIN Batch 60/100 loss 35.873966 loss_att 22.463825 loss_ctc 67.164291 loss_ctc_origin 45.459209 loss_ctc0 117.809479 lr 0.00108245 rank 0
2022-08-23 13:27:07,392 WARNING NaN or Inf found in input tensor.
2022-08-23 13:27:28,813 DEBUG TRAIN Batch 60/200 loss 24.567879 loss_att 15.529990 loss_ctc 45.656281 loss_ctc_origin 36.867805 loss_ctc0 66.162720 lr 0.00108229 rank 0
2022-08-23 13:27:57,148 DEBUG TRAIN Batch 60/300 loss 24.018013 loss_att 12.007942 loss_ctc 52.041508 loss_ctc_origin 37.458549 loss_ctc0 86.068413 lr 0.00108213 rank 0
2022-08-23 13:28:25,565 DEBUG TRAIN Batch 60/400 loss 28.367138 loss_att 14.851595 loss_ctc 59.903404 loss_ctc_origin 42.765621 loss_ctc0 99.891556 lr 0.00108198 rank 0
2022-08-23 13:28:54,757 DEBUG TRAIN Batch 60/500 loss 28.618837 loss_att 21.713400 loss_ctc 44.731522 loss_ctc_origin 39.918404 loss_ctc0 55.962132 lr 0.00108182 rank 0
2022-08-23 13:29:23,060 DEBUG TRAIN Batch 60/600 loss 34.467590 loss_att 23.244106 loss_ctc 60.655716 loss_ctc_origin 43.753735 loss_ctc0 100.093666 lr 0.00108166 rank 0
2022-08-23 13:29:51,756 DEBUG TRAIN Batch 60/700 loss 29.042168 loss_att 18.353317 loss_ctc 53.982819 loss_ctc_origin 46.236073 loss_ctc0 72.058563 lr 0.00108150 rank 0
2022-08-23 13:30:20,646 DEBUG TRAIN Batch 60/800 loss 30.065155 loss_att 16.477179 loss_ctc 61.770432 loss_ctc_origin 49.735310 loss_ctc0 89.852386 lr 0.00108134 rank 0
2022-08-23 13:30:49,135 DEBUG TRAIN Batch 60/900 loss 25.754799 loss_att 12.440639 loss_ctc 56.821167 loss_ctc_origin 41.293678 loss_ctc0 93.051971 lr 0.00108119 rank 0
2022-08-23 13:31:18,556 DEBUG TRAIN Batch 60/1000 loss 32.419289 loss_att 24.210262 loss_ctc 51.573681 loss_ctc_origin 48.413162 loss_ctc0 58.948219 lr 0.00108103 rank 0
2022-08-23 13:31:46,403 DEBUG TRAIN Batch 60/1100 loss 34.735123 loss_att 20.991627 loss_ctc 66.803284 loss_ctc_origin 44.820011 loss_ctc0 118.097588 lr 0.00108087 rank 0
2022-08-23 13:32:14,863 DEBUG TRAIN Batch 60/1200 loss 26.134537 loss_att 15.504139 loss_ctc 50.938797 loss_ctc_origin 41.042953 loss_ctc0 74.029099 lr 0.00108071 rank 0
2022-08-23 13:32:43,540 DEBUG TRAIN Batch 60/1300 loss 26.253464 loss_att 13.877649 loss_ctc 55.130360 loss_ctc_origin 44.402164 loss_ctc0 80.162811 lr 0.00108055 rank 0
2022-08-23 13:33:11,634 DEBUG TRAIN Batch 60/1400 loss 28.926159 loss_att 14.464661 loss_ctc 62.669655 loss_ctc_origin 44.420250 loss_ctc0 105.251595 lr 0.00108040 rank 0
2022-08-23 13:33:46,625 DEBUG TRAIN Batch 60/1500 loss 35.508522 loss_att 27.575016 loss_ctc 54.020042 loss_ctc_origin 40.523701 loss_ctc0 85.511505 lr 0.00108024 rank 0
2022-08-23 13:34:15,819 DEBUG TRAIN Batch 60/1600 loss 34.670429 loss_att 20.506367 loss_ctc 67.719910 loss_ctc_origin 46.473713 loss_ctc0 117.294357 lr 0.00108008 rank 0
2022-08-23 13:34:41,590 WARNING NaN or Inf found in input tensor.
2022-08-23 13:34:43,152 DEBUG TRAIN Batch 60/1700 loss 25.750681 loss_att 15.433195 loss_ctc 49.824814 loss_ctc_origin 40.007984 loss_ctc0 72.730743 lr 0.00107992 rank 0
2022-08-23 13:35:11,336 DEBUG TRAIN Batch 60/1800 loss 25.201271 loss_att 13.103533 loss_ctc 53.429321 loss_ctc_origin 42.147781 loss_ctc0 79.752922 lr 0.00107977 rank 0
2022-08-23 13:35:22,318 WARNING NaN or Inf found in input tensor.
2022-08-23 13:35:40,089 DEBUG TRAIN Batch 60/1900 loss 32.339943 loss_att 17.155825 loss_ctc 67.769554 loss_ctc_origin 53.196484 loss_ctc0 101.773384 lr 0.00107961 rank 0
2022-08-23 13:36:09,052 DEBUG TRAIN Batch 60/2000 loss 25.627279 loss_att 20.366776 loss_ctc 37.901787 loss_ctc_origin 30.431858 loss_ctc0 55.331615 lr 0.00107945 rank 0
2022-08-23 13:36:37,671 DEBUG TRAIN Batch 60/2100 loss 37.721199 loss_att 24.686344 loss_ctc 68.135849 loss_ctc_origin 45.058632 loss_ctc0 121.982697 lr 0.00107929 rank 0
2022-08-23 13:37:06,129 DEBUG TRAIN Batch 60/2200 loss 29.185478 loss_att 19.856411 loss_ctc 50.953300 loss_ctc_origin 41.585213 loss_ctc0 72.812164 lr 0.00107914 rank 0
2022-08-23 13:37:24,912 WARNING NaN or Inf found in input tensor.
2022-08-23 13:37:35,736 DEBUG TRAIN Batch 60/2300 loss 22.875385 loss_att 12.283065 loss_ctc 47.590797 loss_ctc_origin 36.986439 loss_ctc0 72.334297 lr 0.00107898 rank 0
2022-08-23 13:38:00,191 WARNING NaN or Inf found in input tensor.
2022-08-23 13:38:04,813 DEBUG TRAIN Batch 60/2400 loss 33.874332 loss_att 17.433647 loss_ctc 72.235924 loss_ctc_origin 56.647484 loss_ctc0 108.608948 lr 0.00107882 rank 0
2022-08-23 13:38:33,417 DEBUG TRAIN Batch 60/2500 loss 36.187771 loss_att 26.989504 loss_ctc 57.650394 loss_ctc_origin 43.145546 loss_ctc0 91.495041 lr 0.00107867 rank 0
2022-08-23 13:39:02,094 DEBUG TRAIN Batch 60/2600 loss 31.916458 loss_att 20.797354 loss_ctc 57.861031 loss_ctc_origin 39.239616 loss_ctc0 101.310989 lr 0.00107851 rank 0
2022-08-23 13:39:30,107 DEBUG TRAIN Batch 60/2700 loss 26.307930 loss_att 16.510998 loss_ctc 49.167435 loss_ctc_origin 40.510590 loss_ctc0 69.366745 lr 0.00107835 rank 0
2022-08-23 13:39:59,255 DEBUG TRAIN Batch 60/2800 loss 23.590328 loss_att 11.722469 loss_ctc 51.281994 loss_ctc_origin 38.497234 loss_ctc0 81.113098 lr 0.00107820 rank 0
2022-08-23 13:40:27,737 DEBUG TRAIN Batch 60/2900 loss 29.054642 loss_att 15.101555 loss_ctc 61.611847 loss_ctc_origin 43.488167 loss_ctc0 103.900421 lr 0.00107804 rank 0
2022-08-23 13:41:03,427 DEBUG TRAIN Batch 60/3000 loss 27.508694 loss_att 20.381237 loss_ctc 44.139423 loss_ctc_origin 34.150589 loss_ctc0 67.446701 lr 0.00107788 rank 0
2022-08-23 13:41:18,540 WARNING NaN or Inf found in input tensor.
2022-08-23 13:41:32,803 DEBUG TRAIN Batch 60/3100 loss 34.198341 loss_att 21.736710 loss_ctc 63.275490 loss_ctc_origin 42.401451 loss_ctc0 111.981583 lr 0.00107773 rank 0
2022-08-23 13:42:02,118 DEBUG TRAIN Batch 60/3200 loss 27.078472 loss_att 16.550678 loss_ctc 51.643326 loss_ctc_origin 43.494293 loss_ctc0 70.657730 lr 0.00107757 rank 0
2022-08-23 13:42:31,236 DEBUG TRAIN Batch 60/3300 loss 28.890303 loss_att 17.091446 loss_ctc 56.420963 loss_ctc_origin 43.857868 loss_ctc0 85.734848 lr 0.00107741 rank 0
2022-08-23 13:42:58,730 DEBUG TRAIN Batch 60/3400 loss 31.264677 loss_att 15.519461 loss_ctc 68.003510 loss_ctc_origin 52.175652 loss_ctc0 104.935181 lr 0.00107726 rank 0
2022-08-23 13:43:28,394 DEBUG TRAIN Batch 60/3500 loss 31.228725 loss_att 25.328489 loss_ctc 44.995941 loss_ctc_origin 37.418999 loss_ctc0 62.675468 lr 0.00107710 rank 0
2022-08-23 13:43:55,848 DEBUG TRAIN Batch 60/3600 loss 36.365700 loss_att 23.148914 loss_ctc 67.204865 loss_ctc_origin 43.130531 loss_ctc0 123.378311 lr 0.00107694 rank 0
2022-08-23 13:44:23,818 DEBUG TRAIN Batch 60/3700 loss 26.779434 loss_att 16.659149 loss_ctc 50.393433 loss_ctc_origin 40.990669 loss_ctc0 72.333221 lr 0.00107679 rank 0
2022-08-23 13:44:29,383 WARNING NaN or Inf found in input tensor.
2022-08-23 13:44:52,663 DEBUG TRAIN Batch 60/3800 loss 31.139042 loss_att 16.658257 loss_ctc 64.927544 loss_ctc_origin 54.904579 loss_ctc0 88.314468 lr 0.00107663 rank 0
2022-08-23 13:45:21,070 DEBUG TRAIN Batch 60/3900 loss 29.294159 loss_att 14.913367 loss_ctc 62.849342 loss_ctc_origin 47.283569 loss_ctc0 99.169464 lr 0.00107648 rank 0
2022-08-23 13:45:49,914 DEBUG TRAIN Batch 60/4000 loss 36.117874 loss_att 28.186058 loss_ctc 54.625443 loss_ctc_origin 48.941711 loss_ctc0 67.887489 lr 0.00107632 rank 0
2022-08-23 13:46:03,983 WARNING NaN or Inf found in input tensor.
2022-08-23 13:46:18,637 DEBUG TRAIN Batch 60/4100 loss 42.467323 loss_att 29.584999 loss_ctc 72.526070 loss_ctc_origin 48.562279 loss_ctc0 128.441574 lr 0.00107617 rank 0
2022-08-23 13:46:47,401 DEBUG TRAIN Batch 60/4200 loss 23.243961 loss_att 15.108923 loss_ctc 42.225719 loss_ctc_origin 33.270065 loss_ctc0 63.122246 lr 0.00107601 rank 0
2022-08-23 13:47:16,463 DEBUG TRAIN Batch 60/4300 loss 29.013821 loss_att 15.636700 loss_ctc 60.227097 loss_ctc_origin 48.462231 loss_ctc0 87.678452 lr 0.00107585 rank 0
2022-08-23 13:47:45,487 DEBUG TRAIN Batch 60/4400 loss 29.653765 loss_att 15.601570 loss_ctc 62.442215 loss_ctc_origin 46.878262 loss_ctc0 98.758102 lr 0.00107570 rank 0
2022-08-23 13:48:20,459 DEBUG TRAIN Batch 60/4500 loss 28.459686 loss_att 19.752705 loss_ctc 48.775978 loss_ctc_origin 37.652283 loss_ctc0 74.731270 lr 0.00107554 rank 0
2022-08-23 13:48:48,811 DEBUG TRAIN Batch 60/4600 loss 38.134945 loss_att 22.123495 loss_ctc 75.494995 loss_ctc_origin 43.114574 loss_ctc0 151.049316 lr 0.00107539 rank 0
2022-08-23 13:49:17,954 DEBUG TRAIN Batch 60/4700 loss 24.241001 loss_att 11.888099 loss_ctc 53.064438 loss_ctc_origin 42.971107 loss_ctc0 76.615547 lr 0.00107523 rank 0
2022-08-23 13:49:46,247 DEBUG TRAIN Batch 60/4800 loss 27.100346 loss_att 13.886936 loss_ctc 57.931633 loss_ctc_origin 44.402710 loss_ctc0 89.499123 lr 0.00107508 rank 0
2022-08-23 13:50:15,898 DEBUG TRAIN Batch 60/4900 loss 28.648739 loss_att 16.464495 loss_ctc 57.078636 loss_ctc_origin 41.622208 loss_ctc0 93.143639 lr 0.00107492 rank 0
2022-08-23 13:50:44,768 DEBUG TRAIN Batch 60/5000 loss 25.689060 loss_att 18.674707 loss_ctc 42.055878 loss_ctc_origin 37.462845 loss_ctc0 52.772957 lr 0.00107477 rank 0
2022-08-23 13:50:52,539 WARNING NaN or Inf found in input tensor.
2022-08-23 13:51:12,325 DEBUG TRAIN Batch 60/5100 loss 39.552273 loss_att 25.860842 loss_ctc 71.498947 loss_ctc_origin 47.516197 loss_ctc0 127.458694 lr 0.00107461 rank 0
2022-08-23 13:51:41,181 DEBUG TRAIN Batch 60/5200 loss 24.131477 loss_att 13.594794 loss_ctc 48.717068 loss_ctc_origin 39.448090 loss_ctc0 70.344681 lr 0.00107446 rank 0
2022-08-23 13:52:10,840 DEBUG TRAIN Batch 60/5300 loss 22.334623 loss_att 11.379580 loss_ctc 47.896385 loss_ctc_origin 35.494026 loss_ctc0 76.835228 lr 0.00107430 rank 0
2022-08-23 13:52:39,659 DEBUG TRAIN Batch 60/5400 loss 29.419909 loss_att 15.850658 loss_ctc 61.081490 loss_ctc_origin 45.613262 loss_ctc0 97.174026 lr 0.00107415 rank 0
2022-08-23 13:53:08,593 DEBUG TRAIN Batch 60/5500 loss 28.242779 loss_att 21.439835 loss_ctc 44.116314 loss_ctc_origin 43.400517 loss_ctc0 45.786510 lr 0.00107399 rank 0
2022-08-23 13:53:38,204 DEBUG TRAIN Batch 60/5600 loss 36.010109 loss_att 21.353556 loss_ctc 70.208725 loss_ctc_origin 43.273071 loss_ctc0 133.058563 lr 0.00107384 rank 0
2022-08-23 13:54:02,008 DEBUG CV Batch 60/0 loss 19.133039 loss_att 12.932197 loss_ctc 33.601669 loss_ctc_origin 18.841391 loss_ctc0 68.042313 history loss 18.007567 rank 0
2022-08-23 13:54:12,590 DEBUG CV Batch 60/100 loss 32.575066 loss_att 22.349974 loss_ctc 56.433609 loss_ctc_origin 31.428806 loss_ctc0 114.778145 history loss 32.446536 rank 0
2022-08-23 13:54:22,439 DEBUG CV Batch 60/200 loss 27.124435 loss_att 20.579365 loss_ctc 42.396271 loss_ctc_origin 32.364265 loss_ctc0 65.804291 history loss 34.078969 rank 0
2022-08-23 13:54:32,981 DEBUG CV Batch 60/300 loss 27.246178 loss_att 20.307480 loss_ctc 43.436470 loss_ctc_origin 28.779667 loss_ctc0 77.635666 history loss 33.191184 rank 0
2022-08-23 13:54:43,799 DEBUG CV Batch 60/400 loss 41.262436 loss_att 32.802422 loss_ctc 61.002472 loss_ctc_origin 43.790340 loss_ctc0 101.164108 history loss 31.455453 rank 0
2022-08-23 13:54:55,045 DEBUG CV Batch 60/500 loss 26.303427 loss_att 16.751846 loss_ctc 48.590446 loss_ctc_origin 29.095882 loss_ctc0 94.077759 history loss 31.056478 rank 0
2022-08-23 13:55:05,897 DEBUG CV Batch 60/600 loss 23.030777 loss_att 14.685827 loss_ctc 42.502327 loss_ctc_origin 25.011532 loss_ctc0 83.314171 history loss 30.926488 rank 0
2022-08-23 13:55:16,342 DEBUG CV Batch 60/700 loss 22.296459 loss_att 15.639986 loss_ctc 37.828232 loss_ctc_origin 25.000051 loss_ctc0 67.760651 history loss 30.570768 rank 0
2022-08-23 13:55:26,956 DEBUG CV Batch 60/800 loss 24.491165 loss_att 18.445309 loss_ctc 38.598160 loss_ctc_origin 23.675880 loss_ctc0 73.416809 history loss 30.471705 rank 0
2022-08-23 13:55:37,429 INFO Epoch 60 CV info cv_loss 30.469402471656718
2022-08-23 13:55:37,430 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/60.pt
2022-08-23 13:55:37,886 INFO Epoch 61 TRAIN info lr 0.0010737057633782127
2022-08-23 13:55:37,890 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 13:56:05,124 DEBUG TRAIN Batch 61/0 loss 26.151789 loss_att 20.990969 loss_ctc 38.193703 loss_ctc_origin 33.977177 loss_ctc0 48.032257 lr 0.00107370 rank 0
2022-08-23 13:56:33,709 DEBUG TRAIN Batch 61/100 loss 37.857021 loss_att 25.233427 loss_ctc 67.312073 loss_ctc_origin 42.919579 loss_ctc0 124.227890 lr 0.00107354 rank 0
2022-08-23 13:57:02,914 DEBUG TRAIN Batch 61/200 loss 24.539673 loss_att 14.175836 loss_ctc 48.721954 loss_ctc_origin 37.948479 loss_ctc0 73.860069 lr 0.00107339 rank 0
2022-08-23 13:57:32,253 DEBUG TRAIN Batch 61/300 loss 26.430958 loss_att 14.111221 loss_ctc 55.177010 loss_ctc_origin 42.503525 loss_ctc0 84.748474 lr 0.00107324 rank 0
2022-08-23 13:57:55,946 WARNING NaN or Inf found in input tensor.
2022-08-23 13:58:00,535 DEBUG TRAIN Batch 61/400 loss 30.289543 loss_att 14.991152 loss_ctc 65.985794 loss_ctc_origin 50.229374 loss_ctc0 102.750763 lr 0.00107308 rank 0
2022-08-23 13:58:03,244 WARNING NaN or Inf found in input tensor.
2022-08-23 13:58:30,008 DEBUG TRAIN Batch 61/500 loss 29.629021 loss_att 22.909733 loss_ctc 45.307365 loss_ctc_origin 38.293434 loss_ctc0 61.673199 lr 0.00107293 rank 0
2022-08-23 13:58:58,698 DEBUG TRAIN Batch 61/600 loss 32.459431 loss_att 20.362514 loss_ctc 60.685570 loss_ctc_origin 42.974510 loss_ctc0 102.011368 lr 0.00107277 rank 0
2022-08-23 13:59:27,693 DEBUG TRAIN Batch 61/700 loss 19.187109 loss_att 10.749287 loss_ctc 38.875359 loss_ctc_origin 27.545591 loss_ctc0 65.311478 lr 0.00107262 rank 0
2022-08-23 13:59:55,748 DEBUG TRAIN Batch 61/800 loss 24.205395 loss_att 13.244967 loss_ctc 49.779724 loss_ctc_origin 37.845985 loss_ctc0 77.625107 lr 0.00107246 rank 0
2022-08-23 14:00:25,797 DEBUG TRAIN Batch 61/900 loss 31.439535 loss_att 16.366131 loss_ctc 66.610809 loss_ctc_origin 50.877502 loss_ctc0 103.321861 lr 0.00107231 rank 0
2022-08-23 14:00:54,247 DEBUG TRAIN Batch 61/1000 loss 36.766594 loss_att 28.144175 loss_ctc 56.885574 loss_ctc_origin 47.921268 loss_ctc0 77.802284 lr 0.00107216 rank 0
2022-08-23 14:01:22,312 WARNING NaN or Inf found in input tensor.
2022-08-23 14:01:22,353 DEBUG TRAIN Batch 61/1100 loss nan loss_att 31.679884 loss_ctc nan loss_ctc_origin 58.400894 loss_ctc0 nan lr 0.00107200 rank 0
2022-08-23 14:01:51,389 DEBUG TRAIN Batch 61/1200 loss 27.129314 loss_att 16.151855 loss_ctc 52.743385 loss_ctc_origin 43.281418 loss_ctc0 74.821320 lr 0.00107185 rank 0
2022-08-23 14:02:19,711 DEBUG TRAIN Batch 61/1300 loss 23.889877 loss_att 11.714997 loss_ctc 52.297928 loss_ctc_origin 39.951973 loss_ctc0 81.105148 lr 0.00107169 rank 0
2022-08-23 14:02:44,296 WARNING NaN or Inf found in input tensor.
2022-08-23 14:02:49,055 DEBUG TRAIN Batch 61/1400 loss 30.890282 loss_att 16.045647 loss_ctc 65.527763 loss_ctc_origin 51.694263 loss_ctc0 97.805923 lr 0.00107154 rank 0
2022-08-23 14:03:24,163 DEBUG TRAIN Batch 61/1500 loss 28.026508 loss_att 23.019997 loss_ctc 39.708370 loss_ctc_origin 37.109856 loss_ctc0 45.771576 lr 0.00107139 rank 0
2022-08-23 14:03:53,970 DEBUG TRAIN Batch 61/1600 loss 37.737495 loss_att 22.653326 loss_ctc 72.933884 loss_ctc_origin 46.709854 loss_ctc0 134.123291 lr 0.00107123 rank 0
2022-08-23 14:04:22,390 DEBUG TRAIN Batch 61/1700 loss 23.171362 loss_att 13.026578 loss_ctc 46.842522 loss_ctc_origin 36.931435 loss_ctc0 69.968399 lr 0.00107108 rank 0
2022-08-23 14:04:50,665 DEBUG TRAIN Batch 61/1800 loss 23.162483 loss_att 11.535807 loss_ctc 50.291397 loss_ctc_origin 37.873360 loss_ctc0 79.266823 lr 0.00107093 rank 0
2022-08-23 14:05:14,643 WARNING NaN or Inf found in input tensor.
2022-08-23 14:05:18,944 DEBUG TRAIN Batch 61/1900 loss 27.522942 loss_att 13.690901 loss_ctc 59.797699 loss_ctc_origin 43.021801 loss_ctc0 98.941452 lr 0.00107077 rank 0
2022-08-23 14:05:48,843 DEBUG TRAIN Batch 61/2000 loss 36.789467 loss_att 30.157593 loss_ctc 52.263832 loss_ctc_origin 43.693573 loss_ctc0 72.261093 lr 0.00107062 rank 0
2022-08-23 14:06:17,187 DEBUG TRAIN Batch 61/2100 loss 44.930420 loss_att 28.923018 loss_ctc 82.281029 loss_ctc_origin 58.952980 loss_ctc0 136.713135 lr 0.00107047 rank 0
2022-08-23 14:06:46,922 DEBUG TRAIN Batch 61/2200 loss 22.708611 loss_att 14.112801 loss_ctc 42.765495 loss_ctc_origin 32.867222 loss_ctc0 65.861473 lr 0.00107031 rank 0
2022-08-23 14:07:15,560 DEBUG TRAIN Batch 61/2300 loss 20.236847 loss_att 10.082434 loss_ctc 43.930473 loss_ctc_origin 31.244370 loss_ctc0 73.531380 lr 0.00107016 rank 0
2022-08-23 14:07:40,258 WARNING NaN or Inf found in input tensor.
2022-08-23 14:07:44,804 DEBUG TRAIN Batch 61/2400 loss 32.843300 loss_att 17.877106 loss_ctc 67.764420 loss_ctc_origin 52.367073 loss_ctc0 103.691544 lr 0.00107001 rank 0
2022-08-23 14:08:13,119 DEBUG TRAIN Batch 61/2500 loss 30.226971 loss_att 22.822624 loss_ctc 47.503777 loss_ctc_origin 44.951881 loss_ctc0 53.458191 lr 0.00106985 rank 0
2022-08-23 14:08:27,600 WARNING NaN or Inf found in input tensor.
2022-08-23 14:08:41,690 DEBUG TRAIN Batch 61/2600 loss 34.550583 loss_att 24.708960 loss_ctc 57.514366 loss_ctc_origin 43.653019 loss_ctc0 89.857513 lr 0.00106970 rank 0
2022-08-23 14:09:10,435 DEBUG TRAIN Batch 61/2700 loss 25.450975 loss_att 16.007080 loss_ctc 47.486729 loss_ctc_origin 36.972397 loss_ctc0 72.020164 lr 0.00106955 rank 0
2022-08-23 14:09:39,683 DEBUG TRAIN Batch 61/2800 loss 26.899128 loss_att 14.045526 loss_ctc 56.890862 loss_ctc_origin 45.311798 loss_ctc0 83.908676 lr 0.00106939 rank 0
2022-08-23 14:10:06,917 DEBUG TRAIN Batch 61/2900 loss 27.793339 loss_att 14.932745 loss_ctc 57.801392 loss_ctc_origin 42.549500 loss_ctc0 93.389137 lr 0.00106924 rank 0
2022-08-23 14:10:42,801 DEBUG TRAIN Batch 61/3000 loss 29.025154 loss_att 25.029736 loss_ctc 38.347797 loss_ctc_origin 36.786961 loss_ctc0 41.989746 lr 0.00106909 rank 0
2022-08-23 14:11:11,583 DEBUG TRAIN Batch 61/3100 loss 37.957134 loss_att 26.300896 loss_ctc 65.155022 loss_ctc_origin 54.357605 loss_ctc0 90.348991 lr 0.00106894 rank 0
2022-08-23 14:11:40,046 DEBUG TRAIN Batch 61/3200 loss 22.624168 loss_att 14.068157 loss_ctc 42.588196 loss_ctc_origin 32.039165 loss_ctc0 67.202606 lr 0.00106878 rank 0
2022-08-23 14:12:07,820 DEBUG TRAIN Batch 61/3300 loss 29.980499 loss_att 16.470322 loss_ctc 61.504242 loss_ctc_origin 49.304619 loss_ctc0 89.970032 lr 0.00106863 rank 0
2022-08-23 14:12:18,227 WARNING NaN or Inf found in input tensor.
2022-08-23 14:12:36,830 DEBUG TRAIN Batch 61/3400 loss 28.935432 loss_att 14.447571 loss_ctc 62.740440 loss_ctc_origin 47.969284 loss_ctc0 97.206467 lr 0.00106848 rank 0
2022-08-23 14:13:05,576 DEBUG TRAIN Batch 61/3500 loss 32.797600 loss_att 23.361193 loss_ctc 54.815887 loss_ctc_origin 47.439674 loss_ctc0 72.027054 lr 0.00106832 rank 0
2022-08-23 14:13:34,160 DEBUG TRAIN Batch 61/3600 loss 42.371304 loss_att 28.191261 loss_ctc 75.458069 loss_ctc_origin 50.687801 loss_ctc0 133.255371 lr 0.00106817 rank 0
2022-08-23 14:14:02,417 DEBUG TRAIN Batch 61/3700 loss 22.587051 loss_att 13.615310 loss_ctc 43.521111 loss_ctc_origin 33.694763 loss_ctc0 66.449249 lr 0.00106802 rank 0
2022-08-23 14:14:31,715 DEBUG TRAIN Batch 61/3800 loss 27.648491 loss_att 15.050705 loss_ctc 57.043320 loss_ctc_origin 45.838852 loss_ctc0 83.187073 lr 0.00106787 rank 0
2022-08-23 14:15:01,220 DEBUG TRAIN Batch 61/3900 loss 31.772953 loss_att 16.500019 loss_ctc 67.409790 loss_ctc_origin 52.540543 loss_ctc0 102.104713 lr 0.00106772 rank 0
2022-08-23 14:15:29,774 DEBUG TRAIN Batch 61/4000 loss 52.408726 loss_att 35.396183 loss_ctc 92.104652 loss_ctc_origin 61.739792 loss_ctc0 162.955994 lr 0.00106756 rank 0
2022-08-23 14:15:59,496 DEBUG TRAIN Batch 61/4100 loss 46.146866 loss_att 28.529966 loss_ctc 87.252960 loss_ctc_origin 56.662163 loss_ctc0 158.631485 lr 0.00106741 rank 0
2022-08-23 14:16:27,759 DEBUG TRAIN Batch 61/4200 loss 23.713833 loss_att 15.543665 loss_ctc 42.777557 loss_ctc_origin 32.581703 loss_ctc0 66.567886 lr 0.00106726 rank 0
2022-08-23 14:16:57,132 DEBUG TRAIN Batch 61/4300 loss 27.423428 loss_att 15.484234 loss_ctc 55.281548 loss_ctc_origin 45.645462 loss_ctc0 77.765747 lr 0.00106711 rank 0
2022-08-23 14:17:25,130 DEBUG TRAIN Batch 61/4400 loss 26.543594 loss_att 12.260000 loss_ctc 59.871975 loss_ctc_origin 41.188435 loss_ctc0 103.466904 lr 0.00106696 rank 0
2022-08-23 14:18:00,202 DEBUG TRAIN Batch 61/4500 loss 32.309967 loss_att 22.343517 loss_ctc 55.565018 loss_ctc_origin 38.997574 loss_ctc0 94.222382 lr 0.00106680 rank 0
2022-08-23 14:18:28,892 DEBUG TRAIN Batch 61/4600 loss 52.828701 loss_att 31.679169 loss_ctc 102.177612 loss_ctc_origin 61.197304 loss_ctc0 197.798340 lr 0.00106665 rank 0
2022-08-23 14:18:57,054 DEBUG TRAIN Batch 61/4700 loss 27.301317 loss_att 17.255207 loss_ctc 50.742241 loss_ctc_origin 42.321823 loss_ctc0 70.389877 lr 0.00106650 rank 0
2022-08-23 14:19:24,794 DEBUG TRAIN Batch 61/4800 loss 27.191885 loss_att 14.960390 loss_ctc 55.732040 loss_ctc_origin 42.166351 loss_ctc0 87.385307 lr 0.00106635 rank 0
2022-08-23 14:19:53,145 DEBUG TRAIN Batch 61/4900 loss 30.739946 loss_att 15.293610 loss_ctc 66.781395 loss_ctc_origin 49.147141 loss_ctc0 107.927994 lr 0.00106620 rank 0
2022-08-23 14:20:22,221 DEBUG TRAIN Batch 61/5000 loss 41.137543 loss_att 31.685131 loss_ctc 63.193161 loss_ctc_origin 47.304970 loss_ctc0 100.265594 lr 0.00106605 rank 0
2022-08-23 14:20:51,089 DEBUG TRAIN Batch 61/5100 loss 52.915092 loss_att 30.786255 loss_ctc 104.549042 loss_ctc_origin 61.238026 loss_ctc0 205.608063 lr 0.00106589 rank 0
2022-08-23 14:21:19,938 DEBUG TRAIN Batch 61/5200 loss 22.291523 loss_att 13.345774 loss_ctc 43.164940 loss_ctc_origin 32.787582 loss_ctc0 67.378769 lr 0.00106574 rank 0
2022-08-23 14:21:48,609 DEBUG TRAIN Batch 61/5300 loss 23.568853 loss_att 12.473738 loss_ctc 49.457455 loss_ctc_origin 36.164780 loss_ctc0 80.473694 lr 0.00106559 rank 0
2022-08-23 14:22:13,147 WARNING NaN or Inf found in input tensor.
2022-08-23 14:22:17,603 DEBUG TRAIN Batch 61/5400 loss 35.700005 loss_att 20.875923 loss_ctc 70.289520 loss_ctc_origin 56.478672 loss_ctc0 102.514824 lr 0.00106544 rank 0
2022-08-23 14:22:46,849 DEBUG TRAIN Batch 61/5500 loss 41.095295 loss_att 28.191206 loss_ctc 71.204834 loss_ctc_origin 50.054821 loss_ctc0 120.554848 lr 0.00106529 rank 0
2022-08-23 14:23:14,062 DEBUG TRAIN Batch 61/5600 loss 48.356232 loss_att 28.934814 loss_ctc 93.672867 loss_ctc_origin 57.649750 loss_ctc0 177.726791 lr 0.00106514 rank 0
2022-08-23 14:23:36,316 DEBUG CV Batch 61/0 loss 23.442036 loss_att 14.257104 loss_ctc 44.873543 loss_ctc_origin 22.124533 loss_ctc0 97.954567 history loss 22.063092 rank 0
2022-08-23 14:23:47,027 DEBUG CV Batch 61/100 loss 33.627373 loss_att 22.083872 loss_ctc 60.562202 loss_ctc_origin 32.498180 loss_ctc0 126.044922 history loss 33.113747 rank 0
2022-08-23 14:23:57,330 DEBUG CV Batch 61/200 loss 30.934618 loss_att 22.220602 loss_ctc 51.267319 loss_ctc_origin 36.317627 loss_ctc0 86.149933 history loss 35.371912 rank 0
2022-08-23 14:24:07,856 DEBUG CV Batch 61/300 loss 26.707798 loss_att 19.681904 loss_ctc 43.101547 loss_ctc_origin 28.474754 loss_ctc0 77.230728 history loss 34.398601 rank 0
2022-08-23 14:24:18,848 DEBUG CV Batch 61/400 loss 40.208668 loss_att 31.810532 loss_ctc 59.804314 loss_ctc_origin 42.835682 loss_ctc0 99.397789 history loss 32.434028 rank 0
2022-08-23 14:24:30,498 DEBUG CV Batch 61/500 loss 26.243107 loss_att 16.483768 loss_ctc 49.014893 loss_ctc_origin 26.916731 loss_ctc0 100.577263 history loss 31.908306 rank 0
2022-08-23 14:24:41,286 DEBUG CV Batch 61/600 loss 30.053432 loss_att 17.458019 loss_ctc 59.442726 loss_ctc_origin 29.985435 loss_ctc0 128.176407 history loss 31.792267 rank 0
2022-08-23 14:24:51,527 DEBUG CV Batch 61/700 loss 21.472843 loss_att 14.907789 loss_ctc 36.791306 loss_ctc_origin 23.905294 loss_ctc0 66.858658 history loss 31.376525 rank 0
2022-08-23 14:25:02,530 DEBUG CV Batch 61/800 loss 23.761656 loss_att 17.646132 loss_ctc 38.031212 loss_ctc_origin 23.020950 loss_ctc0 73.055161 history loss 31.223741 rank 0
2022-08-23 14:25:12,932 INFO Epoch 61 CV info cv_loss 31.14055593233261
2022-08-23 14:25:12,932 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/61.pt
2022-08-23 14:25:13,425 INFO Epoch 62 TRAIN info lr 0.0010650116464985407
2022-08-23 14:25:13,429 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 14:25:39,973 DEBUG TRAIN Batch 62/0 loss 27.015528 loss_att 19.132339 loss_ctc 45.409634 loss_ctc_origin 34.030853 loss_ctc0 71.960121 lr 0.00106501 rank 0
2022-08-23 14:26:08,390 DEBUG TRAIN Batch 62/100 loss 46.613075 loss_att 29.699184 loss_ctc 86.078827 loss_ctc_origin 50.785282 loss_ctc0 168.430420 lr 0.00106485 rank 0
2022-08-23 14:26:37,277 DEBUG TRAIN Batch 62/200 loss 28.481058 loss_att 17.456123 loss_ctc 54.205906 loss_ctc_origin 45.042732 loss_ctc0 75.586639 lr 0.00106470 rank 0
2022-08-23 14:27:05,516 DEBUG TRAIN Batch 62/300 loss 22.793812 loss_att 11.359186 loss_ctc 49.474602 loss_ctc_origin 36.924278 loss_ctc0 78.758698 lr 0.00106455 rank 0
2022-08-23 14:27:33,446 DEBUG TRAIN Batch 62/400 loss 26.904827 loss_att 13.318745 loss_ctc 58.605686 loss_ctc_origin 43.740990 loss_ctc0 93.289978 lr 0.00106440 rank 0
2022-08-23 14:28:03,244 DEBUG TRAIN Batch 62/500 loss 28.946606 loss_att 19.622383 loss_ctc 50.703125 loss_ctc_origin 34.366402 loss_ctc0 88.822151 lr 0.00106425 rank 0
2022-08-23 14:28:32,448 DEBUG TRAIN Batch 62/600 loss 38.235115 loss_att 25.104368 loss_ctc 68.873520 loss_ctc_origin 39.966736 loss_ctc0 136.322693 lr 0.00106410 rank 0
2022-08-23 14:29:00,739 DEBUG TRAIN Batch 62/700 loss 19.372349 loss_att 10.054003 loss_ctc 41.115150 loss_ctc_origin 28.298010 loss_ctc0 71.021805 lr 0.00106395 rank 0
2022-08-23 14:29:27,045 WARNING NaN or Inf found in input tensor.
2022-08-23 14:29:29,720 DEBUG TRAIN Batch 62/800 loss 25.687122 loss_att 12.134102 loss_ctc 57.310837 loss_ctc_origin 45.366550 loss_ctc0 85.180847 lr 0.00106380 rank 0
2022-08-23 14:29:58,849 DEBUG TRAIN Batch 62/900 loss 27.302517 loss_att 13.386238 loss_ctc 59.773838 loss_ctc_origin 44.476875 loss_ctc0 95.466751 lr 0.00106365 rank 0
2022-08-23 14:30:28,475 DEBUG TRAIN Batch 62/1000 loss 35.294571 loss_att 25.867741 loss_ctc 57.290512 loss_ctc_origin 40.202370 loss_ctc0 97.162842 lr 0.00106350 rank 0
2022-08-23 14:30:56,790 DEBUG TRAIN Batch 62/1100 loss 34.166573 loss_att 20.847233 loss_ctc 65.245026 loss_ctc_origin 40.072479 loss_ctc0 123.980972 lr 0.00106335 rank 0
2022-08-23 14:31:26,943 DEBUG TRAIN Batch 62/1200 loss 22.263477 loss_att 12.558567 loss_ctc 44.908268 loss_ctc_origin 34.618607 loss_ctc0 68.917473 lr 0.00106320 rank 0
2022-08-23 14:31:56,028 DEBUG TRAIN Batch 62/1300 loss 22.394318 loss_att 10.662316 loss_ctc 49.768990 loss_ctc_origin 37.192749 loss_ctc0 79.113548 lr 0.00106305 rank 0
2022-08-23 14:32:24,508 DEBUG TRAIN Batch 62/1400 loss 31.738293 loss_att 17.731258 loss_ctc 64.421371 loss_ctc_origin 48.409191 loss_ctc0 101.783119 lr 0.00106290 rank 0
2022-08-23 14:32:59,462 DEBUG TRAIN Batch 62/1500 loss 29.869368 loss_att 21.257318 loss_ctc 49.964146 loss_ctc_origin 38.773750 loss_ctc0 76.075066 lr 0.00106275 rank 0
2022-08-23 14:33:27,914 DEBUG TRAIN Batch 62/1600 loss 26.919407 loss_att 17.102402 loss_ctc 49.825748 loss_ctc_origin 30.637602 loss_ctc0 94.598083 lr 0.00106260 rank 0
2022-08-23 14:33:55,610 DEBUG TRAIN Batch 62/1700 loss 22.678301 loss_att 13.194030 loss_ctc 44.808266 loss_ctc_origin 36.120514 loss_ctc0 65.079689 lr 0.00106245 rank 0
2022-08-23 14:34:24,026 DEBUG TRAIN Batch 62/1800 loss 26.228905 loss_att 14.994123 loss_ctc 52.443398 loss_ctc_origin 40.539448 loss_ctc0 80.219276 lr 0.00106230 rank 0
2022-08-23 14:34:51,646 DEBUG TRAIN Batch 62/1900 loss 31.303291 loss_att 16.348923 loss_ctc 66.196823 loss_ctc_origin 50.717228 loss_ctc0 102.315887 lr 0.00106215 rank 0
2022-08-23 14:35:20,050 DEBUG TRAIN Batch 62/2000 loss 27.123987 loss_att 22.505571 loss_ctc 37.900291 loss_ctc_origin 33.667198 loss_ctc0 47.777504 lr 0.00106200 rank 0
2022-08-23 14:35:47,609 DEBUG TRAIN Batch 62/2100 loss 47.072342 loss_att 28.169022 loss_ctc 91.180092 loss_ctc_origin 53.100208 loss_ctc0 180.033142 lr 0.00106185 rank 0
2022-08-23 14:36:15,554 DEBUG TRAIN Batch 62/2200 loss 27.870422 loss_att 16.774639 loss_ctc 53.760578 loss_ctc_origin 45.412800 loss_ctc0 73.238724 lr 0.00106170 rank 0
2022-08-23 14:36:43,371 DEBUG TRAIN Batch 62/2300 loss 25.898518 loss_att 14.079544 loss_ctc 53.476120 loss_ctc_origin 41.800877 loss_ctc0 80.718346 lr 0.00106155 rank 0
2022-08-23 14:37:01,393 WARNING NaN or Inf found in input tensor.
2022-08-23 14:37:08,703 WARNING NaN or Inf found in input tensor.
2022-08-23 14:37:13,179 DEBUG TRAIN Batch 62/2400 loss 26.939148 loss_att 14.141376 loss_ctc 56.800613 loss_ctc_origin 41.616699 loss_ctc0 92.229744 lr 0.00106140 rank 0
2022-08-23 14:37:42,185 DEBUG TRAIN Batch 62/2500 loss 33.561237 loss_att 24.915752 loss_ctc 53.734032 loss_ctc_origin 38.976433 loss_ctc0 88.168427 lr 0.00106125 rank 0
2022-08-23 14:37:56,714 WARNING NaN or Inf found in input tensor.
2022-08-23 14:38:10,832 DEBUG TRAIN Batch 62/2600 loss 46.758972 loss_att 29.648968 loss_ctc 86.682312 loss_ctc_origin 45.788387 loss_ctc0 182.101471 lr 0.00106110 rank 0
2022-08-23 14:38:38,899 DEBUG TRAIN Batch 62/2700 loss 24.802933 loss_att 17.318094 loss_ctc 42.267559 loss_ctc_origin 33.890846 loss_ctc0 61.813221 lr 0.00106095 rank 0
2022-08-23 14:38:50,821 WARNING NaN or Inf found in input tensor.
2022-08-23 14:39:07,731 DEBUG TRAIN Batch 62/2800 loss 26.134724 loss_att 13.654463 loss_ctc 55.255333 loss_ctc_origin 43.800076 loss_ctc0 81.984268 lr 0.00106080 rank 0
2022-08-23 14:39:31,129 WARNING NaN or Inf found in input tensor.
2022-08-23 14:39:35,383 DEBUG TRAIN Batch 62/2900 loss 31.499969 loss_att 16.719210 loss_ctc 65.988411 loss_ctc_origin 49.144333 loss_ctc0 105.291267 lr 0.00106065 rank 0
2022-08-23 14:40:10,376 DEBUG TRAIN Batch 62/3000 loss 37.087967 loss_att 27.751944 loss_ctc 58.872009 loss_ctc_origin 49.851528 loss_ctc0 79.919792 lr 0.00106050 rank 0
2022-08-23 14:40:39,399 DEBUG TRAIN Batch 62/3100 loss 46.362583 loss_att 29.122894 loss_ctc 86.588516 loss_ctc_origin 54.267136 loss_ctc0 162.005051 lr 0.00106036 rank 0
2022-08-23 14:41:07,769 DEBUG TRAIN Batch 62/3200 loss 25.855261 loss_att 17.620762 loss_ctc 45.069092 loss_ctc_origin 35.941422 loss_ctc0 66.366989 lr 0.00106021 rank 0
2022-08-23 14:41:35,569 DEBUG TRAIN Batch 62/3300 loss 25.470642 loss_att 13.107489 loss_ctc 54.317997 loss_ctc_origin 42.186195 loss_ctc0 82.625534 lr 0.00106006 rank 0
2022-08-23 14:42:03,017 DEBUG TRAIN Batch 62/3400 loss 26.945175 loss_att 13.481866 loss_ctc 58.359558 loss_ctc_origin 43.627060 loss_ctc0 92.735382 lr 0.00105991 rank 0
2022-08-23 14:42:30,838 DEBUG TRAIN Batch 62/3500 loss 24.161337 loss_att 18.989080 loss_ctc 36.229935 loss_ctc_origin 32.084183 loss_ctc0 45.903351 lr 0.00105976 rank 0
2022-08-23 14:43:00,044 DEBUG TRAIN Batch 62/3600 loss 34.959465 loss_att 19.644424 loss_ctc 70.694550 loss_ctc_origin 42.409916 loss_ctc0 136.692017 lr 0.00105961 rank 0
2022-08-23 14:43:28,079 DEBUG TRAIN Batch 62/3700 loss 19.617722 loss_att 11.230602 loss_ctc 39.187668 loss_ctc_origin 28.206005 loss_ctc0 64.811554 lr 0.00105946 rank 0
2022-08-23 14:43:56,801 DEBUG TRAIN Batch 62/3800 loss 24.775429 loss_att 12.822352 loss_ctc 52.665939 loss_ctc_origin 40.267681 loss_ctc0 81.595207 lr 0.00105931 rank 0
2022-08-23 14:44:25,270 DEBUG TRAIN Batch 62/3900 loss 25.555706 loss_att 12.483404 loss_ctc 56.057743 loss_ctc_origin 38.282616 loss_ctc0 97.533035 lr 0.00105917 rank 0
2022-08-23 14:44:54,255 DEBUG TRAIN Batch 62/4000 loss 31.808483 loss_att 23.909527 loss_ctc 50.239380 loss_ctc_origin 40.125511 loss_ctc0 73.838409 lr 0.00105902 rank 0
2022-08-23 14:45:14,578 WARNING NaN or Inf found in input tensor.
2022-08-23 14:45:21,609 DEBUG TRAIN Batch 62/4100 loss 42.464355 loss_att 27.139084 loss_ctc 78.223320 loss_ctc_origin 51.002113 loss_ctc0 141.739471 lr 0.00105887 rank 0
2022-08-23 14:45:49,481 DEBUG TRAIN Batch 62/4200 loss 22.918457 loss_att 15.146838 loss_ctc 41.052235 loss_ctc_origin 31.502224 loss_ctc0 63.335594 lr 0.00105872 rank 0
2022-08-23 14:46:18,690 DEBUG TRAIN Batch 62/4300 loss 22.280054 loss_att 11.426426 loss_ctc 47.605186 loss_ctc_origin 34.631340 loss_ctc0 77.877487 lr 0.00105857 rank 0
2022-08-23 14:46:46,687 DEBUG TRAIN Batch 62/4400 loss 34.686256 loss_att 19.468746 loss_ctc 70.193787 loss_ctc_origin 54.433685 loss_ctc0 106.967361 lr 0.00105842 rank 0
2022-08-23 14:47:21,999 DEBUG TRAIN Batch 62/4500 loss 26.511011 loss_att 18.799147 loss_ctc 44.505360 loss_ctc_origin 31.828842 loss_ctc0 74.083900 lr 0.00105828 rank 0
2022-08-23 14:47:50,412 DEBUG TRAIN Batch 62/4600 loss 42.694847 loss_att 26.147633 loss_ctc 81.305008 loss_ctc_origin 54.154797 loss_ctc0 144.655487 lr 0.00105813 rank 0
2022-08-23 14:48:18,493 DEBUG TRAIN Batch 62/4700 loss 23.783604 loss_att 15.024757 loss_ctc 44.220913 loss_ctc_origin 34.369484 loss_ctc0 67.207581 lr 0.00105798 rank 0
2022-08-23 14:48:47,481 DEBUG TRAIN Batch 62/4800 loss 24.314426 loss_att 12.246576 loss_ctc 52.472740 loss_ctc_origin 39.340996 loss_ctc0 83.113480 lr 0.00105783 rank 0
2022-08-23 14:49:15,715 DEBUG TRAIN Batch 62/4900 loss 31.651020 loss_att 16.902639 loss_ctc 66.063904 loss_ctc_origin 49.831779 loss_ctc0 103.938858 lr 0.00105768 rank 0
2022-08-23 14:49:44,965 DEBUG TRAIN Batch 62/5000 loss 29.061752 loss_att 21.956018 loss_ctc 45.641792 loss_ctc_origin 41.187592 loss_ctc0 56.034920 lr 0.00105754 rank 0
2022-08-23 14:50:12,950 DEBUG TRAIN Batch 62/5100 loss 41.922287 loss_att 25.771442 loss_ctc 79.607597 loss_ctc_origin 50.427696 loss_ctc0 147.694031 lr 0.00105739 rank 0
2022-08-23 14:50:40,219 WARNING NaN or Inf found in input tensor.
2022-08-23 14:50:41,846 DEBUG TRAIN Batch 62/5200 loss 25.076481 loss_att 14.733189 loss_ctc 49.210831 loss_ctc_origin 39.737579 loss_ctc0 71.315079 lr 0.00105724 rank 0
2022-08-23 14:51:09,152 DEBUG TRAIN Batch 62/5300 loss 25.310349 loss_att 13.918352 loss_ctc 51.891670 loss_ctc_origin 40.454330 loss_ctc0 78.578796 lr 0.00105709 rank 0
2022-08-23 14:51:38,720 DEBUG TRAIN Batch 62/5400 loss 29.670612 loss_att 15.603250 loss_ctc 62.494461 loss_ctc_origin 46.356602 loss_ctc0 100.149475 lr 0.00105694 rank 0
2022-08-23 14:52:07,338 DEBUG TRAIN Batch 62/5500 loss 29.073305 loss_att 20.924374 loss_ctc 48.087479 loss_ctc_origin 39.827579 loss_ctc0 67.360580 lr 0.00105680 rank 0
2022-08-23 14:52:36,279 DEBUG TRAIN Batch 62/5600 loss 39.970104 loss_att 25.748634 loss_ctc 73.153534 loss_ctc_origin 46.127728 loss_ctc0 136.213745 lr 0.00105665 rank 0
2022-08-23 14:52:59,849 DEBUG CV Batch 62/0 loss 18.558342 loss_att 13.258272 loss_ctc 30.925167 loss_ctc_origin 19.630892 loss_ctc0 57.278473 history loss 17.466675 rank 0
2022-08-23 14:53:10,530 DEBUG CV Batch 62/100 loss 25.066490 loss_att 18.014841 loss_ctc 41.520340 loss_ctc_origin 25.281441 loss_ctc0 79.411095 history loss 30.521334 rank 0
2022-08-23 14:53:20,463 DEBUG CV Batch 62/200 loss 27.459360 loss_att 21.161697 loss_ctc 42.153908 loss_ctc_origin 30.875580 loss_ctc0 68.470001 history loss 32.002351 rank 0
2022-08-23 14:53:31,033 DEBUG CV Batch 62/300 loss 25.367910 loss_att 18.650482 loss_ctc 41.041908 loss_ctc_origin 25.987288 loss_ctc0 76.169357 history loss 31.066864 rank 0
2022-08-23 14:53:41,725 DEBUG CV Batch 62/400 loss 40.767910 loss_att 32.414551 loss_ctc 60.259079 loss_ctc_origin 43.661461 loss_ctc0 98.986855 history loss 29.324754 rank 0
2022-08-23 14:53:52,579 DEBUG CV Batch 62/500 loss 19.472034 loss_att 13.805539 loss_ctc 32.693851 loss_ctc_origin 23.030003 loss_ctc0 55.242828 history loss 28.901833 rank 0
2022-08-23 14:54:03,201 DEBUG CV Batch 62/600 loss 22.431557 loss_att 13.977642 loss_ctc 42.157356 loss_ctc_origin 25.513840 loss_ctc0 80.992233 history loss 28.759556 rank 0
2022-08-23 14:54:13,343 DEBUG CV Batch 62/700 loss 21.730322 loss_att 14.617435 loss_ctc 38.327057 loss_ctc_origin 25.684845 loss_ctc0 67.825554 history loss 28.379335 rank 0
2022-08-23 14:54:23,908 DEBUG CV Batch 62/800 loss 23.747082 loss_att 17.957329 loss_ctc 37.256508 loss_ctc_origin 22.343838 loss_ctc0 72.052742 history loss 28.303768 rank 0
2022-08-23 14:54:34,197 INFO Epoch 62 CV info cv_loss 28.349959441037424
2022-08-23 14:54:34,198 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/62.pt
2022-08-23 14:54:34,626 INFO Epoch 63 TRAIN info lr 0.0010565253626791166
2022-08-23 14:54:34,629 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 14:55:01,355 DEBUG TRAIN Batch 63/0 loss 31.398136 loss_att 23.682045 loss_ctc 49.402351 loss_ctc_origin 40.783916 loss_ctc0 69.512039 lr 0.00105652 rank 0
2022-08-23 14:55:29,968 DEBUG TRAIN Batch 63/100 loss 35.688999 loss_att 21.422913 loss_ctc 68.976532 loss_ctc_origin 40.671318 loss_ctc0 135.022034 lr 0.00105637 rank 0
2022-08-23 14:55:56,645 WARNING NaN or Inf found in input tensor.
2022-08-23 14:55:58,355 DEBUG TRAIN Batch 63/200 loss 24.655579 loss_att 14.812981 loss_ctc 47.621639 loss_ctc_origin 37.789650 loss_ctc0 70.562943 lr 0.00105622 rank 0
2022-08-23 14:56:27,726 DEBUG TRAIN Batch 63/300 loss 29.662590 loss_att 15.591764 loss_ctc 62.494514 loss_ctc_origin 51.374092 loss_ctc0 88.442169 lr 0.00105608 rank 0
2022-08-23 14:56:30,713 WARNING NaN or Inf found in input tensor.
2022-08-23 14:56:56,701 DEBUG TRAIN Batch 63/400 loss 29.373520 loss_att 15.062546 loss_ctc 62.765785 loss_ctc_origin 46.182087 loss_ctc0 101.461075 lr 0.00105593 rank 0
2022-08-23 14:57:25,660 DEBUG TRAIN Batch 63/500 loss 31.712292 loss_att 26.052614 loss_ctc 44.918205 loss_ctc_origin 41.391651 loss_ctc0 53.146824 lr 0.00105578 rank 0
2022-08-23 14:57:33,737 WARNING NaN or Inf found in input tensor.
2022-08-23 14:57:54,157 DEBUG TRAIN Batch 63/600 loss 34.142609 loss_att 21.598759 loss_ctc 63.411591 loss_ctc_origin 43.356571 loss_ctc0 110.206619 lr 0.00105564 rank 0
2022-08-23 14:58:22,976 DEBUG TRAIN Batch 63/700 loss 25.703888 loss_att 15.036627 loss_ctc 50.594162 loss_ctc_origin 40.809753 loss_ctc0 73.424454 lr 0.00105549 rank 0
2022-08-23 14:58:51,183 DEBUG TRAIN Batch 63/800 loss 24.848480 loss_att 12.071594 loss_ctc 54.661209 loss_ctc_origin 41.455227 loss_ctc0 85.475166 lr 0.00105534 rank 0
2022-08-23 14:59:20,545 DEBUG TRAIN Batch 63/900 loss 27.974983 loss_att 13.403038 loss_ctc 61.976189 loss_ctc_origin 46.550766 loss_ctc0 97.968826 lr 0.00105520 rank 0
2022-08-23 14:59:49,910 DEBUG TRAIN Batch 63/1000 loss 33.507504 loss_att 26.933235 loss_ctc 48.847466 loss_ctc_origin 44.002083 loss_ctc0 60.153351 lr 0.00105505 rank 0
2022-08-23 15:00:18,024 DEBUG TRAIN Batch 63/1100 loss 24.010784 loss_att 16.962925 loss_ctc 40.455788 loss_ctc_origin 32.527008 loss_ctc0 58.956272 lr 0.00105490 rank 0
2022-08-23 15:00:45,785 DEBUG TRAIN Batch 63/1200 loss 23.383457 loss_att 13.387796 loss_ctc 46.706669 loss_ctc_origin 36.266247 loss_ctc0 71.067657 lr 0.00105475 rank 0
2022-08-23 15:01:05,361 WARNING NaN or Inf found in input tensor.
2022-08-23 15:01:14,981 DEBUG TRAIN Batch 63/1300 loss 25.469223 loss_att 12.643764 loss_ctc 55.395294 loss_ctc_origin 42.295765 loss_ctc0 85.960861 lr 0.00105461 rank 0
2022-08-23 15:01:32,051 WARNING NaN or Inf found in input tensor.
2022-08-23 15:01:43,789 DEBUG TRAIN Batch 63/1400 loss 29.443268 loss_att 14.712469 loss_ctc 63.815132 loss_ctc_origin 46.469933 loss_ctc0 104.287254 lr 0.00105446 rank 0
2022-08-23 15:02:18,448 DEBUG TRAIN Batch 63/1500 loss 28.740944 loss_att 22.881638 loss_ctc 42.412663 loss_ctc_origin 41.845528 loss_ctc0 43.735977 lr 0.00105432 rank 0
2022-08-23 15:02:47,034 DEBUG TRAIN Batch 63/1600 loss 38.729450 loss_att 27.305107 loss_ctc 65.386246 loss_ctc_origin 37.398487 loss_ctc0 130.691010 lr 0.00105417 rank 0
2022-08-23 15:03:14,965 DEBUG TRAIN Batch 63/1700 loss 19.796953 loss_att 10.964100 loss_ctc 40.406944 loss_ctc_origin 28.835659 loss_ctc0 67.406601 lr 0.00105402 rank 0
2022-08-23 15:03:43,525 DEBUG TRAIN Batch 63/1800 loss 23.098452 loss_att 12.766410 loss_ctc 47.206547 loss_ctc_origin 35.608864 loss_ctc0 74.267807 lr 0.00105388 rank 0
2022-08-23 15:04:07,155 WARNING NaN or Inf found in input tensor.
2022-08-23 15:04:11,472 DEBUG TRAIN Batch 63/1900 loss 29.965546 loss_att 14.991307 loss_ctc 64.905434 loss_ctc_origin 48.024479 loss_ctc0 104.294319 lr 0.00105373 rank 0
2022-08-23 15:04:39,819 DEBUG TRAIN Batch 63/2000 loss 25.307665 loss_att 20.478863 loss_ctc 36.574867 loss_ctc_origin 32.561432 loss_ctc0 45.939545 lr 0.00105358 rank 0
2022-08-23 15:05:07,531 DEBUG TRAIN Batch 63/2100 loss 35.256523 loss_att 24.381630 loss_ctc 60.631271 loss_ctc_origin 42.540451 loss_ctc0 102.843185 lr 0.00105344 rank 0
2022-08-23 15:05:36,587 DEBUG TRAIN Batch 63/2200 loss 24.318951 loss_att 13.587135 loss_ctc 49.359848 loss_ctc_origin 38.083790 loss_ctc0 75.670654 lr 0.00105329 rank 0
2022-08-23 15:06:04,615 DEBUG TRAIN Batch 63/2300 loss 26.833138 loss_att 12.998787 loss_ctc 59.113281 loss_ctc_origin 46.343475 loss_ctc0 88.909485 lr 0.00105315 rank 0
2022-08-23 15:06:32,784 DEBUG TRAIN Batch 63/2400 loss 30.530186 loss_att 16.060143 loss_ctc 64.293617 loss_ctc_origin 48.919987 loss_ctc0 100.165421 lr 0.00105300 rank 0
2022-08-23 15:07:03,078 DEBUG TRAIN Batch 63/2500 loss 23.767746 loss_att 16.588890 loss_ctc 40.518410 loss_ctc_origin 29.045418 loss_ctc0 67.288712 lr 0.00105285 rank 0
2022-08-23 15:07:23,725 WARNING NaN or Inf found in input tensor.
2022-08-23 15:07:30,951 DEBUG TRAIN Batch 63/2600 loss 33.505959 loss_att 21.119724 loss_ctc 62.407166 loss_ctc_origin 37.817154 loss_ctc0 119.783859 lr 0.00105271 rank 0
2022-08-23 15:07:59,938 DEBUG TRAIN Batch 63/2700 loss 23.460878 loss_att 13.700583 loss_ctc 46.234901 loss_ctc_origin 35.853432 loss_ctc0 70.458328 lr 0.00105256 rank 0
2022-08-23 15:08:19,325 WARNING NaN or Inf found in input tensor.
2022-08-23 15:08:29,739 DEBUG TRAIN Batch 63/2800 loss 28.152966 loss_att 15.193389 loss_ctc 58.391975 loss_ctc_origin 46.422398 loss_ctc0 86.320992 lr 0.00105242 rank 0
2022-08-23 15:08:58,093 DEBUG TRAIN Batch 63/2900 loss 29.393126 loss_att 15.875596 loss_ctc 60.934029 loss_ctc_origin 43.883286 loss_ctc0 100.719086 lr 0.00105227 rank 0
2022-08-23 15:09:34,341 DEBUG TRAIN Batch 63/3000 loss 22.995173 loss_att 19.482449 loss_ctc 31.191530 loss_ctc_origin 26.877996 loss_ctc0 41.256439 lr 0.00105212 rank 0
2022-08-23 15:10:04,026 DEBUG TRAIN Batch 63/3100 loss 48.001995 loss_att 30.387466 loss_ctc 89.102554 loss_ctc_origin 56.432076 loss_ctc0 165.333664 lr 0.00105198 rank 0
2022-08-23 15:10:32,676 DEBUG TRAIN Batch 63/3200 loss 26.302448 loss_att 15.865189 loss_ctc 50.656055 loss_ctc_origin 41.101929 loss_ctc0 72.949020 lr 0.00105183 rank 0
2022-08-23 15:11:01,287 DEBUG TRAIN Batch 63/3300 loss 22.290617 loss_att 10.631474 loss_ctc 49.495285 loss_ctc_origin 35.020401 loss_ctc0 83.270020 lr 0.00105169 rank 0
2022-08-23 15:11:30,262 DEBUG TRAIN Batch 63/3400 loss 27.368435 loss_att 13.803159 loss_ctc 59.020748 loss_ctc_origin 42.425873 loss_ctc0 97.742119 lr 0.00105154 rank 0
2022-08-23 15:12:00,540 DEBUG TRAIN Batch 63/3500 loss 31.056786 loss_att 23.901983 loss_ctc 47.751320 loss_ctc_origin 39.425476 loss_ctc0 67.178291 lr 0.00105140 rank 0
2022-08-23 15:12:28,975 DEBUG TRAIN Batch 63/3600 loss 40.484261 loss_att 27.189682 loss_ctc 71.504936 loss_ctc_origin 48.122612 loss_ctc0 126.063683 lr 0.00105125 rank 0
2022-08-23 15:12:58,737 DEBUG TRAIN Batch 63/3700 loss 23.203659 loss_att 13.822446 loss_ctc 45.093155 loss_ctc_origin 35.896870 loss_ctc0 66.551147 lr 0.00105111 rank 0
2022-08-23 15:13:27,055 DEBUG TRAIN Batch 63/3800 loss 22.774622 loss_att 11.515366 loss_ctc 49.046219 loss_ctc_origin 36.760002 loss_ctc0 77.714050 lr 0.00105096 rank 0
2022-08-23 15:13:55,909 DEBUG TRAIN Batch 63/3900 loss 28.249741 loss_att 15.365952 loss_ctc 58.311920 loss_ctc_origin 43.873131 loss_ctc0 92.002434 lr 0.00105082 rank 0
2022-08-23 15:14:24,024 DEBUG TRAIN Batch 63/4000 loss 32.581154 loss_att 23.849220 loss_ctc 52.955666 loss_ctc_origin 39.843582 loss_ctc0 83.550522 lr 0.00105067 rank 0
2022-08-23 15:14:52,337 DEBUG TRAIN Batch 63/4100 loss 29.457256 loss_att 20.516474 loss_ctc 50.319084 loss_ctc_origin 35.048721 loss_ctc0 85.949928 lr 0.00105053 rank 0
2022-08-23 15:15:20,704 DEBUG TRAIN Batch 63/4200 loss 29.561731 loss_att 17.270792 loss_ctc 58.240589 loss_ctc_origin 49.500481 loss_ctc0 78.634171 lr 0.00105038 rank 0
2022-08-23 15:15:50,340 DEBUG TRAIN Batch 63/4300 loss 25.057709 loss_att 12.806389 loss_ctc 53.644119 loss_ctc_origin 41.725868 loss_ctc0 81.453369 lr 0.00105024 rank 0
2022-08-23 15:16:18,028 DEBUG TRAIN Batch 63/4400 loss 28.005659 loss_att 13.809395 loss_ctc 61.130276 loss_ctc_origin 44.975288 loss_ctc0 98.825241 lr 0.00105009 rank 0
2022-08-23 15:16:54,665 DEBUG TRAIN Batch 63/4500 loss 32.390640 loss_att 26.801752 loss_ctc 45.431381 loss_ctc_origin 38.727325 loss_ctc0 61.074181 lr 0.00104995 rank 0
2022-08-23 15:17:02,639 WARNING NaN or Inf found in input tensor.
2022-08-23 15:17:23,335 DEBUG TRAIN Batch 63/4600 loss 36.735252 loss_att 24.237499 loss_ctc 65.896667 loss_ctc_origin 46.227524 loss_ctc0 111.791328 lr 0.00104980 rank 0
2022-08-23 15:17:52,591 DEBUG TRAIN Batch 63/4700 loss 26.601925 loss_att 15.541820 loss_ctc 52.408840 loss_ctc_origin 43.718304 loss_ctc0 72.686760 lr 0.00104966 rank 0
2022-08-23 15:18:21,136 DEBUG TRAIN Batch 63/4800 loss 25.798849 loss_att 13.670120 loss_ctc 54.099213 loss_ctc_origin 41.755150 loss_ctc0 82.902023 lr 0.00104951 rank 0
2022-08-23 15:18:50,143 DEBUG TRAIN Batch 63/4900 loss 26.351345 loss_att 13.317953 loss_ctc 56.762589 loss_ctc_origin 40.311974 loss_ctc0 95.147354 lr 0.00104937 rank 0
2022-08-23 15:19:18,735 DEBUG TRAIN Batch 63/5000 loss 31.067802 loss_att 24.921139 loss_ctc 45.410019 loss_ctc_origin 39.769855 loss_ctc0 58.570404 lr 0.00104922 rank 0
2022-08-23 15:19:46,156 DEBUG TRAIN Batch 63/5100 loss 35.015778 loss_att 23.933277 loss_ctc 60.874947 loss_ctc_origin 41.220200 loss_ctc0 106.736031 lr 0.00104908 rank 0
2022-08-23 15:20:13,793 DEBUG TRAIN Batch 63/5200 loss 21.106689 loss_att 13.254021 loss_ctc 39.429588 loss_ctc_origin 29.777697 loss_ctc0 61.950661 lr 0.00104894 rank 0
2022-08-23 15:20:41,451 DEBUG TRAIN Batch 63/5300 loss 22.369350 loss_att 11.061186 loss_ctc 48.755066 loss_ctc_origin 36.184532 loss_ctc0 78.086311 lr 0.00104879 rank 0
2022-08-23 15:21:09,436 DEBUG TRAIN Batch 63/5400 loss 27.739359 loss_att 14.223957 loss_ctc 59.275291 loss_ctc_origin 41.250008 loss_ctc0 101.334290 lr 0.00104865 rank 0
2022-08-23 15:21:38,977 DEBUG TRAIN Batch 63/5500 loss 29.567444 loss_att 23.920973 loss_ctc 42.742542 loss_ctc_origin 39.191021 loss_ctc0 51.029427 lr 0.00104850 rank 0
2022-08-23 15:21:53,402 WARNING NaN or Inf found in input tensor.
2022-08-23 15:22:07,373 DEBUG TRAIN Batch 63/5600 loss 41.586109 loss_att 24.330387 loss_ctc 81.849457 loss_ctc_origin 44.637451 loss_ctc0 168.677460 lr 0.00104836 rank 0
2022-08-23 15:22:30,560 DEBUG CV Batch 63/0 loss 25.579357 loss_att 15.309500 loss_ctc 49.542358 loss_ctc_origin 24.876089 loss_ctc0 107.096985 history loss 24.074689 rank 0
2022-08-23 15:22:41,273 DEBUG CV Batch 63/100 loss 37.218102 loss_att 23.510677 loss_ctc 69.202087 loss_ctc_origin 35.642242 loss_ctc0 147.508377 history loss 34.109809 rank 0
2022-08-23 15:22:51,249 DEBUG CV Batch 63/200 loss 30.988861 loss_att 23.679932 loss_ctc 48.043030 loss_ctc_origin 37.268044 loss_ctc0 73.184662 history loss 36.176789 rank 0
2022-08-23 15:23:01,434 DEBUG CV Batch 63/300 loss 27.073317 loss_att 20.389099 loss_ctc 42.669823 loss_ctc_origin 28.069569 loss_ctc0 76.737076 history loss 35.244401 rank 0
2022-08-23 15:23:12,367 DEBUG CV Batch 63/400 loss 41.655052 loss_att 32.860516 loss_ctc 62.175636 loss_ctc_origin 45.629082 loss_ctc0 100.784256 history loss 33.283390 rank 0
2022-08-23 15:23:23,146 DEBUG CV Batch 63/500 loss 28.280159 loss_att 19.176590 loss_ctc 49.521816 loss_ctc_origin 31.064920 loss_ctc0 92.587906 history loss 32.710159 rank 0
2022-08-23 15:23:33,329 DEBUG CV Batch 63/600 loss 32.055973 loss_att 18.536694 loss_ctc 63.600956 loss_ctc_origin 33.962349 loss_ctc0 132.757706 history loss 32.627043 rank 0
2022-08-23 15:23:43,395 DEBUG CV Batch 63/700 loss 21.657526 loss_att 14.943584 loss_ctc 37.323387 loss_ctc_origin 24.325527 loss_ctc0 67.651718 history loss 32.169123 rank 0
2022-08-23 15:23:54,084 DEBUG CV Batch 63/800 loss 23.946634 loss_att 18.009733 loss_ctc 37.799400 loss_ctc_origin 22.568621 loss_ctc0 73.337891 history loss 32.020653 rank 0
2022-08-23 15:24:04,480 INFO Epoch 63 CV info cv_loss 31.90870763209291
2022-08-23 15:24:04,480 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/63.pt
2022-08-23 15:24:04,925 INFO Epoch 64 TRAIN info lr 0.0010482387613054741
2022-08-23 15:24:04,929 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 15:24:32,105 DEBUG TRAIN Batch 64/0 loss 38.848793 loss_att 30.274794 loss_ctc 58.854790 loss_ctc_origin 46.792877 loss_ctc0 86.999245 lr 0.00104823 rank 0
2022-08-23 15:25:00,627 DEBUG TRAIN Batch 64/100 loss 41.024811 loss_att 24.561459 loss_ctc 79.439301 loss_ctc_origin 52.063728 loss_ctc0 143.315613 lr 0.00104809 rank 0
2022-08-23 15:25:29,356 DEBUG TRAIN Batch 64/200 loss 21.869438 loss_att 12.250137 loss_ctc 44.314472 loss_ctc_origin 32.471695 loss_ctc0 71.947617 lr 0.00104795 rank 0
2022-08-23 15:25:58,432 DEBUG TRAIN Batch 64/300 loss 25.531647 loss_att 12.454400 loss_ctc 56.045219 loss_ctc_origin 43.139790 loss_ctc0 86.157875 lr 0.00104780 rank 0
2022-08-23 15:26:26,599 DEBUG TRAIN Batch 64/400 loss 26.882568 loss_att 12.399529 loss_ctc 60.676331 loss_ctc_origin 44.797794 loss_ctc0 97.726242 lr 0.00104766 rank 0
2022-08-23 15:26:29,290 WARNING NaN or Inf found in input tensor.
2022-08-23 15:26:55,658 DEBUG TRAIN Batch 64/500 loss 32.715042 loss_att 26.442726 loss_ctc 47.350449 loss_ctc_origin 41.529419 loss_ctc0 60.932850 lr 0.00104751 rank 0
2022-08-23 15:27:23,756 DEBUG TRAIN Batch 64/600 loss 44.229927 loss_att 25.779676 loss_ctc 87.280502 loss_ctc_origin 52.724998 loss_ctc0 167.910004 lr 0.00104737 rank 0
2022-08-23 15:27:50,352 WARNING NaN or Inf found in input tensor.
2022-08-23 15:27:51,866 DEBUG TRAIN Batch 64/700 loss 26.636410 loss_att 15.903468 loss_ctc 51.679939 loss_ctc_origin 41.866238 loss_ctc0 74.578583 lr 0.00104723 rank 0
2022-08-23 15:28:20,596 DEBUG TRAIN Batch 64/800 loss 22.281445 loss_att 10.398225 loss_ctc 50.008953 loss_ctc_origin 35.676506 loss_ctc0 83.451324 lr 0.00104708 rank 0
2022-08-23 15:28:50,040 DEBUG TRAIN Batch 64/900 loss 26.796843 loss_att 13.287327 loss_ctc 58.319046 loss_ctc_origin 40.503792 loss_ctc0 99.887970 lr 0.00104694 rank 0
2022-08-23 15:29:18,526 DEBUG TRAIN Batch 64/1000 loss 42.982590 loss_att 33.635273 loss_ctc 64.792999 loss_ctc_origin 52.352226 loss_ctc0 93.821457 lr 0.00104680 rank 0
2022-08-23 15:29:33,054 WARNING NaN or Inf found in input tensor.
2022-08-23 15:29:47,336 DEBUG TRAIN Batch 64/1100 loss 34.941319 loss_att 20.463013 loss_ctc 68.724030 loss_ctc_origin 41.278423 loss_ctc0 132.763779 lr 0.00104665 rank 0
2022-08-23 15:30:16,470 DEBUG TRAIN Batch 64/1200 loss 23.149117 loss_att 12.278606 loss_ctc 48.513641 loss_ctc_origin 38.008312 loss_ctc0 73.026085 lr 0.00104651 rank 0
2022-08-23 15:30:46,203 DEBUG TRAIN Batch 64/1300 loss 25.467918 loss_att 12.996121 loss_ctc 54.568779 loss_ctc_origin 40.759300 loss_ctc0 86.790886 lr 0.00104637 rank 0
2022-08-23 15:31:14,438 DEBUG TRAIN Batch 64/1400 loss 29.782986 loss_att 15.488352 loss_ctc 63.137131 loss_ctc_origin 48.164207 loss_ctc0 98.073959 lr 0.00104622 rank 0
2022-08-23 15:31:22,221 WARNING NaN or Inf found in input tensor.
2022-08-23 15:31:50,097 DEBUG TRAIN Batch 64/1500 loss 33.458630 loss_att 27.531174 loss_ctc 47.289352 loss_ctc_origin 41.251888 loss_ctc0 61.376762 lr 0.00104608 rank 0
2022-08-23 15:32:19,584 DEBUG TRAIN Batch 64/1600 loss 40.482399 loss_att 24.883694 loss_ctc 76.879387 loss_ctc_origin 47.248531 loss_ctc0 146.018051 lr 0.00104594 rank 0
2022-08-23 15:32:47,676 DEBUG TRAIN Batch 64/1700 loss 26.064661 loss_att 15.720001 loss_ctc 50.202198 loss_ctc_origin 39.480576 loss_ctc0 75.219315 lr 0.00104579 rank 0
2022-08-23 15:33:15,358 DEBUG TRAIN Batch 64/1800 loss 25.777718 loss_att 13.048615 loss_ctc 55.478951 loss_ctc_origin 42.029770 loss_ctc0 86.860367 lr 0.00104565 rank 0
2022-08-23 15:33:43,760 DEBUG TRAIN Batch 64/1900 loss 25.852371 loss_att 12.799372 loss_ctc 56.309368 loss_ctc_origin 40.405380 loss_ctc0 93.418671 lr 0.00104551 rank 0
2022-08-23 15:34:12,900 DEBUG TRAIN Batch 64/2000 loss 31.473808 loss_att 25.236752 loss_ctc 46.026936 loss_ctc_origin 45.297024 loss_ctc0 47.730064 lr 0.00104537 rank 0
2022-08-23 15:34:40,674 DEBUG TRAIN Batch 64/2100 loss 28.154404 loss_att 16.418518 loss_ctc 55.538128 loss_ctc_origin 33.859543 loss_ctc0 106.121490 lr 0.00104522 rank 0
2022-08-23 15:35:07,514 DEBUG TRAIN Batch 64/2200 loss 22.400227 loss_att 12.403773 loss_ctc 45.725285 loss_ctc_origin 35.282352 loss_ctc0 70.092125 lr 0.00104508 rank 0
2022-08-23 15:35:37,327 DEBUG TRAIN Batch 64/2300 loss 26.669828 loss_att 14.756995 loss_ctc 54.466438 loss_ctc_origin 42.539246 loss_ctc0 82.296555 lr 0.00104494 rank 0
2022-08-23 15:36:06,464 DEBUG TRAIN Batch 64/2400 loss 26.381231 loss_att 13.331280 loss_ctc 56.831116 loss_ctc_origin 38.426178 loss_ctc0 99.775970 lr 0.00104479 rank 0
2022-08-23 15:36:36,057 DEBUG TRAIN Batch 64/2500 loss 31.295912 loss_att 23.465746 loss_ctc 49.566299 loss_ctc_origin 39.237976 loss_ctc0 73.665718 lr 0.00104465 rank 0
2022-08-23 15:36:49,735 WARNING NaN or Inf found in input tensor.
2022-08-23 15:37:04,310 DEBUG TRAIN Batch 64/2600 loss 33.735626 loss_att 24.947380 loss_ctc 54.241531 loss_ctc_origin 44.330482 loss_ctc0 77.367310 lr 0.00104451 rank 0
2022-08-23 15:37:34,168 DEBUG TRAIN Batch 64/2700 loss 31.218912 loss_att 21.530258 loss_ctc 53.825768 loss_ctc_origin 46.192825 loss_ctc0 71.635963 lr 0.00104437 rank 0
2022-08-23 15:38:02,360 DEBUG TRAIN Batch 64/2800 loss 27.426153 loss_att 14.779427 loss_ctc 56.935181 loss_ctc_origin 45.153984 loss_ctc0 84.424644 lr 0.00104422 rank 0
2022-08-23 15:38:30,392 DEBUG TRAIN Batch 64/2900 loss 32.689442 loss_att 17.864563 loss_ctc 67.280823 loss_ctc_origin 50.084389 loss_ctc0 107.405823 lr 0.00104408 rank 0
2022-08-23 15:38:37,560 WARNING NaN or Inf found in input tensor.
2022-08-23 15:39:02,695 DEBUG TRAIN Batch 64/3000 loss 30.831953 loss_att 23.318832 loss_ctc 48.362564 loss_ctc_origin 40.069416 loss_ctc0 67.713234 lr 0.00104394 rank 0
2022-08-23 15:39:30,290 DEBUG TRAIN Batch 64/3100 loss 34.242420 loss_att 24.240749 loss_ctc 57.579651 loss_ctc_origin 47.162354 loss_ctc0 81.886688 lr 0.00104380 rank 0
2022-08-23 15:39:57,367 DEBUG TRAIN Batch 64/3200 loss 26.930054 loss_att 15.475282 loss_ctc 53.657856 loss_ctc_origin 44.625927 loss_ctc0 74.732361 lr 0.00104366 rank 0
2022-08-23 15:40:24,518 DEBUG TRAIN Batch 64/3300 loss 26.753170 loss_att 14.316395 loss_ctc 55.772316 loss_ctc_origin 44.485477 loss_ctc0 82.108269 lr 0.00104351 rank 0
2022-08-23 15:40:35,389 WARNING NaN or Inf found in input tensor.
2022-08-23 15:40:51,720 DEBUG TRAIN Batch 64/3400 loss 33.400555 loss_att 17.305435 loss_ctc 70.955826 loss_ctc_origin 55.274487 loss_ctc0 107.545616 lr 0.00104337 rank 0
2022-08-23 15:41:19,339 DEBUG TRAIN Batch 64/3500 loss 32.284538 loss_att 25.576588 loss_ctc 47.936424 loss_ctc_origin 42.677025 loss_ctc0 60.208359 lr 0.00104323 rank 0
2022-08-23 15:41:45,956 DEBUG TRAIN Batch 64/3600 loss 45.861687 loss_att 29.263180 loss_ctc 84.591537 loss_ctc_origin 55.370926 loss_ctc0 152.772949 lr 0.00104309 rank 0
2022-08-23 15:42:13,132 DEBUG TRAIN Batch 64/3700 loss 23.093529 loss_att 12.645823 loss_ctc 47.471508 loss_ctc_origin 37.440556 loss_ctc0 70.877060 lr 0.00104295 rank 0
2022-08-23 15:42:39,786 DEBUG TRAIN Batch 64/3800 loss 24.794420 loss_att 13.528065 loss_ctc 51.082581 loss_ctc_origin 40.715073 loss_ctc0 75.273422 lr 0.00104280 rank 0
2022-08-23 15:43:06,340 DEBUG TRAIN Batch 64/3900 loss 31.744274 loss_att 17.840637 loss_ctc 64.186089 loss_ctc_origin 49.505463 loss_ctc0 98.440880 lr 0.00104266 rank 0
2022-08-23 15:43:34,010 WARNING NaN or Inf found in input tensor.
2022-08-23 15:43:34,056 DEBUG TRAIN Batch 64/4000 loss inf loss_att 32.949566 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00104252 rank 0
2022-08-23 15:43:46,679 WARNING NaN or Inf found in input tensor.
2022-08-23 15:44:01,212 DEBUG TRAIN Batch 64/4100 loss 47.671791 loss_att 30.445879 loss_ctc 87.865593 loss_ctc_origin 47.499542 loss_ctc0 182.053040 lr 0.00104238 rank 0
2022-08-23 15:44:27,823 DEBUG TRAIN Batch 64/4200 loss 28.760338 loss_att 18.230927 loss_ctc 53.328964 loss_ctc_origin 44.033985 loss_ctc0 75.017250 lr 0.00104224 rank 0
2022-08-23 15:44:54,497 DEBUG TRAIN Batch 64/4300 loss 28.462597 loss_att 15.927439 loss_ctc 57.711296 loss_ctc_origin 46.470287 loss_ctc0 83.940315 lr 0.00104210 rank 0
2022-08-23 15:45:21,835 DEBUG TRAIN Batch 64/4400 loss 34.349716 loss_att 19.898827 loss_ctc 68.068451 loss_ctc_origin 54.443001 loss_ctc0 99.861176 lr 0.00104196 rank 0
2022-08-23 15:45:54,398 DEBUG TRAIN Batch 64/4500 loss 37.064911 loss_att 26.678936 loss_ctc 61.298855 loss_ctc_origin 46.865913 loss_ctc0 94.975723 lr 0.00104181 rank 0
2022-08-23 15:46:20,989 DEBUG TRAIN Batch 64/4600 loss 46.796593 loss_att 27.231956 loss_ctc 92.447403 loss_ctc_origin 55.970833 loss_ctc0 177.559418 lr 0.00104167 rank 0
2022-08-23 15:46:47,852 DEBUG TRAIN Batch 64/4700 loss 26.280754 loss_att 17.930216 loss_ctc 45.765343 loss_ctc_origin 35.590248 loss_ctc0 69.507233 lr 0.00104153 rank 0
2022-08-23 15:47:14,602 DEBUG TRAIN Batch 64/4800 loss 26.904011 loss_att 14.640169 loss_ctc 55.519634 loss_ctc_origin 43.227646 loss_ctc0 84.200935 lr 0.00104139 rank 0
2022-08-23 15:47:41,159 DEBUG TRAIN Batch 64/4900 loss 27.604353 loss_att 13.339879 loss_ctc 60.888123 loss_ctc_origin 45.002003 loss_ctc0 97.955727 lr 0.00104125 rank 0
2022-08-23 15:47:50,968 WARNING NaN or Inf found in input tensor.
2022-08-23 15:48:08,203 DEBUG TRAIN Batch 64/5000 loss 40.127354 loss_att 27.172056 loss_ctc 70.356377 loss_ctc_origin 49.280354 loss_ctc0 119.533760 lr 0.00104111 rank 0
2022-08-23 15:48:34,770 DEBUG TRAIN Batch 64/5100 loss 48.873997 loss_att 31.712467 loss_ctc 88.917564 loss_ctc_origin 56.553139 loss_ctc0 164.434555 lr 0.00104097 rank 0
2022-08-23 15:49:02,245 DEBUG TRAIN Batch 64/5200 loss 25.446159 loss_att 15.147554 loss_ctc 49.476234 loss_ctc_origin 40.379501 loss_ctc0 70.701942 lr 0.00104083 rank 0
2022-08-23 15:49:29,150 DEBUG TRAIN Batch 64/5300 loss 27.699783 loss_att 14.410681 loss_ctc 58.707687 loss_ctc_origin 47.148731 loss_ctc0 85.678574 lr 0.00104068 rank 0
2022-08-23 15:49:56,706 DEBUG TRAIN Batch 64/5400 loss 32.250126 loss_att 16.167645 loss_ctc 69.775909 loss_ctc_origin 54.628868 loss_ctc0 105.119003 lr 0.00104054 rank 0
2022-08-23 15:50:25,720 DEBUG TRAIN Batch 64/5500 loss 36.747097 loss_att 26.678883 loss_ctc 60.239601 loss_ctc_origin 43.463905 loss_ctc0 99.382889 lr 0.00104040 rank 0
2022-08-23 15:50:38,994 WARNING NaN or Inf found in input tensor.
2022-08-23 15:50:53,464 DEBUG TRAIN Batch 64/5600 loss 40.478878 loss_att 24.500221 loss_ctc 77.762413 loss_ctc_origin 47.533791 loss_ctc0 148.295868 lr 0.00104026 rank 0
2022-08-23 15:51:16,431 DEBUG CV Batch 64/0 loss 16.647221 loss_att 10.241009 loss_ctc 31.595047 loss_ctc_origin 17.795586 loss_ctc0 63.793781 history loss 15.667972 rank 0
2022-08-23 15:51:27,789 DEBUG CV Batch 64/100 loss 28.773712 loss_att 20.607105 loss_ctc 47.829124 loss_ctc_origin 29.343441 loss_ctc0 90.962387 history loss 32.359965 rank 0
2022-08-23 15:51:37,819 DEBUG CV Batch 64/200 loss 33.623665 loss_att 23.597122 loss_ctc 57.018929 loss_ctc_origin 39.133636 loss_ctc0 98.751266 history loss 33.781981 rank 0
2022-08-23 15:51:48,184 DEBUG CV Batch 64/300 loss 27.398781 loss_att 20.562002 loss_ctc 43.351261 loss_ctc_origin 28.393457 loss_ctc0 78.252800 history loss 32.849677 rank 0
2022-08-23 15:51:58,918 DEBUG CV Batch 64/400 loss 43.374252 loss_att 34.372028 loss_ctc 64.379448 loss_ctc_origin 47.580719 loss_ctc0 103.576477 history loss 31.060757 rank 0
2022-08-23 15:52:10,029 DEBUG CV Batch 64/500 loss 21.540140 loss_att 15.477783 loss_ctc 35.685638 loss_ctc_origin 26.467175 loss_ctc0 57.195385 history loss 30.657033 rank 0
2022-08-23 15:52:20,881 DEBUG CV Batch 64/600 loss 24.406595 loss_att 15.053552 loss_ctc 46.230362 loss_ctc_origin 25.706678 loss_ctc0 94.118958 history loss 30.542666 rank 0
2022-08-23 15:52:31,177 DEBUG CV Batch 64/700 loss 22.388807 loss_att 15.242471 loss_ctc 39.063591 loss_ctc_origin 26.144936 loss_ctc0 69.207115 history loss 30.149306 rank 0
2022-08-23 15:52:41,827 DEBUG CV Batch 64/800 loss 24.314034 loss_att 18.048767 loss_ctc 38.932991 loss_ctc_origin 23.733582 loss_ctc0 74.398277 history loss 30.089532 rank 0
2022-08-23 15:52:52,124 INFO Epoch 64 CV info cv_loss 30.12760211451734
2022-08-23 15:52:52,125 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/64.pt
2022-08-23 15:52:52,624 INFO Epoch 65 TRAIN info lr 0.001040144132357161
2022-08-23 15:52:52,628 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 15:53:19,944 DEBUG TRAIN Batch 65/0 loss 40.276932 loss_att 30.847794 loss_ctc 62.278259 loss_ctc_origin 53.800255 loss_ctc0 82.060257 lr 0.00104014 rank 0
2022-08-23 15:53:48,523 DEBUG TRAIN Batch 65/100 loss 41.596218 loss_att 24.821819 loss_ctc 80.736481 loss_ctc_origin 49.148483 loss_ctc0 154.441788 lr 0.00104000 rank 0
2022-08-23 15:54:17,010 DEBUG TRAIN Batch 65/200 loss 25.983036 loss_att 15.486012 loss_ctc 50.476089 loss_ctc_origin 41.397278 loss_ctc0 71.659988 lr 0.00103986 rank 0
2022-08-23 15:54:22,634 WARNING NaN or Inf found in input tensor.
2022-08-23 15:54:45,506 DEBUG TRAIN Batch 65/300 loss 23.908108 loss_att 13.156399 loss_ctc 48.995422 loss_ctc_origin 37.256157 loss_ctc0 76.387047 lr 0.00103972 rank 0
2022-08-23 15:55:13,532 DEBUG TRAIN Batch 65/400 loss 28.258068 loss_att 14.596554 loss_ctc 60.134933 loss_ctc_origin 43.408115 loss_ctc0 99.164169 lr 0.00103958 rank 0
2022-08-23 15:55:43,734 DEBUG TRAIN Batch 65/500 loss 39.525223 loss_att 29.436062 loss_ctc 63.066589 loss_ctc_origin 52.183357 loss_ctc0 88.460800 lr 0.00103944 rank 0
2022-08-23 15:56:13,670 DEBUG TRAIN Batch 65/600 loss 37.806824 loss_att 23.194153 loss_ctc 71.903046 loss_ctc_origin 45.329140 loss_ctc0 133.908813 lr 0.00103930 rank 0
2022-08-23 15:56:41,724 DEBUG TRAIN Batch 65/700 loss 21.199532 loss_att 11.905260 loss_ctc 42.886162 loss_ctc_origin 33.535992 loss_ctc0 64.703232 lr 0.00103916 rank 0
2022-08-23 15:57:09,964 DEBUG TRAIN Batch 65/800 loss 26.439358 loss_att 12.969425 loss_ctc 57.869198 loss_ctc_origin 45.967354 loss_ctc0 85.640167 lr 0.00103902 rank 0
2022-08-23 15:57:38,821 DEBUG TRAIN Batch 65/900 loss 25.893559 loss_att 12.262886 loss_ctc 57.698463 loss_ctc_origin 43.083496 loss_ctc0 91.800049 lr 0.00103887 rank 0
2022-08-23 15:58:07,541 DEBUG TRAIN Batch 65/1000 loss 32.464375 loss_att 24.583717 loss_ctc 50.852577 loss_ctc_origin 37.037216 loss_ctc0 83.088425 lr 0.00103873 rank 0
2022-08-23 15:58:36,480 DEBUG TRAIN Batch 65/1100 loss 35.106827 loss_att 20.146854 loss_ctc 70.013428 loss_ctc_origin 47.842857 loss_ctc0 121.744751 lr 0.00103859 rank 0
2022-08-23 15:59:04,086 DEBUG TRAIN Batch 65/1200 loss 23.185621 loss_att 14.132287 loss_ctc 44.310066 loss_ctc_origin 33.911743 loss_ctc0 68.572815 lr 0.00103845 rank 0
2022-08-23 15:59:33,334 DEBUG TRAIN Batch 65/1300 loss 27.838802 loss_att 12.941328 loss_ctc 62.599571 loss_ctc_origin 50.217072 loss_ctc0 91.492065 lr 0.00103831 rank 0
2022-08-23 16:00:02,455 DEBUG TRAIN Batch 65/1400 loss 32.090916 loss_att 16.791517 loss_ctc 67.789505 loss_ctc_origin 50.167130 loss_ctc0 108.908371 lr 0.00103817 rank 0
2022-08-23 16:00:36,461 DEBUG TRAIN Batch 65/1500 loss 31.898167 loss_att 21.164745 loss_ctc 56.942810 loss_ctc_origin 41.500496 loss_ctc0 92.974869 lr 0.00103803 rank 0
2022-08-23 16:01:05,728 DEBUG TRAIN Batch 65/1600 loss 26.967703 loss_att 15.060874 loss_ctc 54.750301 loss_ctc_origin 32.052101 loss_ctc0 107.712769 lr 0.00103790 rank 0
2022-08-23 16:01:34,733 DEBUG TRAIN Batch 65/1700 loss 26.987980 loss_att 17.214293 loss_ctc 49.793247 loss_ctc_origin 40.950531 loss_ctc0 70.426254 lr 0.00103776 rank 0
2022-08-23 16:01:47,676 WARNING NaN or Inf found in input tensor.
2022-08-23 16:02:02,897 DEBUG TRAIN Batch 65/1800 loss 25.797012 loss_att 13.704267 loss_ctc 54.013412 loss_ctc_origin 42.119419 loss_ctc0 81.766052 lr 0.00103762 rank 0
2022-08-23 16:02:31,016 DEBUG TRAIN Batch 65/1900 loss 33.497086 loss_att 19.111176 loss_ctc 67.064201 loss_ctc_origin 51.965187 loss_ctc0 102.295235 lr 0.00103748 rank 0
2022-08-23 16:02:59,496 DEBUG TRAIN Batch 65/2000 loss 28.135277 loss_att 21.296776 loss_ctc 44.091782 loss_ctc_origin 31.903633 loss_ctc0 72.530792 lr 0.00103734 rank 0
2022-08-23 16:03:27,849 DEBUG TRAIN Batch 65/2100 loss 34.744202 loss_att 21.776674 loss_ctc 65.001770 loss_ctc_origin 36.980728 loss_ctc0 130.384201 lr 0.00103720 rank 0
2022-08-23 16:03:56,349 DEBUG TRAIN Batch 65/2200 loss 27.085638 loss_att 16.963404 loss_ctc 50.704185 loss_ctc_origin 40.967430 loss_ctc0 73.423286 lr 0.00103706 rank 0
2022-08-23 16:04:24,202 DEBUG TRAIN Batch 65/2300 loss 23.724968 loss_att 11.679972 loss_ctc 51.829964 loss_ctc_origin 41.415115 loss_ctc0 76.131287 lr 0.00103692 rank 0
2022-08-23 16:04:53,353 DEBUG TRAIN Batch 65/2400 loss 34.131824 loss_att 18.427654 loss_ctc 70.774887 loss_ctc_origin 57.190613 loss_ctc0 102.471512 lr 0.00103678 rank 0
2022-08-23 16:05:21,736 DEBUG TRAIN Batch 65/2500 loss 29.795120 loss_att 23.875351 loss_ctc 43.607910 loss_ctc_origin 38.223064 loss_ctc0 56.172546 lr 0.00103664 rank 0
2022-08-23 16:05:49,837 DEBUG TRAIN Batch 65/2600 loss 37.473892 loss_att 23.712709 loss_ctc 69.583313 loss_ctc_origin 42.543301 loss_ctc0 132.676682 lr 0.00103650 rank 0
2022-08-23 16:06:19,232 DEBUG TRAIN Batch 65/2700 loss 23.721514 loss_att 14.658062 loss_ctc 44.869568 loss_ctc_origin 35.016609 loss_ctc0 67.859802 lr 0.00103636 rank 0
2022-08-23 16:06:48,243 DEBUG TRAIN Batch 65/2800 loss 26.274286 loss_att 12.361864 loss_ctc 58.736603 loss_ctc_origin 47.056053 loss_ctc0 85.991211 lr 0.00103622 rank 0
2022-08-23 16:07:16,710 DEBUG TRAIN Batch 65/2900 loss 30.882797 loss_att 15.341008 loss_ctc 67.146965 loss_ctc_origin 52.599247 loss_ctc0 101.091629 lr 0.00103608 rank 0
2022-08-23 16:07:53,315 DEBUG TRAIN Batch 65/3000 loss 29.442698 loss_att 21.784769 loss_ctc 47.311195 loss_ctc_origin 39.376534 loss_ctc0 65.825409 lr 0.00103594 rank 0
2022-08-23 16:08:21,784 DEBUG TRAIN Batch 65/3100 loss 34.777489 loss_att 22.693314 loss_ctc 62.973892 loss_ctc_origin 37.147781 loss_ctc0 123.234802 lr 0.00103581 rank 0
2022-08-23 16:08:50,926 DEBUG TRAIN Batch 65/3200 loss 26.972893 loss_att 14.903765 loss_ctc 55.134193 loss_ctc_origin 46.514050 loss_ctc0 75.247871 lr 0.00103567 rank 0
2022-08-23 16:08:56,490 WARNING NaN or Inf found in input tensor.
2022-08-23 16:09:19,074 DEBUG TRAIN Batch 65/3300 loss 26.839781 loss_att 12.958968 loss_ctc 59.228340 loss_ctc_origin 49.093796 loss_ctc0 82.875595 lr 0.00103553 rank 0
2022-08-23 16:09:48,169 DEBUG TRAIN Batch 65/3400 loss 31.455526 loss_att 16.156590 loss_ctc 67.153046 loss_ctc_origin 53.033520 loss_ctc0 100.098602 lr 0.00103539 rank 0
2022-08-23 16:10:17,383 DEBUG TRAIN Batch 65/3500 loss 35.563404 loss_att 27.382971 loss_ctc 54.651077 loss_ctc_origin 41.701302 loss_ctc0 84.867210 lr 0.00103525 rank 0
2022-08-23 16:10:46,216 DEBUG TRAIN Batch 65/3600 loss 31.439825 loss_att 18.116264 loss_ctc 62.528130 loss_ctc_origin 36.811306 loss_ctc0 122.534042 lr 0.00103511 rank 0
2022-08-23 16:11:14,572 DEBUG TRAIN Batch 65/3700 loss 21.388378 loss_att 12.634327 loss_ctc 41.814495 loss_ctc_origin 32.349968 loss_ctc0 63.898388 lr 0.00103497 rank 0
2022-08-23 16:11:43,678 DEBUG TRAIN Batch 65/3800 loss 23.633301 loss_att 12.476818 loss_ctc 49.665092 loss_ctc_origin 38.046822 loss_ctc0 76.774384 lr 0.00103483 rank 0
2022-08-23 16:12:00,865 WARNING NaN or Inf found in input tensor.
2022-08-23 16:12:12,337 DEBUG TRAIN Batch 65/3900 loss 27.008636 loss_att 13.500731 loss_ctc 58.527084 loss_ctc_origin 42.361607 loss_ctc0 96.246536 lr 0.00103470 rank 0
2022-08-23 16:12:14,984 WARNING NaN or Inf found in input tensor.
2022-08-23 16:12:35,088 WARNING NaN or Inf found in input tensor.
2022-08-23 16:12:41,528 DEBUG TRAIN Batch 65/4000 loss 34.595467 loss_att 25.824406 loss_ctc 55.061272 loss_ctc_origin 47.294777 loss_ctc0 73.183090 lr 0.00103456 rank 0
2022-08-23 16:13:10,333 DEBUG TRAIN Batch 65/4100 loss 36.789436 loss_att 24.864733 loss_ctc 64.613747 loss_ctc_origin 43.380894 loss_ctc0 114.157074 lr 0.00103442 rank 0
2022-08-23 16:13:39,662 DEBUG TRAIN Batch 65/4200 loss 23.702181 loss_att 13.470356 loss_ctc 47.576439 loss_ctc_origin 38.838379 loss_ctc0 67.965248 lr 0.00103428 rank 0
2022-08-23 16:14:08,113 DEBUG TRAIN Batch 65/4300 loss 27.923073 loss_att 15.818243 loss_ctc 56.167671 loss_ctc_origin 44.941231 loss_ctc0 82.362694 lr 0.00103414 rank 0
2022-08-23 16:14:32,303 WARNING NaN or Inf found in input tensor.
2022-08-23 16:14:36,789 DEBUG TRAIN Batch 65/4400 loss 26.866032 loss_att 13.986807 loss_ctc 56.917553 loss_ctc_origin 42.795883 loss_ctc0 89.868118 lr 0.00103400 rank 0
2022-08-23 16:15:11,470 DEBUG TRAIN Batch 65/4500 loss 29.845257 loss_att 22.389454 loss_ctc 47.242126 loss_ctc_origin 41.155682 loss_ctc0 61.443829 lr 0.00103387 rank 0
2022-08-23 16:15:40,282 DEBUG TRAIN Batch 65/4600 loss 38.836685 loss_att 25.580292 loss_ctc 69.768265 loss_ctc_origin 48.783501 loss_ctc0 118.732719 lr 0.00103373 rank 0
2022-08-23 16:16:08,382 DEBUG TRAIN Batch 65/4700 loss 24.089350 loss_att 15.055445 loss_ctc 45.168461 loss_ctc_origin 34.310188 loss_ctc0 70.504425 lr 0.00103359 rank 0
2022-08-23 16:16:13,888 WARNING NaN or Inf found in input tensor.
2022-08-23 16:16:37,014 DEBUG TRAIN Batch 65/4800 loss 26.522743 loss_att 13.377275 loss_ctc 57.195496 loss_ctc_origin 44.560516 loss_ctc0 86.677109 lr 0.00103345 rank 0
2022-08-23 16:17:05,905 DEBUG TRAIN Batch 65/4900 loss 30.576691 loss_att 16.918476 loss_ctc 62.445862 loss_ctc_origin 47.580654 loss_ctc0 97.131348 lr 0.00103331 rank 0
2022-08-23 16:17:34,582 DEBUG TRAIN Batch 65/5000 loss 34.017365 loss_att 26.447069 loss_ctc 51.681381 loss_ctc_origin 45.230186 loss_ctc0 66.734169 lr 0.00103318 rank 0
2022-08-23 16:18:02,765 DEBUG TRAIN Batch 65/5100 loss 34.618031 loss_att 22.103617 loss_ctc 63.818329 loss_ctc_origin 43.462082 loss_ctc0 111.316238 lr 0.00103304 rank 0
2022-08-23 16:18:30,649 DEBUG TRAIN Batch 65/5200 loss 21.445486 loss_att 12.563161 loss_ctc 42.170910 loss_ctc_origin 31.989374 loss_ctc0 65.927826 lr 0.00103290 rank 0
2022-08-23 16:18:59,849 DEBUG TRAIN Batch 65/5300 loss 26.271286 loss_att 13.499552 loss_ctc 56.071999 loss_ctc_origin 44.771587 loss_ctc0 82.439621 lr 0.00103276 rank 0
2022-08-23 16:19:24,628 WARNING NaN or Inf found in input tensor.
2022-08-23 16:19:29,021 DEBUG TRAIN Batch 65/5400 loss 27.683966 loss_att 14.240560 loss_ctc 59.051910 loss_ctc_origin 43.720520 loss_ctc0 94.825157 lr 0.00103262 rank 0
2022-08-23 16:19:57,178 DEBUG TRAIN Batch 65/5500 loss 33.867294 loss_att 27.503670 loss_ctc 48.715752 loss_ctc_origin 40.907234 loss_ctc0 66.935631 lr 0.00103249 rank 0
2022-08-23 16:20:25,995 DEBUG TRAIN Batch 65/5600 loss 27.765884 loss_att 16.287994 loss_ctc 54.547623 loss_ctc_origin 34.937447 loss_ctc0 100.304688 lr 0.00103235 rank 0
2022-08-23 16:20:48,508 DEBUG CV Batch 65/0 loss 16.813519 loss_att 11.544040 loss_ctc 29.108971 loss_ctc_origin 20.021339 loss_ctc0 50.313446 history loss 15.824488 rank 0
2022-08-23 16:20:59,188 DEBUG CV Batch 65/100 loss 26.524994 loss_att 20.301136 loss_ctc 41.047325 loss_ctc_origin 28.135643 loss_ctc0 71.174576 history loss 31.068271 rank 0
2022-08-23 16:21:09,172 DEBUG CV Batch 65/200 loss 30.411455 loss_att 23.272915 loss_ctc 47.068047 loss_ctc_origin 35.911739 loss_ctc0 73.099426 history loss 32.669988 rank 0
2022-08-23 16:21:19,374 DEBUG CV Batch 65/300 loss 25.242798 loss_att 18.191219 loss_ctc 41.696476 loss_ctc_origin 26.489067 loss_ctc0 77.180428 history loss 31.664833 rank 0
2022-08-23 16:21:30,127 DEBUG CV Batch 65/400 loss 43.798294 loss_att 35.127533 loss_ctc 64.030060 loss_ctc_origin 47.861233 loss_ctc0 101.757332 history loss 29.948920 rank 0
2022-08-23 16:21:41,071 DEBUG CV Batch 65/500 loss 20.854229 loss_att 15.296832 loss_ctc 33.821484 loss_ctc_origin 25.499989 loss_ctc0 53.238312 history loss 29.534847 rank 0
2022-08-23 16:21:51,816 DEBUG CV Batch 65/600 loss 21.923347 loss_att 14.899935 loss_ctc 38.311310 loss_ctc_origin 24.786360 loss_ctc0 69.869522 history loss 29.342327 rank 0
2022-08-23 16:22:02,154 DEBUG CV Batch 65/700 loss 22.189838 loss_att 15.366616 loss_ctc 38.110687 loss_ctc_origin 25.399605 loss_ctc0 67.769875 history loss 28.948878 rank 0
2022-08-23 16:22:12,829 DEBUG CV Batch 65/800 loss 24.444683 loss_att 18.377007 loss_ctc 38.602592 loss_ctc_origin 23.854744 loss_ctc0 73.014236 history loss 28.870639 rank 0
2022-08-23 16:22:23,168 INFO Epoch 65 CV info cv_loss 28.933893984008286
2022-08-23 16:22:23,168 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/65.pt
2022-08-23 16:22:23,600 INFO Epoch 66 TRAIN info lr 0.0010322341762513576
2022-08-23 16:22:23,603 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 16:22:50,977 DEBUG TRAIN Batch 66/0 loss 28.363934 loss_att 21.216164 loss_ctc 45.042065 loss_ctc_origin 36.208916 loss_ctc0 65.652740 lr 0.00103223 rank 0
2022-08-23 16:23:19,139 DEBUG TRAIN Batch 66/100 loss 29.205036 loss_att 17.483839 loss_ctc 56.554493 loss_ctc_origin 41.111176 loss_ctc0 92.588898 lr 0.00103209 rank 0
2022-08-23 16:23:47,466 DEBUG TRAIN Batch 66/200 loss 24.063839 loss_att 14.956259 loss_ctc 45.314857 loss_ctc_origin 34.928524 loss_ctc0 69.549629 lr 0.00103195 rank 0
2022-08-23 16:24:16,127 DEBUG TRAIN Batch 66/300 loss 25.414516 loss_att 13.865469 loss_ctc 52.362289 loss_ctc_origin 39.442474 loss_ctc0 82.508530 lr 0.00103182 rank 0
2022-08-23 16:24:45,037 DEBUG TRAIN Batch 66/400 loss 26.062500 loss_att 12.026852 loss_ctc 58.812347 loss_ctc_origin 40.343163 loss_ctc0 101.907104 lr 0.00103168 rank 0
2022-08-23 16:25:14,688 DEBUG TRAIN Batch 66/500 loss 30.568834 loss_att 22.134945 loss_ctc 50.247910 loss_ctc_origin 40.041107 loss_ctc0 74.063789 lr 0.00103154 rank 0
2022-08-23 16:25:43,603 DEBUG TRAIN Batch 66/600 loss 32.692883 loss_att 22.206474 loss_ctc 57.161163 loss_ctc_origin 38.003807 loss_ctc0 101.861656 lr 0.00103140 rank 0
2022-08-23 16:26:11,988 DEBUG TRAIN Batch 66/700 loss 27.256847 loss_att 16.924919 loss_ctc 51.364677 loss_ctc_origin 44.467808 loss_ctc0 67.457367 lr 0.00103127 rank 0
2022-08-23 16:26:41,670 DEBUG TRAIN Batch 66/800 loss 26.186756 loss_att 13.935514 loss_ctc 54.772984 loss_ctc_origin 41.897362 loss_ctc0 84.816093 lr 0.00103113 rank 0
2022-08-23 16:27:10,737 DEBUG TRAIN Batch 66/900 loss 27.831717 loss_att 14.290180 loss_ctc 59.428635 loss_ctc_origin 42.328789 loss_ctc0 99.328278 lr 0.00103099 rank 0
2022-08-23 16:27:40,452 DEBUG TRAIN Batch 66/1000 loss 41.495186 loss_att 31.060310 loss_ctc 65.843239 loss_ctc_origin 44.157951 loss_ctc0 116.442238 lr 0.00103086 rank 0
2022-08-23 16:28:09,404 DEBUG TRAIN Batch 66/1100 loss 47.256203 loss_att 29.161167 loss_ctc 89.477951 loss_ctc_origin 56.658390 loss_ctc0 166.056931 lr 0.00103072 rank 0
2022-08-23 16:28:37,843 DEBUG TRAIN Batch 66/1200 loss 25.469791 loss_att 14.487378 loss_ctc 51.095421 loss_ctc_origin 40.528198 loss_ctc0 75.752274 lr 0.00103058 rank 0
2022-08-23 16:29:05,850 DEBUG TRAIN Batch 66/1300 loss 29.103432 loss_att 15.461616 loss_ctc 60.934334 loss_ctc_origin 48.992130 loss_ctc0 88.799469 lr 0.00103045 rank 0
2022-08-23 16:29:35,300 DEBUG TRAIN Batch 66/1400 loss 28.768452 loss_att 13.352745 loss_ctc 64.738434 loss_ctc_origin 48.375740 loss_ctc0 102.918045 lr 0.00103031 rank 0
2022-08-23 16:30:09,890 DEBUG TRAIN Batch 66/1500 loss 35.011688 loss_att 27.169491 loss_ctc 53.310158 loss_ctc_origin 42.529518 loss_ctc0 78.464989 lr 0.00103017 rank 0
2022-08-23 16:30:38,917 DEBUG TRAIN Batch 66/1600 loss 41.704712 loss_att 23.328106 loss_ctc 84.583450 loss_ctc_origin 50.146156 loss_ctc0 164.937119 lr 0.00103004 rank 0
2022-08-23 16:31:07,418 DEBUG TRAIN Batch 66/1700 loss 24.087221 loss_att 15.155421 loss_ctc 44.928085 loss_ctc_origin 34.248222 loss_ctc0 69.847763 lr 0.00102990 rank 0
2022-08-23 16:31:35,852 DEBUG TRAIN Batch 66/1800 loss 23.722687 loss_att 11.618220 loss_ctc 51.966438 loss_ctc_origin 40.474304 loss_ctc0 78.781410 lr 0.00102976 rank 0
2022-08-23 16:32:04,618 DEBUG TRAIN Batch 66/1900 loss 29.063580 loss_att 14.720384 loss_ctc 62.531033 loss_ctc_origin 45.394699 loss_ctc0 102.515808 lr 0.00102963 rank 0
2022-08-23 16:32:33,599 DEBUG TRAIN Batch 66/2000 loss 34.310753 loss_att 25.059076 loss_ctc 55.897987 loss_ctc_origin 41.153778 loss_ctc0 90.301147 lr 0.00102949 rank 0
2022-08-23 16:33:01,561 DEBUG TRAIN Batch 66/2100 loss 35.069801 loss_att 20.957584 loss_ctc 67.998314 loss_ctc_origin 42.445343 loss_ctc0 127.621918 lr 0.00102935 rank 0
2022-08-23 16:33:29,473 DEBUG TRAIN Batch 66/2200 loss 23.116232 loss_att 14.502516 loss_ctc 43.214901 loss_ctc_origin 32.660316 loss_ctc0 67.842262 lr 0.00102922 rank 0
2022-08-23 16:33:57,404 DEBUG TRAIN Batch 66/2300 loss 24.228233 loss_att 12.277575 loss_ctc 52.113106 loss_ctc_origin 41.587585 loss_ctc0 76.672653 lr 0.00102908 rank 0
2022-08-23 16:34:26,238 DEBUG TRAIN Batch 66/2400 loss 29.740955 loss_att 16.565680 loss_ctc 60.483265 loss_ctc_origin 45.902916 loss_ctc0 94.504074 lr 0.00102894 rank 0
2022-08-23 16:34:55,333 DEBUG TRAIN Batch 66/2500 loss 26.238693 loss_att 20.836727 loss_ctc 38.843277 loss_ctc_origin 34.110321 loss_ctc0 49.886841 lr 0.00102881 rank 0
2022-08-23 16:35:24,086 DEBUG TRAIN Batch 66/2600 loss 34.499046 loss_att 22.559275 loss_ctc 62.358501 loss_ctc_origin 40.579834 loss_ctc0 113.175385 lr 0.00102867 rank 0
2022-08-23 16:35:53,280 DEBUG TRAIN Batch 66/2700 loss 22.220055 loss_att 11.913019 loss_ctc 46.269802 loss_ctc_origin 37.083149 loss_ctc0 67.705322 lr 0.00102854 rank 0
2022-08-23 16:36:23,084 DEBUG TRAIN Batch 66/2800 loss 26.120152 loss_att 14.961641 loss_ctc 52.156673 loss_ctc_origin 40.413406 loss_ctc0 79.557625 lr 0.00102840 rank 0
2022-08-23 16:36:51,093 DEBUG TRAIN Batch 66/2900 loss 28.772158 loss_att 14.950422 loss_ctc 61.022873 loss_ctc_origin 45.284061 loss_ctc0 97.746758 lr 0.00102826 rank 0
2022-08-23 16:37:26,909 DEBUG TRAIN Batch 66/3000 loss 32.147736 loss_att 26.933613 loss_ctc 44.314018 loss_ctc_origin 37.757366 loss_ctc0 59.612877 lr 0.00102813 rank 0
2022-08-23 16:37:56,072 DEBUG TRAIN Batch 66/3100 loss 36.385880 loss_att 22.785851 loss_ctc 68.119278 loss_ctc_origin 44.676498 loss_ctc0 122.819084 lr 0.00102799 rank 0
2022-08-23 16:38:24,486 DEBUG TRAIN Batch 66/3200 loss 25.121143 loss_att 14.574799 loss_ctc 49.729279 loss_ctc_origin 40.497139 loss_ctc0 71.270935 lr 0.00102786 rank 0
2022-08-23 16:38:52,639 DEBUG TRAIN Batch 66/3300 loss 24.853729 loss_att 13.730347 loss_ctc 50.808289 loss_ctc_origin 38.480022 loss_ctc0 79.574242 lr 0.00102772 rank 0
2022-08-23 16:39:21,188 DEBUG TRAIN Batch 66/3400 loss 25.581932 loss_att 12.690399 loss_ctc 55.662174 loss_ctc_origin 40.591286 loss_ctc0 90.827576 lr 0.00102759 rank 0
2022-08-23 16:39:50,686 DEBUG TRAIN Batch 66/3500 loss 32.354614 loss_att 24.454659 loss_ctc 50.787834 loss_ctc_origin 41.475609 loss_ctc0 72.516365 lr 0.00102745 rank 0
2022-08-23 16:40:18,806 DEBUG TRAIN Batch 66/3600 loss 32.836494 loss_att 21.473640 loss_ctc 59.349812 loss_ctc_origin 36.697655 loss_ctc0 112.204842 lr 0.00102731 rank 0
2022-08-23 16:40:47,661 DEBUG TRAIN Batch 66/3700 loss 26.467827 loss_att 17.628147 loss_ctc 47.093750 loss_ctc_origin 37.514771 loss_ctc0 69.444702 lr 0.00102718 rank 0
2022-08-23 16:41:06,732 WARNING NaN or Inf found in input tensor.
2022-08-23 16:41:16,716 DEBUG TRAIN Batch 66/3800 loss 25.006367 loss_att 11.737206 loss_ctc 55.967739 loss_ctc_origin 42.177063 loss_ctc0 88.145981 lr 0.00102704 rank 0
2022-08-23 16:41:45,565 DEBUG TRAIN Batch 66/3900 loss 27.904911 loss_att 13.922903 loss_ctc 60.529594 loss_ctc_origin 46.892578 loss_ctc0 92.349304 lr 0.00102691 rank 0
2022-08-23 16:42:15,095 DEBUG TRAIN Batch 66/4000 loss 37.889771 loss_att 30.718246 loss_ctc 54.623322 loss_ctc_origin 47.812683 loss_ctc0 70.514816 lr 0.00102677 rank 0
2022-08-23 16:42:44,388 DEBUG TRAIN Batch 66/4100 loss 42.150852 loss_att 26.854561 loss_ctc 77.842194 loss_ctc_origin 46.458626 loss_ctc0 151.070496 lr 0.00102664 rank 0
2022-08-23 16:43:12,222 DEBUG TRAIN Batch 66/4200 loss 27.201389 loss_att 16.851349 loss_ctc 51.351486 loss_ctc_origin 41.696381 loss_ctc0 73.880066 lr 0.00102650 rank 0
2022-08-23 16:43:41,846 DEBUG TRAIN Batch 66/4300 loss 25.133236 loss_att 11.755373 loss_ctc 56.348244 loss_ctc_origin 43.094383 loss_ctc0 87.273918 lr 0.00102637 rank 0
2022-08-23 16:44:06,989 WARNING NaN or Inf found in input tensor.
2022-08-23 16:44:11,521 DEBUG TRAIN Batch 66/4400 loss 30.753956 loss_att 16.415924 loss_ctc 64.209366 loss_ctc_origin 48.158600 loss_ctc0 101.661156 lr 0.00102623 rank 0
2022-08-23 16:44:47,697 DEBUG TRAIN Batch 66/4500 loss 29.686245 loss_att 22.534985 loss_ctc 46.372520 loss_ctc_origin 40.650574 loss_ctc0 59.723736 lr 0.00102610 rank 0
2022-08-23 16:45:16,563 DEBUG TRAIN Batch 66/4600 loss 40.060875 loss_att 25.858757 loss_ctc 73.199158 loss_ctc_origin 46.448967 loss_ctc0 135.616272 lr 0.00102596 rank 0
2022-08-23 16:45:45,711 DEBUG TRAIN Batch 66/4700 loss 26.256603 loss_att 15.642998 loss_ctc 51.021679 loss_ctc_origin 41.351910 loss_ctc0 73.584473 lr 0.00102583 rank 0
2022-08-23 16:46:14,051 DEBUG TRAIN Batch 66/4800 loss 25.965302 loss_att 13.214830 loss_ctc 55.716396 loss_ctc_origin 42.710701 loss_ctc0 86.063019 lr 0.00102569 rank 0
2022-08-23 16:46:24,878 WARNING NaN or Inf found in input tensor.
2022-08-23 16:46:42,704 DEBUG TRAIN Batch 66/4900 loss 32.654049 loss_att 16.774681 loss_ctc 69.705902 loss_ctc_origin 54.914524 loss_ctc0 104.219116 lr 0.00102556 rank 0
2022-08-23 16:47:12,289 DEBUG TRAIN Batch 66/5000 loss 28.776703 loss_att 22.573444 loss_ctc 43.250977 loss_ctc_origin 35.388184 loss_ctc0 61.597485 lr 0.00102542 rank 0
2022-08-23 16:47:40,721 DEBUG TRAIN Batch 66/5100 loss 36.588505 loss_att 21.612103 loss_ctc 71.533440 loss_ctc_origin 48.077618 loss_ctc0 126.263687 lr 0.00102529 rank 0
2022-08-23 16:48:09,201 DEBUG TRAIN Batch 66/5200 loss 27.223812 loss_att 16.013268 loss_ctc 53.381748 loss_ctc_origin 43.257637 loss_ctc0 77.004669 lr 0.00102515 rank 0
2022-08-23 16:48:37,685 DEBUG TRAIN Batch 66/5300 loss 27.125017 loss_att 13.821632 loss_ctc 58.166245 loss_ctc_origin 45.349564 loss_ctc0 88.071831 lr 0.00102502 rank 0
2022-08-23 16:49:05,458 DEBUG TRAIN Batch 66/5400 loss 28.526787 loss_att 14.755883 loss_ctc 60.658890 loss_ctc_origin 46.721985 loss_ctc0 93.178329 lr 0.00102488 rank 0
2022-08-23 16:49:34,363 DEBUG TRAIN Batch 66/5500 loss 31.257488 loss_att 23.689283 loss_ctc 48.916634 loss_ctc_origin 38.255672 loss_ctc0 73.792198 lr 0.00102475 rank 0
2022-08-23 16:49:55,330 WARNING NaN or Inf found in input tensor.
2022-08-23 16:50:02,279 DEBUG TRAIN Batch 66/5600 loss 31.250462 loss_att 19.747395 loss_ctc 58.090950 loss_ctc_origin 35.206993 loss_ctc0 111.486847 lr 0.00102461 rank 0
2022-08-23 16:50:24,999 DEBUG CV Batch 66/0 loss 17.773428 loss_att 11.945763 loss_ctc 31.371311 loss_ctc_origin 18.122643 loss_ctc0 62.284866 history loss 16.727932 rank 0
2022-08-23 16:50:35,660 DEBUG CV Batch 66/100 loss 27.196663 loss_att 19.173796 loss_ctc 45.916687 loss_ctc_origin 26.662546 loss_ctc0 90.843018 history loss 31.795242 rank 0
2022-08-23 16:50:45,662 DEBUG CV Batch 66/200 loss 33.019142 loss_att 23.813438 loss_ctc 54.499123 loss_ctc_origin 37.068367 loss_ctc0 95.170883 history loss 33.094590 rank 0
2022-08-23 16:50:56,010 DEBUG CV Batch 66/300 loss 27.455845 loss_att 20.738785 loss_ctc 43.128986 loss_ctc_origin 28.739872 loss_ctc0 76.703583 history loss 32.158996 rank 0
2022-08-23 16:51:06,732 DEBUG CV Batch 66/400 loss 42.756470 loss_att 34.498245 loss_ctc 62.025658 loss_ctc_origin 45.918541 loss_ctc0 99.608925 history loss 30.338332 rank 0
2022-08-23 16:51:17,830 DEBUG CV Batch 66/500 loss 23.588243 loss_att 16.593481 loss_ctc 39.909355 loss_ctc_origin 25.678333 loss_ctc0 73.115082 history loss 29.900724 rank 0
2022-08-23 16:51:28,758 DEBUG CV Batch 66/600 loss 24.246265 loss_att 14.698091 loss_ctc 46.525337 loss_ctc_origin 25.724028 loss_ctc0 95.061722 history loss 29.744641 rank 0
2022-08-23 16:51:39,040 DEBUG CV Batch 66/700 loss 21.205954 loss_att 14.246098 loss_ctc 37.445618 loss_ctc_origin 24.699501 loss_ctc0 67.186554 history loss 29.369655 rank 0
2022-08-23 16:51:49,490 DEBUG CV Batch 66/800 loss 24.772747 loss_att 18.870041 loss_ctc 38.545731 loss_ctc_origin 23.781527 loss_ctc0 72.995544 history loss 29.291274 rank 0
2022-08-23 16:51:59,960 INFO Epoch 66 CV info cv_loss 29.32042316642586
2022-08-23 16:51:59,960 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/66.pt
2022-08-23 16:52:00,408 INFO Epoch 67 TRAIN info lr 0.0010245019761714515
2022-08-23 16:52:00,412 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 16:52:27,879 DEBUG TRAIN Batch 67/0 loss 26.176018 loss_att 18.507030 loss_ctc 44.070324 loss_ctc_origin 32.043003 loss_ctc0 72.134071 lr 0.00102450 rank 0
2022-08-23 16:52:43,146 WARNING NaN or Inf found in input tensor.
2022-08-23 16:52:57,178 DEBUG TRAIN Batch 67/100 loss 37.291103 loss_att 22.569172 loss_ctc 71.642273 loss_ctc_origin 44.403908 loss_ctc0 135.198456 lr 0.00102436 rank 0
2022-08-23 16:53:25,809 DEBUG TRAIN Batch 67/200 loss 24.070829 loss_att 13.838535 loss_ctc 47.946182 loss_ctc_origin 38.172531 loss_ctc0 70.751373 lr 0.00102423 rank 0
2022-08-23 16:53:53,987 DEBUG TRAIN Batch 67/300 loss 26.229626 loss_att 13.573229 loss_ctc 55.761219 loss_ctc_origin 44.228764 loss_ctc0 82.670280 lr 0.00102409 rank 0
2022-08-23 16:54:22,294 DEBUG TRAIN Batch 67/400 loss 29.197895 loss_att 14.041340 loss_ctc 64.563187 loss_ctc_origin 49.587765 loss_ctc0 99.505844 lr 0.00102396 rank 0
2022-08-23 16:54:51,984 DEBUG TRAIN Batch 67/500 loss 33.886391 loss_att 25.346697 loss_ctc 53.812344 loss_ctc_origin 39.681404 loss_ctc0 86.784531 lr 0.00102383 rank 0
2022-08-23 16:54:59,924 WARNING NaN or Inf found in input tensor.
2022-08-23 16:55:20,180 DEBUG TRAIN Batch 67/600 loss 37.963585 loss_att 24.356020 loss_ctc 69.714577 loss_ctc_origin 46.345612 loss_ctc0 124.242149 lr 0.00102369 rank 0
2022-08-23 16:55:48,353 DEBUG TRAIN Batch 67/700 loss 26.243217 loss_att 15.430154 loss_ctc 51.473694 loss_ctc_origin 40.650002 loss_ctc0 76.728973 lr 0.00102356 rank 0
2022-08-23 16:56:17,526 DEBUG TRAIN Batch 67/800 loss 24.641171 loss_att 11.708586 loss_ctc 54.817200 loss_ctc_origin 41.159695 loss_ctc0 86.684700 lr 0.00102342 rank 0
2022-08-23 16:56:41,944 WARNING NaN or Inf found in input tensor.
2022-08-23 16:56:46,397 DEBUG TRAIN Batch 67/900 loss 32.448059 loss_att 17.107504 loss_ctc 68.242691 loss_ctc_origin 55.308495 loss_ctc0 98.422470 lr 0.00102329 rank 0
2022-08-23 16:57:15,151 DEBUG TRAIN Batch 67/1000 loss 30.684299 loss_att 24.379650 loss_ctc 45.395149 loss_ctc_origin 36.400993 loss_ctc0 66.381500 lr 0.00102316 rank 0
2022-08-23 16:57:44,095 DEBUG TRAIN Batch 67/1100 loss 28.160511 loss_att 17.318142 loss_ctc 53.459366 loss_ctc_origin 33.996014 loss_ctc0 98.873856 lr 0.00102302 rank 0
2022-08-23 16:58:12,383 DEBUG TRAIN Batch 67/1200 loss 22.935638 loss_att 13.086596 loss_ctc 45.916740 loss_ctc_origin 36.197483 loss_ctc0 68.595001 lr 0.00102289 rank 0
2022-08-23 16:58:41,333 DEBUG TRAIN Batch 67/1300 loss 24.380867 loss_att 11.372814 loss_ctc 54.732986 loss_ctc_origin 42.982567 loss_ctc0 82.150620 lr 0.00102275 rank 0
2022-08-23 16:59:10,752 DEBUG TRAIN Batch 67/1400 loss 26.160988 loss_att 12.462803 loss_ctc 58.123421 loss_ctc_origin 44.198380 loss_ctc0 90.615173 lr 0.00102262 rank 0
2022-08-23 16:59:45,272 DEBUG TRAIN Batch 67/1500 loss 29.402458 loss_att 24.567593 loss_ctc 40.683811 loss_ctc_origin 35.981728 loss_ctc0 51.655342 lr 0.00102249 rank 0
2022-08-23 17:00:00,849 WARNING NaN or Inf found in input tensor.
2022-08-23 17:00:14,452 DEBUG TRAIN Batch 67/1600 loss 29.567944 loss_att 18.395782 loss_ctc 55.636322 loss_ctc_origin 37.746826 loss_ctc0 97.378479 lr 0.00102235 rank 0
2022-08-23 17:00:42,551 DEBUG TRAIN Batch 67/1700 loss 26.817152 loss_att 16.432096 loss_ctc 51.048946 loss_ctc_origin 40.655518 loss_ctc0 75.300278 lr 0.00102222 rank 0
2022-08-23 17:00:48,216 WARNING NaN or Inf found in input tensor.
2022-08-23 17:01:10,788 DEBUG TRAIN Batch 67/1800 loss 25.375280 loss_att 13.058483 loss_ctc 54.114475 loss_ctc_origin 41.526695 loss_ctc0 83.485962 lr 0.00102209 rank 0
2022-08-23 17:01:38,694 DEBUG TRAIN Batch 67/1900 loss 24.706652 loss_att 12.563545 loss_ctc 53.040565 loss_ctc_origin 38.014435 loss_ctc0 88.101532 lr 0.00102195 rank 0
2022-08-23 17:02:06,598 DEBUG TRAIN Batch 67/2000 loss 31.019485 loss_att 25.670898 loss_ctc 43.499523 loss_ctc_origin 39.512516 loss_ctc0 52.802544 lr 0.00102182 rank 0
2022-08-23 17:02:34,796 DEBUG TRAIN Batch 67/2100 loss 32.070305 loss_att 21.876524 loss_ctc 55.855797 loss_ctc_origin 41.679169 loss_ctc0 88.934593 lr 0.00102169 rank 0
2022-08-23 17:03:02,658 DEBUG TRAIN Batch 67/2200 loss 26.162582 loss_att 16.086180 loss_ctc 49.674187 loss_ctc_origin 40.535019 loss_ctc0 70.998901 lr 0.00102155 rank 0
2022-08-23 17:03:32,509 DEBUG TRAIN Batch 67/2300 loss 26.947695 loss_att 13.435317 loss_ctc 58.476570 loss_ctc_origin 47.050396 loss_ctc0 85.137634 lr 0.00102142 rank 0
2022-08-23 17:04:01,168 DEBUG TRAIN Batch 67/2400 loss 29.203598 loss_att 13.961869 loss_ctc 64.767624 loss_ctc_origin 51.343349 loss_ctc0 96.090927 lr 0.00102129 rank 0
2022-08-23 17:04:29,734 DEBUG TRAIN Batch 67/2500 loss 23.481113 loss_att 18.943802 loss_ctc 34.068176 loss_ctc_origin 27.744446 loss_ctc0 48.823544 lr 0.00102115 rank 0
2022-08-23 17:04:57,745 WARNING NaN or Inf found in input tensor.
2022-08-23 17:04:58,543 DEBUG TRAIN Batch 67/2600 loss 41.434174 loss_att 27.636974 loss_ctc 73.627640 loss_ctc_origin 51.210514 loss_ctc0 125.934250 lr 0.00102102 rank 0
2022-08-23 17:05:26,657 DEBUG TRAIN Batch 67/2700 loss 22.471346 loss_att 12.956622 loss_ctc 44.672367 loss_ctc_origin 35.510921 loss_ctc0 66.049072 lr 0.00102089 rank 0
2022-08-23 17:05:39,014 WARNING NaN or Inf found in input tensor.
2022-08-23 17:05:55,809 DEBUG TRAIN Batch 67/2800 loss 29.732780 loss_att 15.606342 loss_ctc 62.694473 loss_ctc_origin 51.346310 loss_ctc0 89.173508 lr 0.00102075 rank 0
2022-08-23 17:06:25,064 DEBUG TRAIN Batch 67/2900 loss 26.885895 loss_att 13.421078 loss_ctc 58.303799 loss_ctc_origin 43.700733 loss_ctc0 92.377617 lr 0.00102062 rank 0
2022-08-23 17:06:59,338 DEBUG TRAIN Batch 67/3000 loss 33.455093 loss_att 27.943953 loss_ctc 46.314419 loss_ctc_origin 36.647770 loss_ctc0 68.869934 lr 0.00102049 rank 0
2022-08-23 17:07:06,910 WARNING NaN or Inf found in input tensor.
2022-08-23 17:07:27,823 DEBUG TRAIN Batch 67/3100 loss 25.830273 loss_att 15.209452 loss_ctc 50.612183 loss_ctc_origin 31.772827 loss_ctc0 94.570671 lr 0.00102036 rank 0
2022-08-23 17:07:55,570 DEBUG TRAIN Batch 67/3200 loss 26.260344 loss_att 15.454546 loss_ctc 51.473869 loss_ctc_origin 42.785988 loss_ctc0 71.745583 lr 0.00102022 rank 0
2022-08-23 17:08:22,849 DEBUG TRAIN Batch 67/3300 loss 25.632990 loss_att 11.678728 loss_ctc 58.192932 loss_ctc_origin 45.358566 loss_ctc0 88.139793 lr 0.00102009 rank 0
2022-08-23 17:08:49,275 DEBUG TRAIN Batch 67/3400 loss 31.491432 loss_att 17.098526 loss_ctc 65.074875 loss_ctc_origin 49.968842 loss_ctc0 100.322281 lr 0.00101996 rank 0
2022-08-23 17:09:16,941 DEBUG TRAIN Batch 67/3500 loss 36.906288 loss_att 27.367363 loss_ctc 59.163769 loss_ctc_origin 47.325432 loss_ctc0 86.786560 lr 0.00101982 rank 0
2022-08-23 17:09:43,843 DEBUG TRAIN Batch 67/3600 loss 34.935715 loss_att 21.637012 loss_ctc 65.966026 loss_ctc_origin 41.505104 loss_ctc0 123.041519 lr 0.00101969 rank 0
2022-08-23 17:10:11,507 DEBUG TRAIN Batch 67/3700 loss 24.421366 loss_att 14.403971 loss_ctc 47.795288 loss_ctc_origin 37.883774 loss_ctc0 70.922165 lr 0.00101956 rank 0
2022-08-23 17:10:37,358 DEBUG TRAIN Batch 67/3800 loss 28.555063 loss_att 14.800222 loss_ctc 60.649689 loss_ctc_origin 49.300041 loss_ctc0 87.132202 lr 0.00101943 rank 0
2022-08-23 17:11:04,913 DEBUG TRAIN Batch 67/3900 loss 29.126347 loss_att 14.284708 loss_ctc 63.756832 loss_ctc_origin 47.666565 loss_ctc0 101.300781 lr 0.00101929 rank 0
2022-08-23 17:11:07,644 WARNING NaN or Inf found in input tensor.
2022-08-23 17:11:32,133 DEBUG TRAIN Batch 67/4000 loss 29.724789 loss_att 23.800713 loss_ctc 43.547630 loss_ctc_origin 37.260803 loss_ctc0 58.216892 lr 0.00101916 rank 0
2022-08-23 17:11:59,337 DEBUG TRAIN Batch 67/4100 loss 44.682175 loss_att 28.338741 loss_ctc 82.816849 loss_ctc_origin 55.534355 loss_ctc0 146.476013 lr 0.00101903 rank 0
2022-08-23 17:12:27,550 DEBUG TRAIN Batch 67/4200 loss 24.750214 loss_att 15.788715 loss_ctc 45.660378 loss_ctc_origin 35.703331 loss_ctc0 68.893494 lr 0.00101890 rank 0
2022-08-23 17:12:55,089 DEBUG TRAIN Batch 67/4300 loss 23.465462 loss_att 11.543803 loss_ctc 51.282669 loss_ctc_origin 38.354980 loss_ctc0 81.447266 lr 0.00101877 rank 0
2022-08-23 17:13:22,144 DEBUG TRAIN Batch 67/4400 loss 29.557987 loss_att 15.983793 loss_ctc 61.231102 loss_ctc_origin 47.017654 loss_ctc0 94.395813 lr 0.00101863 rank 0
2022-08-23 17:13:54,339 DEBUG TRAIN Batch 67/4500 loss 33.890846 loss_att 25.306057 loss_ctc 53.922016 loss_ctc_origin 46.471645 loss_ctc0 71.306213 lr 0.00101850 rank 0
2022-08-23 17:13:55,139 WARNING NaN or Inf found in input tensor.
2022-08-23 17:14:21,477 DEBUG TRAIN Batch 67/4600 loss 44.051956 loss_att 30.633623 loss_ctc 75.361404 loss_ctc_origin 53.824432 loss_ctc0 125.614342 lr 0.00101837 rank 0
2022-08-23 17:14:48,817 DEBUG TRAIN Batch 67/4700 loss 21.623295 loss_att 12.135847 loss_ctc 43.760674 loss_ctc_origin 33.871834 loss_ctc0 66.834633 lr 0.00101824 rank 0
2022-08-23 17:15:15,742 DEBUG TRAIN Batch 67/4800 loss 24.022417 loss_att 12.728863 loss_ctc 50.374043 loss_ctc_origin 38.173626 loss_ctc0 78.841675 lr 0.00101811 rank 0
2022-08-23 17:15:43,448 DEBUG TRAIN Batch 67/4900 loss 34.793186 loss_att 19.695023 loss_ctc 70.022232 loss_ctc_origin 55.757919 loss_ctc0 103.305611 lr 0.00101797 rank 0
2022-08-23 17:16:10,812 DEBUG TRAIN Batch 67/5000 loss 35.356556 loss_att 27.164879 loss_ctc 54.470467 loss_ctc_origin 41.176453 loss_ctc0 85.489838 lr 0.00101784 rank 0
2022-08-23 17:16:36,484 DEBUG TRAIN Batch 67/5100 loss 37.420418 loss_att 24.285076 loss_ctc 68.069542 loss_ctc_origin 44.766571 loss_ctc0 122.443130 lr 0.00101771 rank 0
2022-08-23 17:17:03,722 DEBUG TRAIN Batch 67/5200 loss 22.343384 loss_att 13.148763 loss_ctc 43.797501 loss_ctc_origin 31.632885 loss_ctc0 72.181610 lr 0.00101758 rank 0
2022-08-23 17:17:31,301 DEBUG TRAIN Batch 67/5300 loss 25.562071 loss_att 13.285255 loss_ctc 54.207970 loss_ctc_origin 42.012497 loss_ctc0 82.664070 lr 0.00101745 rank 0
2022-08-23 17:17:59,655 DEBUG TRAIN Batch 67/5400 loss 30.379066 loss_att 15.049406 loss_ctc 66.148270 loss_ctc_origin 50.609116 loss_ctc0 102.406296 lr 0.00101731 rank 0
2022-08-23 17:18:27,542 DEBUG TRAIN Batch 67/5500 loss 31.158287 loss_att 23.718327 loss_ctc 48.518188 loss_ctc_origin 41.047188 loss_ctc0 65.950516 lr 0.00101718 rank 0
2022-08-23 17:18:48,055 WARNING NaN or Inf found in input tensor.
2022-08-23 17:18:55,414 DEBUG TRAIN Batch 67/5600 loss 33.169479 loss_att 22.316914 loss_ctc 58.492134 loss_ctc_origin 39.637920 loss_ctc0 102.485298 lr 0.00101705 rank 0
2022-08-23 17:19:19,033 DEBUG CV Batch 67/0 loss 17.163921 loss_att 11.611485 loss_ctc 30.119602 loss_ctc_origin 20.118952 loss_ctc0 53.454453 history loss 16.154279 rank 0
2022-08-23 17:19:29,681 DEBUG CV Batch 67/100 loss 27.738605 loss_att 20.667034 loss_ctc 44.238934 loss_ctc_origin 28.244308 loss_ctc0 81.559723 history loss 31.982956 rank 0
2022-08-23 17:19:39,141 DEBUG CV Batch 67/200 loss 34.293270 loss_att 25.282387 loss_ctc 55.318665 loss_ctc_origin 40.089668 loss_ctc0 90.852997 history loss 33.197714 rank 0
2022-08-23 17:19:49,114 DEBUG CV Batch 67/300 loss 26.698750 loss_att 20.069370 loss_ctc 42.167297 loss_ctc_origin 27.754025 loss_ctc0 75.798264 history loss 32.149453 rank 0
2022-08-23 17:19:59,879 DEBUG CV Batch 67/400 loss 41.818119 loss_att 34.016296 loss_ctc 60.022369 loss_ctc_origin 43.370964 loss_ctc0 98.875641 history loss 30.341483 rank 0
2022-08-23 17:20:10,370 DEBUG CV Batch 67/500 loss 21.959534 loss_att 15.795713 loss_ctc 36.341782 loss_ctc_origin 24.376394 loss_ctc0 64.261017 history loss 29.901118 rank 0
2022-08-23 17:20:21,238 DEBUG CV Batch 67/600 loss 23.176426 loss_att 14.543689 loss_ctc 43.319481 loss_ctc_origin 25.910454 loss_ctc0 83.940544 history loss 29.742720 rank 0
2022-08-23 17:20:31,184 DEBUG CV Batch 67/700 loss 21.849043 loss_att 15.260544 loss_ctc 37.222206 loss_ctc_origin 24.799072 loss_ctc0 66.209518 history loss 29.369475 rank 0
2022-08-23 17:20:41,624 DEBUG CV Batch 67/800 loss 24.964380 loss_att 18.751995 loss_ctc 39.459946 loss_ctc_origin 24.831411 loss_ctc0 73.593185 history loss 29.287718 rank 0
2022-08-23 17:20:51,854 INFO Epoch 67 CV info cv_loss 29.34246787404518
2022-08-23 17:20:51,855 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/67.pt
2022-08-23 17:20:52,350 INFO Epoch 68 TRAIN info lr 0.0010169409726421385
2022-08-23 17:20:52,354 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 17:21:19,378 DEBUG TRAIN Batch 68/0 loss 29.776138 loss_att 23.387804 loss_ctc 44.682251 loss_ctc_origin 34.421532 loss_ctc0 68.623924 lr 0.00101694 rank 0
2022-08-23 17:21:47,656 DEBUG TRAIN Batch 68/100 loss 30.516430 loss_att 19.635426 loss_ctc 55.905441 loss_ctc_origin 32.478416 loss_ctc0 110.568504 lr 0.00101680 rank 0
2022-08-23 17:22:16,275 DEBUG TRAIN Batch 68/200 loss 20.549477 loss_att 12.433463 loss_ctc 39.486835 loss_ctc_origin 31.115499 loss_ctc0 59.019951 lr 0.00101667 rank 0
2022-08-23 17:22:45,107 DEBUG TRAIN Batch 68/300 loss 22.484529 loss_att 11.425798 loss_ctc 48.288231 loss_ctc_origin 33.885948 loss_ctc0 81.893547 lr 0.00101654 rank 0
2022-08-23 17:23:09,891 WARNING NaN or Inf found in input tensor.
2022-08-23 17:23:14,522 DEBUG TRAIN Batch 68/400 loss 33.011551 loss_att 16.841866 loss_ctc 70.740814 loss_ctc_origin 56.267609 loss_ctc0 104.511627 lr 0.00101641 rank 0
2022-08-23 17:23:43,118 DEBUG TRAIN Batch 68/500 loss 36.674980 loss_att 28.972816 loss_ctc 54.646694 loss_ctc_origin 44.541016 loss_ctc0 78.226608 lr 0.00101628 rank 0
2022-08-23 17:24:12,285 DEBUG TRAIN Batch 68/600 loss 33.211601 loss_att 22.218279 loss_ctc 58.862690 loss_ctc_origin 39.178513 loss_ctc0 104.792435 lr 0.00101615 rank 0
2022-08-23 17:24:40,137 DEBUG TRAIN Batch 68/700 loss 22.768295 loss_att 12.399608 loss_ctc 46.961899 loss_ctc_origin 36.088718 loss_ctc0 72.332649 lr 0.00101602 rank 0
2022-08-23 17:25:08,622 DEBUG TRAIN Batch 68/800 loss 26.485935 loss_att 12.300459 loss_ctc 59.585381 loss_ctc_origin 46.878635 loss_ctc0 89.234451 lr 0.00101589 rank 0
2022-08-23 17:25:37,099 DEBUG TRAIN Batch 68/900 loss 30.275013 loss_att 15.027167 loss_ctc 65.853317 loss_ctc_origin 47.956863 loss_ctc0 107.611694 lr 0.00101575 rank 0
2022-08-23 17:26:06,372 DEBUG TRAIN Batch 68/1000 loss 28.639881 loss_att 21.077740 loss_ctc 46.284874 loss_ctc_origin 38.573189 loss_ctc0 64.278809 lr 0.00101562 rank 0
2022-08-23 17:26:33,711 DEBUG TRAIN Batch 68/1100 loss 32.955036 loss_att 22.759163 loss_ctc 56.745407 loss_ctc_origin 36.321400 loss_ctc0 104.401413 lr 0.00101549 rank 0
2022-08-23 17:27:03,795 DEBUG TRAIN Batch 68/1200 loss 21.221916 loss_att 11.844237 loss_ctc 43.103161 loss_ctc_origin 32.807983 loss_ctc0 67.125244 lr 0.00101536 rank 0
2022-08-23 17:27:32,223 DEBUG TRAIN Batch 68/1300 loss 30.776649 loss_att 16.151899 loss_ctc 64.901062 loss_ctc_origin 53.920731 loss_ctc0 90.521820 lr 0.00101523 rank 0
2022-08-23 17:28:01,962 DEBUG TRAIN Batch 68/1400 loss 25.706244 loss_att 11.769461 loss_ctc 58.225403 loss_ctc_origin 42.668861 loss_ctc0 94.524002 lr 0.00101510 rank 0
2022-08-23 17:28:36,338 DEBUG TRAIN Batch 68/1500 loss 24.108040 loss_att 19.412395 loss_ctc 35.064541 loss_ctc_origin 28.970257 loss_ctc0 49.284538 lr 0.00101497 rank 0
2022-08-23 17:29:05,066 DEBUG TRAIN Batch 68/1600 loss 32.800022 loss_att 19.933130 loss_ctc 62.822769 loss_ctc_origin 42.042282 loss_ctc0 111.310562 lr 0.00101484 rank 0
2022-08-23 17:29:33,937 DEBUG TRAIN Batch 68/1700 loss 20.978914 loss_att 12.131414 loss_ctc 41.623077 loss_ctc_origin 31.805996 loss_ctc0 64.529602 lr 0.00101471 rank 0
2022-08-23 17:30:02,748 DEBUG TRAIN Batch 68/1800 loss 21.343941 loss_att 10.399989 loss_ctc 46.879829 loss_ctc_origin 33.245319 loss_ctc0 78.693687 lr 0.00101458 rank 0
2022-08-23 17:30:32,104 DEBUG TRAIN Batch 68/1900 loss 30.155565 loss_att 15.976501 loss_ctc 63.240051 loss_ctc_origin 47.532230 loss_ctc0 99.891624 lr 0.00101445 rank 0
2022-08-23 17:31:01,248 DEBUG TRAIN Batch 68/2000 loss 20.226606 loss_att 14.325011 loss_ctc 33.996994 loss_ctc_origin 28.735733 loss_ctc0 46.273262 lr 0.00101432 rank 0
2022-08-23 17:31:21,751 WARNING NaN or Inf found in input tensor.
2022-08-23 17:31:28,604 DEBUG TRAIN Batch 68/2100 loss 40.467941 loss_att 27.467743 loss_ctc 70.801735 loss_ctc_origin 46.074459 loss_ctc0 128.498703 lr 0.00101419 rank 0
2022-08-23 17:31:46,986 WARNING NaN or Inf found in input tensor.
2022-08-23 17:31:55,719 DEBUG TRAIN Batch 68/2200 loss 22.499090 loss_att 12.239807 loss_ctc 46.437416 loss_ctc_origin 36.889519 loss_ctc0 68.715836 lr 0.00101406 rank 0
2022-08-23 17:32:23,527 DEBUG TRAIN Batch 68/2300 loss 23.506233 loss_att 11.489370 loss_ctc 51.545578 loss_ctc_origin 39.059464 loss_ctc0 80.679840 lr 0.00101393 rank 0
2022-08-23 17:32:52,354 DEBUG TRAIN Batch 68/2400 loss 31.328615 loss_att 16.691328 loss_ctc 65.482285 loss_ctc_origin 49.715492 loss_ctc0 102.271477 lr 0.00101380 rank 0
2022-08-23 17:33:20,212 DEBUG TRAIN Batch 68/2500 loss 34.481945 loss_att 26.648514 loss_ctc 52.759953 loss_ctc_origin 45.393326 loss_ctc0 69.948746 lr 0.00101367 rank 0
2022-08-23 17:33:49,148 DEBUG TRAIN Batch 68/2600 loss 31.156357 loss_att 21.498766 loss_ctc 53.690735 loss_ctc_origin 37.624283 loss_ctc0 91.179115 lr 0.00101353 rank 0
2022-08-23 17:34:17,860 DEBUG TRAIN Batch 68/2700 loss 21.624344 loss_att 12.484043 loss_ctc 42.951714 loss_ctc_origin 33.020935 loss_ctc0 66.123535 lr 0.00101340 rank 0
2022-08-23 17:34:47,125 DEBUG TRAIN Batch 68/2800 loss 26.627071 loss_att 13.472336 loss_ctc 57.321457 loss_ctc_origin 44.387405 loss_ctc0 87.500900 lr 0.00101327 rank 0
2022-08-23 17:35:16,192 DEBUG TRAIN Batch 68/2900 loss 33.434151 loss_att 16.552277 loss_ctc 72.825195 loss_ctc_origin 59.566433 loss_ctc0 103.762299 lr 0.00101314 rank 0
2022-08-23 17:35:51,211 DEBUG TRAIN Batch 68/3000 loss 27.653231 loss_att 20.445141 loss_ctc 44.472103 loss_ctc_origin 39.060005 loss_ctc0 57.100330 lr 0.00101301 rank 0
2022-08-23 17:36:19,970 DEBUG TRAIN Batch 68/3100 loss 28.459076 loss_att 19.512999 loss_ctc 49.333260 loss_ctc_origin 36.133728 loss_ctc0 80.132164 lr 0.00101288 rank 0
2022-08-23 17:36:49,309 DEBUG TRAIN Batch 68/3200 loss 31.257042 loss_att 19.104637 loss_ctc 59.612648 loss_ctc_origin 50.297577 loss_ctc0 81.347809 lr 0.00101275 rank 0
2022-08-23 17:37:17,216 DEBUG TRAIN Batch 68/3300 loss 24.931479 loss_att 13.457129 loss_ctc 51.704960 loss_ctc_origin 40.844177 loss_ctc0 77.046783 lr 0.00101263 rank 0
2022-08-23 17:37:45,531 DEBUG TRAIN Batch 68/3400 loss 31.943102 loss_att 16.559999 loss_ctc 67.837006 loss_ctc_origin 52.710464 loss_ctc0 103.132278 lr 0.00101250 rank 0
2022-08-23 17:38:15,052 DEBUG TRAIN Batch 68/3500 loss 28.742840 loss_att 23.962179 loss_ctc 39.897713 loss_ctc_origin 36.523487 loss_ctc0 47.770912 lr 0.00101237 rank 0
2022-08-23 17:38:43,737 DEBUG TRAIN Batch 68/3600 loss 32.134987 loss_att 21.884422 loss_ctc 56.052963 loss_ctc_origin 42.576698 loss_ctc0 87.497581 lr 0.00101224 rank 0
2022-08-23 17:39:12,280 DEBUG TRAIN Batch 68/3700 loss 30.647224 loss_att 21.000664 loss_ctc 53.155861 loss_ctc_origin 45.462624 loss_ctc0 71.106750 lr 0.00101211 rank 0
2022-08-23 17:39:40,517 DEBUG TRAIN Batch 68/3800 loss 28.098526 loss_att 14.850101 loss_ctc 59.011517 loss_ctc_origin 46.362335 loss_ctc0 88.526276 lr 0.00101198 rank 0
2022-08-23 17:40:10,364 DEBUG TRAIN Batch 68/3900 loss 31.498722 loss_att 16.831005 loss_ctc 65.723389 loss_ctc_origin 51.763649 loss_ctc0 98.296120 lr 0.00101185 rank 0
2022-08-23 17:40:40,060 DEBUG TRAIN Batch 68/4000 loss 28.117863 loss_att 21.446581 loss_ctc 43.684181 loss_ctc_origin 36.966599 loss_ctc0 59.358528 lr 0.00101172 rank 0
2022-08-23 17:41:09,312 DEBUG TRAIN Batch 68/4100 loss 30.956577 loss_att 21.585482 loss_ctc 52.822468 loss_ctc_origin 41.872177 loss_ctc0 78.373146 lr 0.00101159 rank 0
2022-08-23 17:41:37,941 DEBUG TRAIN Batch 68/4200 loss 22.477638 loss_att 12.580740 loss_ctc 45.570404 loss_ctc_origin 34.709442 loss_ctc0 70.912643 lr 0.00101146 rank 0
2022-08-23 17:42:06,726 DEBUG TRAIN Batch 68/4300 loss 27.484110 loss_att 14.210300 loss_ctc 58.456329 loss_ctc_origin 45.552841 loss_ctc0 88.564468 lr 0.00101133 rank 0
2022-08-23 17:42:35,181 DEBUG TRAIN Batch 68/4400 loss 26.717691 loss_att 13.978354 loss_ctc 56.442814 loss_ctc_origin 41.274639 loss_ctc0 91.835220 lr 0.00101120 rank 0
2022-08-23 17:43:09,913 DEBUG TRAIN Batch 68/4500 loss 40.389381 loss_att 28.823456 loss_ctc 67.376549 loss_ctc_origin 48.030365 loss_ctc0 112.517639 lr 0.00101107 rank 0
2022-08-23 17:43:38,553 DEBUG TRAIN Batch 68/4600 loss 31.821362 loss_att 19.350166 loss_ctc 60.920815 loss_ctc_origin 39.942101 loss_ctc0 109.871147 lr 0.00101094 rank 0
2022-08-23 17:44:07,990 DEBUG TRAIN Batch 68/4700 loss 27.814365 loss_att 18.337482 loss_ctc 49.927090 loss_ctc_origin 40.041229 loss_ctc0 72.994095 lr 0.00101081 rank 0
2022-08-23 17:44:13,189 WARNING NaN or Inf found in input tensor.
2022-08-23 17:44:36,573 DEBUG TRAIN Batch 68/4800 loss 23.258291 loss_att 11.658648 loss_ctc 50.324123 loss_ctc_origin 37.098030 loss_ctc0 81.185005 lr 0.00101068 rank 0
2022-08-23 17:45:05,027 DEBUG TRAIN Batch 68/4900 loss 29.483250 loss_att 14.360716 loss_ctc 64.769165 loss_ctc_origin 48.812187 loss_ctc0 102.002106 lr 0.00101055 rank 0
2022-08-23 17:45:33,737 DEBUG TRAIN Batch 68/5000 loss 34.174095 loss_att 28.278349 loss_ctc 47.930843 loss_ctc_origin 44.606743 loss_ctc0 55.687073 lr 0.00101043 rank 0
2022-08-23 17:45:54,387 WARNING NaN or Inf found in input tensor.
2022-08-23 17:46:01,172 DEBUG TRAIN Batch 68/5100 loss 31.442642 loss_att 20.528667 loss_ctc 56.908585 loss_ctc_origin 44.008450 loss_ctc0 87.008896 lr 0.00101030 rank 0
2022-08-23 17:46:29,947 DEBUG TRAIN Batch 68/5200 loss 23.585100 loss_att 13.956810 loss_ctc 46.051109 loss_ctc_origin 36.088394 loss_ctc0 69.297440 lr 0.00101017 rank 0
2022-08-23 17:46:58,989 DEBUG TRAIN Batch 68/5300 loss 22.361433 loss_att 11.115646 loss_ctc 48.601601 loss_ctc_origin 35.072357 loss_ctc0 80.169830 lr 0.00101004 rank 0
2022-08-23 17:47:27,744 DEBUG TRAIN Batch 68/5400 loss 33.601181 loss_att 18.662128 loss_ctc 68.458961 loss_ctc_origin 54.388306 loss_ctc0 101.290497 lr 0.00100991 rank 0
2022-08-23 17:47:55,651 DEBUG TRAIN Batch 68/5500 loss 39.282524 loss_att 31.478584 loss_ctc 57.491722 loss_ctc_origin 48.430511 loss_ctc0 78.634560 lr 0.00100978 rank 0
2022-08-23 17:48:24,502 DEBUG TRAIN Batch 68/5600 loss 37.225670 loss_att 26.621162 loss_ctc 61.969513 loss_ctc_origin 46.752892 loss_ctc0 97.474953 lr 0.00100965 rank 0
2022-08-23 17:48:47,843 DEBUG CV Batch 68/0 loss 17.674412 loss_att 13.136883 loss_ctc 28.261974 loss_ctc_origin 22.246391 loss_ctc0 42.298332 history loss 16.634740 rank 0
2022-08-23 17:48:58,691 DEBUG CV Batch 68/100 loss 27.661057 loss_att 21.248270 loss_ctc 42.624222 loss_ctc_origin 33.408073 loss_ctc0 64.128571 history loss 31.088899 rank 0
2022-08-23 17:49:08,743 DEBUG CV Batch 68/200 loss 31.989357 loss_att 24.679558 loss_ctc 49.045559 loss_ctc_origin 39.194263 loss_ctc0 72.031914 history loss 32.529486 rank 0
2022-08-23 17:49:18,816 DEBUG CV Batch 68/300 loss 26.624039 loss_att 19.787813 loss_ctc 42.575226 loss_ctc_origin 27.909744 loss_ctc0 76.794678 history loss 31.579581 rank 0
2022-08-23 17:49:29,376 DEBUG CV Batch 68/400 loss 40.220219 loss_att 31.449146 loss_ctc 60.686050 loss_ctc_origin 43.665169 loss_ctc0 100.401443 history loss 29.777154 rank 0
2022-08-23 17:49:39,858 DEBUG CV Batch 68/500 loss 20.552555 loss_att 15.792532 loss_ctc 31.659279 loss_ctc_origin 24.779690 loss_ctc0 47.711647 history loss 29.355153 rank 0
2022-08-23 17:49:50,228 DEBUG CV Batch 68/600 loss 23.772461 loss_att 16.607464 loss_ctc 40.490784 loss_ctc_origin 30.975006 loss_ctc0 62.694252 history loss 29.194334 rank 0
2022-08-23 17:50:00,325 DEBUG CV Batch 68/700 loss 22.582829 loss_att 15.513567 loss_ctc 39.077766 loss_ctc_origin 26.553116 loss_ctc0 68.301956 history loss 28.830196 rank 0
2022-08-23 17:50:10,401 DEBUG CV Batch 68/800 loss 24.819405 loss_att 18.785084 loss_ctc 38.899483 loss_ctc_origin 24.224407 loss_ctc0 73.141327 history loss 28.762267 rank 0
2022-08-23 17:50:20,685 INFO Epoch 68 CV info cv_loss 28.787358785961963
2022-08-23 17:50:20,686 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/68.pt
2022-08-23 17:50:21,149 INFO Epoch 69 TRAIN info lr 0.001009544940138636
2022-08-23 17:50:21,152 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 17:50:47,734 DEBUG TRAIN Batch 69/0 loss 25.703083 loss_att 19.810421 loss_ctc 39.452625 loss_ctc_origin 33.681152 loss_ctc0 52.919395 lr 0.00100954 rank 0
2022-08-23 17:51:15,392 DEBUG TRAIN Batch 69/100 loss 36.350113 loss_att 25.319832 loss_ctc 62.087425 loss_ctc_origin 44.600468 loss_ctc0 102.890320 lr 0.00100941 rank 0
2022-08-23 17:51:43,601 DEBUG TRAIN Batch 69/200 loss 23.763685 loss_att 12.416351 loss_ctc 50.240799 loss_ctc_origin 40.020760 loss_ctc0 74.087563 lr 0.00100928 rank 0
2022-08-23 17:52:12,266 DEBUG TRAIN Batch 69/300 loss 25.925014 loss_att 13.244825 loss_ctc 55.512119 loss_ctc_origin 44.812115 loss_ctc0 80.478790 lr 0.00100915 rank 0
2022-08-23 17:52:41,938 DEBUG TRAIN Batch 69/400 loss 27.244249 loss_att 13.850651 loss_ctc 58.495975 loss_ctc_origin 42.425018 loss_ctc0 95.994873 lr 0.00100903 rank 0
2022-08-23 17:53:11,278 DEBUG TRAIN Batch 69/500 loss 30.475521 loss_att 22.391640 loss_ctc 49.337914 loss_ctc_origin 41.661140 loss_ctc0 67.250374 lr 0.00100890 rank 0
2022-08-23 17:53:19,311 WARNING NaN or Inf found in input tensor.
2022-08-23 17:53:39,856 DEBUG TRAIN Batch 69/600 loss 43.664730 loss_att 29.502548 loss_ctc 76.709824 loss_ctc_origin 54.495113 loss_ctc0 128.544159 lr 0.00100877 rank 0
2022-08-23 17:54:09,393 DEBUG TRAIN Batch 69/700 loss 25.979515 loss_att 15.227514 loss_ctc 51.067520 loss_ctc_origin 41.921432 loss_ctc0 72.408394 lr 0.00100864 rank 0
2022-08-23 17:54:37,605 DEBUG TRAIN Batch 69/800 loss 26.652885 loss_att 12.601233 loss_ctc 59.440071 loss_ctc_origin 45.957481 loss_ctc0 90.899452 lr 0.00100851 rank 0
2022-08-23 17:55:05,349 DEBUG TRAIN Batch 69/900 loss 26.370077 loss_att 12.951963 loss_ctc 57.679008 loss_ctc_origin 43.176552 loss_ctc0 91.518082 lr 0.00100838 rank 0
2022-08-23 17:55:35,410 DEBUG TRAIN Batch 69/1000 loss 38.692196 loss_att 29.917820 loss_ctc 59.165733 loss_ctc_origin 46.257484 loss_ctc0 89.284988 lr 0.00100826 rank 0
2022-08-23 17:56:04,203 DEBUG TRAIN Batch 69/1100 loss 35.626583 loss_att 23.311172 loss_ctc 64.362541 loss_ctc_origin 44.742294 loss_ctc0 110.143127 lr 0.00100813 rank 0
2022-08-23 17:56:33,340 DEBUG TRAIN Batch 69/1200 loss 22.802607 loss_att 12.486503 loss_ctc 46.873512 loss_ctc_origin 35.912460 loss_ctc0 72.449303 lr 0.00100800 rank 0
2022-08-23 17:57:01,702 DEBUG TRAIN Batch 69/1300 loss 20.263004 loss_att 9.290837 loss_ctc 45.864723 loss_ctc_origin 31.424747 loss_ctc0 79.558006 lr 0.00100787 rank 0
2022-08-23 17:57:29,498 DEBUG TRAIN Batch 69/1400 loss 27.735561 loss_att 14.009283 loss_ctc 59.763542 loss_ctc_origin 42.924606 loss_ctc0 99.054390 lr 0.00100774 rank 0
2022-08-23 17:57:38,200 WARNING NaN or Inf found in input tensor.
2022-08-23 17:58:03,882 DEBUG TRAIN Batch 69/1500 loss 36.093796 loss_att 26.074993 loss_ctc 59.471001 loss_ctc_origin 48.773785 loss_ctc0 84.431175 lr 0.00100762 rank 0
2022-08-23 17:58:32,835 DEBUG TRAIN Batch 69/1600 loss 41.428802 loss_att 26.193029 loss_ctc 76.978928 loss_ctc_origin 51.440926 loss_ctc0 136.567596 lr 0.00100749 rank 0
2022-08-23 17:59:01,338 DEBUG TRAIN Batch 69/1700 loss 27.397520 loss_att 17.358383 loss_ctc 50.822170 loss_ctc_origin 42.169029 loss_ctc0 71.012833 lr 0.00100736 rank 0
2022-08-23 17:59:30,221 DEBUG TRAIN Batch 69/1800 loss 26.724579 loss_att 14.470358 loss_ctc 55.317757 loss_ctc_origin 43.208885 loss_ctc0 83.571777 lr 0.00100723 rank 0
2022-08-23 17:59:58,507 DEBUG TRAIN Batch 69/1900 loss 29.870632 loss_att 16.294428 loss_ctc 61.548439 loss_ctc_origin 46.219452 loss_ctc0 97.316071 lr 0.00100711 rank 0
2022-08-23 18:00:27,304 DEBUG TRAIN Batch 69/2000 loss 26.317835 loss_att 18.394093 loss_ctc 44.806564 loss_ctc_origin 33.444344 loss_ctc0 71.318405 lr 0.00100698 rank 0
2022-08-23 18:00:56,017 DEBUG TRAIN Batch 69/2100 loss 35.868919 loss_att 23.425463 loss_ctc 64.903648 loss_ctc_origin 43.263237 loss_ctc0 115.397949 lr 0.00100685 rank 0
2022-08-23 18:01:24,784 DEBUG TRAIN Batch 69/2200 loss 20.514906 loss_att 11.522180 loss_ctc 41.497932 loss_ctc_origin 30.758989 loss_ctc0 66.555473 lr 0.00100672 rank 0
2022-08-23 18:01:53,233 DEBUG TRAIN Batch 69/2300 loss 23.009966 loss_att 12.122978 loss_ctc 48.412933 loss_ctc_origin 34.931564 loss_ctc0 79.869461 lr 0.00100659 rank 0
2022-08-23 18:02:23,291 DEBUG TRAIN Batch 69/2400 loss 31.674068 loss_att 16.885586 loss_ctc 66.180527 loss_ctc_origin 50.472168 loss_ctc0 102.833351 lr 0.00100647 rank 0
2022-08-23 18:02:52,692 DEBUG TRAIN Batch 69/2500 loss 31.582035 loss_att 24.811840 loss_ctc 47.379150 loss_ctc_origin 38.767372 loss_ctc0 67.473297 lr 0.00100634 rank 0
2022-08-23 18:03:22,885 DEBUG TRAIN Batch 69/2600 loss 30.776550 loss_att 20.158367 loss_ctc 55.552307 loss_ctc_origin 38.275448 loss_ctc0 95.864975 lr 0.00100621 rank 0
2022-08-23 18:03:50,364 DEBUG TRAIN Batch 69/2700 loss 24.707722 loss_att 15.779997 loss_ctc 45.539082 loss_ctc_origin 35.607109 loss_ctc0 68.713684 lr 0.00100609 rank 0
2022-08-23 18:04:19,540 DEBUG TRAIN Batch 69/2800 loss 24.801319 loss_att 12.968575 loss_ctc 52.411057 loss_ctc_origin 40.378475 loss_ctc0 80.487076 lr 0.00100596 rank 0
2022-08-23 18:04:48,081 DEBUG TRAIN Batch 69/2900 loss 24.915283 loss_att 12.613506 loss_ctc 53.619427 loss_ctc_origin 38.801453 loss_ctc0 88.194695 lr 0.00100583 rank 0
2022-08-23 18:05:22,384 DEBUG TRAIN Batch 69/3000 loss 28.548998 loss_att 21.340054 loss_ctc 45.369869 loss_ctc_origin 37.707348 loss_ctc0 63.249084 lr 0.00100570 rank 0
2022-08-23 18:05:51,804 DEBUG TRAIN Batch 69/3100 loss 32.872913 loss_att 21.593647 loss_ctc 59.191200 loss_ctc_origin 41.785461 loss_ctc0 99.804581 lr 0.00100558 rank 0
2022-08-23 18:06:04,909 WARNING NaN or Inf found in input tensor.
2022-08-23 18:06:20,334 DEBUG TRAIN Batch 69/3200 loss 24.867640 loss_att 16.344849 loss_ctc 44.754150 loss_ctc_origin 35.577484 loss_ctc0 66.166367 lr 0.00100545 rank 0
2022-08-23 18:06:32,651 WARNING NaN or Inf found in input tensor.
2022-08-23 18:06:49,500 DEBUG TRAIN Batch 69/3300 loss 24.101032 loss_att 12.415161 loss_ctc 51.368065 loss_ctc_origin 38.330597 loss_ctc0 81.788826 lr 0.00100532 rank 0
2022-08-23 18:07:18,989 DEBUG TRAIN Batch 69/3400 loss 28.252117 loss_att 14.805043 loss_ctc 59.628616 loss_ctc_origin 45.233013 loss_ctc0 93.218361 lr 0.00100520 rank 0
2022-08-23 18:07:47,800 DEBUG TRAIN Batch 69/3500 loss 31.616882 loss_att 24.151653 loss_ctc 49.035755 loss_ctc_origin 41.102180 loss_ctc0 67.547424 lr 0.00100507 rank 0
2022-08-23 18:07:55,767 WARNING NaN or Inf found in input tensor.
2022-08-23 18:08:16,208 DEBUG TRAIN Batch 69/3600 loss 34.974838 loss_att 20.515572 loss_ctc 68.713120 loss_ctc_origin 40.974449 loss_ctc0 133.436676 lr 0.00100494 rank 0
2022-08-23 18:08:44,902 DEBUG TRAIN Batch 69/3700 loss 26.111834 loss_att 15.926362 loss_ctc 49.877930 loss_ctc_origin 40.212517 loss_ctc0 72.430557 lr 0.00100481 rank 0
2022-08-23 18:09:13,580 DEBUG TRAIN Batch 69/3800 loss 26.048573 loss_att 13.777454 loss_ctc 54.681175 loss_ctc_origin 44.553711 loss_ctc0 78.311920 lr 0.00100469 rank 0
2022-08-23 18:09:42,474 DEBUG TRAIN Batch 69/3900 loss 31.534027 loss_att 16.414459 loss_ctc 66.813019 loss_ctc_origin 53.000282 loss_ctc0 99.042740 lr 0.00100456 rank 0
2022-08-23 18:10:12,435 DEBUG TRAIN Batch 69/4000 loss 24.179001 loss_att 19.361320 loss_ctc 35.420258 loss_ctc_origin 32.650177 loss_ctc0 41.883774 lr 0.00100443 rank 0
2022-08-23 18:10:41,335 DEBUG TRAIN Batch 69/4100 loss 42.281898 loss_att 25.511623 loss_ctc 81.412537 loss_ctc_origin 50.582024 loss_ctc0 153.350403 lr 0.00100431 rank 0
2022-08-23 18:11:08,079 WARNING NaN or Inf found in input tensor.
2022-08-23 18:11:09,616 DEBUG TRAIN Batch 69/4200 loss 22.397835 loss_att 12.701396 loss_ctc 45.022854 loss_ctc_origin 34.425549 loss_ctc0 69.749901 lr 0.00100418 rank 0
2022-08-23 18:11:39,113 DEBUG TRAIN Batch 69/4300 loss 20.075377 loss_att 8.603283 loss_ctc 46.843594 loss_ctc_origin 31.673880 loss_ctc0 82.239594 lr 0.00100405 rank 0
2022-08-23 18:12:08,430 DEBUG TRAIN Batch 69/4400 loss 31.875999 loss_att 17.145023 loss_ctc 66.248276 loss_ctc_origin 52.419609 loss_ctc0 98.515167 lr 0.00100393 rank 0
2022-08-23 18:12:42,903 DEBUG TRAIN Batch 69/4500 loss 30.815983 loss_att 21.206018 loss_ctc 53.239231 loss_ctc_origin 39.102867 loss_ctc0 86.224075 lr 0.00100380 rank 0
2022-08-23 18:13:12,321 DEBUG TRAIN Batch 69/4600 loss 41.798222 loss_att 26.056639 loss_ctc 78.528580 loss_ctc_origin 46.333412 loss_ctc0 153.650620 lr 0.00100368 rank 0
2022-08-23 18:13:40,615 DEBUG TRAIN Batch 69/4700 loss 27.646185 loss_att 18.194227 loss_ctc 49.700752 loss_ctc_origin 40.766747 loss_ctc0 70.546768 lr 0.00100355 rank 0
2022-08-23 18:13:46,070 WARNING NaN or Inf found in input tensor.
2022-08-23 18:14:09,849 DEBUG TRAIN Batch 69/4800 loss 30.484180 loss_att 16.674168 loss_ctc 62.707542 loss_ctc_origin 51.242134 loss_ctc0 89.460175 lr 0.00100342 rank 0
2022-08-23 18:14:39,011 DEBUG TRAIN Batch 69/4900 loss 34.064781 loss_att 17.161020 loss_ctc 73.506882 loss_ctc_origin 58.628082 loss_ctc0 108.224075 lr 0.00100330 rank 0
2022-08-23 18:15:08,513 DEBUG TRAIN Batch 69/5000 loss 36.763809 loss_att 26.682034 loss_ctc 60.287949 loss_ctc_origin 45.856552 loss_ctc0 93.961212 lr 0.00100317 rank 0
2022-08-23 18:15:37,520 DEBUG TRAIN Batch 69/5100 loss 45.727623 loss_att 30.833778 loss_ctc 80.479919 loss_ctc_origin 49.400139 loss_ctc0 152.999390 lr 0.00100304 rank 0
2022-08-23 18:16:06,422 DEBUG TRAIN Batch 69/5200 loss 26.592857 loss_att 15.632427 loss_ctc 52.167198 loss_ctc_origin 43.221275 loss_ctc0 73.041008 lr 0.00100292 rank 0
2022-08-23 18:16:34,901 DEBUG TRAIN Batch 69/5300 loss 25.027584 loss_att 12.225145 loss_ctc 54.899937 loss_ctc_origin 43.866951 loss_ctc0 80.643570 lr 0.00100279 rank 0
2022-08-23 18:17:03,792 DEBUG TRAIN Batch 69/5400 loss 26.578369 loss_att 13.960233 loss_ctc 56.020683 loss_ctc_origin 39.022900 loss_ctc0 95.682175 lr 0.00100267 rank 0
2022-08-23 18:17:32,473 DEBUG TRAIN Batch 69/5500 loss 33.664780 loss_att 25.077864 loss_ctc 53.700912 loss_ctc_origin 43.373886 loss_ctc0 77.797302 lr 0.00100254 rank 0
2022-08-23 18:18:01,348 DEBUG TRAIN Batch 69/5600 loss 45.210701 loss_att 26.691795 loss_ctc 88.421478 loss_ctc_origin 55.505554 loss_ctc0 165.225311 lr 0.00100241 rank 0
2022-08-23 18:18:24,658 DEBUG CV Batch 69/0 loss 21.592884 loss_att 14.153588 loss_ctc 38.951244 loss_ctc_origin 22.133402 loss_ctc0 78.192871 history loss 20.322714 rank 0
2022-08-23 18:18:35,348 DEBUG CV Batch 69/100 loss 32.201763 loss_att 21.382875 loss_ctc 57.445831 loss_ctc_origin 33.270523 loss_ctc0 113.854889 history loss 32.475657 rank 0
2022-08-23 18:18:45,487 DEBUG CV Batch 69/200 loss 30.169621 loss_att 22.957222 loss_ctc 46.998550 loss_ctc_origin 36.906761 loss_ctc0 70.546051 history loss 34.010462 rank 0
2022-08-23 18:18:55,785 DEBUG CV Batch 69/300 loss 26.814022 loss_att 20.155966 loss_ctc 42.349487 loss_ctc_origin 26.737061 loss_ctc0 78.778488 history loss 32.980018 rank 0
2022-08-23 18:19:06,379 DEBUG CV Batch 69/400 loss 41.848969 loss_att 33.324230 loss_ctc 61.740017 loss_ctc_origin 44.539642 loss_ctc0 101.874222 history loss 31.115296 rank 0
2022-08-23 18:19:17,461 DEBUG CV Batch 69/500 loss 25.346382 loss_att 18.190216 loss_ctc 42.044098 loss_ctc_origin 29.090717 loss_ctc0 72.268646 history loss 30.636008 rank 0
2022-08-23 18:19:28,328 DEBUG CV Batch 69/600 loss 23.592697 loss_att 14.408082 loss_ctc 45.023468 loss_ctc_origin 25.699852 loss_ctc0 90.111908 history loss 30.511845 rank 0
2022-08-23 18:19:38,359 DEBUG CV Batch 69/700 loss 21.046659 loss_att 14.254145 loss_ctc 36.895859 loss_ctc_origin 23.237234 loss_ctc0 68.765976 history loss 30.152413 rank 0
2022-08-23 18:19:48,820 DEBUG CV Batch 69/800 loss 24.068977 loss_att 18.180779 loss_ctc 37.808105 loss_ctc_origin 22.483889 loss_ctc0 73.564613 history loss 30.091080 rank 0
2022-08-23 18:19:59,212 INFO Epoch 69 CV info cv_loss 30.099050421071432
2022-08-23 18:19:59,213 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/69.pt
2022-08-23 18:19:59,660 INFO Epoch 70 TRAIN info lr 0.0010023079655404395
2022-08-23 18:19:59,663 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 18:20:26,315 DEBUG TRAIN Batch 70/0 loss 41.272537 loss_att 29.790909 loss_ctc 68.063011 loss_ctc_origin 55.201576 loss_ctc0 98.073021 lr 0.00100230 rank 0
2022-08-23 18:20:54,268 DEBUG TRAIN Batch 70/100 loss 39.954288 loss_att 24.777588 loss_ctc 75.366592 loss_ctc_origin 45.017780 loss_ctc0 146.180496 lr 0.00100218 rank 0
2022-08-23 18:21:22,876 DEBUG TRAIN Batch 70/200 loss 27.718376 loss_att 17.162638 loss_ctc 52.348434 loss_ctc_origin 43.231255 loss_ctc0 73.621857 lr 0.00100205 rank 0
2022-08-23 18:21:51,476 DEBUG TRAIN Batch 70/300 loss 28.802885 loss_att 15.728951 loss_ctc 59.308731 loss_ctc_origin 46.230736 loss_ctc0 89.824051 lr 0.00100193 rank 0
2022-08-23 18:22:19,863 DEBUG TRAIN Batch 70/400 loss 27.978363 loss_att 13.632054 loss_ctc 61.453087 loss_ctc_origin 44.694901 loss_ctc0 100.555527 lr 0.00100180 rank 0
2022-08-23 18:22:22,569 WARNING NaN or Inf found in input tensor.
2022-08-23 18:22:48,873 DEBUG TRAIN Batch 70/500 loss 33.026226 loss_att 24.856525 loss_ctc 52.088860 loss_ctc_origin 46.245903 loss_ctc0 65.722420 lr 0.00100167 rank 0
2022-08-23 18:23:17,224 DEBUG TRAIN Batch 70/600 loss 37.655731 loss_att 24.245638 loss_ctc 68.945938 loss_ctc_origin 47.357887 loss_ctc0 119.318069 lr 0.00100155 rank 0
2022-08-23 18:23:44,889 DEBUG TRAIN Batch 70/700 loss 28.978466 loss_att 17.908554 loss_ctc 54.808258 loss_ctc_origin 47.599228 loss_ctc0 71.629333 lr 0.00100142 rank 0
2022-08-23 18:23:50,223 WARNING NaN or Inf found in input tensor.
2022-08-23 18:24:13,696 DEBUG TRAIN Batch 70/800 loss 23.796597 loss_att 12.812480 loss_ctc 49.426201 loss_ctc_origin 37.594574 loss_ctc0 77.033333 lr 0.00100130 rank 0
2022-08-23 18:24:42,869 DEBUG TRAIN Batch 70/900 loss 27.617826 loss_att 13.419239 loss_ctc 60.747860 loss_ctc_origin 46.275620 loss_ctc0 94.516418 lr 0.00100117 rank 0
2022-08-23 18:25:11,916 DEBUG TRAIN Batch 70/1000 loss 34.697273 loss_att 24.951874 loss_ctc 57.436531 loss_ctc_origin 38.877499 loss_ctc0 100.740936 lr 0.00100105 rank 0
2022-08-23 18:25:40,917 DEBUG TRAIN Batch 70/1100 loss 35.744476 loss_att 24.141418 loss_ctc 62.818275 loss_ctc_origin 47.862617 loss_ctc0 97.714813 lr 0.00100092 rank 0
2022-08-23 18:26:09,160 DEBUG TRAIN Batch 70/1200 loss 26.678905 loss_att 15.132277 loss_ctc 53.621040 loss_ctc_origin 44.689503 loss_ctc0 74.461288 lr 0.00100080 rank 0
2022-08-23 18:26:37,152 DEBUG TRAIN Batch 70/1300 loss 21.029043 loss_att 9.135597 loss_ctc 48.780418 loss_ctc_origin 36.720100 loss_ctc0 76.921158 lr 0.00100067 rank 0
2022-08-23 18:26:54,558 WARNING NaN or Inf found in input tensor.
2022-08-23 18:27:06,106 DEBUG TRAIN Batch 70/1400 loss 30.605907 loss_att 15.853372 loss_ctc 65.028496 loss_ctc_origin 48.131233 loss_ctc0 104.455444 lr 0.00100055 rank 0
2022-08-23 18:27:40,502 DEBUG TRAIN Batch 70/1500 loss 30.224264 loss_att 23.367163 loss_ctc 46.224167 loss_ctc_origin 40.936165 loss_ctc0 58.562836 lr 0.00100042 rank 0
2022-08-23 18:27:55,811 WARNING NaN or Inf found in input tensor.
2022-08-23 18:28:09,033 DEBUG TRAIN Batch 70/1600 loss 27.703880 loss_att 18.698385 loss_ctc 48.716698 loss_ctc_origin 39.235008 loss_ctc0 70.840630 lr 0.00100030 rank 0
2022-08-23 18:28:37,343 DEBUG TRAIN Batch 70/1700 loss 24.420292 loss_att 16.009554 loss_ctc 44.045341 loss_ctc_origin 35.802277 loss_ctc0 63.279163 lr 0.00100017 rank 0
2022-08-23 18:29:05,636 DEBUG TRAIN Batch 70/1800 loss 25.664234 loss_att 12.976534 loss_ctc 55.268867 loss_ctc_origin 43.306717 loss_ctc0 83.180557 lr 0.00100005 rank 0
2022-08-23 18:29:32,957 DEBUG TRAIN Batch 70/1900 loss 32.129200 loss_att 16.550686 loss_ctc 68.479065 loss_ctc_origin 53.118614 loss_ctc0 104.320114 lr 0.00099992 rank 0
2022-08-23 18:30:02,013 DEBUG TRAIN Batch 70/2000 loss 27.714592 loss_att 23.364777 loss_ctc 37.864159 loss_ctc_origin 34.171864 loss_ctc0 46.479519 lr 0.00099980 rank 0
2022-08-23 18:30:29,917 DEBUG TRAIN Batch 70/2100 loss 27.126446 loss_att 17.200359 loss_ctc 50.287308 loss_ctc_origin 39.755180 loss_ctc0 74.862259 lr 0.00099967 rank 0
2022-08-23 18:30:59,194 DEBUG TRAIN Batch 70/2200 loss 26.348904 loss_att 16.510532 loss_ctc 49.305099 loss_ctc_origin 40.521347 loss_ctc0 69.800514 lr 0.00099955 rank 0
2022-08-23 18:31:27,427 DEBUG TRAIN Batch 70/2300 loss 27.719250 loss_att 15.659819 loss_ctc 55.857914 loss_ctc_origin 44.254105 loss_ctc0 82.933464 lr 0.00099942 rank 0
2022-08-23 18:31:51,994 WARNING NaN or Inf found in input tensor.
2022-08-23 18:31:56,555 DEBUG TRAIN Batch 70/2400 loss 26.561491 loss_att 13.202406 loss_ctc 57.732685 loss_ctc_origin 42.566658 loss_ctc0 93.120079 lr 0.00099930 rank 0
2022-08-23 18:32:25,181 DEBUG TRAIN Batch 70/2500 loss 26.096310 loss_att 20.616928 loss_ctc 38.881531 loss_ctc_origin 36.235352 loss_ctc0 45.055943 lr 0.00099917 rank 0
2022-08-23 18:32:51,436 DEBUG TRAIN Batch 70/2600 loss 32.781559 loss_att 21.632275 loss_ctc 58.796547 loss_ctc_origin 41.714233 loss_ctc0 98.655281 lr 0.00099905 rank 0
2022-08-23 18:33:20,491 DEBUG TRAIN Batch 70/2700 loss 27.107531 loss_att 17.049633 loss_ctc 50.575958 loss_ctc_origin 40.171165 loss_ctc0 74.853798 lr 0.00099892 rank 0
2022-08-23 18:33:49,852 DEBUG TRAIN Batch 70/2800 loss 25.455933 loss_att 12.565952 loss_ctc 55.532547 loss_ctc_origin 44.307674 loss_ctc0 81.723923 lr 0.00099880 rank 0
2022-08-23 18:34:18,876 DEBUG TRAIN Batch 70/2900 loss 27.590656 loss_att 14.252421 loss_ctc 58.713200 loss_ctc_origin 43.638428 loss_ctc0 93.887665 lr 0.00099867 rank 0
2022-08-23 18:34:52,656 DEBUG TRAIN Batch 70/3000 loss 26.856321 loss_att 20.005930 loss_ctc 42.840569 loss_ctc_origin 35.327003 loss_ctc0 60.372208 lr 0.00099855 rank 0
2022-08-23 18:35:21,229 DEBUG TRAIN Batch 70/3100 loss 30.126949 loss_att 20.193859 loss_ctc 53.304161 loss_ctc_origin 38.333508 loss_ctc0 88.235680 lr 0.00099842 rank 0
2022-08-23 18:35:50,033 DEBUG TRAIN Batch 70/3200 loss 22.283009 loss_att 13.010494 loss_ctc 43.918877 loss_ctc_origin 32.548347 loss_ctc0 70.450111 lr 0.00099830 rank 0
2022-08-23 18:35:55,494 WARNING NaN or Inf found in input tensor.
2022-08-23 18:36:17,973 DEBUG TRAIN Batch 70/3300 loss 21.780840 loss_att 10.280643 loss_ctc 48.614632 loss_ctc_origin 36.286945 loss_ctc0 77.379227 lr 0.00099818 rank 0
2022-08-23 18:36:28,972 WARNING NaN or Inf found in input tensor.
2022-08-23 18:36:46,847 DEBUG TRAIN Batch 70/3400 loss 30.154095 loss_att 16.223156 loss_ctc 62.659618 loss_ctc_origin 49.183620 loss_ctc0 94.103607 lr 0.00099805 rank 0
2022-08-23 18:37:16,193 DEBUG TRAIN Batch 70/3500 loss 29.551926 loss_att 22.570047 loss_ctc 45.842972 loss_ctc_origin 38.268227 loss_ctc0 63.517372 lr 0.00099793 rank 0
2022-08-23 18:37:44,707 DEBUG TRAIN Batch 70/3600 loss 29.313438 loss_att 18.284077 loss_ctc 55.048607 loss_ctc_origin 40.314880 loss_ctc0 89.427307 lr 0.00099780 rank 0
2022-08-23 18:38:04,471 WARNING NaN or Inf found in input tensor.
2022-08-23 18:38:13,219 DEBUG TRAIN Batch 70/3700 loss 22.769352 loss_att 12.892195 loss_ctc 45.816055 loss_ctc_origin 35.455887 loss_ctc0 69.989777 lr 0.00099768 rank 0
2022-08-23 18:38:41,400 DEBUG TRAIN Batch 70/3800 loss 26.107780 loss_att 13.292988 loss_ctc 56.008965 loss_ctc_origin 43.953880 loss_ctc0 84.137489 lr 0.00099755 rank 0
2022-08-23 18:39:05,734 WARNING NaN or Inf found in input tensor.
2022-08-23 18:39:10,256 DEBUG TRAIN Batch 70/3900 loss 26.754265 loss_att 14.517399 loss_ctc 55.306946 loss_ctc_origin 39.972206 loss_ctc0 91.088013 lr 0.00099743 rank 0
2022-08-23 18:39:38,623 DEBUG TRAIN Batch 70/4000 loss 25.399147 loss_att 19.695711 loss_ctc 38.707165 loss_ctc_origin 33.472229 loss_ctc0 50.922012 lr 0.00099731 rank 0
2022-08-23 18:40:07,035 DEBUG TRAIN Batch 70/4100 loss 30.479156 loss_att 21.848087 loss_ctc 50.618317 loss_ctc_origin 40.530434 loss_ctc0 74.156708 lr 0.00099718 rank 0
2022-08-23 18:40:34,186 DEBUG TRAIN Batch 70/4200 loss 24.293777 loss_att 15.195145 loss_ctc 45.523922 loss_ctc_origin 34.299637 loss_ctc0 71.713921 lr 0.00099706 rank 0
2022-08-23 18:41:02,211 DEBUG TRAIN Batch 70/4300 loss 27.923443 loss_att 15.403625 loss_ctc 57.136349 loss_ctc_origin 45.183506 loss_ctc0 85.026314 lr 0.00099693 rank 0
2022-08-23 18:41:32,159 DEBUG TRAIN Batch 70/4400 loss 32.293823 loss_att 17.485161 loss_ctc 66.847374 loss_ctc_origin 52.924664 loss_ctc0 99.333694 lr 0.00099681 rank 0
2022-08-23 18:41:40,952 WARNING NaN or Inf found in input tensor.
2022-08-23 18:42:07,163 DEBUG TRAIN Batch 70/4500 loss 28.268784 loss_att 19.924530 loss_ctc 47.738708 loss_ctc_origin 33.656651 loss_ctc0 80.596840 lr 0.00099669 rank 0
2022-08-23 18:42:36,217 DEBUG TRAIN Batch 70/4600 loss 33.793465 loss_att 21.395767 loss_ctc 62.721428 loss_ctc_origin 35.846958 loss_ctc0 125.428520 lr 0.00099656 rank 0
2022-08-23 18:43:05,378 DEBUG TRAIN Batch 70/4700 loss 21.558420 loss_att 11.255226 loss_ctc 45.599205 loss_ctc_origin 35.575722 loss_ctc0 68.987320 lr 0.00099644 rank 0
2022-08-23 18:43:33,863 DEBUG TRAIN Batch 70/4800 loss 22.698891 loss_att 10.697455 loss_ctc 50.702236 loss_ctc_origin 38.044922 loss_ctc0 80.235970 lr 0.00099632 rank 0
2022-08-23 18:43:57,577 WARNING NaN or Inf found in input tensor.
2022-08-23 18:44:01,767 DEBUG TRAIN Batch 70/4900 loss 33.630638 loss_att 17.536602 loss_ctc 71.183395 loss_ctc_origin 54.734467 loss_ctc0 109.564240 lr 0.00099619 rank 0
2022-08-23 18:44:31,296 DEBUG TRAIN Batch 70/5000 loss 29.080833 loss_att 22.505632 loss_ctc 44.422966 loss_ctc_origin 33.452377 loss_ctc0 70.021004 lr 0.00099607 rank 0
2022-08-23 18:44:59,172 DEBUG TRAIN Batch 70/5100 loss 34.351124 loss_att 23.534142 loss_ctc 59.590752 loss_ctc_origin 35.320679 loss_ctc0 116.220932 lr 0.00099594 rank 0
2022-08-23 18:45:26,104 WARNING NaN or Inf found in input tensor.
2022-08-23 18:45:27,704 DEBUG TRAIN Batch 70/5200 loss 21.808231 loss_att 12.461932 loss_ctc 43.616264 loss_ctc_origin 34.224037 loss_ctc0 65.531464 lr 0.00099582 rank 0
2022-08-23 18:45:56,695 DEBUG TRAIN Batch 70/5300 loss 28.389765 loss_att 15.140059 loss_ctc 59.305744 loss_ctc_origin 47.033489 loss_ctc0 87.941002 lr 0.00099570 rank 0
2022-08-23 18:46:25,543 DEBUG TRAIN Batch 70/5400 loss 28.716923 loss_att 14.400152 loss_ctc 62.122719 loss_ctc_origin 46.491913 loss_ctc0 98.594604 lr 0.00099557 rank 0
2022-08-23 18:46:54,055 DEBUG TRAIN Batch 70/5500 loss 40.643738 loss_att 31.777536 loss_ctc 61.331528 loss_ctc_origin 52.447090 loss_ctc0 82.061874 lr 0.00099545 rank 0
2022-08-23 18:46:54,748 WARNING NaN or Inf found in input tensor.
2022-08-23 18:47:08,159 WARNING NaN or Inf found in input tensor.
2022-08-23 18:47:22,637 DEBUG TRAIN Batch 70/5600 loss 33.650146 loss_att 21.311613 loss_ctc 62.440048 loss_ctc_origin 45.028988 loss_ctc0 103.065865 lr 0.00099533 rank 0
2022-08-23 18:47:45,749 DEBUG CV Batch 70/0 loss 16.507828 loss_att 11.138416 loss_ctc 29.036457 loss_ctc_origin 18.276470 loss_ctc0 54.143093 history loss 15.536779 rank 0
2022-08-23 18:47:56,633 DEBUG CV Batch 70/100 loss 23.640373 loss_att 17.688244 loss_ctc 37.528679 loss_ctc_origin 23.251144 loss_ctc0 70.842934 history loss 30.241039 rank 0
2022-08-23 18:48:06,507 DEBUG CV Batch 70/200 loss 30.475159 loss_att 23.395267 loss_ctc 46.994904 loss_ctc_origin 37.254990 loss_ctc0 69.721367 history loss 31.698255 rank 0
2022-08-23 18:48:16,590 DEBUG CV Batch 70/300 loss 26.968945 loss_att 19.937672 loss_ctc 43.375248 loss_ctc_origin 29.264706 loss_ctc0 76.299843 history loss 30.834692 rank 0
2022-08-23 18:48:27,507 DEBUG CV Batch 70/400 loss 42.368652 loss_att 34.482895 loss_ctc 60.768761 loss_ctc_origin 44.222210 loss_ctc0 99.377373 history loss 29.145110 rank 0
2022-08-23 18:48:38,643 DEBUG CV Batch 70/500 loss 20.297636 loss_att 15.233307 loss_ctc 32.114403 loss_ctc_origin 23.824841 loss_ctc0 51.456722 history loss 28.850012 rank 0
2022-08-23 18:48:49,071 DEBUG CV Batch 70/600 loss 20.218651 loss_att 12.838726 loss_ctc 37.438477 loss_ctc_origin 23.416981 loss_ctc0 70.155304 history loss 28.671075 rank 0
2022-08-23 18:48:59,397 DEBUG CV Batch 70/700 loss 21.248837 loss_att 14.473354 loss_ctc 37.058292 loss_ctc_origin 24.003433 loss_ctc0 67.519630 history loss 28.349648 rank 0
2022-08-23 18:49:09,981 DEBUG CV Batch 70/800 loss 25.734032 loss_att 19.738281 loss_ctc 39.724121 loss_ctc_origin 25.295259 loss_ctc0 73.391464 history loss 28.304026 rank 0
2022-08-23 18:49:20,276 INFO Epoch 70 CV info cv_loss 28.380780309827692
2022-08-23 18:49:20,276 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/70.pt
2022-08-23 18:49:20,740 INFO Epoch 71 TRAIN info lr 0.0009952244282601453
2022-08-23 18:49:20,743 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 18:49:46,634 DEBUG TRAIN Batch 71/0 loss 25.046326 loss_att 18.322212 loss_ctc 40.735924 loss_ctc_origin 33.023666 loss_ctc0 58.731194 lr 0.00099522 rank 0
2022-08-23 18:50:16,249 DEBUG TRAIN Batch 71/100 loss 32.405678 loss_att 21.803621 loss_ctc 57.143803 loss_ctc_origin 41.616085 loss_ctc0 93.375137 lr 0.00099510 rank 0
2022-08-23 18:50:44,640 DEBUG TRAIN Batch 71/200 loss 19.612289 loss_att 11.123693 loss_ctc 39.419010 loss_ctc_origin 28.757318 loss_ctc0 64.296288 lr 0.00099497 rank 0
2022-08-23 18:51:14,406 DEBUG TRAIN Batch 71/300 loss 18.928791 loss_att 9.252722 loss_ctc 41.506283 loss_ctc_origin 25.202320 loss_ctc0 79.548859 lr 0.00099485 rank 0
2022-08-23 18:51:42,700 DEBUG TRAIN Batch 71/400 loss 29.822323 loss_att 15.295887 loss_ctc 63.717339 loss_ctc_origin 48.144268 loss_ctc0 100.054489 lr 0.00099473 rank 0
2022-08-23 18:52:12,810 DEBUG TRAIN Batch 71/500 loss 29.810972 loss_att 21.215382 loss_ctc 49.867348 loss_ctc_origin 40.689873 loss_ctc0 71.281448 lr 0.00099460 rank 0
2022-08-23 18:52:20,763 WARNING NaN or Inf found in input tensor.
2022-08-23 18:52:41,178 DEBUG TRAIN Batch 71/600 loss 34.508606 loss_att 21.832222 loss_ctc 64.086838 loss_ctc_origin 44.284580 loss_ctc0 110.292084 lr 0.00099448 rank 0
2022-08-23 18:53:09,214 DEBUG TRAIN Batch 71/700 loss 26.464848 loss_att 16.683578 loss_ctc 49.287804 loss_ctc_origin 39.555534 loss_ctc0 71.996429 lr 0.00099436 rank 0
2022-08-23 18:53:38,096 DEBUG TRAIN Batch 71/800 loss 21.960022 loss_att 10.146709 loss_ctc 49.524414 loss_ctc_origin 35.997417 loss_ctc0 81.087402 lr 0.00099424 rank 0
2022-08-23 18:54:02,520 WARNING NaN or Inf found in input tensor.
2022-08-23 18:54:06,878 DEBUG TRAIN Batch 71/900 loss 32.601269 loss_att 16.813217 loss_ctc 69.440048 loss_ctc_origin 54.115135 loss_ctc0 105.198181 lr 0.00099411 rank 0
2022-08-23 18:54:35,738 DEBUG TRAIN Batch 71/1000 loss 28.307222 loss_att 20.991753 loss_ctc 45.376652 loss_ctc_origin 36.649605 loss_ctc0 65.739761 lr 0.00099399 rank 0
2022-08-23 18:55:04,057 DEBUG TRAIN Batch 71/1100 loss 31.666744 loss_att 19.704422 loss_ctc 59.578827 loss_ctc_origin 38.049549 loss_ctc0 109.813797 lr 0.00099387 rank 0
2022-08-23 18:55:30,830 WARNING NaN or Inf found in input tensor.
2022-08-23 18:55:32,439 DEBUG TRAIN Batch 71/1200 loss 25.796680 loss_att 14.825663 loss_ctc 51.395721 loss_ctc_origin 42.068630 loss_ctc0 73.158936 lr 0.00099374 rank 0
2022-08-23 18:56:02,033 DEBUG TRAIN Batch 71/1300 loss 23.420250 loss_att 12.234001 loss_ctc 49.521496 loss_ctc_origin 37.021687 loss_ctc0 78.687714 lr 0.00099362 rank 0
2022-08-23 18:56:25,847 WARNING NaN or Inf found in input tensor.
2022-08-23 18:56:30,455 DEBUG TRAIN Batch 71/1400 loss 27.715599 loss_att 13.747755 loss_ctc 60.307236 loss_ctc_origin 45.389664 loss_ctc0 95.114899 lr 0.00099350 rank 0
2022-08-23 18:57:06,411 DEBUG TRAIN Batch 71/1500 loss 25.252823 loss_att 17.902451 loss_ctc 42.403694 loss_ctc_origin 29.382278 loss_ctc0 72.786995 lr 0.00099338 rank 0
2022-08-23 18:57:35,426 DEBUG TRAIN Batch 71/1600 loss 33.455898 loss_att 20.772606 loss_ctc 63.050243 loss_ctc_origin 42.694229 loss_ctc0 110.547607 lr 0.00099325 rank 0
2022-08-23 18:58:03,189 DEBUG TRAIN Batch 71/1700 loss 25.283297 loss_att 17.968603 loss_ctc 42.350914 loss_ctc_origin 32.753162 loss_ctc0 64.745667 lr 0.00099313 rank 0
2022-08-23 18:58:31,518 DEBUG TRAIN Batch 71/1800 loss 25.770649 loss_att 12.793549 loss_ctc 56.050545 loss_ctc_origin 45.512817 loss_ctc0 80.638565 lr 0.00099301 rank 0
2022-08-23 18:58:59,669 DEBUG TRAIN Batch 71/1900 loss 26.705589 loss_att 12.785744 loss_ctc 59.185223 loss_ctc_origin 44.035786 loss_ctc0 94.533905 lr 0.00099289 rank 0
2022-08-23 18:59:28,709 DEBUG TRAIN Batch 71/2000 loss 29.650465 loss_att 21.188133 loss_ctc 49.395905 loss_ctc_origin 38.272163 loss_ctc0 75.351303 lr 0.00099276 rank 0
2022-08-23 18:59:36,342 WARNING NaN or Inf found in input tensor.
2022-08-23 18:59:56,921 DEBUG TRAIN Batch 71/2100 loss 32.266804 loss_att 19.722115 loss_ctc 61.537743 loss_ctc_origin 36.739491 loss_ctc0 119.400330 lr 0.00099264 rank 0
2022-08-23 19:00:23,493 WARNING NaN or Inf found in input tensor.
2022-08-23 19:00:25,096 DEBUG TRAIN Batch 71/2200 loss 23.984318 loss_att 12.994439 loss_ctc 49.627365 loss_ctc_origin 39.741600 loss_ctc0 72.694153 lr 0.00099252 rank 0
2022-08-23 19:00:53,926 DEBUG TRAIN Batch 71/2300 loss 24.648867 loss_att 12.074446 loss_ctc 53.989182 loss_ctc_origin 42.410614 loss_ctc0 81.005829 lr 0.00099240 rank 0
2022-08-23 19:01:23,126 DEBUG TRAIN Batch 71/2400 loss 30.534550 loss_att 16.614700 loss_ctc 63.014198 loss_ctc_origin 47.324547 loss_ctc0 99.623375 lr 0.00099228 rank 0
2022-08-23 19:01:50,730 DEBUG TRAIN Batch 71/2500 loss 20.524044 loss_att 15.864321 loss_ctc 31.396727 loss_ctc_origin 25.632381 loss_ctc0 44.846863 lr 0.00099215 rank 0
2022-08-23 19:02:18,371 DEBUG TRAIN Batch 71/2600 loss 26.433361 loss_att 14.855722 loss_ctc 53.447845 loss_ctc_origin 34.222485 loss_ctc0 98.307014 lr 0.00099203 rank 0
2022-08-23 19:02:46,863 DEBUG TRAIN Batch 71/2700 loss 20.272877 loss_att 11.189904 loss_ctc 41.466476 loss_ctc_origin 32.101063 loss_ctc0 63.319099 lr 0.00099191 rank 0
2022-08-23 19:02:59,407 WARNING NaN or Inf found in input tensor.
2022-08-23 19:03:16,433 DEBUG TRAIN Batch 71/2800 loss 25.365562 loss_att 12.886083 loss_ctc 54.484344 loss_ctc_origin 40.760864 loss_ctc0 86.505798 lr 0.00099179 rank 0
2022-08-23 19:03:45,884 DEBUG TRAIN Batch 71/2900 loss 28.910553 loss_att 15.769288 loss_ctc 59.573502 loss_ctc_origin 46.386406 loss_ctc0 90.343399 lr 0.00099167 rank 0
2022-08-23 19:04:21,235 WARNING NaN or Inf found in input tensor.
2022-08-23 19:04:21,310 DEBUG TRAIN Batch 71/3000 loss inf loss_att 32.583549 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00099154 rank 0
2022-08-23 19:04:49,845 DEBUG TRAIN Batch 71/3100 loss 31.881233 loss_att 20.270489 loss_ctc 58.972973 loss_ctc_origin 42.224754 loss_ctc0 98.052147 lr 0.00099142 rank 0
2022-08-23 19:05:19,130 DEBUG TRAIN Batch 71/3200 loss 27.176727 loss_att 15.731751 loss_ctc 53.881668 loss_ctc_origin 44.676575 loss_ctc0 75.360214 lr 0.00099130 rank 0
2022-08-23 19:05:47,914 DEBUG TRAIN Batch 71/3300 loss 22.731461 loss_att 12.117031 loss_ctc 47.498466 loss_ctc_origin 34.048401 loss_ctc0 78.881950 lr 0.00099118 rank 0
2022-08-23 19:06:11,495 WARNING NaN or Inf found in input tensor.
2022-08-23 19:06:16,332 DEBUG TRAIN Batch 71/3400 loss 28.526699 loss_att 14.809307 loss_ctc 60.533943 loss_ctc_origin 43.216133 loss_ctc0 100.942169 lr 0.00099106 rank 0
2022-08-23 19:06:46,181 DEBUG TRAIN Batch 71/3500 loss 24.621662 loss_att 18.572193 loss_ctc 38.737091 loss_ctc_origin 30.325478 loss_ctc0 58.364182 lr 0.00099093 rank 0
2022-08-23 19:07:15,640 DEBUG TRAIN Batch 71/3600 loss 36.375626 loss_att 27.072964 loss_ctc 58.081825 loss_ctc_origin 43.788391 loss_ctc0 91.433167 lr 0.00099081 rank 0
2022-08-23 19:07:45,251 DEBUG TRAIN Batch 71/3700 loss 25.097017 loss_att 15.636181 loss_ctc 47.172298 loss_ctc_origin 37.271698 loss_ctc0 70.273697 lr 0.00099069 rank 0
2022-08-23 19:08:13,687 DEBUG TRAIN Batch 71/3800 loss 27.009926 loss_att 12.485281 loss_ctc 60.900761 loss_ctc_origin 47.861336 loss_ctc0 91.326088 lr 0.00099057 rank 0
2022-08-23 19:08:38,786 WARNING NaN or Inf found in input tensor.
2022-08-23 19:08:43,473 DEBUG TRAIN Batch 71/3900 loss 27.328281 loss_att 13.364515 loss_ctc 59.910400 loss_ctc_origin 42.562607 loss_ctc0 100.388588 lr 0.00099045 rank 0
2022-08-23 19:09:11,923 DEBUG TRAIN Batch 71/4000 loss 28.255644 loss_att 22.542160 loss_ctc 41.587105 loss_ctc_origin 32.562195 loss_ctc0 62.645233 lr 0.00099033 rank 0
2022-08-23 19:09:39,948 DEBUG TRAIN Batch 71/4100 loss 33.663296 loss_att 21.513729 loss_ctc 62.012280 loss_ctc_origin 40.348812 loss_ctc0 112.560371 lr 0.00099021 rank 0
2022-08-23 19:10:09,163 DEBUG TRAIN Batch 71/4200 loss 23.280088 loss_att 13.923306 loss_ctc 45.112579 loss_ctc_origin 35.800438 loss_ctc0 66.840912 lr 0.00099008 rank 0
2022-08-23 19:10:37,644 DEBUG TRAIN Batch 71/4300 loss 24.186539 loss_att 12.819193 loss_ctc 50.710350 loss_ctc_origin 38.123817 loss_ctc0 80.078918 lr 0.00098996 rank 0
2022-08-23 19:11:07,125 DEBUG TRAIN Batch 71/4400 loss 26.664043 loss_att 13.834407 loss_ctc 56.599857 loss_ctc_origin 39.470238 loss_ctc0 96.568970 lr 0.00098984 rank 0
2022-08-23 19:11:42,593 DEBUG TRAIN Batch 71/4500 loss 27.254543 loss_att 21.319019 loss_ctc 41.104103 loss_ctc_origin 37.074913 loss_ctc0 50.505554 lr 0.00098972 rank 0
2022-08-23 19:12:11,340 DEBUG TRAIN Batch 71/4600 loss 35.713936 loss_att 26.729776 loss_ctc 56.676968 loss_ctc_origin 43.232513 loss_ctc0 88.047363 lr 0.00098960 rank 0
2022-08-23 19:12:39,798 DEBUG TRAIN Batch 71/4700 loss 22.635975 loss_att 13.577164 loss_ctc 43.773197 loss_ctc_origin 32.945152 loss_ctc0 69.038635 lr 0.00098948 rank 0
2022-08-23 19:13:08,550 DEBUG TRAIN Batch 71/4800 loss 23.794786 loss_att 10.252018 loss_ctc 55.394577 loss_ctc_origin 41.802238 loss_ctc0 87.110039 lr 0.00098936 rank 0
2022-08-23 19:13:37,193 DEBUG TRAIN Batch 71/4900 loss 34.114246 loss_att 18.350025 loss_ctc 70.897430 loss_ctc_origin 58.414272 loss_ctc0 100.024796 lr 0.00098924 rank 0
2022-08-23 19:14:07,277 DEBUG TRAIN Batch 71/5000 loss 28.370073 loss_att 21.369356 loss_ctc 44.705078 loss_ctc_origin 36.450600 loss_ctc0 63.965530 lr 0.00098912 rank 0
2022-08-23 19:14:35,728 DEBUG TRAIN Batch 71/5100 loss 30.024590 loss_att 20.079454 loss_ctc 53.229900 loss_ctc_origin 34.827362 loss_ctc0 96.169159 lr 0.00098899 rank 0
2022-08-23 19:14:56,070 WARNING NaN or Inf found in input tensor.
2022-08-23 19:15:03,323 WARNING NaN or Inf found in input tensor.
2022-08-23 19:15:04,924 DEBUG TRAIN Batch 71/5200 loss 24.526411 loss_att 14.225426 loss_ctc 48.562042 loss_ctc_origin 39.355301 loss_ctc0 70.044434 lr 0.00098887 rank 0
2022-08-23 19:15:10,438 WARNING NaN or Inf found in input tensor.
2022-08-23 19:15:33,344 DEBUG TRAIN Batch 71/5300 loss 24.311630 loss_att 12.845537 loss_ctc 51.065849 loss_ctc_origin 39.335670 loss_ctc0 78.436272 lr 0.00098875 rank 0
2022-08-23 19:15:51,263 WARNING NaN or Inf found in input tensor.
2022-08-23 19:16:02,960 DEBUG TRAIN Batch 71/5400 loss 26.144005 loss_att 13.166162 loss_ctc 56.425636 loss_ctc_origin 41.747643 loss_ctc0 90.674286 lr 0.00098863 rank 0
2022-08-23 19:16:32,098 DEBUG TRAIN Batch 71/5500 loss 25.071268 loss_att 20.730721 loss_ctc 35.199211 loss_ctc_origin 27.513748 loss_ctc0 53.131966 lr 0.00098851 rank 0
2022-08-23 19:17:01,485 DEBUG TRAIN Batch 71/5600 loss 36.886017 loss_att 26.681652 loss_ctc 60.696198 loss_ctc_origin 40.486107 loss_ctc0 107.853073 lr 0.00098839 rank 0
2022-08-23 19:17:14,885 WARNING NaN or Inf found in input tensor.
2022-08-23 19:17:24,342 DEBUG CV Batch 71/0 loss 17.584574 loss_att 12.420073 loss_ctc 29.635077 loss_ctc_origin 19.943188 loss_ctc0 52.249485 history loss 16.550187 rank 0
2022-08-23 19:17:35,312 DEBUG CV Batch 71/100 loss 25.613407 loss_att 19.744913 loss_ctc 39.306557 loss_ctc_origin 26.536312 loss_ctc0 69.103790 history loss 30.425599 rank 0
2022-08-23 19:17:45,090 DEBUG CV Batch 71/200 loss 29.451622 loss_att 22.426020 loss_ctc 45.844688 loss_ctc_origin 36.551323 loss_ctc0 67.529213 history loss 31.691897 rank 0
2022-08-23 19:17:55,127 DEBUG CV Batch 71/300 loss 26.384266 loss_att 19.636082 loss_ctc 42.130028 loss_ctc_origin 27.603157 loss_ctc0 76.026062 history loss 30.747806 rank 0
2022-08-23 19:18:06,269 DEBUG CV Batch 71/400 loss 40.656868 loss_att 32.269745 loss_ctc 60.226814 loss_ctc_origin 43.509369 loss_ctc0 99.234177 history loss 28.961807 rank 0
2022-08-23 19:18:17,133 DEBUG CV Batch 71/500 loss 19.639961 loss_att 14.423870 loss_ctc 31.810839 loss_ctc_origin 23.673214 loss_ctc0 50.798630 history loss 28.520164 rank 0
2022-08-23 19:18:28,166 DEBUG CV Batch 71/600 loss 18.920773 loss_att 12.301735 loss_ctc 34.365196 loss_ctc_origin 21.954515 loss_ctc0 63.323456 history loss 28.311208 rank 0
2022-08-23 19:18:38,502 DEBUG CV Batch 71/700 loss 20.825825 loss_att 14.175159 loss_ctc 36.344048 loss_ctc_origin 23.463766 loss_ctc0 66.398033 history loss 27.914590 rank 0
2022-08-23 19:18:48,860 DEBUG CV Batch 71/800 loss 24.170029 loss_att 18.282114 loss_ctc 37.908493 loss_ctc_origin 22.923756 loss_ctc0 72.872879 history loss 27.857463 rank 0
2022-08-23 19:18:59,331 INFO Epoch 71 CV info cv_loss 27.940776698477997
2022-08-23 19:18:59,332 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/71.pt
2022-08-23 19:18:59,848 INFO Epoch 72 TRAIN info lr 0.0009882889818955834
2022-08-23 19:18:59,852 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 19:19:26,475 DEBUG TRAIN Batch 72/0 loss 30.630474 loss_att 24.085537 loss_ctc 45.901993 loss_ctc_origin 42.155106 loss_ctc0 54.644730 lr 0.00098828 rank 0
2022-08-23 19:19:54,371 DEBUG TRAIN Batch 72/100 loss 35.256096 loss_att 24.373825 loss_ctc 60.648048 loss_ctc_origin 41.159939 loss_ctc0 106.120300 lr 0.00098816 rank 0
2022-08-23 19:20:22,048 DEBUG TRAIN Batch 72/200 loss 26.619427 loss_att 15.701012 loss_ctc 52.095726 loss_ctc_origin 41.103149 loss_ctc0 77.745071 lr 0.00098804 rank 0
2022-08-23 19:20:50,279 DEBUG TRAIN Batch 72/300 loss 23.520973 loss_att 11.324524 loss_ctc 51.979355 loss_ctc_origin 38.445656 loss_ctc0 83.557991 lr 0.00098792 rank 0
2022-08-23 19:21:18,962 DEBUG TRAIN Batch 72/400 loss 30.528160 loss_att 15.586849 loss_ctc 65.391220 loss_ctc_origin 50.931583 loss_ctc0 99.130363 lr 0.00098780 rank 0
2022-08-23 19:21:48,361 DEBUG TRAIN Batch 72/500 loss 25.438099 loss_att 19.643282 loss_ctc 38.959335 loss_ctc_origin 32.832718 loss_ctc0 53.254768 lr 0.00098768 rank 0
2022-08-23 19:21:56,356 WARNING NaN or Inf found in input tensor.
2022-08-23 19:22:15,399 WARNING NaN or Inf found in input tensor.
2022-08-23 19:22:15,444 DEBUG TRAIN Batch 72/600 loss nan loss_att 24.752819 loss_ctc nan loss_ctc_origin 41.063766 loss_ctc0 nan lr 0.00098756 rank 0
2022-08-23 19:22:42,948 DEBUG TRAIN Batch 72/700 loss 21.913540 loss_att 12.857586 loss_ctc 43.044098 loss_ctc_origin 33.862450 loss_ctc0 64.467941 lr 0.00098744 rank 0
2022-08-23 19:23:11,441 DEBUG TRAIN Batch 72/800 loss 27.966705 loss_att 14.470694 loss_ctc 59.457397 loss_ctc_origin 47.295719 loss_ctc0 87.834641 lr 0.00098732 rank 0
2022-08-23 19:23:39,892 DEBUG TRAIN Batch 72/900 loss 24.098141 loss_att 11.408985 loss_ctc 53.706169 loss_ctc_origin 36.801403 loss_ctc0 93.150627 lr 0.00098720 rank 0
2022-08-23 19:24:09,125 DEBUG TRAIN Batch 72/1000 loss 35.931992 loss_att 24.894714 loss_ctc 61.685638 loss_ctc_origin 46.368397 loss_ctc0 97.425865 lr 0.00098708 rank 0
2022-08-23 19:24:38,687 DEBUG TRAIN Batch 72/1100 loss 43.693104 loss_att 27.025406 loss_ctc 82.584396 loss_ctc_origin 59.589600 loss_ctc0 136.238922 lr 0.00098696 rank 0
2022-08-23 19:25:06,747 DEBUG TRAIN Batch 72/1200 loss 26.867870 loss_att 15.442078 loss_ctc 53.528053 loss_ctc_origin 45.317551 loss_ctc0 72.685890 lr 0.00098684 rank 0
2022-08-23 19:25:35,944 DEBUG TRAIN Batch 72/1300 loss 26.403843 loss_att 13.321505 loss_ctc 56.929295 loss_ctc_origin 45.349438 loss_ctc0 83.948959 lr 0.00098672 rank 0
2022-08-23 19:26:04,874 DEBUG TRAIN Batch 72/1400 loss 27.048534 loss_att 13.204079 loss_ctc 59.352261 loss_ctc_origin 43.478958 loss_ctc0 96.389961 lr 0.00098660 rank 0
2022-08-23 19:26:39,950 DEBUG TRAIN Batch 72/1500 loss 26.024248 loss_att 20.452282 loss_ctc 39.025501 loss_ctc_origin 34.058243 loss_ctc0 50.615768 lr 0.00098648 rank 0
2022-08-23 19:27:09,024 DEBUG TRAIN Batch 72/1600 loss 35.206200 loss_att 23.603325 loss_ctc 62.279564 loss_ctc_origin 40.231182 loss_ctc0 113.725784 lr 0.00098636 rank 0
2022-08-23 19:27:37,393 DEBUG TRAIN Batch 72/1700 loss 25.086544 loss_att 13.952476 loss_ctc 51.066032 loss_ctc_origin 41.577599 loss_ctc0 73.205711 lr 0.00098624 rank 0
2022-08-23 19:28:06,979 DEBUG TRAIN Batch 72/1800 loss 23.989832 loss_att 11.689745 loss_ctc 52.690033 loss_ctc_origin 40.037441 loss_ctc0 82.212738 lr 0.00098612 rank 0
2022-08-23 19:28:30,203 WARNING NaN or Inf found in input tensor.
2022-08-23 19:28:34,637 DEBUG TRAIN Batch 72/1900 loss 29.281935 loss_att 15.523396 loss_ctc 61.385193 loss_ctc_origin 44.780876 loss_ctc0 100.128601 lr 0.00098600 rank 0
2022-08-23 19:29:03,524 DEBUG TRAIN Batch 72/2000 loss 28.380024 loss_att 22.010065 loss_ctc 43.243256 loss_ctc_origin 34.990650 loss_ctc0 62.499329 lr 0.00098588 rank 0
2022-08-23 19:29:30,887 DEBUG TRAIN Batch 72/2100 loss 35.650318 loss_att 21.868069 loss_ctc 67.808899 loss_ctc_origin 42.696049 loss_ctc0 126.405563 lr 0.00098576 rank 0
2022-08-23 19:29:59,997 DEBUG TRAIN Batch 72/2200 loss 23.213688 loss_att 13.202169 loss_ctc 46.573902 loss_ctc_origin 36.730873 loss_ctc0 69.540970 lr 0.00098564 rank 0
2022-08-23 19:30:28,049 DEBUG TRAIN Batch 72/2300 loss 25.775755 loss_att 13.321155 loss_ctc 54.836487 loss_ctc_origin 41.451836 loss_ctc0 86.067337 lr 0.00098552 rank 0
2022-08-23 19:30:56,576 DEBUG TRAIN Batch 72/2400 loss 28.721516 loss_att 14.762480 loss_ctc 61.292595 loss_ctc_origin 46.345554 loss_ctc0 96.169029 lr 0.00098540 rank 0
2022-08-23 19:31:24,945 DEBUG TRAIN Batch 72/2500 loss 39.607246 loss_att 29.846676 loss_ctc 62.381916 loss_ctc_origin 50.150803 loss_ctc0 90.921181 lr 0.00098528 rank 0
2022-08-23 19:31:46,333 WARNING NaN or Inf found in input tensor.
2022-08-23 19:31:53,239 DEBUG TRAIN Batch 72/2600 loss 38.314743 loss_att 23.713146 loss_ctc 72.385132 loss_ctc_origin 49.340069 loss_ctc0 126.156952 lr 0.00098516 rank 0
2022-08-23 19:32:21,866 DEBUG TRAIN Batch 72/2700 loss 21.521570 loss_att 12.351750 loss_ctc 42.917816 loss_ctc_origin 32.433495 loss_ctc0 67.381241 lr 0.00098504 rank 0
2022-08-23 19:32:50,473 DEBUG TRAIN Batch 72/2800 loss 24.031265 loss_att 11.302337 loss_ctc 53.732098 loss_ctc_origin 40.978268 loss_ctc0 83.491028 lr 0.00098492 rank 0
2022-08-23 19:33:15,220 WARNING NaN or Inf found in input tensor.
2022-08-23 19:33:19,674 DEBUG TRAIN Batch 72/2900 loss 28.892342 loss_att 14.197560 loss_ctc 63.180161 loss_ctc_origin 47.592354 loss_ctc0 99.551704 lr 0.00098480 rank 0
2022-08-23 19:33:55,801 DEBUG TRAIN Batch 72/3000 loss 26.420752 loss_att 20.626101 loss_ctc 39.941601 loss_ctc_origin 36.081020 loss_ctc0 48.949623 lr 0.00098468 rank 0
2022-08-23 19:34:04,006 WARNING NaN or Inf found in input tensor.
2022-08-23 19:34:24,939 DEBUG TRAIN Batch 72/3100 loss 37.505558 loss_att 25.179140 loss_ctc 66.267197 loss_ctc_origin 46.686100 loss_ctc0 111.956429 lr 0.00098456 rank 0
2022-08-23 19:34:53,687 DEBUG TRAIN Batch 72/3200 loss 30.907745 loss_att 18.428518 loss_ctc 60.025940 loss_ctc_origin 50.537243 loss_ctc0 82.166229 lr 0.00098445 rank 0
2022-08-23 19:35:22,237 DEBUG TRAIN Batch 72/3300 loss 27.974072 loss_att 15.071321 loss_ctc 58.080490 loss_ctc_origin 47.321762 loss_ctc0 83.184196 lr 0.00098433 rank 0
2022-08-23 19:35:50,171 DEBUG TRAIN Batch 72/3400 loss 26.103024 loss_att 12.456505 loss_ctc 57.944901 loss_ctc_origin 40.910442 loss_ctc0 97.691971 lr 0.00098421 rank 0
2022-08-23 19:36:19,145 DEBUG TRAIN Batch 72/3500 loss 27.677578 loss_att 19.342861 loss_ctc 47.125244 loss_ctc_origin 32.440716 loss_ctc0 81.389145 lr 0.00098409 rank 0
2022-08-23 19:36:47,401 DEBUG TRAIN Batch 72/3600 loss 36.393234 loss_att 21.440590 loss_ctc 71.282738 loss_ctc_origin 45.357796 loss_ctc0 131.774261 lr 0.00098397 rank 0
2022-08-23 19:37:15,833 DEBUG TRAIN Batch 72/3700 loss 20.829948 loss_att 11.760750 loss_ctc 41.991409 loss_ctc_origin 29.881369 loss_ctc0 70.248169 lr 0.00098385 rank 0
2022-08-23 19:37:44,030 DEBUG TRAIN Batch 72/3800 loss 24.526966 loss_att 13.061763 loss_ctc 51.279102 loss_ctc_origin 38.499069 loss_ctc0 81.099174 lr 0.00098373 rank 0
2022-08-23 19:38:11,825 DEBUG TRAIN Batch 72/3900 loss 31.357502 loss_att 16.346233 loss_ctc 66.383789 loss_ctc_origin 50.375809 loss_ctc0 103.735748 lr 0.00098361 rank 0
2022-08-23 19:38:40,510 DEBUG TRAIN Batch 72/4000 loss 35.616081 loss_att 28.734430 loss_ctc 51.673264 loss_ctc_origin 47.915459 loss_ctc0 60.441471 lr 0.00098349 rank 0
2022-08-23 19:39:10,340 DEBUG TRAIN Batch 72/4100 loss 40.881660 loss_att 25.459503 loss_ctc 76.866699 loss_ctc_origin 49.073135 loss_ctc0 141.718353 lr 0.00098337 rank 0
2022-08-23 19:39:38,997 DEBUG TRAIN Batch 72/4200 loss 25.219261 loss_att 15.843280 loss_ctc 47.096550 loss_ctc_origin 37.671535 loss_ctc0 69.088242 lr 0.00098326 rank 0
2022-08-23 19:39:51,009 WARNING NaN or Inf found in input tensor.
2022-08-23 19:40:07,949 DEBUG TRAIN Batch 72/4300 loss 25.418282 loss_att 12.923189 loss_ctc 54.573498 loss_ctc_origin 43.066223 loss_ctc0 81.423798 lr 0.00098314 rank 0
2022-08-23 19:40:37,382 DEBUG TRAIN Batch 72/4400 loss 26.226421 loss_att 13.068994 loss_ctc 56.927078 loss_ctc_origin 41.946220 loss_ctc0 91.882401 lr 0.00098302 rank 0
2022-08-23 19:40:46,284 WARNING NaN or Inf found in input tensor.
2022-08-23 19:41:12,697 DEBUG TRAIN Batch 72/4500 loss 30.439789 loss_att 24.114586 loss_ctc 45.198593 loss_ctc_origin 41.395958 loss_ctc0 54.071404 lr 0.00098290 rank 0
2022-08-23 19:41:42,450 DEBUG TRAIN Batch 72/4600 loss 39.500145 loss_att 24.245247 loss_ctc 75.094910 loss_ctc_origin 47.285889 loss_ctc0 139.982635 lr 0.00098278 rank 0
2022-08-23 19:42:11,687 DEBUG TRAIN Batch 72/4700 loss 24.621719 loss_att 14.986637 loss_ctc 47.103580 loss_ctc_origin 38.359138 loss_ctc0 67.507278 lr 0.00098266 rank 0
2022-08-23 19:42:40,319 DEBUG TRAIN Batch 72/4800 loss 26.051426 loss_att 13.370379 loss_ctc 55.640530 loss_ctc_origin 43.685677 loss_ctc0 83.535187 lr 0.00098254 rank 0
2022-08-23 19:43:09,415 DEBUG TRAIN Batch 72/4900 loss 29.335653 loss_att 16.289728 loss_ctc 59.776146 loss_ctc_origin 44.211548 loss_ctc0 96.093544 lr 0.00098242 rank 0
2022-08-23 19:43:39,007 DEBUG TRAIN Batch 72/5000 loss 27.944450 loss_att 20.817314 loss_ctc 44.574432 loss_ctc_origin 36.587967 loss_ctc0 63.209515 lr 0.00098231 rank 0
2022-08-23 19:44:06,909 DEBUG TRAIN Batch 72/5100 loss 38.440590 loss_att 24.472523 loss_ctc 71.032738 loss_ctc_origin 45.956402 loss_ctc0 129.544189 lr 0.00098219 rank 0
2022-08-23 19:44:36,196 DEBUG TRAIN Batch 72/5200 loss 25.914173 loss_att 14.109852 loss_ctc 53.457588 loss_ctc_origin 43.177334 loss_ctc0 77.444847 lr 0.00098207 rank 0
2022-08-23 19:45:04,657 DEBUG TRAIN Batch 72/5300 loss 24.144232 loss_att 11.553609 loss_ctc 53.522346 loss_ctc_origin 42.489765 loss_ctc0 79.265030 lr 0.00098195 rank 0
2022-08-23 19:45:33,445 DEBUG TRAIN Batch 72/5400 loss 26.653702 loss_att 12.412462 loss_ctc 59.883263 loss_ctc_origin 44.661282 loss_ctc0 95.401222 lr 0.00098183 rank 0
2022-08-23 19:46:03,890 DEBUG TRAIN Batch 72/5500 loss 33.882004 loss_att 24.254921 loss_ctc 56.345184 loss_ctc_origin 37.267715 loss_ctc0 100.859283 lr 0.00098171 rank 0
2022-08-23 19:46:32,706 DEBUG TRAIN Batch 72/5600 loss 40.669209 loss_att 24.715805 loss_ctc 77.893814 loss_ctc_origin 52.579544 loss_ctc0 136.960449 lr 0.00098160 rank 0
2022-08-23 19:46:56,195 DEBUG CV Batch 72/0 loss 18.060459 loss_att 11.418618 loss_ctc 33.558090 loss_ctc_origin 18.155569 loss_ctc0 69.497299 history loss 16.998079 rank 0
2022-08-23 19:47:07,016 DEBUG CV Batch 72/100 loss 27.354780 loss_att 18.871468 loss_ctc 47.149178 loss_ctc_origin 27.833454 loss_ctc0 92.219200 history loss 30.920855 rank 0
2022-08-23 19:47:16,890 DEBUG CV Batch 72/200 loss 31.507423 loss_att 22.916275 loss_ctc 51.553436 loss_ctc_origin 34.416176 loss_ctc0 91.540382 history loss 32.540292 rank 0
2022-08-23 19:47:27,172 DEBUG CV Batch 72/300 loss 25.873764 loss_att 18.971607 loss_ctc 41.978798 loss_ctc_origin 26.675741 loss_ctc0 77.685928 history loss 31.510360 rank 0
2022-08-23 19:47:38,033 DEBUG CV Batch 72/400 loss 40.868336 loss_att 32.693794 loss_ctc 59.942265 loss_ctc_origin 42.576244 loss_ctc0 100.462975 history loss 29.729214 rank 0
2022-08-23 19:47:49,216 DEBUG CV Batch 72/500 loss 22.298241 loss_att 15.071293 loss_ctc 39.161118 loss_ctc_origin 25.767672 loss_ctc0 70.412491 history loss 29.324090 rank 0
2022-08-23 19:48:00,028 DEBUG CV Batch 72/600 loss 23.859602 loss_att 14.271969 loss_ctc 46.230743 loss_ctc_origin 24.975613 loss_ctc0 95.826035 history loss 29.175320 rank 0
2022-08-23 19:48:10,410 DEBUG CV Batch 72/700 loss 20.932133 loss_att 14.146506 loss_ctc 36.765259 loss_ctc_origin 23.350555 loss_ctc0 68.066223 history loss 28.785756 rank 0
2022-08-23 19:48:20,931 DEBUG CV Batch 72/800 loss 24.916805 loss_att 19.180161 loss_ctc 38.302307 loss_ctc_origin 22.847874 loss_ctc0 74.362656 history loss 28.702554 rank 0
2022-08-23 19:48:31,844 INFO Epoch 72 CV info cv_loss 28.736994627990317
2022-08-23 19:48:31,844 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/72.pt
2022-08-23 19:48:32,314 INFO Epoch 73 TRAIN info lr 0.0009814965372691485
2022-08-23 19:48:32,318 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 19:48:59,577 DEBUG TRAIN Batch 73/0 loss 30.157894 loss_att 21.277864 loss_ctc 50.877968 loss_ctc_origin 41.194378 loss_ctc0 73.473007 lr 0.00098149 rank 0
2022-08-23 19:49:27,991 DEBUG TRAIN Batch 73/100 loss 36.040649 loss_att 21.712713 loss_ctc 69.472504 loss_ctc_origin 45.254723 loss_ctc0 125.980667 lr 0.00098137 rank 0
2022-08-23 19:49:56,122 DEBUG TRAIN Batch 73/200 loss 21.920826 loss_att 13.196079 loss_ctc 42.278572 loss_ctc_origin 32.105114 loss_ctc0 66.016647 lr 0.00098126 rank 0
2022-08-23 19:50:08,168 WARNING NaN or Inf found in input tensor.
2022-08-23 19:50:25,486 DEBUG TRAIN Batch 73/300 loss 20.942673 loss_att 10.960585 loss_ctc 44.234215 loss_ctc_origin 32.373528 loss_ctc0 71.909157 lr 0.00098114 rank 0
2022-08-23 19:50:54,750 DEBUG TRAIN Batch 73/400 loss 26.627968 loss_att 13.021667 loss_ctc 58.376003 loss_ctc_origin 42.271103 loss_ctc0 95.954102 lr 0.00098102 rank 0
2022-08-23 19:51:24,047 DEBUG TRAIN Batch 73/500 loss 33.070164 loss_att 26.869202 loss_ctc 47.539070 loss_ctc_origin 42.408676 loss_ctc0 59.509995 lr 0.00098090 rank 0
2022-08-23 19:51:52,974 DEBUG TRAIN Batch 73/600 loss 47.535255 loss_att 31.473648 loss_ctc 85.012329 loss_ctc_origin 61.916519 loss_ctc0 138.902542 lr 0.00098078 rank 0
2022-08-23 19:52:20,893 DEBUG TRAIN Batch 73/700 loss 21.687801 loss_att 12.232275 loss_ctc 43.750698 loss_ctc_origin 33.152939 loss_ctc0 68.478806 lr 0.00098067 rank 0
2022-08-23 19:52:49,026 DEBUG TRAIN Batch 73/800 loss 24.010807 loss_att 12.275449 loss_ctc 51.393311 loss_ctc_origin 38.019791 loss_ctc0 82.598190 lr 0.00098055 rank 0
2022-08-23 19:53:18,785 DEBUG TRAIN Batch 73/900 loss 29.414070 loss_att 14.438841 loss_ctc 64.356270 loss_ctc_origin 49.019295 loss_ctc0 100.142548 lr 0.00098043 rank 0
2022-08-23 19:53:46,827 DEBUG TRAIN Batch 73/1000 loss 27.038250 loss_att 22.446270 loss_ctc 37.752872 loss_ctc_origin 33.514450 loss_ctc0 47.642521 lr 0.00098031 rank 0
2022-08-23 19:54:15,777 DEBUG TRAIN Batch 73/1100 loss 38.872124 loss_att 27.073862 loss_ctc 66.401398 loss_ctc_origin 43.778282 loss_ctc0 119.188667 lr 0.00098019 rank 0
2022-08-23 19:54:45,122 DEBUG TRAIN Batch 73/1200 loss 26.301994 loss_att 14.751487 loss_ctc 53.253178 loss_ctc_origin 43.891708 loss_ctc0 75.096603 lr 0.00098008 rank 0
2022-08-23 19:55:14,924 DEBUG TRAIN Batch 73/1300 loss 25.294952 loss_att 11.975355 loss_ctc 56.374004 loss_ctc_origin 43.316139 loss_ctc0 86.842354 lr 0.00097996 rank 0
2022-08-23 19:55:43,798 DEBUG TRAIN Batch 73/1400 loss 27.491528 loss_att 13.104009 loss_ctc 61.062401 loss_ctc_origin 45.762894 loss_ctc0 96.761246 lr 0.00097984 rank 0
2022-08-23 19:56:18,706 DEBUG TRAIN Batch 73/1500 loss 27.956144 loss_att 21.099325 loss_ctc 43.955387 loss_ctc_origin 31.828283 loss_ctc0 72.251961 lr 0.00097972 rank 0
2022-08-23 19:56:47,759 DEBUG TRAIN Batch 73/1600 loss 38.207966 loss_att 25.866848 loss_ctc 67.003906 loss_ctc_origin 44.305302 loss_ctc0 119.967331 lr 0.00097961 rank 0
2022-08-23 19:57:16,566 DEBUG TRAIN Batch 73/1700 loss 25.258698 loss_att 15.821106 loss_ctc 47.279739 loss_ctc_origin 38.015900 loss_ctc0 68.895370 lr 0.00097949 rank 0
2022-08-23 19:57:45,668 DEBUG TRAIN Batch 73/1800 loss 25.368698 loss_att 11.216142 loss_ctc 58.391327 loss_ctc_origin 44.348843 loss_ctc0 91.157120 lr 0.00097937 rank 0
2022-08-23 19:58:14,001 DEBUG TRAIN Batch 73/1900 loss 29.261440 loss_att 14.675804 loss_ctc 63.294594 loss_ctc_origin 47.877949 loss_ctc0 99.266769 lr 0.00097925 rank 0
2022-08-23 19:58:42,912 DEBUG TRAIN Batch 73/2000 loss 27.814806 loss_att 21.412207 loss_ctc 42.754204 loss_ctc_origin 32.380157 loss_ctc0 66.960320 lr 0.00097914 rank 0
2022-08-23 19:59:10,695 DEBUG TRAIN Batch 73/2100 loss 32.706833 loss_att 21.691387 loss_ctc 58.409542 loss_ctc_origin 40.583759 loss_ctc0 100.003036 lr 0.00097902 rank 0
2022-08-23 19:59:39,664 DEBUG TRAIN Batch 73/2200 loss 24.357548 loss_att 15.238865 loss_ctc 45.634476 loss_ctc_origin 36.770103 loss_ctc0 66.318008 lr 0.00097890 rank 0
2022-08-23 19:59:45,122 WARNING NaN or Inf found in input tensor.
2022-08-23 20:00:08,003 DEBUG TRAIN Batch 73/2300 loss 21.629013 loss_att 11.019642 loss_ctc 46.384209 loss_ctc_origin 35.244865 loss_ctc0 72.376007 lr 0.00097878 rank 0
2022-08-23 20:00:37,395 DEBUG TRAIN Batch 73/2400 loss 28.035786 loss_att 14.077516 loss_ctc 60.605087 loss_ctc_origin 47.237366 loss_ctc0 91.796448 lr 0.00097867 rank 0
2022-08-23 20:01:07,369 DEBUG TRAIN Batch 73/2500 loss 29.465378 loss_att 23.471981 loss_ctc 43.449970 loss_ctc_origin 36.925331 loss_ctc0 58.674129 lr 0.00097855 rank 0
2022-08-23 20:01:35,375 DEBUG TRAIN Batch 73/2600 loss 27.317949 loss_att 17.498983 loss_ctc 50.228867 loss_ctc_origin 33.076042 loss_ctc0 90.252129 lr 0.00097843 rank 0
2022-08-23 20:02:03,553 DEBUG TRAIN Batch 73/2700 loss 23.343254 loss_att 13.636849 loss_ctc 45.991531 loss_ctc_origin 36.859970 loss_ctc0 67.298500 lr 0.00097832 rank 0
2022-08-23 20:02:31,529 DEBUG TRAIN Batch 73/2800 loss 21.417938 loss_att 10.839186 loss_ctc 46.101696 loss_ctc_origin 33.330086 loss_ctc0 75.902115 lr 0.00097820 rank 0
2022-08-23 20:03:01,860 DEBUG TRAIN Batch 73/2900 loss 28.281555 loss_att 13.765683 loss_ctc 62.151924 loss_ctc_origin 46.166359 loss_ctc0 99.451569 lr 0.00097808 rank 0
2022-08-23 20:03:36,058 DEBUG TRAIN Batch 73/3000 loss 31.617912 loss_att 25.026024 loss_ctc 46.998978 loss_ctc_origin 39.376831 loss_ctc0 64.783989 lr 0.00097797 rank 0
2022-08-23 20:04:05,277 DEBUG TRAIN Batch 73/3100 loss 35.316628 loss_att 22.709915 loss_ctc 64.732292 loss_ctc_origin 46.464249 loss_ctc0 107.357719 lr 0.00097785 rank 0
2022-08-23 20:04:34,701 DEBUG TRAIN Batch 73/3200 loss 29.043514 loss_att 17.652273 loss_ctc 55.623074 loss_ctc_origin 47.564430 loss_ctc0 74.426575 lr 0.00097773 rank 0
2022-08-23 20:05:03,426 DEBUG TRAIN Batch 73/3300 loss 31.181372 loss_att 16.821117 loss_ctc 64.688629 loss_ctc_origin 53.283478 loss_ctc0 91.300644 lr 0.00097761 rank 0
2022-08-23 20:05:31,908 DEBUG TRAIN Batch 73/3400 loss 31.476526 loss_att 16.329746 loss_ctc 66.819008 loss_ctc_origin 51.304821 loss_ctc0 103.018768 lr 0.00097750 rank 0
2022-08-23 20:06:01,014 DEBUG TRAIN Batch 73/3500 loss 35.086185 loss_att 27.426445 loss_ctc 52.958912 loss_ctc_origin 45.832115 loss_ctc0 69.588097 lr 0.00097738 rank 0
2022-08-23 20:06:29,415 DEBUG TRAIN Batch 73/3600 loss 29.713936 loss_att 18.886852 loss_ctc 54.977127 loss_ctc_origin 41.070023 loss_ctc0 87.427032 lr 0.00097726 rank 0
2022-08-23 20:06:58,306 DEBUG TRAIN Batch 73/3700 loss 29.648918 loss_att 18.709057 loss_ctc 55.175255 loss_ctc_origin 46.695095 loss_ctc0 74.962296 lr 0.00097715 rank 0
2022-08-23 20:07:26,979 DEBUG TRAIN Batch 73/3800 loss 24.243855 loss_att 11.893396 loss_ctc 53.061592 loss_ctc_origin 39.377991 loss_ctc0 84.989990 lr 0.00097703 rank 0
2022-08-23 20:07:56,118 DEBUG TRAIN Batch 73/3900 loss 26.528318 loss_att 12.942189 loss_ctc 58.229286 loss_ctc_origin 43.377224 loss_ctc0 92.884094 lr 0.00097691 rank 0
2022-08-23 20:08:24,732 DEBUG TRAIN Batch 73/4000 loss 26.236288 loss_att 20.295990 loss_ctc 40.096985 loss_ctc_origin 32.004517 loss_ctc0 58.979401 lr 0.00097680 rank 0
2022-08-23 20:08:52,180 DEBUG TRAIN Batch 73/4100 loss -27133.931641 loss_att 19.084534 loss_ctc -90490.968750 loss_ctc_origin 43.445351 loss_ctc0 -301737.937500 lr 0.00097668 rank 0
2022-08-23 20:09:20,783 DEBUG TRAIN Batch 73/4200 loss 26.695587 loss_att 15.375703 loss_ctc 53.108650 loss_ctc_origin 43.209312 loss_ctc0 76.207100 lr 0.00097657 rank 0
2022-08-23 20:09:32,566 WARNING NaN or Inf found in input tensor.
2022-08-23 20:09:48,746 DEBUG TRAIN Batch 73/4300 loss 27.186043 loss_att 14.660305 loss_ctc 56.412758 loss_ctc_origin 44.164642 loss_ctc0 84.991684 lr 0.00097645 rank 0
2022-08-23 20:10:18,048 DEBUG TRAIN Batch 73/4400 loss 31.827988 loss_att 15.993660 loss_ctc 68.774750 loss_ctc_origin 52.780968 loss_ctc0 106.093582 lr 0.00097633 rank 0
2022-08-23 20:10:53,242 DEBUG TRAIN Batch 73/4500 loss 30.315184 loss_att 24.038614 loss_ctc 44.960510 loss_ctc_origin 39.587883 loss_ctc0 57.496635 lr 0.00097622 rank 0
2022-08-23 20:11:22,320 DEBUG TRAIN Batch 73/4600 loss 32.645329 loss_att 20.782501 loss_ctc 60.325260 loss_ctc_origin 44.303761 loss_ctc0 97.708755 lr 0.00097610 rank 0
2022-08-23 20:11:51,897 DEBUG TRAIN Batch 73/4700 loss 24.068758 loss_att 15.345839 loss_ctc 44.422237 loss_ctc_origin 33.779369 loss_ctc0 69.255600 lr 0.00097598 rank 0
2022-08-23 20:12:20,424 DEBUG TRAIN Batch 73/4800 loss 22.261183 loss_att 10.604800 loss_ctc 49.459408 loss_ctc_origin 37.230785 loss_ctc0 77.992859 lr 0.00097587 rank 0
2022-08-23 20:12:31,369 WARNING NaN or Inf found in input tensor.
2022-08-23 20:12:48,734 DEBUG TRAIN Batch 73/4900 loss 30.309326 loss_att 15.049550 loss_ctc 65.915466 loss_ctc_origin 50.800770 loss_ctc0 101.183090 lr 0.00097575 rank 0
2022-08-23 20:13:18,453 DEBUG TRAIN Batch 73/5000 loss 30.114300 loss_att 22.580355 loss_ctc 47.693501 loss_ctc_origin 40.372250 loss_ctc0 64.776421 lr 0.00097564 rank 0
2022-08-23 20:13:46,400 DEBUG TRAIN Batch 73/5100 loss 30.961540 loss_att 21.826195 loss_ctc 52.277340 loss_ctc_origin 35.605247 loss_ctc0 91.178886 lr 0.00097552 rank 0
2022-08-23 20:14:14,435 DEBUG TRAIN Batch 73/5200 loss 25.639736 loss_att 16.962685 loss_ctc 45.886185 loss_ctc_origin 37.227081 loss_ctc0 66.090759 lr 0.00097540 rank 0
2022-08-23 20:14:42,948 DEBUG TRAIN Batch 73/5300 loss 24.104221 loss_att 13.170356 loss_ctc 49.616570 loss_ctc_origin 38.156311 loss_ctc0 76.357178 lr 0.00097529 rank 0
2022-08-23 20:15:06,516 WARNING NaN or Inf found in input tensor.
2022-08-23 20:15:10,964 DEBUG TRAIN Batch 73/5400 loss 31.310883 loss_att 16.886837 loss_ctc 64.966988 loss_ctc_origin 49.785652 loss_ctc0 100.390106 lr 0.00097517 rank 0
2022-08-23 20:15:39,474 DEBUG TRAIN Batch 73/5500 loss 26.755209 loss_att 20.518833 loss_ctc 41.306751 loss_ctc_origin 32.687786 loss_ctc0 61.417667 lr 0.00097506 rank 0
2022-08-23 20:16:07,364 DEBUG TRAIN Batch 73/5600 loss 31.174713 loss_att 21.423164 loss_ctc 53.928329 loss_ctc_origin 39.349899 loss_ctc0 87.944672 lr 0.00097494 rank 0
2022-08-23 20:16:29,822 DEBUG CV Batch 73/0 loss 15.526346 loss_att 11.523431 loss_ctc 24.866482 loss_ctc_origin 17.939396 loss_ctc0 41.029682 history loss 14.613032 rank 0
2022-08-23 20:16:40,919 DEBUG CV Batch 73/100 loss 23.891314 loss_att 18.150028 loss_ctc 37.287643 loss_ctc_origin 27.587091 loss_ctc0 59.922256 history loss 30.062020 rank 0
2022-08-23 20:16:50,227 DEBUG CV Batch 73/200 loss 28.259859 loss_att 22.197277 loss_ctc 42.405884 loss_ctc_origin 32.619541 loss_ctc0 65.240677 history loss 31.489529 rank 0
2022-08-23 20:17:00,256 DEBUG CV Batch 73/300 loss 27.247341 loss_att 20.133623 loss_ctc 43.846012 loss_ctc_origin 30.012220 loss_ctc0 76.124855 history loss 30.613445 rank 0
2022-08-23 20:17:10,832 DEBUG CV Batch 73/400 loss 41.315319 loss_att 33.020706 loss_ctc 60.669411 loss_ctc_origin 44.047050 loss_ctc0 99.454910 history loss 28.861134 rank 0
2022-08-23 20:17:21,606 DEBUG CV Batch 73/500 loss 20.529787 loss_att 15.561625 loss_ctc 32.122166 loss_ctc_origin 25.498825 loss_ctc0 47.576633 history loss 28.464686 rank 0
2022-08-23 20:17:32,452 DEBUG CV Batch 73/600 loss 20.945122 loss_att 14.179981 loss_ctc 36.730453 loss_ctc_origin 24.891172 loss_ctc0 64.355446 history loss 28.292150 rank 0
2022-08-23 20:17:42,842 DEBUG CV Batch 73/700 loss 21.059898 loss_att 14.412014 loss_ctc 36.571632 loss_ctc_origin 23.839094 loss_ctc0 66.280884 history loss 27.930848 rank 0
2022-08-23 20:17:53,601 DEBUG CV Batch 73/800 loss 24.013233 loss_att 18.311186 loss_ctc 37.318008 loss_ctc_origin 22.340019 loss_ctc0 72.266655 history loss 27.851447 rank 0
2022-08-23 20:18:03,930 INFO Epoch 73 CV info cv_loss 27.896164196038633
2022-08-23 20:18:03,931 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/73.pt
2022-08-23 20:18:04,379 INFO Epoch 74 TRAIN info lr 0.000974842246732059
2022-08-23 20:18:04,383 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 20:18:31,362 DEBUG TRAIN Batch 74/0 loss 31.598976 loss_att 25.220520 loss_ctc 46.482044 loss_ctc_origin 45.333355 loss_ctc0 49.162315 lr 0.00097484 rank 0
2022-08-23 20:18:59,922 DEBUG TRAIN Batch 74/100 loss 33.594246 loss_att 23.067001 loss_ctc 58.157822 loss_ctc_origin 44.581375 loss_ctc0 89.836197 lr 0.00097472 rank 0
2022-08-23 20:19:27,509 DEBUG TRAIN Batch 74/200 loss 25.604660 loss_att 16.445625 loss_ctc 46.975739 loss_ctc_origin 38.817261 loss_ctc0 66.012177 lr 0.00097461 rank 0
2022-08-23 20:19:55,928 DEBUG TRAIN Batch 74/300 loss 22.498316 loss_att 11.257442 loss_ctc 48.727016 loss_ctc_origin 34.825142 loss_ctc0 81.164719 lr 0.00097449 rank 0
2022-08-23 20:20:19,876 WARNING NaN or Inf found in input tensor.
2022-08-23 20:20:24,343 DEBUG TRAIN Batch 74/400 loss 31.698053 loss_att 16.608936 loss_ctc 66.905991 loss_ctc_origin 53.458061 loss_ctc0 98.284485 lr 0.00097437 rank 0
2022-08-23 20:20:53,227 DEBUG TRAIN Batch 74/500 loss 28.123516 loss_att 22.846474 loss_ctc 40.436615 loss_ctc_origin 37.138103 loss_ctc0 48.133141 lr 0.00097426 rank 0
2022-08-23 20:21:20,408 DEBUG TRAIN Batch 74/600 loss 34.178085 loss_att 22.928909 loss_ctc 60.426155 loss_ctc_origin 46.628754 loss_ctc0 92.620094 lr 0.00097414 rank 0
2022-08-23 20:21:49,276 DEBUG TRAIN Batch 74/700 loss 31.163834 loss_att 20.243458 loss_ctc 56.644703 loss_ctc_origin 47.603287 loss_ctc0 77.741341 lr 0.00097403 rank 0
2022-08-23 20:22:16,843 DEBUG TRAIN Batch 74/800 loss 26.174112 loss_att 12.768993 loss_ctc 57.452721 loss_ctc_origin 44.191998 loss_ctc0 88.394402 lr 0.00097391 rank 0
2022-08-23 20:22:45,999 DEBUG TRAIN Batch 74/900 loss 28.253067 loss_att 14.309862 loss_ctc 60.787212 loss_ctc_origin 44.430923 loss_ctc0 98.951881 lr 0.00097380 rank 0
2022-08-23 20:23:14,368 DEBUG TRAIN Batch 74/1000 loss 30.345552 loss_att 22.435711 loss_ctc 48.801849 loss_ctc_origin 42.930592 loss_ctc0 62.501442 lr 0.00097368 rank 0
2022-08-23 20:23:43,546 DEBUG TRAIN Batch 74/1100 loss 31.313419 loss_att 20.581364 loss_ctc 56.354874 loss_ctc_origin 43.836781 loss_ctc0 85.563766 lr 0.00097357 rank 0
2022-08-23 20:24:11,000 DEBUG TRAIN Batch 74/1200 loss 23.810974 loss_att 15.113436 loss_ctc 44.105228 loss_ctc_origin 34.119488 loss_ctc0 67.405289 lr 0.00097345 rank 0
2022-08-23 20:24:40,053 DEBUG TRAIN Batch 74/1300 loss 23.542561 loss_att 12.111814 loss_ctc 50.214302 loss_ctc_origin 38.627361 loss_ctc0 77.250504 lr 0.00097334 rank 0
2022-08-23 20:25:08,492 DEBUG TRAIN Batch 74/1400 loss 26.108871 loss_att 12.390621 loss_ctc 58.118118 loss_ctc_origin 40.132179 loss_ctc0 100.085297 lr 0.00097322 rank 0
2022-08-23 20:25:43,122 DEBUG TRAIN Batch 74/1500 loss 32.987366 loss_att 27.854069 loss_ctc 44.965057 loss_ctc_origin 40.402550 loss_ctc0 55.610901 lr 0.00097311 rank 0
2022-08-23 20:26:11,773 DEBUG TRAIN Batch 74/1600 loss 38.925606 loss_att 26.310760 loss_ctc 68.360245 loss_ctc_origin 50.110146 loss_ctc0 110.943787 lr 0.00097299 rank 0
2022-08-23 20:26:40,067 DEBUG TRAIN Batch 74/1700 loss 25.795088 loss_att 17.231430 loss_ctc 45.776955 loss_ctc_origin 37.021896 loss_ctc0 66.205414 lr 0.00097287 rank 0
2022-08-23 20:27:07,717 DEBUG TRAIN Batch 74/1800 loss 19.167570 loss_att 9.842493 loss_ctc 40.926079 loss_ctc_origin 28.681095 loss_ctc0 69.497711 lr 0.00097276 rank 0
2022-08-23 20:27:36,607 DEBUG TRAIN Batch 74/1900 loss 27.196159 loss_att 12.945044 loss_ctc 60.448761 loss_ctc_origin 43.749779 loss_ctc0 99.413055 lr 0.00097264 rank 0
2022-08-23 20:28:04,912 DEBUG TRAIN Batch 74/2000 loss 30.413612 loss_att 23.326170 loss_ctc 46.950974 loss_ctc_origin 39.031578 loss_ctc0 65.429565 lr 0.00097253 rank 0
2022-08-23 20:28:32,990 DEBUG TRAIN Batch 74/2100 loss 31.352409 loss_att 18.745316 loss_ctc 60.768959 loss_ctc_origin 40.716125 loss_ctc0 107.558907 lr 0.00097241 rank 0
2022-08-23 20:29:01,535 DEBUG TRAIN Batch 74/2200 loss 20.337648 loss_att 10.812189 loss_ctc 42.563721 loss_ctc_origin 32.040634 loss_ctc0 67.117584 lr 0.00097230 rank 0
2022-08-23 20:29:07,190 WARNING NaN or Inf found in input tensor.
2022-08-23 20:29:30,601 DEBUG TRAIN Batch 74/2300 loss 28.147665 loss_att 14.426038 loss_ctc 60.164791 loss_ctc_origin 46.846687 loss_ctc0 91.240372 lr 0.00097219 rank 0
2022-08-23 20:29:33,644 WARNING NaN or Inf found in input tensor.
2022-08-23 20:29:59,283 DEBUG TRAIN Batch 74/2400 loss 28.495159 loss_att 14.621109 loss_ctc 60.867939 loss_ctc_origin 45.564213 loss_ctc0 96.576630 lr 0.00097207 rank 0
2022-08-23 20:30:27,914 DEBUG TRAIN Batch 74/2500 loss 28.192316 loss_att 22.615467 loss_ctc 41.204964 loss_ctc_origin 36.109810 loss_ctc0 53.093658 lr 0.00097196 rank 0
2022-08-23 20:30:56,140 DEBUG TRAIN Batch 74/2600 loss 54.835823 loss_att 38.579849 loss_ctc 92.766434 loss_ctc_origin 63.765999 loss_ctc0 160.434097 lr 0.00097184 rank 0
2022-08-23 20:31:24,262 DEBUG TRAIN Batch 74/2700 loss 22.872515 loss_att 13.010844 loss_ctc 45.883080 loss_ctc_origin 35.517387 loss_ctc0 70.069687 lr 0.00097173 rank 0
2022-08-23 20:31:53,622 DEBUG TRAIN Batch 74/2800 loss 25.958607 loss_att 12.768472 loss_ctc 56.735592 loss_ctc_origin 42.941757 loss_ctc0 88.921204 lr 0.00097161 rank 0
2022-08-23 20:32:22,040 DEBUG TRAIN Batch 74/2900 loss 26.788567 loss_att 13.692150 loss_ctc 57.346870 loss_ctc_origin 40.875805 loss_ctc0 95.779358 lr 0.00097150 rank 0
2022-08-23 20:32:57,757 DEBUG TRAIN Batch 74/3000 loss 33.331200 loss_att 27.340349 loss_ctc 47.309841 loss_ctc_origin 42.727596 loss_ctc0 58.001747 lr 0.00097138 rank 0
2022-08-23 20:33:05,727 WARNING NaN or Inf found in input tensor.
2022-08-23 20:33:27,495 DEBUG TRAIN Batch 74/3100 loss 49.595909 loss_att 31.447227 loss_ctc 91.942825 loss_ctc_origin 58.248589 loss_ctc0 170.562698 lr 0.00097127 rank 0
2022-08-23 20:33:55,496 DEBUG TRAIN Batch 74/3200 loss 25.178598 loss_att 15.053972 loss_ctc 48.802723 loss_ctc_origin 37.796593 loss_ctc0 74.483688 lr 0.00097115 rank 0
2022-08-23 20:34:00,827 WARNING NaN or Inf found in input tensor.
2022-08-23 20:34:24,106 DEBUG TRAIN Batch 74/3300 loss 23.001240 loss_att 11.561571 loss_ctc 49.693794 loss_ctc_origin 37.884892 loss_ctc0 77.247902 lr 0.00097104 rank 0
2022-08-23 20:34:53,496 DEBUG TRAIN Batch 74/3400 loss 23.616238 loss_att 12.000658 loss_ctc 50.719254 loss_ctc_origin 36.286934 loss_ctc0 84.394669 lr 0.00097092 rank 0
2022-08-23 20:35:23,080 DEBUG TRAIN Batch 74/3500 loss 39.008789 loss_att 30.082359 loss_ctc 59.837128 loss_ctc_origin 47.657394 loss_ctc0 88.256493 lr 0.00097081 rank 0
2022-08-23 20:35:52,170 DEBUG TRAIN Batch 74/3600 loss 47.191410 loss_att 31.122616 loss_ctc 84.685257 loss_ctc_origin 50.169823 loss_ctc0 165.221283 lr 0.00097070 rank 0
2022-08-23 20:36:21,350 DEBUG TRAIN Batch 74/3700 loss 22.684277 loss_att 12.413115 loss_ctc 46.650318 loss_ctc_origin 34.708248 loss_ctc0 74.515152 lr 0.00097058 rank 0
2022-08-23 20:36:50,347 DEBUG TRAIN Batch 74/3800 loss 25.173819 loss_att 12.013926 loss_ctc 55.880234 loss_ctc_origin 42.848106 loss_ctc0 86.288528 lr 0.00097047 rank 0
2022-08-23 20:37:19,163 DEBUG TRAIN Batch 74/3900 loss 26.996763 loss_att 13.394318 loss_ctc 58.735798 loss_ctc_origin 41.674988 loss_ctc0 98.544350 lr 0.00097035 rank 0
2022-08-23 20:37:21,773 WARNING NaN or Inf found in input tensor.
2022-08-23 20:37:48,093 DEBUG TRAIN Batch 74/4000 loss 32.910027 loss_att 22.689190 loss_ctc 56.758652 loss_ctc_origin 40.761543 loss_ctc0 94.085236 lr 0.00097024 rank 0
2022-08-23 20:38:16,276 DEBUG TRAIN Batch 74/4100 loss 42.009178 loss_att 26.449741 loss_ctc 78.314529 loss_ctc_origin 51.249023 loss_ctc0 141.467377 lr 0.00097012 rank 0
2022-08-23 20:38:45,213 DEBUG TRAIN Batch 74/4200 loss 20.484446 loss_att 11.958759 loss_ctc 40.377712 loss_ctc_origin 28.748550 loss_ctc0 67.512421 lr 0.00097001 rank 0
2022-08-23 20:39:12,997 DEBUG TRAIN Batch 74/4300 loss 23.714024 loss_att 10.618007 loss_ctc 54.271389 loss_ctc_origin 41.299095 loss_ctc0 84.540070 lr 0.00096990 rank 0
2022-08-23 20:39:31,179 WARNING NaN or Inf found in input tensor.
2022-08-23 20:39:42,909 DEBUG TRAIN Batch 74/4400 loss 29.332447 loss_att 16.132652 loss_ctc 60.131966 loss_ctc_origin 43.227348 loss_ctc0 99.576073 lr 0.00096978 rank 0
2022-08-23 20:40:19,510 DEBUG TRAIN Batch 74/4500 loss 35.237358 loss_att 28.279716 loss_ctc 51.471848 loss_ctc_origin 41.850357 loss_ctc0 73.921982 lr 0.00096967 rank 0
2022-08-23 20:40:34,543 WARNING NaN or Inf found in input tensor.
2022-08-23 20:40:48,728 DEBUG TRAIN Batch 74/4600 loss 32.779881 loss_att 20.278463 loss_ctc 61.949852 loss_ctc_origin 37.748211 loss_ctc0 118.420341 lr 0.00096955 rank 0
2022-08-23 20:41:16,868 DEBUG TRAIN Batch 74/4700 loss 25.881992 loss_att 15.007816 loss_ctc 51.255066 loss_ctc_origin 41.345348 loss_ctc0 74.377731 lr 0.00096944 rank 0
2022-08-23 20:41:45,596 DEBUG TRAIN Batch 74/4800 loss 23.118248 loss_att 11.641327 loss_ctc 49.897728 loss_ctc_origin 37.089355 loss_ctc0 79.783936 lr 0.00096933 rank 0
2022-08-23 20:42:15,430 DEBUG TRAIN Batch 74/4900 loss 29.455570 loss_att 14.781233 loss_ctc 63.695686 loss_ctc_origin 48.818836 loss_ctc0 98.408340 lr 0.00096921 rank 0
2022-08-23 20:42:43,711 DEBUG TRAIN Batch 74/5000 loss 25.850796 loss_att 19.472477 loss_ctc 40.733540 loss_ctc_origin 31.299492 loss_ctc0 62.746319 lr 0.00096910 rank 0
2022-08-23 20:43:12,259 DEBUG TRAIN Batch 74/5100 loss 34.663727 loss_att 20.058475 loss_ctc 68.742645 loss_ctc_origin 40.400314 loss_ctc0 134.874741 lr 0.00096898 rank 0
2022-08-23 20:43:40,188 DEBUG TRAIN Batch 74/5200 loss 23.546577 loss_att 14.258749 loss_ctc 45.218174 loss_ctc_origin 35.451958 loss_ctc0 68.006012 lr 0.00096887 rank 0
2022-08-23 20:43:45,469 WARNING NaN or Inf found in input tensor.
2022-08-23 20:44:08,628 DEBUG TRAIN Batch 74/5300 loss 27.161743 loss_att 14.070839 loss_ctc 57.707184 loss_ctc_origin 46.718597 loss_ctc0 83.347214 lr 0.00096876 rank 0
2022-08-23 20:44:36,976 DEBUG TRAIN Batch 74/5400 loss 26.803036 loss_att 13.334024 loss_ctc 58.230728 loss_ctc_origin 42.899357 loss_ctc0 94.003937 lr 0.00096864 rank 0
2022-08-23 20:45:06,876 DEBUG TRAIN Batch 74/5500 loss 33.450584 loss_att 26.244528 loss_ctc 50.264713 loss_ctc_origin 41.643677 loss_ctc0 70.380463 lr 0.00096853 rank 0
2022-08-23 20:45:07,586 WARNING NaN or Inf found in input tensor.
2022-08-23 20:45:35,531 DEBUG TRAIN Batch 74/5600 loss 36.648087 loss_att 23.516008 loss_ctc 67.289604 loss_ctc_origin 42.799278 loss_ctc0 124.433701 lr 0.00096842 rank 0
2022-08-23 20:45:58,994 DEBUG CV Batch 74/0 loss 20.727425 loss_att 13.579247 loss_ctc 37.406502 loss_ctc_origin 21.137306 loss_ctc0 75.367966 history loss 19.508164 rank 0
2022-08-23 20:46:09,808 DEBUG CV Batch 74/100 loss 30.771088 loss_att 22.169724 loss_ctc 50.840935 loss_ctc_origin 32.447166 loss_ctc0 93.759720 history loss 31.785003 rank 0
2022-08-23 20:46:19,885 DEBUG CV Batch 74/200 loss 28.616093 loss_att 21.321054 loss_ctc 45.637848 loss_ctc_origin 33.770927 loss_ctc0 73.327332 history loss 33.408109 rank 0
2022-08-23 20:46:30,011 DEBUG CV Batch 74/300 loss 25.229710 loss_att 18.503510 loss_ctc 40.924179 loss_ctc_origin 25.913212 loss_ctc0 75.949768 history loss 32.384105 rank 0
2022-08-23 20:46:40,915 DEBUG CV Batch 74/400 loss 41.813030 loss_att 33.641548 loss_ctc 60.879822 loss_ctc_origin 44.338013 loss_ctc0 99.477371 history loss 30.474286 rank 0
2022-08-23 20:46:52,029 DEBUG CV Batch 74/500 loss 25.574650 loss_att 18.567425 loss_ctc 41.924839 loss_ctc_origin 30.130812 loss_ctc0 69.444237 history loss 30.120136 rank 0
2022-08-23 20:47:02,770 DEBUG CV Batch 74/600 loss 25.040663 loss_att 15.721456 loss_ctc 46.785477 loss_ctc_origin 27.182117 loss_ctc0 92.526657 history loss 30.046047 rank 0
2022-08-23 20:47:13,126 DEBUG CV Batch 74/700 loss 21.864359 loss_att 15.261040 loss_ctc 37.272102 loss_ctc_origin 24.429230 loss_ctc0 67.238808 history loss 29.712176 rank 0
2022-08-23 20:47:23,614 DEBUG CV Batch 74/800 loss 23.842972 loss_att 18.469501 loss_ctc 36.381065 loss_ctc_origin 21.068357 loss_ctc0 72.110710 history loss 29.619351 rank 0
2022-08-23 20:47:34,148 INFO Epoch 74 CV info cv_loss 29.60974164866782
2022-08-23 20:47:34,149 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/74.pt
2022-08-23 20:47:34,615 INFO Epoch 75 TRAIN info lr 0.0009683214896235446
2022-08-23 20:47:34,618 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 20:48:00,799 DEBUG TRAIN Batch 75/0 loss 28.861279 loss_att 24.089874 loss_ctc 39.994553 loss_ctc_origin 36.631531 loss_ctc0 47.841606 lr 0.00096832 rank 0
2022-08-23 20:48:08,916 WARNING NaN or Inf found in input tensor.
2022-08-23 20:48:29,040 WARNING NaN or Inf found in input tensor.
2022-08-23 20:48:29,083 DEBUG TRAIN Batch 75/100 loss nan loss_att 22.609795 loss_ctc nan loss_ctc_origin 43.000813 loss_ctc0 nan lr 0.00096820 rank 0
2022-08-23 20:48:56,803 DEBUG TRAIN Batch 75/200 loss 21.492260 loss_att 11.964529 loss_ctc 43.723633 loss_ctc_origin 33.945736 loss_ctc0 66.538719 lr 0.00096809 rank 0
2022-08-23 20:49:24,364 DEBUG TRAIN Batch 75/300 loss 25.504478 loss_att 13.748159 loss_ctc 52.935890 loss_ctc_origin 40.962303 loss_ctc0 80.874252 lr 0.00096798 rank 0
2022-08-23 20:49:53,019 DEBUG TRAIN Batch 75/400 loss 26.352623 loss_att 13.443889 loss_ctc 56.473000 loss_ctc_origin 39.101112 loss_ctc0 97.007393 lr 0.00096786 rank 0
2022-08-23 20:50:22,478 DEBUG TRAIN Batch 75/500 loss 31.920364 loss_att 24.801439 loss_ctc 48.531185 loss_ctc_origin 41.025059 loss_ctc0 66.045479 lr 0.00096775 rank 0
2022-08-23 20:50:23,173 WARNING NaN or Inf found in input tensor.
2022-08-23 20:50:50,615 DEBUG TRAIN Batch 75/600 loss 34.961590 loss_att 22.594879 loss_ctc 63.817242 loss_ctc_origin 43.979836 loss_ctc0 110.104523 lr 0.00096764 rank 0
2022-08-23 20:51:18,776 DEBUG TRAIN Batch 75/700 loss 24.445887 loss_att 14.176560 loss_ctc 48.407646 loss_ctc_origin 38.974236 loss_ctc0 70.418938 lr 0.00096752 rank 0
2022-08-23 20:51:37,324 WARNING NaN or Inf found in input tensor.
2022-08-23 20:51:46,955 DEBUG TRAIN Batch 75/800 loss 25.400116 loss_att 13.054348 loss_ctc 54.206902 loss_ctc_origin 40.434242 loss_ctc0 86.343109 lr 0.00096741 rank 0
2022-08-23 20:52:16,264 DEBUG TRAIN Batch 75/900 loss 32.034187 loss_att 16.721077 loss_ctc 67.764778 loss_ctc_origin 52.579697 loss_ctc0 103.196632 lr 0.00096730 rank 0
2022-08-23 20:52:45,527 DEBUG TRAIN Batch 75/1000 loss 28.733826 loss_att 23.778099 loss_ctc 40.297184 loss_ctc_origin 35.394150 loss_ctc0 51.737595 lr 0.00096718 rank 0
2022-08-23 20:53:14,231 DEBUG TRAIN Batch 75/1100 loss 34.554771 loss_att 21.738363 loss_ctc 64.459717 loss_ctc_origin 40.817276 loss_ctc0 119.625412 lr 0.00096707 rank 0
2022-08-23 20:53:42,378 DEBUG TRAIN Batch 75/1200 loss 23.948284 loss_att 13.788207 loss_ctc 47.655128 loss_ctc_origin 36.725853 loss_ctc0 73.156776 lr 0.00096696 rank 0
2022-08-23 20:54:11,849 DEBUG TRAIN Batch 75/1300 loss 26.261356 loss_att 14.100826 loss_ctc 54.635925 loss_ctc_origin 40.470459 loss_ctc0 87.688683 lr 0.00096684 rank 0
2022-08-23 20:54:40,520 DEBUG TRAIN Batch 75/1400 loss 32.901653 loss_att 16.269894 loss_ctc 71.709091 loss_ctc_origin 57.069809 loss_ctc0 105.867416 lr 0.00096673 rank 0
2022-08-23 20:55:17,075 DEBUG TRAIN Batch 75/1500 loss 28.372795 loss_att 20.033897 loss_ctc 47.830223 loss_ctc_origin 38.831009 loss_ctc0 68.828384 lr 0.00096662 rank 0
2022-08-23 20:55:45,922 DEBUG TRAIN Batch 75/1600 loss 32.660118 loss_att 20.264347 loss_ctc 61.583580 loss_ctc_origin 48.190353 loss_ctc0 92.834442 lr 0.00096651 rank 0
2022-08-23 20:56:14,431 DEBUG TRAIN Batch 75/1700 loss 27.177193 loss_att 17.017685 loss_ctc 50.882713 loss_ctc_origin 41.737450 loss_ctc0 72.221649 lr 0.00096639 rank 0
2022-08-23 20:56:43,728 DEBUG TRAIN Batch 75/1800 loss 25.767918 loss_att 13.789431 loss_ctc 53.717716 loss_ctc_origin 41.544167 loss_ctc0 82.122665 lr 0.00096628 rank 0
2022-08-23 20:57:11,780 DEBUG TRAIN Batch 75/1900 loss 27.493328 loss_att 14.134155 loss_ctc 58.664726 loss_ctc_origin 42.335533 loss_ctc0 96.766182 lr 0.00096617 rank 0
2022-08-23 20:57:41,163 DEBUG TRAIN Batch 75/2000 loss 27.867647 loss_att 20.461166 loss_ctc 45.149437 loss_ctc_origin 36.818268 loss_ctc0 64.588837 lr 0.00096606 rank 0
2022-08-23 20:58:09,200 DEBUG TRAIN Batch 75/2100 loss 36.095692 loss_att 22.648165 loss_ctc 67.473251 loss_ctc_origin 45.054531 loss_ctc0 119.783585 lr 0.00096594 rank 0
2022-08-23 20:58:37,750 DEBUG TRAIN Batch 75/2200 loss 24.414076 loss_att 14.320217 loss_ctc 47.966412 loss_ctc_origin 37.993568 loss_ctc0 71.236382 lr 0.00096583 rank 0
2022-08-23 20:59:05,444 DEBUG TRAIN Batch 75/2300 loss 22.526937 loss_att 10.284514 loss_ctc 51.092590 loss_ctc_origin 40.013275 loss_ctc0 76.944321 lr 0.00096572 rank 0
2022-08-23 20:59:34,881 DEBUG TRAIN Batch 75/2400 loss 27.388134 loss_att 13.215361 loss_ctc 60.457939 loss_ctc_origin 42.218163 loss_ctc0 103.017410 lr 0.00096560 rank 0
2022-08-23 21:00:04,931 DEBUG TRAIN Batch 75/2500 loss 34.566338 loss_att 26.802759 loss_ctc 52.681358 loss_ctc_origin 45.369774 loss_ctc0 69.741730 lr 0.00096549 rank 0
2022-08-23 21:00:20,213 WARNING NaN or Inf found in input tensor.
2022-08-23 21:00:35,079 DEBUG TRAIN Batch 75/2600 loss 34.988373 loss_att 24.140196 loss_ctc 60.300781 loss_ctc_origin 41.845745 loss_ctc0 103.362526 lr 0.00096538 rank 0
2022-08-23 21:01:04,206 DEBUG TRAIN Batch 75/2700 loss 22.332365 loss_att 12.269174 loss_ctc 45.813141 loss_ctc_origin 34.305222 loss_ctc0 72.664955 lr 0.00096527 rank 0
2022-08-23 21:01:33,106 DEBUG TRAIN Batch 75/2800 loss 22.283974 loss_att 11.355988 loss_ctc 47.782608 loss_ctc_origin 34.796829 loss_ctc0 78.082764 lr 0.00096515 rank 0
2022-08-23 21:02:01,003 DEBUG TRAIN Batch 75/2900 loss 26.268761 loss_att 12.359188 loss_ctc 58.724430 loss_ctc_origin 44.178715 loss_ctc0 92.664429 lr 0.00096504 rank 0
2022-08-23 21:02:35,899 DEBUG TRAIN Batch 75/3000 loss 25.739422 loss_att 20.349470 loss_ctc 38.315979 loss_ctc_origin 32.670925 loss_ctc0 51.487774 lr 0.00096493 rank 0
2022-08-23 21:03:04,381 DEBUG TRAIN Batch 75/3100 loss 32.002735 loss_att 22.224447 loss_ctc 54.818737 loss_ctc_origin 37.781837 loss_ctc0 94.571495 lr 0.00096482 rank 0
2022-08-23 21:03:31,094 WARNING NaN or Inf found in input tensor.
2022-08-23 21:03:32,791 DEBUG TRAIN Batch 75/3200 loss 23.795322 loss_att 14.344611 loss_ctc 45.846985 loss_ctc_origin 36.128014 loss_ctc0 68.524574 lr 0.00096471 rank 0
2022-08-23 21:04:01,567 DEBUG TRAIN Batch 75/3300 loss 25.333069 loss_att 13.258270 loss_ctc 53.507599 loss_ctc_origin 42.031334 loss_ctc0 80.285553 lr 0.00096459 rank 0
2022-08-23 21:04:25,990 WARNING NaN or Inf found in input tensor.
2022-08-23 21:04:30,613 DEBUG TRAIN Batch 75/3400 loss 24.917152 loss_att 11.898647 loss_ctc 55.293667 loss_ctc_origin 37.646717 loss_ctc0 96.469879 lr 0.00096448 rank 0
2022-08-23 21:04:59,483 DEBUG TRAIN Batch 75/3500 loss 28.794102 loss_att 23.180323 loss_ctc 41.892925 loss_ctc_origin 35.368782 loss_ctc0 57.115929 lr 0.00096437 rank 0
2022-08-23 21:05:27,475 DEBUG TRAIN Batch 75/3600 loss 30.680119 loss_att 19.024382 loss_ctc 57.876839 loss_ctc_origin 36.099121 loss_ctc0 108.691513 lr 0.00096426 rank 0
2022-08-23 21:05:54,018 DEBUG TRAIN Batch 75/3700 loss 23.983715 loss_att 14.709280 loss_ctc 45.624062 loss_ctc_origin 35.795258 loss_ctc0 68.557938 lr 0.00096414 rank 0
2022-08-23 21:06:23,143 DEBUG TRAIN Batch 75/3800 loss 24.192978 loss_att 11.000880 loss_ctc 54.974537 loss_ctc_origin 38.278481 loss_ctc0 93.931999 lr 0.00096403 rank 0
2022-08-23 21:06:52,340 DEBUG TRAIN Batch 75/3900 loss 25.421122 loss_att 12.372511 loss_ctc 55.867882 loss_ctc_origin 37.982349 loss_ctc0 97.600784 lr 0.00096392 rank 0
2022-08-23 21:07:22,140 DEBUG TRAIN Batch 75/4000 loss 29.700645 loss_att 21.608490 loss_ctc 48.582336 loss_ctc_origin 37.917915 loss_ctc0 73.465981 lr 0.00096381 rank 0
2022-08-23 21:07:52,400 DEBUG TRAIN Batch 75/4100 loss 23.310883 loss_att 13.571624 loss_ctc 46.035820 loss_ctc_origin 27.774527 loss_ctc0 88.645508 lr 0.00096370 rank 0
2022-08-23 21:08:19,928 DEBUG TRAIN Batch 75/4200 loss 22.720118 loss_att 12.615958 loss_ctc 46.296486 loss_ctc_origin 34.887814 loss_ctc0 72.916718 lr 0.00096359 rank 0
2022-08-23 21:08:48,057 DEBUG TRAIN Batch 75/4300 loss 25.533957 loss_att 12.045664 loss_ctc 57.006638 loss_ctc_origin 45.974976 loss_ctc0 82.747185 lr 0.00096347 rank 0
2022-08-23 21:09:15,180 DEBUG TRAIN Batch 75/4400 loss 30.615671 loss_att 15.338639 loss_ctc 66.262077 loss_ctc_origin 51.262039 loss_ctc0 101.262169 lr 0.00096336 rank 0
2022-08-23 21:09:48,948 DEBUG TRAIN Batch 75/4500 loss 30.498039 loss_att 24.512428 loss_ctc 44.464462 loss_ctc_origin 35.136269 loss_ctc0 66.230247 lr 0.00096325 rank 0
2022-08-23 21:10:16,004 DEBUG TRAIN Batch 75/4600 loss 29.351505 loss_att 17.653679 loss_ctc 56.646435 loss_ctc_origin 36.253845 loss_ctc0 104.229141 lr 0.00096314 rank 0
2022-08-23 21:10:43,871 DEBUG TRAIN Batch 75/4700 loss 20.878761 loss_att 12.078653 loss_ctc 41.412346 loss_ctc_origin 32.187275 loss_ctc0 62.937508 lr 0.00096303 rank 0
2022-08-23 21:11:11,180 DEBUG TRAIN Batch 75/4800 loss 23.755295 loss_att 12.281417 loss_ctc 50.527672 loss_ctc_origin 38.211063 loss_ctc0 79.266426 lr 0.00096291 rank 0
2022-08-23 21:11:38,611 DEBUG TRAIN Batch 75/4900 loss 28.068413 loss_att 15.277945 loss_ctc 57.912834 loss_ctc_origin 42.287792 loss_ctc0 94.371262 lr 0.00096280 rank 0
2022-08-23 21:12:05,930 DEBUG TRAIN Batch 75/5000 loss 31.473488 loss_att 23.986771 loss_ctc 48.942497 loss_ctc_origin 39.468987 loss_ctc0 71.047348 lr 0.00096269 rank 0
2022-08-23 21:12:32,604 DEBUG TRAIN Batch 75/5100 loss 33.410980 loss_att 22.876305 loss_ctc 57.991898 loss_ctc_origin 41.161110 loss_ctc0 97.263725 lr 0.00096258 rank 0
2022-08-23 21:12:59,083 DEBUG TRAIN Batch 75/5200 loss 23.571102 loss_att 14.446396 loss_ctc 44.862080 loss_ctc_origin 35.982079 loss_ctc0 65.582085 lr 0.00096247 rank 0
2022-08-23 21:13:25,974 DEBUG TRAIN Batch 75/5300 loss 22.086084 loss_att 10.039671 loss_ctc 50.194382 loss_ctc_origin 36.773323 loss_ctc0 81.510193 lr 0.00096236 rank 0
2022-08-23 21:13:48,831 WARNING NaN or Inf found in input tensor.
2022-08-23 21:13:53,173 DEBUG TRAIN Batch 75/5400 loss 29.417873 loss_att 14.385343 loss_ctc 64.493774 loss_ctc_origin 48.589191 loss_ctc0 101.604477 lr 0.00096225 rank 0
2022-08-23 21:14:22,204 DEBUG TRAIN Batch 75/5500 loss 23.225166 loss_att 17.894121 loss_ctc 35.664272 loss_ctc_origin 33.202744 loss_ctc0 41.407837 lr 0.00096213 rank 0
2022-08-23 21:14:49,226 DEBUG TRAIN Batch 75/5600 loss 33.556515 loss_att 23.997688 loss_ctc 55.860439 loss_ctc_origin 38.023277 loss_ctc0 97.480484 lr 0.00096202 rank 0
2022-08-23 21:15:12,818 DEBUG CV Batch 75/0 loss 16.829819 loss_att 11.197550 loss_ctc 29.971779 loss_ctc_origin 18.354553 loss_ctc0 57.078636 history loss 15.839829 rank 0
2022-08-23 21:15:23,542 DEBUG CV Batch 75/100 loss 25.901711 loss_att 18.991634 loss_ctc 42.025223 loss_ctc_origin 26.286692 loss_ctc0 78.748466 history loss 30.582693 rank 0
2022-08-23 21:15:32,813 DEBUG CV Batch 75/200 loss 27.410515 loss_att 20.854326 loss_ctc 42.708290 loss_ctc_origin 33.049763 loss_ctc0 65.244843 history loss 31.857923 rank 0
2022-08-23 21:15:42,979 DEBUG CV Batch 75/300 loss 26.032248 loss_att 19.132441 loss_ctc 42.131798 loss_ctc_origin 27.436699 loss_ctc0 76.420364 history loss 30.884290 rank 0
2022-08-23 21:15:53,103 DEBUG CV Batch 75/400 loss 41.993752 loss_att 34.114044 loss_ctc 60.379738 loss_ctc_origin 43.787579 loss_ctc0 99.094772 history loss 29.148053 rank 0
2022-08-23 21:16:03,126 DEBUG CV Batch 75/500 loss 21.177479 loss_att 15.571334 loss_ctc 34.258484 loss_ctc_origin 25.523521 loss_ctc0 54.640053 history loss 28.800066 rank 0
2022-08-23 21:16:13,282 DEBUG CV Batch 75/600 loss 21.498486 loss_att 13.899458 loss_ctc 39.229553 loss_ctc_origin 24.568909 loss_ctc0 73.437729 history loss 28.708235 rank 0
2022-08-23 21:16:23,531 DEBUG CV Batch 75/700 loss 21.985611 loss_att 14.976894 loss_ctc 38.339287 loss_ctc_origin 25.990225 loss_ctc0 67.153763 history loss 28.364517 rank 0
2022-08-23 21:16:34,376 DEBUG CV Batch 75/800 loss 24.330906 loss_att 18.667320 loss_ctc 37.545937 loss_ctc_origin 22.830681 loss_ctc0 71.881531 history loss 28.294620 rank 0
2022-08-23 21:16:44,711 INFO Epoch 75 CV info cv_loss 28.361547526939137
2022-08-23 21:16:44,712 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/75.pt
2022-08-23 21:16:45,198 INFO Epoch 76 TRAIN info lr 0.0009619298587858559
2022-08-23 21:16:45,202 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 21:17:12,598 DEBUG TRAIN Batch 76/0 loss 28.317577 loss_att 22.651247 loss_ctc 41.539017 loss_ctc_origin 36.699413 loss_ctc0 52.831425 lr 0.00096193 rank 0
2022-08-23 21:17:41,452 DEBUG TRAIN Batch 76/100 loss 32.319420 loss_att 22.417030 loss_ctc 55.424999 loss_ctc_origin 41.691818 loss_ctc0 87.469086 lr 0.00096181 rank 0
2022-08-23 21:18:10,047 DEBUG TRAIN Batch 76/200 loss 24.028034 loss_att 14.175596 loss_ctc 47.017052 loss_ctc_origin 38.432816 loss_ctc0 67.046936 lr 0.00096170 rank 0
2022-08-23 21:18:15,532 WARNING NaN or Inf found in input tensor.
2022-08-23 21:18:38,180 DEBUG TRAIN Batch 76/300 loss 22.528358 loss_att 11.139447 loss_ctc 49.102478 loss_ctc_origin 34.407196 loss_ctc0 83.391457 lr 0.00096159 rank 0
2022-08-23 21:19:06,496 DEBUG TRAIN Batch 76/400 loss 27.343582 loss_att 13.491689 loss_ctc 59.664658 loss_ctc_origin 44.350857 loss_ctc0 95.396851 lr 0.00096148 rank 0
2022-08-23 21:19:34,912 DEBUG TRAIN Batch 76/500 loss 25.661091 loss_att 18.819233 loss_ctc 41.625427 loss_ctc_origin 35.371918 loss_ctc0 56.216942 lr 0.00096137 rank 0
2022-08-23 21:20:04,329 DEBUG TRAIN Batch 76/600 loss 38.048161 loss_att 25.560564 loss_ctc 67.185883 loss_ctc_origin 45.098999 loss_ctc0 118.721947 lr 0.00096126 rank 0
2022-08-23 21:20:22,897 WARNING NaN or Inf found in input tensor.
2022-08-23 21:20:31,693 DEBUG TRAIN Batch 76/700 loss 25.875031 loss_att 15.770217 loss_ctc 49.452930 loss_ctc_origin 39.381691 loss_ctc0 72.952492 lr 0.00096115 rank 0
2022-08-23 21:20:59,684 DEBUG TRAIN Batch 76/800 loss 23.494638 loss_att 10.006430 loss_ctc 54.967121 loss_ctc_origin 43.394943 loss_ctc0 81.968872 lr 0.00096104 rank 0
2022-08-23 21:21:28,114 DEBUG TRAIN Batch 76/900 loss 33.343067 loss_att 18.902647 loss_ctc 67.037376 loss_ctc_origin 51.214207 loss_ctc0 103.958099 lr 0.00096093 rank 0
2022-08-23 21:21:57,334 DEBUG TRAIN Batch 76/1000 loss 34.484787 loss_att 26.679527 loss_ctc 52.697052 loss_ctc_origin 44.409431 loss_ctc0 72.034836 lr 0.00096081 rank 0
2022-08-23 21:22:26,132 DEBUG TRAIN Batch 76/1100 loss 33.543934 loss_att 19.312471 loss_ctc 66.750679 loss_ctc_origin 39.609215 loss_ctc0 130.080750 lr 0.00096070 rank 0
2022-08-23 21:22:54,274 DEBUG TRAIN Batch 76/1200 loss 25.350191 loss_att 16.090603 loss_ctc 46.955894 loss_ctc_origin 38.293079 loss_ctc0 67.169128 lr 0.00096059 rank 0
2022-08-23 21:23:22,425 DEBUG TRAIN Batch 76/1300 loss 25.397583 loss_att 11.211937 loss_ctc 58.497421 loss_ctc_origin 45.975784 loss_ctc0 87.714577 lr 0.00096048 rank 0
2022-08-23 21:23:48,172 WARNING NaN or Inf found in input tensor.
2022-08-23 21:23:52,753 DEBUG TRAIN Batch 76/1400 loss 30.875652 loss_att 16.096561 loss_ctc 65.360199 loss_ctc_origin 49.440483 loss_ctc0 102.506210 lr 0.00096037 rank 0
2022-08-23 21:24:27,288 DEBUG TRAIN Batch 76/1500 loss 35.309334 loss_att 26.545441 loss_ctc 55.758408 loss_ctc_origin 45.265282 loss_ctc0 80.242371 lr 0.00096026 rank 0
2022-08-23 21:24:57,275 DEBUG TRAIN Batch 76/1600 loss 31.106102 loss_att 19.878433 loss_ctc 57.304001 loss_ctc_origin 38.153717 loss_ctc0 101.987999 lr 0.00096015 rank 0
2022-08-23 21:25:25,078 DEBUG TRAIN Batch 76/1700 loss 21.622894 loss_att 12.135914 loss_ctc 43.759182 loss_ctc_origin 34.333145 loss_ctc0 65.753265 lr 0.00096004 rank 0
2022-08-23 21:25:53,750 DEBUG TRAIN Batch 76/1800 loss 23.282116 loss_att 11.596596 loss_ctc 50.548332 loss_ctc_origin 37.595947 loss_ctc0 80.770554 lr 0.00095993 rank 0
2022-08-23 21:26:24,089 DEBUG TRAIN Batch 76/1900 loss 29.040115 loss_att 14.342114 loss_ctc 63.335449 loss_ctc_origin 47.482735 loss_ctc0 100.325104 lr 0.00095982 rank 0
2022-08-23 21:26:53,082 DEBUG TRAIN Batch 76/2000 loss 28.346769 loss_att 22.890486 loss_ctc 41.078094 loss_ctc_origin 33.636528 loss_ctc0 58.441750 lr 0.00095971 rank 0
2022-08-23 21:27:21,678 DEBUG TRAIN Batch 76/2100 loss 34.534103 loss_att 22.938274 loss_ctc 61.591045 loss_ctc_origin 46.355339 loss_ctc0 97.141022 lr 0.00095960 rank 0
2022-08-23 21:27:49,964 DEBUG TRAIN Batch 76/2200 loss 25.870106 loss_att 14.784214 loss_ctc 51.737190 loss_ctc_origin 42.305733 loss_ctc0 73.743927 lr 0.00095949 rank 0
2022-08-23 21:28:19,251 DEBUG TRAIN Batch 76/2300 loss 27.573233 loss_att 14.883123 loss_ctc 57.183487 loss_ctc_origin 46.633186 loss_ctc0 81.800842 lr 0.00095938 rank 0
2022-08-23 21:28:47,796 DEBUG TRAIN Batch 76/2400 loss 27.319618 loss_att 13.712608 loss_ctc 59.069305 loss_ctc_origin 43.372055 loss_ctc0 95.696228 lr 0.00095927 rank 0
2022-08-23 21:29:15,860 DEBUG TRAIN Batch 76/2500 loss 23.578829 loss_att 17.589293 loss_ctc 37.554413 loss_ctc_origin 33.584877 loss_ctc0 46.816666 lr 0.00095916 rank 0
2022-08-23 21:29:44,400 DEBUG TRAIN Batch 76/2600 loss 33.515400 loss_att 24.420444 loss_ctc 54.736961 loss_ctc_origin 38.539787 loss_ctc0 92.530365 lr 0.00095905 rank 0
2022-08-23 21:30:11,591 DEBUG TRAIN Batch 76/2700 loss 22.757109 loss_att 13.510737 loss_ctc 44.331974 loss_ctc_origin 34.962181 loss_ctc0 66.194824 lr 0.00095894 rank 0
2022-08-23 21:30:41,078 DEBUG TRAIN Batch 76/2800 loss 24.620661 loss_att 11.376345 loss_ctc 55.524059 loss_ctc_origin 43.368073 loss_ctc0 83.888023 lr 0.00095883 rank 0
2022-08-23 21:31:09,488 DEBUG TRAIN Batch 76/2900 loss 28.055923 loss_att 13.454301 loss_ctc 62.126373 loss_ctc_origin 47.028107 loss_ctc0 97.355667 lr 0.00095872 rank 0
2022-08-23 21:31:45,046 DEBUG TRAIN Batch 76/3000 loss 32.555321 loss_att 27.062006 loss_ctc 45.373062 loss_ctc_origin 39.422539 loss_ctc0 59.257618 lr 0.00095860 rank 0
2022-08-23 21:32:14,765 DEBUG TRAIN Batch 76/3100 loss 31.408669 loss_att 23.106710 loss_ctc 50.779900 loss_ctc_origin 38.020359 loss_ctc0 80.552155 lr 0.00095849 rank 0
2022-08-23 21:32:44,481 DEBUG TRAIN Batch 76/3200 loss 24.500278 loss_att 14.244961 loss_ctc 48.429348 loss_ctc_origin 39.393105 loss_ctc0 69.513916 lr 0.00095838 rank 0
2022-08-23 21:32:50,268 WARNING NaN or Inf found in input tensor.
2022-08-23 21:33:13,983 DEBUG TRAIN Batch 76/3300 loss 30.383770 loss_att 16.117182 loss_ctc 63.672478 loss_ctc_origin 54.587013 loss_ctc0 84.871902 lr 0.00095827 rank 0
2022-08-23 21:33:42,408 DEBUG TRAIN Batch 76/3400 loss 29.245026 loss_att 13.764235 loss_ctc 65.366867 loss_ctc_origin 49.622459 loss_ctc0 102.103813 lr 0.00095816 rank 0
2022-08-23 21:34:10,837 DEBUG TRAIN Batch 76/3500 loss 29.122686 loss_att 21.531698 loss_ctc 46.834991 loss_ctc_origin 40.236671 loss_ctc0 62.231075 lr 0.00095805 rank 0
2022-08-23 21:34:38,763 DEBUG TRAIN Batch 76/3600 loss 42.645218 loss_att 30.012291 loss_ctc 72.122040 loss_ctc_origin 45.899059 loss_ctc0 133.308975 lr 0.00095794 rank 0
2022-08-23 21:35:06,825 DEBUG TRAIN Batch 76/3700 loss 28.130417 loss_att 18.659445 loss_ctc 50.229355 loss_ctc_origin 41.622784 loss_ctc0 70.311356 lr 0.00095784 rank 0
2022-08-23 21:35:36,023 DEBUG TRAIN Batch 76/3800 loss 26.381464 loss_att 13.550968 loss_ctc 56.319286 loss_ctc_origin 43.328823 loss_ctc0 86.630363 lr 0.00095773 rank 0
2022-08-23 21:36:04,960 DEBUG TRAIN Batch 76/3900 loss 26.746231 loss_att 12.755367 loss_ctc 59.391579 loss_ctc_origin 43.344856 loss_ctc0 96.833939 lr 0.00095762 rank 0
2022-08-23 21:36:34,437 DEBUG TRAIN Batch 76/4000 loss 21.954956 loss_att 15.945274 loss_ctc 35.977551 loss_ctc_origin 31.834736 loss_ctc0 45.644119 lr 0.00095751 rank 0
2022-08-23 21:37:03,170 DEBUG TRAIN Batch 76/4100 loss 31.848759 loss_att 19.158335 loss_ctc 61.459751 loss_ctc_origin 35.517262 loss_ctc0 121.992218 lr 0.00095740 rank 0
2022-08-23 21:37:30,578 DEBUG TRAIN Batch 76/4200 loss 25.215776 loss_att 14.218653 loss_ctc 50.875732 loss_ctc_origin 43.332657 loss_ctc0 68.476242 lr 0.00095729 rank 0
2022-08-23 21:37:59,947 DEBUG TRAIN Batch 76/4300 loss 26.923801 loss_att 13.571790 loss_ctc 58.078491 loss_ctc_origin 44.521191 loss_ctc0 89.712181 lr 0.00095718 rank 0
2022-08-23 21:38:28,424 DEBUG TRAIN Batch 76/4400 loss 28.408607 loss_att 13.578308 loss_ctc 63.012634 loss_ctc_origin 48.603432 loss_ctc0 96.634109 lr 0.00095707 rank 0
2022-08-23 21:39:02,449 DEBUG TRAIN Batch 76/4500 loss 28.657032 loss_att 22.488091 loss_ctc 43.051231 loss_ctc_origin 34.214882 loss_ctc0 63.669388 lr 0.00095696 rank 0
2022-08-23 21:39:17,943 WARNING NaN or Inf found in input tensor.
2022-08-23 21:39:30,738 DEBUG TRAIN Batch 76/4600 loss 41.419048 loss_att 23.464155 loss_ctc 83.313797 loss_ctc_origin 46.273827 loss_ctc0 169.740387 lr 0.00095685 rank 0
2022-08-23 21:39:58,525 DEBUG TRAIN Batch 76/4700 loss 23.659744 loss_att 15.246878 loss_ctc 43.289764 loss_ctc_origin 34.326721 loss_ctc0 64.203537 lr 0.00095674 rank 0
2022-08-23 21:40:27,040 DEBUG TRAIN Batch 76/4800 loss 22.652691 loss_att 10.687918 loss_ctc 50.570496 loss_ctc_origin 37.133289 loss_ctc0 81.923981 lr 0.00095663 rank 0
2022-08-23 21:40:55,466 DEBUG TRAIN Batch 76/4900 loss 28.359634 loss_att 13.884069 loss_ctc 62.135956 loss_ctc_origin 47.210644 loss_ctc0 96.961678 lr 0.00095652 rank 0
2022-08-23 21:41:24,126 DEBUG TRAIN Batch 76/5000 loss 37.641884 loss_att 27.567110 loss_ctc 61.149693 loss_ctc_origin 44.705925 loss_ctc0 99.518478 lr 0.00095641 rank 0
2022-08-23 21:41:52,953 DEBUG TRAIN Batch 76/5100 loss 46.338043 loss_att 30.766693 loss_ctc 82.671188 loss_ctc_origin 53.809235 loss_ctc0 150.015747 lr 0.00095630 rank 0
2022-08-23 21:42:21,113 DEBUG TRAIN Batch 76/5200 loss 24.087015 loss_att 12.400623 loss_ctc 51.355263 loss_ctc_origin 40.001076 loss_ctc0 77.848358 lr 0.00095619 rank 0
2022-08-23 21:42:50,093 DEBUG TRAIN Batch 76/5300 loss 28.053505 loss_att 14.829628 loss_ctc 58.909218 loss_ctc_origin 47.598274 loss_ctc0 85.301422 lr 0.00095608 rank 0
2022-08-23 21:43:18,489 DEBUG TRAIN Batch 76/5400 loss 26.327101 loss_att 12.579986 loss_ctc 58.403702 loss_ctc_origin 40.963722 loss_ctc0 99.096992 lr 0.00095597 rank 0
2022-08-23 21:43:21,154 WARNING NaN or Inf found in input tensor.
2022-08-23 21:43:47,365 DEBUG TRAIN Batch 76/5500 loss 31.239536 loss_att 23.920212 loss_ctc 48.317963 loss_ctc_origin 39.980408 loss_ctc0 67.772255 lr 0.00095586 rank 0
2022-08-23 21:44:15,550 DEBUG TRAIN Batch 76/5600 loss 38.996506 loss_att 20.966789 loss_ctc 81.065842 loss_ctc_origin 38.566544 loss_ctc0 180.230865 lr 0.00095575 rank 0
2022-08-23 21:44:37,664 DEBUG CV Batch 76/0 loss 23.685284 loss_att 13.050079 loss_ctc 48.500763 loss_ctc_origin 20.560577 loss_ctc0 113.694534 history loss 22.292032 rank 0
2022-08-23 21:44:48,706 DEBUG CV Batch 76/100 loss 33.712463 loss_att 21.713949 loss_ctc 61.709000 loss_ctc_origin 31.398731 loss_ctc0 132.432953 history loss 32.372697 rank 0
2022-08-23 21:44:58,477 DEBUG CV Batch 76/200 loss 30.790159 loss_att 22.483610 loss_ctc 50.172104 loss_ctc_origin 35.966400 loss_ctc0 83.318748 history loss 34.467521 rank 0
2022-08-23 21:45:08,960 DEBUG CV Batch 76/300 loss 25.808086 loss_att 18.733803 loss_ctc 42.314743 loss_ctc_origin 27.587215 loss_ctc0 76.678978 history loss 33.470003 rank 0
2022-08-23 21:45:19,863 DEBUG CV Batch 76/400 loss 41.060616 loss_att 33.112350 loss_ctc 59.606575 loss_ctc_origin 42.726345 loss_ctc0 98.993767 history loss 31.493364 rank 0
2022-08-23 21:45:30,947 DEBUG CV Batch 76/500 loss 24.922077 loss_att 14.905096 loss_ctc 48.295036 loss_ctc_origin 25.933544 loss_ctc0 100.471848 history loss 31.022757 rank 0
2022-08-23 21:45:42,329 DEBUG CV Batch 76/600 loss 25.760780 loss_att 15.034540 loss_ctc 50.788673 loss_ctc_origin 26.246290 loss_ctc0 108.054230 history loss 30.885296 rank 0
2022-08-23 21:45:52,552 DEBUG CV Batch 76/700 loss 21.287979 loss_att 14.654408 loss_ctc 36.766312 loss_ctc_origin 24.136074 loss_ctc0 66.236862 history loss 30.482918 rank 0
2022-08-23 21:46:03,458 DEBUG CV Batch 76/800 loss 24.414082 loss_att 18.703705 loss_ctc 37.738289 loss_ctc_origin 22.436045 loss_ctc0 73.443527 history loss 30.382312 rank 0
2022-08-23 21:46:14,092 INFO Epoch 76 CV info cv_loss 30.354936486970622
2022-08-23 21:46:14,092 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/76.pt
2022-08-23 21:46:14,545 INFO Epoch 77 TRAIN info lr 0.0009556631480456693
2022-08-23 21:46:14,548 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 21:46:41,498 DEBUG TRAIN Batch 77/0 loss 25.626047 loss_att 21.404045 loss_ctc 35.477386 loss_ctc_origin 30.384720 loss_ctc0 47.360275 lr 0.00095566 rank 0
2022-08-23 21:47:10,169 DEBUG TRAIN Batch 77/100 loss 42.589146 loss_att 25.973644 loss_ctc 81.358643 loss_ctc_origin 42.007782 loss_ctc0 173.177307 lr 0.00095555 rank 0
2022-08-23 21:47:37,514 WARNING NaN or Inf found in input tensor.
2022-08-23 21:47:39,096 DEBUG TRAIN Batch 77/200 loss 23.047028 loss_att 13.313148 loss_ctc 45.759415 loss_ctc_origin 36.946529 loss_ctc0 66.322807 lr 0.00095544 rank 0
2022-08-23 21:48:06,973 DEBUG TRAIN Batch 77/300 loss 24.126766 loss_att 13.044758 loss_ctc 49.984787 loss_ctc_origin 37.167797 loss_ctc0 79.891098 lr 0.00095533 rank 0
2022-08-23 21:48:10,733 WARNING NaN or Inf found in input tensor.
2022-08-23 21:48:35,372 DEBUG TRAIN Batch 77/400 loss 24.444096 loss_att 11.966041 loss_ctc 53.559555 loss_ctc_origin 38.129154 loss_ctc0 89.563820 lr 0.00095522 rank 0
2022-08-23 21:49:04,486 DEBUG TRAIN Batch 77/500 loss 29.873280 loss_att 23.624979 loss_ctc 44.452644 loss_ctc_origin 34.325008 loss_ctc0 68.083801 lr 0.00095511 rank 0
2022-08-23 21:49:32,616 DEBUG TRAIN Batch 77/600 loss 41.623253 loss_att 27.478554 loss_ctc 74.627541 loss_ctc_origin 48.592148 loss_ctc0 135.376785 lr 0.00095500 rank 0
2022-08-23 21:50:00,167 DEBUG TRAIN Batch 77/700 loss 22.728397 loss_att 13.921864 loss_ctc 43.276974 loss_ctc_origin 34.790726 loss_ctc0 63.078217 lr 0.00095490 rank 0
2022-08-23 21:50:29,136 DEBUG TRAIN Batch 77/800 loss 25.982862 loss_att 13.071798 loss_ctc 56.108673 loss_ctc_origin 42.676945 loss_ctc0 87.449371 lr 0.00095479 rank 0
2022-08-23 21:50:57,523 DEBUG TRAIN Batch 77/900 loss 29.381090 loss_att 15.269674 loss_ctc 62.307724 loss_ctc_origin 46.655899 loss_ctc0 98.828636 lr 0.00095468 rank 0
2022-08-23 21:51:26,951 DEBUG TRAIN Batch 77/1000 loss 33.668716 loss_att 24.418594 loss_ctc 55.252338 loss_ctc_origin 42.238121 loss_ctc0 85.618843 lr 0.00095457 rank 0
2022-08-23 21:51:54,593 DEBUG TRAIN Batch 77/1100 loss 42.324905 loss_att 26.444574 loss_ctc 79.379013 loss_ctc_origin 46.297928 loss_ctc0 156.568207 lr 0.00095446 rank 0
2022-08-23 21:52:23,224 DEBUG TRAIN Batch 77/1200 loss 19.589653 loss_att 10.298278 loss_ctc 41.269524 loss_ctc_origin 29.544603 loss_ctc0 68.627670 lr 0.00095435 rank 0
2022-08-23 21:52:51,585 DEBUG TRAIN Batch 77/1300 loss 24.026398 loss_att 12.439944 loss_ctc 51.061455 loss_ctc_origin 38.198082 loss_ctc0 81.075989 lr 0.00095424 rank 0
2022-08-23 21:53:16,208 WARNING NaN or Inf found in input tensor.
2022-08-23 21:53:20,854 DEBUG TRAIN Batch 77/1400 loss 27.172270 loss_att 13.729760 loss_ctc 58.538124 loss_ctc_origin 41.202000 loss_ctc0 98.989075 lr 0.00095414 rank 0
2022-08-23 21:53:56,011 DEBUG TRAIN Batch 77/1500 loss 37.259430 loss_att 26.388716 loss_ctc 62.624420 loss_ctc_origin 51.327137 loss_ctc0 88.984741 lr 0.00095403 rank 0
2022-08-23 21:54:24,639 DEBUG TRAIN Batch 77/1600 loss 35.843071 loss_att 23.495907 loss_ctc 64.653114 loss_ctc_origin 41.496819 loss_ctc0 118.684471 lr 0.00095392 rank 0
2022-08-23 21:54:54,118 DEBUG TRAIN Batch 77/1700 loss 24.680054 loss_att 13.922623 loss_ctc 49.780724 loss_ctc_origin 39.188484 loss_ctc0 74.495941 lr 0.00095381 rank 0
2022-08-23 21:55:23,143 DEBUG TRAIN Batch 77/1800 loss 21.667255 loss_att 10.094992 loss_ctc 48.669205 loss_ctc_origin 33.130859 loss_ctc0 84.925339 lr 0.00095370 rank 0
2022-08-23 21:55:52,149 DEBUG TRAIN Batch 77/1900 loss 30.147308 loss_att 13.832043 loss_ctc 68.216255 loss_ctc_origin 50.838417 loss_ctc0 108.764542 lr 0.00095359 rank 0
2022-08-23 21:56:21,148 DEBUG TRAIN Batch 77/2000 loss 31.081314 loss_att 27.601871 loss_ctc 39.200012 loss_ctc_origin 36.150154 loss_ctc0 46.316349 lr 0.00095348 rank 0
2022-08-23 21:56:49,739 DEBUG TRAIN Batch 77/2100 loss 37.882446 loss_att 22.932735 loss_ctc 72.765106 loss_ctc_origin 42.952713 loss_ctc0 142.327362 lr 0.00095338 rank 0
2022-08-23 21:57:18,669 DEBUG TRAIN Batch 77/2200 loss 28.082640 loss_att 18.505013 loss_ctc 50.430435 loss_ctc_origin 41.960182 loss_ctc0 70.194351 lr 0.00095327 rank 0
2022-08-23 21:57:47,981 DEBUG TRAIN Batch 77/2300 loss 28.524837 loss_att 14.696444 loss_ctc 60.791092 loss_ctc_origin 48.052818 loss_ctc0 90.513741 lr 0.00095316 rank 0
2022-08-23 21:58:12,397 WARNING NaN or Inf found in input tensor.
2022-08-23 21:58:16,760 DEBUG TRAIN Batch 77/2400 loss 26.014076 loss_att 12.075411 loss_ctc 58.537624 loss_ctc_origin 41.345497 loss_ctc0 98.652588 lr 0.00095305 rank 0
2022-08-23 21:58:44,390 DEBUG TRAIN Batch 77/2500 loss 25.645803 loss_att 20.657463 loss_ctc 37.285263 loss_ctc_origin 33.636166 loss_ctc0 45.799831 lr 0.00095294 rank 0
2022-08-23 21:59:12,915 DEBUG TRAIN Batch 77/2600 loss 41.627338 loss_att 25.290407 loss_ctc 79.746841 loss_ctc_origin 48.397072 loss_ctc0 152.896317 lr 0.00095283 rank 0
2022-08-23 21:59:41,407 DEBUG TRAIN Batch 77/2700 loss 28.607410 loss_att 17.359711 loss_ctc 54.852043 loss_ctc_origin 45.809879 loss_ctc0 75.950424 lr 0.00095273 rank 0
2022-08-23 22:00:10,769 DEBUG TRAIN Batch 77/2800 loss 27.247601 loss_att 13.443297 loss_ctc 59.457634 loss_ctc_origin 47.202682 loss_ctc0 88.052521 lr 0.00095262 rank 0
2022-08-23 22:00:39,975 DEBUG TRAIN Batch 77/2900 loss 27.498402 loss_att 14.008942 loss_ctc 58.973808 loss_ctc_origin 44.883728 loss_ctc0 91.850662 lr 0.00095251 rank 0
2022-08-23 22:01:14,330 DEBUG TRAIN Batch 77/3000 loss 37.132965 loss_att 28.879025 loss_ctc 56.392166 loss_ctc_origin 49.181747 loss_ctc0 73.216476 lr 0.00095240 rank 0
2022-08-23 22:01:42,892 DEBUG TRAIN Batch 77/3100 loss 37.610054 loss_att 22.555696 loss_ctc 72.736885 loss_ctc_origin 42.383743 loss_ctc0 143.560883 lr 0.00095229 rank 0
2022-08-23 22:02:09,817 DEBUG TRAIN Batch 77/3200 loss 23.052677 loss_att 13.474222 loss_ctc 45.402409 loss_ctc_origin 33.712273 loss_ctc0 72.679390 lr 0.00095219 rank 0
2022-08-23 22:02:37,887 DEBUG TRAIN Batch 77/3300 loss 25.957169 loss_att 13.796778 loss_ctc 54.331413 loss_ctc_origin 41.847111 loss_ctc0 83.461456 lr 0.00095208 rank 0
2022-08-23 22:03:07,273 DEBUG TRAIN Batch 77/3400 loss 26.658432 loss_att 12.550358 loss_ctc 59.577274 loss_ctc_origin 43.131115 loss_ctc0 97.951645 lr 0.00095197 rank 0
2022-08-23 22:03:36,255 DEBUG TRAIN Batch 77/3500 loss 26.686436 loss_att 20.886963 loss_ctc 40.218536 loss_ctc_origin 37.142593 loss_ctc0 47.395733 lr 0.00095186 rank 0
2022-08-23 22:04:04,153 WARNING NaN or Inf found in input tensor.
2022-08-23 22:04:04,945 DEBUG TRAIN Batch 77/3600 loss 35.683899 loss_att 21.502893 loss_ctc 68.772911 loss_ctc_origin 39.709209 loss_ctc0 136.588211 lr 0.00095176 rank 0
2022-08-23 22:04:31,174 WARNING NaN or Inf found in input tensor.
2022-08-23 22:04:32,917 DEBUG TRAIN Batch 77/3700 loss 23.210800 loss_att 13.297739 loss_ctc 46.341278 loss_ctc_origin 35.617485 loss_ctc0 71.363464 lr 0.00095165 rank 0
2022-08-23 22:05:02,474 DEBUG TRAIN Batch 77/3800 loss 25.483070 loss_att 13.765152 loss_ctc 52.824883 loss_ctc_origin 40.676659 loss_ctc0 81.170738 lr 0.00095154 rank 0
2022-08-23 22:05:32,207 DEBUG TRAIN Batch 77/3900 loss 26.253643 loss_att 12.748171 loss_ctc 57.766407 loss_ctc_origin 40.958847 loss_ctc0 96.984047 lr 0.00095143 rank 0
2022-08-23 22:05:47,411 WARNING NaN or Inf found in input tensor.
2022-08-23 22:06:01,031 DEBUG TRAIN Batch 77/4000 loss 34.853859 loss_att 25.004429 loss_ctc 57.835854 loss_ctc_origin 38.560753 loss_ctc0 102.811081 lr 0.00095132 rank 0
2022-08-23 22:06:29,898 DEBUG TRAIN Batch 77/4100 loss 39.890953 loss_att 23.538239 loss_ctc 78.047287 loss_ctc_origin 44.935307 loss_ctc0 155.308563 lr 0.00095122 rank 0
2022-08-23 22:06:58,243 DEBUG TRAIN Batch 77/4200 loss 24.517056 loss_att 16.494997 loss_ctc 43.235191 loss_ctc_origin 34.158360 loss_ctc0 64.414474 lr 0.00095111 rank 0
2022-08-23 22:07:27,295 DEBUG TRAIN Batch 77/4300 loss 25.128670 loss_att 12.677383 loss_ctc 54.181671 loss_ctc_origin 42.010590 loss_ctc0 82.580864 lr 0.00095100 rank 0
2022-08-23 22:07:55,708 DEBUG TRAIN Batch 77/4400 loss 28.438488 loss_att 15.151096 loss_ctc 59.442406 loss_ctc_origin 45.498768 loss_ctc0 91.977570 lr 0.00095089 rank 0
2022-08-23 22:08:30,892 DEBUG TRAIN Batch 77/4500 loss 32.478767 loss_att 23.326117 loss_ctc 53.834957 loss_ctc_origin 38.524796 loss_ctc0 89.558670 lr 0.00095079 rank 0
2022-08-23 22:08:59,531 DEBUG TRAIN Batch 77/4600 loss 33.756378 loss_att 17.948824 loss_ctc 70.640663 loss_ctc_origin 36.540062 loss_ctc0 150.208740 lr 0.00095068 rank 0
2022-08-23 22:09:27,819 DEBUG TRAIN Batch 77/4700 loss 25.262609 loss_att 15.394917 loss_ctc 48.287220 loss_ctc_origin 39.695766 loss_ctc0 68.333939 lr 0.00095057 rank 0
2022-08-23 22:09:33,402 WARNING NaN or Inf found in input tensor.
2022-08-23 22:09:56,208 DEBUG TRAIN Batch 77/4800 loss 26.606716 loss_att 14.691007 loss_ctc 54.410034 loss_ctc_origin 41.389137 loss_ctc0 84.792130 lr 0.00095046 rank 0
2022-08-23 22:10:25,205 DEBUG TRAIN Batch 77/4900 loss 27.211704 loss_att 12.453030 loss_ctc 61.648613 loss_ctc_origin 47.777016 loss_ctc0 94.015686 lr 0.00095036 rank 0
2022-08-23 22:10:54,624 DEBUG TRAIN Batch 77/5000 loss 36.960754 loss_att 25.528316 loss_ctc 63.636444 loss_ctc_origin 41.527111 loss_ctc0 115.224884 lr 0.00095025 rank 0
2022-08-23 22:11:22,683 DEBUG TRAIN Batch 77/5100 loss 40.499893 loss_att 24.263302 loss_ctc 78.385269 loss_ctc_origin 47.988747 loss_ctc0 149.310471 lr 0.00095014 rank 0
2022-08-23 22:11:51,350 DEBUG TRAIN Batch 77/5200 loss 25.009377 loss_att 15.396664 loss_ctc 47.439037 loss_ctc_origin 38.166542 loss_ctc0 69.074860 lr 0.00095004 rank 0
2022-08-23 22:12:19,879 DEBUG TRAIN Batch 77/5300 loss 24.802620 loss_att 13.190827 loss_ctc 51.896805 loss_ctc_origin 40.523026 loss_ctc0 78.435623 lr 0.00094993 rank 0
2022-08-23 22:12:50,308 DEBUG TRAIN Batch 77/5400 loss 27.071932 loss_att 13.413275 loss_ctc 58.942131 loss_ctc_origin 42.724930 loss_ctc0 96.782272 lr 0.00094982 rank 0
2022-08-23 22:13:18,539 DEBUG TRAIN Batch 77/5500 loss 30.777184 loss_att 21.844387 loss_ctc 51.620377 loss_ctc_origin 35.694942 loss_ctc0 88.779716 lr 0.00094971 rank 0
2022-08-23 22:13:47,189 DEBUG TRAIN Batch 77/5600 loss 36.517403 loss_att 21.585285 loss_ctc 71.359009 loss_ctc_origin 41.038647 loss_ctc0 142.106506 lr 0.00094961 rank 0
2022-08-23 22:14:10,450 DEBUG CV Batch 77/0 loss 22.344013 loss_att 12.467567 loss_ctc 45.389053 loss_ctc_origin 21.010904 loss_ctc0 102.271400 history loss 21.029659 rank 0
2022-08-23 22:14:21,593 DEBUG CV Batch 77/100 loss 29.713440 loss_att 19.204468 loss_ctc 54.234367 loss_ctc_origin 29.245968 loss_ctc0 112.540634 history loss 31.782989 rank 0
2022-08-23 22:14:31,472 DEBUG CV Batch 77/200 loss 25.993198 loss_att 19.113180 loss_ctc 42.046577 loss_ctc_origin 30.767704 loss_ctc0 68.363953 history loss 33.107068 rank 0
2022-08-23 22:14:41,829 DEBUG CV Batch 77/300 loss 25.888020 loss_att 19.127312 loss_ctc 41.663002 loss_ctc_origin 25.957233 loss_ctc0 78.309792 history loss 32.250758 rank 0
2022-08-23 22:14:53,028 DEBUG CV Batch 77/400 loss 40.953945 loss_att 32.446980 loss_ctc 60.803532 loss_ctc_origin 43.233578 loss_ctc0 101.800087 history loss 30.476178 rank 0
2022-08-23 22:15:04,469 DEBUG CV Batch 77/500 loss 23.368778 loss_att 14.907959 loss_ctc 43.110687 loss_ctc_origin 24.801319 loss_ctc0 85.832535 history loss 30.081985 rank 0
2022-08-23 22:15:15,094 DEBUG CV Batch 77/600 loss 23.156841 loss_att 12.877659 loss_ctc 47.141594 loss_ctc_origin 22.670696 loss_ctc0 104.240356 history loss 29.966921 rank 0
2022-08-23 22:15:25,409 DEBUG CV Batch 77/700 loss 21.830513 loss_att 14.972940 loss_ctc 37.831512 loss_ctc_origin 24.595932 loss_ctc0 68.714539 history loss 29.589717 rank 0
2022-08-23 22:15:35,881 DEBUG CV Batch 77/800 loss 24.082262 loss_att 18.032566 loss_ctc 38.198219 loss_ctc_origin 23.048798 loss_ctc0 73.546867 history loss 29.515180 rank 0
2022-08-23 22:15:46,506 INFO Epoch 77 CV info cv_loss 29.523030880483187
2022-08-23 22:15:46,507 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/77.pt
2022-08-23 22:15:47,005 INFO Epoch 78 TRAIN info lr 0.0009495173405810938
2022-08-23 22:15:47,008 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 22:16:14,235 DEBUG TRAIN Batch 78/0 loss 24.290768 loss_att 16.878105 loss_ctc 41.586975 loss_ctc_origin 31.472891 loss_ctc0 65.186508 lr 0.00094951 rank 0
2022-08-23 22:16:22,304 WARNING NaN or Inf found in input tensor.
2022-08-23 22:16:42,603 DEBUG TRAIN Batch 78/100 loss 41.679962 loss_att 25.026754 loss_ctc 80.537437 loss_ctc_origin 47.213837 loss_ctc0 158.292496 lr 0.00094941 rank 0
2022-08-23 22:16:56,886 WARNING NaN or Inf found in input tensor.
2022-08-23 22:17:10,824 DEBUG TRAIN Batch 78/200 loss 21.871347 loss_att 13.187401 loss_ctc 42.133888 loss_ctc_origin 32.650589 loss_ctc0 64.261581 lr 0.00094930 rank 0
2022-08-23 22:17:39,479 DEBUG TRAIN Batch 78/300 loss 22.479967 loss_att 10.167794 loss_ctc 51.208366 loss_ctc_origin 37.709007 loss_ctc0 82.706863 lr 0.00094919 rank 0
2022-08-23 22:18:08,304 DEBUG TRAIN Batch 78/400 loss 31.026283 loss_att 16.950762 loss_ctc 63.869164 loss_ctc_origin 49.192112 loss_ctc0 98.115608 lr 0.00094909 rank 0
2022-08-23 22:18:37,292 DEBUG TRAIN Batch 78/500 loss 26.100962 loss_att 21.657299 loss_ctc 36.469505 loss_ctc_origin 31.015554 loss_ctc0 49.195396 lr 0.00094898 rank 0
2022-08-23 22:19:05,622 DEBUG TRAIN Batch 78/600 loss 24.917061 loss_att 16.027077 loss_ctc 45.660355 loss_ctc_origin 29.604675 loss_ctc0 83.123611 lr 0.00094887 rank 0
2022-08-23 22:19:34,679 DEBUG TRAIN Batch 78/700 loss 21.093361 loss_att 13.463707 loss_ctc 38.895885 loss_ctc_origin 28.234127 loss_ctc0 63.773319 lr 0.00094876 rank 0
2022-08-23 22:19:40,216 WARNING NaN or Inf found in input tensor.
2022-08-23 22:20:03,217 DEBUG TRAIN Batch 78/800 loss 25.460480 loss_att 13.353737 loss_ctc 53.709549 loss_ctc_origin 42.772232 loss_ctc0 79.229958 lr 0.00094866 rank 0
2022-08-23 22:20:32,143 DEBUG TRAIN Batch 78/900 loss 33.739296 loss_att 17.917904 loss_ctc 70.655869 loss_ctc_origin 54.260098 loss_ctc0 108.912659 lr 0.00094855 rank 0
2022-08-23 22:21:00,916 DEBUG TRAIN Batch 78/1000 loss 25.569521 loss_att 19.785009 loss_ctc 39.066715 loss_ctc_origin 34.934029 loss_ctc0 48.709656 lr 0.00094844 rank 0
2022-08-23 22:21:27,803 DEBUG TRAIN Batch 78/1100 loss 33.608540 loss_att 21.239712 loss_ctc 62.469135 loss_ctc_origin 40.156136 loss_ctc0 114.532791 lr 0.00094834 rank 0
2022-08-23 22:21:56,301 DEBUG TRAIN Batch 78/1200 loss 24.266411 loss_att 14.763968 loss_ctc 46.438774 loss_ctc_origin 36.836617 loss_ctc0 68.843811 lr 0.00094823 rank 0
2022-08-23 22:22:07,622 WARNING NaN or Inf found in input tensor.
2022-08-23 22:22:24,517 DEBUG TRAIN Batch 78/1300 loss 23.278957 loss_att 11.638845 loss_ctc 50.439217 loss_ctc_origin 38.777210 loss_ctc0 77.650566 lr 0.00094813 rank 0
2022-08-23 22:22:52,962 DEBUG TRAIN Batch 78/1400 loss 33.165493 loss_att 17.223511 loss_ctc 70.363449 loss_ctc_origin 55.982277 loss_ctc0 103.919525 lr 0.00094802 rank 0
2022-08-23 22:23:28,552 DEBUG TRAIN Batch 78/1500 loss 30.298683 loss_att 23.420546 loss_ctc 46.347668 loss_ctc_origin 36.937809 loss_ctc0 68.304001 lr 0.00094791 rank 0
2022-08-23 22:23:56,668 DEBUG TRAIN Batch 78/1600 loss 34.110615 loss_att 22.292065 loss_ctc 61.687225 loss_ctc_origin 42.828712 loss_ctc0 105.690414 lr 0.00094781 rank 0
2022-08-23 22:24:24,910 DEBUG TRAIN Batch 78/1700 loss 21.142239 loss_att 11.630308 loss_ctc 43.336739 loss_ctc_origin 32.567764 loss_ctc0 68.464355 lr 0.00094770 rank 0
2022-08-23 22:24:53,020 DEBUG TRAIN Batch 78/1800 loss 19.651072 loss_att 9.718103 loss_ctc 42.827995 loss_ctc_origin 29.351486 loss_ctc0 74.273178 lr 0.00094759 rank 0
2022-08-23 22:25:22,413 DEBUG TRAIN Batch 78/1900 loss 28.273600 loss_att 12.936794 loss_ctc 64.059479 loss_ctc_origin 48.566872 loss_ctc0 100.208878 lr 0.00094749 rank 0
2022-08-23 22:25:52,041 DEBUG TRAIN Batch 78/2000 loss 28.364033 loss_att 21.726303 loss_ctc 43.852066 loss_ctc_origin 36.795715 loss_ctc0 60.316883 lr 0.00094738 rank 0
2022-08-23 22:25:59,873 WARNING NaN or Inf found in input tensor.
2022-08-23 22:26:20,563 DEBUG TRAIN Batch 78/2100 loss 34.073013 loss_att 23.258099 loss_ctc 59.307823 loss_ctc_origin 42.879356 loss_ctc0 97.640907 lr 0.00094727 rank 0
2022-08-23 22:26:48,652 DEBUG TRAIN Batch 78/2200 loss 26.177979 loss_att 14.492364 loss_ctc 53.444408 loss_ctc_origin 43.606377 loss_ctc0 76.399811 lr 0.00094717 rank 0
2022-08-23 22:27:16,883 DEBUG TRAIN Batch 78/2300 loss 24.266609 loss_att 11.039036 loss_ctc 55.130943 loss_ctc_origin 43.836784 loss_ctc0 81.483978 lr 0.00094706 rank 0
2022-08-23 22:27:20,679 WARNING NaN or Inf found in input tensor.
2022-08-23 22:27:34,059 WARNING NaN or Inf found in input tensor.
2022-08-23 22:27:45,697 DEBUG TRAIN Batch 78/2400 loss 27.276047 loss_att 13.788755 loss_ctc 58.746395 loss_ctc_origin 41.918365 loss_ctc0 98.011795 lr 0.00094696 rank 0
2022-08-23 22:28:14,110 DEBUG TRAIN Batch 78/2500 loss 28.955526 loss_att 22.202234 loss_ctc 44.713207 loss_ctc_origin 36.689270 loss_ctc0 63.435726 lr 0.00094685 rank 0
2022-08-23 22:28:42,423 DEBUG TRAIN Batch 78/2600 loss 27.939875 loss_att 18.211996 loss_ctc 50.638256 loss_ctc_origin 32.838623 loss_ctc0 92.170731 lr 0.00094674 rank 0
2022-08-23 22:29:11,341 DEBUG TRAIN Batch 78/2700 loss 22.835011 loss_att 13.279839 loss_ctc 45.130409 loss_ctc_origin 33.794090 loss_ctc0 71.581818 lr 0.00094664 rank 0
2022-08-23 22:29:40,672 DEBUG TRAIN Batch 78/2800 loss 24.514112 loss_att 11.705873 loss_ctc 54.400005 loss_ctc_origin 41.076195 loss_ctc0 85.488892 lr 0.00094653 rank 0
2022-08-23 22:30:09,871 DEBUG TRAIN Batch 78/2900 loss 24.333073 loss_att 10.835021 loss_ctc 55.828522 loss_ctc_origin 38.697803 loss_ctc0 95.800201 lr 0.00094642 rank 0
2022-08-23 22:30:44,228 DEBUG TRAIN Batch 78/3000 loss 29.975750 loss_att 23.711540 loss_ctc 44.592239 loss_ctc_origin 37.906326 loss_ctc0 60.192703 lr 0.00094632 rank 0
2022-08-23 22:31:12,351 DEBUG TRAIN Batch 78/3100 loss 34.435707 loss_att 24.548676 loss_ctc 57.505440 loss_ctc_origin 40.712456 loss_ctc0 96.689072 lr 0.00094621 rank 0
2022-08-23 22:31:18,853 WARNING NaN or Inf found in input tensor.
2022-08-23 22:31:38,282 WARNING NaN or Inf found in input tensor.
2022-08-23 22:31:39,907 DEBUG TRAIN Batch 78/3200 loss 26.176834 loss_att 16.164482 loss_ctc 49.538986 loss_ctc_origin 41.131126 loss_ctc0 69.157326 lr 0.00094611 rank 0
2022-08-23 22:32:07,609 DEBUG TRAIN Batch 78/3300 loss 25.147840 loss_att 14.155124 loss_ctc 50.797512 loss_ctc_origin 37.518360 loss_ctc0 81.782196 lr 0.00094600 rank 0
2022-08-23 22:32:36,112 DEBUG TRAIN Batch 78/3400 loss 24.907669 loss_att 11.697433 loss_ctc 55.731556 loss_ctc_origin 40.242378 loss_ctc0 91.872971 lr 0.00094590 rank 0
2022-08-23 22:33:05,239 DEBUG TRAIN Batch 78/3500 loss 33.406441 loss_att 24.266598 loss_ctc 54.732742 loss_ctc_origin 37.884590 loss_ctc0 94.045090 lr 0.00094579 rank 0
2022-08-23 22:33:33,928 DEBUG TRAIN Batch 78/3600 loss 39.456139 loss_att 23.766870 loss_ctc 76.064438 loss_ctc_origin 46.427021 loss_ctc0 145.218399 lr 0.00094568 rank 0
2022-08-23 22:34:01,980 DEBUG TRAIN Batch 78/3700 loss 23.065418 loss_att 14.523830 loss_ctc 42.995789 loss_ctc_origin 33.968987 loss_ctc0 64.058334 lr 0.00094558 rank 0
2022-08-23 22:34:31,610 DEBUG TRAIN Batch 78/3800 loss 23.289734 loss_att 12.149937 loss_ctc 49.282589 loss_ctc_origin 36.457897 loss_ctc0 79.206871 lr 0.00094547 rank 0
2022-08-23 22:35:00,020 DEBUG TRAIN Batch 78/3900 loss 29.362329 loss_att 15.504124 loss_ctc 61.698139 loss_ctc_origin 46.768997 loss_ctc0 96.532806 lr 0.00094537 rank 0
2022-08-23 22:35:30,121 DEBUG TRAIN Batch 78/4000 loss 29.761862 loss_att 21.507191 loss_ctc 49.022758 loss_ctc_origin 36.888268 loss_ctc0 77.336563 lr 0.00094526 rank 0
2022-08-23 22:35:59,262 DEBUG TRAIN Batch 78/4100 loss 30.965500 loss_att 22.689117 loss_ctc 50.277054 loss_ctc_origin 38.063507 loss_ctc0 78.775330 lr 0.00094516 rank 0
2022-08-23 22:36:27,592 DEBUG TRAIN Batch 78/4200 loss 25.161221 loss_att 15.039581 loss_ctc 48.778374 loss_ctc_origin 40.467972 loss_ctc0 68.169304 lr 0.00094505 rank 0
2022-08-23 22:36:57,815 DEBUG TRAIN Batch 78/4300 loss 22.059315 loss_att 10.944868 loss_ctc 47.993027 loss_ctc_origin 34.321957 loss_ctc0 79.892197 lr 0.00094494 rank 0
2022-08-23 22:37:25,802 DEBUG TRAIN Batch 78/4400 loss 29.000162 loss_att 15.115757 loss_ctc 61.397102 loss_ctc_origin 43.174492 loss_ctc0 103.916534 lr 0.00094484 rank 0
2022-08-23 22:38:02,964 DEBUG TRAIN Batch 78/4500 loss 30.982285 loss_att 26.504683 loss_ctc 41.430016 loss_ctc_origin 37.271652 loss_ctc0 51.132854 lr 0.00094473 rank 0
2022-08-23 22:38:32,428 DEBUG TRAIN Batch 78/4600 loss 29.592377 loss_att 21.368641 loss_ctc 48.781090 loss_ctc_origin 34.268196 loss_ctc0 82.644501 lr 0.00094463 rank 0
2022-08-23 22:39:00,795 DEBUG TRAIN Batch 78/4700 loss 26.380146 loss_att 16.039021 loss_ctc 50.509438 loss_ctc_origin 42.191582 loss_ctc0 69.917770 lr 0.00094452 rank 0
2022-08-23 22:39:29,678 DEBUG TRAIN Batch 78/4800 loss 25.313091 loss_att 13.869253 loss_ctc 52.015381 loss_ctc_origin 39.805981 loss_ctc0 80.503983 lr 0.00094442 rank 0
2022-08-23 22:39:58,367 DEBUG TRAIN Batch 78/4900 loss 27.486748 loss_att 14.590239 loss_ctc 57.578602 loss_ctc_origin 42.119461 loss_ctc0 93.649933 lr 0.00094431 rank 0
2022-08-23 22:40:27,562 DEBUG TRAIN Batch 78/5000 loss 32.733242 loss_att 26.874073 loss_ctc 46.404633 loss_ctc_origin 40.697586 loss_ctc0 59.721077 lr 0.00094421 rank 0
2022-08-23 22:40:55,142 DEBUG TRAIN Batch 78/5100 loss 34.004845 loss_att 22.537056 loss_ctc 60.763016 loss_ctc_origin 42.042366 loss_ctc0 104.444527 lr 0.00094410 rank 0
2022-08-23 22:41:24,805 DEBUG TRAIN Batch 78/5200 loss 21.420284 loss_att 13.104587 loss_ctc 40.823582 loss_ctc_origin 30.250401 loss_ctc0 65.494339 lr 0.00094400 rank 0
2022-08-23 22:41:30,200 WARNING NaN or Inf found in input tensor.
2022-08-23 22:41:52,225 DEBUG TRAIN Batch 78/5300 loss 27.022293 loss_att 13.882652 loss_ctc 57.681450 loss_ctc_origin 45.946991 loss_ctc0 85.061859 lr 0.00094389 rank 0
2022-08-23 22:42:20,704 DEBUG TRAIN Batch 78/5400 loss 27.385269 loss_att 13.755795 loss_ctc 59.187370 loss_ctc_origin 46.684578 loss_ctc0 88.360550 lr 0.00094379 rank 0
2022-08-23 22:42:49,925 DEBUG TRAIN Batch 78/5500 loss 24.122654 loss_att 18.778111 loss_ctc 36.593254 loss_ctc_origin 34.981247 loss_ctc0 40.354599 lr 0.00094368 rank 0
2022-08-23 22:43:17,753 DEBUG TRAIN Batch 78/5600 loss 41.671413 loss_att 25.251743 loss_ctc 79.983978 loss_ctc_origin 50.362366 loss_ctc0 149.101074 lr 0.00094358 rank 0
2022-08-23 22:43:41,262 DEBUG CV Batch 78/0 loss 17.134594 loss_att 11.272061 loss_ctc 30.813835 loss_ctc_origin 17.420128 loss_ctc0 62.065819 history loss 16.126677 rank 0
2022-08-23 22:43:52,308 DEBUG CV Batch 78/100 loss 24.435310 loss_att 18.367184 loss_ctc 38.594276 loss_ctc_origin 24.780159 loss_ctc0 70.827217 history loss 29.783167 rank 0
2022-08-23 22:44:02,344 DEBUG CV Batch 78/200 loss 25.869728 loss_att 19.494856 loss_ctc 40.744431 loss_ctc_origin 29.773449 loss_ctc0 66.343384 history loss 31.354130 rank 0
2022-08-23 22:44:12,546 DEBUG CV Batch 78/300 loss 26.675171 loss_att 19.996090 loss_ctc 42.259689 loss_ctc_origin 26.944893 loss_ctc0 77.994202 history loss 30.416032 rank 0
2022-08-23 22:44:23,532 DEBUG CV Batch 78/400 loss 40.873932 loss_att 33.110672 loss_ctc 58.988197 loss_ctc_origin 41.160015 loss_ctc0 100.587296 history loss 28.779903 rank 0
2022-08-23 22:44:34,823 DEBUG CV Batch 78/500 loss 25.610397 loss_att 16.971481 loss_ctc 45.767868 loss_ctc_origin 25.968683 loss_ctc0 91.965965 history loss 28.451874 rank 0
2022-08-23 22:44:45,707 DEBUG CV Batch 78/600 loss 19.432899 loss_att 13.115509 loss_ctc 34.173481 loss_ctc_origin 22.300325 loss_ctc0 61.877510 history loss 28.312152 rank 0
2022-08-23 22:44:56,018 DEBUG CV Batch 78/700 loss 21.996769 loss_att 14.916749 loss_ctc 38.516815 loss_ctc_origin 26.089075 loss_ctc0 67.514877 history loss 27.992737 rank 0
2022-08-23 22:45:06,627 DEBUG CV Batch 78/800 loss 23.879314 loss_att 18.070587 loss_ctc 37.433006 loss_ctc_origin 21.751385 loss_ctc0 74.023453 history loss 27.931187 rank 0
2022-08-23 22:45:17,181 INFO Epoch 78 CV info cv_loss 27.979830525346934
2022-08-23 22:45:17,181 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/78.pt
2022-08-23 22:45:17,632 INFO Epoch 79 TRAIN info lr 0.0009434885981011771
2022-08-23 22:45:17,636 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 22:45:44,143 DEBUG TRAIN Batch 79/0 loss 32.024097 loss_att 23.568130 loss_ctc 51.754684 loss_ctc_origin 40.921051 loss_ctc0 77.033157 lr 0.00094348 rank 0
2022-08-23 22:45:58,931 WARNING NaN or Inf found in input tensor.
2022-08-23 22:46:12,892 DEBUG TRAIN Batch 79/100 loss 32.698685 loss_att 23.621685 loss_ctc 53.878357 loss_ctc_origin 37.419922 loss_ctc0 92.281372 lr 0.00094338 rank 0
2022-08-23 22:46:40,328 WARNING NaN or Inf found in input tensor.
2022-08-23 22:46:42,002 DEBUG TRAIN Batch 79/200 loss 21.950241 loss_att 12.181959 loss_ctc 44.742897 loss_ctc_origin 33.786369 loss_ctc0 70.308136 lr 0.00094327 rank 0
2022-08-23 22:47:10,337 DEBUG TRAIN Batch 79/300 loss 22.595556 loss_att 11.208414 loss_ctc 49.165554 loss_ctc_origin 35.177277 loss_ctc0 81.804863 lr 0.00094317 rank 0
2022-08-23 22:47:39,072 DEBUG TRAIN Batch 79/400 loss 29.227684 loss_att 14.888464 loss_ctc 62.685860 loss_ctc_origin 45.436638 loss_ctc0 102.934044 lr 0.00094306 rank 0
2022-08-23 22:48:07,609 DEBUG TRAIN Batch 79/500 loss 20.696453 loss_att 14.550091 loss_ctc 35.037960 loss_ctc_origin 31.390240 loss_ctc0 43.549305 lr 0.00094296 rank 0
2022-08-23 22:48:34,606 DEBUG TRAIN Batch 79/600 loss 32.986847 loss_att 22.223179 loss_ctc 58.102074 loss_ctc_origin 36.078304 loss_ctc0 109.490875 lr 0.00094286 rank 0
2022-08-23 22:49:02,694 DEBUG TRAIN Batch 79/700 loss 22.499928 loss_att 13.610155 loss_ctc 43.242729 loss_ctc_origin 32.195869 loss_ctc0 69.018738 lr 0.00094275 rank 0
2022-08-23 22:49:08,023 WARNING NaN or Inf found in input tensor.
2022-08-23 22:49:20,616 WARNING NaN or Inf found in input tensor.
2022-08-23 22:49:30,718 DEBUG TRAIN Batch 79/800 loss 19.651373 loss_att 8.286255 loss_ctc 46.169983 loss_ctc_origin 32.931084 loss_ctc0 77.060745 lr 0.00094265 rank 0
2022-08-23 22:49:58,093 DEBUG TRAIN Batch 79/900 loss 25.984518 loss_att 12.529123 loss_ctc 57.380440 loss_ctc_origin 40.257832 loss_ctc0 97.333191 lr 0.00094254 rank 0
2022-08-23 22:50:26,908 DEBUG TRAIN Batch 79/1000 loss 35.741730 loss_att 25.726048 loss_ctc 59.111656 loss_ctc_origin 50.955940 loss_ctc0 78.141647 lr 0.00094244 rank 0
2022-08-23 22:50:47,472 WARNING NaN or Inf found in input tensor.
2022-08-23 22:50:54,588 DEBUG TRAIN Batch 79/1100 loss 37.001358 loss_att 22.996237 loss_ctc 69.679962 loss_ctc_origin 41.712780 loss_ctc0 134.936707 lr 0.00094233 rank 0
2022-08-23 22:51:22,878 DEBUG TRAIN Batch 79/1200 loss 23.908104 loss_att 14.767260 loss_ctc 45.236740 loss_ctc_origin 36.771843 loss_ctc0 64.988174 lr 0.00094223 rank 0
2022-08-23 22:51:50,080 DEBUG TRAIN Batch 79/1300 loss 19.751202 loss_att 10.476494 loss_ctc 41.392181 loss_ctc_origin 28.299061 loss_ctc0 71.942795 lr 0.00094212 rank 0
2022-08-23 22:52:13,386 WARNING NaN or Inf found in input tensor.
2022-08-23 22:52:18,229 DEBUG TRAIN Batch 79/1400 loss 27.967865 loss_att 12.694812 loss_ctc 63.604988 loss_ctc_origin 47.330925 loss_ctc0 101.577805 lr 0.00094202 rank 0
2022-08-23 22:52:53,203 DEBUG TRAIN Batch 79/1500 loss 33.752052 loss_att 27.254707 loss_ctc 48.912521 loss_ctc_origin 40.727116 loss_ctc0 68.011803 lr 0.00094191 rank 0
2022-08-23 22:53:21,204 DEBUG TRAIN Batch 79/1600 loss 39.399284 loss_att 24.142246 loss_ctc 74.999039 loss_ctc_origin 39.679211 loss_ctc0 157.411972 lr 0.00094181 rank 0
2022-08-23 22:53:47,910 WARNING NaN or Inf found in input tensor.
2022-08-23 22:53:49,514 DEBUG TRAIN Batch 79/1700 loss 23.507992 loss_att 13.633024 loss_ctc 46.549583 loss_ctc_origin 36.799156 loss_ctc0 69.300583 lr 0.00094170 rank 0
2022-08-23 22:54:18,185 DEBUG TRAIN Batch 79/1800 loss 24.773132 loss_att 13.699114 loss_ctc 50.612511 loss_ctc_origin 38.770683 loss_ctc0 78.243431 lr 0.00094160 rank 0
2022-08-23 22:54:46,666 DEBUG TRAIN Batch 79/1900 loss 28.258204 loss_att 13.529478 loss_ctc 62.625229 loss_ctc_origin 46.791599 loss_ctc0 99.570351 lr 0.00094150 rank 0
2022-08-23 22:55:16,870 DEBUG TRAIN Batch 79/2000 loss 34.405388 loss_att 25.657148 loss_ctc 54.817940 loss_ctc_origin 40.547581 loss_ctc0 88.115433 lr 0.00094139 rank 0
2022-08-23 22:55:44,194 WARNING NaN or Inf found in input tensor.
2022-08-23 22:55:45,111 DEBUG TRAIN Batch 79/2100 loss 27.930946 loss_att 17.702976 loss_ctc 51.796207 loss_ctc_origin 32.162533 loss_ctc0 97.608109 lr 0.00094129 rank 0
2022-08-23 22:56:10,804 DEBUG TRAIN Batch 79/2200 loss 24.927423 loss_att 15.472296 loss_ctc 46.989388 loss_ctc_origin 36.976738 loss_ctc0 70.352242 lr 0.00094118 rank 0
2022-08-23 22:56:16,054 WARNING NaN or Inf found in input tensor.
2022-08-23 22:56:38,862 DEBUG TRAIN Batch 79/2300 loss 21.097488 loss_att 10.092136 loss_ctc 46.776642 loss_ctc_origin 34.960258 loss_ctc0 74.348190 lr 0.00094108 rank 0
2022-08-23 22:57:02,320 WARNING NaN or Inf found in input tensor.
2022-08-23 22:57:06,535 DEBUG TRAIN Batch 79/2400 loss 26.862663 loss_att 13.654075 loss_ctc 57.682705 loss_ctc_origin 39.722984 loss_ctc0 99.588715 lr 0.00094097 rank 0
2022-08-23 22:57:36,082 DEBUG TRAIN Batch 79/2500 loss 24.557774 loss_att 18.325153 loss_ctc 39.100555 loss_ctc_origin 28.770748 loss_ctc0 63.203442 lr 0.00094087 rank 0
2022-08-23 22:57:36,754 WARNING NaN or Inf found in input tensor.
2022-08-23 22:58:03,518 DEBUG TRAIN Batch 79/2600 loss 30.335615 loss_att 21.211748 loss_ctc 51.624638 loss_ctc_origin 38.614700 loss_ctc0 81.981155 lr 0.00094077 rank 0
2022-08-23 22:58:31,335 DEBUG TRAIN Batch 79/2700 loss 25.106739 loss_att 13.377955 loss_ctc 52.473896 loss_ctc_origin 42.574024 loss_ctc0 75.573593 lr 0.00094066 rank 0
2022-08-23 22:59:00,860 DEBUG TRAIN Batch 79/2800 loss 22.280014 loss_att 11.016938 loss_ctc 48.560520 loss_ctc_origin 36.685284 loss_ctc0 76.269402 lr 0.00094056 rank 0
2022-08-23 22:59:30,355 DEBUG TRAIN Batch 79/2900 loss 29.139786 loss_att 14.611652 loss_ctc 63.038765 loss_ctc_origin 46.417614 loss_ctc0 101.821449 lr 0.00094045 rank 0
2022-08-23 23:00:04,961 DEBUG TRAIN Batch 79/3000 loss 22.019852 loss_att 17.502033 loss_ctc 32.561424 loss_ctc_origin 29.814682 loss_ctc0 38.970486 lr 0.00094035 rank 0
2022-08-23 23:00:33,980 DEBUG TRAIN Batch 79/3100 loss 30.261307 loss_att 19.432146 loss_ctc 55.529343 loss_ctc_origin 37.942688 loss_ctc0 96.564865 lr 0.00094025 rank 0
2022-08-23 23:01:02,730 DEBUG TRAIN Batch 79/3200 loss 26.175146 loss_att 15.644393 loss_ctc 50.746902 loss_ctc_origin 41.517147 loss_ctc0 72.283005 lr 0.00094014 rank 0
2022-08-23 23:01:32,212 DEBUG TRAIN Batch 79/3300 loss 29.359390 loss_att 14.433496 loss_ctc 64.186478 loss_ctc_origin 53.639565 loss_ctc0 88.795929 lr 0.00094004 rank 0
2022-08-23 23:02:00,464 DEBUG TRAIN Batch 79/3400 loss 25.918211 loss_att 12.988281 loss_ctc 56.088047 loss_ctc_origin 40.194572 loss_ctc0 93.172821 lr 0.00093994 rank 0
2022-08-23 23:02:28,969 DEBUG TRAIN Batch 79/3500 loss 29.924507 loss_att 23.336220 loss_ctc 45.297173 loss_ctc_origin 36.893299 loss_ctc0 64.906212 lr 0.00093983 rank 0
2022-08-23 23:02:57,561 DEBUG TRAIN Batch 79/3600 loss 32.009617 loss_att 19.586393 loss_ctc 60.997139 loss_ctc_origin 38.783676 loss_ctc0 112.828560 lr 0.00093973 rank 0
2022-08-23 23:03:25,720 DEBUG TRAIN Batch 79/3700 loss 23.023275 loss_att 12.799908 loss_ctc 46.877800 loss_ctc_origin 36.601753 loss_ctc0 70.855240 lr 0.00093962 rank 0
2022-08-23 23:03:54,355 DEBUG TRAIN Batch 79/3800 loss 25.769749 loss_att 13.033373 loss_ctc 55.487953 loss_ctc_origin 44.034916 loss_ctc0 82.211716 lr 0.00093952 rank 0
2022-08-23 23:04:24,138 DEBUG TRAIN Batch 79/3900 loss 27.115623 loss_att 14.230043 loss_ctc 57.181976 loss_ctc_origin 40.290588 loss_ctc0 96.595207 lr 0.00093942 rank 0
2022-08-23 23:04:53,628 DEBUG TRAIN Batch 79/4000 loss 29.929029 loss_att 22.841976 loss_ctc 46.465488 loss_ctc_origin 36.430092 loss_ctc0 69.881409 lr 0.00093931 rank 0
2022-08-23 23:05:22,441 DEBUG TRAIN Batch 79/4100 loss 32.850151 loss_att 19.662331 loss_ctc 63.621727 loss_ctc_origin 36.690193 loss_ctc0 126.461983 lr 0.00093921 rank 0
2022-08-23 23:05:50,151 DEBUG TRAIN Batch 79/4200 loss 24.098492 loss_att 14.523315 loss_ctc 46.440567 loss_ctc_origin 36.095222 loss_ctc0 70.579712 lr 0.00093911 rank 0
2022-08-23 23:06:18,010 DEBUG TRAIN Batch 79/4300 loss 25.150602 loss_att 12.750784 loss_ctc 54.083511 loss_ctc_origin 42.397064 loss_ctc0 81.351891 lr 0.00093900 rank 0
2022-08-23 23:06:43,671 WARNING NaN or Inf found in input tensor.
2022-08-23 23:06:48,811 DEBUG TRAIN Batch 79/4400 loss 26.828568 loss_att 12.834904 loss_ctc 59.480446 loss_ctc_origin 43.026405 loss_ctc0 97.873199 lr 0.00093890 rank 0
2022-08-23 23:07:22,158 DEBUG TRAIN Batch 79/4500 loss 26.070068 loss_att 20.834549 loss_ctc 38.286282 loss_ctc_origin 35.199432 loss_ctc0 45.488930 lr 0.00093880 rank 0
2022-08-23 23:07:51,803 DEBUG TRAIN Batch 79/4600 loss 28.271261 loss_att 20.770935 loss_ctc 45.772018 loss_ctc_origin 32.832977 loss_ctc0 75.963120 lr 0.00093869 rank 0
2022-08-23 23:08:20,349 DEBUG TRAIN Batch 79/4700 loss 29.286303 loss_att 17.441366 loss_ctc 56.924488 loss_ctc_origin 49.869888 loss_ctc0 73.385223 lr 0.00093859 rank 0
2022-08-23 23:08:49,010 DEBUG TRAIN Batch 79/4800 loss 22.395948 loss_att 10.744424 loss_ctc 49.582840 loss_ctc_origin 36.376522 loss_ctc0 80.397568 lr 0.00093849 rank 0
2022-08-23 23:09:17,709 DEBUG TRAIN Batch 79/4900 loss 25.005850 loss_att 11.980621 loss_ctc 55.398048 loss_ctc_origin 37.369759 loss_ctc0 97.464058 lr 0.00093838 rank 0
2022-08-23 23:09:47,023 DEBUG TRAIN Batch 79/5000 loss 25.125866 loss_att 19.863722 loss_ctc 37.404202 loss_ctc_origin 33.227440 loss_ctc0 47.149979 lr 0.00093828 rank 0
2022-08-23 23:10:14,671 DEBUG TRAIN Batch 79/5100 loss 27.275002 loss_att 17.972656 loss_ctc 48.980469 loss_ctc_origin 35.395321 loss_ctc0 80.679138 lr 0.00093818 rank 0
2022-08-23 23:10:43,434 DEBUG TRAIN Batch 79/5200 loss 21.906372 loss_att 13.362514 loss_ctc 41.842037 loss_ctc_origin 31.792063 loss_ctc0 65.291977 lr 0.00093807 rank 0
2022-08-23 23:11:12,065 DEBUG TRAIN Batch 79/5300 loss 24.604080 loss_att 12.725699 loss_ctc 52.320297 loss_ctc_origin 41.207035 loss_ctc0 78.251236 lr 0.00093797 rank 0
2022-08-23 23:11:34,912 WARNING NaN or Inf found in input tensor.
2022-08-23 23:11:39,325 DEBUG TRAIN Batch 79/5400 loss 25.119953 loss_att 12.765823 loss_ctc 53.946259 loss_ctc_origin 36.495354 loss_ctc0 94.665039 lr 0.00093787 rank 0
2022-08-23 23:12:08,223 DEBUG TRAIN Batch 79/5500 loss 28.917812 loss_att 22.662548 loss_ctc 43.513424 loss_ctc_origin 41.241859 loss_ctc0 48.813744 lr 0.00093776 rank 0
2022-08-23 23:12:36,829 DEBUG TRAIN Batch 79/5600 loss 29.568249 loss_att 20.995586 loss_ctc 49.571125 loss_ctc_origin 39.421577 loss_ctc0 73.253403 lr 0.00093766 rank 0
2022-08-23 23:13:00,143 DEBUG CV Batch 79/0 loss 17.156059 loss_att 12.334042 loss_ctc 28.407434 loss_ctc_origin 18.718140 loss_ctc0 51.015789 history loss 16.146879 rank 0
2022-08-23 23:13:10,409 DEBUG CV Batch 79/100 loss 22.229132 loss_att 17.200195 loss_ctc 33.963318 loss_ctc_origin 24.718117 loss_ctc0 55.535458 history loss 29.934812 rank 0
2022-08-23 23:13:19,731 DEBUG CV Batch 79/200 loss 26.784563 loss_att 20.326767 loss_ctc 41.852753 loss_ctc_origin 31.771500 loss_ctc0 65.375671 history loss 31.530566 rank 0
2022-08-23 23:13:29,526 DEBUG CV Batch 79/300 loss 25.582348 loss_att 19.166668 loss_ctc 40.552269 loss_ctc_origin 25.431278 loss_ctc0 75.834572 history loss 30.519372 rank 0
2022-08-23 23:13:39,686 DEBUG CV Batch 79/400 loss 41.734619 loss_att 33.766392 loss_ctc 60.327152 loss_ctc_origin 43.720383 loss_ctc0 99.076279 history loss 28.841413 rank 0
2022-08-23 23:13:50,596 DEBUG CV Batch 79/500 loss 24.322571 loss_att 16.455719 loss_ctc 42.678558 loss_ctc_origin 26.243004 loss_ctc0 81.028183 history loss 28.553440 rank 0
2022-08-23 23:14:01,367 DEBUG CV Batch 79/600 loss 18.246441 loss_att 12.508795 loss_ctc 31.634279 loss_ctc_origin 20.830706 loss_ctc0 56.842617 history loss 28.350348 rank 0
2022-08-23 23:14:10,867 DEBUG CV Batch 79/700 loss 21.385094 loss_att 14.345095 loss_ctc 37.811756 loss_ctc_origin 25.246773 loss_ctc0 67.130051 history loss 27.958977 rank 0
2022-08-23 23:14:19,883 DEBUG CV Batch 79/800 loss 24.629635 loss_att 18.893867 loss_ctc 38.013092 loss_ctc_origin 22.893906 loss_ctc0 73.291199 history loss 27.911794 rank 0
2022-08-23 23:14:30,030 INFO Epoch 79 CV info cv_loss 27.96056038521086
2022-08-23 23:14:30,031 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/79.pt
2022-08-23 23:14:30,472 INFO Epoch 80 TRAIN info lr 0.0009375732507716866
2022-08-23 23:14:30,476 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 23:14:58,303 DEBUG TRAIN Batch 80/0 loss 21.953011 loss_att 16.757700 loss_ctc 34.075401 loss_ctc_origin 29.728561 loss_ctc0 44.218029 lr 0.00093757 rank 0
2022-08-23 23:15:26,701 DEBUG TRAIN Batch 80/100 loss 30.371986 loss_att 21.672285 loss_ctc 50.671288 loss_ctc_origin 41.775711 loss_ctc0 71.427620 lr 0.00093747 rank 0
2022-08-23 23:15:55,600 DEBUG TRAIN Batch 80/200 loss 25.655212 loss_att 16.450960 loss_ctc 47.131798 loss_ctc_origin 37.867794 loss_ctc0 68.747803 lr 0.00093736 rank 0
2022-08-23 23:16:24,010 DEBUG TRAIN Batch 80/300 loss 24.805309 loss_att 11.269152 loss_ctc 56.389671 loss_ctc_origin 41.964211 loss_ctc0 90.049072 lr 0.00093726 rank 0
2022-08-23 23:16:53,830 DEBUG TRAIN Batch 80/400 loss 26.268326 loss_att 12.101398 loss_ctc 59.324486 loss_ctc_origin 42.744118 loss_ctc0 98.012009 lr 0.00093716 rank 0
2022-08-23 23:17:23,102 DEBUG TRAIN Batch 80/500 loss 29.355419 loss_att 23.696115 loss_ctc 42.560463 loss_ctc_origin 36.441544 loss_ctc0 56.837940 lr 0.00093705 rank 0
2022-08-23 23:17:43,826 WARNING NaN or Inf found in input tensor.
2022-08-23 23:17:51,369 DEBUG TRAIN Batch 80/600 loss 25.878918 loss_att 18.232677 loss_ctc 43.720146 loss_ctc_origin 35.841888 loss_ctc0 62.102753 lr 0.00093695 rank 0
2022-08-23 23:18:19,758 DEBUG TRAIN Batch 80/700 loss 21.552429 loss_att 12.060467 loss_ctc 43.700344 loss_ctc_origin 34.626450 loss_ctc0 64.872765 lr 0.00093685 rank 0
2022-08-23 23:18:47,689 DEBUG TRAIN Batch 80/800 loss 22.977823 loss_att 10.754992 loss_ctc 51.497761 loss_ctc_origin 36.188728 loss_ctc0 87.218834 lr 0.00093675 rank 0
2022-08-23 23:19:16,452 DEBUG TRAIN Batch 80/900 loss 26.111467 loss_att 13.432438 loss_ctc 55.695869 loss_ctc_origin 40.879913 loss_ctc0 90.266434 lr 0.00093664 rank 0
2022-08-23 23:19:45,716 DEBUG TRAIN Batch 80/1000 loss 23.196722 loss_att 18.189695 loss_ctc 34.879784 loss_ctc_origin 29.956406 loss_ctc0 46.367657 lr 0.00093654 rank 0
2022-08-23 23:20:14,497 DEBUG TRAIN Batch 80/1100 loss 25.138454 loss_att 18.462757 loss_ctc 40.715080 loss_ctc_origin 31.472136 loss_ctc0 62.281952 lr 0.00093644 rank 0
2022-08-23 23:20:43,896 DEBUG TRAIN Batch 80/1200 loss 24.919590 loss_att 13.304024 loss_ctc 52.022575 loss_ctc_origin 41.793221 loss_ctc0 75.891060 lr 0.00093634 rank 0
2022-08-23 23:21:12,319 DEBUG TRAIN Batch 80/1300 loss 24.300045 loss_att 12.238227 loss_ctc 52.444283 loss_ctc_origin 39.847969 loss_ctc0 81.835670 lr 0.00093623 rank 0
2022-08-23 23:21:41,034 DEBUG TRAIN Batch 80/1400 loss 29.253719 loss_att 13.143319 loss_ctc 66.844650 loss_ctc_origin 51.630463 loss_ctc0 102.344421 lr 0.00093613 rank 0
2022-08-23 23:22:17,435 DEBUG TRAIN Batch 80/1500 loss 26.601345 loss_att 21.343735 loss_ctc 38.869102 loss_ctc_origin 34.428715 loss_ctc0 49.230007 lr 0.00093603 rank 0
2022-08-23 23:22:45,372 DEBUG TRAIN Batch 80/1600 loss 23.396761 loss_att 16.950779 loss_ctc 38.437386 loss_ctc_origin 27.883276 loss_ctc0 63.063637 lr 0.00093593 rank 0
2022-08-23 23:23:13,430 DEBUG TRAIN Batch 80/1700 loss 29.091383 loss_att 18.469999 loss_ctc 53.874611 loss_ctc_origin 44.610424 loss_ctc0 75.491051 lr 0.00093582 rank 0
2022-08-23 23:23:41,924 DEBUG TRAIN Batch 80/1800 loss 22.586555 loss_att 10.806021 loss_ctc 50.074471 loss_ctc_origin 36.636951 loss_ctc0 81.428680 lr 0.00093572 rank 0
2022-08-23 23:24:10,564 DEBUG TRAIN Batch 80/1900 loss 28.542011 loss_att 14.413809 loss_ctc 61.507812 loss_ctc_origin 44.404411 loss_ctc0 101.415749 lr 0.00093562 rank 0
2022-08-23 23:24:40,146 DEBUG TRAIN Batch 80/2000 loss 32.460518 loss_att 26.189442 loss_ctc 47.093029 loss_ctc_origin 44.688885 loss_ctc0 52.702698 lr 0.00093552 rank 0
2022-08-23 23:25:08,563 DEBUG TRAIN Batch 80/2100 loss 25.513533 loss_att 17.939634 loss_ctc 43.185959 loss_ctc_origin 33.585327 loss_ctc0 65.587425 lr 0.00093541 rank 0
2022-08-23 23:25:36,747 DEBUG TRAIN Batch 80/2200 loss 23.790867 loss_att 12.974421 loss_ctc 49.029243 loss_ctc_origin 36.571526 loss_ctc0 78.097252 lr 0.00093531 rank 0
2022-08-23 23:26:05,627 DEBUG TRAIN Batch 80/2300 loss 20.271015 loss_att 9.502077 loss_ctc 45.398537 loss_ctc_origin 31.601650 loss_ctc0 77.591263 lr 0.00093521 rank 0
2022-08-23 23:26:34,896 DEBUG TRAIN Batch 80/2400 loss 31.945713 loss_att 16.272949 loss_ctc 68.515488 loss_ctc_origin 53.204071 loss_ctc0 104.242126 lr 0.00093511 rank 0
2022-08-23 23:27:04,997 DEBUG TRAIN Batch 80/2500 loss 27.685801 loss_att 22.895370 loss_ctc 38.863472 loss_ctc_origin 35.714752 loss_ctc0 46.210487 lr 0.00093500 rank 0
2022-08-23 23:27:32,723 DEBUG TRAIN Batch 80/2600 loss 29.460091 loss_att 22.049450 loss_ctc 46.751587 loss_ctc_origin 38.285141 loss_ctc0 66.506630 lr 0.00093490 rank 0
2022-08-23 23:28:02,191 DEBUG TRAIN Batch 80/2700 loss 22.355045 loss_att 10.782308 loss_ctc 49.358101 loss_ctc_origin 35.788551 loss_ctc0 81.020386 lr 0.00093480 rank 0
2022-08-23 23:28:28,674 DEBUG TRAIN Batch 80/2800 loss 21.126766 loss_att 11.455326 loss_ctc 43.693459 loss_ctc_origin 29.930628 loss_ctc0 75.806732 lr 0.00093470 rank 0
2022-08-23 23:28:59,225 DEBUG TRAIN Batch 80/2900 loss 29.296812 loss_att 14.253382 loss_ctc 64.398148 loss_ctc_origin 49.531387 loss_ctc0 99.087250 lr 0.00093460 rank 0
2022-08-23 23:29:33,070 DEBUG TRAIN Batch 80/3000 loss 25.874870 loss_att 21.031013 loss_ctc 37.177204 loss_ctc_origin 30.650877 loss_ctc0 52.405300 lr 0.00093449 rank 0
2022-08-23 23:30:01,711 DEBUG TRAIN Batch 80/3100 loss 26.806820 loss_att 17.568186 loss_ctc 48.363636 loss_ctc_origin 39.833893 loss_ctc0 68.266373 lr 0.00093439 rank 0
2022-08-23 23:30:31,072 DEBUG TRAIN Batch 80/3200 loss 19.596943 loss_att 11.126270 loss_ctc 39.361847 loss_ctc_origin 27.128654 loss_ctc0 67.905968 lr 0.00093429 rank 0
2022-08-23 23:31:00,559 DEBUG TRAIN Batch 80/3300 loss 27.496685 loss_att 14.064300 loss_ctc 58.838921 loss_ctc_origin 45.327484 loss_ctc0 90.365608 lr 0.00093419 rank 0
2022-08-23 23:31:27,928 DEBUG TRAIN Batch 80/3400 loss 24.052299 loss_att 11.774843 loss_ctc 52.699699 loss_ctc_origin 34.323044 loss_ctc0 95.578560 lr 0.00093409 rank 0
2022-08-23 23:31:57,865 DEBUG TRAIN Batch 80/3500 loss 27.617512 loss_att 20.911064 loss_ctc 43.265888 loss_ctc_origin 36.183872 loss_ctc0 59.790592 lr 0.00093398 rank 0
2022-08-23 23:32:27,260 DEBUG TRAIN Batch 80/3600 loss 24.741367 loss_att 17.066467 loss_ctc 42.649467 loss_ctc_origin 35.254601 loss_ctc0 59.904152 lr 0.00093388 rank 0
2022-08-23 23:32:55,849 DEBUG TRAIN Batch 80/3700 loss 27.199100 loss_att 15.227383 loss_ctc 55.133102 loss_ctc_origin 45.124878 loss_ctc0 78.485626 lr 0.00093378 rank 0
2022-08-23 23:33:25,447 DEBUG TRAIN Batch 80/3800 loss 25.186428 loss_att 13.483051 loss_ctc 52.494308 loss_ctc_origin 40.799751 loss_ctc0 79.781601 lr 0.00093368 rank 0
2022-08-23 23:33:53,245 DEBUG TRAIN Batch 80/3900 loss 26.171085 loss_att 12.375591 loss_ctc 58.360573 loss_ctc_origin 42.511063 loss_ctc0 95.342751 lr 0.00093358 rank 0
2022-08-23 23:34:21,725 DEBUG TRAIN Batch 80/4000 loss 36.250771 loss_att 29.673292 loss_ctc 51.598221 loss_ctc_origin 43.844028 loss_ctc0 69.691345 lr 0.00093348 rank 0
2022-08-23 23:34:50,978 DEBUG TRAIN Batch 80/4100 loss 25.638315 loss_att 17.317299 loss_ctc 45.054016 loss_ctc_origin 35.173439 loss_ctc0 68.108688 lr 0.00093337 rank 0
2022-08-23 23:35:18,704 DEBUG TRAIN Batch 80/4200 loss 24.577097 loss_att 15.076427 loss_ctc 46.745323 loss_ctc_origin 35.440704 loss_ctc0 73.122772 lr 0.00093327 rank 0
2022-08-23 23:35:47,595 DEBUG TRAIN Batch 80/4300 loss 27.952450 loss_att 13.624154 loss_ctc 61.385132 loss_ctc_origin 48.036633 loss_ctc0 92.531624 lr 0.00093317 rank 0
2022-08-23 23:36:17,723 DEBUG TRAIN Batch 80/4400 loss 26.502380 loss_att 11.868343 loss_ctc 60.648464 loss_ctc_origin 45.075497 loss_ctc0 96.985390 lr 0.00093307 rank 0
2022-08-23 23:36:54,834 DEBUG TRAIN Batch 80/4500 loss 29.901299 loss_att 23.189320 loss_ctc 45.562584 loss_ctc_origin 36.457916 loss_ctc0 66.806816 lr 0.00093297 rank 0
2022-08-23 23:37:23,673 DEBUG TRAIN Batch 80/4600 loss 31.014481 loss_att 22.578506 loss_ctc 50.698418 loss_ctc_origin 41.040733 loss_ctc0 73.233017 lr 0.00093287 rank 0
2022-08-23 23:37:53,057 DEBUG TRAIN Batch 80/4700 loss 23.664482 loss_att 13.385626 loss_ctc 47.648483 loss_ctc_origin 36.885765 loss_ctc0 72.761490 lr 0.00093276 rank 0
2022-08-23 23:38:21,753 DEBUG TRAIN Batch 80/4800 loss 22.936876 loss_att 11.209435 loss_ctc 50.300903 loss_ctc_origin 36.704990 loss_ctc0 82.024696 lr 0.00093266 rank 0
2022-08-23 23:38:51,008 DEBUG TRAIN Batch 80/4900 loss 30.528816 loss_att 14.540925 loss_ctc 67.833893 loss_ctc_origin 50.882980 loss_ctc0 107.386032 lr 0.00093256 rank 0
2022-08-23 23:39:20,232 DEBUG TRAIN Batch 80/5000 loss 25.472202 loss_att 19.686314 loss_ctc 38.972610 loss_ctc_origin 28.531414 loss_ctc0 63.335411 lr 0.00093246 rank 0
2022-08-23 23:39:47,743 DEBUG TRAIN Batch 80/5100 loss 32.548561 loss_att 21.462032 loss_ctc 58.417130 loss_ctc_origin 43.631729 loss_ctc0 92.916389 lr 0.00093236 rank 0
2022-08-23 23:40:17,174 DEBUG TRAIN Batch 80/5200 loss 23.054935 loss_att 14.263678 loss_ctc 43.567867 loss_ctc_origin 32.968353 loss_ctc0 68.300064 lr 0.00093226 rank 0
2022-08-23 23:40:45,691 DEBUG TRAIN Batch 80/5300 loss 22.508186 loss_att 10.302574 loss_ctc 50.987946 loss_ctc_origin 38.225723 loss_ctc0 80.766457 lr 0.00093216 rank 0
2022-08-23 23:41:13,960 DEBUG TRAIN Batch 80/5400 loss 28.084995 loss_att 13.665881 loss_ctc 61.729591 loss_ctc_origin 44.645760 loss_ctc0 101.591858 lr 0.00093206 rank 0
2022-08-23 23:41:43,190 DEBUG TRAIN Batch 80/5500 loss 24.899117 loss_att 19.193558 loss_ctc 38.212082 loss_ctc_origin 29.556767 loss_ctc0 58.407810 lr 0.00093195 rank 0
2022-08-23 23:41:58,566 WARNING NaN or Inf found in input tensor.
2022-08-23 23:42:12,922 DEBUG TRAIN Batch 80/5600 loss 25.349232 loss_att 17.679283 loss_ctc 43.245773 loss_ctc_origin 31.799030 loss_ctc0 69.954834 lr 0.00093185 rank 0
2022-08-23 23:42:36,420 DEBUG CV Batch 80/0 loss 14.139149 loss_att 10.690235 loss_ctc 22.186615 loss_ctc_origin 16.073900 loss_ctc0 36.449619 history loss 13.307434 rank 0
2022-08-23 23:42:46,772 DEBUG CV Batch 80/100 loss 22.481905 loss_att 17.848471 loss_ctc 33.293251 loss_ctc_origin 23.499790 loss_ctc0 56.144653 history loss 29.590286 rank 0
2022-08-23 23:42:55,863 DEBUG CV Batch 80/200 loss 25.406712 loss_att 19.233679 loss_ctc 39.810455 loss_ctc_origin 28.642605 loss_ctc0 65.868774 history loss 30.806652 rank 0
2022-08-23 23:43:05,510 DEBUG CV Batch 80/300 loss 25.863407 loss_att 19.464115 loss_ctc 40.795090 loss_ctc_origin 25.271267 loss_ctc0 77.017334 history loss 29.879870 rank 0
2022-08-23 23:43:15,935 DEBUG CV Batch 80/400 loss 40.933929 loss_att 32.974072 loss_ctc 59.506920 loss_ctc_origin 42.079491 loss_ctc0 100.170929 history loss 28.135222 rank 0
2022-08-23 23:43:25,923 DEBUG CV Batch 80/500 loss 17.693600 loss_att 13.187910 loss_ctc 28.206877 loss_ctc_origin 21.014240 loss_ctc0 44.989697 history loss 27.770755 rank 0
2022-08-23 23:43:36,260 DEBUG CV Batch 80/600 loss 18.522106 loss_att 12.911672 loss_ctc 31.613121 loss_ctc_origin 20.743214 loss_ctc0 56.976242 history loss 27.583124 rank 0
2022-08-23 23:43:45,772 DEBUG CV Batch 80/700 loss 21.232391 loss_att 14.525869 loss_ctc 36.880943 loss_ctc_origin 24.234055 loss_ctc0 66.390343 history loss 27.230890 rank 0
2022-08-23 23:43:55,632 DEBUG CV Batch 80/800 loss 24.196091 loss_att 18.587990 loss_ctc 37.281658 loss_ctc_origin 22.148348 loss_ctc0 72.592712 history loss 27.199554 rank 0
2022-08-23 23:44:05,921 INFO Epoch 80 CV info cv_loss 27.272080122771364
2022-08-23 23:44:05,921 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/80.pt
2022-08-23 23:44:06,413 INFO Epoch 81 TRAIN info lr 0.0009317677878270882
2022-08-23 23:44:06,417 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-23 23:44:33,346 DEBUG TRAIN Batch 81/0 loss 27.693684 loss_att 19.535543 loss_ctc 46.729347 loss_ctc_origin 32.740219 loss_ctc0 79.370651 lr 0.00093176 rank 0
2022-08-23 23:44:41,284 WARNING NaN or Inf found in input tensor.
2022-08-23 23:45:02,728 DEBUG TRAIN Batch 81/100 loss 30.890781 loss_att 21.030411 loss_ctc 53.898315 loss_ctc_origin 41.812965 loss_ctc0 82.097458 lr 0.00093166 rank 0
2022-08-23 23:45:31,361 DEBUG TRAIN Batch 81/200 loss 22.940231 loss_att 12.665347 loss_ctc 46.914963 loss_ctc_origin 36.918125 loss_ctc0 70.240921 lr 0.00093156 rank 0
2022-08-23 23:46:00,787 DEBUG TRAIN Batch 81/300 loss 25.237972 loss_att 11.820179 loss_ctc 56.546158 loss_ctc_origin 40.721001 loss_ctc0 93.471527 lr 0.00093146 rank 0
2022-08-23 23:46:25,450 WARNING NaN or Inf found in input tensor.
2022-08-23 23:46:29,902 DEBUG TRAIN Batch 81/400 loss 27.515097 loss_att 13.045660 loss_ctc 61.277115 loss_ctc_origin 47.234745 loss_ctc0 94.042648 lr 0.00093136 rank 0
2022-08-23 23:46:38,948 WARNING NaN or Inf found in input tensor.
2022-08-23 23:46:59,003 DEBUG TRAIN Batch 81/500 loss 26.998909 loss_att 19.514441 loss_ctc 44.462662 loss_ctc_origin 31.106827 loss_ctc0 75.626266 lr 0.00093126 rank 0
2022-08-23 23:47:27,514 DEBUG TRAIN Batch 81/600 loss 32.539665 loss_att 25.370258 loss_ctc 49.268284 loss_ctc_origin 41.163303 loss_ctc0 68.179901 lr 0.00093116 rank 0
2022-08-23 23:47:56,258 DEBUG TRAIN Batch 81/700 loss 21.808527 loss_att 13.332895 loss_ctc 41.584999 loss_ctc_origin 30.860609 loss_ctc0 66.608566 lr 0.00093106 rank 0
2022-08-23 23:48:24,796 DEBUG TRAIN Batch 81/800 loss 24.599173 loss_att 12.364757 loss_ctc 53.146141 loss_ctc_origin 39.024261 loss_ctc0 86.097191 lr 0.00093096 rank 0
2022-08-23 23:48:53,420 DEBUG TRAIN Batch 81/900 loss 29.351501 loss_att 13.654028 loss_ctc 65.978935 loss_ctc_origin 50.720173 loss_ctc0 101.582718 lr 0.00093086 rank 0
2022-08-23 23:49:21,698 DEBUG TRAIN Batch 81/1000 loss 31.113087 loss_att 23.822613 loss_ctc 48.124195 loss_ctc_origin 41.650047 loss_ctc0 63.230537 lr 0.00093075 rank 0
2022-08-23 23:49:50,758 DEBUG TRAIN Batch 81/1100 loss 28.379116 loss_att 19.903545 loss_ctc 48.155441 loss_ctc_origin 39.231750 loss_ctc0 68.977386 lr 0.00093065 rank 0
2022-08-23 23:50:10,605 WARNING NaN or Inf found in input tensor.
2022-08-23 23:50:18,861 DEBUG TRAIN Batch 81/1200 loss 23.120789 loss_att 12.635859 loss_ctc 47.585625 loss_ctc_origin 36.340008 loss_ctc0 73.825401 lr 0.00093055 rank 0
2022-08-23 23:50:48,708 DEBUG TRAIN Batch 81/1300 loss 22.974113 loss_att 9.780224 loss_ctc 53.759850 loss_ctc_origin 40.047165 loss_ctc0 85.756119 lr 0.00093045 rank 0
2022-08-23 23:51:17,227 DEBUG TRAIN Batch 81/1400 loss 28.612572 loss_att 14.057055 loss_ctc 62.575439 loss_ctc_origin 45.536690 loss_ctc0 102.332527 lr 0.00093035 rank 0
2022-08-23 23:51:53,056 DEBUG TRAIN Batch 81/1500 loss 27.808830 loss_att 21.792732 loss_ctc 41.846394 loss_ctc_origin 37.006294 loss_ctc0 53.139957 lr 0.00093025 rank 0
2022-08-23 23:52:22,055 DEBUG TRAIN Batch 81/1600 loss 28.935732 loss_att 19.967546 loss_ctc 49.861496 loss_ctc_origin 34.662785 loss_ctc0 85.325157 lr 0.00093015 rank 0
2022-08-23 23:52:51,335 DEBUG TRAIN Batch 81/1700 loss 19.785927 loss_att 11.301949 loss_ctc 39.581875 loss_ctc_origin 27.931950 loss_ctc0 66.765030 lr 0.00093005 rank 0
2022-08-23 23:53:20,131 DEBUG TRAIN Batch 81/1800 loss 25.875187 loss_att 12.188188 loss_ctc 57.811512 loss_ctc_origin 45.027588 loss_ctc0 87.640663 lr 0.00092995 rank 0
2022-08-23 23:53:49,292 DEBUG TRAIN Batch 81/1900 loss 29.403090 loss_att 15.314686 loss_ctc 62.276031 loss_ctc_origin 47.296227 loss_ctc0 97.228912 lr 0.00092985 rank 0
2022-08-23 23:54:18,658 DEBUG TRAIN Batch 81/2000 loss 28.432030 loss_att 20.875305 loss_ctc 46.064388 loss_ctc_origin 34.940029 loss_ctc0 72.021225 lr 0.00092975 rank 0
2022-08-23 23:54:47,734 DEBUG TRAIN Batch 81/2100 loss 25.234222 loss_att 15.576986 loss_ctc 47.767769 loss_ctc_origin 28.121687 loss_ctc0 93.608620 lr 0.00092965 rank 0
2022-08-23 23:55:15,893 DEBUG TRAIN Batch 81/2200 loss 26.263096 loss_att 15.196142 loss_ctc 52.085983 loss_ctc_origin 42.049057 loss_ctc0 75.505478 lr 0.00092955 rank 0
2022-08-23 23:55:45,124 DEBUG TRAIN Batch 81/2300 loss 27.669081 loss_att 14.090454 loss_ctc 59.352539 loss_ctc_origin 48.754307 loss_ctc0 84.081757 lr 0.00092945 rank 0
2022-08-23 23:56:14,558 DEBUG TRAIN Batch 81/2400 loss 24.289757 loss_att 11.849203 loss_ctc 53.317711 loss_ctc_origin 37.511692 loss_ctc0 90.198425 lr 0.00092935 rank 0
2022-08-23 23:56:43,487 DEBUG TRAIN Batch 81/2500 loss 33.026657 loss_att 23.051559 loss_ctc 56.301880 loss_ctc_origin 39.878601 loss_ctc0 94.622864 lr 0.00092925 rank 0
2022-08-23 23:57:12,328 DEBUG TRAIN Batch 81/2600 loss 34.437004 loss_att 23.448036 loss_ctc 60.077927 loss_ctc_origin 38.104401 loss_ctc0 111.349487 lr 0.00092915 rank 0
2022-08-23 23:57:41,489 DEBUG TRAIN Batch 81/2700 loss 26.006418 loss_att 14.080402 loss_ctc 53.833790 loss_ctc_origin 44.623436 loss_ctc0 75.324615 lr 0.00092905 rank 0
2022-08-23 23:58:09,796 DEBUG TRAIN Batch 81/2800 loss 23.471155 loss_att 12.201742 loss_ctc 49.766449 loss_ctc_origin 37.545326 loss_ctc0 78.282394 lr 0.00092895 rank 0
2022-08-23 23:58:38,450 DEBUG TRAIN Batch 81/2900 loss 31.079475 loss_att 15.819618 loss_ctc 66.685806 loss_ctc_origin 48.976398 loss_ctc0 108.007767 lr 0.00092885 rank 0
2022-08-23 23:59:13,778 DEBUG TRAIN Batch 81/3000 loss 30.689224 loss_att 22.447273 loss_ctc 49.920441 loss_ctc_origin 34.831470 loss_ctc0 85.128036 lr 0.00092874 rank 0
2022-08-23 23:59:42,159 DEBUG TRAIN Batch 81/3100 loss 28.567709 loss_att 16.910265 loss_ctc 55.768410 loss_ctc_origin 31.937834 loss_ctc0 111.373077 lr 0.00092864 rank 0
2022-08-24 00:00:11,491 DEBUG TRAIN Batch 81/3200 loss 26.550102 loss_att 15.775589 loss_ctc 51.690628 loss_ctc_origin 41.852512 loss_ctc0 74.646225 lr 0.00092854 rank 0
2022-08-24 00:00:40,658 DEBUG TRAIN Batch 81/3300 loss 24.640995 loss_att 11.774450 loss_ctc 54.662933 loss_ctc_origin 40.536201 loss_ctc0 87.625305 lr 0.00092844 rank 0
2022-08-24 00:01:08,329 DEBUG TRAIN Batch 81/3400 loss 29.507217 loss_att 14.386570 loss_ctc 64.788727 loss_ctc_origin 48.015060 loss_ctc0 103.927277 lr 0.00092834 rank 0
2022-08-24 00:01:37,592 DEBUG TRAIN Batch 81/3500 loss 31.433733 loss_att 23.357143 loss_ctc 50.279106 loss_ctc_origin 37.210655 loss_ctc0 80.772163 lr 0.00092824 rank 0
2022-08-24 00:02:07,728 DEBUG TRAIN Batch 81/3600 loss 32.139694 loss_att 21.430861 loss_ctc 57.126976 loss_ctc_origin 35.270420 loss_ctc0 108.125610 lr 0.00092814 rank 0
2022-08-24 00:02:35,555 DEBUG TRAIN Batch 81/3700 loss 20.259619 loss_att 11.232862 loss_ctc 41.322052 loss_ctc_origin 29.153446 loss_ctc0 69.715469 lr 0.00092804 rank 0
2022-08-24 00:03:04,664 DEBUG TRAIN Batch 81/3800 loss 28.358591 loss_att 15.121153 loss_ctc 59.245949 loss_ctc_origin 47.446541 loss_ctc0 86.777908 lr 0.00092794 rank 0
2022-08-24 00:03:34,283 DEBUG TRAIN Batch 81/3900 loss 27.264202 loss_att 13.964919 loss_ctc 58.295860 loss_ctc_origin 40.323303 loss_ctc0 100.231827 lr 0.00092785 rank 0
2022-08-24 00:04:02,691 DEBUG TRAIN Batch 81/4000 loss 30.437641 loss_att 21.911711 loss_ctc 50.331474 loss_ctc_origin 34.465244 loss_ctc0 87.352669 lr 0.00092775 rank 0
2022-08-24 00:04:30,523 DEBUG TRAIN Batch 81/4100 loss 39.708904 loss_att 24.674835 loss_ctc 74.788399 loss_ctc_origin 45.266907 loss_ctc0 143.671875 lr 0.00092765 rank 0
2022-08-24 00:04:56,598 WARNING NaN or Inf found in input tensor.
2022-08-24 00:04:58,184 DEBUG TRAIN Batch 81/4200 loss 24.226149 loss_att 14.695409 loss_ctc 46.464539 loss_ctc_origin 36.608517 loss_ctc0 69.461929 lr 0.00092755 rank 0
2022-08-24 00:05:29,263 DEBUG TRAIN Batch 81/4300 loss 25.378925 loss_att 11.461155 loss_ctc 57.853722 loss_ctc_origin 43.679077 loss_ctc0 90.927887 lr 0.00092745 rank 0
2022-08-24 00:05:56,752 DEBUG TRAIN Batch 81/4400 loss 26.038729 loss_att 12.749460 loss_ctc 57.047020 loss_ctc_origin 40.220325 loss_ctc0 96.309311 lr 0.00092735 rank 0
2022-08-24 00:06:33,508 DEBUG TRAIN Batch 81/4500 loss 30.939472 loss_att 22.999538 loss_ctc 49.465981 loss_ctc_origin 36.547436 loss_ctc0 79.609245 lr 0.00092725 rank 0
2022-08-24 00:07:02,060 DEBUG TRAIN Batch 81/4600 loss 33.975029 loss_att 18.958021 loss_ctc 69.014717 loss_ctc_origin 39.697289 loss_ctc0 137.422043 lr 0.00092715 rank 0
2022-08-24 00:07:30,366 DEBUG TRAIN Batch 81/4700 loss 24.716803 loss_att 14.086953 loss_ctc 49.519783 loss_ctc_origin 40.194504 loss_ctc0 71.278770 lr 0.00092705 rank 0
2022-08-24 00:07:58,845 DEBUG TRAIN Batch 81/4800 loss 25.008652 loss_att 12.695065 loss_ctc 53.740353 loss_ctc_origin 40.876465 loss_ctc0 83.756088 lr 0.00092695 rank 0
2022-08-24 00:08:27,305 DEBUG TRAIN Batch 81/4900 loss 30.956264 loss_att 15.189903 loss_ctc 67.744438 loss_ctc_origin 51.668980 loss_ctc0 105.253845 lr 0.00092685 rank 0
2022-08-24 00:08:55,794 DEBUG TRAIN Batch 81/5000 loss 29.908478 loss_att 19.034344 loss_ctc 55.281452 loss_ctc_origin 34.846554 loss_ctc0 102.962875 lr 0.00092675 rank 0
2022-08-24 00:09:23,747 DEBUG TRAIN Batch 81/5100 loss 32.362080 loss_att 19.001556 loss_ctc 63.536636 loss_ctc_origin 37.916229 loss_ctc0 123.317589 lr 0.00092665 rank 0
2022-08-24 00:09:53,226 DEBUG TRAIN Batch 81/5200 loss 20.875450 loss_att 12.117399 loss_ctc 41.310898 loss_ctc_origin 31.211685 loss_ctc0 64.875732 lr 0.00092655 rank 0
2022-08-24 00:10:19,798 DEBUG TRAIN Batch 81/5300 loss 20.763016 loss_att 10.197105 loss_ctc 45.416801 loss_ctc_origin 31.236929 loss_ctc0 78.503174 lr 0.00092645 rank 0
2022-08-24 00:10:48,849 DEBUG TRAIN Batch 81/5400 loss 25.838261 loss_att 11.968624 loss_ctc 58.200745 loss_ctc_origin 41.989105 loss_ctc0 96.027893 lr 0.00092635 rank 0
2022-08-24 00:11:16,605 DEBUG TRAIN Batch 81/5500 loss 26.941431 loss_att 17.945999 loss_ctc 47.930771 loss_ctc_origin 34.475319 loss_ctc0 79.326828 lr 0.00092625 rank 0
2022-08-24 00:11:45,138 DEBUG TRAIN Batch 81/5600 loss 37.620068 loss_att 26.753376 loss_ctc 62.975677 loss_ctc_origin 39.204029 loss_ctc0 118.442863 lr 0.00092615 rank 0
2022-08-24 00:12:08,910 DEBUG CV Batch 81/0 loss 15.605829 loss_att 11.945045 loss_ctc 24.147659 loss_ctc_origin 18.772781 loss_ctc0 36.689037 history loss 14.687839 rank 0
2022-08-24 00:12:19,931 DEBUG CV Batch 81/100 loss 24.257343 loss_att 18.891068 loss_ctc 36.778648 loss_ctc_origin 27.454170 loss_ctc0 58.535759 history loss 29.889310 rank 0
2022-08-24 00:12:29,922 DEBUG CV Batch 81/200 loss 26.989433 loss_att 21.002270 loss_ctc 40.959476 loss_ctc_origin 30.577694 loss_ctc0 65.183640 history loss 31.199969 rank 0
2022-08-24 00:12:39,940 DEBUG CV Batch 81/300 loss 26.830524 loss_att 20.267534 loss_ctc 42.144165 loss_ctc_origin 27.315577 loss_ctc0 76.744202 history loss 30.233687 rank 0
2022-08-24 00:12:50,473 DEBUG CV Batch 81/400 loss 40.482628 loss_att 32.776482 loss_ctc 58.463631 loss_ctc_origin 40.750404 loss_ctc0 99.794495 history loss 28.516119 rank 0
2022-08-24 00:13:00,884 DEBUG CV Batch 81/500 loss 18.049299 loss_att 13.624139 loss_ctc 28.374674 loss_ctc_origin 21.729292 loss_ctc0 43.880562 history loss 28.186600 rank 0
2022-08-24 00:13:11,598 DEBUG CV Batch 81/600 loss 18.198570 loss_att 12.683413 loss_ctc 31.067272 loss_ctc_origin 20.283199 loss_ctc0 56.230110 history loss 27.965774 rank 0
2022-08-24 00:13:22,056 DEBUG CV Batch 81/700 loss 21.407207 loss_att 14.594275 loss_ctc 37.304043 loss_ctc_origin 24.621628 loss_ctc0 66.896339 history loss 27.633085 rank 0
2022-08-24 00:13:32,428 DEBUG CV Batch 81/800 loss 25.043186 loss_att 19.089912 loss_ctc 38.934158 loss_ctc_origin 24.136257 loss_ctc0 73.462585 history loss 27.582922 rank 0
2022-08-24 00:13:42,718 INFO Epoch 81 CV info cv_loss 27.690176636773142
2022-08-24 00:13:42,718 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/81.pt
2022-08-24 00:13:43,170 INFO Epoch 82 TRAIN info lr 0.0009260688488141626
2022-08-24 00:13:43,174 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 00:14:10,061 DEBUG TRAIN Batch 82/0 loss 34.569092 loss_att 25.554207 loss_ctc 55.603828 loss_ctc_origin 40.566448 loss_ctc0 90.691040 lr 0.00092606 rank 0
2022-08-24 00:14:37,798 DEBUG TRAIN Batch 82/100 loss 32.738480 loss_att 17.350054 loss_ctc 68.644798 loss_ctc_origin 38.076714 loss_ctc0 139.970322 lr 0.00092597 rank 0
2022-08-24 00:15:05,965 DEBUG TRAIN Batch 82/200 loss 25.187708 loss_att 16.027866 loss_ctc 46.560669 loss_ctc_origin 37.419598 loss_ctc0 67.889832 lr 0.00092587 rank 0
2022-08-24 00:15:34,297 DEBUG TRAIN Batch 82/300 loss 23.101246 loss_att 11.666400 loss_ctc 49.782547 loss_ctc_origin 37.569801 loss_ctc0 78.278954 lr 0.00092577 rank 0
2022-08-24 00:16:02,414 DEBUG TRAIN Batch 82/400 loss 27.441616 loss_att 12.943487 loss_ctc 61.270584 loss_ctc_origin 47.000557 loss_ctc0 94.567307 lr 0.00092567 rank 0
2022-08-24 00:16:32,329 DEBUG TRAIN Batch 82/500 loss 34.868145 loss_att 23.563446 loss_ctc 61.245773 loss_ctc_origin 43.820351 loss_ctc0 101.905090 lr 0.00092557 rank 0
2022-08-24 00:17:01,322 DEBUG TRAIN Batch 82/600 loss 33.643761 loss_att 19.964836 loss_ctc 65.561249 loss_ctc_origin 39.654160 loss_ctc0 126.011124 lr 0.00092547 rank 0
2022-08-24 00:17:29,787 DEBUG TRAIN Batch 82/700 loss 23.442629 loss_att 11.895660 loss_ctc 50.385551 loss_ctc_origin 38.872078 loss_ctc0 77.250320 lr 0.00092537 rank 0
2022-08-24 00:18:00,194 DEBUG TRAIN Batch 82/800 loss 26.412266 loss_att 12.801003 loss_ctc 58.171883 loss_ctc_origin 46.955982 loss_ctc0 84.342308 lr 0.00092527 rank 0
2022-08-24 00:18:27,153 DEBUG TRAIN Batch 82/900 loss 24.358381 loss_att 11.809382 loss_ctc 53.639378 loss_ctc_origin 37.776764 loss_ctc0 90.652138 lr 0.00092517 rank 0
2022-08-24 00:18:54,797 DEBUG TRAIN Batch 82/1000 loss 40.836418 loss_att 28.102173 loss_ctc 70.549652 loss_ctc_origin 44.121269 loss_ctc0 132.215866 lr 0.00092507 rank 0
2022-08-24 00:19:22,422 DEBUG TRAIN Batch 82/1100 loss 34.612762 loss_att 16.727600 loss_ctc 76.344803 loss_ctc_origin 43.905865 loss_ctc0 152.035645 lr 0.00092497 rank 0
2022-08-24 00:19:43,023 WARNING NaN or Inf found in input tensor.
2022-08-24 00:19:50,781 DEBUG TRAIN Batch 82/1200 loss 25.212147 loss_att 13.922556 loss_ctc 51.554527 loss_ctc_origin 42.820580 loss_ctc0 71.933731 lr 0.00092488 rank 0
2022-08-24 00:20:18,730 DEBUG TRAIN Batch 82/1300 loss 22.030846 loss_att 10.193605 loss_ctc 49.651070 loss_ctc_origin 37.249340 loss_ctc0 78.588448 lr 0.00092478 rank 0
2022-08-24 00:20:48,524 DEBUG TRAIN Batch 82/1400 loss 27.359993 loss_att 13.260586 loss_ctc 60.258606 loss_ctc_origin 42.242897 loss_ctc0 102.295258 lr 0.00092468 rank 0
2022-08-24 00:21:21,421 DEBUG TRAIN Batch 82/1500 loss 36.825302 loss_att 26.604483 loss_ctc 60.673882 loss_ctc_origin 42.003452 loss_ctc0 104.238220 lr 0.00092458 rank 0
2022-08-24 00:21:50,195 DEBUG TRAIN Batch 82/1600 loss 32.405712 loss_att 18.885254 loss_ctc 63.953449 loss_ctc_origin 39.429840 loss_ctc0 121.175201 lr 0.00092448 rank 0
2022-08-24 00:22:19,533 DEBUG TRAIN Batch 82/1700 loss 24.621696 loss_att 14.963459 loss_ctc 47.157585 loss_ctc_origin 36.243126 loss_ctc0 72.624664 lr 0.00092438 rank 0
2022-08-24 00:22:48,187 DEBUG TRAIN Batch 82/1800 loss 23.655209 loss_att 11.142123 loss_ctc 52.852409 loss_ctc_origin 40.148434 loss_ctc0 82.495010 lr 0.00092428 rank 0
2022-08-24 00:23:12,745 WARNING NaN or Inf found in input tensor.
2022-08-24 00:23:17,231 DEBUG TRAIN Batch 82/1900 loss 27.207554 loss_att 14.095958 loss_ctc 57.801277 loss_ctc_origin 42.587372 loss_ctc0 93.300392 lr 0.00092418 rank 0
2022-08-24 00:23:46,172 DEBUG TRAIN Batch 82/2000 loss 33.966862 loss_att 22.219597 loss_ctc 61.377144 loss_ctc_origin 34.198311 loss_ctc0 124.794426 lr 0.00092409 rank 0
2022-08-24 00:24:14,231 DEBUG TRAIN Batch 82/2100 loss 37.706268 loss_att 20.156044 loss_ctc 78.656784 loss_ctc_origin 44.213474 loss_ctc0 159.024506 lr 0.00092399 rank 0
2022-08-24 00:24:40,609 WARNING NaN or Inf found in input tensor.
2022-08-24 00:24:42,138 DEBUG TRAIN Batch 82/2200 loss 24.533388 loss_att 13.622094 loss_ctc 49.993073 loss_ctc_origin 39.897739 loss_ctc0 73.548843 lr 0.00092389 rank 0
2022-08-24 00:25:10,633 DEBUG TRAIN Batch 82/2300 loss 25.479055 loss_att 10.995268 loss_ctc 59.274559 loss_ctc_origin 43.935234 loss_ctc0 95.066315 lr 0.00092379 rank 0
2022-08-24 00:25:35,705 WARNING NaN or Inf found in input tensor.
2022-08-24 00:25:40,320 DEBUG TRAIN Batch 82/2400 loss 28.153580 loss_att 12.238251 loss_ctc 65.289345 loss_ctc_origin 47.422001 loss_ctc0 106.979813 lr 0.00092369 rank 0
2022-08-24 00:26:08,862 DEBUG TRAIN Batch 82/2500 loss 35.407078 loss_att 23.857729 loss_ctc 62.355556 loss_ctc_origin 33.884403 loss_ctc0 128.788239 lr 0.00092359 rank 0
2022-08-24 00:26:37,697 DEBUG TRAIN Batch 82/2600 loss 34.972179 loss_att 20.567146 loss_ctc 68.583923 loss_ctc_origin 39.196449 loss_ctc0 137.154694 lr 0.00092349 rank 0
2022-08-24 00:27:07,395 DEBUG TRAIN Batch 82/2700 loss 25.826809 loss_att 15.707063 loss_ctc 49.439552 loss_ctc_origin 38.973618 loss_ctc0 73.860062 lr 0.00092340 rank 0
2022-08-24 00:27:35,666 DEBUG TRAIN Batch 82/2800 loss 25.236521 loss_att 12.629346 loss_ctc 54.653259 loss_ctc_origin 43.968517 loss_ctc0 79.584328 lr 0.00092330 rank 0
2022-08-24 00:28:04,310 DEBUG TRAIN Batch 82/2900 loss 26.551956 loss_att 12.858204 loss_ctc 58.504044 loss_ctc_origin 42.216454 loss_ctc0 96.508408 lr 0.00092320 rank 0
2022-08-24 00:28:37,654 DEBUG TRAIN Batch 82/3000 loss 38.719482 loss_att 22.077019 loss_ctc 77.551895 loss_ctc_origin 46.630287 loss_ctc0 149.702301 lr 0.00092310 rank 0
2022-08-24 00:29:06,300 DEBUG TRAIN Batch 82/3100 loss 36.659378 loss_att 19.780287 loss_ctc 76.043915 loss_ctc_origin 38.589184 loss_ctc0 163.438293 lr 0.00092300 rank 0
2022-08-24 00:29:32,789 WARNING NaN or Inf found in input tensor.
2022-08-24 00:29:34,481 DEBUG TRAIN Batch 82/3200 loss 23.395893 loss_att 14.014837 loss_ctc 45.285019 loss_ctc_origin 35.029686 loss_ctc0 69.214119 lr 0.00092290 rank 0
2022-08-24 00:30:03,168 DEBUG TRAIN Batch 82/3300 loss 25.756777 loss_att 12.469501 loss_ctc 56.760418 loss_ctc_origin 44.578239 loss_ctc0 85.185501 lr 0.00092281 rank 0
2022-08-24 00:30:31,409 DEBUG TRAIN Batch 82/3400 loss 27.918093 loss_att 13.584208 loss_ctc 61.363823 loss_ctc_origin 45.605972 loss_ctc0 98.132141 lr 0.00092271 rank 0
2022-08-24 00:31:00,878 DEBUG TRAIN Batch 82/3500 loss 37.187912 loss_att 26.414202 loss_ctc 62.326569 loss_ctc_origin 50.629440 loss_ctc0 89.619858 lr 0.00092261 rank 0
2022-08-24 00:31:29,152 DEBUG TRAIN Batch 82/3600 loss 33.222412 loss_att 20.200542 loss_ctc 63.606766 loss_ctc_origin 43.392300 loss_ctc0 110.773849 lr 0.00092251 rank 0
2022-08-24 00:31:55,515 DEBUG TRAIN Batch 82/3700 loss 24.665081 loss_att 15.029312 loss_ctc 47.148544 loss_ctc_origin 36.728714 loss_ctc0 71.461487 lr 0.00092241 rank 0
2022-08-24 00:32:24,308 DEBUG TRAIN Batch 82/3800 loss 26.006557 loss_att 13.312999 loss_ctc 55.624855 loss_ctc_origin 43.610435 loss_ctc0 83.658501 lr 0.00092232 rank 0
2022-08-24 00:32:47,939 WARNING NaN or Inf found in input tensor.
2022-08-24 00:32:52,230 DEBUG TRAIN Batch 82/3900 loss 31.787786 loss_att 16.435953 loss_ctc 67.608727 loss_ctc_origin 52.700424 loss_ctc0 102.394760 lr 0.00092222 rank 0
2022-08-24 00:33:20,370 DEBUG TRAIN Batch 82/4000 loss 32.651093 loss_att 23.017181 loss_ctc 55.130211 loss_ctc_origin 36.317009 loss_ctc0 99.027687 lr 0.00092212 rank 0
2022-08-24 00:33:49,593 DEBUG TRAIN Batch 82/4100 loss 39.679478 loss_att 24.423191 loss_ctc 75.277481 loss_ctc_origin 45.981403 loss_ctc0 143.634995 lr 0.00092202 rank 0
2022-08-24 00:34:18,530 DEBUG TRAIN Batch 82/4200 loss 20.910030 loss_att 11.200016 loss_ctc 43.566727 loss_ctc_origin 30.709032 loss_ctc0 73.568008 lr 0.00092192 rank 0
2022-08-24 00:34:46,694 DEBUG TRAIN Batch 82/4300 loss 23.068827 loss_att 11.148281 loss_ctc 50.883430 loss_ctc_origin 38.445717 loss_ctc0 79.904762 lr 0.00092183 rank 0
2022-08-24 00:35:17,744 DEBUG TRAIN Batch 82/4400 loss 31.098492 loss_att 15.305227 loss_ctc 67.949440 loss_ctc_origin 50.001907 loss_ctc0 109.827011 lr 0.00092173 rank 0
2022-08-24 00:35:54,114 DEBUG TRAIN Batch 82/4500 loss 32.288063 loss_att 19.482197 loss_ctc 62.168411 loss_ctc_origin 35.876846 loss_ctc0 123.515388 lr 0.00092163 rank 0
2022-08-24 00:36:02,675 WARNING NaN or Inf found in input tensor.
2022-08-24 00:36:22,554 DEBUG TRAIN Batch 82/4600 loss 39.393410 loss_att 26.150967 loss_ctc 70.292450 loss_ctc_origin 40.458054 loss_ctc0 139.906052 lr 0.00092153 rank 0
2022-08-24 00:36:51,245 DEBUG TRAIN Batch 82/4700 loss 23.904844 loss_att 14.431070 loss_ctc 46.010315 loss_ctc_origin 36.916763 loss_ctc0 67.228607 lr 0.00092143 rank 0
2022-08-24 00:37:19,917 DEBUG TRAIN Batch 82/4800 loss 23.238338 loss_att 11.791687 loss_ctc 49.947189 loss_ctc_origin 37.298828 loss_ctc0 79.460030 lr 0.00092134 rank 0
2022-08-24 00:37:43,845 WARNING NaN or Inf found in input tensor.
2022-08-24 00:37:48,264 DEBUG TRAIN Batch 82/4900 loss 30.964729 loss_att 15.417084 loss_ctc 67.242569 loss_ctc_origin 53.261589 loss_ctc0 99.864868 lr 0.00092124 rank 0
2022-08-24 00:37:50,874 WARNING NaN or Inf found in input tensor.
2022-08-24 00:38:16,844 DEBUG TRAIN Batch 82/5000 loss 36.227905 loss_att 23.198519 loss_ctc 66.629799 loss_ctc_origin 40.801384 loss_ctc0 126.896095 lr 0.00092114 rank 0
2022-08-24 00:38:45,733 DEBUG TRAIN Batch 82/5100 loss 36.510719 loss_att 21.080891 loss_ctc 72.513657 loss_ctc_origin 38.410172 loss_ctc0 152.088440 lr 0.00092104 rank 0
2022-08-24 00:39:13,713 DEBUG TRAIN Batch 82/5200 loss 27.440674 loss_att 16.912777 loss_ctc 52.005768 loss_ctc_origin 42.680599 loss_ctc0 73.764488 lr 0.00092095 rank 0
2022-08-24 00:39:42,815 DEBUG TRAIN Batch 82/5300 loss 26.335232 loss_att 14.038927 loss_ctc 55.026608 loss_ctc_origin 43.443787 loss_ctc0 82.053185 lr 0.00092085 rank 0
2022-08-24 00:40:06,962 WARNING NaN or Inf found in input tensor.
2022-08-24 00:40:11,161 DEBUG TRAIN Batch 82/5400 loss 30.234280 loss_att 14.635407 loss_ctc 66.631645 loss_ctc_origin 52.022785 loss_ctc0 100.718979 lr 0.00092075 rank 0
2022-08-24 00:40:40,397 DEBUG TRAIN Batch 82/5500 loss 39.169758 loss_att 26.330399 loss_ctc 69.128265 loss_ctc_origin 37.833389 loss_ctc0 142.149628 lr 0.00092065 rank 0
2022-08-24 00:41:09,510 DEBUG TRAIN Batch 82/5600 loss 49.798027 loss_att 31.009378 loss_ctc 93.638214 loss_ctc_origin 56.301754 loss_ctc0 180.756622 lr 0.00092056 rank 0
2022-08-24 00:41:32,813 DEBUG CV Batch 82/0 loss 15.881855 loss_att 12.198385 loss_ctc 24.476614 loss_ctc_origin 18.779701 loss_ctc0 37.769409 history loss 14.947628 rank 0
2022-08-24 00:41:43,237 DEBUG CV Batch 82/100 loss 22.883022 loss_att 18.090601 loss_ctc 34.065334 loss_ctc_origin 24.325607 loss_ctc0 56.791363 history loss 31.185257 rank 0
2022-08-24 00:41:52,513 DEBUG CV Batch 82/200 loss 28.017975 loss_att 22.075996 loss_ctc 41.882587 loss_ctc_origin 31.613716 loss_ctc0 65.843285 history loss 32.179651 rank 0
2022-08-24 00:42:02,888 DEBUG CV Batch 82/300 loss 27.103687 loss_att 20.516167 loss_ctc 42.474571 loss_ctc_origin 27.809326 loss_ctc0 76.693466 history loss 31.324978 rank 0
2022-08-24 00:42:13,916 DEBUG CV Batch 82/400 loss 42.905712 loss_att 34.472130 loss_ctc 62.584068 loss_ctc_origin 46.321678 loss_ctc0 100.529648 history loss 29.588135 rank 0
2022-08-24 00:42:25,453 DEBUG CV Batch 82/500 loss 18.879154 loss_att 14.221853 loss_ctc 29.746191 loss_ctc_origin 23.344545 loss_ctc0 44.683365 history loss 29.196677 rank 0
2022-08-24 00:42:36,691 DEBUG CV Batch 82/600 loss 18.668303 loss_att 12.885435 loss_ctc 32.161659 loss_ctc_origin 21.075706 loss_ctc0 58.028873 history loss 29.086702 rank 0
2022-08-24 00:42:47,106 DEBUG CV Batch 82/700 loss 21.860947 loss_att 14.943586 loss_ctc 38.001457 loss_ctc_origin 25.249920 loss_ctc0 67.755035 history loss 28.735706 rank 0
2022-08-24 00:42:57,948 DEBUG CV Batch 82/800 loss 24.513916 loss_att 18.338779 loss_ctc 38.922562 loss_ctc_origin 24.312695 loss_ctc0 73.012253 history loss 28.696769 rank 0
2022-08-24 00:43:08,713 INFO Epoch 82 CV info cv_loss 28.78324974061656
2022-08-24 00:43:08,714 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/82.pt
2022-08-24 00:43:09,190 INFO Epoch 83 TRAIN info lr 0.0009204732154176403
2022-08-24 00:43:09,194 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 00:43:36,132 DEBUG TRAIN Batch 83/0 loss 43.142731 loss_att 28.050327 loss_ctc 78.358345 loss_ctc_origin 47.045311 loss_ctc0 151.422089 lr 0.00092047 rank 0
2022-08-24 00:44:05,116 WARNING NaN or Inf found in input tensor.
2022-08-24 00:44:05,163 DEBUG TRAIN Batch 83/100 loss nan loss_att 24.412920 loss_ctc nan loss_ctc_origin 45.721657 loss_ctc0 nan lr 0.00092037 rank 0
2022-08-24 00:44:33,379 DEBUG TRAIN Batch 83/200 loss 24.755180 loss_att 15.292942 loss_ctc 46.833740 loss_ctc_origin 38.041588 loss_ctc0 67.348770 lr 0.00092027 rank 0
2022-08-24 00:44:38,671 WARNING NaN or Inf found in input tensor.
2022-08-24 00:45:01,550 DEBUG TRAIN Batch 83/300 loss 26.939728 loss_att 12.329693 loss_ctc 61.029808 loss_ctc_origin 47.812351 loss_ctc0 91.870529 lr 0.00092018 rank 0
2022-08-24 00:45:30,167 DEBUG TRAIN Batch 83/400 loss 25.824776 loss_att 12.209602 loss_ctc 57.593506 loss_ctc_origin 40.977402 loss_ctc0 96.364410 lr 0.00092008 rank 0
2022-08-24 00:46:00,464 DEBUG TRAIN Batch 83/500 loss 38.881432 loss_att 24.147755 loss_ctc 73.260010 loss_ctc_origin 39.597713 loss_ctc0 151.805374 lr 0.00091998 rank 0
2022-08-24 00:46:28,940 DEBUG TRAIN Batch 83/600 loss 36.964191 loss_att 22.370872 loss_ctc 71.015266 loss_ctc_origin 40.876385 loss_ctc0 141.339325 lr 0.00091988 rank 0
2022-08-24 00:46:58,139 DEBUG TRAIN Batch 83/700 loss 27.369236 loss_att 18.300285 loss_ctc 48.530121 loss_ctc_origin 40.940994 loss_ctc0 66.238083 lr 0.00091979 rank 0
2022-08-24 00:47:25,892 DEBUG TRAIN Batch 83/800 loss 23.652121 loss_att 10.949655 loss_ctc 53.291206 loss_ctc_origin 39.102699 loss_ctc0 86.397720 lr 0.00091969 rank 0
2022-08-24 00:47:56,142 DEBUG TRAIN Batch 83/900 loss 27.743013 loss_att 14.125974 loss_ctc 59.516106 loss_ctc_origin 41.407085 loss_ctc0 101.770485 lr 0.00091959 rank 0
2022-08-24 00:48:24,117 DEBUG TRAIN Batch 83/1000 loss 33.181713 loss_att 21.688793 loss_ctc 59.998528 loss_ctc_origin 41.611774 loss_ctc0 102.900940 lr 0.00091950 rank 0
2022-08-24 00:48:46,021 WARNING NaN or Inf found in input tensor.
2022-08-24 00:48:53,594 DEBUG TRAIN Batch 83/1100 loss 40.332085 loss_att 25.406275 loss_ctc 75.158966 loss_ctc_origin 49.345440 loss_ctc0 135.390518 lr 0.00091940 rank 0
2022-08-24 00:49:21,432 DEBUG TRAIN Batch 83/1200 loss 24.384516 loss_att 15.185810 loss_ctc 45.848160 loss_ctc_origin 35.935959 loss_ctc0 68.976631 lr 0.00091930 rank 0
2022-08-24 00:49:50,434 DEBUG TRAIN Batch 83/1300 loss 26.461212 loss_att 13.372643 loss_ctc 57.001205 loss_ctc_origin 43.577785 loss_ctc0 88.322510 lr 0.00091920 rank 0
2022-08-24 00:50:19,171 DEBUG TRAIN Batch 83/1400 loss 28.048182 loss_att 12.337971 loss_ctc 64.705338 loss_ctc_origin 46.633278 loss_ctc0 106.873474 lr 0.00091911 rank 0
2022-08-24 00:50:54,717 DEBUG TRAIN Batch 83/1500 loss 38.022812 loss_att 28.750698 loss_ctc 59.657738 loss_ctc_origin 43.170059 loss_ctc0 98.128990 lr 0.00091901 rank 0
2022-08-24 00:51:23,635 DEBUG TRAIN Batch 83/1600 loss 39.264862 loss_att 24.939123 loss_ctc 72.691589 loss_ctc_origin 43.926208 loss_ctc0 139.810806 lr 0.00091891 rank 0
2022-08-24 00:51:52,847 DEBUG TRAIN Batch 83/1700 loss 26.085985 loss_att 16.437801 loss_ctc 48.598412 loss_ctc_origin 37.240913 loss_ctc0 75.099236 lr 0.00091882 rank 0
2022-08-24 00:52:21,616 DEBUG TRAIN Batch 83/1800 loss 24.668173 loss_att 11.866888 loss_ctc 54.537834 loss_ctc_origin 42.112041 loss_ctc0 83.531342 lr 0.00091872 rank 0
2022-08-24 00:52:50,493 DEBUG TRAIN Batch 83/1900 loss 30.081387 loss_att 15.072968 loss_ctc 65.101028 loss_ctc_origin 48.692436 loss_ctc0 103.387733 lr 0.00091862 rank 0
2022-08-24 00:53:19,659 DEBUG TRAIN Batch 83/2000 loss 36.566071 loss_att 25.736515 loss_ctc 61.835026 loss_ctc_origin 45.336983 loss_ctc0 100.330460 lr 0.00091853 rank 0
2022-08-24 00:53:27,428 WARNING NaN or Inf found in input tensor.
2022-08-24 00:53:48,251 DEBUG TRAIN Batch 83/2100 loss 41.363762 loss_att 22.693295 loss_ctc 84.928185 loss_ctc_origin 45.668884 loss_ctc0 176.533203 lr 0.00091843 rank 0
2022-08-24 00:54:16,942 DEBUG TRAIN Batch 83/2200 loss 23.234478 loss_att 14.822408 loss_ctc 42.862640 loss_ctc_origin 32.331615 loss_ctc0 67.435036 lr 0.00091833 rank 0
2022-08-24 00:54:36,357 WARNING NaN or Inf found in input tensor.
2022-08-24 00:54:45,957 DEBUG TRAIN Batch 83/2300 loss 23.230501 loss_att 11.093613 loss_ctc 51.549908 loss_ctc_origin 37.343941 loss_ctc0 84.697159 lr 0.00091824 rank 0
2022-08-24 00:55:15,048 DEBUG TRAIN Batch 83/2400 loss 23.121502 loss_att 10.921013 loss_ctc 51.589310 loss_ctc_origin 35.693615 loss_ctc0 88.679260 lr 0.00091814 rank 0
2022-08-24 00:55:45,194 DEBUG TRAIN Batch 83/2500 loss 45.990356 loss_att 32.434372 loss_ctc 77.620987 loss_ctc_origin 55.059883 loss_ctc0 130.263565 lr 0.00091804 rank 0
2022-08-24 00:56:11,900 DEBUG TRAIN Batch 83/2600 loss 40.598656 loss_att 24.792231 loss_ctc 77.480316 loss_ctc_origin 41.148411 loss_ctc0 162.254745 lr 0.00091795 rank 0
2022-08-24 00:56:40,214 DEBUG TRAIN Batch 83/2700 loss 24.383705 loss_att 14.002705 loss_ctc 48.606037 loss_ctc_origin 37.727036 loss_ctc0 73.990372 lr 0.00091785 rank 0
2022-08-24 00:57:10,932 DEBUG TRAIN Batch 83/2800 loss 29.487385 loss_att 15.435355 loss_ctc 62.275452 loss_ctc_origin 51.135017 loss_ctc0 88.269806 lr 0.00091775 rank 0
2022-08-24 00:57:39,267 DEBUG TRAIN Batch 83/2900 loss 29.423347 loss_att 13.720748 loss_ctc 66.062744 loss_ctc_origin 49.534718 loss_ctc0 104.628143 lr 0.00091766 rank 0
2022-08-24 00:58:15,034 DEBUG TRAIN Batch 83/3000 loss 32.977371 loss_att 22.568241 loss_ctc 57.265343 loss_ctc_origin 34.362366 loss_ctc0 110.705620 lr 0.00091756 rank 0
2022-08-24 00:58:44,640 DEBUG TRAIN Batch 83/3100 loss 40.703442 loss_att 24.119297 loss_ctc 79.399780 loss_ctc_origin 50.234604 loss_ctc0 147.451843 lr 0.00091746 rank 0
2022-08-24 00:59:13,581 DEBUG TRAIN Batch 83/3200 loss 22.228401 loss_att 11.718008 loss_ctc 46.752647 loss_ctc_origin 37.377209 loss_ctc0 68.628677 lr 0.00091737 rank 0
2022-08-24 00:59:43,098 DEBUG TRAIN Batch 83/3300 loss 23.481089 loss_att 11.289255 loss_ctc 51.928696 loss_ctc_origin 39.693214 loss_ctc0 80.478149 lr 0.00091727 rank 0
2022-08-24 01:00:11,779 DEBUG TRAIN Batch 83/3400 loss 25.471506 loss_att 11.415179 loss_ctc 58.269600 loss_ctc_origin 42.890083 loss_ctc0 94.155128 lr 0.00091717 rank 0
2022-08-24 01:00:39,974 DEBUG TRAIN Batch 83/3500 loss 31.098427 loss_att 20.709793 loss_ctc 55.338570 loss_ctc_origin 29.846743 loss_ctc0 114.819496 lr 0.00091708 rank 0
2022-08-24 01:01:08,860 DEBUG TRAIN Batch 83/3600 loss 35.748562 loss_att 21.170349 loss_ctc 69.764389 loss_ctc_origin 38.047054 loss_ctc0 143.771500 lr 0.00091698 rank 0
2022-08-24 01:01:37,202 DEBUG TRAIN Batch 83/3700 loss 26.418421 loss_att 14.635098 loss_ctc 53.912842 loss_ctc_origin 45.506172 loss_ctc0 73.528397 lr 0.00091688 rank 0
2022-08-24 01:02:06,609 DEBUG TRAIN Batch 83/3800 loss 23.374065 loss_att 11.266445 loss_ctc 51.625175 loss_ctc_origin 36.286049 loss_ctc0 87.416458 lr 0.00091679 rank 0
2022-08-24 01:02:36,997 DEBUG TRAIN Batch 83/3900 loss 27.847176 loss_att 12.752848 loss_ctc 63.067268 loss_ctc_origin 49.474297 loss_ctc0 94.784195 lr 0.00091669 rank 0
2022-08-24 01:03:06,075 DEBUG TRAIN Batch 83/4000 loss 38.811031 loss_att 26.305847 loss_ctc 67.989792 loss_ctc_origin 43.589069 loss_ctc0 124.924797 lr 0.00091659 rank 0
2022-08-24 01:03:26,985 WARNING NaN or Inf found in input tensor.
2022-08-24 01:03:34,681 DEBUG TRAIN Batch 83/4100 loss 39.500202 loss_att 22.300688 loss_ctc 79.632401 loss_ctc_origin 45.800327 loss_ctc0 158.573883 lr 0.00091650 rank 0
2022-08-24 01:04:03,339 DEBUG TRAIN Batch 83/4200 loss 25.619560 loss_att 16.058222 loss_ctc 47.929352 loss_ctc_origin 37.678673 loss_ctc0 71.847610 lr 0.00091640 rank 0
2022-08-24 01:04:31,740 DEBUG TRAIN Batch 83/4300 loss 25.298164 loss_att 12.539388 loss_ctc 55.068634 loss_ctc_origin 41.323570 loss_ctc0 87.140457 lr 0.00091631 rank 0
2022-08-24 01:04:59,608 DEBUG TRAIN Batch 83/4400 loss 26.247383 loss_att 11.583004 loss_ctc 60.464264 loss_ctc_origin 43.417439 loss_ctc0 100.240181 lr 0.00091621 rank 0
2022-08-24 01:05:34,786 DEBUG TRAIN Batch 83/4500 loss 40.538841 loss_att 28.238291 loss_ctc 69.240128 loss_ctc_origin 44.799744 loss_ctc0 126.267700 lr 0.00091611 rank 0
2022-08-24 01:06:03,700 DEBUG TRAIN Batch 83/4600 loss 32.492008 loss_att 19.522585 loss_ctc 62.753990 loss_ctc_origin 33.430130 loss_ctc0 131.176331 lr 0.00091602 rank 0
2022-08-24 01:06:31,839 DEBUG TRAIN Batch 83/4700 loss 22.757355 loss_att 12.604549 loss_ctc 46.447235 loss_ctc_origin 35.827347 loss_ctc0 71.226967 lr 0.00091592 rank 0
2022-08-24 01:07:00,841 DEBUG TRAIN Batch 83/4800 loss 26.865410 loss_att 13.410324 loss_ctc 58.260605 loss_ctc_origin 45.522942 loss_ctc0 87.981827 lr 0.00091583 rank 0
2022-08-24 01:07:29,269 DEBUG TRAIN Batch 83/4900 loss 23.114021 loss_att 11.340698 loss_ctc 50.585110 loss_ctc_origin 35.596329 loss_ctc0 85.558929 lr 0.00091573 rank 0
2022-08-24 01:07:59,911 DEBUG TRAIN Batch 83/5000 loss 34.618027 loss_att 23.976559 loss_ctc 59.448120 loss_ctc_origin 38.503269 loss_ctc0 108.319427 lr 0.00091563 rank 0
2022-08-24 01:08:28,348 DEBUG TRAIN Batch 83/5100 loss 35.318771 loss_att 21.792587 loss_ctc 66.879868 loss_ctc_origin 41.567200 loss_ctc0 125.942764 lr 0.00091554 rank 0
2022-08-24 01:08:57,325 DEBUG TRAIN Batch 83/5200 loss 27.261536 loss_att 16.667133 loss_ctc 51.981804 loss_ctc_origin 42.799355 loss_ctc0 73.407516 lr 0.00091544 rank 0
2022-08-24 01:09:26,122 DEBUG TRAIN Batch 83/5300 loss 24.632504 loss_att 11.256176 loss_ctc 55.843933 loss_ctc_origin 43.574684 loss_ctc0 84.472183 lr 0.00091535 rank 0
2022-08-24 01:09:55,547 DEBUG TRAIN Batch 83/5400 loss 26.031404 loss_att 13.513540 loss_ctc 55.239754 loss_ctc_origin 37.335968 loss_ctc0 97.015251 lr 0.00091525 rank 0
2022-08-24 01:10:23,441 DEBUG TRAIN Batch 83/5500 loss 36.236145 loss_att 25.675125 loss_ctc 60.878517 loss_ctc_origin 41.449928 loss_ctc0 106.211884 lr 0.00091515 rank 0
2022-08-24 01:10:52,353 DEBUG TRAIN Batch 83/5600 loss 30.813656 loss_att 21.116913 loss_ctc 53.439384 loss_ctc_origin 33.197693 loss_ctc0 100.669998 lr 0.00091506 rank 0
2022-08-24 01:11:15,186 DEBUG CV Batch 83/0 loss 14.595928 loss_att 11.050443 loss_ctc 22.868729 loss_ctc_origin 16.577850 loss_ctc0 37.547443 history loss 13.737344 rank 0
2022-08-24 01:11:25,259 DEBUG CV Batch 83/100 loss 23.044903 loss_att 17.896145 loss_ctc 35.058670 loss_ctc_origin 24.754877 loss_ctc0 59.100861 history loss 30.118585 rank 0
2022-08-24 01:11:34,476 DEBUG CV Batch 83/200 loss 26.460535 loss_att 20.572603 loss_ctc 40.199043 loss_ctc_origin 29.584467 loss_ctc0 64.966385 history loss 31.525848 rank 0
2022-08-24 01:11:43,845 DEBUG CV Batch 83/300 loss 26.486618 loss_att 19.783716 loss_ctc 42.126717 loss_ctc_origin 27.441437 loss_ctc0 76.392365 history loss 30.619864 rank 0
2022-08-24 01:11:53,866 DEBUG CV Batch 83/400 loss 42.905369 loss_att 35.229401 loss_ctc 60.815964 loss_ctc_origin 44.149719 loss_ctc0 99.703865 history loss 28.820401 rank 0
2022-08-24 01:12:04,847 DEBUG CV Batch 83/500 loss 19.599075 loss_att 15.206306 loss_ctc 29.848869 loss_ctc_origin 22.922020 loss_ctc0 46.011513 history loss 28.424876 rank 0
2022-08-24 01:12:15,660 DEBUG CV Batch 83/600 loss 18.756344 loss_att 13.327348 loss_ctc 31.424000 loss_ctc_origin 20.424883 loss_ctc0 57.088608 history loss 28.247380 rank 0
2022-08-24 01:12:25,293 DEBUG CV Batch 83/700 loss 23.223469 loss_att 16.230038 loss_ctc 39.541477 loss_ctc_origin 27.590687 loss_ctc0 67.426651 history loss 27.883450 rank 0
2022-08-24 01:12:34,073 DEBUG CV Batch 83/800 loss 24.314251 loss_att 18.410831 loss_ctc 38.088894 loss_ctc_origin 23.087231 loss_ctc0 73.092773 history loss 27.820868 rank 0
2022-08-24 01:12:43,832 INFO Epoch 83 CV info cv_loss 27.911910558633863
2022-08-24 01:12:43,833 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/83.pt
2022-08-24 01:12:44,321 INFO Epoch 84 TRAIN info lr 0.0009149778038226823
2022-08-24 01:12:44,325 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 01:13:12,133 DEBUG TRAIN Batch 84/0 loss 36.244244 loss_att 24.358059 loss_ctc 63.978676 loss_ctc_origin 46.447010 loss_ctc0 104.885895 lr 0.00091497 rank 0
2022-08-24 01:13:40,783 DEBUG TRAIN Batch 84/100 loss 35.061096 loss_att 21.687817 loss_ctc 66.265411 loss_ctc_origin 40.664673 loss_ctc0 126.000458 lr 0.00091488 rank 0
2022-08-24 01:14:10,324 DEBUG TRAIN Batch 84/200 loss 19.838150 loss_att 10.935413 loss_ctc 40.611202 loss_ctc_origin 29.605408 loss_ctc0 66.291389 lr 0.00091478 rank 0
2022-08-24 01:14:15,747 WARNING NaN or Inf found in input tensor.
2022-08-24 01:14:39,532 DEBUG TRAIN Batch 84/300 loss 24.085888 loss_att 11.494696 loss_ctc 53.465340 loss_ctc_origin 40.540558 loss_ctc0 83.623169 lr 0.00091469 rank 0
2022-08-24 01:15:09,154 DEBUG TRAIN Batch 84/400 loss 28.757786 loss_att 13.224460 loss_ctc 65.002213 loss_ctc_origin 48.904804 loss_ctc0 102.562820 lr 0.00091459 rank 0
2022-08-24 01:15:39,327 DEBUG TRAIN Batch 84/500 loss 34.844887 loss_att 24.915066 loss_ctc 58.014458 loss_ctc_origin 32.910027 loss_ctc0 116.591461 lr 0.00091450 rank 0
2022-08-24 01:16:07,699 DEBUG TRAIN Batch 84/600 loss 30.866192 loss_att 15.529977 loss_ctc 66.650696 loss_ctc_origin 33.449238 loss_ctc0 144.120758 lr 0.00091440 rank 0
2022-08-24 01:16:36,570 DEBUG TRAIN Batch 84/700 loss 24.007826 loss_att 14.476702 loss_ctc 46.247116 loss_ctc_origin 36.384674 loss_ctc0 69.259491 lr 0.00091430 rank 0
2022-08-24 01:17:04,944 DEBUG TRAIN Batch 84/800 loss 24.563049 loss_att 11.232101 loss_ctc 55.668594 loss_ctc_origin 40.620975 loss_ctc0 90.779694 lr 0.00091421 rank 0
2022-08-24 01:17:33,738 DEBUG TRAIN Batch 84/900 loss 32.471764 loss_att 16.253054 loss_ctc 70.315414 loss_ctc_origin 54.030678 loss_ctc0 108.313148 lr 0.00091411 rank 0
2022-08-24 01:18:02,298 DEBUG TRAIN Batch 84/1000 loss 37.216019 loss_att 26.693386 loss_ctc 61.768833 loss_ctc_origin 36.177048 loss_ctc0 121.483002 lr 0.00091402 rank 0
2022-08-24 01:18:17,200 WARNING NaN or Inf found in input tensor.
2022-08-24 01:18:30,961 DEBUG TRAIN Batch 84/1100 loss 35.931984 loss_att 19.815128 loss_ctc 73.537979 loss_ctc_origin 38.869522 loss_ctc0 154.431046 lr 0.00091392 rank 0
2022-08-24 01:19:00,530 DEBUG TRAIN Batch 84/1200 loss 20.727409 loss_att 12.207689 loss_ctc 40.606750 loss_ctc_origin 28.533997 loss_ctc0 68.776505 lr 0.00091383 rank 0
2022-08-24 01:19:27,316 DEBUG TRAIN Batch 84/1300 loss 25.442329 loss_att 11.172063 loss_ctc 58.739616 loss_ctc_origin 46.006210 loss_ctc0 88.450897 lr 0.00091373 rank 0
2022-08-24 01:19:58,167 DEBUG TRAIN Batch 84/1400 loss 25.958534 loss_att 12.162117 loss_ctc 58.150173 loss_ctc_origin 41.046150 loss_ctc0 98.059555 lr 0.00091364 rank 0
2022-08-24 01:20:33,780 DEBUG TRAIN Batch 84/1500 loss 36.119808 loss_att 23.265152 loss_ctc 66.114006 loss_ctc_origin 44.778549 loss_ctc0 115.896736 lr 0.00091354 rank 0
2022-08-24 01:21:02,364 DEBUG TRAIN Batch 84/1600 loss 40.027046 loss_att 24.033888 loss_ctc 77.344421 loss_ctc_origin 46.538338 loss_ctc0 149.225266 lr 0.00091345 rank 0
2022-08-24 01:21:30,643 DEBUG TRAIN Batch 84/1700 loss 21.641342 loss_att 11.972244 loss_ctc 44.202568 loss_ctc_origin 32.418064 loss_ctc0 71.699738 lr 0.00091335 rank 0
2022-08-24 01:21:59,489 DEBUG TRAIN Batch 84/1800 loss 25.433764 loss_att 12.606373 loss_ctc 55.364342 loss_ctc_origin 41.920982 loss_ctc0 86.732185 lr 0.00091326 rank 0
2022-08-24 01:22:27,966 DEBUG TRAIN Batch 84/1900 loss 28.794100 loss_att 14.282982 loss_ctc 62.653374 loss_ctc_origin 46.473358 loss_ctc0 100.406746 lr 0.00091316 rank 0
2022-08-24 01:22:30,589 WARNING NaN or Inf found in input tensor.
2022-08-24 01:22:57,334 DEBUG TRAIN Batch 84/2000 loss 33.980343 loss_att 19.799164 loss_ctc 67.069763 loss_ctc_origin 41.604576 loss_ctc0 126.488541 lr 0.00091306 rank 0
2022-08-24 01:23:25,748 DEBUG TRAIN Batch 84/2100 loss 47.471458 loss_att 31.903410 loss_ctc 83.796898 loss_ctc_origin 53.800362 loss_ctc0 153.788818 lr 0.00091297 rank 0
2022-08-24 01:23:54,102 DEBUG TRAIN Batch 84/2200 loss 20.186434 loss_att 11.244501 loss_ctc 41.050941 loss_ctc_origin 31.419226 loss_ctc0 63.524940 lr 0.00091287 rank 0
2022-08-24 01:24:22,941 DEBUG TRAIN Batch 84/2300 loss 26.771793 loss_att 13.301165 loss_ctc 58.203262 loss_ctc_origin 46.684135 loss_ctc0 85.081223 lr 0.00091278 rank 0
2022-08-24 01:24:52,797 DEBUG TRAIN Batch 84/2400 loss 23.682093 loss_att 11.607897 loss_ctc 51.855217 loss_ctc_origin 35.497032 loss_ctc0 90.024307 lr 0.00091268 rank 0
2022-08-24 01:25:22,368 DEBUG TRAIN Batch 84/2500 loss 36.032101 loss_att 25.580719 loss_ctc 60.418655 loss_ctc_origin 36.124283 loss_ctc0 117.105530 lr 0.00091259 rank 0
2022-08-24 01:25:52,267 DEBUG TRAIN Batch 84/2600 loss 33.463905 loss_att 20.904861 loss_ctc 62.768341 loss_ctc_origin 38.740711 loss_ctc0 118.832809 lr 0.00091249 rank 0
2022-08-24 01:26:20,253 DEBUG TRAIN Batch 84/2700 loss 23.236835 loss_att 14.377505 loss_ctc 43.908600 loss_ctc_origin 34.295483 loss_ctc0 66.339203 lr 0.00091240 rank 0
2022-08-24 01:26:50,206 DEBUG TRAIN Batch 84/2800 loss 24.703972 loss_att 11.201855 loss_ctc 56.208912 loss_ctc_origin 42.635063 loss_ctc0 87.881226 lr 0.00091230 rank 0
2022-08-24 01:27:18,299 DEBUG TRAIN Batch 84/2900 loss 27.712048 loss_att 13.409943 loss_ctc 61.083618 loss_ctc_origin 43.789665 loss_ctc0 101.436172 lr 0.00091221 rank 0
2022-08-24 01:27:52,904 DEBUG TRAIN Batch 84/3000 loss 37.524555 loss_att 27.259911 loss_ctc 61.475391 loss_ctc_origin 42.678543 loss_ctc0 105.334702 lr 0.00091211 rank 0
2022-08-24 01:28:22,268 DEBUG TRAIN Batch 84/3100 loss 41.108547 loss_att 23.922783 loss_ctc 81.208664 loss_ctc_origin 48.700668 loss_ctc0 157.060669 lr 0.00091202 rank 0
2022-08-24 01:28:49,206 WARNING NaN or Inf found in input tensor.
2022-08-24 01:28:51,036 DEBUG TRAIN Batch 84/3200 loss 21.326427 loss_att 12.325340 loss_ctc 42.328960 loss_ctc_origin 30.088823 loss_ctc0 70.889282 lr 0.00091193 rank 0
2022-08-24 01:29:20,234 DEBUG TRAIN Batch 84/3300 loss 25.716555 loss_att 12.994674 loss_ctc 55.400940 loss_ctc_origin 43.264854 loss_ctc0 83.718475 lr 0.00091183 rank 0
2022-08-24 01:29:49,063 DEBUG TRAIN Batch 84/3400 loss 28.941872 loss_att 14.194586 loss_ctc 63.352203 loss_ctc_origin 45.812477 loss_ctc0 104.278229 lr 0.00091174 rank 0
2022-08-24 01:30:18,571 DEBUG TRAIN Batch 84/3500 loss 42.670181 loss_att 25.445656 loss_ctc 82.860748 loss_ctc_origin 44.244995 loss_ctc0 172.964172 lr 0.00091164 rank 0
2022-08-24 01:30:46,862 DEBUG TRAIN Batch 84/3600 loss 43.711750 loss_att 25.801308 loss_ctc 85.502777 loss_ctc_origin 47.975967 loss_ctc0 173.065338 lr 0.00091155 rank 0
2022-08-24 01:31:16,009 DEBUG TRAIN Batch 84/3700 loss 23.746885 loss_att 13.600651 loss_ctc 47.421432 loss_ctc_origin 37.468765 loss_ctc0 70.644325 lr 0.00091145 rank 0
2022-08-24 01:31:21,406 WARNING NaN or Inf found in input tensor.
2022-08-24 01:31:45,702 DEBUG TRAIN Batch 84/3800 loss 22.274323 loss_att 11.303955 loss_ctc 47.871841 loss_ctc_origin 36.860184 loss_ctc0 73.565712 lr 0.00091136 rank 0
2022-08-24 01:32:03,232 WARNING NaN or Inf found in input tensor.
2022-08-24 01:32:14,747 DEBUG TRAIN Batch 84/3900 loss 27.523037 loss_att 12.458412 loss_ctc 62.673828 loss_ctc_origin 45.743034 loss_ctc0 102.179016 lr 0.00091126 rank 0
2022-08-24 01:32:43,690 DEBUG TRAIN Batch 84/4000 loss 39.503063 loss_att 23.961273 loss_ctc 75.767242 loss_ctc_origin 43.790985 loss_ctc0 150.378510 lr 0.00091117 rank 0
2022-08-24 01:33:14,212 DEBUG TRAIN Batch 84/4100 loss 39.723343 loss_att 24.458242 loss_ctc 75.341904 loss_ctc_origin 40.888916 loss_ctc0 155.732208 lr 0.00091107 rank 0
2022-08-24 01:33:43,429 DEBUG TRAIN Batch 84/4200 loss 26.484268 loss_att 15.923594 loss_ctc 51.125847 loss_ctc_origin 42.173401 loss_ctc0 72.014893 lr 0.00091098 rank 0
2022-08-24 01:34:14,233 DEBUG TRAIN Batch 84/4300 loss 29.394419 loss_att 16.249924 loss_ctc 60.064903 loss_ctc_origin 48.794479 loss_ctc0 86.362556 lr 0.00091088 rank 0
2022-08-24 01:34:41,503 DEBUG TRAIN Batch 84/4400 loss 28.756159 loss_att 14.503931 loss_ctc 62.011353 loss_ctc_origin 47.727734 loss_ctc0 95.339798 lr 0.00091079 rank 0
2022-08-24 01:35:16,917 DEBUG TRAIN Batch 84/4500 loss 34.454239 loss_att 23.572224 loss_ctc 59.845604 loss_ctc_origin 39.977757 loss_ctc0 106.203918 lr 0.00091070 rank 0
2022-08-24 01:35:45,013 DEBUG TRAIN Batch 84/4600 loss 34.738819 loss_att 22.473381 loss_ctc 63.358170 loss_ctc_origin 38.301373 loss_ctc0 121.824013 lr 0.00091060 rank 0
2022-08-24 01:36:13,653 DEBUG TRAIN Batch 84/4700 loss 23.551144 loss_att 13.099646 loss_ctc 47.937973 loss_ctc_origin 38.854103 loss_ctc0 69.133675 lr 0.00091051 rank 0
2022-08-24 01:36:43,193 DEBUG TRAIN Batch 84/4800 loss 25.700869 loss_att 12.513065 loss_ctc 56.472404 loss_ctc_origin 42.577881 loss_ctc0 88.892960 lr 0.00091041 rank 0
2022-08-24 01:37:07,506 WARNING NaN or Inf found in input tensor.
2022-08-24 01:37:11,853 DEBUG TRAIN Batch 84/4900 loss 27.325626 loss_att 12.436845 loss_ctc 62.066116 loss_ctc_origin 46.253536 loss_ctc0 98.962135 lr 0.00091032 rank 0
2022-08-24 01:37:41,242 DEBUG TRAIN Batch 84/5000 loss 30.562355 loss_att 20.396725 loss_ctc 54.282158 loss_ctc_origin 33.954079 loss_ctc0 101.714348 lr 0.00091022 rank 0
2022-08-24 01:38:02,422 WARNING NaN or Inf found in input tensor.
2022-08-24 01:38:09,240 DEBUG TRAIN Batch 84/5100 loss 35.610226 loss_att 24.438156 loss_ctc 61.678391 loss_ctc_origin 39.496059 loss_ctc0 113.437157 lr 0.00091013 rank 0
2022-08-24 01:38:37,994 DEBUG TRAIN Batch 84/5200 loss 24.448597 loss_att 12.907545 loss_ctc 51.377716 loss_ctc_origin 42.211872 loss_ctc0 72.764694 lr 0.00091004 rank 0
2022-08-24 01:39:07,188 DEBUG TRAIN Batch 84/5300 loss 23.683372 loss_att 11.118972 loss_ctc 53.000309 loss_ctc_origin 38.921165 loss_ctc0 85.851639 lr 0.00090994 rank 0
2022-08-24 01:39:35,992 DEBUG TRAIN Batch 84/5400 loss 25.020144 loss_att 10.950175 loss_ctc 57.850067 loss_ctc_origin 41.231339 loss_ctc0 96.627106 lr 0.00090985 rank 0
2022-08-24 01:40:05,591 DEBUG TRAIN Batch 84/5500 loss 41.879593 loss_att 29.561169 loss_ctc 70.622574 loss_ctc_origin 43.012947 loss_ctc0 135.045044 lr 0.00090975 rank 0
2022-08-24 01:40:34,216 DEBUG TRAIN Batch 84/5600 loss 40.114750 loss_att 25.743299 loss_ctc 73.648132 loss_ctc_origin 46.555359 loss_ctc0 136.864609 lr 0.00090966 rank 0
2022-08-24 01:40:55,894 DEBUG CV Batch 84/0 loss 14.758998 loss_att 11.120552 loss_ctc 23.248705 loss_ctc_origin 15.744009 loss_ctc0 40.759659 history loss 13.890822 rank 0
2022-08-24 01:41:05,740 DEBUG CV Batch 84/100 loss 24.403645 loss_att 19.338821 loss_ctc 36.221565 loss_ctc_origin 25.534740 loss_ctc0 61.157494 history loss 30.482862 rank 0
2022-08-24 01:41:14,592 DEBUG CV Batch 84/200 loss 28.208723 loss_att 22.127388 loss_ctc 42.398506 loss_ctc_origin 32.633629 loss_ctc0 65.183212 history loss 31.719969 rank 0
2022-08-24 01:41:24,097 DEBUG CV Batch 84/300 loss 26.828426 loss_att 20.326143 loss_ctc 42.000420 loss_ctc_origin 27.270533 loss_ctc0 76.370163 history loss 30.882467 rank 0
2022-08-24 01:41:34,160 DEBUG CV Batch 84/400 loss 41.197678 loss_att 33.210091 loss_ctc 59.835381 loss_ctc_origin 42.781185 loss_ctc0 99.628510 history loss 29.173853 rank 0
2022-08-24 01:41:44,245 DEBUG CV Batch 84/500 loss 19.400034 loss_att 14.855577 loss_ctc 30.003765 loss_ctc_origin 23.936901 loss_ctc0 44.159782 history loss 28.783570 rank 0
2022-08-24 01:41:54,528 DEBUG CV Batch 84/600 loss 18.942421 loss_att 13.412010 loss_ctc 31.846710 loss_ctc_origin 21.265095 loss_ctc0 56.537140 history loss 28.604820 rank 0
2022-08-24 01:42:04,332 DEBUG CV Batch 84/700 loss 21.819643 loss_att 15.130896 loss_ctc 37.426720 loss_ctc_origin 24.571138 loss_ctc0 67.423080 history loss 28.246193 rank 0
2022-08-24 01:42:14,178 DEBUG CV Batch 84/800 loss 25.874729 loss_att 19.814770 loss_ctc 40.014633 loss_ctc_origin 25.195021 loss_ctc0 74.593719 history loss 28.185531 rank 0
2022-08-24 01:42:24,199 INFO Epoch 84 CV info cv_loss 28.27872187202471
2022-08-24 01:42:24,199 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/84.pt
2022-08-24 01:42:24,647 INFO Epoch 85 TRAIN info lr 0.0009095796575730303
2022-08-24 01:42:24,650 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 01:42:51,929 DEBUG TRAIN Batch 85/0 loss 32.309357 loss_att 20.583181 loss_ctc 59.670425 loss_ctc_origin 31.934946 loss_ctc0 124.386536 lr 0.00090958 rank 0
2022-08-24 01:43:21,698 DEBUG TRAIN Batch 85/100 loss 38.438004 loss_att 20.920433 loss_ctc 79.312332 loss_ctc_origin 41.476234 loss_ctc0 167.596558 lr 0.00090948 rank 0
2022-08-24 01:43:50,952 DEBUG TRAIN Batch 85/200 loss 23.078716 loss_att 13.623642 loss_ctc 45.140556 loss_ctc_origin 32.541649 loss_ctc0 74.538002 lr 0.00090939 rank 0
2022-08-24 01:44:20,533 DEBUG TRAIN Batch 85/300 loss 21.566360 loss_att 9.543518 loss_ctc 49.619659 loss_ctc_origin 36.423584 loss_ctc0 80.410507 lr 0.00090929 rank 0
2022-08-24 01:44:48,146 DEBUG TRAIN Batch 85/400 loss 28.653921 loss_att 14.955644 loss_ctc 60.616570 loss_ctc_origin 43.284595 loss_ctc0 101.057831 lr 0.00090920 rank 0
2022-08-24 01:45:17,054 DEBUG TRAIN Batch 85/500 loss 42.124321 loss_att 31.301035 loss_ctc 67.378654 loss_ctc_origin 48.707493 loss_ctc0 110.944687 lr 0.00090911 rank 0
2022-08-24 01:45:46,421 DEBUG TRAIN Batch 85/600 loss 35.127762 loss_att 20.094000 loss_ctc 70.206535 loss_ctc_origin 42.409466 loss_ctc0 135.066360 lr 0.00090901 rank 0
2022-08-24 01:46:14,798 DEBUG TRAIN Batch 85/700 loss 25.548515 loss_att 15.204332 loss_ctc 49.684944 loss_ctc_origin 40.704239 loss_ctc0 70.639915 lr 0.00090892 rank 0
2022-08-24 01:46:43,397 DEBUG TRAIN Batch 85/800 loss 19.884319 loss_att 9.403481 loss_ctc 44.339603 loss_ctc_origin 30.548244 loss_ctc0 76.519440 lr 0.00090882 rank 0
2022-08-24 01:47:11,220 DEBUG TRAIN Batch 85/900 loss 27.445576 loss_att 14.216219 loss_ctc 58.314075 loss_ctc_origin 42.838493 loss_ctc0 94.423767 lr 0.00090873 rank 0
2022-08-24 01:47:13,721 WARNING NaN or Inf found in input tensor.
2022-08-24 01:47:39,618 DEBUG TRAIN Batch 85/1000 loss 33.140316 loss_att 26.942656 loss_ctc 47.601517 loss_ctc_origin 36.341454 loss_ctc0 73.875000 lr 0.00090864 rank 0
2022-08-24 01:48:08,277 DEBUG TRAIN Batch 85/1100 loss 37.213066 loss_att 22.462601 loss_ctc 71.630821 loss_ctc_origin 42.798111 loss_ctc0 138.907135 lr 0.00090854 rank 0
2022-08-24 01:48:33,404 WARNING NaN or Inf found in input tensor.
2022-08-24 01:48:35,052 DEBUG TRAIN Batch 85/1200 loss 25.273363 loss_att 14.073224 loss_ctc 51.407021 loss_ctc_origin 42.576805 loss_ctc0 72.010849 lr 0.00090845 rank 0
2022-08-24 01:49:02,784 DEBUG TRAIN Batch 85/1300 loss 26.438957 loss_att 12.803769 loss_ctc 58.254398 loss_ctc_origin 45.307426 loss_ctc0 88.463997 lr 0.00090836 rank 0
2022-08-24 01:49:30,565 DEBUG TRAIN Batch 85/1400 loss 27.320267 loss_att 13.006433 loss_ctc 60.719208 loss_ctc_origin 46.700859 loss_ctc0 93.428680 lr 0.00090826 rank 0
2022-08-24 01:50:05,117 DEBUG TRAIN Batch 85/1500 loss 28.345379 loss_att 20.335930 loss_ctc 47.034096 loss_ctc_origin 36.001904 loss_ctc0 72.775871 lr 0.00090817 rank 0
2022-08-24 01:50:12,887 WARNING NaN or Inf found in input tensor.
2022-08-24 01:50:32,644 WARNING NaN or Inf found in input tensor.
2022-08-24 01:50:33,433 DEBUG TRAIN Batch 85/1600 loss 40.482956 loss_att 24.396244 loss_ctc 78.018616 loss_ctc_origin 45.723206 loss_ctc0 153.374573 lr 0.00090807 rank 0
2022-08-24 01:51:01,039 DEBUG TRAIN Batch 85/1700 loss 23.529972 loss_att 14.866366 loss_ctc 43.745049 loss_ctc_origin 33.830402 loss_ctc0 66.879227 lr 0.00090798 rank 0
2022-08-24 01:51:28,298 DEBUG TRAIN Batch 85/1800 loss 26.114628 loss_att 12.111202 loss_ctc 58.789284 loss_ctc_origin 45.675289 loss_ctc0 89.388611 lr 0.00090789 rank 0
2022-08-24 01:51:54,923 DEBUG TRAIN Batch 85/1900 loss 27.842787 loss_att 13.390997 loss_ctc 61.563629 loss_ctc_origin 46.128155 loss_ctc0 97.579735 lr 0.00090779 rank 0
2022-08-24 01:52:23,150 DEBUG TRAIN Batch 85/2000 loss 29.825598 loss_att 22.969795 loss_ctc 45.822472 loss_ctc_origin 35.711704 loss_ctc0 69.414261 lr 0.00090770 rank 0
2022-08-24 01:52:50,042 DEBUG TRAIN Batch 85/2100 loss 37.036621 loss_att 22.847275 loss_ctc 70.145096 loss_ctc_origin 43.958374 loss_ctc0 131.247437 lr 0.00090761 rank 0
2022-08-24 01:53:16,657 DEBUG TRAIN Batch 85/2200 loss 25.642719 loss_att 15.607666 loss_ctc 49.057842 loss_ctc_origin 39.712753 loss_ctc0 70.863045 lr 0.00090751 rank 0
2022-08-24 01:53:44,700 DEBUG TRAIN Batch 85/2300 loss 21.934464 loss_att 10.305372 loss_ctc 49.069004 loss_ctc_origin 36.390579 loss_ctc0 78.651993 lr 0.00090742 rank 0
2022-08-24 01:54:12,831 DEBUG TRAIN Batch 85/2400 loss 31.227348 loss_att 15.729277 loss_ctc 67.389519 loss_ctc_origin 53.093414 loss_ctc0 100.747101 lr 0.00090733 rank 0
2022-08-24 01:54:39,369 DEBUG TRAIN Batch 85/2500 loss 28.754642 loss_att 22.596920 loss_ctc 43.122665 loss_ctc_origin 31.046709 loss_ctc0 71.299896 lr 0.00090723 rank 0
2022-08-24 01:54:51,832 WARNING NaN or Inf found in input tensor.
2022-08-24 01:55:05,988 DEBUG TRAIN Batch 85/2600 loss 43.621300 loss_att 25.189308 loss_ctc 86.629272 loss_ctc_origin 44.788746 loss_ctc0 184.257156 lr 0.00090714 rank 0
2022-08-24 01:55:32,683 DEBUG TRAIN Batch 85/2700 loss 23.475544 loss_att 13.347547 loss_ctc 47.107536 loss_ctc_origin 38.109116 loss_ctc0 68.103851 lr 0.00090705 rank 0
2022-08-24 01:55:59,935 DEBUG TRAIN Batch 85/2800 loss 23.867390 loss_att 11.679058 loss_ctc 52.306831 loss_ctc_origin 38.146202 loss_ctc0 85.348297 lr 0.00090695 rank 0
2022-08-24 01:56:27,043 DEBUG TRAIN Batch 85/2900 loss 30.495644 loss_att 15.311593 loss_ctc 65.925095 loss_ctc_origin 50.536098 loss_ctc0 101.832764 lr 0.00090686 rank 0
2022-08-24 01:56:59,373 DEBUG TRAIN Batch 85/3000 loss 30.058754 loss_att 21.411129 loss_ctc 50.236542 loss_ctc_origin 31.700226 loss_ctc0 93.487953 lr 0.00090677 rank 0
2022-08-24 01:57:25,807 DEBUG TRAIN Batch 85/3100 loss 32.880989 loss_att 16.970842 loss_ctc 70.004669 loss_ctc_origin 33.135338 loss_ctc0 156.033096 lr 0.00090667 rank 0
2022-08-24 01:57:51,858 DEBUG TRAIN Batch 85/3200 loss 25.846340 loss_att 15.891636 loss_ctc 49.073982 loss_ctc_origin 37.712582 loss_ctc0 75.583916 lr 0.00090658 rank 0
2022-08-24 01:58:19,084 DEBUG TRAIN Batch 85/3300 loss 19.300215 loss_att 9.067466 loss_ctc 43.176628 loss_ctc_origin 30.645416 loss_ctc0 72.416122 lr 0.00090649 rank 0
2022-08-24 01:58:47,107 DEBUG TRAIN Batch 85/3400 loss 31.263992 loss_att 14.905579 loss_ctc 69.433624 loss_ctc_origin 54.687416 loss_ctc0 103.841446 lr 0.00090639 rank 0
2022-08-24 01:59:14,647 DEBUG TRAIN Batch 85/3500 loss 49.814743 loss_att 32.646744 loss_ctc 89.873398 loss_ctc_origin 51.855579 loss_ctc0 178.581635 lr 0.00090630 rank 0
2022-08-24 01:59:40,666 DEBUG TRAIN Batch 85/3600 loss 40.846420 loss_att 23.344543 loss_ctc 81.684128 loss_ctc_origin 47.276741 loss_ctc0 161.968033 lr 0.00090621 rank 0
2022-08-24 02:00:06,542 DEBUG TRAIN Batch 85/3700 loss 26.134979 loss_att 12.974526 loss_ctc 56.842697 loss_ctc_origin 46.009483 loss_ctc0 82.120193 lr 0.00090612 rank 0
2022-08-24 02:00:33,260 DEBUG TRAIN Batch 85/3800 loss 24.809864 loss_att 12.374969 loss_ctc 53.824615 loss_ctc_origin 41.633041 loss_ctc0 82.271622 lr 0.00090602 rank 0
2022-08-24 02:01:01,971 DEBUG TRAIN Batch 85/3900 loss 27.472193 loss_att 13.005091 loss_ctc 61.228760 loss_ctc_origin 45.102009 loss_ctc0 98.857849 lr 0.00090593 rank 0
2022-08-24 02:01:28,857 DEBUG TRAIN Batch 85/4000 loss 43.160080 loss_att 29.159336 loss_ctc 75.828484 loss_ctc_origin 49.173775 loss_ctc0 138.022797 lr 0.00090584 rank 0
2022-08-24 02:01:55,661 DEBUG TRAIN Batch 85/4100 loss 43.028923 loss_att 23.892292 loss_ctc 87.681053 loss_ctc_origin 43.125374 loss_ctc0 191.644287 lr 0.00090574 rank 0
2022-08-24 02:02:21,721 DEBUG TRAIN Batch 85/4200 loss 24.582565 loss_att 17.056944 loss_ctc 42.142349 loss_ctc_origin 33.776932 loss_ctc0 61.661655 lr 0.00090565 rank 0
2022-08-24 02:02:39,796 WARNING NaN or Inf found in input tensor.
2022-08-24 02:02:49,595 DEBUG TRAIN Batch 85/4300 loss 26.897724 loss_att 12.704473 loss_ctc 60.015305 loss_ctc_origin 49.031113 loss_ctc0 85.645081 lr 0.00090556 rank 0
2022-08-24 02:03:16,280 DEBUG TRAIN Batch 85/4400 loss 22.548065 loss_att 10.395048 loss_ctc 50.905102 loss_ctc_origin 33.501842 loss_ctc0 91.512703 lr 0.00090547 rank 0
2022-08-24 02:03:48,957 DEBUG TRAIN Batch 85/4500 loss 43.933090 loss_att 27.869400 loss_ctc 81.415039 loss_ctc_origin 50.402927 loss_ctc0 153.776642 lr 0.00090537 rank 0
2022-08-24 02:04:16,833 DEBUG TRAIN Batch 85/4600 loss 36.741764 loss_att 18.887503 loss_ctc 78.401711 loss_ctc_origin 36.005508 loss_ctc0 177.326187 lr 0.00090528 rank 0
2022-08-24 02:04:44,563 DEBUG TRAIN Batch 85/4700 loss 21.692686 loss_att 13.088242 loss_ctc 41.769722 loss_ctc_origin 31.232347 loss_ctc0 66.356934 lr 0.00090519 rank 0
2022-08-24 02:05:12,283 DEBUG TRAIN Batch 85/4800 loss 22.373520 loss_att 9.719558 loss_ctc 51.899429 loss_ctc_origin 38.017235 loss_ctc0 84.291222 lr 0.00090509 rank 0
2022-08-24 02:05:38,257 DEBUG TRAIN Batch 85/4900 loss 26.645983 loss_att 12.997750 loss_ctc 58.491859 loss_ctc_origin 42.208218 loss_ctc0 96.487030 lr 0.00090500 rank 0
2022-08-24 02:06:05,673 DEBUG TRAIN Batch 85/5000 loss 41.215130 loss_att 26.268625 loss_ctc 76.090309 loss_ctc_origin 47.816551 loss_ctc0 142.062408 lr 0.00090491 rank 0
2022-08-24 02:06:33,473 DEBUG TRAIN Batch 85/5100 loss 45.164406 loss_att 25.794037 loss_ctc 90.361931 loss_ctc_origin 46.946655 loss_ctc0 191.664230 lr 0.00090482 rank 0
2022-08-24 02:06:59,470 DEBUG TRAIN Batch 85/5200 loss 23.064562 loss_att 14.144483 loss_ctc 43.878078 loss_ctc_origin 34.754276 loss_ctc0 65.166946 lr 0.00090472 rank 0
2022-08-24 02:07:26,740 DEBUG TRAIN Batch 85/5300 loss 26.389301 loss_att 12.750210 loss_ctc 58.213844 loss_ctc_origin 46.424309 loss_ctc0 85.722763 lr 0.00090463 rank 0
2022-08-24 02:07:53,394 DEBUG TRAIN Batch 85/5400 loss 28.706791 loss_att 14.215006 loss_ctc 62.520950 loss_ctc_origin 45.233078 loss_ctc0 102.859314 lr 0.00090454 rank 0
2022-08-24 02:08:20,346 DEBUG TRAIN Batch 85/5500 loss 32.338974 loss_att 24.046558 loss_ctc 51.687939 loss_ctc_origin 37.162361 loss_ctc0 85.580948 lr 0.00090445 rank 0
2022-08-24 02:08:48,318 DEBUG TRAIN Batch 85/5600 loss 35.284363 loss_att 18.568132 loss_ctc 74.288895 loss_ctc_origin 37.469532 loss_ctc0 160.200745 lr 0.00090435 rank 0
2022-08-24 02:09:10,925 DEBUG CV Batch 85/0 loss 14.937963 loss_att 11.097884 loss_ctc 23.898148 loss_ctc_origin 17.356724 loss_ctc0 39.161465 history loss 14.059260 rank 0
2022-08-24 02:09:20,871 DEBUG CV Batch 85/100 loss 23.856380 loss_att 18.373270 loss_ctc 36.650303 loss_ctc_origin 26.681023 loss_ctc0 59.911953 history loss 30.289979 rank 0
2022-08-24 02:09:29,781 DEBUG CV Batch 85/200 loss 27.019394 loss_att 21.176434 loss_ctc 40.652969 loss_ctc_origin 30.722500 loss_ctc0 63.824066 history loss 31.562921 rank 0
2022-08-24 02:09:39,227 DEBUG CV Batch 85/300 loss 25.968666 loss_att 19.942074 loss_ctc 40.030708 loss_ctc_origin 24.681461 loss_ctc0 75.845619 history loss 30.583707 rank 0
2022-08-24 02:09:49,197 DEBUG CV Batch 85/400 loss 42.033222 loss_att 33.706402 loss_ctc 61.462471 loss_ctc_origin 45.003834 loss_ctc0 99.865959 history loss 28.787177 rank 0
2022-08-24 02:09:58,696 DEBUG CV Batch 85/500 loss 19.833029 loss_att 15.400546 loss_ctc 30.175488 loss_ctc_origin 24.089592 loss_ctc0 44.375908 history loss 28.410868 rank 0
2022-08-24 02:10:08,541 DEBUG CV Batch 85/600 loss 19.518837 loss_att 13.804658 loss_ctc 32.851921 loss_ctc_origin 22.525225 loss_ctc0 56.947548 history loss 28.201683 rank 0
2022-08-24 02:10:18,231 DEBUG CV Batch 85/700 loss 21.732302 loss_att 15.281071 loss_ctc 36.785172 loss_ctc_origin 24.409264 loss_ctc0 65.662292 history loss 27.835408 rank 0
2022-08-24 02:10:28,091 DEBUG CV Batch 85/800 loss 24.272564 loss_att 18.351028 loss_ctc 38.089481 loss_ctc_origin 23.091713 loss_ctc0 73.084274 history loss 27.771145 rank 0
2022-08-24 02:10:38,277 INFO Epoch 85 CV info cv_loss 27.862483644648556
2022-08-24 02:10:38,278 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/85.pt
2022-08-24 02:10:38,724 INFO Epoch 86 TRAIN info lr 0.0009042759408872513
2022-08-24 02:10:38,728 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 02:11:06,546 DEBUG TRAIN Batch 86/0 loss 41.843071 loss_att 28.023941 loss_ctc 74.087708 loss_ctc_origin 49.715187 loss_ctc0 130.956924 lr 0.00090427 rank 0
2022-08-24 02:11:35,251 DEBUG TRAIN Batch 86/100 loss 40.928867 loss_att 25.322142 loss_ctc 77.344559 loss_ctc_origin 50.311687 loss_ctc0 140.421265 lr 0.00090418 rank 0
2022-08-24 02:12:03,784 DEBUG TRAIN Batch 86/200 loss 21.223343 loss_att 11.955047 loss_ctc 42.849365 loss_ctc_origin 34.011463 loss_ctc0 63.471138 lr 0.00090409 rank 0
2022-08-24 02:12:33,395 DEBUG TRAIN Batch 86/300 loss 24.416348 loss_att 10.978646 loss_ctc 55.770981 loss_ctc_origin 43.811157 loss_ctc0 83.677231 lr 0.00090400 rank 0
2022-08-24 02:13:01,716 DEBUG TRAIN Batch 86/400 loss 24.971859 loss_att 11.172091 loss_ctc 57.171318 loss_ctc_origin 39.586960 loss_ctc0 98.201485 lr 0.00090390 rank 0
2022-08-24 02:13:30,647 DEBUG TRAIN Batch 86/500 loss 36.173435 loss_att 22.889122 loss_ctc 67.170166 loss_ctc_origin 39.824585 loss_ctc0 130.976532 lr 0.00090381 rank 0
2022-08-24 02:14:00,087 DEBUG TRAIN Batch 86/600 loss 39.797329 loss_att 23.573442 loss_ctc 77.653061 loss_ctc_origin 46.794952 loss_ctc0 149.655304 lr 0.00090372 rank 0
2022-08-24 02:14:29,895 DEBUG TRAIN Batch 86/700 loss 23.281231 loss_att 15.736142 loss_ctc 40.886436 loss_ctc_origin 31.342815 loss_ctc0 63.154892 lr 0.00090363 rank 0
2022-08-24 02:14:59,008 DEBUG TRAIN Batch 86/800 loss 19.969801 loss_att 9.675966 loss_ctc 43.988747 loss_ctc_origin 31.214474 loss_ctc0 73.795372 lr 0.00090353 rank 0
2022-08-24 02:15:27,795 DEBUG TRAIN Batch 86/900 loss 24.034216 loss_att 10.690090 loss_ctc 55.170509 loss_ctc_origin 39.469688 loss_ctc0 91.805748 lr 0.00090344 rank 0
2022-08-24 02:15:56,834 DEBUG TRAIN Batch 86/1000 loss 38.597389 loss_att 25.918940 loss_ctc 68.180443 loss_ctc_origin 38.232010 loss_ctc0 138.060120 lr 0.00090335 rank 0
2022-08-24 02:16:25,137 DEBUG TRAIN Batch 86/1100 loss 38.124874 loss_att 21.455063 loss_ctc 77.021095 loss_ctc_origin 46.619835 loss_ctc0 147.957367 lr 0.00090326 rank 0
2022-08-24 02:16:53,493 DEBUG TRAIN Batch 86/1200 loss 22.887390 loss_att 11.989190 loss_ctc 48.316517 loss_ctc_origin 36.547253 loss_ctc0 75.778130 lr 0.00090317 rank 0
2022-08-24 02:17:23,054 DEBUG TRAIN Batch 86/1300 loss 25.263172 loss_att 13.602669 loss_ctc 52.471008 loss_ctc_origin 40.975010 loss_ctc0 79.295006 lr 0.00090307 rank 0
2022-08-24 02:17:52,135 DEBUG TRAIN Batch 86/1400 loss 25.016356 loss_att 10.630103 loss_ctc 58.584274 loss_ctc_origin 39.693752 loss_ctc0 102.662155 lr 0.00090298 rank 0
2022-08-24 02:18:26,948 DEBUG TRAIN Batch 86/1500 loss 29.223984 loss_att 22.050842 loss_ctc 45.961311 loss_ctc_origin 34.699257 loss_ctc0 72.239426 lr 0.00090289 rank 0
2022-08-24 02:18:55,675 DEBUG TRAIN Batch 86/1600 loss 47.392170 loss_att 33.744724 loss_ctc 79.236206 loss_ctc_origin 48.456287 loss_ctc0 151.056015 lr 0.00090280 rank 0
2022-08-24 02:19:24,099 DEBUG TRAIN Batch 86/1700 loss 21.298542 loss_att 12.665778 loss_ctc 41.441658 loss_ctc_origin 31.380356 loss_ctc0 64.918030 lr 0.00090271 rank 0
2022-08-24 02:19:51,288 DEBUG TRAIN Batch 86/1800 loss 24.819775 loss_att 12.893351 loss_ctc 52.648102 loss_ctc_origin 39.034203 loss_ctc0 84.413864 lr 0.00090261 rank 0
2022-08-24 02:20:16,176 WARNING NaN or Inf found in input tensor.
2022-08-24 02:20:20,554 DEBUG TRAIN Batch 86/1900 loss 25.967442 loss_att 11.754922 loss_ctc 59.129986 loss_ctc_origin 43.036137 loss_ctc0 96.682297 lr 0.00090252 rank 0
2022-08-24 02:20:50,301 DEBUG TRAIN Batch 86/2000 loss 31.255411 loss_att 19.154161 loss_ctc 59.491657 loss_ctc_origin 33.208881 loss_ctc0 120.818138 lr 0.00090243 rank 0
2022-08-24 02:21:17,996 DEBUG TRAIN Batch 86/2100 loss 45.519737 loss_att 24.124825 loss_ctc 95.441193 loss_ctc_origin 45.829010 loss_ctc0 211.202927 lr 0.00090234 rank 0
2022-08-24 02:21:36,759 WARNING NaN or Inf found in input tensor.
2022-08-24 02:21:46,783 DEBUG TRAIN Batch 86/2200 loss 24.408943 loss_att 15.556195 loss_ctc 45.065353 loss_ctc_origin 36.832180 loss_ctc0 64.276085 lr 0.00090225 rank 0
2022-08-24 02:22:15,058 DEBUG TRAIN Batch 86/2300 loss 24.886633 loss_att 12.975443 loss_ctc 52.679409 loss_ctc_origin 39.755371 loss_ctc0 82.835495 lr 0.00090215 rank 0
2022-08-24 02:22:43,048 DEBUG TRAIN Batch 86/2400 loss 27.725304 loss_att 13.275952 loss_ctc 61.440453 loss_ctc_origin 45.954720 loss_ctc0 97.573822 lr 0.00090206 rank 0
2022-08-24 02:23:12,151 DEBUG TRAIN Batch 86/2500 loss 53.032852 loss_att 36.167351 loss_ctc 92.385681 loss_ctc_origin 53.852245 loss_ctc0 182.297012 lr 0.00090197 rank 0
2022-08-24 02:23:40,015 DEBUG TRAIN Batch 86/2600 loss 52.749573 loss_att 28.194704 loss_ctc 110.044273 loss_ctc_origin 58.722820 loss_ctc0 229.794327 lr 0.00090188 rank 0
2022-08-24 02:23:54,314 WARNING NaN or Inf found in input tensor.
2022-08-24 02:24:09,409 DEBUG TRAIN Batch 86/2700 loss 28.368534 loss_att 18.461514 loss_ctc 51.484917 loss_ctc_origin 41.825184 loss_ctc0 74.024284 lr 0.00090179 rank 0
2022-08-24 02:24:36,785 DEBUG TRAIN Batch 86/2800 loss 23.928246 loss_att 11.619774 loss_ctc 52.648014 loss_ctc_origin 39.654091 loss_ctc0 82.967163 lr 0.00090170 rank 0
2022-08-24 02:25:05,266 DEBUG TRAIN Batch 86/2900 loss 28.562782 loss_att 13.003262 loss_ctc 64.868324 loss_ctc_origin 49.946922 loss_ctc0 99.684921 lr 0.00090160 rank 0
2022-08-24 02:25:40,932 DEBUG TRAIN Batch 86/3000 loss 32.858215 loss_att 24.548389 loss_ctc 52.247814 loss_ctc_origin 38.700829 loss_ctc0 83.857445 lr 0.00090151 rank 0
2022-08-24 02:25:56,398 WARNING NaN or Inf found in input tensor.
2022-08-24 02:26:09,768 DEBUG TRAIN Batch 86/3100 loss 36.093342 loss_att 20.168919 loss_ctc 73.250320 loss_ctc_origin 40.315247 loss_ctc0 150.098816 lr 0.00090142 rank 0
2022-08-24 02:26:37,526 DEBUG TRAIN Batch 86/3200 loss 22.418455 loss_att 13.441301 loss_ctc 43.365147 loss_ctc_origin 33.851078 loss_ctc0 65.564636 lr 0.00090133 rank 0
2022-08-24 02:27:06,556 DEBUG TRAIN Batch 86/3300 loss 29.345882 loss_att 15.585232 loss_ctc 61.454067 loss_ctc_origin 49.166008 loss_ctc0 90.126198 lr 0.00090124 rank 0
2022-08-24 02:27:35,547 DEBUG TRAIN Batch 86/3400 loss 25.689537 loss_att 12.435369 loss_ctc 56.615929 loss_ctc_origin 39.701950 loss_ctc0 96.081879 lr 0.00090115 rank 0
2022-08-24 02:28:03,435 DEBUG TRAIN Batch 86/3500 loss 26.018665 loss_att 19.299456 loss_ctc 41.696819 loss_ctc_origin 31.541248 loss_ctc0 65.393150 lr 0.00090105 rank 0
2022-08-24 02:28:31,892 DEBUG TRAIN Batch 86/3600 loss 37.568520 loss_att 21.089050 loss_ctc 76.020615 loss_ctc_origin 38.660454 loss_ctc0 163.194336 lr 0.00090096 rank 0
2022-08-24 02:29:01,825 DEBUG TRAIN Batch 86/3700 loss 24.938938 loss_att 14.846303 loss_ctc 48.488419 loss_ctc_origin 38.993080 loss_ctc0 70.644196 lr 0.00090087 rank 0
2022-08-24 02:29:30,177 DEBUG TRAIN Batch 86/3800 loss 22.403046 loss_att 11.350790 loss_ctc 48.191643 loss_ctc_origin 35.649704 loss_ctc0 77.456169 lr 0.00090078 rank 0
2022-08-24 02:29:58,798 DEBUG TRAIN Batch 86/3900 loss 28.739563 loss_att 15.064037 loss_ctc 60.649128 loss_ctc_origin 44.680122 loss_ctc0 97.910141 lr 0.00090069 rank 0
2022-08-24 02:30:28,403 DEBUG TRAIN Batch 86/4000 loss 42.741859 loss_att 27.789465 loss_ctc 77.630783 loss_ctc_origin 47.626923 loss_ctc0 147.639786 lr 0.00090060 rank 0
2022-08-24 02:30:57,087 DEBUG TRAIN Batch 86/4100 loss 43.543766 loss_att 27.195889 loss_ctc 81.688812 loss_ctc_origin 49.835648 loss_ctc0 156.012863 lr 0.00090051 rank 0
2022-08-24 02:31:23,898 DEBUG TRAIN Batch 86/4200 loss 23.726089 loss_att 13.354373 loss_ctc 47.926762 loss_ctc_origin 37.876816 loss_ctc0 71.376633 lr 0.00090042 rank 0
2022-08-24 02:31:52,996 DEBUG TRAIN Batch 86/4300 loss 24.256760 loss_att 13.419150 loss_ctc 49.544510 loss_ctc_origin 36.866665 loss_ctc0 79.126152 lr 0.00090032 rank 0
2022-08-24 02:32:23,605 DEBUG TRAIN Batch 86/4400 loss 27.690971 loss_att 14.132609 loss_ctc 59.327148 loss_ctc_origin 43.372734 loss_ctc0 96.554108 lr 0.00090023 rank 0
2022-08-24 02:32:57,398 DEBUG TRAIN Batch 86/4500 loss 31.926147 loss_att 21.598330 loss_ctc 56.024387 loss_ctc_origin 35.319443 loss_ctc0 104.335922 lr 0.00090014 rank 0
2022-08-24 02:33:26,453 DEBUG TRAIN Batch 86/4600 loss 45.000149 loss_att 28.739243 loss_ctc 82.942261 loss_ctc_origin 48.935280 loss_ctc0 162.291870 lr 0.00090005 rank 0
2022-08-24 02:33:54,497 DEBUG TRAIN Batch 86/4700 loss 23.541838 loss_att 13.938241 loss_ctc 45.950230 loss_ctc_origin 37.357647 loss_ctc0 65.999588 lr 0.00089996 rank 0
2022-08-24 02:34:23,214 DEBUG TRAIN Batch 86/4800 loss 26.653286 loss_att 15.452034 loss_ctc 52.789536 loss_ctc_origin 39.356575 loss_ctc0 84.133102 lr 0.00089987 rank 0
2022-08-24 02:34:52,044 DEBUG TRAIN Batch 86/4900 loss 26.930599 loss_att 13.627450 loss_ctc 57.971275 loss_ctc_origin 41.098297 loss_ctc0 97.341553 lr 0.00089978 rank 0
2022-08-24 02:35:20,644 DEBUG TRAIN Batch 86/5000 loss 39.431778 loss_att 22.487883 loss_ctc 78.967529 loss_ctc_origin 41.103355 loss_ctc0 167.317261 lr 0.00089969 rank 0
2022-08-24 02:35:48,531 DEBUG TRAIN Batch 86/5100 loss 39.939434 loss_att 21.825859 loss_ctc 82.204437 loss_ctc_origin 42.474522 loss_ctc0 174.907562 lr 0.00089959 rank 0
2022-08-24 02:36:16,698 DEBUG TRAIN Batch 86/5200 loss 22.518673 loss_att 12.825959 loss_ctc 45.135002 loss_ctc_origin 34.471210 loss_ctc0 70.017174 lr 0.00089950 rank 0
2022-08-24 02:36:45,239 DEBUG TRAIN Batch 86/5300 loss 23.451488 loss_att 11.547318 loss_ctc 51.227890 loss_ctc_origin 37.919476 loss_ctc0 82.280853 lr 0.00089941 rank 0
2022-08-24 02:37:14,936 DEBUG TRAIN Batch 86/5400 loss 30.800308 loss_att 17.155937 loss_ctc 62.637177 loss_ctc_origin 48.112251 loss_ctc0 96.528679 lr 0.00089932 rank 0
2022-08-24 02:37:43,156 DEBUG TRAIN Batch 86/5500 loss 43.887257 loss_att 24.570185 loss_ctc 88.960419 loss_ctc_origin 48.491547 loss_ctc0 183.387802 lr 0.00089923 rank 0
2022-08-24 02:38:04,107 WARNING NaN or Inf found in input tensor.
2022-08-24 02:38:10,759 DEBUG TRAIN Batch 86/5600 loss 42.750717 loss_att 21.725210 loss_ctc 91.810234 loss_ctc_origin 48.201408 loss_ctc0 193.564148 lr 0.00089914 rank 0
2022-08-24 02:38:32,847 DEBUG CV Batch 86/0 loss 13.523636 loss_att 9.720011 loss_ctc 22.398762 loss_ctc_origin 16.366627 loss_ctc0 36.473747 history loss 12.728128 rank 0
2022-08-24 02:38:42,999 DEBUG CV Batch 86/100 loss 24.355629 loss_att 18.237083 loss_ctc 38.632233 loss_ctc_origin 28.721996 loss_ctc0 61.756115 history loss 29.687205 rank 0
2022-08-24 02:38:52,386 DEBUG CV Batch 86/200 loss 26.911097 loss_att 20.710779 loss_ctc 41.378502 loss_ctc_origin 31.673004 loss_ctc0 64.024658 history loss 30.906659 rank 0
2022-08-24 02:39:02,013 DEBUG CV Batch 86/300 loss 25.842384 loss_att 19.912766 loss_ctc 39.678162 loss_ctc_origin 24.340164 loss_ctc0 75.466820 history loss 29.969660 rank 0
2022-08-24 02:39:12,747 DEBUG CV Batch 86/400 loss 40.506477 loss_att 32.218342 loss_ctc 59.845459 loss_ctc_origin 42.970718 loss_ctc0 99.219849 history loss 28.227052 rank 0
2022-08-24 02:39:23,676 DEBUG CV Batch 86/500 loss 18.516649 loss_att 14.154076 loss_ctc 28.695986 loss_ctc_origin 22.148281 loss_ctc0 43.973961 history loss 27.881156 rank 0
2022-08-24 02:39:34,170 DEBUG CV Batch 86/600 loss 18.458454 loss_att 12.829109 loss_ctc 31.593590 loss_ctc_origin 20.779369 loss_ctc0 56.826767 history loss 27.683569 rank 0
2022-08-24 02:39:45,022 DEBUG CV Batch 86/700 loss 21.285145 loss_att 14.674515 loss_ctc 36.709946 loss_ctc_origin 23.906078 loss_ctc0 66.585640 history loss 27.338405 rank 0
2022-08-24 02:39:55,497 DEBUG CV Batch 86/800 loss 23.771166 loss_att 17.997608 loss_ctc 37.242798 loss_ctc_origin 22.298735 loss_ctc0 72.112282 history loss 27.271382 rank 0
2022-08-24 02:40:03,980 INFO Epoch 86 CV info cv_loss 27.334835416466724
2022-08-24 02:40:03,980 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/86.pt
2022-08-24 02:40:04,425 INFO Epoch 87 TRAIN info lr 0.0008990639323987537
2022-08-24 02:40:04,429 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 02:40:31,103 DEBUG TRAIN Batch 87/0 loss 41.994713 loss_att 26.493435 loss_ctc 78.164368 loss_ctc_origin 39.832962 loss_ctc0 167.604294 lr 0.00089906 rank 0
2022-08-24 02:41:00,466 DEBUG TRAIN Batch 87/100 loss 38.642601 loss_att 21.128874 loss_ctc 79.507965 loss_ctc_origin 45.850677 loss_ctc0 158.041626 lr 0.00089897 rank 0
2022-08-24 02:41:28,770 DEBUG TRAIN Batch 87/200 loss 26.762722 loss_att 17.176861 loss_ctc 49.129730 loss_ctc_origin 40.757984 loss_ctc0 68.663811 lr 0.00089888 rank 0
2022-08-24 02:41:56,969 DEBUG TRAIN Batch 87/300 loss 21.773794 loss_att 10.857522 loss_ctc 47.245094 loss_ctc_origin 34.257431 loss_ctc0 77.549637 lr 0.00089879 rank 0
2022-08-24 02:42:26,200 DEBUG TRAIN Batch 87/400 loss 26.172550 loss_att 11.598666 loss_ctc 60.178276 loss_ctc_origin 41.621803 loss_ctc0 103.476707 lr 0.00089870 rank 0
2022-08-24 02:42:54,347 DEBUG TRAIN Batch 87/500 loss 48.033623 loss_att 31.434969 loss_ctc 86.763809 loss_ctc_origin 49.573349 loss_ctc0 173.541534 lr 0.00089861 rank 0
2022-08-24 02:43:23,050 DEBUG TRAIN Batch 87/600 loss 46.826256 loss_att 25.254444 loss_ctc 97.160484 loss_ctc_origin 47.712563 loss_ctc0 212.538971 lr 0.00089852 rank 0
2022-08-24 02:43:51,272 DEBUG TRAIN Batch 87/700 loss 23.439754 loss_att 12.128527 loss_ctc 49.832619 loss_ctc_origin 38.873444 loss_ctc0 75.404030 lr 0.00089843 rank 0
2022-08-24 02:44:20,764 DEBUG TRAIN Batch 87/800 loss 27.535755 loss_att 14.021044 loss_ctc 59.070084 loss_ctc_origin 48.417923 loss_ctc0 83.925133 lr 0.00089833 rank 0
2022-08-24 02:44:50,225 DEBUG TRAIN Batch 87/900 loss 29.847660 loss_att 14.782782 loss_ctc 64.999039 loss_ctc_origin 49.264275 loss_ctc0 101.713470 lr 0.00089824 rank 0
2022-08-24 02:45:18,749 DEBUG TRAIN Batch 87/1000 loss 46.206619 loss_att 30.549273 loss_ctc 82.740417 loss_ctc_origin 46.128914 loss_ctc0 168.167252 lr 0.00089815 rank 0
2022-08-24 02:45:47,447 DEBUG TRAIN Batch 87/1100 loss 47.319408 loss_att 27.014900 loss_ctc 94.696594 loss_ctc_origin 55.750626 loss_ctc0 185.570526 lr 0.00089806 rank 0
2022-08-24 02:46:15,214 DEBUG TRAIN Batch 87/1200 loss 21.814203 loss_att 14.032393 loss_ctc 39.971760 loss_ctc_origin 28.464611 loss_ctc0 66.821770 lr 0.00089797 rank 0
2022-08-24 02:46:44,431 DEBUG TRAIN Batch 87/1300 loss 20.795038 loss_att 9.997535 loss_ctc 45.989212 loss_ctc_origin 32.746910 loss_ctc0 76.887909 lr 0.00089788 rank 0
2022-08-24 02:47:11,371 DEBUG TRAIN Batch 87/1400 loss 27.767887 loss_att 12.667715 loss_ctc 63.001625 loss_ctc_origin 46.538097 loss_ctc0 101.416527 lr 0.00089779 rank 0
2022-08-24 02:47:48,095 DEBUG TRAIN Batch 87/1500 loss 43.273293 loss_att 28.333292 loss_ctc 78.133286 loss_ctc_origin 50.353600 loss_ctc0 142.952560 lr 0.00089770 rank 0
2022-08-24 02:48:17,609 DEBUG TRAIN Batch 87/1600 loss 42.879410 loss_att 26.446625 loss_ctc 81.222580 loss_ctc_origin 51.527397 loss_ctc0 150.511353 lr 0.00089761 rank 0
2022-08-24 02:48:46,067 DEBUG TRAIN Batch 87/1700 loss 23.212931 loss_att 13.702394 loss_ctc 45.404182 loss_ctc_origin 34.511505 loss_ctc0 70.820427 lr 0.00089752 rank 0
2022-08-24 02:49:13,948 DEBUG TRAIN Batch 87/1800 loss 26.772316 loss_att 13.082674 loss_ctc 58.714813 loss_ctc_origin 45.657639 loss_ctc0 89.181549 lr 0.00089743 rank 0
2022-08-24 02:49:41,723 DEBUG TRAIN Batch 87/1900 loss 27.289558 loss_att 13.334922 loss_ctc 59.850380 loss_ctc_origin 44.592316 loss_ctc0 95.452530 lr 0.00089734 rank 0
2022-08-24 02:50:10,438 DEBUG TRAIN Batch 87/2000 loss 37.113377 loss_att 20.793091 loss_ctc 75.194046 loss_ctc_origin 39.775562 loss_ctc0 157.837158 lr 0.00089725 rank 0
2022-08-24 02:50:38,435 DEBUG TRAIN Batch 87/2100 loss 43.165833 loss_att 22.415543 loss_ctc 91.583176 loss_ctc_origin 48.469208 loss_ctc0 192.182434 lr 0.00089716 rank 0
2022-08-24 02:51:06,520 DEBUG TRAIN Batch 87/2200 loss 23.093695 loss_att 12.530990 loss_ctc 47.740005 loss_ctc_origin 38.829430 loss_ctc0 68.531342 lr 0.00089707 rank 0
2022-08-24 02:51:34,125 DEBUG TRAIN Batch 87/2300 loss 21.939163 loss_att 10.498444 loss_ctc 48.634178 loss_ctc_origin 34.205097 loss_ctc0 82.302032 lr 0.00089698 rank 0
2022-08-24 02:52:03,637 DEBUG TRAIN Batch 87/2400 loss 26.269215 loss_att 13.445242 loss_ctc 56.191818 loss_ctc_origin 39.399841 loss_ctc0 95.373085 lr 0.00089689 rank 0
2022-08-24 02:52:32,998 DEBUG TRAIN Batch 87/2500 loss 46.287811 loss_att 30.383593 loss_ctc 83.397652 loss_ctc_origin 43.510036 loss_ctc0 176.468750 lr 0.00089680 rank 0
2022-08-24 02:53:01,929 DEBUG TRAIN Batch 87/2600 loss 49.064110 loss_att 27.172430 loss_ctc 100.144699 loss_ctc_origin 54.436337 loss_ctc0 206.797546 lr 0.00089671 rank 0
2022-08-24 02:53:30,492 DEBUG TRAIN Batch 87/2700 loss 26.761280 loss_att 16.986326 loss_ctc 49.569500 loss_ctc_origin 40.352104 loss_ctc0 71.076752 lr 0.00089662 rank 0
2022-08-24 02:53:59,924 DEBUG TRAIN Batch 87/2800 loss 24.123569 loss_att 12.790770 loss_ctc 50.566765 loss_ctc_origin 38.028328 loss_ctc0 79.823120 lr 0.00089653 rank 0
2022-08-24 02:54:28,772 DEBUG TRAIN Batch 87/2900 loss 25.700180 loss_att 12.452558 loss_ctc 56.611301 loss_ctc_origin 40.168030 loss_ctc0 94.978935 lr 0.00089644 rank 0
2022-08-24 02:55:02,411 DEBUG TRAIN Batch 87/3000 loss 47.669930 loss_att 28.990200 loss_ctc 91.255959 loss_ctc_origin 54.794819 loss_ctc0 176.331940 lr 0.00089635 rank 0
2022-08-24 02:55:30,528 DEBUG TRAIN Batch 87/3100 loss 55.796444 loss_att 32.320595 loss_ctc 110.573425 loss_ctc_origin 60.790466 loss_ctc0 226.733673 lr 0.00089626 rank 0
2022-08-24 02:55:58,473 DEBUG TRAIN Batch 87/3200 loss 19.885530 loss_att 10.784185 loss_ctc 41.121998 loss_ctc_origin 29.971642 loss_ctc0 67.139496 lr 0.00089617 rank 0
2022-08-24 02:56:27,507 DEBUG TRAIN Batch 87/3300 loss 24.917322 loss_att 11.930594 loss_ctc 55.219685 loss_ctc_origin 43.612164 loss_ctc0 82.303894 lr 0.00089608 rank 0
2022-08-24 02:56:56,389 DEBUG TRAIN Batch 87/3400 loss 26.749592 loss_att 11.886749 loss_ctc 61.429554 loss_ctc_origin 42.966240 loss_ctc0 104.510612 lr 0.00089599 rank 0
2022-08-24 02:57:25,864 DEBUG TRAIN Batch 87/3500 loss 46.005882 loss_att 31.440933 loss_ctc 79.990753 loss_ctc_origin 53.040749 loss_ctc0 142.874100 lr 0.00089590 rank 0
2022-08-24 02:57:52,813 DEBUG TRAIN Batch 87/3600 loss 45.306488 loss_att 28.965654 loss_ctc 83.435104 loss_ctc_origin 49.040512 loss_ctc0 163.689163 lr 0.00089581 rank 0
2022-08-24 02:58:20,806 DEBUG TRAIN Batch 87/3700 loss 26.145206 loss_att 15.395889 loss_ctc 51.226944 loss_ctc_origin 41.910156 loss_ctc0 72.966110 lr 0.00089572 rank 0
2022-08-24 02:58:47,418 DEBUG TRAIN Batch 87/3800 loss 23.496746 loss_att 12.303750 loss_ctc 49.613739 loss_ctc_origin 36.715916 loss_ctc0 79.708664 lr 0.00089563 rank 0
2022-08-24 02:59:15,677 DEBUG TRAIN Batch 87/3900 loss 26.505829 loss_att 12.355413 loss_ctc 59.523460 loss_ctc_origin 44.374447 loss_ctc0 94.871147 lr 0.00089554 rank 0
2022-08-24 02:59:43,956 DEBUG TRAIN Batch 87/4000 loss 51.449203 loss_att 36.528000 loss_ctc 86.265350 loss_ctc_origin 55.498795 loss_ctc0 158.053970 lr 0.00089545 rank 0
2022-08-24 03:00:12,726 DEBUG TRAIN Batch 87/4100 loss 36.980705 loss_att 20.996754 loss_ctc 74.276588 loss_ctc_origin 42.240471 loss_ctc0 149.027527 lr 0.00089536 rank 0
2022-08-24 03:00:40,313 DEBUG TRAIN Batch 87/4200 loss 19.507011 loss_att 10.632812 loss_ctc 40.213474 loss_ctc_origin 29.401182 loss_ctc0 65.442154 lr 0.00089527 rank 0
2022-08-24 03:01:09,136 DEBUG TRAIN Batch 87/4300 loss 23.767843 loss_att 12.075344 loss_ctc 51.050339 loss_ctc_origin 37.568336 loss_ctc0 82.508347 lr 0.00089518 rank 0
2022-08-24 03:01:37,098 DEBUG TRAIN Batch 87/4400 loss 35.064598 loss_att 18.436819 loss_ctc 73.862747 loss_ctc_origin 60.524937 loss_ctc0 104.984314 lr 0.00089509 rank 0
2022-08-24 03:02:11,360 DEBUG TRAIN Batch 87/4500 loss 40.463203 loss_att 29.048626 loss_ctc 67.097214 loss_ctc_origin 41.356499 loss_ctc0 127.158890 lr 0.00089500 rank 0
2022-08-24 03:02:18,776 WARNING NaN or Inf found in input tensor.
2022-08-24 03:02:39,553 DEBUG TRAIN Batch 87/4600 loss 39.358528 loss_att 23.873343 loss_ctc 75.490616 loss_ctc_origin 44.713097 loss_ctc0 147.304840 lr 0.00089491 rank 0
2022-08-24 03:03:07,940 DEBUG TRAIN Batch 87/4700 loss 22.038670 loss_att 12.818604 loss_ctc 43.552158 loss_ctc_origin 33.948395 loss_ctc0 65.960938 lr 0.00089482 rank 0
2022-08-24 03:03:13,358 WARNING NaN or Inf found in input tensor.
2022-08-24 03:03:36,773 DEBUG TRAIN Batch 87/4800 loss 25.320011 loss_att 12.567553 loss_ctc 55.075745 loss_ctc_origin 42.237373 loss_ctc0 85.031944 lr 0.00089473 rank 0
2022-08-24 03:04:04,933 DEBUG TRAIN Batch 87/4900 loss 24.591078 loss_att 11.033029 loss_ctc 56.226524 loss_ctc_origin 38.917915 loss_ctc0 96.613274 lr 0.00089464 rank 0
2022-08-24 03:04:28,441 WARNING NaN or Inf found in input tensor.
2022-08-24 03:04:34,537 DEBUG TRAIN Batch 87/5000 loss 44.495579 loss_att 29.990887 loss_ctc 78.339859 loss_ctc_origin 49.078327 loss_ctc0 146.616776 lr 0.00089455 rank 0
2022-08-24 03:04:42,082 WARNING NaN or Inf found in input tensor.
2022-08-24 03:04:55,857 WARNING NaN or Inf found in input tensor.
2022-08-24 03:05:02,562 DEBUG TRAIN Batch 87/5100 loss 49.477787 loss_att 29.287586 loss_ctc 96.588249 loss_ctc_origin 57.165012 loss_ctc0 188.575806 lr 0.00089446 rank 0
2022-08-24 03:05:31,186 DEBUG TRAIN Batch 87/5200 loss 23.584663 loss_att 13.789237 loss_ctc 46.440659 loss_ctc_origin 36.997414 loss_ctc0 68.474899 lr 0.00089437 rank 0
2022-08-24 03:05:58,629 DEBUG TRAIN Batch 87/5300 loss 23.954353 loss_att 12.268247 loss_ctc 51.221939 loss_ctc_origin 39.866238 loss_ctc0 77.718582 lr 0.00089428 rank 0
2022-08-24 03:06:27,611 DEBUG TRAIN Batch 87/5400 loss 28.740952 loss_att 13.706952 loss_ctc 63.820274 loss_ctc_origin 47.839912 loss_ctc0 101.107788 lr 0.00089419 rank 0
2022-08-24 03:06:56,875 DEBUG TRAIN Batch 87/5500 loss 39.794498 loss_att 25.089209 loss_ctc 74.106834 loss_ctc_origin 47.290604 loss_ctc0 136.678040 lr 0.00089411 rank 0
2022-08-24 03:07:24,579 DEBUG TRAIN Batch 87/5600 loss 37.055420 loss_att 22.818985 loss_ctc 70.273758 loss_ctc_origin 44.467384 loss_ctc0 130.488617 lr 0.00089402 rank 0
2022-08-24 03:07:46,418 DEBUG CV Batch 87/0 loss 13.696014 loss_att 10.258307 loss_ctc 21.717335 loss_ctc_origin 14.625444 loss_ctc0 38.265076 history loss 12.890366 rank 0
2022-08-24 03:07:56,495 DEBUG CV Batch 87/100 loss 25.740705 loss_att 19.062584 loss_ctc 41.322990 loss_ctc_origin 28.196938 loss_ctc0 71.950439 history loss 29.117055 rank 0
2022-08-24 03:08:05,963 DEBUG CV Batch 87/200 loss 26.249260 loss_att 20.011818 loss_ctc 40.803291 loss_ctc_origin 30.995766 loss_ctc0 63.687511 history loss 30.670882 rank 0
2022-08-24 03:08:15,369 DEBUG CV Batch 87/300 loss 24.323494 loss_att 18.183647 loss_ctc 38.649803 loss_ctc_origin 23.367420 loss_ctc0 74.308701 history loss 29.578583 rank 0
2022-08-24 03:08:25,318 DEBUG CV Batch 87/400 loss 40.169601 loss_att 32.452190 loss_ctc 58.176899 loss_ctc_origin 40.924675 loss_ctc0 98.432083 history loss 27.905922 rank 0
2022-08-24 03:08:35,330 DEBUG CV Batch 87/500 loss 18.343189 loss_att 13.960850 loss_ctc 28.568645 loss_ctc_origin 22.236851 loss_ctc0 43.342834 history loss 27.550804 rank 0
2022-08-24 03:08:45,269 DEBUG CV Batch 87/600 loss 19.031876 loss_att 13.308561 loss_ctc 32.386276 loss_ctc_origin 22.296215 loss_ctc0 55.929745 history loss 27.411353 rank 0
2022-08-24 03:08:55,321 DEBUG CV Batch 87/700 loss 20.921051 loss_att 14.338630 loss_ctc 36.280037 loss_ctc_origin 23.886631 loss_ctc0 65.197983 history loss 27.022616 rank 0
2022-08-24 03:09:04,684 DEBUG CV Batch 87/800 loss 23.015610 loss_att 17.651260 loss_ctc 35.532421 loss_ctc_origin 20.109444 loss_ctc0 71.519363 history loss 26.948796 rank 0
2022-08-24 03:09:15,522 INFO Epoch 87 CV info cv_loss 27.0024631974452
2022-08-24 03:09:15,523 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/87.pt
2022-08-24 03:09:16,007 INFO Epoch 88 TRAIN info lr 0.0008939410192881793
2022-08-24 03:09:16,011 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 03:09:42,895 DEBUG TRAIN Batch 88/0 loss 40.745102 loss_att 26.733194 loss_ctc 73.439560 loss_ctc_origin 44.994865 loss_ctc0 139.810516 lr 0.00089394 rank 0
2022-08-24 03:09:50,944 WARNING NaN or Inf found in input tensor.
2022-08-24 03:10:11,325 DEBUG TRAIN Batch 88/100 loss 48.530647 loss_att 31.826172 loss_ctc 87.507751 loss_ctc_origin 59.482002 loss_ctc0 152.901169 lr 0.00089385 rank 0
2022-08-24 03:10:39,350 DEBUG TRAIN Batch 88/200 loss 21.706078 loss_att 14.825464 loss_ctc 37.760841 loss_ctc_origin 27.981609 loss_ctc0 60.579056 lr 0.00089376 rank 0
2022-08-24 03:11:06,700 DEBUG TRAIN Batch 88/300 loss 20.644123 loss_att 8.809576 loss_ctc 48.258064 loss_ctc_origin 31.848560 loss_ctc0 86.546906 lr 0.00089367 rank 0
2022-08-24 03:11:35,661 DEBUG TRAIN Batch 88/400 loss 27.711559 loss_att 13.974834 loss_ctc 59.763916 loss_ctc_origin 43.953304 loss_ctc0 96.655334 lr 0.00089358 rank 0
2022-08-24 03:12:03,802 DEBUG TRAIN Batch 88/500 loss 36.452648 loss_att 25.454449 loss_ctc 62.115112 loss_ctc_origin 38.389885 loss_ctc0 117.473969 lr 0.00089349 rank 0
2022-08-24 03:12:33,105 DEBUG TRAIN Batch 88/600 loss 46.710335 loss_att 31.466244 loss_ctc 82.279884 loss_ctc_origin 53.135277 loss_ctc0 150.283966 lr 0.00089340 rank 0
2022-08-24 03:13:00,844 DEBUG TRAIN Batch 88/700 loss 25.792027 loss_att 14.573298 loss_ctc 51.969063 loss_ctc_origin 43.696243 loss_ctc0 71.272301 lr 0.00089331 rank 0
2022-08-24 03:13:29,317 DEBUG TRAIN Batch 88/800 loss 24.916237 loss_att 12.537146 loss_ctc 53.800777 loss_ctc_origin 41.309418 loss_ctc0 82.947281 lr 0.00089322 rank 0
2022-08-24 03:13:58,210 DEBUG TRAIN Batch 88/900 loss 23.790302 loss_att 10.062087 loss_ctc 55.822800 loss_ctc_origin 37.401382 loss_ctc0 98.806099 lr 0.00089313 rank 0
2022-08-24 03:14:27,583 DEBUG TRAIN Batch 88/1000 loss 33.439137 loss_att 27.147800 loss_ctc 48.118919 loss_ctc_origin 38.539051 loss_ctc0 70.471939 lr 0.00089305 rank 0
2022-08-24 03:14:55,880 DEBUG TRAIN Batch 88/1100 loss 41.348572 loss_att 26.038483 loss_ctc 77.072113 loss_ctc_origin 50.391205 loss_ctc0 139.327560 lr 0.00089296 rank 0
2022-08-24 03:15:24,904 DEBUG TRAIN Batch 88/1200 loss 22.769524 loss_att 13.020802 loss_ctc 45.516541 loss_ctc_origin 36.125118 loss_ctc0 67.429855 lr 0.00089287 rank 0
2022-08-24 03:15:37,779 WARNING NaN or Inf found in input tensor.
2022-08-24 03:15:54,740 DEBUG TRAIN Batch 88/1300 loss 22.643557 loss_att 10.160830 loss_ctc 51.769920 loss_ctc_origin 38.401756 loss_ctc0 82.962296 lr 0.00089278 rank 0
2022-08-24 03:16:23,650 DEBUG TRAIN Batch 88/1400 loss 26.537704 loss_att 13.454853 loss_ctc 57.064362 loss_ctc_origin 40.778862 loss_ctc0 95.063858 lr 0.00089269 rank 0
2022-08-24 03:16:57,650 DEBUG TRAIN Batch 88/1500 loss 36.935467 loss_att 23.331064 loss_ctc 68.679070 loss_ctc_origin 38.460140 loss_ctc0 139.189896 lr 0.00089260 rank 0
2022-08-24 03:17:26,849 DEBUG TRAIN Batch 88/1600 loss 43.336815 loss_att 25.793859 loss_ctc 84.270363 loss_ctc_origin 52.970837 loss_ctc0 157.302582 lr 0.00089251 rank 0
2022-08-24 03:17:53,996 DEBUG TRAIN Batch 88/1700 loss 23.144140 loss_att 14.517754 loss_ctc 43.272377 loss_ctc_origin 33.088921 loss_ctc0 67.033775 lr 0.00089242 rank 0
2022-08-24 03:18:23,651 DEBUG TRAIN Batch 88/1800 loss 27.165157 loss_att 14.187538 loss_ctc 57.446266 loss_ctc_origin 44.285789 loss_ctc0 88.154037 lr 0.00089233 rank 0
2022-08-24 03:18:51,772 DEBUG TRAIN Batch 88/1900 loss 27.687599 loss_att 13.371822 loss_ctc 61.091076 loss_ctc_origin 44.943661 loss_ctc0 98.768379 lr 0.00089225 rank 0
2022-08-24 03:19:19,765 DEBUG TRAIN Batch 88/2000 loss 33.116310 loss_att 22.647406 loss_ctc 57.543755 loss_ctc_origin 37.213158 loss_ctc0 104.981812 lr 0.00089216 rank 0
2022-08-24 03:19:47,395 DEBUG TRAIN Batch 88/2100 loss 40.028419 loss_att 24.953175 loss_ctc 75.203979 loss_ctc_origin 48.717751 loss_ctc0 137.005188 lr 0.00089207 rank 0
2022-08-24 03:20:17,006 DEBUG TRAIN Batch 88/2200 loss 26.928215 loss_att 16.701996 loss_ctc 50.789394 loss_ctc_origin 42.584564 loss_ctc0 69.933998 lr 0.00089198 rank 0
2022-08-24 03:20:43,371 DEBUG TRAIN Batch 88/2300 loss 20.995371 loss_att 9.141735 loss_ctc 48.653854 loss_ctc_origin 34.097317 loss_ctc0 82.619095 lr 0.00089189 rank 0
2022-08-24 03:21:11,266 DEBUG TRAIN Batch 88/2400 loss 27.523434 loss_att 13.153077 loss_ctc 61.054260 loss_ctc_origin 40.990288 loss_ctc0 107.870201 lr 0.00089180 rank 0
2022-08-24 03:21:38,258 DEBUG TRAIN Batch 88/2500 loss 36.647270 loss_att 25.300198 loss_ctc 63.123772 loss_ctc_origin 53.388187 loss_ctc0 85.840141 lr 0.00089171 rank 0
2022-08-24 03:22:07,949 DEBUG TRAIN Batch 88/2600 loss 29.717503 loss_att 19.278782 loss_ctc 54.074520 loss_ctc_origin 36.362652 loss_ctc0 95.402214 lr 0.00089162 rank 0
2022-08-24 03:22:35,062 DEBUG TRAIN Batch 88/2700 loss 26.302673 loss_att 16.442764 loss_ctc 49.309132 loss_ctc_origin 39.496735 loss_ctc0 72.204720 lr 0.00089154 rank 0
2022-08-24 03:23:03,740 DEBUG TRAIN Batch 88/2800 loss 20.788990 loss_att 9.326309 loss_ctc 47.535244 loss_ctc_origin 33.381733 loss_ctc0 80.560104 lr 0.00089145 rank 0
2022-08-24 03:23:27,263 WARNING NaN or Inf found in input tensor.
2022-08-24 03:23:31,325 DEBUG TRAIN Batch 88/2900 loss 25.814526 loss_att 12.167131 loss_ctc 57.658440 loss_ctc_origin 42.625263 loss_ctc0 92.735847 lr 0.00089136 rank 0
2022-08-24 03:24:07,099 DEBUG TRAIN Batch 88/3000 loss 31.030651 loss_att 22.208786 loss_ctc 51.614998 loss_ctc_origin 33.489273 loss_ctc0 93.908348 lr 0.00089127 rank 0
2022-08-24 03:24:36,734 DEBUG TRAIN Batch 88/3100 loss 35.018555 loss_att 22.911171 loss_ctc 63.269119 loss_ctc_origin 40.613647 loss_ctc0 116.131882 lr 0.00089118 rank 0
2022-08-24 03:25:05,044 DEBUG TRAIN Batch 88/3200 loss 20.415789 loss_att 11.283036 loss_ctc 41.725540 loss_ctc_origin 29.874691 loss_ctc0 69.377518 lr 0.00089109 rank 0
2022-08-24 03:25:33,717 DEBUG TRAIN Batch 88/3300 loss 25.792271 loss_att 11.843986 loss_ctc 58.338272 loss_ctc_origin 45.686440 loss_ctc0 87.859215 lr 0.00089101 rank 0
2022-08-24 03:26:02,342 DEBUG TRAIN Batch 88/3400 loss 26.285656 loss_att 13.757627 loss_ctc 55.517723 loss_ctc_origin 38.956993 loss_ctc0 94.159424 lr 0.00089092 rank 0
2022-08-24 03:26:31,323 DEBUG TRAIN Batch 88/3500 loss 28.515476 loss_att 20.482899 loss_ctc 47.258156 loss_ctc_origin 33.498734 loss_ctc0 79.363464 lr 0.00089083 rank 0
2022-08-24 03:27:01,124 DEBUG TRAIN Batch 88/3600 loss 34.873863 loss_att 22.013834 loss_ctc 64.880592 loss_ctc_origin 44.598030 loss_ctc0 112.206566 lr 0.00089074 rank 0
2022-08-24 03:27:29,342 DEBUG TRAIN Batch 88/3700 loss 22.849205 loss_att 12.305847 loss_ctc 47.450371 loss_ctc_origin 36.002689 loss_ctc0 74.161636 lr 0.00089065 rank 0
2022-08-24 03:27:35,058 WARNING NaN or Inf found in input tensor.
2022-08-24 03:27:57,051 DEBUG TRAIN Batch 88/3800 loss 19.801462 loss_att 9.300985 loss_ctc 44.302574 loss_ctc_origin 28.474800 loss_ctc0 81.234039 lr 0.00089056 rank 0
2022-08-24 03:28:26,509 DEBUG TRAIN Batch 88/3900 loss 27.299967 loss_att 13.574020 loss_ctc 59.327171 loss_ctc_origin 43.762943 loss_ctc0 95.643707 lr 0.00089048 rank 0
2022-08-24 03:28:55,321 DEBUG TRAIN Batch 88/4000 loss 25.330328 loss_att 18.667768 loss_ctc 40.876297 loss_ctc_origin 30.118279 loss_ctc0 65.978340 lr 0.00089039 rank 0
2022-08-24 03:29:23,157 DEBUG TRAIN Batch 88/4100 loss 43.336586 loss_att 28.855400 loss_ctc 77.126022 loss_ctc_origin 50.724483 loss_ctc0 138.729630 lr 0.00089030 rank 0
2022-08-24 03:29:50,808 DEBUG TRAIN Batch 88/4200 loss 25.059734 loss_att 13.808700 loss_ctc 51.312149 loss_ctc_origin 40.163559 loss_ctc0 77.325531 lr 0.00089021 rank 0
2022-08-24 03:30:20,072 DEBUG TRAIN Batch 88/4300 loss 23.858988 loss_att 11.352029 loss_ctc 53.041893 loss_ctc_origin 40.713593 loss_ctc0 81.807922 lr 0.00089012 rank 0
2022-08-24 03:30:48,785 DEBUG TRAIN Batch 88/4400 loss 28.374725 loss_att 13.981804 loss_ctc 61.958206 loss_ctc_origin 47.101398 loss_ctc0 96.624100 lr 0.00089003 rank 0
2022-08-24 03:30:56,868 WARNING NaN or Inf found in input tensor.
2022-08-24 03:31:22,739 DEBUG TRAIN Batch 88/4500 loss 38.690948 loss_att 25.888428 loss_ctc 68.563492 loss_ctc_origin 42.409294 loss_ctc0 129.589935 lr 0.00088995 rank 0
2022-08-24 03:31:51,525 DEBUG TRAIN Batch 88/4600 loss 39.839886 loss_att 25.158409 loss_ctc 74.096664 loss_ctc_origin 48.119858 loss_ctc0 134.709229 lr 0.00088986 rank 0
2022-08-24 03:32:19,130 DEBUG TRAIN Batch 88/4700 loss 24.786926 loss_att 15.071640 loss_ctc 47.455929 loss_ctc_origin 38.511101 loss_ctc0 68.327194 lr 0.00088977 rank 0
2022-08-24 03:32:47,352 DEBUG TRAIN Batch 88/4800 loss 20.305334 loss_att 8.783047 loss_ctc 47.190666 loss_ctc_origin 33.473228 loss_ctc0 79.198013 lr 0.00088968 rank 0
2022-08-24 03:32:50,224 WARNING NaN or Inf found in input tensor.
2022-08-24 03:33:12,180 WARNING NaN or Inf found in input tensor.
2022-08-24 03:33:16,789 DEBUG TRAIN Batch 88/4900 loss 27.078386 loss_att 14.107306 loss_ctc 57.344238 loss_ctc_origin 40.106796 loss_ctc0 97.564926 lr 0.00088959 rank 0
2022-08-24 03:33:45,212 DEBUG TRAIN Batch 88/5000 loss 35.612267 loss_att 21.979954 loss_ctc 67.420998 loss_ctc_origin 40.032032 loss_ctc0 131.328583 lr 0.00088951 rank 0
2022-08-24 03:34:13,534 DEBUG TRAIN Batch 88/5100 loss 34.158821 loss_att 21.567719 loss_ctc 63.538063 loss_ctc_origin 44.011475 loss_ctc0 109.100113 lr 0.00088942 rank 0
2022-08-24 03:34:42,341 DEBUG TRAIN Batch 88/5200 loss 20.289581 loss_att 11.677305 loss_ctc 40.384895 loss_ctc_origin 28.992325 loss_ctc0 66.967552 lr 0.00088933 rank 0
2022-08-24 03:35:09,909 DEBUG TRAIN Batch 88/5300 loss 25.260338 loss_att 12.683588 loss_ctc 54.606083 loss_ctc_origin 41.420250 loss_ctc0 85.373024 lr 0.00088924 rank 0
2022-08-24 03:35:34,379 WARNING NaN or Inf found in input tensor.
2022-08-24 03:35:38,531 DEBUG TRAIN Batch 88/5400 loss 26.087072 loss_att 11.850049 loss_ctc 59.306793 loss_ctc_origin 43.814968 loss_ctc0 95.454391 lr 0.00088915 rank 0
2022-08-24 03:36:06,990 DEBUG TRAIN Batch 88/5500 loss 38.595177 loss_att 26.594891 loss_ctc 66.595840 loss_ctc_origin 40.207710 loss_ctc0 128.168152 lr 0.00088907 rank 0
2022-08-24 03:36:21,589 WARNING NaN or Inf found in input tensor.
2022-08-24 03:36:35,465 DEBUG TRAIN Batch 88/5600 loss 35.727127 loss_att 20.631832 loss_ctc 70.949478 loss_ctc_origin 46.560646 loss_ctc0 127.856758 lr 0.00088898 rank 0
2022-08-24 03:36:57,320 DEBUG CV Batch 88/0 loss 13.325489 loss_att 9.892188 loss_ctc 21.336523 loss_ctc_origin 15.117066 loss_ctc0 35.848587 history loss 12.541637 rank 0
2022-08-24 03:37:07,629 DEBUG CV Batch 88/100 loss 25.156019 loss_att 19.455948 loss_ctc 38.456184 loss_ctc_origin 26.773937 loss_ctc0 65.714752 history loss 29.278433 rank 0
2022-08-24 03:37:16,545 DEBUG CV Batch 88/200 loss 25.840370 loss_att 19.736933 loss_ctc 40.081726 loss_ctc_origin 30.103918 loss_ctc0 63.363274 history loss 30.375747 rank 0
2022-08-24 03:37:26,313 DEBUG CV Batch 88/300 loss 25.529127 loss_att 19.085350 loss_ctc 40.564606 loss_ctc_origin 25.808170 loss_ctc0 74.996292 history loss 29.419198 rank 0
2022-08-24 03:37:36,498 DEBUG CV Batch 88/400 loss 39.114723 loss_att 31.461979 loss_ctc 56.971123 loss_ctc_origin 39.688801 loss_ctc0 97.296547 history loss 27.679565 rank 0
2022-08-24 03:37:46,399 DEBUG CV Batch 88/500 loss 17.578249 loss_att 13.476416 loss_ctc 27.149193 loss_ctc_origin 20.291470 loss_ctc0 43.150547 history loss 27.296119 rank 0
2022-08-24 03:37:56,699 DEBUG CV Batch 88/600 loss 18.886806 loss_att 13.498069 loss_ctc 31.460522 loss_ctc_origin 20.889614 loss_ctc0 56.125977 history loss 27.102308 rank 0
2022-08-24 03:38:06,207 DEBUG CV Batch 88/700 loss 20.026388 loss_att 13.665375 loss_ctc 34.868752 loss_ctc_origin 22.116673 loss_ctc0 64.623604 history loss 26.748884 rank 0
2022-08-24 03:38:16,357 DEBUG CV Batch 88/800 loss 23.959066 loss_att 18.298431 loss_ctc 37.167213 loss_ctc_origin 22.280249 loss_ctc0 71.903458 history loss 26.687011 rank 0
2022-08-24 03:38:26,555 INFO Epoch 88 CV info cv_loss 26.75065408944834
2022-08-24 03:38:26,556 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/88.pt
2022-08-24 03:38:27,020 INFO Epoch 89 TRAIN info lr 0.0008889046917794364
2022-08-24 03:38:27,023 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 03:38:53,160 DEBUG TRAIN Batch 89/0 loss 39.388283 loss_att 26.131834 loss_ctc 70.319992 loss_ctc_origin 42.193794 loss_ctc0 135.947784 lr 0.00088890 rank 0
2022-08-24 03:39:21,923 DEBUG TRAIN Batch 89/100 loss 40.177429 loss_att 27.737019 loss_ctc 69.205048 loss_ctc_origin 46.727997 loss_ctc0 121.651505 lr 0.00088881 rank 0
2022-08-24 03:39:50,428 DEBUG TRAIN Batch 89/200 loss 21.901031 loss_att 11.357954 loss_ctc 46.501541 loss_ctc_origin 36.398243 loss_ctc0 70.075897 lr 0.00088873 rank 0
2022-08-24 03:40:19,078 DEBUG TRAIN Batch 89/300 loss 24.565083 loss_att 11.259537 loss_ctc 55.611355 loss_ctc_origin 42.651226 loss_ctc0 85.851654 lr 0.00088864 rank 0
2022-08-24 03:40:47,783 DEBUG TRAIN Batch 89/400 loss 26.275129 loss_att 12.852181 loss_ctc 57.595341 loss_ctc_origin 40.331989 loss_ctc0 97.876495 lr 0.00088855 rank 0
2022-08-24 03:41:17,115 DEBUG TRAIN Batch 89/500 loss 37.426544 loss_att 24.464148 loss_ctc 67.672142 loss_ctc_origin 41.473434 loss_ctc0 128.802460 lr 0.00088846 rank 0
2022-08-24 03:41:45,882 DEBUG TRAIN Batch 89/600 loss 50.733757 loss_att 27.263996 loss_ctc 105.496536 loss_ctc_origin 60.914856 loss_ctc0 209.520462 lr 0.00088837 rank 0
2022-08-24 03:42:14,564 DEBUG TRAIN Batch 89/700 loss 24.285202 loss_att 16.209488 loss_ctc 43.128529 loss_ctc_origin 32.707253 loss_ctc0 67.444839 lr 0.00088829 rank 0
2022-08-24 03:42:44,243 DEBUG TRAIN Batch 89/800 loss 23.692888 loss_att 11.496605 loss_ctc 52.150879 loss_ctc_origin 38.711967 loss_ctc0 83.508331 lr 0.00088820 rank 0
2022-08-24 03:43:14,286 DEBUG TRAIN Batch 89/900 loss 23.268970 loss_att 10.349452 loss_ctc 53.414513 loss_ctc_origin 35.772259 loss_ctc0 94.579773 lr 0.00088811 rank 0
2022-08-24 03:43:43,454 DEBUG TRAIN Batch 89/1000 loss 32.018097 loss_att 22.092920 loss_ctc 55.176834 loss_ctc_origin 40.938995 loss_ctc0 88.398453 lr 0.00088802 rank 0
2022-08-24 03:44:11,233 DEBUG TRAIN Batch 89/1100 loss 44.287170 loss_att 29.738541 loss_ctc 78.233963 loss_ctc_origin 51.236946 loss_ctc0 141.227020 lr 0.00088794 rank 0
2022-08-24 03:44:39,692 DEBUG TRAIN Batch 89/1200 loss 26.140347 loss_att 17.150240 loss_ctc 47.117264 loss_ctc_origin 37.849392 loss_ctc0 68.742294 lr 0.00088785 rank 0
2022-08-24 03:45:08,289 DEBUG TRAIN Batch 89/1300 loss 22.387041 loss_att 9.802866 loss_ctc 51.750114 loss_ctc_origin 35.653866 loss_ctc0 89.308022 lr 0.00088776 rank 0
2022-08-24 03:45:37,646 DEBUG TRAIN Batch 89/1400 loss 25.659431 loss_att 11.204496 loss_ctc 59.387611 loss_ctc_origin 41.073807 loss_ctc0 102.119812 lr 0.00088767 rank 0
2022-08-24 03:45:47,110 WARNING NaN or Inf found in input tensor.
2022-08-24 03:46:13,455 DEBUG TRAIN Batch 89/1500 loss 38.079300 loss_att 23.259140 loss_ctc 72.659668 loss_ctc_origin 41.604980 loss_ctc0 145.120590 lr 0.00088759 rank 0
2022-08-24 03:46:42,408 DEBUG TRAIN Batch 89/1600 loss 40.741795 loss_att 25.885143 loss_ctc 75.407310 loss_ctc_origin 47.213737 loss_ctc0 141.192322 lr 0.00088750 rank 0
2022-08-24 03:47:11,679 DEBUG TRAIN Batch 89/1700 loss 22.741398 loss_att 11.843441 loss_ctc 48.169960 loss_ctc_origin 36.898689 loss_ctc0 74.469597 lr 0.00088741 rank 0
2022-08-24 03:47:40,228 DEBUG TRAIN Batch 89/1800 loss 20.945328 loss_att 9.326647 loss_ctc 48.055580 loss_ctc_origin 34.791546 loss_ctc0 79.004990 lr 0.00088733 rank 0
2022-08-24 03:48:09,481 DEBUG TRAIN Batch 89/1900 loss 25.283014 loss_att 12.018774 loss_ctc 56.232906 loss_ctc_origin 39.081249 loss_ctc0 96.253433 lr 0.00088724 rank 0
2022-08-24 03:48:40,152 DEBUG TRAIN Batch 89/2000 loss 38.953312 loss_att 25.308414 loss_ctc 70.791405 loss_ctc_origin 41.455795 loss_ctc0 139.241150 lr 0.00088715 rank 0
2022-08-24 03:49:07,817 DEBUG TRAIN Batch 89/2100 loss 43.395782 loss_att 25.305973 loss_ctc 85.605347 loss_ctc_origin 47.678127 loss_ctc0 174.102203 lr 0.00088706 rank 0
2022-08-24 03:49:27,240 WARNING NaN or Inf found in input tensor.
2022-08-24 03:49:36,639 DEBUG TRAIN Batch 89/2200 loss 28.975368 loss_att 16.654137 loss_ctc 57.724915 loss_ctc_origin 48.496300 loss_ctc0 79.258347 lr 0.00088698 rank 0
2022-08-24 03:50:04,141 DEBUG TRAIN Batch 89/2300 loss 22.575817 loss_att 11.181789 loss_ctc 49.161877 loss_ctc_origin 33.203594 loss_ctc0 86.397865 lr 0.00088689 rank 0
2022-08-24 03:50:34,241 DEBUG TRAIN Batch 89/2400 loss 26.571966 loss_att 12.610365 loss_ctc 59.149033 loss_ctc_origin 42.805984 loss_ctc0 97.282814 lr 0.00088680 rank 0
2022-08-24 03:51:02,860 DEBUG TRAIN Batch 89/2500 loss 43.884007 loss_att 29.168495 loss_ctc 78.220200 loss_ctc_origin 49.410233 loss_ctc0 145.443451 lr 0.00088671 rank 0
2022-08-24 03:51:31,870 DEBUG TRAIN Batch 89/2600 loss 40.352627 loss_att 24.737270 loss_ctc 76.788452 loss_ctc_origin 47.277382 loss_ctc0 145.647629 lr 0.00088663 rank 0
2022-08-24 03:52:00,625 DEBUG TRAIN Batch 89/2700 loss 23.260790 loss_att 13.314548 loss_ctc 46.468685 loss_ctc_origin 37.287865 loss_ctc0 67.890594 lr 0.00088654 rank 0
2022-08-24 03:52:13,079 WARNING NaN or Inf found in input tensor.
2022-08-24 03:52:29,852 DEBUG TRAIN Batch 89/2800 loss 24.180740 loss_att 11.786976 loss_ctc 53.099525 loss_ctc_origin 39.962727 loss_ctc0 83.752052 lr 0.00088645 rank 0
2022-08-24 03:52:58,019 DEBUG TRAIN Batch 89/2900 loss 27.026096 loss_att 13.612084 loss_ctc 58.325455 loss_ctc_origin 42.738064 loss_ctc0 94.696022 lr 0.00088637 rank 0
2022-08-24 03:53:32,633 DEBUG TRAIN Batch 89/3000 loss 35.692554 loss_att 23.738266 loss_ctc 63.585896 loss_ctc_origin 41.805229 loss_ctc0 114.407440 lr 0.00088628 rank 0
2022-08-24 03:54:01,478 DEBUG TRAIN Batch 89/3100 loss 33.921440 loss_att 20.489336 loss_ctc 65.263023 loss_ctc_origin 42.308918 loss_ctc0 118.822601 lr 0.00088619 rank 0
2022-08-24 03:54:30,110 DEBUG TRAIN Batch 89/3200 loss 20.680351 loss_att 11.318305 loss_ctc 42.525124 loss_ctc_origin 31.862535 loss_ctc0 67.404488 lr 0.00088610 rank 0
2022-08-24 03:54:57,867 DEBUG TRAIN Batch 89/3300 loss 24.022093 loss_att 11.996559 loss_ctc 52.081669 loss_ctc_origin 39.670929 loss_ctc0 81.040062 lr 0.00088602 rank 0
2022-08-24 03:55:21,914 WARNING NaN or Inf found in input tensor.
2022-08-24 03:55:26,164 DEBUG TRAIN Batch 89/3400 loss 24.538815 loss_att 12.409052 loss_ctc 52.841587 loss_ctc_origin 36.715305 loss_ctc0 90.469574 lr 0.00088593 rank 0
2022-08-24 03:55:34,902 WARNING NaN or Inf found in input tensor.
2022-08-24 03:55:55,914 DEBUG TRAIN Batch 89/3500 loss 40.489391 loss_att 25.775349 loss_ctc 74.822159 loss_ctc_origin 39.577473 loss_ctc0 157.059753 lr 0.00088584 rank 0
2022-08-24 03:56:25,743 DEBUG TRAIN Batch 89/3600 loss 38.573509 loss_att 23.179480 loss_ctc 74.492905 loss_ctc_origin 44.632912 loss_ctc0 144.166199 lr 0.00088576 rank 0
2022-08-24 03:56:54,436 DEBUG TRAIN Batch 89/3700 loss 23.645695 loss_att 14.732504 loss_ctc 44.443142 loss_ctc_origin 35.773758 loss_ctc0 64.671707 lr 0.00088567 rank 0
2022-08-24 03:57:22,263 DEBUG TRAIN Batch 89/3800 loss 20.815939 loss_att 10.143177 loss_ctc 45.719048 loss_ctc_origin 32.499172 loss_ctc0 76.565430 lr 0.00088558 rank 0
2022-08-24 03:57:51,668 DEBUG TRAIN Batch 89/3900 loss 26.647554 loss_att 13.341574 loss_ctc 57.694839 loss_ctc_origin 42.684151 loss_ctc0 92.719788 lr 0.00088550 rank 0
2022-08-24 03:58:19,833 DEBUG TRAIN Batch 89/4000 loss 35.215805 loss_att 24.278923 loss_ctc 60.735191 loss_ctc_origin 34.811462 loss_ctc0 121.223885 lr 0.00088541 rank 0
2022-08-24 03:58:48,827 DEBUG TRAIN Batch 89/4100 loss 35.126335 loss_att 22.146027 loss_ctc 65.413727 loss_ctc_origin 38.725292 loss_ctc0 127.686752 lr 0.00088532 rank 0
2022-08-24 03:59:16,652 DEBUG TRAIN Batch 89/4200 loss 22.965038 loss_att 12.333705 loss_ctc 47.771484 loss_ctc_origin 35.426285 loss_ctc0 76.576950 lr 0.00088524 rank 0
2022-08-24 03:59:47,040 DEBUG TRAIN Batch 89/4300 loss 20.810133 loss_att 9.781474 loss_ctc 46.543671 loss_ctc_origin 33.508389 loss_ctc0 76.959335 lr 0.00088515 rank 0
2022-08-24 04:00:09,561 WARNING NaN or Inf found in input tensor.
2022-08-24 04:00:14,218 DEBUG TRAIN Batch 89/4400 loss 28.530087 loss_att 13.506136 loss_ctc 63.585972 loss_ctc_origin 45.365944 loss_ctc0 106.099365 lr 0.00088506 rank 0
2022-08-24 04:00:48,552 DEBUG TRAIN Batch 89/4500 loss 32.130680 loss_att 20.775963 loss_ctc 58.625015 loss_ctc_origin 32.707729 loss_ctc0 119.098679 lr 0.00088498 rank 0
2022-08-24 04:01:17,451 DEBUG TRAIN Batch 89/4600 loss 38.339844 loss_att 26.635721 loss_ctc 65.649467 loss_ctc_origin 51.766891 loss_ctc0 98.042137 lr 0.00088489 rank 0
2022-08-24 04:01:30,981 WARNING NaN or Inf found in input tensor.
2022-08-24 04:01:44,415 WARNING NaN or Inf found in input tensor.
2022-08-24 04:01:45,884 DEBUG TRAIN Batch 89/4700 loss 22.516331 loss_att 14.457872 loss_ctc 41.319405 loss_ctc_origin 31.708626 loss_ctc0 63.744553 lr 0.00088480 rank 0
2022-08-24 04:02:14,778 DEBUG TRAIN Batch 89/4800 loss 20.588097 loss_att 9.711933 loss_ctc 45.965805 loss_ctc_origin 33.773731 loss_ctc0 74.413971 lr 0.00088472 rank 0
2022-08-24 04:02:43,455 DEBUG TRAIN Batch 89/4900 loss 28.349499 loss_att 14.441236 loss_ctc 60.802109 loss_ctc_origin 46.602806 loss_ctc0 93.933815 lr 0.00088463 rank 0
2022-08-24 04:03:12,598 DEBUG TRAIN Batch 89/5000 loss 42.599003 loss_att 29.516392 loss_ctc 73.125092 loss_ctc_origin 47.682007 loss_ctc0 132.492279 lr 0.00088454 rank 0
2022-08-24 04:03:40,832 DEBUG TRAIN Batch 89/5100 loss 35.707298 loss_att 20.419376 loss_ctc 71.379112 loss_ctc_origin 42.587635 loss_ctc0 138.559219 lr 0.00088446 rank 0
2022-08-24 04:03:59,557 WARNING NaN or Inf found in input tensor.
2022-08-24 04:04:09,331 DEBUG TRAIN Batch 89/5200 loss 20.239454 loss_att 10.700060 loss_ctc 42.498039 loss_ctc_origin 32.101654 loss_ctc0 66.756279 lr 0.00088437 rank 0
2022-08-24 04:04:38,376 DEBUG TRAIN Batch 89/5300 loss 22.289047 loss_att 9.667469 loss_ctc 51.739395 loss_ctc_origin 38.860554 loss_ctc0 81.790024 lr 0.00088428 rank 0
2022-08-24 04:05:07,739 DEBUG TRAIN Batch 89/5400 loss 24.454367 loss_att 12.280396 loss_ctc 52.860298 loss_ctc_origin 35.461334 loss_ctc0 93.457886 lr 0.00088420 rank 0
2022-08-24 04:05:36,861 DEBUG TRAIN Batch 89/5500 loss 47.229973 loss_att 32.415810 loss_ctc 81.796356 loss_ctc_origin 53.554211 loss_ctc0 147.694702 lr 0.00088411 rank 0
2022-08-24 04:06:05,492 DEBUG TRAIN Batch 89/5600 loss 43.443958 loss_att 27.000334 loss_ctc 81.812408 loss_ctc_origin 50.461609 loss_ctc0 154.964264 lr 0.00088403 rank 0
2022-08-24 04:06:28,079 DEBUG CV Batch 89/0 loss 14.414450 loss_att 11.065542 loss_ctc 22.228565 loss_ctc_origin 15.683871 loss_ctc0 37.499516 history loss 13.566541 rank 0
2022-08-24 04:06:38,452 DEBUG CV Batch 89/100 loss 27.566780 loss_att 20.846367 loss_ctc 43.247738 loss_ctc_origin 29.593510 loss_ctc0 75.107605 history loss 29.629046 rank 0
2022-08-24 04:06:47,528 DEBUG CV Batch 89/200 loss 25.926559 loss_att 19.916733 loss_ctc 39.949493 loss_ctc_origin 29.290258 loss_ctc0 64.821045 history loss 31.038919 rank 0
2022-08-24 04:06:56,852 DEBUG CV Batch 89/300 loss 25.592279 loss_att 19.197124 loss_ctc 40.514305 loss_ctc_origin 25.221291 loss_ctc0 76.198006 history loss 29.958691 rank 0
2022-08-24 04:07:07,012 DEBUG CV Batch 89/400 loss 39.971214 loss_att 32.349529 loss_ctc 57.755138 loss_ctc_origin 39.942440 loss_ctc0 99.318100 history loss 28.182314 rank 0
2022-08-24 04:07:16,786 DEBUG CV Batch 89/500 loss 17.399324 loss_att 13.221931 loss_ctc 27.146576 loss_ctc_origin 19.665882 loss_ctc0 44.601532 history loss 27.807410 rank 0
2022-08-24 04:07:26,711 DEBUG CV Batch 89/600 loss 18.624336 loss_att 12.986258 loss_ctc 31.779854 loss_ctc_origin 21.408566 loss_ctc0 55.979523 history loss 27.626293 rank 0
2022-08-24 04:07:36,219 DEBUG CV Batch 89/700 loss 19.808418 loss_att 13.333390 loss_ctc 34.916813 loss_ctc_origin 21.499865 loss_ctc0 66.223022 history loss 27.281343 rank 0
2022-08-24 04:07:46,163 DEBUG CV Batch 89/800 loss 23.497108 loss_att 17.977879 loss_ctc 36.375313 loss_ctc_origin 20.580193 loss_ctc0 73.230591 history loss 27.202097 rank 0
2022-08-24 04:07:55,894 INFO Epoch 89 CV info cv_loss 27.258621011865674
2022-08-24 04:07:55,895 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/89.pt
2022-08-24 04:07:56,371 INFO Epoch 90 TRAIN info lr 0.0008839525379730334
2022-08-24 04:07:56,374 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 04:08:22,755 DEBUG TRAIN Batch 90/0 loss 34.613808 loss_att 20.082232 loss_ctc 68.520821 loss_ctc_origin 39.075279 loss_ctc0 137.227081 lr 0.00088395 rank 0
2022-08-24 04:08:30,432 WARNING NaN or Inf found in input tensor.
2022-08-24 04:08:50,846 DEBUG TRAIN Batch 90/100 loss 44.779846 loss_att 24.861469 loss_ctc 91.256058 loss_ctc_origin 49.186356 loss_ctc0 189.418701 lr 0.00088386 rank 0
2022-08-24 04:09:19,597 DEBUG TRAIN Batch 90/200 loss 25.382618 loss_att 17.914513 loss_ctc 42.808193 loss_ctc_origin 33.547005 loss_ctc0 64.417633 lr 0.00088378 rank 0
2022-08-24 04:09:49,461 DEBUG TRAIN Batch 90/300 loss 23.509525 loss_att 10.881378 loss_ctc 52.975197 loss_ctc_origin 39.711132 loss_ctc0 83.924683 lr 0.00088369 rank 0
2022-08-24 04:10:17,978 DEBUG TRAIN Batch 90/400 loss 24.752861 loss_att 11.978558 loss_ctc 54.559563 loss_ctc_origin 36.208576 loss_ctc0 97.378525 lr 0.00088360 rank 0
2022-08-24 04:10:47,207 DEBUG TRAIN Batch 90/500 loss 40.045113 loss_att 24.560343 loss_ctc 76.176247 loss_ctc_origin 44.191818 loss_ctc0 150.806580 lr 0.00088352 rank 0
2022-08-24 04:11:16,380 DEBUG TRAIN Batch 90/600 loss 38.064674 loss_att 24.492868 loss_ctc 69.732224 loss_ctc_origin 49.309334 loss_ctc0 117.385620 lr 0.00088343 rank 0
2022-08-24 04:11:42,779 WARNING NaN or Inf found in input tensor.
2022-08-24 04:11:44,377 DEBUG TRAIN Batch 90/700 loss 24.581282 loss_att 14.402022 loss_ctc 48.332886 loss_ctc_origin 37.574276 loss_ctc0 73.436302 lr 0.00088335 rank 0
2022-08-24 04:12:13,128 DEBUG TRAIN Batch 90/800 loss 20.743475 loss_att 10.099918 loss_ctc 45.578438 loss_ctc_origin 31.155899 loss_ctc0 79.231033 lr 0.00088326 rank 0
2022-08-24 04:12:42,548 DEBUG TRAIN Batch 90/900 loss 28.011112 loss_att 13.463297 loss_ctc 61.956009 loss_ctc_origin 46.728970 loss_ctc0 97.485764 lr 0.00088317 rank 0
2022-08-24 04:13:12,423 DEBUG TRAIN Batch 90/1000 loss 38.285488 loss_att 28.554325 loss_ctc 60.991531 loss_ctc_origin 39.792610 loss_ctc0 110.455688 lr 0.00088309 rank 0
2022-08-24 04:13:40,711 DEBUG TRAIN Batch 90/1100 loss 38.525238 loss_att 20.291868 loss_ctc 81.069763 loss_ctc_origin 41.443863 loss_ctc0 173.530182 lr 0.00088300 rank 0
2022-08-24 04:14:08,530 DEBUG TRAIN Batch 90/1200 loss 24.765581 loss_att 15.469181 loss_ctc 46.457180 loss_ctc_origin 37.009338 loss_ctc0 68.502144 lr 0.00088291 rank 0
2022-08-24 04:14:38,346 DEBUG TRAIN Batch 90/1300 loss 22.798288 loss_att 10.292843 loss_ctc 51.977661 loss_ctc_origin 38.592449 loss_ctc0 83.209831 lr 0.00088283 rank 0
2022-08-24 04:15:04,976 DEBUG TRAIN Batch 90/1400 loss 25.002792 loss_att 11.114601 loss_ctc 57.408569 loss_ctc_origin 42.160576 loss_ctc0 92.987213 lr 0.00088274 rank 0
2022-08-24 04:15:42,212 DEBUG TRAIN Batch 90/1500 loss 40.952431 loss_att 28.844145 loss_ctc 69.205101 loss_ctc_origin 46.224442 loss_ctc0 122.826630 lr 0.00088266 rank 0
2022-08-24 04:16:10,943 DEBUG TRAIN Batch 90/1600 loss 34.424557 loss_att 21.566391 loss_ctc 64.426941 loss_ctc_origin 44.000355 loss_ctc0 112.088974 lr 0.00088257 rank 0
2022-08-24 04:16:39,379 DEBUG TRAIN Batch 90/1700 loss 23.297201 loss_att 12.274535 loss_ctc 49.016754 loss_ctc_origin 36.302818 loss_ctc0 78.682602 lr 0.00088249 rank 0
2022-08-24 04:16:52,311 WARNING NaN or Inf found in input tensor.
2022-08-24 04:17:07,564 DEBUG TRAIN Batch 90/1800 loss 21.761251 loss_att 9.978771 loss_ctc 49.253704 loss_ctc_origin 35.797997 loss_ctc0 80.650352 lr 0.00088240 rank 0
2022-08-24 04:17:36,562 DEBUG TRAIN Batch 90/1900 loss 29.308556 loss_att 13.634675 loss_ctc 65.880936 loss_ctc_origin 46.986721 loss_ctc0 109.967438 lr 0.00088231 rank 0
2022-08-24 04:18:06,334 DEBUG TRAIN Batch 90/2000 loss 38.579796 loss_att 25.442276 loss_ctc 69.234001 loss_ctc_origin 43.036301 loss_ctc0 130.361969 lr 0.00088223 rank 0
2022-08-24 04:18:34,246 DEBUG TRAIN Batch 90/2100 loss 35.758881 loss_att 21.543144 loss_ctc 68.928932 loss_ctc_origin 38.135551 loss_ctc0 140.780151 lr 0.00088214 rank 0
2022-08-24 04:19:02,740 DEBUG TRAIN Batch 90/2200 loss 24.204147 loss_att 14.548254 loss_ctc 46.734566 loss_ctc_origin 38.211342 loss_ctc0 66.622093 lr 0.00088206 rank 0
2022-08-24 04:19:28,009 WARNING NaN or Inf found in input tensor.
2022-08-24 04:19:31,319 DEBUG TRAIN Batch 90/2300 loss 22.309883 loss_att 10.891327 loss_ctc 48.953178 loss_ctc_origin 37.612480 loss_ctc0 75.414803 lr 0.00088197 rank 0
2022-08-24 04:19:59,871 DEBUG TRAIN Batch 90/2400 loss 26.994637 loss_att 12.368710 loss_ctc 61.121799 loss_ctc_origin 44.577480 loss_ctc0 99.725212 lr 0.00088188 rank 0
2022-08-24 04:20:02,521 WARNING NaN or Inf found in input tensor.
2022-08-24 04:20:28,814 DEBUG TRAIN Batch 90/2500 loss 39.222076 loss_att 22.999634 loss_ctc 77.074448 loss_ctc_origin 41.735474 loss_ctc0 159.532043 lr 0.00088180 rank 0
2022-08-24 04:20:56,417 DEBUG TRAIN Batch 90/2600 loss 39.974113 loss_att 22.114359 loss_ctc 81.646866 loss_ctc_origin 40.379204 loss_ctc0 177.938080 lr 0.00088171 rank 0
2022-08-24 04:21:22,900 DEBUG TRAIN Batch 90/2700 loss 19.563101 loss_att 11.657116 loss_ctc 38.010399 loss_ctc_origin 26.427322 loss_ctc0 65.037582 lr 0.00088163 rank 0
2022-08-24 04:21:54,169 DEBUG TRAIN Batch 90/2800 loss 24.092134 loss_att 11.375021 loss_ctc 53.765396 loss_ctc_origin 40.953468 loss_ctc0 83.659897 lr 0.00088154 rank 0
2022-08-24 04:22:22,195 DEBUG TRAIN Batch 90/2900 loss 26.350315 loss_att 12.795111 loss_ctc 57.979122 loss_ctc_origin 41.084808 loss_ctc0 97.399185 lr 0.00088146 rank 0
2022-08-24 04:22:57,775 DEBUG TRAIN Batch 90/3000 loss 39.953758 loss_att 27.908356 loss_ctc 68.059692 loss_ctc_origin 41.608833 loss_ctc0 129.778351 lr 0.00088137 rank 0
2022-08-24 04:23:25,855 DEBUG TRAIN Batch 90/3100 loss 42.495354 loss_att 23.147017 loss_ctc 87.641472 loss_ctc_origin 46.640694 loss_ctc0 183.309952 lr 0.00088128 rank 0
2022-08-24 04:23:54,483 DEBUG TRAIN Batch 90/3200 loss 20.793270 loss_att 12.452951 loss_ctc 40.254013 loss_ctc_origin 31.926151 loss_ctc0 59.685684 lr 0.00088120 rank 0
2022-08-24 04:24:22,124 DEBUG TRAIN Batch 90/3300 loss 24.153933 loss_att 11.547636 loss_ctc 53.568619 loss_ctc_origin 39.397545 loss_ctc0 86.634453 lr 0.00088111 rank 0
2022-08-24 04:24:50,753 DEBUG TRAIN Batch 90/3400 loss 26.316490 loss_att 13.467675 loss_ctc 56.297050 loss_ctc_origin 38.012989 loss_ctc0 98.959846 lr 0.00088103 rank 0
2022-08-24 04:25:20,247 DEBUG TRAIN Batch 90/3500 loss 43.028111 loss_att 26.761810 loss_ctc 80.982811 loss_ctc_origin 48.337215 loss_ctc0 157.155853 lr 0.00088094 rank 0
2022-08-24 04:25:48,889 DEBUG TRAIN Batch 90/3600 loss 39.828014 loss_att 22.778608 loss_ctc 79.609955 loss_ctc_origin 46.202969 loss_ctc0 157.559570 lr 0.00088086 rank 0
2022-08-24 04:26:17,148 DEBUG TRAIN Batch 90/3700 loss 21.623095 loss_att 11.975246 loss_ctc 44.134739 loss_ctc_origin 31.519323 loss_ctc0 73.570709 lr 0.00088077 rank 0
2022-08-24 04:26:47,138 DEBUG TRAIN Batch 90/3800 loss 18.188339 loss_att 7.783004 loss_ctc 42.467453 loss_ctc_origin 28.373793 loss_ctc0 75.352661 lr 0.00088069 rank 0
2022-08-24 04:27:16,267 DEBUG TRAIN Batch 90/3900 loss 27.158585 loss_att 13.136435 loss_ctc 59.876930 loss_ctc_origin 42.380310 loss_ctc0 100.702377 lr 0.00088060 rank 0
2022-08-24 04:27:42,964 DEBUG TRAIN Batch 90/4000 loss 40.024147 loss_att 28.706186 loss_ctc 66.432724 loss_ctc_origin 43.960503 loss_ctc0 118.867897 lr 0.00088052 rank 0
2022-08-24 04:28:11,451 DEBUG TRAIN Batch 90/4100 loss 44.079845 loss_att 25.783228 loss_ctc 86.771950 loss_ctc_origin 50.663437 loss_ctc0 171.025146 lr 0.00088043 rank 0
2022-08-24 04:28:40,047 DEBUG TRAIN Batch 90/4200 loss 23.909271 loss_att 12.293674 loss_ctc 51.012333 loss_ctc_origin 40.661728 loss_ctc0 75.163742 lr 0.00088035 rank 0
2022-08-24 04:29:10,773 DEBUG TRAIN Batch 90/4300 loss 22.311062 loss_att 9.746316 loss_ctc 51.628799 loss_ctc_origin 36.138123 loss_ctc0 87.773712 lr 0.00088026 rank 0
2022-08-24 04:29:36,997 DEBUG TRAIN Batch 90/4400 loss 28.503559 loss_att 14.130636 loss_ctc 62.040375 loss_ctc_origin 46.781326 loss_ctc0 97.644806 lr 0.00088017 rank 0
2022-08-24 04:30:12,753 DEBUG TRAIN Batch 90/4500 loss 31.634872 loss_att 19.497330 loss_ctc 59.955803 loss_ctc_origin 34.392487 loss_ctc0 119.603546 lr 0.00088009 rank 0
2022-08-24 04:30:41,706 DEBUG TRAIN Batch 90/4600 loss 46.611595 loss_att 27.581776 loss_ctc 91.014511 loss_ctc_origin 52.239319 loss_ctc0 181.489944 lr 0.00088000 rank 0
2022-08-24 04:31:10,282 DEBUG TRAIN Batch 90/4700 loss 19.480518 loss_att 11.375706 loss_ctc 38.391747 loss_ctc_origin 27.976395 loss_ctc0 62.694237 lr 0.00087992 rank 0
2022-08-24 04:31:39,838 DEBUG TRAIN Batch 90/4800 loss 18.899399 loss_att 8.442667 loss_ctc 43.298439 loss_ctc_origin 27.779348 loss_ctc0 79.509651 lr 0.00087983 rank 0
2022-08-24 04:32:05,077 WARNING NaN or Inf found in input tensor.
2022-08-24 04:32:09,609 DEBUG TRAIN Batch 90/4900 loss 23.717342 loss_att 11.603708 loss_ctc 51.982491 loss_ctc_origin 35.014538 loss_ctc0 91.574371 lr 0.00087975 rank 0
2022-08-24 04:32:38,863 DEBUG TRAIN Batch 90/5000 loss 35.702389 loss_att 23.369225 loss_ctc 64.479767 loss_ctc_origin 39.754280 loss_ctc0 122.172577 lr 0.00087966 rank 0
2022-08-24 04:33:07,075 DEBUG TRAIN Batch 90/5100 loss 38.736103 loss_att 21.557529 loss_ctc 78.819435 loss_ctc_origin 42.417267 loss_ctc0 163.757812 lr 0.00087958 rank 0
2022-08-24 04:33:35,370 DEBUG TRAIN Batch 90/5200 loss 24.334690 loss_att 15.351924 loss_ctc 45.294479 loss_ctc_origin 35.732056 loss_ctc0 67.606812 lr 0.00087949 rank 0
2022-08-24 04:33:40,667 WARNING NaN or Inf found in input tensor.
2022-08-24 04:34:04,194 DEBUG TRAIN Batch 90/5300 loss 19.691847 loss_att 9.298641 loss_ctc 43.942657 loss_ctc_origin 30.874718 loss_ctc0 74.434517 lr 0.00087941 rank 0
2022-08-24 04:34:28,641 WARNING NaN or Inf found in input tensor.
2022-08-24 04:34:33,078 DEBUG TRAIN Batch 90/5400 loss 23.263702 loss_att 11.518112 loss_ctc 50.670074 loss_ctc_origin 33.771523 loss_ctc0 90.100021 lr 0.00087932 rank 0
2022-08-24 04:34:55,124 WARNING NaN or Inf found in input tensor.
2022-08-24 04:35:02,311 DEBUG TRAIN Batch 90/5500 loss 39.140179 loss_att 25.267746 loss_ctc 71.509186 loss_ctc_origin 43.039528 loss_ctc0 137.938385 lr 0.00087924 rank 0
2022-08-24 04:35:30,489 DEBUG TRAIN Batch 90/5600 loss 42.057281 loss_att 22.170193 loss_ctc 88.460480 loss_ctc_origin 42.483948 loss_ctc0 195.739044 lr 0.00087915 rank 0
2022-08-24 04:35:54,337 DEBUG CV Batch 90/0 loss 14.328999 loss_att 10.945988 loss_ctc 22.222691 loss_ctc_origin 16.523903 loss_ctc0 35.519867 history loss 13.486116 rank 0
2022-08-24 04:36:05,363 DEBUG CV Batch 90/100 loss 24.794296 loss_att 19.741350 loss_ctc 36.584503 loss_ctc_origin 27.201565 loss_ctc0 58.478027 history loss 29.195101 rank 0
2022-08-24 04:36:15,325 DEBUG CV Batch 90/200 loss 24.974718 loss_att 18.964314 loss_ctc 38.998993 loss_ctc_origin 28.546722 loss_ctc0 63.387619 history loss 30.615970 rank 0
2022-08-24 04:36:25,784 DEBUG CV Batch 90/300 loss 25.844955 loss_att 19.839960 loss_ctc 39.856613 loss_ctc_origin 25.073032 loss_ctc0 74.351639 history loss 29.627523 rank 0
2022-08-24 04:36:36,557 DEBUG CV Batch 90/400 loss 39.461647 loss_att 31.529099 loss_ctc 57.970924 loss_ctc_origin 40.665634 loss_ctc0 98.349930 history loss 27.808967 rank 0
2022-08-24 04:36:47,638 DEBUG CV Batch 90/500 loss 18.237469 loss_att 13.582273 loss_ctc 29.099594 loss_ctc_origin 22.489948 loss_ctc0 44.522095 history loss 27.378269 rank 0
2022-08-24 04:36:58,689 DEBUG CV Batch 90/600 loss 18.502718 loss_att 12.863703 loss_ctc 31.660419 loss_ctc_origin 21.002758 loss_ctc0 56.528290 history loss 27.173733 rank 0
2022-08-24 04:37:08,772 DEBUG CV Batch 90/700 loss 21.178314 loss_att 14.696230 loss_ctc 36.303177 loss_ctc_origin 23.741234 loss_ctc0 65.614365 history loss 26.829225 rank 0
2022-08-24 04:37:19,271 DEBUG CV Batch 90/800 loss 23.913645 loss_att 18.444454 loss_ctc 36.675091 loss_ctc_origin 22.062296 loss_ctc0 70.771606 history loss 26.733993 rank 0
2022-08-24 04:37:30,037 INFO Epoch 90 CV info cv_loss 26.77920668977349
2022-08-24 04:37:30,037 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/90.pt
2022-08-24 04:37:30,563 INFO Epoch 91 TRAIN info lr 0.0008790822389925559
2022-08-24 04:37:30,567 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 04:37:57,859 DEBUG TRAIN Batch 91/0 loss 42.614052 loss_att 29.346748 loss_ctc 73.571091 loss_ctc_origin 48.356365 loss_ctc0 132.405426 lr 0.00087908 rank 0
2022-08-24 04:38:26,618 DEBUG TRAIN Batch 91/100 loss 42.022305 loss_att 21.410559 loss_ctc 90.116379 loss_ctc_origin 46.955532 loss_ctc0 190.825027 lr 0.00087899 rank 0
2022-08-24 04:38:55,655 DEBUG TRAIN Batch 91/200 loss 20.260746 loss_att 10.508356 loss_ctc 43.016323 loss_ctc_origin 31.084297 loss_ctc0 70.857712 lr 0.00087891 rank 0
2022-08-24 04:39:25,227 DEBUG TRAIN Batch 91/300 loss 21.787083 loss_att 11.039534 loss_ctc 46.864693 loss_ctc_origin 32.643429 loss_ctc0 80.047638 lr 0.00087882 rank 0
2022-08-24 04:39:53,382 DEBUG TRAIN Batch 91/400 loss 24.258089 loss_att 10.521544 loss_ctc 56.310028 loss_ctc_origin 41.598385 loss_ctc0 90.637192 lr 0.00087874 rank 0
2022-08-24 04:40:23,713 DEBUG TRAIN Batch 91/500 loss 45.115841 loss_att 28.363716 loss_ctc 84.204132 loss_ctc_origin 51.642792 loss_ctc0 160.180603 lr 0.00087865 rank 0
2022-08-24 04:40:50,639 DEBUG TRAIN Batch 91/600 loss 56.843178 loss_att 31.717945 loss_ctc 115.468719 loss_ctc_origin 70.517288 loss_ctc0 220.355377 lr 0.00087857 rank 0
2022-08-24 04:41:20,253 DEBUG TRAIN Batch 91/700 loss 29.060038 loss_att 17.721550 loss_ctc 55.516510 loss_ctc_origin 46.365936 loss_ctc0 76.867844 lr 0.00087849 rank 0
2022-08-24 04:41:49,464 DEBUG TRAIN Batch 91/800 loss 21.310947 loss_att 9.680964 loss_ctc 48.447571 loss_ctc_origin 35.691856 loss_ctc0 78.210907 lr 0.00087840 rank 0
2022-08-24 04:42:17,804 DEBUG TRAIN Batch 91/900 loss 23.352512 loss_att 11.030663 loss_ctc 52.103493 loss_ctc_origin 35.228481 loss_ctc0 91.478516 lr 0.00087832 rank 0
2022-08-24 04:42:47,336 DEBUG TRAIN Batch 91/1000 loss 41.533676 loss_att 30.177042 loss_ctc 68.032494 loss_ctc_origin 41.115929 loss_ctc0 130.837814 lr 0.00087823 rank 0
2022-08-24 04:43:16,877 DEBUG TRAIN Batch 91/1100 loss 42.883263 loss_att 26.750954 loss_ctc 80.525314 loss_ctc_origin 48.182640 loss_ctc0 155.991547 lr 0.00087815 rank 0
2022-08-24 04:43:38,363 WARNING NaN or Inf found in input tensor.
2022-08-24 04:43:48,377 DEBUG TRAIN Batch 91/1200 loss 21.563194 loss_att 13.878270 loss_ctc 39.494678 loss_ctc_origin 28.832996 loss_ctc0 64.371933 lr 0.00087806 rank 0
2022-08-24 04:44:15,079 DEBUG TRAIN Batch 91/1300 loss 21.021458 loss_att 9.085176 loss_ctc 48.872780 loss_ctc_origin 36.355583 loss_ctc0 78.079575 lr 0.00087798 rank 0
2022-08-24 04:44:39,574 WARNING NaN or Inf found in input tensor.
2022-08-24 04:44:43,707 DEBUG TRAIN Batch 91/1400 loss 29.228554 loss_att 14.397056 loss_ctc 63.835381 loss_ctc_origin 48.123787 loss_ctc0 100.495766 lr 0.00087789 rank 0
2022-08-24 04:45:20,423 DEBUG TRAIN Batch 91/1500 loss 38.521671 loss_att 25.935913 loss_ctc 67.888443 loss_ctc_origin 41.686897 loss_ctc0 129.025391 lr 0.00087781 rank 0
2022-08-24 04:45:49,237 DEBUG TRAIN Batch 91/1600 loss 42.224022 loss_att 24.031824 loss_ctc 84.672470 loss_ctc_origin 47.413704 loss_ctc0 171.609589 lr 0.00087772 rank 0
2022-08-24 04:46:18,392 DEBUG TRAIN Batch 91/1700 loss 25.213795 loss_att 15.258356 loss_ctc 48.443146 loss_ctc_origin 38.781349 loss_ctc0 70.987328 lr 0.00087764 rank 0
2022-08-24 04:46:46,989 DEBUG TRAIN Batch 91/1800 loss 25.529133 loss_att 12.350650 loss_ctc 56.278923 loss_ctc_origin 42.156067 loss_ctc0 89.232246 lr 0.00087755 rank 0
2022-08-24 04:47:15,270 DEBUG TRAIN Batch 91/1900 loss 26.323822 loss_att 12.979967 loss_ctc 57.459480 loss_ctc_origin 40.379440 loss_ctc0 97.312904 lr 0.00087747 rank 0
2022-08-24 04:47:43,807 DEBUG TRAIN Batch 91/2000 loss 37.992443 loss_att 25.479395 loss_ctc 67.189552 loss_ctc_origin 43.349464 loss_ctc0 122.816422 lr 0.00087739 rank 0
2022-08-24 04:48:12,559 DEBUG TRAIN Batch 91/2100 loss 50.022873 loss_att 31.070778 loss_ctc 94.244431 loss_ctc_origin 57.066223 loss_ctc0 180.993576 lr 0.00087730 rank 0
2022-08-24 04:48:40,231 DEBUG TRAIN Batch 91/2200 loss 23.738321 loss_att 15.312873 loss_ctc 43.397697 loss_ctc_origin 34.374397 loss_ctc0 64.452057 lr 0.00087722 rank 0
2022-08-24 04:49:07,948 DEBUG TRAIN Batch 91/2300 loss 21.208569 loss_att 8.987917 loss_ctc 49.723419 loss_ctc_origin 34.710789 loss_ctc0 84.752884 lr 0.00087713 rank 0
2022-08-24 04:49:38,145 DEBUG TRAIN Batch 91/2400 loss 29.387079 loss_att 14.060560 loss_ctc 65.148956 loss_ctc_origin 49.962646 loss_ctc0 100.583694 lr 0.00087705 rank 0
2022-08-24 04:50:06,879 DEBUG TRAIN Batch 91/2500 loss 34.101280 loss_att 24.664028 loss_ctc 56.121532 loss_ctc_origin 39.884388 loss_ctc0 94.008202 lr 0.00087696 rank 0
2022-08-24 04:50:35,662 DEBUG TRAIN Batch 91/2600 loss 42.183876 loss_att 27.744820 loss_ctc 75.875008 loss_ctc_origin 45.772976 loss_ctc0 146.113068 lr 0.00087688 rank 0
2022-08-24 04:51:02,549 DEBUG TRAIN Batch 91/2700 loss 24.104649 loss_att 13.398756 loss_ctc 49.085060 loss_ctc_origin 37.484264 loss_ctc0 76.153580 lr 0.00087680 rank 0
2022-08-24 04:51:31,807 DEBUG TRAIN Batch 91/2800 loss 23.131699 loss_att 12.037058 loss_ctc 49.019188 loss_ctc_origin 35.232037 loss_ctc0 81.189194 lr 0.00087671 rank 0
2022-08-24 04:51:59,640 DEBUG TRAIN Batch 91/2900 loss 29.500935 loss_att 14.042587 loss_ctc 65.570412 loss_ctc_origin 50.244522 loss_ctc0 101.330826 lr 0.00087663 rank 0
2022-08-24 04:52:35,318 DEBUG TRAIN Batch 91/3000 loss 30.498779 loss_att 20.047050 loss_ctc 54.886139 loss_ctc_origin 35.886803 loss_ctc0 99.217911 lr 0.00087654 rank 0
2022-08-24 04:53:04,359 DEBUG TRAIN Batch 91/3100 loss 47.729568 loss_att 25.483997 loss_ctc 99.635902 loss_ctc_origin 58.494049 loss_ctc0 195.633545 lr 0.00087646 rank 0
2022-08-24 04:53:33,256 DEBUG TRAIN Batch 91/3200 loss 24.519920 loss_att 13.210289 loss_ctc 50.909058 loss_ctc_origin 42.170467 loss_ctc0 71.299103 lr 0.00087637 rank 0
2022-08-24 04:54:01,594 DEBUG TRAIN Batch 91/3300 loss 22.375622 loss_att 11.323076 loss_ctc 48.164894 loss_ctc_origin 34.952271 loss_ctc0 78.994339 lr 0.00087629 rank 0
2022-08-24 04:54:25,652 WARNING NaN or Inf found in input tensor.
2022-08-24 04:54:30,628 DEBUG TRAIN Batch 91/3400 loss 26.814980 loss_att 12.208589 loss_ctc 60.896561 loss_ctc_origin 45.598114 loss_ctc0 96.592926 lr 0.00087621 rank 0
2022-08-24 04:54:58,123 DEBUG TRAIN Batch 91/3500 loss 32.298073 loss_att 21.366476 loss_ctc 57.805138 loss_ctc_origin 38.336784 loss_ctc0 103.231300 lr 0.00087612 rank 0
2022-08-24 04:55:28,243 DEBUG TRAIN Batch 91/3600 loss 49.386395 loss_att 27.211666 loss_ctc 101.127426 loss_ctc_origin 53.415897 loss_ctc0 212.454300 lr 0.00087604 rank 0
2022-08-24 04:55:49,336 WARNING NaN or Inf found in input tensor.
2022-08-24 04:55:57,344 DEBUG TRAIN Batch 91/3700 loss 21.807121 loss_att 12.139056 loss_ctc 44.365936 loss_ctc_origin 33.091324 loss_ctc0 70.673363 lr 0.00087595 rank 0
2022-08-24 04:56:26,935 DEBUG TRAIN Batch 91/3800 loss 26.403507 loss_att 13.964468 loss_ctc 55.427933 loss_ctc_origin 43.036324 loss_ctc0 84.341690 lr 0.00087587 rank 0
2022-08-24 04:56:55,608 DEBUG TRAIN Batch 91/3900 loss 25.401651 loss_att 12.263734 loss_ctc 56.056789 loss_ctc_origin 37.889587 loss_ctc0 98.446922 lr 0.00087579 rank 0
2022-08-24 04:57:25,409 DEBUG TRAIN Batch 91/4000 loss 31.139053 loss_att 20.993061 loss_ctc 54.813034 loss_ctc_origin 36.442703 loss_ctc0 97.677147 lr 0.00087570 rank 0
2022-08-24 04:57:53,519 DEBUG TRAIN Batch 91/4100 loss 42.740433 loss_att 23.403463 loss_ctc 87.860023 loss_ctc_origin 45.548294 loss_ctc0 186.587372 lr 0.00087562 rank 0
2022-08-24 04:58:21,866 DEBUG TRAIN Batch 91/4200 loss 23.556810 loss_att 13.494912 loss_ctc 47.034569 loss_ctc_origin 35.549335 loss_ctc0 73.833443 lr 0.00087553 rank 0
2022-08-24 04:58:52,285 DEBUG TRAIN Batch 91/4300 loss 20.263456 loss_att 9.328087 loss_ctc 45.779320 loss_ctc_origin 32.019348 loss_ctc0 77.885925 lr 0.00087545 rank 0
2022-08-24 04:59:20,365 DEBUG TRAIN Batch 91/4400 loss 27.422880 loss_att 12.926494 loss_ctc 61.247776 loss_ctc_origin 45.441116 loss_ctc0 98.129982 lr 0.00087537 rank 0
2022-08-24 04:59:53,638 DEBUG TRAIN Batch 91/4500 loss 37.430588 loss_att 25.950871 loss_ctc 64.216591 loss_ctc_origin 42.574226 loss_ctc0 114.715431 lr 0.00087528 rank 0
2022-08-24 05:00:20,969 DEBUG TRAIN Batch 91/4600 loss 49.908749 loss_att 30.299603 loss_ctc 95.663422 loss_ctc_origin 51.485828 loss_ctc0 198.744461 lr 0.00087520 rank 0
2022-08-24 05:00:49,718 DEBUG TRAIN Batch 91/4700 loss 22.807480 loss_att 12.763069 loss_ctc 46.244438 loss_ctc_origin 35.846218 loss_ctc0 70.506943 lr 0.00087511 rank 0
2022-08-24 05:01:15,103 WARNING NaN or Inf found in input tensor.
2022-08-24 05:01:17,606 DEBUG TRAIN Batch 91/4800 loss 23.196735 loss_att 12.043312 loss_ctc 49.221390 loss_ctc_origin 37.590832 loss_ctc0 76.359360 lr 0.00087503 rank 0
2022-08-24 05:01:46,254 DEBUG TRAIN Batch 91/4900 loss 28.138723 loss_att 14.694457 loss_ctc 59.508675 loss_ctc_origin 44.751183 loss_ctc0 93.942825 lr 0.00087495 rank 0
2022-08-24 05:02:15,010 DEBUG TRAIN Batch 91/5000 loss 42.684616 loss_att 28.735867 loss_ctc 75.231689 loss_ctc_origin 45.660980 loss_ctc0 144.230011 lr 0.00087486 rank 0
2022-08-24 05:02:43,310 DEBUG TRAIN Batch 91/5100 loss 51.676674 loss_att 27.957689 loss_ctc 107.020966 loss_ctc_origin 50.621773 loss_ctc0 238.619080 lr 0.00087478 rank 0
2022-08-24 05:03:10,803 DEBUG TRAIN Batch 91/5200 loss 20.560038 loss_att 10.279276 loss_ctc 44.548481 loss_ctc_origin 33.738976 loss_ctc0 69.770660 lr 0.00087470 rank 0
2022-08-24 05:03:39,633 DEBUG TRAIN Batch 91/5300 loss 20.876686 loss_att 9.509220 loss_ctc 47.400772 loss_ctc_origin 33.646084 loss_ctc0 79.495041 lr 0.00087461 rank 0
2022-08-24 05:04:08,073 DEBUG TRAIN Batch 91/5400 loss 29.162144 loss_att 13.684212 loss_ctc 65.277313 loss_ctc_origin 50.038048 loss_ctc0 100.835587 lr 0.00087453 rank 0
2022-08-24 05:04:36,155 DEBUG TRAIN Batch 91/5500 loss 43.488190 loss_att 24.784492 loss_ctc 87.130157 loss_ctc_origin 48.868935 loss_ctc0 176.406326 lr 0.00087445 rank 0
2022-08-24 05:05:05,060 DEBUG TRAIN Batch 91/5600 loss 52.179825 loss_att 29.020227 loss_ctc 106.218887 loss_ctc_origin 49.227119 loss_ctc0 239.199677 lr 0.00087436 rank 0
2022-08-24 05:05:27,158 DEBUG CV Batch 91/0 loss 13.265375 loss_att 10.055959 loss_ctc 20.754013 loss_ctc_origin 14.755203 loss_ctc0 34.751236 history loss 12.485059 rank 0
2022-08-24 05:05:37,099 DEBUG CV Batch 91/100 loss 23.379894 loss_att 18.577467 loss_ctc 34.585556 loss_ctc_origin 25.412766 loss_ctc0 55.988735 history loss 28.759600 rank 0
2022-08-24 05:05:46,271 DEBUG CV Batch 91/200 loss 25.512699 loss_att 19.330976 loss_ctc 39.936718 loss_ctc_origin 29.970448 loss_ctc0 63.191345 history loss 30.158903 rank 0
2022-08-24 05:05:55,727 DEBUG CV Batch 91/300 loss 24.867924 loss_att 18.621040 loss_ctc 39.443985 loss_ctc_origin 24.370443 loss_ctc0 74.615585 history loss 29.238966 rank 0
2022-08-24 05:06:05,690 DEBUG CV Batch 91/400 loss 39.955795 loss_att 32.020538 loss_ctc 58.471390 loss_ctc_origin 41.569580 loss_ctc0 97.908951 history loss 27.505710 rank 0
2022-08-24 05:06:16,464 DEBUG CV Batch 91/500 loss 17.355255 loss_att 12.994986 loss_ctc 27.529215 loss_ctc_origin 20.818834 loss_ctc0 43.186768 history loss 27.154205 rank 0
2022-08-24 05:06:26,375 DEBUG CV Batch 91/600 loss 18.566349 loss_att 13.007884 loss_ctc 31.536102 loss_ctc_origin 21.197926 loss_ctc0 55.658508 history loss 26.915337 rank 0
2022-08-24 05:06:35,944 DEBUG CV Batch 91/700 loss 20.282280 loss_att 13.701273 loss_ctc 35.637959 loss_ctc_origin 22.922619 loss_ctc0 65.307083 history loss 26.568269 rank 0
2022-08-24 05:06:45,691 DEBUG CV Batch 91/800 loss 23.943016 loss_att 18.568983 loss_ctc 36.482430 loss_ctc_origin 21.612694 loss_ctc0 71.178474 history loss 26.498774 rank 0
2022-08-24 05:06:55,667 INFO Epoch 91 CV info cv_loss 26.590783910590922
2022-08-24 05:06:55,667 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/91.pt
2022-08-24 05:06:56,111 INFO Epoch 92 TRAIN info lr 0.0008742915644220992
2022-08-24 05:06:56,114 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 05:07:23,305 DEBUG TRAIN Batch 92/0 loss 45.135757 loss_att 28.362698 loss_ctc 84.272903 loss_ctc_origin 53.134224 loss_ctc0 156.929840 lr 0.00087429 rank 0
2022-08-24 05:07:52,280 DEBUG TRAIN Batch 92/100 loss 57.988380 loss_att 31.977554 loss_ctc 118.680313 loss_ctc_origin 62.052353 loss_ctc0 250.812210 lr 0.00087420 rank 0
2022-08-24 05:08:21,617 DEBUG TRAIN Batch 92/200 loss 23.831106 loss_att 14.604975 loss_ctc 45.358746 loss_ctc_origin 36.086021 loss_ctc0 66.995102 lr 0.00087412 rank 0
2022-08-24 05:08:49,592 DEBUG TRAIN Batch 92/300 loss 23.495758 loss_att 11.524520 loss_ctc 51.428642 loss_ctc_origin 39.245369 loss_ctc0 79.856285 lr 0.00087404 rank 0
2022-08-24 05:09:19,232 DEBUG TRAIN Batch 92/400 loss 24.877844 loss_att 12.380835 loss_ctc 54.037529 loss_ctc_origin 37.605309 loss_ctc0 92.379379 lr 0.00087395 rank 0
2022-08-24 05:09:48,633 DEBUG TRAIN Batch 92/500 loss 39.075665 loss_att 22.139065 loss_ctc 78.594398 loss_ctc_origin 37.784233 loss_ctc0 173.818115 lr 0.00087387 rank 0
2022-08-24 05:10:09,343 WARNING NaN or Inf found in input tensor.
2022-08-24 05:10:17,045 DEBUG TRAIN Batch 92/600 loss 49.669884 loss_att 28.281216 loss_ctc 99.576782 loss_ctc_origin 54.561256 loss_ctc0 204.613007 lr 0.00087379 rank 0
2022-08-24 05:10:45,783 DEBUG TRAIN Batch 92/700 loss 27.830723 loss_att 17.041090 loss_ctc 53.006531 loss_ctc_origin 45.047775 loss_ctc0 71.576965 lr 0.00087370 rank 0
2022-08-24 05:11:14,756 DEBUG TRAIN Batch 92/800 loss 23.095795 loss_att 9.113156 loss_ctc 55.721951 loss_ctc_origin 42.080589 loss_ctc0 87.551796 lr 0.00087362 rank 0
2022-08-24 05:11:44,615 DEBUG TRAIN Batch 92/900 loss 25.081150 loss_att 11.254979 loss_ctc 57.342213 loss_ctc_origin 39.439976 loss_ctc0 99.114098 lr 0.00087354 rank 0
2022-08-24 05:12:12,129 DEBUG TRAIN Batch 92/1000 loss 38.728241 loss_att 25.398048 loss_ctc 69.832016 loss_ctc_origin 43.347118 loss_ctc0 131.630096 lr 0.00087345 rank 0
2022-08-24 05:12:26,141 WARNING NaN or Inf found in input tensor.
2022-08-24 05:12:40,759 DEBUG TRAIN Batch 92/1100 loss 45.932167 loss_att 23.812824 loss_ctc 97.543961 loss_ctc_origin 50.169548 loss_ctc0 208.084259 lr 0.00087337 rank 0
2022-08-24 05:13:08,579 DEBUG TRAIN Batch 92/1200 loss 23.467636 loss_att 12.883511 loss_ctc 48.163925 loss_ctc_origin 37.717518 loss_ctc0 72.538872 lr 0.00087329 rank 0
2022-08-24 05:13:38,258 DEBUG TRAIN Batch 92/1300 loss 22.462214 loss_att 10.313368 loss_ctc 50.809517 loss_ctc_origin 38.135254 loss_ctc0 80.382797 lr 0.00087320 rank 0
2022-08-24 05:14:07,418 DEBUG TRAIN Batch 92/1400 loss 29.053448 loss_att 13.137180 loss_ctc 66.191406 loss_ctc_origin 46.781998 loss_ctc0 111.480003 lr 0.00087312 rank 0
2022-08-24 05:14:42,229 DEBUG TRAIN Batch 92/1500 loss 47.878937 loss_att 30.990433 loss_ctc 87.285454 loss_ctc_origin 51.562531 loss_ctc0 170.638947 lr 0.00087304 rank 0
2022-08-24 05:15:10,290 DEBUG TRAIN Batch 92/1600 loss 39.949009 loss_att 23.655663 loss_ctc 77.966812 loss_ctc_origin 39.858829 loss_ctc0 166.885422 lr 0.00087295 rank 0
2022-08-24 05:15:38,967 DEBUG TRAIN Batch 92/1700 loss 21.662086 loss_att 12.660401 loss_ctc 42.666016 loss_ctc_origin 33.672474 loss_ctc0 63.650948 lr 0.00087287 rank 0
2022-08-24 05:16:07,812 DEBUG TRAIN Batch 92/1800 loss 22.054050 loss_att 10.721342 loss_ctc 48.497036 loss_ctc_origin 34.809708 loss_ctc0 80.434135 lr 0.00087279 rank 0
2022-08-24 05:16:36,690 DEBUG TRAIN Batch 92/1900 loss 24.412308 loss_att 11.605748 loss_ctc 54.294277 loss_ctc_origin 36.515755 loss_ctc0 95.777496 lr 0.00087271 rank 0
2022-08-24 05:16:38,557 WARNING NaN or Inf found in input tensor.
2022-08-24 05:17:05,732 DEBUG TRAIN Batch 92/2000 loss 39.982311 loss_att 25.511837 loss_ctc 73.746750 loss_ctc_origin 43.443069 loss_ctc0 144.455338 lr 0.00087262 rank 0
2022-08-24 05:17:14,045 WARNING NaN or Inf found in input tensor.
2022-08-24 05:17:34,631 DEBUG TRAIN Batch 92/2100 loss 33.828514 loss_att 19.228870 loss_ctc 67.894348 loss_ctc_origin 40.235466 loss_ctc0 132.431732 lr 0.00087254 rank 0
2022-08-24 05:18:03,092 DEBUG TRAIN Batch 92/2200 loss 22.896124 loss_att 12.850534 loss_ctc 46.335831 loss_ctc_origin 36.711014 loss_ctc0 68.793732 lr 0.00087246 rank 0
2022-08-24 05:18:31,036 DEBUG TRAIN Batch 92/2300 loss 23.146015 loss_att 12.390483 loss_ctc 48.242256 loss_ctc_origin 36.020729 loss_ctc0 76.759155 lr 0.00087237 rank 0
2022-08-24 05:18:59,407 DEBUG TRAIN Batch 92/2400 loss 23.795515 loss_att 10.874609 loss_ctc 53.944290 loss_ctc_origin 36.164101 loss_ctc0 95.431396 lr 0.00087229 rank 0
2022-08-24 05:19:27,109 DEBUG TRAIN Batch 92/2500 loss 42.008751 loss_att 25.523174 loss_ctc 80.475098 loss_ctc_origin 41.284790 loss_ctc0 171.919159 lr 0.00087221 rank 0
2022-08-24 05:19:54,926 DEBUG TRAIN Batch 92/2600 loss 47.818439 loss_att 27.164017 loss_ctc 96.012093 loss_ctc_origin 45.373833 loss_ctc0 214.168030 lr 0.00087212 rank 0
2022-08-24 05:20:22,963 DEBUG TRAIN Batch 92/2700 loss 21.962738 loss_att 13.036039 loss_ctc 42.791702 loss_ctc_origin 33.382568 loss_ctc0 64.746338 lr 0.00087204 rank 0
2022-08-24 05:20:52,433 DEBUG TRAIN Batch 92/2800 loss 26.995085 loss_att 13.701221 loss_ctc 58.014099 loss_ctc_origin 46.431278 loss_ctc0 85.040665 lr 0.00087196 rank 0
2022-08-24 05:21:21,622 DEBUG TRAIN Batch 92/2900 loss 27.774158 loss_att 13.459924 loss_ctc 61.174042 loss_ctc_origin 45.621006 loss_ctc0 97.464462 lr 0.00087188 rank 0
2022-08-24 05:21:56,968 DEBUG TRAIN Batch 92/3000 loss 44.553226 loss_att 28.951019 loss_ctc 80.958374 loss_ctc_origin 46.908596 loss_ctc0 160.407837 lr 0.00087179 rank 0
2022-08-24 05:22:25,561 DEBUG TRAIN Batch 92/3100 loss 52.145172 loss_att 31.807724 loss_ctc 99.599213 loss_ctc_origin 55.986828 loss_ctc0 201.361420 lr 0.00087171 rank 0
2022-08-24 05:22:54,270 DEBUG TRAIN Batch 92/3200 loss 21.470173 loss_att 11.725676 loss_ctc 44.207333 loss_ctc_origin 33.796089 loss_ctc0 68.500229 lr 0.00087163 rank 0
2022-08-24 05:23:22,187 DEBUG TRAIN Batch 92/3300 loss 22.719917 loss_att 10.529411 loss_ctc 51.164429 loss_ctc_origin 37.958122 loss_ctc0 81.979141 lr 0.00087154 rank 0
2022-08-24 05:23:51,189 DEBUG TRAIN Batch 92/3400 loss 26.593975 loss_att 13.045656 loss_ctc 58.206718 loss_ctc_origin 41.967113 loss_ctc0 96.099121 lr 0.00087146 rank 0
2022-08-24 05:24:19,777 DEBUG TRAIN Batch 92/3500 loss 37.723251 loss_att 25.926525 loss_ctc 65.248947 loss_ctc_origin 39.603127 loss_ctc0 125.089188 lr 0.00087138 rank 0
2022-08-24 05:24:48,741 DEBUG TRAIN Batch 92/3600 loss 43.124664 loss_att 23.450642 loss_ctc 89.030708 loss_ctc_origin 43.871914 loss_ctc0 194.401230 lr 0.00087130 rank 0
2022-08-24 05:25:15,386 DEBUG TRAIN Batch 92/3700 loss 24.691124 loss_att 14.932717 loss_ctc 47.460739 loss_ctc_origin 37.715603 loss_ctc0 70.199387 lr 0.00087121 rank 0
2022-08-24 05:25:42,836 DEBUG TRAIN Batch 92/3800 loss 20.972164 loss_att 10.022709 loss_ctc 46.520889 loss_ctc_origin 32.860760 loss_ctc0 78.394516 lr 0.00087113 rank 0
2022-08-24 05:26:10,072 DEBUG TRAIN Batch 92/3900 loss 25.012733 loss_att 11.988727 loss_ctc 55.402081 loss_ctc_origin 37.246536 loss_ctc0 97.765015 lr 0.00087105 rank 0
2022-08-24 05:26:37,919 DEBUG TRAIN Batch 92/4000 loss 38.734756 loss_att 26.333134 loss_ctc 67.671875 loss_ctc_origin 43.387299 loss_ctc0 124.335892 lr 0.00087097 rank 0
2022-08-24 05:27:05,999 DEBUG TRAIN Batch 92/4100 loss 47.079422 loss_att 23.621515 loss_ctc 101.814529 loss_ctc_origin 52.233795 loss_ctc0 217.502899 lr 0.00087088 rank 0
2022-08-24 05:27:33,348 DEBUG TRAIN Batch 92/4200 loss 20.858078 loss_att 10.726299 loss_ctc 44.498894 loss_ctc_origin 32.098648 loss_ctc0 73.432808 lr 0.00087080 rank 0
2022-08-24 05:28:00,944 DEBUG TRAIN Batch 92/4300 loss 23.075573 loss_att 10.888678 loss_ctc 51.511658 loss_ctc_origin 38.938927 loss_ctc0 80.848038 lr 0.00087072 rank 0
2022-08-24 05:28:27,857 DEBUG TRAIN Batch 92/4400 loss 26.111172 loss_att 11.545651 loss_ctc 60.097389 loss_ctc_origin 42.810432 loss_ctc0 100.433624 lr 0.00087064 rank 0
2022-08-24 05:29:03,156 DEBUG TRAIN Batch 92/4500 loss 43.802162 loss_att 25.719370 loss_ctc 85.995331 loss_ctc_origin 51.107822 loss_ctc0 167.399506 lr 0.00087055 rank 0
2022-08-24 05:29:32,619 DEBUG TRAIN Batch 92/4600 loss 45.927166 loss_att 23.815817 loss_ctc 97.520309 loss_ctc_origin 50.659138 loss_ctc0 206.863037 lr 0.00087047 rank 0
2022-08-24 05:30:01,019 DEBUG TRAIN Batch 92/4700 loss 24.459694 loss_att 15.254753 loss_ctc 45.937889 loss_ctc_origin 34.613548 loss_ctc0 72.361351 lr 0.00087039 rank 0
2022-08-24 05:30:29,435 DEBUG TRAIN Batch 92/4800 loss 23.266689 loss_att 11.826082 loss_ctc 49.961441 loss_ctc_origin 37.599091 loss_ctc0 78.806931 lr 0.00087031 rank 0
2022-08-24 05:30:57,114 DEBUG TRAIN Batch 92/4900 loss 27.817200 loss_att 14.261209 loss_ctc 59.447845 loss_ctc_origin 43.150990 loss_ctc0 97.473846 lr 0.00087022 rank 0
2022-08-24 05:31:26,324 DEBUG TRAIN Batch 92/5000 loss 51.555321 loss_att 31.987690 loss_ctc 97.213120 loss_ctc_origin 61.112328 loss_ctc0 181.448303 lr 0.00087014 rank 0
2022-08-24 05:31:53,262 DEBUG TRAIN Batch 92/5100 loss 47.495270 loss_att 24.523581 loss_ctc 101.095871 loss_ctc_origin 49.421051 loss_ctc0 221.670441 lr 0.00087006 rank 0
2022-08-24 05:32:21,764 DEBUG TRAIN Batch 92/5200 loss 22.531235 loss_att 13.741590 loss_ctc 43.040401 loss_ctc_origin 33.623730 loss_ctc0 65.012634 lr 0.00086998 rank 0
2022-08-24 05:32:47,601 DEBUG TRAIN Batch 92/5300 loss 25.014467 loss_att 13.032784 loss_ctc 52.971725 loss_ctc_origin 40.897724 loss_ctc0 81.144402 lr 0.00086989 rank 0
2022-08-24 05:33:14,512 DEBUG TRAIN Batch 92/5400 loss 23.776384 loss_att 10.330013 loss_ctc 55.151249 loss_ctc_origin 39.093582 loss_ctc0 92.619133 lr 0.00086981 rank 0
2022-08-24 05:33:42,675 DEBUG TRAIN Batch 92/5500 loss 46.720467 loss_att 30.423679 loss_ctc 84.746292 loss_ctc_origin 46.169960 loss_ctc0 174.757736 lr 0.00086973 rank 0
2022-08-24 05:34:09,459 DEBUG TRAIN Batch 92/5600 loss 48.223324 loss_att 28.196840 loss_ctc 94.951782 loss_ctc_origin 58.242085 loss_ctc0 180.607727 lr 0.00086965 rank 0
2022-08-24 05:34:31,416 DEBUG CV Batch 92/0 loss 13.097513 loss_att 9.597851 loss_ctc 21.263393 loss_ctc_origin 15.091502 loss_ctc0 35.664471 history loss 12.327071 rank 0
2022-08-24 05:34:41,689 DEBUG CV Batch 92/100 loss 22.539898 loss_att 17.181065 loss_ctc 35.043839 loss_ctc_origin 25.169104 loss_ctc0 58.084888 history loss 28.288139 rank 0
2022-08-24 05:34:51,283 DEBUG CV Batch 92/200 loss 24.107887 loss_att 18.284477 loss_ctc 37.695847 loss_ctc_origin 26.448393 loss_ctc0 63.939903 history loss 29.402218 rank 0
2022-08-24 05:35:00,800 DEBUG CV Batch 92/300 loss 24.450699 loss_att 17.966095 loss_ctc 39.581444 loss_ctc_origin 24.135382 loss_ctc0 75.622253 history loss 28.526772 rank 0
2022-08-24 05:35:10,886 DEBUG CV Batch 92/400 loss 39.770405 loss_att 32.024300 loss_ctc 57.844646 loss_ctc_origin 40.392342 loss_ctc0 98.566689 history loss 26.887820 rank 0
2022-08-24 05:35:21,774 DEBUG CV Batch 92/500 loss 17.588764 loss_att 13.300941 loss_ctc 27.593685 loss_ctc_origin 21.205173 loss_ctc0 42.500210 history loss 26.547600 rank 0
2022-08-24 05:35:31,639 DEBUG CV Batch 92/600 loss 18.308006 loss_att 12.681506 loss_ctc 31.436502 loss_ctc_origin 20.479189 loss_ctc0 57.003563 history loss 26.396534 rank 0
2022-08-24 05:35:41,027 DEBUG CV Batch 92/700 loss 19.188900 loss_att 12.620399 loss_ctc 34.515400 loss_ctc_origin 21.253456 loss_ctc0 65.459938 history loss 26.045625 rank 0
2022-08-24 05:35:50,913 DEBUG CV Batch 92/800 loss 23.159580 loss_att 17.455364 loss_ctc 36.469418 loss_ctc_origin 21.440750 loss_ctc0 71.536301 history loss 25.982245 rank 0
2022-08-24 05:36:00,944 INFO Epoch 92 CV info cv_loss 26.06980775753385
2022-08-24 05:36:00,945 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/92.pt
2022-08-24 05:36:01,384 INFO Epoch 93 TRAIN info lr 0.0008695783680142665
2022-08-24 05:36:01,387 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 05:36:27,706 DEBUG TRAIN Batch 93/0 loss 47.568726 loss_att 29.159517 loss_ctc 90.523537 loss_ctc_origin 56.830711 loss_ctc0 169.140121 lr 0.00086958 rank 0
2022-08-24 05:36:56,099 DEBUG TRAIN Batch 93/100 loss 52.591393 loss_att 29.482689 loss_ctc 106.511703 loss_ctc_origin 56.496677 loss_ctc0 223.213425 lr 0.00086949 rank 0
2022-08-24 05:37:24,678 DEBUG TRAIN Batch 93/200 loss 23.840073 loss_att 11.647963 loss_ctc 52.288322 loss_ctc_origin 42.219635 loss_ctc0 75.781921 lr 0.00086941 rank 0
2022-08-24 05:37:51,943 DEBUG TRAIN Batch 93/300 loss 23.758633 loss_att 10.986321 loss_ctc 53.560692 loss_ctc_origin 40.972530 loss_ctc0 82.933060 lr 0.00086933 rank 0
2022-08-24 05:38:19,862 DEBUG TRAIN Batch 93/400 loss 27.325264 loss_att 12.721887 loss_ctc 61.399811 loss_ctc_origin 44.467876 loss_ctc0 100.907646 lr 0.00086925 rank 0
2022-08-24 05:38:47,627 DEBUG TRAIN Batch 93/500 loss 46.743420 loss_att 29.368172 loss_ctc 87.285660 loss_ctc_origin 54.771599 loss_ctc0 163.151794 lr 0.00086916 rank 0
2022-08-24 05:39:14,343 DEBUG TRAIN Batch 93/600 loss 45.120884 loss_att 26.083614 loss_ctc 89.541176 loss_ctc_origin 55.319893 loss_ctc0 169.390839 lr 0.00086908 rank 0
2022-08-24 05:39:41,383 DEBUG TRAIN Batch 93/700 loss 20.932041 loss_att 11.773697 loss_ctc 42.301514 loss_ctc_origin 31.214073 loss_ctc0 68.172211 lr 0.00086900 rank 0
2022-08-24 05:40:08,785 DEBUG TRAIN Batch 93/800 loss 19.660322 loss_att 8.734876 loss_ctc 45.153030 loss_ctc_origin 30.570183 loss_ctc0 79.179672 lr 0.00086892 rank 0
2022-08-24 05:40:36,554 DEBUG TRAIN Batch 93/900 loss 24.907471 loss_att 11.559929 loss_ctc 56.051727 loss_ctc_origin 38.158783 loss_ctc0 97.801926 lr 0.00086884 rank 0
2022-08-24 05:41:04,768 DEBUG TRAIN Batch 93/1000 loss 43.578911 loss_att 28.455610 loss_ctc 78.866608 loss_ctc_origin 45.934498 loss_ctc0 155.708191 lr 0.00086875 rank 0
2022-08-24 05:41:32,557 DEBUG TRAIN Batch 93/1100 loss 39.898560 loss_att 22.687433 loss_ctc 80.057854 loss_ctc_origin 44.779579 loss_ctc0 162.373810 lr 0.00086867 rank 0
2022-08-24 05:41:59,576 DEBUG TRAIN Batch 93/1200 loss 24.594406 loss_att 13.767544 loss_ctc 49.857082 loss_ctc_origin 39.556641 loss_ctc0 73.891449 lr 0.00086859 rank 0
2022-08-24 05:42:26,131 DEBUG TRAIN Batch 93/1300 loss 22.675434 loss_att 11.103167 loss_ctc 49.677391 loss_ctc_origin 35.070137 loss_ctc0 83.760979 lr 0.00086851 rank 0
2022-08-24 05:42:52,715 DEBUG TRAIN Batch 93/1400 loss 26.589207 loss_att 12.110781 loss_ctc 60.372200 loss_ctc_origin 41.740700 loss_ctc0 103.845703 lr 0.00086843 rank 0
2022-08-24 05:43:26,085 DEBUG TRAIN Batch 93/1500 loss 46.044098 loss_att 29.766033 loss_ctc 84.026237 loss_ctc_origin 52.865700 loss_ctc0 156.734161 lr 0.00086834 rank 0
2022-08-24 05:43:53,701 DEBUG TRAIN Batch 93/1600 loss 47.302628 loss_att 26.107224 loss_ctc 96.758560 loss_ctc_origin 50.635639 loss_ctc0 204.378693 lr 0.00086826 rank 0
2022-08-24 05:44:20,989 DEBUG TRAIN Batch 93/1700 loss 25.908176 loss_att 16.314995 loss_ctc 48.292263 loss_ctc_origin 40.800678 loss_ctc0 65.772629 lr 0.00086818 rank 0
2022-08-24 05:44:47,717 DEBUG TRAIN Batch 93/1800 loss 21.619747 loss_att 10.917504 loss_ctc 46.591644 loss_ctc_origin 33.834518 loss_ctc0 76.358276 lr 0.00086810 rank 0
2022-08-24 05:45:15,539 DEBUG TRAIN Batch 93/1900 loss 25.170479 loss_att 11.153027 loss_ctc 57.877869 loss_ctc_origin 39.428093 loss_ctc0 100.927338 lr 0.00086802 rank 0
2022-08-24 05:45:43,544 DEBUG TRAIN Batch 93/2000 loss 42.442379 loss_att 27.812441 loss_ctc 76.578903 loss_ctc_origin 42.733765 loss_ctc0 155.550903 lr 0.00086794 rank 0
2022-08-24 05:46:11,848 DEBUG TRAIN Batch 93/2100 loss 49.577507 loss_att 28.172964 loss_ctc 99.521439 loss_ctc_origin 54.362541 loss_ctc0 204.892181 lr 0.00086785 rank 0
2022-08-24 05:46:39,610 DEBUG TRAIN Batch 93/2200 loss 26.010424 loss_att 16.671612 loss_ctc 47.800983 loss_ctc_origin 38.215740 loss_ctc0 70.166550 lr 0.00086777 rank 0
2022-08-24 05:47:07,475 DEBUG TRAIN Batch 93/2300 loss 21.088821 loss_att 9.272909 loss_ctc 48.659279 loss_ctc_origin 34.512039 loss_ctc0 81.669510 lr 0.00086769 rank 0
2022-08-24 05:47:34,696 DEBUG TRAIN Batch 93/2400 loss 25.033199 loss_att 12.109174 loss_ctc 55.189255 loss_ctc_origin 38.962719 loss_ctc0 93.051178 lr 0.00086761 rank 0
2022-08-24 05:48:01,370 DEBUG TRAIN Batch 93/2500 loss 38.481941 loss_att 23.149406 loss_ctc 74.257858 loss_ctc_origin 37.827736 loss_ctc0 159.261475 lr 0.00086753 rank 0
2022-08-24 05:48:27,852 DEBUG TRAIN Batch 93/2600 loss 43.610184 loss_att 23.854731 loss_ctc 89.706238 loss_ctc_origin 53.946095 loss_ctc0 173.146576 lr 0.00086745 rank 0
2022-08-24 05:48:55,976 DEBUG TRAIN Batch 93/2700 loss 20.899647 loss_att 12.050673 loss_ctc 41.547256 loss_ctc_origin 31.134388 loss_ctc0 65.843948 lr 0.00086736 rank 0
2022-08-24 05:49:22,263 DEBUG TRAIN Batch 93/2800 loss 21.033089 loss_att 10.558616 loss_ctc 45.473526 loss_ctc_origin 31.120861 loss_ctc0 78.963066 lr 0.00086728 rank 0
2022-08-24 05:49:51,550 DEBUG TRAIN Batch 93/2900 loss 26.203558 loss_att 13.587072 loss_ctc 55.642021 loss_ctc_origin 38.880447 loss_ctc0 94.752357 lr 0.00086720 rank 0
2022-08-24 05:50:24,175 DEBUG TRAIN Batch 93/3000 loss 37.637383 loss_att 20.444990 loss_ctc 77.752960 loss_ctc_origin 41.199013 loss_ctc0 163.045502 lr 0.00086712 rank 0
2022-08-24 05:50:50,512 DEBUG TRAIN Batch 93/3100 loss 48.692631 loss_att 29.319046 loss_ctc 93.897659 loss_ctc_origin 47.748810 loss_ctc0 201.578308 lr 0.00086704 rank 0
2022-08-24 05:51:17,088 DEBUG TRAIN Batch 93/3200 loss 22.033459 loss_att 12.127245 loss_ctc 45.147957 loss_ctc_origin 33.837669 loss_ctc0 71.538620 lr 0.00086696 rank 0
2022-08-24 05:51:44,259 DEBUG TRAIN Batch 93/3300 loss 24.102465 loss_att 11.241837 loss_ctc 54.110596 loss_ctc_origin 40.356445 loss_ctc0 86.203613 lr 0.00086688 rank 0
2022-08-24 05:52:12,602 DEBUG TRAIN Batch 93/3400 loss 23.859051 loss_att 11.484092 loss_ctc 52.733955 loss_ctc_origin 34.314842 loss_ctc0 95.711884 lr 0.00086679 rank 0
2022-08-24 05:52:40,238 DEBUG TRAIN Batch 93/3500 loss 46.973404 loss_att 31.613024 loss_ctc 82.814285 loss_ctc_origin 47.396378 loss_ctc0 165.456055 lr 0.00086671 rank 0
2022-08-24 05:53:07,708 DEBUG TRAIN Batch 93/3600 loss 43.635460 loss_att 24.956154 loss_ctc 87.220505 loss_ctc_origin 48.070133 loss_ctc0 178.571381 lr 0.00086663 rank 0
2022-08-24 05:53:34,038 DEBUG TRAIN Batch 93/3700 loss 23.961903 loss_att 13.315991 loss_ctc 48.802364 loss_ctc_origin 38.729755 loss_ctc0 72.305115 lr 0.00086655 rank 0
2022-08-24 05:54:00,646 DEBUG TRAIN Batch 93/3800 loss 25.735481 loss_att 13.424424 loss_ctc 54.461281 loss_ctc_origin 40.614571 loss_ctc0 86.770264 lr 0.00086647 rank 0
2022-08-24 05:54:23,491 WARNING NaN or Inf found in input tensor.
2022-08-24 05:54:27,681 DEBUG TRAIN Batch 93/3900 loss 29.886845 loss_att 14.394127 loss_ctc 66.036514 loss_ctc_origin 48.729786 loss_ctc0 106.418861 lr 0.00086639 rank 0
2022-08-24 05:54:55,259 DEBUG TRAIN Batch 93/4000 loss 48.392742 loss_att 31.562117 loss_ctc 87.664200 loss_ctc_origin 54.169983 loss_ctc0 165.817368 lr 0.00086631 rank 0
2022-08-24 05:55:23,008 DEBUG TRAIN Batch 93/4100 loss 46.637936 loss_att 26.150581 loss_ctc 94.441757 loss_ctc_origin 52.606495 loss_ctc0 192.057373 lr 0.00086622 rank 0
2022-08-24 05:55:49,646 DEBUG TRAIN Batch 93/4200 loss 21.951927 loss_att 12.239006 loss_ctc 44.615414 loss_ctc_origin 33.659145 loss_ctc0 70.180038 lr 0.00086614 rank 0
2022-08-24 05:56:17,566 DEBUG TRAIN Batch 93/4300 loss 25.194769 loss_att 12.738111 loss_ctc 54.260300 loss_ctc_origin 41.363525 loss_ctc0 84.352768 lr 0.00086606 rank 0
2022-08-24 05:56:43,773 DEBUG TRAIN Batch 93/4400 loss 29.226250 loss_att 15.248390 loss_ctc 61.841248 loss_ctc_origin 46.228970 loss_ctc0 98.269890 lr 0.00086598 rank 0
2022-08-24 05:57:16,325 DEBUG TRAIN Batch 93/4500 loss 40.335499 loss_att 25.542582 loss_ctc 74.852303 loss_ctc_origin 46.974533 loss_ctc0 139.900436 lr 0.00086590 rank 0
2022-08-24 05:57:42,749 DEBUG TRAIN Batch 93/4600 loss 44.163509 loss_att 22.954878 loss_ctc 93.650314 loss_ctc_origin 47.000523 loss_ctc0 202.499832 lr 0.00086582 rank 0
2022-08-24 05:58:09,026 DEBUG TRAIN Batch 93/4700 loss 22.885178 loss_att 14.528238 loss_ctc 42.384705 loss_ctc_origin 31.818916 loss_ctc0 67.038208 lr 0.00086574 rank 0
2022-08-24 05:58:36,408 DEBUG TRAIN Batch 93/4800 loss 25.009539 loss_att 12.065538 loss_ctc 55.212204 loss_ctc_origin 41.000950 loss_ctc0 88.371796 lr 0.00086566 rank 0
2022-08-24 05:59:02,784 DEBUG TRAIN Batch 93/4900 loss 29.515944 loss_att 13.617508 loss_ctc 66.612289 loss_ctc_origin 48.254585 loss_ctc0 109.446915 lr 0.00086558 rank 0
2022-08-24 05:59:30,696 DEBUG TRAIN Batch 93/5000 loss 48.258808 loss_att 29.876156 loss_ctc 91.151657 loss_ctc_origin 53.519840 loss_ctc0 178.959229 lr 0.00086549 rank 0
2022-08-24 05:59:57,105 DEBUG TRAIN Batch 93/5100 loss 48.048820 loss_att 26.900229 loss_ctc 97.395538 loss_ctc_origin 49.141296 loss_ctc0 209.988770 lr 0.00086541 rank 0
2022-08-24 06:00:23,655 DEBUG TRAIN Batch 93/5200 loss 25.410612 loss_att 15.086040 loss_ctc 49.501278 loss_ctc_origin 39.636330 loss_ctc0 72.519493 lr 0.00086533 rank 0
2022-08-24 06:00:50,280 DEBUG TRAIN Batch 93/5300 loss 19.010990 loss_att 8.250225 loss_ctc 44.119438 loss_ctc_origin 29.366774 loss_ctc0 78.542313 lr 0.00086525 rank 0
2022-08-24 06:01:18,206 DEBUG TRAIN Batch 93/5400 loss 26.356359 loss_att 13.049804 loss_ctc 57.404984 loss_ctc_origin 40.056114 loss_ctc0 97.885674 lr 0.00086517 rank 0
2022-08-24 06:01:45,014 DEBUG TRAIN Batch 93/5500 loss 47.155403 loss_att 31.109123 loss_ctc 84.596710 loss_ctc_origin 51.077934 loss_ctc0 162.807159 lr 0.00086509 rank 0
2022-08-24 06:02:12,525 DEBUG TRAIN Batch 93/5600 loss 49.381844 loss_att 30.804426 loss_ctc 92.729141 loss_ctc_origin 61.291809 loss_ctc0 166.082916 lr 0.00086501 rank 0
2022-08-24 06:02:34,605 DEBUG CV Batch 93/0 loss 13.794819 loss_att 10.449336 loss_ctc 21.600943 loss_ctc_origin 15.454524 loss_ctc0 35.942585 history loss 12.983359 rank 0
2022-08-24 06:02:44,674 DEBUG CV Batch 93/100 loss 23.959999 loss_att 17.660517 loss_ctc 38.658791 loss_ctc_origin 26.358948 loss_ctc0 67.358414 history loss 29.465361 rank 0
2022-08-24 06:02:54,003 DEBUG CV Batch 93/200 loss 27.579586 loss_att 21.216619 loss_ctc 42.426506 loss_ctc_origin 32.707130 loss_ctc0 65.105042 history loss 30.978124 rank 0
2022-08-24 06:03:03,385 DEBUG CV Batch 93/300 loss 25.216179 loss_att 19.173901 loss_ctc 39.314827 loss_ctc_origin 23.872913 loss_ctc0 75.345955 history loss 29.966150 rank 0
2022-08-24 06:03:13,429 DEBUG CV Batch 93/400 loss 41.702610 loss_att 34.123734 loss_ctc 59.386650 loss_ctc_origin 42.099087 loss_ctc0 99.724304 history loss 28.193159 rank 0
2022-08-24 06:03:23,759 DEBUG CV Batch 93/500 loss 17.795048 loss_att 13.276869 loss_ctc 28.337465 loss_ctc_origin 21.966263 loss_ctc0 43.203602 history loss 27.751220 rank 0
2022-08-24 06:03:34,207 DEBUG CV Batch 93/600 loss 19.247566 loss_att 13.707817 loss_ctc 32.173653 loss_ctc_origin 21.700006 loss_ctc0 56.612152 history loss 27.519849 rank 0
2022-08-24 06:03:44,491 DEBUG CV Batch 93/700 loss 20.259018 loss_att 14.031120 loss_ctc 34.790775 loss_ctc_origin 21.483795 loss_ctc0 65.840393 history loss 27.156281 rank 0
2022-08-24 06:03:53,471 DEBUG CV Batch 93/800 loss 23.857250 loss_att 18.538780 loss_ctc 36.267014 loss_ctc_origin 21.063133 loss_ctc0 71.742729 history loss 27.092091 rank 0
2022-08-24 06:04:03,096 INFO Epoch 93 CV info cv_loss 27.19762826433499
2022-08-24 06:04:03,096 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/93.pt
2022-08-24 06:04:03,551 INFO Epoch 94 TRAIN info lr 0.0008649405836499729
2022-08-24 06:04:03,554 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 06:04:30,282 DEBUG TRAIN Batch 94/0 loss 49.397644 loss_att 33.767467 loss_ctc 85.868050 loss_ctc_origin 53.635578 loss_ctc0 161.077148 lr 0.00086494 rank 0
2022-08-24 06:04:57,677 DEBUG TRAIN Batch 94/100 loss 45.343342 loss_att 26.391123 loss_ctc 89.565186 loss_ctc_origin 45.527195 loss_ctc0 192.320480 lr 0.00086486 rank 0
2022-08-24 06:05:26,772 DEBUG TRAIN Batch 94/200 loss 23.205730 loss_att 13.530273 loss_ctc 45.781799 loss_ctc_origin 36.726406 loss_ctc0 66.911041 lr 0.00086478 rank 0
2022-08-24 06:05:55,233 DEBUG TRAIN Batch 94/300 loss 22.012594 loss_att 10.776782 loss_ctc 48.229488 loss_ctc_origin 34.889957 loss_ctc0 79.355057 lr 0.00086469 rank 0
2022-08-24 06:06:24,542 DEBUG TRAIN Batch 94/400 loss 28.470036 loss_att 13.531771 loss_ctc 63.325989 loss_ctc_origin 47.378059 loss_ctc0 100.537827 lr 0.00086461 rank 0
2022-08-24 06:06:53,258 DEBUG TRAIN Batch 94/500 loss 43.422604 loss_att 27.588417 loss_ctc 80.369034 loss_ctc_origin 47.966675 loss_ctc0 155.974548 lr 0.00086453 rank 0
2022-08-24 06:07:21,880 DEBUG TRAIN Batch 94/600 loss 37.014801 loss_att 20.937235 loss_ctc 74.529121 loss_ctc_origin 40.839497 loss_ctc0 153.138245 lr 0.00086445 rank 0
2022-08-24 06:07:49,947 DEBUG TRAIN Batch 94/700 loss 26.314651 loss_att 15.178121 loss_ctc 52.299889 loss_ctc_origin 43.393444 loss_ctc0 73.081589 lr 0.00086437 rank 0
2022-08-24 06:08:19,362 DEBUG TRAIN Batch 94/800 loss 25.252850 loss_att 12.201313 loss_ctc 55.706432 loss_ctc_origin 41.228611 loss_ctc0 89.488014 lr 0.00086429 rank 0
2022-08-24 06:08:47,734 DEBUG TRAIN Batch 94/900 loss 27.796926 loss_att 13.770517 loss_ctc 60.525211 loss_ctc_origin 44.466663 loss_ctc0 97.995155 lr 0.00086421 rank 0
2022-08-24 06:09:19,650 DEBUG TRAIN Batch 94/1000 loss 42.403854 loss_att 26.530663 loss_ctc 79.441307 loss_ctc_origin 46.444122 loss_ctc0 156.434738 lr 0.00086413 rank 0
2022-08-24 06:09:33,891 WARNING NaN or Inf found in input tensor.
2022-08-24 06:09:47,935 DEBUG TRAIN Batch 94/1100 loss 50.787895 loss_att 29.179836 loss_ctc 101.206703 loss_ctc_origin 53.493332 loss_ctc0 212.537903 lr 0.00086405 rank 0
2022-08-24 06:10:15,906 DEBUG TRAIN Batch 94/1200 loss 22.380981 loss_att 12.964704 loss_ctc 44.352291 loss_ctc_origin 32.633472 loss_ctc0 71.696205 lr 0.00086397 rank 0
2022-08-24 06:10:43,035 DEBUG TRAIN Batch 94/1300 loss 24.777939 loss_att 11.756064 loss_ctc 55.162315 loss_ctc_origin 41.209900 loss_ctc0 87.717957 lr 0.00086389 rank 0
2022-08-24 06:11:09,553 DEBUG TRAIN Batch 94/1400 loss 28.649223 loss_att 14.321642 loss_ctc 62.080238 loss_ctc_origin 45.398323 loss_ctc0 101.004707 lr 0.00086381 rank 0
2022-08-24 06:11:42,771 DEBUG TRAIN Batch 94/1500 loss 26.351856 loss_att 18.344604 loss_ctc 45.035442 loss_ctc_origin 32.245979 loss_ctc0 74.877518 lr 0.00086373 rank 0
2022-08-24 06:12:10,376 DEBUG TRAIN Batch 94/1600 loss 38.496994 loss_att 22.847509 loss_ctc 75.012459 loss_ctc_origin 44.848103 loss_ctc0 145.395966 lr 0.00086365 rank 0
2022-08-24 06:12:37,930 DEBUG TRAIN Batch 94/1700 loss 23.388638 loss_att 13.452229 loss_ctc 46.573586 loss_ctc_origin 36.868095 loss_ctc0 69.219727 lr 0.00086357 rank 0
2022-08-24 06:13:05,408 DEBUG TRAIN Batch 94/1800 loss 20.881781 loss_att 9.685873 loss_ctc 47.005562 loss_ctc_origin 34.498566 loss_ctc0 76.188545 lr 0.00086349 rank 0
2022-08-24 06:13:32,866 DEBUG TRAIN Batch 94/1900 loss 26.206684 loss_att 13.204102 loss_ctc 56.546043 loss_ctc_origin 41.064690 loss_ctc0 92.669205 lr 0.00086340 rank 0
2022-08-24 06:14:01,356 DEBUG TRAIN Batch 94/2000 loss 45.814304 loss_att 31.141592 loss_ctc 80.050629 loss_ctc_origin 49.134705 loss_ctc0 152.187775 lr 0.00086332 rank 0
2022-08-24 06:14:29,788 DEBUG TRAIN Batch 94/2100 loss 48.229431 loss_att 29.494129 loss_ctc 91.945145 loss_ctc_origin 54.074432 loss_ctc0 180.310135 lr 0.00086324 rank 0
2022-08-24 06:14:57,319 DEBUG TRAIN Batch 94/2200 loss 26.156454 loss_att 16.185072 loss_ctc 49.423012 loss_ctc_origin 39.809715 loss_ctc0 71.854034 lr 0.00086316 rank 0
2022-08-24 06:15:26,187 DEBUG TRAIN Batch 94/2300 loss 24.661766 loss_att 12.072773 loss_ctc 54.036079 loss_ctc_origin 41.280930 loss_ctc0 83.798096 lr 0.00086308 rank 0
2022-08-24 06:15:54,333 DEBUG TRAIN Batch 94/2400 loss 23.758865 loss_att 10.916401 loss_ctc 53.724609 loss_ctc_origin 35.787842 loss_ctc0 95.577057 lr 0.00086300 rank 0
2022-08-24 06:16:22,849 DEBUG TRAIN Batch 94/2500 loss 43.210770 loss_att 30.815607 loss_ctc 72.132812 loss_ctc_origin 43.773392 loss_ctc0 138.304794 lr 0.00086292 rank 0
2022-08-24 06:16:51,545 DEBUG TRAIN Batch 94/2600 loss 46.319290 loss_att 26.069939 loss_ctc 93.567780 loss_ctc_origin 51.417881 loss_ctc0 191.917526 lr 0.00086284 rank 0
2022-08-24 06:17:19,777 DEBUG TRAIN Batch 94/2700 loss 24.040415 loss_att 14.426249 loss_ctc 46.473469 loss_ctc_origin 36.448082 loss_ctc0 69.866035 lr 0.00086276 rank 0
2022-08-24 06:17:49,946 DEBUG TRAIN Batch 94/2800 loss 24.159855 loss_att 11.825932 loss_ctc 52.939007 loss_ctc_origin 41.343327 loss_ctc0 79.995590 lr 0.00086268 rank 0
2022-08-24 06:18:15,091 DEBUG TRAIN Batch 94/2900 loss 26.706459 loss_att 12.502432 loss_ctc 59.849182 loss_ctc_origin 44.291580 loss_ctc0 96.150253 lr 0.00086260 rank 0
2022-08-24 06:18:50,426 DEBUG TRAIN Batch 94/3000 loss 45.326759 loss_att 25.230495 loss_ctc 92.218048 loss_ctc_origin 45.277431 loss_ctc0 201.746140 lr 0.00086252 rank 0
2022-08-24 06:19:19,220 DEBUG TRAIN Batch 94/3100 loss 48.265793 loss_att 25.317036 loss_ctc 101.812897 loss_ctc_origin 50.411549 loss_ctc0 221.749374 lr 0.00086244 rank 0
2022-08-24 06:19:49,095 DEBUG TRAIN Batch 94/3200 loss 23.254913 loss_att 12.115398 loss_ctc 49.247112 loss_ctc_origin 37.666946 loss_ctc0 76.267502 lr 0.00086236 rank 0
2022-08-24 06:20:16,756 DEBUG TRAIN Batch 94/3300 loss 23.224602 loss_att 12.451258 loss_ctc 48.362400 loss_ctc_origin 36.978695 loss_ctc0 74.924377 lr 0.00086228 rank 0
2022-08-24 06:20:43,382 DEBUG TRAIN Batch 94/3400 loss 23.170124 loss_att 10.755123 loss_ctc 52.138458 loss_ctc_origin 34.475578 loss_ctc0 93.351852 lr 0.00086220 rank 0
2022-08-24 06:21:11,485 DEBUG TRAIN Batch 94/3500 loss 41.471817 loss_att 26.161293 loss_ctc 77.196381 loss_ctc_origin 40.796146 loss_ctc0 162.130249 lr 0.00086212 rank 0
2022-08-24 06:21:38,932 DEBUG TRAIN Batch 94/3600 loss 44.776413 loss_att 26.092136 loss_ctc 88.373047 loss_ctc_origin 52.456894 loss_ctc0 172.177399 lr 0.00086204 rank 0
2022-08-24 06:22:06,209 DEBUG TRAIN Batch 94/3700 loss 19.628548 loss_att 11.907204 loss_ctc 37.645016 loss_ctc_origin 26.703876 loss_ctc0 63.174339 lr 0.00086196 rank 0
2022-08-24 06:22:33,780 DEBUG TRAIN Batch 94/3800 loss 22.460306 loss_att 10.689345 loss_ctc 49.925880 loss_ctc_origin 35.910019 loss_ctc0 82.629555 lr 0.00086188 rank 0
2022-08-24 06:23:01,026 DEBUG TRAIN Batch 94/3900 loss 29.853212 loss_att 14.969060 loss_ctc 64.582901 loss_ctc_origin 49.214893 loss_ctc0 100.441589 lr 0.00086180 rank 0
2022-08-24 06:23:29,839 DEBUG TRAIN Batch 94/4000 loss 40.890167 loss_att 26.985180 loss_ctc 73.335136 loss_ctc_origin 39.799576 loss_ctc0 151.584778 lr 0.00086172 rank 0
2022-08-24 06:23:57,554 DEBUG TRAIN Batch 94/4100 loss 53.727566 loss_att 30.512108 loss_ctc 107.896965 loss_ctc_origin 64.304878 loss_ctc0 209.611832 lr 0.00086164 rank 0
2022-08-24 06:24:25,949 DEBUG TRAIN Batch 94/4200 loss 20.606035 loss_att 11.809280 loss_ctc 41.131798 loss_ctc_origin 29.518543 loss_ctc0 68.229401 lr 0.00086156 rank 0
2022-08-24 06:24:53,634 DEBUG TRAIN Batch 94/4300 loss 24.316824 loss_att 13.074211 loss_ctc 50.549583 loss_ctc_origin 38.829773 loss_ctc0 77.895798 lr 0.00086148 rank 0
2022-08-24 06:25:21,746 DEBUG TRAIN Batch 94/4400 loss 25.639439 loss_att 11.776234 loss_ctc 57.986916 loss_ctc_origin 40.003742 loss_ctc0 99.947647 lr 0.00086140 rank 0
2022-08-24 06:25:54,134 DEBUG TRAIN Batch 94/4500 loss 49.408997 loss_att 31.182747 loss_ctc 91.936905 loss_ctc_origin 57.191826 loss_ctc0 173.008728 lr 0.00086132 rank 0
2022-08-24 06:25:54,887 WARNING NaN or Inf found in input tensor.
2022-08-24 06:26:22,572 DEBUG TRAIN Batch 94/4600 loss 50.439323 loss_att 28.247471 loss_ctc 102.220306 loss_ctc_origin 56.137657 loss_ctc0 209.746490 lr 0.00086124 rank 0
2022-08-24 06:26:50,309 DEBUG TRAIN Batch 94/4700 loss 19.926172 loss_att 10.927851 loss_ctc 40.922253 loss_ctc_origin 31.012529 loss_ctc0 64.044937 lr 0.00086116 rank 0
2022-08-24 06:27:03,306 WARNING NaN or Inf found in input tensor.
2022-08-24 06:27:18,145 DEBUG TRAIN Batch 94/4800 loss 23.698997 loss_att 11.168765 loss_ctc 52.936207 loss_ctc_origin 38.905533 loss_ctc0 85.674438 lr 0.00086108 rank 0
2022-08-24 06:27:46,649 DEBUG TRAIN Batch 94/4900 loss 23.690687 loss_att 10.814770 loss_ctc 53.734493 loss_ctc_origin 36.805031 loss_ctc0 93.236572 lr 0.00086100 rank 0
2022-08-24 06:27:49,393 WARNING NaN or Inf found in input tensor.
2022-08-24 06:28:14,877 DEBUG TRAIN Batch 94/5000 loss 28.386139 loss_att 17.846565 loss_ctc 52.978474 loss_ctc_origin 27.415020 loss_ctc0 112.626526 lr 0.00086092 rank 0
2022-08-24 06:28:43,036 DEBUG TRAIN Batch 94/5100 loss 48.551872 loss_att 30.164120 loss_ctc 91.456619 loss_ctc_origin 50.954571 loss_ctc0 185.961411 lr 0.00086084 rank 0
2022-08-24 06:29:12,856 DEBUG TRAIN Batch 94/5200 loss 24.500370 loss_att 13.530630 loss_ctc 50.096428 loss_ctc_origin 41.244591 loss_ctc0 70.750702 lr 0.00086076 rank 0
2022-08-24 06:29:40,503 DEBUG TRAIN Batch 94/5300 loss 24.708141 loss_att 11.820912 loss_ctc 54.778347 loss_ctc_origin 41.925949 loss_ctc0 84.767273 lr 0.00086068 rank 0
2022-08-24 06:30:08,804 DEBUG TRAIN Batch 94/5400 loss 22.788698 loss_att 10.371658 loss_ctc 51.761791 loss_ctc_origin 35.216045 loss_ctc0 90.368530 lr 0.00086060 rank 0
2022-08-24 06:30:36,229 DEBUG TRAIN Batch 94/5500 loss 41.968452 loss_att 27.513590 loss_ctc 75.696457 loss_ctc_origin 47.746925 loss_ctc0 140.912033 lr 0.00086052 rank 0
2022-08-24 06:31:03,448 DEBUG TRAIN Batch 94/5600 loss 53.054932 loss_att 28.402065 loss_ctc 110.578278 loss_ctc_origin 56.578400 loss_ctc0 236.577972 lr 0.00086044 rank 0
2022-08-24 06:31:25,452 DEBUG CV Batch 94/0 loss 13.642866 loss_att 10.329123 loss_ctc 21.374935 loss_ctc_origin 15.711487 loss_ctc0 34.589645 history loss 12.840345 rank 0
2022-08-24 06:31:36,181 DEBUG CV Batch 94/100 loss 23.238949 loss_att 18.472698 loss_ctc 34.360203 loss_ctc_origin 25.258228 loss_ctc0 55.598145 history loss 28.500774 rank 0
2022-08-24 06:31:45,766 DEBUG CV Batch 94/200 loss 26.183720 loss_att 20.112480 loss_ctc 40.349941 loss_ctc_origin 30.407207 loss_ctc0 63.549648 history loss 29.914527 rank 0
2022-08-24 06:31:55,712 DEBUG CV Batch 94/300 loss 25.003817 loss_att 18.921986 loss_ctc 39.194756 loss_ctc_origin 23.948189 loss_ctc0 74.770088 history loss 28.971421 rank 0
2022-08-24 06:32:05,839 DEBUG CV Batch 94/400 loss 40.700584 loss_att 33.579674 loss_ctc 57.316048 loss_ctc_origin 40.124985 loss_ctc0 97.428528 history loss 27.281027 rank 0
2022-08-24 06:32:16,103 DEBUG CV Batch 94/500 loss 17.339863 loss_att 13.150163 loss_ctc 27.115833 loss_ctc_origin 20.219006 loss_ctc0 43.208431 history loss 26.903754 rank 0
2022-08-24 06:32:26,375 DEBUG CV Batch 94/600 loss 19.106001 loss_att 13.374390 loss_ctc 32.479759 loss_ctc_origin 22.391245 loss_ctc0 56.019619 history loss 26.665300 rank 0
2022-08-24 06:32:35,878 DEBUG CV Batch 94/700 loss 19.583860 loss_att 13.096642 loss_ctc 34.720703 loss_ctc_origin 21.553711 loss_ctc0 65.443680 history loss 26.315877 rank 0
2022-08-24 06:32:46,176 DEBUG CV Batch 94/800 loss 22.882450 loss_att 17.473980 loss_ctc 35.502209 loss_ctc_origin 20.214376 loss_ctc0 71.173820 history loss 26.233067 rank 0
2022-08-24 06:32:57,113 INFO Epoch 94 CV info cv_loss 26.32128521718291
2022-08-24 06:32:57,114 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/94.pt
2022-08-24 06:32:57,599 INFO Epoch 95 TRAIN info lr 0.0008603762215327789
2022-08-24 06:32:57,603 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 06:33:23,795 DEBUG TRAIN Batch 95/0 loss 44.171066 loss_att 28.717388 loss_ctc 80.229652 loss_ctc_origin 49.282173 loss_ctc0 152.440430 lr 0.00086037 rank 0
2022-08-24 06:33:52,277 DEBUG TRAIN Batch 95/100 loss 49.749229 loss_att 29.662642 loss_ctc 96.617935 loss_ctc_origin 56.362167 loss_ctc0 190.548035 lr 0.00086029 rank 0
2022-08-24 06:34:17,627 WARNING NaN or Inf found in input tensor.
2022-08-24 06:34:19,147 DEBUG TRAIN Batch 95/200 loss 25.558966 loss_att 14.169834 loss_ctc 52.133606 loss_ctc_origin 43.500954 loss_ctc0 72.276459 lr 0.00086021 rank 0
2022-08-24 06:34:47,139 DEBUG TRAIN Batch 95/300 loss 22.098873 loss_att 10.336798 loss_ctc 49.543713 loss_ctc_origin 35.390469 loss_ctc0 82.567947 lr 0.00086013 rank 0
2022-08-24 06:35:13,440 DEBUG TRAIN Batch 95/400 loss 19.661221 loss_att 8.267806 loss_ctc 46.245853 loss_ctc_origin 27.496847 loss_ctc0 89.993530 lr 0.00086005 rank 0
2022-08-24 06:35:41,649 DEBUG TRAIN Batch 95/500 loss 48.688766 loss_att 29.589445 loss_ctc 93.253845 loss_ctc_origin 55.075768 loss_ctc0 182.336029 lr 0.00085998 rank 0
2022-08-24 06:36:09,639 DEBUG TRAIN Batch 95/600 loss 49.209320 loss_att 26.877914 loss_ctc 101.315933 loss_ctc_origin 54.658615 loss_ctc0 210.183014 lr 0.00085990 rank 0
2022-08-24 06:36:36,807 DEBUG TRAIN Batch 95/700 loss 23.022858 loss_att 13.015829 loss_ctc 46.372589 loss_ctc_origin 36.767151 loss_ctc0 68.785278 lr 0.00085982 rank 0
2022-08-24 06:37:04,991 DEBUG TRAIN Batch 95/800 loss 21.704237 loss_att 10.950003 loss_ctc 46.797447 loss_ctc_origin 34.210850 loss_ctc0 76.166168 lr 0.00085974 rank 0
2022-08-24 06:37:28,663 WARNING NaN or Inf found in input tensor.
2022-08-24 06:37:33,221 DEBUG TRAIN Batch 95/900 loss 24.094208 loss_att 11.252676 loss_ctc 54.057777 loss_ctc_origin 36.046703 loss_ctc0 96.083603 lr 0.00085966 rank 0
2022-08-24 06:38:00,856 DEBUG TRAIN Batch 95/1000 loss 41.541492 loss_att 25.118294 loss_ctc 79.862289 loss_ctc_origin 46.983715 loss_ctc0 156.578979 lr 0.00085958 rank 0
2022-08-24 06:38:29,273 DEBUG TRAIN Batch 95/1100 loss 46.504692 loss_att 27.730543 loss_ctc 90.311035 loss_ctc_origin 46.071724 loss_ctc0 193.536087 lr 0.00085950 rank 0
2022-08-24 06:38:54,346 DEBUG TRAIN Batch 95/1200 loss 21.857517 loss_att 12.242035 loss_ctc 44.293636 loss_ctc_origin 35.708656 loss_ctc0 64.325256 lr 0.00085942 rank 0
2022-08-24 06:39:21,885 DEBUG TRAIN Batch 95/1300 loss 22.311226 loss_att 10.976620 loss_ctc 48.758640 loss_ctc_origin 34.875439 loss_ctc0 81.152771 lr 0.00085934 rank 0
2022-08-24 06:39:49,799 DEBUG TRAIN Batch 95/1400 loss 23.171387 loss_att 10.369027 loss_ctc 53.043556 loss_ctc_origin 35.486870 loss_ctc0 94.009155 lr 0.00085926 rank 0
2022-08-24 06:40:22,013 DEBUG TRAIN Batch 95/1500 loss 52.367546 loss_att 35.698524 loss_ctc 91.261932 loss_ctc_origin 57.211098 loss_ctc0 170.713867 lr 0.00085918 rank 0
2022-08-24 06:40:49,211 DEBUG TRAIN Batch 95/1600 loss 50.128792 loss_att 26.758873 loss_ctc 104.658592 loss_ctc_origin 54.497803 loss_ctc0 221.700439 lr 0.00085910 rank 0
2022-08-24 06:41:16,816 DEBUG TRAIN Batch 95/1700 loss 24.718000 loss_att 12.984632 loss_ctc 52.095856 loss_ctc_origin 42.343399 loss_ctc0 74.851578 lr 0.00085902 rank 0
2022-08-24 06:41:44,082 DEBUG TRAIN Batch 95/1800 loss 21.720505 loss_att 10.046834 loss_ctc 48.959064 loss_ctc_origin 35.089088 loss_ctc0 81.322342 lr 0.00085894 rank 0
2022-08-24 06:42:11,456 DEBUG TRAIN Batch 95/1900 loss 23.109360 loss_att 9.103271 loss_ctc 55.790234 loss_ctc_origin 38.024864 loss_ctc0 97.242760 lr 0.00085886 rank 0
2022-08-24 06:42:39,397 DEBUG TRAIN Batch 95/2000 loss 42.533653 loss_att 26.990381 loss_ctc 78.801285 loss_ctc_origin 41.305847 loss_ctc0 166.290619 lr 0.00085879 rank 0
2022-08-24 06:43:04,902 WARNING NaN or Inf found in input tensor.
2022-08-24 06:43:05,658 DEBUG TRAIN Batch 95/2100 loss 61.386269 loss_att 38.202118 loss_ctc 115.482620 loss_ctc_origin 77.106277 loss_ctc0 205.027435 lr 0.00085871 rank 0
2022-08-24 06:43:32,746 DEBUG TRAIN Batch 95/2200 loss 22.216871 loss_att 11.677414 loss_ctc 46.808937 loss_ctc_origin 35.405510 loss_ctc0 73.416924 lr 0.00085863 rank 0
2022-08-24 06:44:00,842 DEBUG TRAIN Batch 95/2300 loss 21.968517 loss_att 9.879335 loss_ctc 50.176609 loss_ctc_origin 35.487610 loss_ctc0 84.450943 lr 0.00085855 rank 0
2022-08-24 06:44:29,068 DEBUG TRAIN Batch 95/2400 loss 25.280304 loss_att 11.308174 loss_ctc 57.881935 loss_ctc_origin 41.600227 loss_ctc0 95.872574 lr 0.00085847 rank 0
2022-08-24 06:44:56,348 DEBUG TRAIN Batch 95/2500 loss 44.520317 loss_att 29.115688 loss_ctc 80.464447 loss_ctc_origin 46.569115 loss_ctc0 159.553558 lr 0.00085839 rank 0
2022-08-24 06:45:24,493 DEBUG TRAIN Batch 95/2600 loss 52.330383 loss_att 32.926956 loss_ctc 97.605042 loss_ctc_origin 62.088814 loss_ctc0 180.476227 lr 0.00085831 rank 0
2022-08-24 06:45:51,467 DEBUG TRAIN Batch 95/2700 loss 25.476837 loss_att 13.003384 loss_ctc 54.581558 loss_ctc_origin 43.817501 loss_ctc0 79.697693 lr 0.00085823 rank 0
2022-08-24 06:46:19,542 DEBUG TRAIN Batch 95/2800 loss 21.896976 loss_att 9.592247 loss_ctc 50.608006 loss_ctc_origin 36.723133 loss_ctc0 83.006042 lr 0.00085815 rank 0
2022-08-24 06:46:47,277 DEBUG TRAIN Batch 95/2900 loss 23.557346 loss_att 9.906903 loss_ctc 55.408379 loss_ctc_origin 38.630093 loss_ctc0 94.557709 lr 0.00085807 rank 0
2022-08-24 06:47:18,509 DEBUG TRAIN Batch 95/3000 loss 45.507271 loss_att 29.138271 loss_ctc 83.701599 loss_ctc_origin 53.432011 loss_ctc0 154.330612 lr 0.00085799 rank 0
2022-08-24 06:47:45,643 DEBUG TRAIN Batch 95/3100 loss 52.022423 loss_att 31.079964 loss_ctc 100.888153 loss_ctc_origin 58.205448 loss_ctc0 200.481140 lr 0.00085792 rank 0
2022-08-24 06:48:12,351 DEBUG TRAIN Batch 95/3200 loss 24.928812 loss_att 15.822372 loss_ctc 46.177170 loss_ctc_origin 37.210609 loss_ctc0 67.099152 lr 0.00085784 rank 0
2022-08-24 06:48:25,256 WARNING NaN or Inf found in input tensor.
2022-08-24 06:48:39,940 DEBUG TRAIN Batch 95/3300 loss 27.683128 loss_att 13.153206 loss_ctc 61.586273 loss_ctc_origin 51.010315 loss_ctc0 86.263512 lr 0.00085776 rank 0
2022-08-24 06:49:07,655 DEBUG TRAIN Batch 95/3400 loss 26.396004 loss_att 11.981262 loss_ctc 60.030403 loss_ctc_origin 43.977444 loss_ctc0 97.487305 lr 0.00085768 rank 0
2022-08-24 06:49:35,340 DEBUG TRAIN Batch 95/3500 loss 38.179108 loss_att 25.381069 loss_ctc 68.041199 loss_ctc_origin 40.612862 loss_ctc0 132.040649 lr 0.00085760 rank 0
2022-08-24 06:50:02,611 DEBUG TRAIN Batch 95/3600 loss 51.259804 loss_att 31.734577 loss_ctc 96.818665 loss_ctc_origin 60.692093 loss_ctc0 181.114014 lr 0.00085752 rank 0
2022-08-24 06:50:29,196 DEBUG TRAIN Batch 95/3700 loss 23.733059 loss_att 14.764469 loss_ctc 44.659767 loss_ctc_origin 33.986473 loss_ctc0 69.564117 lr 0.00085744 rank 0
2022-08-24 06:50:55,710 DEBUG TRAIN Batch 95/3800 loss 21.370066 loss_att 9.945845 loss_ctc 48.026581 loss_ctc_origin 34.806747 loss_ctc0 78.872849 lr 0.00085736 rank 0
2022-08-24 06:51:24,669 DEBUG TRAIN Batch 95/3900 loss 24.852894 loss_att 12.066048 loss_ctc 54.688862 loss_ctc_origin 37.805573 loss_ctc0 94.083206 lr 0.00085728 rank 0
2022-08-24 06:51:52,322 DEBUG TRAIN Batch 95/4000 loss 37.929443 loss_att 24.880835 loss_ctc 68.376198 loss_ctc_origin 41.556568 loss_ctc0 130.955322 lr 0.00085721 rank 0
2022-08-24 06:52:18,352 DEBUG TRAIN Batch 95/4100 loss 47.978180 loss_att 30.706690 loss_ctc 88.278313 loss_ctc_origin 55.616169 loss_ctc0 164.489975 lr 0.00085713 rank 0
2022-08-24 06:52:45,504 DEBUG TRAIN Batch 95/4200 loss 22.807842 loss_att 13.043522 loss_ctc 45.591255 loss_ctc_origin 34.594261 loss_ctc0 71.250916 lr 0.00085705 rank 0
2022-08-24 06:53:12,495 DEBUG TRAIN Batch 95/4300 loss 23.167820 loss_att 10.492124 loss_ctc 52.744442 loss_ctc_origin 38.894848 loss_ctc0 85.060158 lr 0.00085697 rank 0
2022-08-24 06:53:36,125 WARNING NaN or Inf found in input tensor.
2022-08-24 06:53:40,875 DEBUG TRAIN Batch 95/4400 loss 26.569139 loss_att 13.196278 loss_ctc 57.772484 loss_ctc_origin 42.545815 loss_ctc0 93.301376 lr 0.00085689 rank 0
2022-08-24 06:54:12,465 DEBUG TRAIN Batch 95/4500 loss 40.988564 loss_att 29.721981 loss_ctc 67.277252 loss_ctc_origin 47.353355 loss_ctc0 113.766342 lr 0.00085681 rank 0
2022-08-24 06:54:39,384 DEBUG TRAIN Batch 95/4600 loss 51.885963 loss_att 32.861454 loss_ctc 96.276482 loss_ctc_origin 58.379250 loss_ctc0 184.703354 lr 0.00085673 rank 0
2022-08-24 06:55:06,567 DEBUG TRAIN Batch 95/4700 loss 20.379223 loss_att 11.083420 loss_ctc 42.069427 loss_ctc_origin 30.911400 loss_ctc0 68.104828 lr 0.00085666 rank 0
2022-08-24 06:55:33,937 DEBUG TRAIN Batch 95/4800 loss 23.802145 loss_att 11.507954 loss_ctc 52.488590 loss_ctc_origin 38.920467 loss_ctc0 84.147537 lr 0.00085658 rank 0
2022-08-24 06:56:01,108 DEBUG TRAIN Batch 95/4900 loss 24.047808 loss_att 10.991570 loss_ctc 54.512360 loss_ctc_origin 35.142128 loss_ctc0 99.709564 lr 0.00085650 rank 0
2022-08-24 06:56:28,756 DEBUG TRAIN Batch 95/5000 loss 29.947395 loss_att 20.841967 loss_ctc 51.193398 loss_ctc_origin 35.291718 loss_ctc0 88.297318 lr 0.00085642 rank 0
2022-08-24 06:56:55,370 DEBUG TRAIN Batch 95/5100 loss 51.429340 loss_att 32.945072 loss_ctc 94.559296 loss_ctc_origin 65.741142 loss_ctc0 161.801636 lr 0.00085634 rank 0
2022-08-24 06:57:22,618 DEBUG TRAIN Batch 95/5200 loss 23.680145 loss_att 12.695215 loss_ctc 49.311649 loss_ctc_origin 38.443501 loss_ctc0 74.670662 lr 0.00085626 rank 0
2022-08-24 06:57:49,029 DEBUG TRAIN Batch 95/5300 loss 25.817406 loss_att 12.735306 loss_ctc 56.342308 loss_ctc_origin 44.440372 loss_ctc0 84.113495 lr 0.00085618 rank 0
2022-08-24 06:58:11,882 WARNING NaN or Inf found in input tensor.
2022-08-24 06:58:16,398 DEBUG TRAIN Batch 95/5400 loss 25.230797 loss_att 11.496232 loss_ctc 57.278114 loss_ctc_origin 40.748375 loss_ctc0 95.847504 lr 0.00085611 rank 0
2022-08-24 06:58:44,504 DEBUG TRAIN Batch 95/5500 loss 34.934906 loss_att 23.041874 loss_ctc 62.685310 loss_ctc_origin 41.578388 loss_ctc0 111.934799 lr 0.00085603 rank 0
2022-08-24 06:58:56,462 WARNING NaN or Inf found in input tensor.
2022-08-24 06:59:10,472 DEBUG TRAIN Batch 95/5600 loss 48.944126 loss_att 33.676323 loss_ctc 84.569000 loss_ctc_origin 59.755913 loss_ctc0 142.466202 lr 0.00085595 rank 0
2022-08-24 06:59:33,899 DEBUG CV Batch 95/0 loss 16.584042 loss_att 12.035576 loss_ctc 27.197124 loss_ctc_origin 19.365730 loss_ctc0 45.470375 history loss 15.608510 rank 0
2022-08-24 06:59:43,878 DEBUG CV Batch 95/100 loss 26.281315 loss_att 19.614258 loss_ctc 41.837776 loss_ctc_origin 27.862976 loss_ctc0 74.445633 history loss 29.117820 rank 0
2022-08-24 06:59:53,014 DEBUG CV Batch 95/200 loss 29.332085 loss_att 22.009827 loss_ctc 46.417351 loss_ctc_origin 34.486908 loss_ctc0 74.255051 history loss 30.704603 rank 0
2022-08-24 07:00:02,734 DEBUG CV Batch 95/300 loss 24.046825 loss_att 18.030222 loss_ctc 38.085564 loss_ctc_origin 22.269148 loss_ctc0 74.990532 history loss 29.713468 rank 0
2022-08-24 07:00:12,125 DEBUG CV Batch 95/400 loss 38.727787 loss_att 31.608433 loss_ctc 55.339615 loss_ctc_origin 37.294907 loss_ctc0 97.443924 history loss 28.000738 rank 0
2022-08-24 07:00:21,563 DEBUG CV Batch 95/500 loss 23.809105 loss_att 17.361980 loss_ctc 38.852398 loss_ctc_origin 28.751163 loss_ctc0 62.421940 history loss 27.637461 rank 0
2022-08-24 07:00:31,594 DEBUG CV Batch 95/600 loss 23.780058 loss_att 15.826685 loss_ctc 42.337929 loss_ctc_origin 27.179596 loss_ctc0 77.707367 history loss 27.550921 rank 0
2022-08-24 07:00:41,097 DEBUG CV Batch 95/700 loss 19.574791 loss_att 12.914381 loss_ctc 35.115749 loss_ctc_origin 22.083981 loss_ctc0 65.523209 history loss 27.206814 rank 0
2022-08-24 07:00:50,725 DEBUG CV Batch 95/800 loss 22.688820 loss_att 17.664486 loss_ctc 34.412270 loss_ctc_origin 19.131765 loss_ctc0 70.066772 history loss 27.141682 rank 0
2022-08-24 07:01:00,870 INFO Epoch 95 CV info cv_loss 27.155728143449853
2022-08-24 07:01:00,870 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/95.pt
2022-08-24 07:01:01,330 INFO Epoch 96 TRAIN info lr 0.0008558833646018344
2022-08-24 07:01:01,334 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 07:01:28,526 DEBUG TRAIN Batch 96/0 loss 37.333122 loss_att 26.914642 loss_ctc 61.642899 loss_ctc_origin 45.986542 loss_ctc0 98.174393 lr 0.00085588 rank 0
2022-08-24 07:01:57,049 DEBUG TRAIN Batch 96/100 loss 49.939125 loss_att 34.883537 loss_ctc 85.068817 loss_ctc_origin 60.786091 loss_ctc0 141.728500 lr 0.00085580 rank 0
2022-08-24 07:02:24,661 DEBUG TRAIN Batch 96/200 loss 22.635437 loss_att 14.049312 loss_ctc 42.669731 loss_ctc_origin 32.247627 loss_ctc0 66.987968 lr 0.00085572 rank 0
2022-08-24 07:02:53,160 DEBUG TRAIN Batch 96/300 loss 23.172289 loss_att 10.009044 loss_ctc 53.886528 loss_ctc_origin 40.224579 loss_ctc0 85.764404 lr 0.00085565 rank 0
2022-08-24 07:03:22,025 DEBUG TRAIN Batch 96/400 loss 24.950150 loss_att 10.899478 loss_ctc 57.735046 loss_ctc_origin 40.527111 loss_ctc0 97.886887 lr 0.00085557 rank 0
2022-08-24 07:03:51,516 DEBUG TRAIN Batch 96/500 loss 38.979752 loss_att 27.100458 loss_ctc 66.698097 loss_ctc_origin 52.160858 loss_ctc0 100.618317 lr 0.00085549 rank 0
2022-08-24 07:04:19,855 DEBUG TRAIN Batch 96/600 loss 41.965790 loss_att 25.915817 loss_ctc 79.415718 loss_ctc_origin 54.828087 loss_ctc0 136.786850 lr 0.00085541 rank 0
2022-08-24 07:04:48,753 DEBUG TRAIN Batch 96/700 loss 24.707001 loss_att 15.389503 loss_ctc 46.447823 loss_ctc_origin 35.601952 loss_ctc0 71.754852 lr 0.00085533 rank 0
2022-08-24 07:04:54,137 WARNING NaN or Inf found in input tensor.
2022-08-24 07:05:18,225 DEBUG TRAIN Batch 96/800 loss 24.400787 loss_att 12.720308 loss_ctc 51.655239 loss_ctc_origin 39.332333 loss_ctc0 80.408684 lr 0.00085525 rank 0
2022-08-24 07:05:46,907 DEBUG TRAIN Batch 96/900 loss 23.722481 loss_att 10.977903 loss_ctc 53.459827 loss_ctc_origin 37.054821 loss_ctc0 91.738174 lr 0.00085518 rank 0
2022-08-24 07:06:16,738 DEBUG TRAIN Batch 96/1000 loss 33.833462 loss_att 24.487644 loss_ctc 55.640373 loss_ctc_origin 37.879120 loss_ctc0 97.083298 lr 0.00085510 rank 0
2022-08-24 07:06:45,352 DEBUG TRAIN Batch 96/1100 loss 54.912483 loss_att 37.047195 loss_ctc 96.598145 loss_ctc_origin 74.092606 loss_ctc0 149.111084 lr 0.00085502 rank 0
2022-08-24 07:07:14,151 DEBUG TRAIN Batch 96/1200 loss 24.547810 loss_att 13.835897 loss_ctc 49.542267 loss_ctc_origin 38.924812 loss_ctc0 74.316330 lr 0.00085494 rank 0
2022-08-24 07:07:33,214 WARNING NaN or Inf found in input tensor.
2022-08-24 07:07:43,046 DEBUG TRAIN Batch 96/1300 loss 23.833538 loss_att 11.043638 loss_ctc 53.676636 loss_ctc_origin 39.924919 loss_ctc0 85.763969 lr 0.00085486 rank 0
2022-08-24 07:08:12,206 DEBUG TRAIN Batch 96/1400 loss 27.365715 loss_att 12.259581 loss_ctc 62.613361 loss_ctc_origin 45.379723 loss_ctc0 102.825180 lr 0.00085479 rank 0
2022-08-24 07:08:46,108 DEBUG TRAIN Batch 96/1500 loss 42.650791 loss_att 28.823387 loss_ctc 74.914734 loss_ctc_origin 47.711395 loss_ctc0 138.389191 lr 0.00085471 rank 0
2022-08-24 07:09:14,630 DEBUG TRAIN Batch 96/1600 loss 64.451019 loss_att 40.327984 loss_ctc 120.738113 loss_ctc_origin 72.002335 loss_ctc0 234.454926 lr 0.00085463 rank 0
2022-08-24 07:09:42,093 DEBUG TRAIN Batch 96/1700 loss 26.010706 loss_att 16.941471 loss_ctc 47.172253 loss_ctc_origin 37.113182 loss_ctc0 70.643417 lr 0.00085455 rank 0
2022-08-24 07:10:10,690 DEBUG TRAIN Batch 96/1800 loss 24.237316 loss_att 12.553497 loss_ctc 51.499561 loss_ctc_origin 38.448158 loss_ctc0 81.952835 lr 0.00085447 rank 0
2022-08-24 07:10:38,974 DEBUG TRAIN Batch 96/1900 loss 31.074409 loss_att 15.599258 loss_ctc 67.183098 loss_ctc_origin 53.257427 loss_ctc0 99.676331 lr 0.00085440 rank 0
2022-08-24 07:11:08,984 DEBUG TRAIN Batch 96/2000 loss 36.591854 loss_att 23.709984 loss_ctc 66.649551 loss_ctc_origin 36.150188 loss_ctc0 137.814728 lr 0.00085432 rank 0
2022-08-24 07:11:17,055 WARNING NaN or Inf found in input tensor.
2022-08-24 07:11:37,617 DEBUG TRAIN Batch 96/2100 loss 53.546902 loss_att 32.163692 loss_ctc 103.441055 loss_ctc_origin 70.017731 loss_ctc0 181.428818 lr 0.00085424 rank 0
2022-08-24 07:12:05,642 DEBUG TRAIN Batch 96/2200 loss 21.446264 loss_att 11.538481 loss_ctc 44.564423 loss_ctc_origin 32.825054 loss_ctc0 71.956276 lr 0.00085416 rank 0
2022-08-24 07:12:35,326 DEBUG TRAIN Batch 96/2300 loss 21.603535 loss_att 9.411771 loss_ctc 50.050980 loss_ctc_origin 38.155510 loss_ctc0 77.807083 lr 0.00085408 rank 0
2022-08-24 07:13:04,216 DEBUG TRAIN Batch 96/2400 loss 21.836214 loss_att 10.679548 loss_ctc 47.868431 loss_ctc_origin 31.152224 loss_ctc0 86.872910 lr 0.00085401 rank 0
2022-08-24 07:13:33,124 DEBUG TRAIN Batch 96/2500 loss 42.965813 loss_att 30.556931 loss_ctc 71.919876 loss_ctc_origin 49.354431 loss_ctc0 124.572594 lr 0.00085393 rank 0
2022-08-24 07:14:00,392 DEBUG TRAIN Batch 96/2600 loss 75.684494 loss_att 48.224800 loss_ctc 139.757095 loss_ctc_origin 83.456299 loss_ctc0 271.125610 lr 0.00085385 rank 0
2022-08-24 07:14:30,433 DEBUG TRAIN Batch 96/2700 loss 20.000900 loss_att 11.136492 loss_ctc 40.684521 loss_ctc_origin 30.008718 loss_ctc0 65.594719 lr 0.00085377 rank 0
2022-08-24 07:14:59,578 DEBUG TRAIN Batch 96/2800 loss 20.061373 loss_att 8.462852 loss_ctc 47.124584 loss_ctc_origin 34.378582 loss_ctc0 76.865257 lr 0.00085369 rank 0
2022-08-24 07:15:28,036 DEBUG TRAIN Batch 96/2900 loss 25.896877 loss_att 11.994764 loss_ctc 58.335144 loss_ctc_origin 39.819115 loss_ctc0 101.539200 lr 0.00085362 rank 0
2022-08-24 07:16:03,398 DEBUG TRAIN Batch 96/3000 loss 40.380630 loss_att 26.046160 loss_ctc 73.827728 loss_ctc_origin 45.187950 loss_ctc0 140.653870 lr 0.00085354 rank 0
2022-08-24 07:16:32,196 DEBUG TRAIN Batch 96/3100 loss 47.639301 loss_att 28.172791 loss_ctc 93.061157 loss_ctc_origin 53.476891 loss_ctc0 185.424438 lr 0.00085346 rank 0
2022-08-24 07:16:59,040 WARNING NaN or Inf found in input tensor.
2022-08-24 07:17:00,558 DEBUG TRAIN Batch 96/3200 loss 24.911747 loss_att 15.606017 loss_ctc 46.625118 loss_ctc_origin 36.916603 loss_ctc0 69.278320 lr 0.00085338 rank 0
2022-08-24 07:17:30,044 DEBUG TRAIN Batch 96/3300 loss 24.226665 loss_att 10.545469 loss_ctc 56.149452 loss_ctc_origin 41.595520 loss_ctc0 90.108627 lr 0.00085331 rank 0
2022-08-24 07:17:58,926 DEBUG TRAIN Batch 96/3400 loss 24.533447 loss_att 10.697714 loss_ctc 56.816826 loss_ctc_origin 37.761452 loss_ctc0 101.279358 lr 0.00085323 rank 0
2022-08-24 07:18:28,738 DEBUG TRAIN Batch 96/3500 loss 46.298790 loss_att 29.806812 loss_ctc 84.780075 loss_ctc_origin 50.266994 loss_ctc0 165.310577 lr 0.00085315 rank 0
2022-08-24 07:18:58,023 DEBUG TRAIN Batch 96/3600 loss 58.014435 loss_att 32.245823 loss_ctc 118.141197 loss_ctc_origin 66.331680 loss_ctc0 239.030060 lr 0.00085307 rank 0
2022-08-24 07:19:26,945 DEBUG TRAIN Batch 96/3700 loss 21.840635 loss_att 12.896507 loss_ctc 42.710266 loss_ctc_origin 31.622337 loss_ctc0 68.582108 lr 0.00085300 rank 0
2022-08-24 07:19:55,421 DEBUG TRAIN Batch 96/3800 loss 21.550068 loss_att 10.831087 loss_ctc 46.561020 loss_ctc_origin 33.151985 loss_ctc0 77.848770 lr 0.00085292 rank 0
2022-08-24 07:20:23,832 DEBUG TRAIN Batch 96/3900 loss 24.633060 loss_att 12.233765 loss_ctc 53.564751 loss_ctc_origin 35.881767 loss_ctc0 94.825043 lr 0.00085284 rank 0
2022-08-24 07:20:53,263 DEBUG TRAIN Batch 96/4000 loss 38.747177 loss_att 29.493324 loss_ctc 60.339504 loss_ctc_origin 43.797318 loss_ctc0 98.937943 lr 0.00085276 rank 0
2022-08-24 07:21:21,164 DEBUG TRAIN Batch 96/4100 loss 50.688602 loss_att 30.538395 loss_ctc 97.705750 loss_ctc_origin 66.041283 loss_ctc0 171.589493 lr 0.00085269 rank 0
2022-08-24 07:21:48,418 DEBUG TRAIN Batch 96/4200 loss 24.350639 loss_att 14.838739 loss_ctc 46.545067 loss_ctc_origin 38.064857 loss_ctc0 66.332214 lr 0.00085261 rank 0
2022-08-24 07:22:18,926 DEBUG TRAIN Batch 96/4300 loss 22.150478 loss_att 10.304186 loss_ctc 49.791824 loss_ctc_origin 36.893227 loss_ctc0 79.888550 lr 0.00085253 rank 0
2022-08-24 07:22:48,211 DEBUG TRAIN Batch 96/4400 loss 25.409872 loss_att 11.628246 loss_ctc 57.566998 loss_ctc_origin 39.200470 loss_ctc0 100.422226 lr 0.00085245 rank 0
2022-08-24 07:23:23,931 DEBUG TRAIN Batch 96/4500 loss 39.190323 loss_att 24.558132 loss_ctc 73.332092 loss_ctc_origin 44.320133 loss_ctc0 141.026657 lr 0.00085238 rank 0
2022-08-24 07:23:52,372 DEBUG TRAIN Batch 96/4600 loss 47.185181 loss_att 29.888676 loss_ctc 87.543686 loss_ctc_origin 57.133881 loss_ctc0 158.499893 lr 0.00085230 rank 0
2022-08-24 07:24:21,623 DEBUG TRAIN Batch 96/4700 loss 25.625462 loss_att 16.798080 loss_ctc 46.222679 loss_ctc_origin 36.322124 loss_ctc0 69.323967 lr 0.00085222 rank 0
2022-08-24 07:24:50,390 DEBUG TRAIN Batch 96/4800 loss 24.996958 loss_att 12.808581 loss_ctc 53.436497 loss_ctc_origin 38.977428 loss_ctc0 87.174324 lr 0.00085214 rank 0
2022-08-24 07:25:13,985 WARNING NaN or Inf found in input tensor.
2022-08-24 07:25:18,251 DEBUG TRAIN Batch 96/4900 loss 28.559711 loss_att 13.314599 loss_ctc 64.131638 loss_ctc_origin 46.994736 loss_ctc0 104.117752 lr 0.00085207 rank 0
2022-08-24 07:25:48,243 DEBUG TRAIN Batch 96/5000 loss 38.617363 loss_att 28.995190 loss_ctc 61.069107 loss_ctc_origin 43.259609 loss_ctc0 102.624588 lr 0.00085199 rank 0
2022-08-24 07:26:15,928 DEBUG TRAIN Batch 96/5100 loss 45.332203 loss_att 31.186834 loss_ctc 78.338058 loss_ctc_origin 50.736580 loss_ctc0 142.741486 lr 0.00085191 rank 0
2022-08-24 07:26:44,710 DEBUG TRAIN Batch 96/5200 loss 17.492111 loss_att 9.424918 loss_ctc 36.315559 loss_ctc_origin 23.659630 loss_ctc0 65.846054 lr 0.00085183 rank 0
2022-08-24 07:27:12,243 DEBUG TRAIN Batch 96/5300 loss 21.654495 loss_att 12.058994 loss_ctc 44.043995 loss_ctc_origin 31.422018 loss_ctc0 73.495270 lr 0.00085176 rank 0
2022-08-24 07:27:41,360 DEBUG TRAIN Batch 96/5400 loss 21.810070 loss_att 9.765249 loss_ctc 49.914654 loss_ctc_origin 35.035706 loss_ctc0 84.632195 lr 0.00085168 rank 0
2022-08-24 07:28:09,307 DEBUG TRAIN Batch 96/5500 loss 33.601421 loss_att 24.770622 loss_ctc 54.206619 loss_ctc_origin 40.978493 loss_ctc0 85.072243 lr 0.00085160 rank 0
2022-08-24 07:28:38,651 DEBUG TRAIN Batch 96/5600 loss 62.050545 loss_att 35.231850 loss_ctc 124.627487 loss_ctc_origin 70.539124 loss_ctc0 250.833649 lr 0.00085152 rank 0
2022-08-24 07:29:01,952 DEBUG CV Batch 96/0 loss 16.797260 loss_att 13.113996 loss_ctc 25.391546 loss_ctc_origin 19.738701 loss_ctc0 38.581520 history loss 15.809186 rank 0
2022-08-24 07:29:12,837 DEBUG CV Batch 96/100 loss 24.472151 loss_att 19.582193 loss_ctc 35.882053 loss_ctc_origin 25.830074 loss_ctc0 59.336670 history loss 28.543128 rank 0
2022-08-24 07:29:22,309 DEBUG CV Batch 96/200 loss 26.574188 loss_att 19.900448 loss_ctc 42.146244 loss_ctc_origin 31.887081 loss_ctc0 66.084290 history loss 29.955474 rank 0
2022-08-24 07:29:32,474 DEBUG CV Batch 96/300 loss 25.313726 loss_att 19.029264 loss_ctc 39.977470 loss_ctc_origin 25.084221 loss_ctc0 74.728378 history loss 28.993365 rank 0
2022-08-24 07:29:43,262 DEBUG CV Batch 96/400 loss 38.632088 loss_att 31.015293 loss_ctc 56.404610 loss_ctc_origin 38.752373 loss_ctc0 97.593155 history loss 27.288093 rank 0
2022-08-24 07:29:54,046 DEBUG CV Batch 96/500 loss 18.629868 loss_att 13.895379 loss_ctc 29.677006 loss_ctc_origin 22.374395 loss_ctc0 46.716423 history loss 26.926335 rank 0
2022-08-24 07:30:04,964 DEBUG CV Batch 96/600 loss 19.992216 loss_att 14.339058 loss_ctc 33.182919 loss_ctc_origin 21.801107 loss_ctc0 59.740479 history loss 26.753070 rank 0
2022-08-24 07:30:15,489 DEBUG CV Batch 96/700 loss 19.544701 loss_att 13.222130 loss_ctc 34.297363 loss_ctc_origin 20.824181 loss_ctc0 65.734787 history loss 26.421066 rank 0
2022-08-24 07:30:25,610 DEBUG CV Batch 96/800 loss 22.780462 loss_att 17.457983 loss_ctc 35.199581 loss_ctc_origin 19.668543 loss_ctc0 71.438675 history loss 26.358227 rank 0
2022-08-24 07:30:36,361 INFO Epoch 96 CV info cv_loss 26.43032993048527
2022-08-24 07:30:36,362 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/96.pt
2022-08-24 07:30:36,820 INFO Epoch 97 TRAIN info lr 0.0008514601651487427
2022-08-24 07:30:36,823 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 07:31:03,506 DEBUG TRAIN Batch 97/0 loss 40.311569 loss_att 28.180466 loss_ctc 68.617470 loss_ctc_origin 43.346687 loss_ctc0 127.582634 lr 0.00085146 rank 0
2022-08-24 07:31:32,784 DEBUG TRAIN Batch 97/100 loss 54.476219 loss_att 28.735224 loss_ctc 114.538544 loss_ctc_origin 57.724922 loss_ctc0 247.103668 lr 0.00085138 rank 0
2022-08-24 07:31:59,985 WARNING NaN or Inf found in input tensor.
2022-08-24 07:32:01,546 DEBUG TRAIN Batch 97/200 loss 24.591164 loss_att 14.914095 loss_ctc 47.170994 loss_ctc_origin 37.752079 loss_ctc0 69.148460 lr 0.00085130 rank 0
2022-08-24 07:32:30,247 DEBUG TRAIN Batch 97/300 loss 20.247736 loss_att 8.441260 loss_ctc 47.796177 loss_ctc_origin 33.634995 loss_ctc0 80.838928 lr 0.00085123 rank 0
2022-08-24 07:32:41,351 WARNING NaN or Inf found in input tensor.
2022-08-24 07:32:58,940 DEBUG TRAIN Batch 97/400 loss 27.052368 loss_att 13.402292 loss_ctc 58.902542 loss_ctc_origin 43.811722 loss_ctc0 94.114456 lr 0.00085115 rank 0
2022-08-24 07:33:20,913 WARNING NaN or Inf found in input tensor.
2022-08-24 07:33:27,948 DEBUG TRAIN Batch 97/500 loss 44.649139 loss_att 29.462259 loss_ctc 80.085190 loss_ctc_origin 47.876350 loss_ctc0 155.239166 lr 0.00085107 rank 0
2022-08-24 07:33:35,726 WARNING NaN or Inf found in input tensor.
2022-08-24 07:33:48,916 WARNING NaN or Inf found in input tensor.
2022-08-24 07:33:56,514 DEBUG TRAIN Batch 97/600 loss 51.560120 loss_att 31.329636 loss_ctc 98.764572 loss_ctc_origin 53.922775 loss_ctc0 203.395416 lr 0.00085099 rank 0
2022-08-24 07:34:24,164 DEBUG TRAIN Batch 97/700 loss 20.072254 loss_att 11.173285 loss_ctc 40.836510 loss_ctc_origin 28.794094 loss_ctc0 68.935486 lr 0.00085092 rank 0
2022-08-24 07:34:52,476 DEBUG TRAIN Batch 97/800 loss 21.254053 loss_att 10.536221 loss_ctc 46.262329 loss_ctc_origin 32.683376 loss_ctc0 77.946556 lr 0.00085084 rank 0
2022-08-24 07:35:11,082 WARNING NaN or Inf found in input tensor.
2022-08-24 07:35:22,632 DEBUG TRAIN Batch 97/900 loss 26.669310 loss_att 12.922375 loss_ctc 58.745491 loss_ctc_origin 40.431274 loss_ctc0 101.478668 lr 0.00085076 rank 0
2022-08-24 07:35:39,149 WARNING NaN or Inf found in input tensor.
2022-08-24 07:35:52,425 DEBUG TRAIN Batch 97/1000 loss 44.890762 loss_att 32.297176 loss_ctc 74.275803 loss_ctc_origin 48.647064 loss_ctc0 134.076172 lr 0.00085069 rank 0
2022-08-24 07:36:22,214 DEBUG TRAIN Batch 97/1100 loss 52.862114 loss_att 31.689386 loss_ctc 102.265137 loss_ctc_origin 58.854507 loss_ctc0 203.556610 lr 0.00085061 rank 0
2022-08-24 07:36:50,794 DEBUG TRAIN Batch 97/1200 loss 21.231878 loss_att 10.614706 loss_ctc 46.005280 loss_ctc_origin 35.445671 loss_ctc0 70.644371 lr 0.00085053 rank 0
2022-08-24 07:37:19,893 DEBUG TRAIN Batch 97/1300 loss 20.492247 loss_att 9.409325 loss_ctc 46.352398 loss_ctc_origin 33.675350 loss_ctc0 75.932175 lr 0.00085046 rank 0
2022-08-24 07:37:44,559 WARNING NaN or Inf found in input tensor.
2022-08-24 07:37:49,132 DEBUG TRAIN Batch 97/1400 loss 26.124332 loss_att 11.496645 loss_ctc 60.255600 loss_ctc_origin 44.681236 loss_ctc0 96.595787 lr 0.00085038 rank 0
2022-08-24 07:38:24,522 DEBUG TRAIN Batch 97/1500 loss 35.916931 loss_att 24.212212 loss_ctc 63.227940 loss_ctc_origin 39.997326 loss_ctc0 117.432709 lr 0.00085030 rank 0
2022-08-24 07:38:54,022 DEBUG TRAIN Batch 97/1600 loss 59.068920 loss_att 33.501583 loss_ctc 118.726044 loss_ctc_origin 68.066757 loss_ctc0 236.931030 lr 0.00085023 rank 0
2022-08-24 07:39:24,281 DEBUG TRAIN Batch 97/1700 loss 24.379150 loss_att 13.782080 loss_ctc 49.105652 loss_ctc_origin 39.539864 loss_ctc0 71.425827 lr 0.00085015 rank 0
2022-08-24 07:39:52,326 DEBUG TRAIN Batch 97/1800 loss 21.068338 loss_att 10.879004 loss_ctc 44.843449 loss_ctc_origin 32.001686 loss_ctc0 74.807556 lr 0.00085007 rank 0
2022-08-24 07:40:21,822 DEBUG TRAIN Batch 97/1900 loss 25.761093 loss_att 11.766343 loss_ctc 58.415504 loss_ctc_origin 39.821140 loss_ctc0 101.802345 lr 0.00084999 rank 0
2022-08-24 07:40:51,477 DEBUG TRAIN Batch 97/2000 loss 35.079292 loss_att 22.718061 loss_ctc 63.922157 loss_ctc_origin 37.765621 loss_ctc0 124.954063 lr 0.00084992 rank 0
2022-08-24 07:41:12,829 WARNING NaN or Inf found in input tensor.
2022-08-24 07:41:20,538 DEBUG TRAIN Batch 97/2100 loss 52.505791 loss_att 31.094715 loss_ctc 102.464966 loss_ctc_origin 56.838829 loss_ctc0 208.925949 lr 0.00084984 rank 0
2022-08-24 07:41:49,207 DEBUG TRAIN Batch 97/2200 loss 24.186043 loss_att 14.400215 loss_ctc 47.019638 loss_ctc_origin 35.668194 loss_ctc0 73.506332 lr 0.00084976 rank 0
2022-08-24 07:42:17,776 DEBUG TRAIN Batch 97/2300 loss 20.602158 loss_att 8.695676 loss_ctc 48.383942 loss_ctc_origin 32.808941 loss_ctc0 84.725601 lr 0.00084969 rank 0
2022-08-24 07:42:47,281 DEBUG TRAIN Batch 97/2400 loss 25.210402 loss_att 10.923296 loss_ctc 58.546982 loss_ctc_origin 42.525990 loss_ctc0 95.929291 lr 0.00084961 rank 0
2022-08-24 07:43:17,029 DEBUG TRAIN Batch 97/2500 loss 34.647675 loss_att 21.389353 loss_ctc 65.583763 loss_ctc_origin 34.643913 loss_ctc0 137.776733 lr 0.00084953 rank 0
2022-08-24 07:43:45,146 DEBUG TRAIN Batch 97/2600 loss 44.110909 loss_att 22.711052 loss_ctc 94.043907 loss_ctc_origin 47.679527 loss_ctc0 202.227463 lr 0.00084946 rank 0
2022-08-24 07:44:13,032 DEBUG TRAIN Batch 97/2700 loss 22.829292 loss_att 12.823870 loss_ctc 46.175278 loss_ctc_origin 35.743027 loss_ctc0 70.517189 lr 0.00084938 rank 0
2022-08-24 07:44:40,897 DEBUG TRAIN Batch 97/2800 loss 21.204578 loss_att 9.877746 loss_ctc 47.633850 loss_ctc_origin 32.719788 loss_ctc0 82.433334 lr 0.00084930 rank 0
2022-08-24 07:45:10,334 DEBUG TRAIN Batch 97/2900 loss 28.018953 loss_att 12.724490 loss_ctc 63.706032 loss_ctc_origin 48.681210 loss_ctc0 98.763954 lr 0.00084923 rank 0
2022-08-24 07:45:45,435 DEBUG TRAIN Batch 97/3000 loss 34.765045 loss_att 21.666100 loss_ctc 65.329254 loss_ctc_origin 35.648300 loss_ctc0 134.584808 lr 0.00084915 rank 0
2022-08-24 07:46:13,389 DEBUG TRAIN Batch 97/3100 loss 62.127125 loss_att 37.290890 loss_ctc 120.078339 loss_ctc_origin 66.403931 loss_ctc0 245.318619 lr 0.00084908 rank 0
2022-08-24 07:46:42,281 DEBUG TRAIN Batch 97/3200 loss 24.061707 loss_att 13.593914 loss_ctc 48.486557 loss_ctc_origin 38.869492 loss_ctc0 70.926376 lr 0.00084900 rank 0
2022-08-24 07:47:11,197 DEBUG TRAIN Batch 97/3300 loss 23.107283 loss_att 9.977562 loss_ctc 53.743294 loss_ctc_origin 38.373524 loss_ctc0 89.606094 lr 0.00084892 rank 0
2022-08-24 07:47:39,410 DEBUG TRAIN Batch 97/3400 loss 26.411369 loss_att 12.216623 loss_ctc 59.532440 loss_ctc_origin 42.585487 loss_ctc0 99.075325 lr 0.00084885 rank 0
2022-08-24 07:48:08,881 DEBUG TRAIN Batch 97/3500 loss 36.253197 loss_att 21.074997 loss_ctc 71.668991 loss_ctc_origin 42.404259 loss_ctc0 139.953369 lr 0.00084877 rank 0
2022-08-24 07:48:36,938 DEBUG TRAIN Batch 97/3600 loss 64.710068 loss_att 37.156944 loss_ctc 129.000702 loss_ctc_origin 68.488052 loss_ctc0 270.196899 lr 0.00084869 rank 0
2022-08-24 07:49:05,454 DEBUG TRAIN Batch 97/3700 loss 25.984673 loss_att 15.284941 loss_ctc 50.950714 loss_ctc_origin 42.199661 loss_ctc0 71.369843 lr 0.00084862 rank 0
2022-08-24 07:49:34,754 DEBUG TRAIN Batch 97/3800 loss 21.840538 loss_att 10.639420 loss_ctc 47.976479 loss_ctc_origin 32.772182 loss_ctc0 83.453171 lr 0.00084854 rank 0
2022-08-24 07:50:02,815 DEBUG TRAIN Batch 97/3900 loss 26.081520 loss_att 12.290691 loss_ctc 58.260120 loss_ctc_origin 42.389584 loss_ctc0 95.291367 lr 0.00084846 rank 0
2022-08-24 07:50:31,771 DEBUG TRAIN Batch 97/4000 loss 42.247375 loss_att 29.609409 loss_ctc 71.735970 loss_ctc_origin 44.945168 loss_ctc0 134.247833 lr 0.00084839 rank 0
2022-08-24 07:51:00,291 DEBUG TRAIN Batch 97/4100 loss 53.072094 loss_att 30.431293 loss_ctc 105.900627 loss_ctc_origin 55.345528 loss_ctc0 223.862518 lr 0.00084831 rank 0
2022-08-24 07:51:28,885 DEBUG TRAIN Batch 97/4200 loss 19.990583 loss_att 12.022610 loss_ctc 38.582520 loss_ctc_origin 28.634775 loss_ctc0 61.793926 lr 0.00084823 rank 0
2022-08-24 07:51:41,406 WARNING NaN or Inf found in input tensor.
2022-08-24 07:51:58,848 DEBUG TRAIN Batch 97/4300 loss 24.809956 loss_att 12.030596 loss_ctc 54.628460 loss_ctc_origin 41.782021 loss_ctc0 84.603485 lr 0.00084816 rank 0
2022-08-24 07:52:16,905 WARNING NaN or Inf found in input tensor.
2022-08-24 07:52:28,510 DEBUG TRAIN Batch 97/4400 loss 24.893314 loss_att 12.296000 loss_ctc 54.287041 loss_ctc_origin 37.446590 loss_ctc0 93.581429 lr 0.00084808 rank 0
2022-08-24 07:53:04,544 DEBUG TRAIN Batch 97/4500 loss 38.865929 loss_att 26.574509 loss_ctc 67.545898 loss_ctc_origin 41.313026 loss_ctc0 128.755920 lr 0.00084801 rank 0
2022-08-24 07:53:32,755 DEBUG TRAIN Batch 97/4600 loss 58.632065 loss_att 33.099701 loss_ctc 118.207581 loss_ctc_origin 65.313141 loss_ctc0 241.627930 lr 0.00084793 rank 0
2022-08-24 07:54:01,021 DEBUG TRAIN Batch 97/4700 loss 22.148663 loss_att 11.990688 loss_ctc 45.850605 loss_ctc_origin 36.422615 loss_ctc0 67.849243 lr 0.00084785 rank 0
2022-08-24 07:54:29,675 DEBUG TRAIN Batch 97/4800 loss 21.891413 loss_att 9.436705 loss_ctc 50.952396 loss_ctc_origin 37.221592 loss_ctc0 82.990936 lr 0.00084778 rank 0
2022-08-24 07:54:58,253 DEBUG TRAIN Batch 97/4900 loss 23.186535 loss_att 11.745624 loss_ctc 49.881996 loss_ctc_origin 32.655090 loss_ctc0 90.078102 lr 0.00084770 rank 0
2022-08-24 07:55:27,895 DEBUG TRAIN Batch 97/5000 loss 38.166664 loss_att 26.910332 loss_ctc 64.431427 loss_ctc_origin 36.522255 loss_ctc0 129.552826 lr 0.00084763 rank 0
2022-08-24 07:55:56,523 DEBUG TRAIN Batch 97/5100 loss 70.303284 loss_att 39.761250 loss_ctc 141.568024 loss_ctc_origin 84.346298 loss_ctc0 275.085388 lr 0.00084755 rank 0
2022-08-24 07:56:23,939 WARNING NaN or Inf found in input tensor.
2022-08-24 07:56:25,542 DEBUG TRAIN Batch 97/5200 loss 17.949600 loss_att 9.758183 loss_ctc 37.062912 loss_ctc_origin 26.060398 loss_ctc0 62.735432 lr 0.00084747 rank 0
2022-08-24 07:56:54,308 DEBUG TRAIN Batch 97/5300 loss 24.781590 loss_att 11.489014 loss_ctc 55.797596 loss_ctc_origin 43.231514 loss_ctc0 85.118446 lr 0.00084740 rank 0
2022-08-24 07:57:22,686 DEBUG TRAIN Batch 97/5400 loss 24.262470 loss_att 10.696661 loss_ctc 55.916023 loss_ctc_origin 37.066502 loss_ctc0 99.898239 lr 0.00084732 rank 0
2022-08-24 07:57:52,427 DEBUG TRAIN Batch 97/5500 loss 41.461998 loss_att 25.887665 loss_ctc 77.802116 loss_ctc_origin 44.015869 loss_ctc0 156.636688 lr 0.00084724 rank 0
2022-08-24 07:58:20,710 DEBUG TRAIN Batch 97/5600 loss 61.264095 loss_att 34.425316 loss_ctc 123.887909 loss_ctc_origin 63.347599 loss_ctc0 265.148621 lr 0.00084717 rank 0
2022-08-24 07:58:43,930 DEBUG CV Batch 97/0 loss 16.018818 loss_att 12.332666 loss_ctc 24.619839 loss_ctc_origin 17.600630 loss_ctc0 40.997993 history loss 15.076534 rank 0
2022-08-24 07:58:54,827 DEBUG CV Batch 97/100 loss 27.012764 loss_att 22.013947 loss_ctc 38.676674 loss_ctc_origin 29.384521 loss_ctc0 60.358364 history loss 29.581506 rank 0
2022-08-24 07:59:04,746 DEBUG CV Batch 97/200 loss 25.075672 loss_att 19.103954 loss_ctc 39.009686 loss_ctc_origin 28.610744 loss_ctc0 63.273876 history loss 31.474045 rank 0
2022-08-24 07:59:14,844 DEBUG CV Batch 97/300 loss 24.606514 loss_att 18.324188 loss_ctc 39.265274 loss_ctc_origin 24.456959 loss_ctc0 73.818008 history loss 30.317684 rank 0
2022-08-24 07:59:25,854 DEBUG CV Batch 97/400 loss 38.919231 loss_att 31.280787 loss_ctc 56.742264 loss_ctc_origin 39.260635 loss_ctc0 97.532730 history loss 28.526529 rank 0
2022-08-24 07:59:37,072 DEBUG CV Batch 97/500 loss 22.057194 loss_att 17.740944 loss_ctc 32.128445 loss_ctc_origin 26.063843 loss_ctc0 46.279182 history loss 28.105965 rank 0
2022-08-24 07:59:47,826 DEBUG CV Batch 97/600 loss 22.137194 loss_att 15.402399 loss_ctc 37.851715 loss_ctc_origin 26.606613 loss_ctc0 64.090279 history loss 27.922971 rank 0
2022-08-24 07:59:58,002 DEBUG CV Batch 97/700 loss 19.917414 loss_att 13.494370 loss_ctc 34.904518 loss_ctc_origin 21.935425 loss_ctc0 65.165741 history loss 27.584307 rank 0
2022-08-24 08:00:08,618 DEBUG CV Batch 97/800 loss 23.528313 loss_att 18.201038 loss_ctc 35.958622 loss_ctc_origin 20.804260 loss_ctc0 71.318802 history loss 27.492818 rank 0
2022-08-24 08:00:18,406 INFO Epoch 97 CV info cv_loss 27.51673406591766
2022-08-24 08:00:18,406 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/97.pt
2022-08-24 08:00:18,967 INFO Epoch 98 TRAIN info lr 0.0008471048416247858
2022-08-24 08:00:18,971 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 08:00:46,037 DEBUG TRAIN Batch 98/0 loss 42.942688 loss_att 28.250389 loss_ctc 77.224716 loss_ctc_origin 41.774071 loss_ctc0 159.942886 lr 0.00084710 rank 0
2022-08-24 08:00:54,046 WARNING NaN or Inf found in input tensor.
2022-08-24 08:01:14,861 DEBUG TRAIN Batch 98/100 loss 67.033134 loss_att 35.021164 loss_ctc 141.727722 loss_ctc_origin 72.876076 loss_ctc0 302.381531 lr 0.00084703 rank 0
2022-08-24 08:01:43,593 DEBUG TRAIN Batch 98/200 loss 18.713099 loss_att 11.277544 loss_ctc 36.062721 loss_ctc_origin 25.150051 loss_ctc0 61.525612 lr 0.00084695 rank 0
2022-08-24 08:02:12,532 DEBUG TRAIN Batch 98/300 loss 21.502176 loss_att 9.818416 loss_ctc 48.764282 loss_ctc_origin 36.535419 loss_ctc0 77.298294 lr 0.00084687 rank 0
2022-08-24 08:02:41,263 DEBUG TRAIN Batch 98/400 loss 24.827370 loss_att 10.927577 loss_ctc 57.260216 loss_ctc_origin 39.309509 loss_ctc0 99.145187 lr 0.00084680 rank 0
2022-08-24 08:03:11,225 DEBUG TRAIN Batch 98/500 loss 42.451645 loss_att 27.653477 loss_ctc 76.980698 loss_ctc_origin 43.381485 loss_ctc0 155.378845 lr 0.00084672 rank 0
2022-08-24 08:03:19,053 WARNING NaN or Inf found in input tensor.
2022-08-24 08:03:39,046 DEBUG TRAIN Batch 98/600 loss 70.139969 loss_att 39.978806 loss_ctc 140.516006 loss_ctc_origin 79.247482 loss_ctc0 283.475891 lr 0.00084665 rank 0
2022-08-24 08:04:08,386 DEBUG TRAIN Batch 98/700 loss 20.500126 loss_att 11.970266 loss_ctc 40.403130 loss_ctc_origin 30.936562 loss_ctc0 62.491787 lr 0.00084657 rank 0
2022-08-24 08:04:37,448 DEBUG TRAIN Batch 98/800 loss 25.529028 loss_att 13.041979 loss_ctc 54.665474 loss_ctc_origin 42.381950 loss_ctc0 83.327026 lr 0.00084649 rank 0
2022-08-24 08:05:01,923 WARNING NaN or Inf found in input tensor.
2022-08-24 08:05:06,185 DEBUG TRAIN Batch 98/900 loss 25.747570 loss_att 11.813555 loss_ctc 58.260265 loss_ctc_origin 40.364777 loss_ctc0 100.016403 lr 0.00084642 rank 0
2022-08-24 08:05:35,494 DEBUG TRAIN Batch 98/1000 loss 41.396126 loss_att 27.605099 loss_ctc 73.575180 loss_ctc_origin 43.726463 loss_ctc0 143.222198 lr 0.00084634 rank 0
2022-08-24 08:06:04,034 DEBUG TRAIN Batch 98/1100 loss 40.027061 loss_att 24.425152 loss_ctc 76.431519 loss_ctc_origin 40.875893 loss_ctc0 159.394623 lr 0.00084627 rank 0
2022-08-24 08:06:22,162 WARNING NaN or Inf found in input tensor.
2022-08-24 08:06:31,517 DEBUG TRAIN Batch 98/1200 loss 24.310385 loss_att 15.005862 loss_ctc 46.020935 loss_ctc_origin 38.728699 loss_ctc0 63.036148 lr 0.00084619 rank 0
2022-08-24 08:06:59,712 DEBUG TRAIN Batch 98/1300 loss 17.306305 loss_att 8.404185 loss_ctc 38.077911 loss_ctc_origin 24.761684 loss_ctc0 69.149101 lr 0.00084612 rank 0
2022-08-24 08:07:17,234 WARNING NaN or Inf found in input tensor.
2022-08-24 08:07:24,504 WARNING NaN or Inf found in input tensor.
2022-08-24 08:07:29,154 DEBUG TRAIN Batch 98/1400 loss 29.378996 loss_att 13.404800 loss_ctc 66.652115 loss_ctc_origin 49.500687 loss_ctc0 106.672134 lr 0.00084604 rank 0
2022-08-24 08:08:03,416 DEBUG TRAIN Batch 98/1500 loss 40.729584 loss_att 26.793377 loss_ctc 73.247398 loss_ctc_origin 44.892582 loss_ctc0 139.408630 lr 0.00084596 rank 0
2022-08-24 08:08:11,392 WARNING NaN or Inf found in input tensor.
2022-08-24 08:08:30,586 DEBUG TRAIN Batch 98/1600 loss 63.929222 loss_att 40.609352 loss_ctc 118.342255 loss_ctc_origin 71.095963 loss_ctc0 228.583603 lr 0.00084589 rank 0
2022-08-24 08:08:58,491 DEBUG TRAIN Batch 98/1700 loss 21.980982 loss_att 13.650007 loss_ctc 41.419922 loss_ctc_origin 31.899206 loss_ctc0 63.634918 lr 0.00084581 rank 0
2022-08-24 08:09:26,425 DEBUG TRAIN Batch 98/1800 loss 18.721184 loss_att 9.048756 loss_ctc 41.290184 loss_ctc_origin 28.410023 loss_ctc0 71.343895 lr 0.00084574 rank 0
2022-08-24 08:09:49,043 WARNING NaN or Inf found in input tensor.
2022-08-24 08:09:53,626 DEBUG TRAIN Batch 98/1900 loss 21.054016 loss_att 9.567129 loss_ctc 47.856750 loss_ctc_origin 32.618755 loss_ctc0 83.412079 lr 0.00084566 rank 0
2022-08-24 08:10:21,461 DEBUG TRAIN Batch 98/2000 loss 36.184143 loss_att 21.626469 loss_ctc 70.152054 loss_ctc_origin 38.859844 loss_ctc0 143.167206 lr 0.00084559 rank 0
2022-08-24 08:10:49,895 DEBUG TRAIN Batch 98/2100 loss 53.434467 loss_att 29.850414 loss_ctc 108.463921 loss_ctc_origin 60.790680 loss_ctc0 219.701477 lr 0.00084551 rank 0
2022-08-24 08:11:16,901 DEBUG TRAIN Batch 98/2200 loss 22.730637 loss_att 12.949892 loss_ctc 45.552372 loss_ctc_origin 36.289368 loss_ctc0 67.166046 lr 0.00084544 rank 0
2022-08-24 08:11:44,938 DEBUG TRAIN Batch 98/2300 loss 26.073812 loss_att 11.856058 loss_ctc 59.248569 loss_ctc_origin 45.582981 loss_ctc0 91.134941 lr 0.00084536 rank 0
2022-08-24 08:12:13,022 DEBUG TRAIN Batch 98/2400 loss 31.054138 loss_att 15.709574 loss_ctc 66.858124 loss_ctc_origin 52.135124 loss_ctc0 101.211792 lr 0.00084528 rank 0
2022-08-24 08:12:41,467 DEBUG TRAIN Batch 98/2500 loss 30.525311 loss_att 19.363869 loss_ctc 56.568676 loss_ctc_origin 32.722954 loss_ctc0 112.208694 lr 0.00084521 rank 0
2022-08-24 08:12:54,989 WARNING NaN or Inf found in input tensor.
2022-08-24 08:13:09,575 DEBUG TRAIN Batch 98/2600 loss 42.139755 loss_att 28.461849 loss_ctc 74.054871 loss_ctc_origin 45.429935 loss_ctc0 140.846375 lr 0.00084513 rank 0
2022-08-24 08:13:38,730 DEBUG TRAIN Batch 98/2700 loss 20.533466 loss_att 11.672215 loss_ctc 41.209717 loss_ctc_origin 31.444403 loss_ctc0 63.995457 lr 0.00084506 rank 0
2022-08-24 08:13:54,848 WARNING NaN or Inf found in input tensor.
2022-08-24 08:14:04,703 DEBUG TRAIN Batch 98/2800 loss 22.290106 loss_att 10.657329 loss_ctc 49.433250 loss_ctc_origin 36.603333 loss_ctc0 79.369736 lr 0.00084498 rank 0
2022-08-24 08:14:32,287 DEBUG TRAIN Batch 98/2900 loss 26.444769 loss_att 12.809816 loss_ctc 58.259659 loss_ctc_origin 38.815140 loss_ctc0 103.630203 lr 0.00084491 rank 0
2022-08-24 08:15:07,110 DEBUG TRAIN Batch 98/3000 loss 35.866608 loss_att 20.824413 loss_ctc 70.965065 loss_ctc_origin 34.627907 loss_ctc0 155.751770 lr 0.00084483 rank 0
2022-08-24 08:15:35,235 DEBUG TRAIN Batch 98/3100 loss 55.046051 loss_att 31.200912 loss_ctc 110.684692 loss_ctc_origin 59.520828 loss_ctc0 230.067017 lr 0.00084476 rank 0
2022-08-24 08:16:02,919 DEBUG TRAIN Batch 98/3200 loss 20.960167 loss_att 12.712753 loss_ctc 40.204136 loss_ctc_origin 30.962006 loss_ctc0 61.769108 lr 0.00084468 rank 0
2022-08-24 08:16:08,600 WARNING NaN or Inf found in input tensor.
2022-08-24 08:16:30,678 DEBUG TRAIN Batch 98/3300 loss 23.922756 loss_att 11.546431 loss_ctc 52.800846 loss_ctc_origin 39.514664 loss_ctc0 83.801933 lr 0.00084461 rank 0
2022-08-24 08:17:00,013 DEBUG TRAIN Batch 98/3400 loss 23.762165 loss_att 11.593229 loss_ctc 52.156345 loss_ctc_origin 35.150826 loss_ctc0 91.835892 lr 0.00084453 rank 0
2022-08-24 08:17:29,291 DEBUG TRAIN Batch 98/3500 loss 43.837212 loss_att 29.435404 loss_ctc 77.441429 loss_ctc_origin 47.435490 loss_ctc0 147.455292 lr 0.00084445 rank 0
2022-08-24 08:17:56,651 DEBUG TRAIN Batch 98/3600 loss 47.153828 loss_att 27.699877 loss_ctc 92.546379 loss_ctc_origin 57.003029 loss_ctc0 175.480865 lr 0.00084438 rank 0
2022-08-24 08:18:25,261 DEBUG TRAIN Batch 98/3700 loss 21.268505 loss_att 14.323232 loss_ctc 37.474140 loss_ctc_origin 28.026939 loss_ctc0 59.517609 lr 0.00084430 rank 0
2022-08-24 08:18:53,477 DEBUG TRAIN Batch 98/3800 loss 23.295561 loss_att 11.369064 loss_ctc 51.124054 loss_ctc_origin 37.741241 loss_ctc0 82.350616 lr 0.00084423 rank 0
2022-08-24 08:19:21,946 DEBUG TRAIN Batch 98/3900 loss 27.231243 loss_att 13.147912 loss_ctc 60.092346 loss_ctc_origin 44.536514 loss_ctc0 96.389282 lr 0.00084415 rank 0
2022-08-24 08:19:52,000 DEBUG TRAIN Batch 98/4000 loss 48.775230 loss_att 29.248215 loss_ctc 94.338264 loss_ctc_origin 53.503429 loss_ctc0 189.619537 lr 0.00084408 rank 0
2022-08-24 08:20:20,208 DEBUG TRAIN Batch 98/4100 loss 59.684052 loss_att 32.375641 loss_ctc 123.403671 loss_ctc_origin 61.730057 loss_ctc0 267.308746 lr 0.00084400 rank 0
2022-08-24 08:20:48,130 DEBUG TRAIN Batch 98/4200 loss 19.976498 loss_att 10.844944 loss_ctc 41.283455 loss_ctc_origin 29.871258 loss_ctc0 67.911919 lr 0.00084393 rank 0
2022-08-24 08:21:15,871 DEBUG TRAIN Batch 98/4300 loss 20.793402 loss_att 9.511758 loss_ctc 47.117233 loss_ctc_origin 33.590881 loss_ctc0 78.678711 lr 0.00084385 rank 0
2022-08-24 08:21:44,294 DEBUG TRAIN Batch 98/4400 loss 31.026157 loss_att 16.136673 loss_ctc 65.768288 loss_ctc_origin 50.910156 loss_ctc0 100.437256 lr 0.00084378 rank 0
2022-08-24 08:22:21,238 DEBUG TRAIN Batch 98/4500 loss 49.196396 loss_att 32.480247 loss_ctc 88.200745 loss_ctc_origin 53.271736 loss_ctc0 169.701752 lr 0.00084370 rank 0
2022-08-24 08:22:50,342 DEBUG TRAIN Batch 98/4600 loss 62.663227 loss_att 33.276100 loss_ctc 131.233185 loss_ctc_origin 63.890392 loss_ctc0 288.366333 lr 0.00084363 rank 0
2022-08-24 08:23:19,014 DEBUG TRAIN Batch 98/4700 loss 22.460239 loss_att 13.126558 loss_ctc 44.238831 loss_ctc_origin 34.379803 loss_ctc0 67.243225 lr 0.00084355 rank 0
2022-08-24 08:23:48,191 DEBUG TRAIN Batch 98/4800 loss 22.511364 loss_att 10.427811 loss_ctc 50.706322 loss_ctc_origin 38.569901 loss_ctc0 79.024628 lr 0.00084348 rank 0
2022-08-24 08:24:17,181 DEBUG TRAIN Batch 98/4900 loss 26.435822 loss_att 13.045397 loss_ctc 57.680138 loss_ctc_origin 38.820332 loss_ctc0 101.686356 lr 0.00084340 rank 0
2022-08-24 08:24:47,103 DEBUG TRAIN Batch 98/5000 loss 48.106049 loss_att 30.444130 loss_ctc 89.317184 loss_ctc_origin 50.169235 loss_ctc0 180.662399 lr 0.00084333 rank 0
2022-08-24 08:25:16,861 DEBUG TRAIN Batch 98/5100 loss 55.489796 loss_att 26.219444 loss_ctc 123.787277 loss_ctc_origin 55.343536 loss_ctc0 283.489319 lr 0.00084325 rank 0
2022-08-24 08:25:45,829 DEBUG TRAIN Batch 98/5200 loss 19.376293 loss_att 11.323960 loss_ctc 38.165070 loss_ctc_origin 26.801592 loss_ctc0 64.679840 lr 0.00084318 rank 0
2022-08-24 08:26:14,750 DEBUG TRAIN Batch 98/5300 loss 24.475983 loss_att 11.483293 loss_ctc 54.792259 loss_ctc_origin 40.423309 loss_ctc0 88.319809 lr 0.00084310 rank 0
2022-08-24 08:26:43,409 DEBUG TRAIN Batch 98/5400 loss 25.445259 loss_att 12.275526 loss_ctc 56.174633 loss_ctc_origin 40.492184 loss_ctc0 92.767014 lr 0.00084303 rank 0
2022-08-24 08:27:11,488 DEBUG TRAIN Batch 98/5500 loss 52.868694 loss_att 33.323746 loss_ctc 98.473572 loss_ctc_origin 56.867550 loss_ctc0 195.554291 lr 0.00084295 rank 0
2022-08-24 08:27:41,465 DEBUG TRAIN Batch 98/5600 loss 48.552307 loss_att 24.571308 loss_ctc 104.507965 loss_ctc_origin 51.816036 loss_ctc0 227.455795 lr 0.00084288 rank 0
2022-08-24 08:28:04,797 DEBUG CV Batch 98/0 loss 13.378780 loss_att 10.201284 loss_ctc 20.792934 loss_ctc_origin 14.055902 loss_ctc0 36.512676 history loss 12.591793 rank 0
2022-08-24 08:28:15,622 DEBUG CV Batch 98/100 loss 24.686375 loss_att 18.633240 loss_ctc 38.810356 loss_ctc_origin 27.874969 loss_ctc0 64.326256 history loss 28.275595 rank 0
2022-08-24 08:28:25,613 DEBUG CV Batch 98/200 loss 25.474957 loss_att 19.937321 loss_ctc 38.396111 loss_ctc_origin 27.516916 loss_ctc0 63.780899 history loss 29.842175 rank 0
2022-08-24 08:28:35,913 DEBUG CV Batch 98/300 loss 23.913519 loss_att 18.272724 loss_ctc 37.075371 loss_ctc_origin 21.584471 loss_ctc0 73.220810 history loss 28.808871 rank 0
2022-08-24 08:28:46,686 DEBUG CV Batch 98/400 loss 38.941349 loss_att 31.590527 loss_ctc 56.093262 loss_ctc_origin 38.801239 loss_ctc0 96.441307 history loss 27.111720 rank 0
2022-08-24 08:28:57,871 DEBUG CV Batch 98/500 loss 18.443924 loss_att 14.089045 loss_ctc 28.605305 loss_ctc_origin 22.300507 loss_ctc0 43.316498 history loss 26.793279 rank 0
2022-08-24 08:29:08,894 DEBUG CV Batch 98/600 loss 18.614803 loss_att 13.077975 loss_ctc 31.534065 loss_ctc_origin 20.423676 loss_ctc0 57.458309 history loss 26.649099 rank 0
2022-08-24 08:29:19,280 DEBUG CV Batch 98/700 loss 20.210049 loss_att 13.671899 loss_ctc 35.465733 loss_ctc_origin 22.740772 loss_ctc0 65.157310 history loss 26.299238 rank 0
2022-08-24 08:29:30,270 DEBUG CV Batch 98/800 loss 23.835342 loss_att 18.655890 loss_ctc 35.920734 loss_ctc_origin 21.022226 loss_ctc0 70.683914 history loss 26.258131 rank 0
2022-08-24 08:29:40,871 INFO Epoch 98 CV info cv_loss 26.32130887805105
2022-08-24 08:29:40,871 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/98.pt
2022-08-24 08:29:41,376 INFO Epoch 99 TRAIN info lr 0.0008428156756259812
2022-08-24 08:29:41,380 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 08:30:09,248 DEBUG TRAIN Batch 99/0 loss 51.657631 loss_att 30.592239 loss_ctc 100.810211 loss_ctc_origin 59.377769 loss_ctc0 197.485916 lr 0.00084281 rank 0
2022-08-24 08:30:37,767 DEBUG TRAIN Batch 99/100 loss 58.927719 loss_att 33.494293 loss_ctc 118.272385 loss_ctc_origin 64.418449 loss_ctc0 243.931549 lr 0.00084274 rank 0
2022-08-24 08:31:06,900 DEBUG TRAIN Batch 99/200 loss 22.324911 loss_att 12.824032 loss_ctc 44.493629 loss_ctc_origin 33.864323 loss_ctc0 69.295349 lr 0.00084266 rank 0
2022-08-24 08:31:35,807 DEBUG TRAIN Batch 99/300 loss 23.423496 loss_att 10.514090 loss_ctc 53.545441 loss_ctc_origin 38.930824 loss_ctc0 87.646202 lr 0.00084259 rank 0
2022-08-24 08:31:38,904 WARNING NaN or Inf found in input tensor.
2022-08-24 08:32:00,160 WARNING NaN or Inf found in input tensor.
2022-08-24 08:32:04,928 DEBUG TRAIN Batch 99/400 loss 29.466661 loss_att 13.701916 loss_ctc 66.251068 loss_ctc_origin 47.964363 loss_ctc0 108.920059 lr 0.00084251 rank 0
2022-08-24 08:32:14,979 WARNING NaN or Inf found in input tensor.
2022-08-24 08:32:34,639 DEBUG TRAIN Batch 99/500 loss 47.233181 loss_att 31.492569 loss_ctc 83.961273 loss_ctc_origin 53.014465 loss_ctc0 156.170486 lr 0.00084244 rank 0
2022-08-24 08:33:04,174 DEBUG TRAIN Batch 99/600 loss 60.307610 loss_att 36.802345 loss_ctc 115.153229 loss_ctc_origin 65.912361 loss_ctc0 230.048569 lr 0.00084236 rank 0
2022-08-24 08:33:24,287 WARNING NaN or Inf found in input tensor.
2022-08-24 08:33:32,820 DEBUG TRAIN Batch 99/700 loss 23.742516 loss_att 14.420707 loss_ctc 45.493401 loss_ctc_origin 35.648872 loss_ctc0 68.463966 lr 0.00084229 rank 0
2022-08-24 08:34:01,711 DEBUG TRAIN Batch 99/800 loss 23.875132 loss_att 10.896941 loss_ctc 54.157570 loss_ctc_origin 41.317741 loss_ctc0 84.117165 lr 0.00084221 rank 0
2022-08-24 08:34:31,646 DEBUG TRAIN Batch 99/900 loss 27.005421 loss_att 12.188725 loss_ctc 61.577705 loss_ctc_origin 44.507896 loss_ctc0 101.407249 lr 0.00084214 rank 0
2022-08-24 08:35:00,591 DEBUG TRAIN Batch 99/1000 loss 47.202309 loss_att 31.021049 loss_ctc 84.958572 loss_ctc_origin 53.285820 loss_ctc0 158.861664 lr 0.00084207 rank 0
2022-08-24 08:35:29,997 DEBUG TRAIN Batch 99/1100 loss 55.957684 loss_att 33.076504 loss_ctc 109.347092 loss_ctc_origin 63.998920 loss_ctc0 215.159485 lr 0.00084199 rank 0
2022-08-24 08:35:59,134 DEBUG TRAIN Batch 99/1200 loss 22.079273 loss_att 11.400898 loss_ctc 46.995483 loss_ctc_origin 36.408035 loss_ctc0 71.699524 lr 0.00084192 rank 0
2022-08-24 08:36:27,891 DEBUG TRAIN Batch 99/1300 loss 23.431595 loss_att 11.117014 loss_ctc 52.165619 loss_ctc_origin 38.751343 loss_ctc0 83.465599 lr 0.00084184 rank 0
2022-08-24 08:36:57,236 DEBUG TRAIN Batch 99/1400 loss 23.089230 loss_att 9.613562 loss_ctc 54.532448 loss_ctc_origin 39.084175 loss_ctc0 90.578415 lr 0.00084177 rank 0
2022-08-24 08:37:31,877 DEBUG TRAIN Batch 99/1500 loss 44.217499 loss_att 26.608063 loss_ctc 85.306183 loss_ctc_origin 52.645134 loss_ctc0 161.515274 lr 0.00084169 rank 0
2022-08-24 08:37:40,189 WARNING NaN or Inf found in input tensor.
2022-08-24 08:38:01,330 DEBUG TRAIN Batch 99/1600 loss 56.973366 loss_att 34.382416 loss_ctc 109.685593 loss_ctc_origin 62.267780 loss_ctc0 220.327164 lr 0.00084162 rank 0
2022-08-24 08:38:29,727 DEBUG TRAIN Batch 99/1700 loss 23.629593 loss_att 13.817915 loss_ctc 46.523506 loss_ctc_origin 36.083645 loss_ctc0 70.883186 lr 0.00084154 rank 0
2022-08-24 08:38:58,013 DEBUG TRAIN Batch 99/1800 loss 23.000557 loss_att 10.653988 loss_ctc 51.809219 loss_ctc_origin 38.581444 loss_ctc0 82.674026 lr 0.00084147 rank 0
2022-08-24 08:39:25,822 DEBUG TRAIN Batch 99/1900 loss 22.917246 loss_att 9.213295 loss_ctc 54.893127 loss_ctc_origin 35.277695 loss_ctc0 100.662460 lr 0.00084139 rank 0
2022-08-24 08:39:28,534 WARNING NaN or Inf found in input tensor.
2022-08-24 08:39:55,139 DEBUG TRAIN Batch 99/2000 loss 49.594219 loss_att 31.287121 loss_ctc 92.310783 loss_ctc_origin 53.282860 loss_ctc0 183.375931 lr 0.00084132 rank 0
2022-08-24 08:40:23,328 DEBUG TRAIN Batch 99/2100 loss 64.988495 loss_att 38.554504 loss_ctc 126.667809 loss_ctc_origin 71.293892 loss_ctc0 255.873611 lr 0.00084125 rank 0
2022-08-24 08:40:51,210 DEBUG TRAIN Batch 99/2200 loss 24.886761 loss_att 14.373171 loss_ctc 49.418472 loss_ctc_origin 38.134670 loss_ctc0 75.747345 lr 0.00084117 rank 0
2022-08-24 08:41:19,336 DEBUG TRAIN Batch 99/2300 loss 25.218685 loss_att 10.996710 loss_ctc 58.403290 loss_ctc_origin 44.289421 loss_ctc0 91.335648 lr 0.00084110 rank 0
2022-08-24 08:41:48,620 DEBUG TRAIN Batch 99/2400 loss 26.374809 loss_att 11.952148 loss_ctc 60.027679 loss_ctc_origin 44.560341 loss_ctc0 96.118141 lr 0.00084102 rank 0
2022-08-24 08:41:51,358 WARNING NaN or Inf found in input tensor.
2022-08-24 08:42:17,480 DEBUG TRAIN Batch 99/2500 loss 46.586182 loss_att 31.642090 loss_ctc 81.455734 loss_ctc_origin 49.177006 loss_ctc0 156.772766 lr 0.00084095 rank 0
2022-08-24 08:42:45,374 DEBUG TRAIN Batch 99/2600 loss 59.402626 loss_att 35.462181 loss_ctc 115.263672 loss_ctc_origin 64.579071 loss_ctc0 233.527710 lr 0.00084087 rank 0
2022-08-24 08:43:13,297 DEBUG TRAIN Batch 99/2700 loss 25.442078 loss_att 14.423712 loss_ctc 51.151596 loss_ctc_origin 41.191906 loss_ctc0 74.390869 lr 0.00084080 rank 0
2022-08-24 08:43:41,928 DEBUG TRAIN Batch 99/2800 loss 25.813154 loss_att 12.883465 loss_ctc 55.982426 loss_ctc_origin 41.497833 loss_ctc0 89.779808 lr 0.00084073 rank 0
2022-08-24 08:44:09,518 DEBUG TRAIN Batch 99/2900 loss 21.209356 loss_att 9.403844 loss_ctc 48.755550 loss_ctc_origin 31.388943 loss_ctc0 89.277634 lr 0.00084065 rank 0
2022-08-24 08:44:43,697 DEBUG TRAIN Batch 99/3000 loss 43.504021 loss_att 27.496517 loss_ctc 80.854866 loss_ctc_origin 44.593891 loss_ctc0 165.463806 lr 0.00084058 rank 0
2022-08-24 08:45:11,429 DEBUG TRAIN Batch 99/3100 loss 56.150955 loss_att 31.691132 loss_ctc 113.223877 loss_ctc_origin 59.261551 loss_ctc0 239.135971 lr 0.00084050 rank 0
2022-08-24 08:45:39,171 DEBUG TRAIN Batch 99/3200 loss 24.229460 loss_att 14.144091 loss_ctc 47.761986 loss_ctc_origin 36.071159 loss_ctc0 75.040588 lr 0.00084043 rank 0
2022-08-24 08:46:07,241 DEBUG TRAIN Batch 99/3300 loss 21.482300 loss_att 10.766687 loss_ctc 46.485390 loss_ctc_origin 32.350708 loss_ctc0 79.466309 lr 0.00084035 rank 0
2022-08-24 08:46:35,436 DEBUG TRAIN Batch 99/3400 loss 21.214344 loss_att 9.462785 loss_ctc 48.634651 loss_ctc_origin 30.522217 loss_ctc0 90.896988 lr 0.00084028 rank 0
2022-08-24 08:47:04,217 DEBUG TRAIN Batch 99/3500 loss 45.637230 loss_att 28.929127 loss_ctc 84.622803 loss_ctc_origin 49.687710 loss_ctc0 166.138016 lr 0.00084021 rank 0
2022-08-24 08:47:30,733 DEBUG TRAIN Batch 99/3600 loss 42.294617 loss_att 24.522419 loss_ctc 83.763069 loss_ctc_origin 45.088547 loss_ctc0 174.003601 lr 0.00084013 rank 0
2022-08-24 08:47:58,621 DEBUG TRAIN Batch 99/3700 loss 20.026062 loss_att 9.704877 loss_ctc 44.108826 loss_ctc_origin 32.206028 loss_ctc0 71.882019 lr 0.00084006 rank 0
2022-08-24 08:48:27,043 DEBUG TRAIN Batch 99/3800 loss 25.246262 loss_att 10.970438 loss_ctc 58.556519 loss_ctc_origin 47.163097 loss_ctc0 85.141167 lr 0.00083998 rank 0
2022-08-24 08:48:52,035 WARNING NaN or Inf found in input tensor.
2022-08-24 08:48:56,526 DEBUG TRAIN Batch 99/3900 loss 22.852791 loss_att 10.447737 loss_ctc 51.797913 loss_ctc_origin 33.433586 loss_ctc0 94.648010 lr 0.00083991 rank 0
2022-08-24 08:49:25,012 DEBUG TRAIN Batch 99/4000 loss 43.194855 loss_att 29.224525 loss_ctc 75.792297 loss_ctc_origin 47.243610 loss_ctc0 142.405914 lr 0.00083984 rank 0
2022-08-24 08:49:52,553 DEBUG TRAIN Batch 99/4100 loss 48.576714 loss_att 28.087456 loss_ctc 96.384979 loss_ctc_origin 62.353214 loss_ctc0 175.792419 lr 0.00083976 rank 0
2022-08-24 08:50:20,675 DEBUG TRAIN Batch 99/4200 loss 21.541231 loss_att 12.521482 loss_ctc 42.587311 loss_ctc_origin 31.062428 loss_ctc0 69.478714 lr 0.00083969 rank 0
2022-08-24 08:50:48,241 DEBUG TRAIN Batch 99/4300 loss 20.737301 loss_att 9.397355 loss_ctc 47.197174 loss_ctc_origin 33.384331 loss_ctc0 79.427139 lr 0.00083961 rank 0
2022-08-24 08:51:17,517 DEBUG TRAIN Batch 99/4400 loss 28.628796 loss_att 13.306627 loss_ctc 64.380524 loss_ctc_origin 47.843189 loss_ctc0 102.967636 lr 0.00083954 rank 0
2022-08-24 08:51:51,406 DEBUG TRAIN Batch 99/4500 loss 45.847221 loss_att 30.925432 loss_ctc 80.664719 loss_ctc_origin 53.117870 loss_ctc0 144.940674 lr 0.00083947 rank 0
2022-08-24 08:52:20,395 DEBUG TRAIN Batch 99/4600 loss 46.210350 loss_att 28.924597 loss_ctc 86.543777 loss_ctc_origin 55.722153 loss_ctc0 158.460907 lr 0.00083939 rank 0
2022-08-24 08:52:49,250 DEBUG TRAIN Batch 99/4700 loss 18.452370 loss_att 10.475634 loss_ctc 37.064751 loss_ctc_origin 26.102661 loss_ctc0 62.642967 lr 0.00083932 rank 0
2022-08-24 08:53:17,001 DEBUG TRAIN Batch 99/4800 loss 23.303085 loss_att 10.518953 loss_ctc 53.132725 loss_ctc_origin 39.037720 loss_ctc0 86.021072 lr 0.00083924 rank 0
2022-08-24 08:53:46,252 DEBUG TRAIN Batch 99/4900 loss 25.211828 loss_att 11.000008 loss_ctc 58.372742 loss_ctc_origin 40.880127 loss_ctc0 99.188843 lr 0.00083917 rank 0
2022-08-24 08:54:17,008 DEBUG TRAIN Batch 99/5000 loss 42.747437 loss_att 27.590721 loss_ctc 78.113098 loss_ctc_origin 45.751984 loss_ctc0 153.622360 lr 0.00083910 rank 0
2022-08-24 08:54:46,143 DEBUG TRAIN Batch 99/5100 loss 54.601738 loss_att 32.343601 loss_ctc 106.537384 loss_ctc_origin 69.235176 loss_ctc0 193.575867 lr 0.00083902 rank 0
2022-08-24 08:55:14,802 DEBUG TRAIN Batch 99/5200 loss 23.022717 loss_att 13.876242 loss_ctc 44.364487 loss_ctc_origin 34.224770 loss_ctc0 68.023827 lr 0.00083895 rank 0
2022-08-24 08:55:43,595 DEBUG TRAIN Batch 99/5300 loss 22.078413 loss_att 12.132982 loss_ctc 45.284416 loss_ctc_origin 32.749405 loss_ctc0 74.532768 lr 0.00083887 rank 0
2022-08-24 08:56:13,163 DEBUG TRAIN Batch 99/5400 loss 20.897280 loss_att 10.112709 loss_ctc 46.061279 loss_ctc_origin 30.875572 loss_ctc0 81.494598 lr 0.00083880 rank 0
2022-08-24 08:56:41,760 DEBUG TRAIN Batch 99/5500 loss 50.754616 loss_att 34.569740 loss_ctc 88.519318 loss_ctc_origin 52.531219 loss_ctc0 172.491547 lr 0.00083873 rank 0
2022-08-24 08:57:10,360 DEBUG TRAIN Batch 99/5600 loss 54.005707 loss_att 32.343853 loss_ctc 104.550018 loss_ctc_origin 57.222252 loss_ctc0 214.981445 lr 0.00083865 rank 0
2022-08-24 08:57:33,706 DEBUG CV Batch 99/0 loss 14.906307 loss_att 11.483429 loss_ctc 22.893024 loss_ctc_origin 16.488619 loss_ctc0 37.836639 history loss 14.029466 rank 0
2022-08-24 08:57:44,166 DEBUG CV Batch 99/100 loss 25.549347 loss_att 20.330511 loss_ctc 37.726627 loss_ctc_origin 26.993504 loss_ctc0 62.770580 history loss 28.819720 rank 0
2022-08-24 08:57:53,703 DEBUG CV Batch 99/200 loss 24.508211 loss_att 18.871359 loss_ctc 37.660866 loss_ctc_origin 27.037849 loss_ctc0 62.447906 history loss 30.372502 rank 0
2022-08-24 08:58:03,631 DEBUG CV Batch 99/300 loss 24.360804 loss_att 18.293291 loss_ctc 38.518333 loss_ctc_origin 23.381111 loss_ctc0 73.838516 history loss 29.491123 rank 0
2022-08-24 08:58:13,920 DEBUG CV Batch 99/400 loss 39.452709 loss_att 31.860676 loss_ctc 57.167450 loss_ctc_origin 40.238449 loss_ctc0 96.668442 history loss 27.814127 rank 0
2022-08-24 08:58:24,663 DEBUG CV Batch 99/500 loss 18.493561 loss_att 14.106029 loss_ctc 28.731133 loss_ctc_origin 22.458063 loss_ctc0 43.368298 history loss 27.488906 rank 0
2022-08-24 08:58:35,180 DEBUG CV Batch 99/600 loss 21.177952 loss_att 14.996561 loss_ctc 35.601196 loss_ctc_origin 25.361723 loss_ctc0 59.493305 history loss 27.359950 rank 0
2022-08-24 08:58:45,158 DEBUG CV Batch 99/700 loss 19.553158 loss_att 13.304793 loss_ctc 34.132675 loss_ctc_origin 20.828510 loss_ctc0 65.175720 history loss 26.998813 rank 0
2022-08-24 08:58:55,723 DEBUG CV Batch 99/800 loss 23.538256 loss_att 18.222040 loss_ctc 35.942757 loss_ctc_origin 20.828691 loss_ctc0 71.208908 history loss 26.931847 rank 0
2022-08-24 08:59:06,152 INFO Epoch 99 CV info cv_loss 26.974343504419444
2022-08-24 08:59:06,153 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/99.pt
2022-08-24 08:59:06,590 INFO Epoch 100 TRAIN info lr 0.0008385910090443794
2022-08-24 08:59:06,594 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 08:59:33,312 DEBUG TRAIN Batch 100/0 loss 39.020378 loss_att 25.768000 loss_ctc 69.942589 loss_ctc_origin 39.567116 loss_ctc0 140.818695 lr 0.00083859 rank 0
2022-08-24 09:00:03,296 DEBUG TRAIN Batch 100/100 loss 48.771721 loss_att 31.801720 loss_ctc 88.368385 loss_ctc_origin 58.685104 loss_ctc0 157.629379 lr 0.00083851 rank 0
2022-08-24 09:00:32,102 DEBUG TRAIN Batch 100/200 loss 21.504272 loss_att 12.047583 loss_ctc 43.569885 loss_ctc_origin 32.774605 loss_ctc0 68.758881 lr 0.00083844 rank 0
2022-08-24 09:00:59,920 DEBUG TRAIN Batch 100/300 loss 25.116488 loss_att 11.342232 loss_ctc 57.256416 loss_ctc_origin 45.542015 loss_ctc0 84.590012 lr 0.00083837 rank 0
2022-08-24 09:01:29,550 DEBUG TRAIN Batch 100/400 loss 25.044094 loss_att 11.803574 loss_ctc 55.938637 loss_ctc_origin 40.061241 loss_ctc0 92.985901 lr 0.00083829 rank 0
2022-08-24 09:01:58,598 DEBUG TRAIN Batch 100/500 loss 44.337788 loss_att 30.660913 loss_ctc 76.250496 loss_ctc_origin 50.788586 loss_ctc0 135.661621 lr 0.00083822 rank 0
2022-08-24 09:02:27,948 DEBUG TRAIN Batch 100/600 loss 46.628067 loss_att 29.505287 loss_ctc 86.581215 loss_ctc_origin 57.463554 loss_ctc0 154.522415 lr 0.00083815 rank 0
2022-08-24 09:02:56,107 DEBUG TRAIN Batch 100/700 loss 19.604050 loss_att 8.357860 loss_ctc 45.845158 loss_ctc_origin 35.847549 loss_ctc0 69.172905 lr 0.00083807 rank 0
2022-08-24 09:03:25,580 DEBUG TRAIN Batch 100/800 loss 21.679029 loss_att 9.869902 loss_ctc 49.233658 loss_ctc_origin 34.130211 loss_ctc0 84.475021 lr 0.00083800 rank 0
2022-08-24 09:03:55,536 DEBUG TRAIN Batch 100/900 loss 20.560371 loss_att 8.294784 loss_ctc 49.180077 loss_ctc_origin 30.301212 loss_ctc0 93.230766 lr 0.00083793 rank 0
2022-08-24 09:04:23,713 DEBUG TRAIN Batch 100/1000 loss 36.751671 loss_att 24.388386 loss_ctc 65.599342 loss_ctc_origin 36.890209 loss_ctc0 132.587311 lr 0.00083785 rank 0
2022-08-24 09:04:52,499 DEBUG TRAIN Batch 100/1100 loss 47.161781 loss_att 26.680698 loss_ctc 94.950974 loss_ctc_origin 60.808372 loss_ctc0 174.617035 lr 0.00083778 rank 0
2022-08-24 09:05:20,898 DEBUG TRAIN Batch 100/1200 loss 24.621147 loss_att 14.176555 loss_ctc 48.991859 loss_ctc_origin 40.671627 loss_ctc0 68.405731 lr 0.00083770 rank 0
2022-08-24 09:05:50,687 DEBUG TRAIN Batch 100/1300 loss 18.391678 loss_att 8.422850 loss_ctc 41.652275 loss_ctc_origin 27.226603 loss_ctc0 75.312180 lr 0.00083763 rank 0
2022-08-24 09:06:23,632 DEBUG TRAIN Batch 100/1400 loss 24.593540 loss_att 10.222176 loss_ctc 58.126720 loss_ctc_origin 39.599480 loss_ctc0 101.356949 lr 0.00083756 rank 0
2022-08-24 09:07:07,874 DEBUG TRAIN Batch 100/1500 loss 45.732903 loss_att 29.492054 loss_ctc 83.628220 loss_ctc_origin 49.357700 loss_ctc0 163.592758 lr 0.00083748 rank 0
2022-08-24 09:07:43,820 DEBUG TRAIN Batch 100/1600 loss 43.624271 loss_att 25.013477 loss_ctc 87.049454 loss_ctc_origin 50.818481 loss_ctc0 171.588379 lr 0.00083741 rank 0
2022-08-24 09:08:19,659 DEBUG TRAIN Batch 100/1700 loss 18.517073 loss_att 9.936326 loss_ctc 38.538815 loss_ctc_origin 28.010078 loss_ctc0 63.105869 lr 0.00083734 rank 0
2022-08-24 09:08:56,306 DEBUG TRAIN Batch 100/1800 loss 22.834812 loss_att 11.495529 loss_ctc 49.293137 loss_ctc_origin 33.864784 loss_ctc0 85.292625 lr 0.00083726 rank 0
2022-08-24 09:09:28,071 DEBUG TRAIN Batch 100/1900 loss 29.779341 loss_att 14.302518 loss_ctc 65.891922 loss_ctc_origin 49.633392 loss_ctc0 103.828499 lr 0.00083719 rank 0
2022-08-24 09:09:58,324 DEBUG TRAIN Batch 100/2000 loss 47.597061 loss_att 31.250839 loss_ctc 85.738235 loss_ctc_origin 48.207214 loss_ctc0 173.310608 lr 0.00083712 rank 0
2022-08-24 09:10:33,571 DEBUG TRAIN Batch 100/2100 loss 60.635006 loss_att 37.938957 loss_ctc 113.592453 loss_ctc_origin 70.289009 loss_ctc0 214.633820 lr 0.00083704 rank 0
2022-08-24 09:11:07,487 WARNING NaN or Inf found in input tensor.
2022-08-24 09:11:09,351 DEBUG TRAIN Batch 100/2200 loss 26.298286 loss_att 15.449125 loss_ctc 51.612999 loss_ctc_origin 41.909077 loss_ctc0 74.255486 lr 0.00083697 rank 0
2022-08-24 09:11:15,644 WARNING NaN or Inf found in input tensor.
2022-08-24 09:11:46,096 DEBUG TRAIN Batch 100/2300 loss 17.196320 loss_att 7.861042 loss_ctc 38.978630 loss_ctc_origin 24.847771 loss_ctc0 71.950638 lr 0.00083690 rank 0
2022-08-24 09:12:22,471 DEBUG TRAIN Batch 100/2400 loss 26.855755 loss_att 13.976872 loss_ctc 56.906475 loss_ctc_origin 41.408066 loss_ctc0 93.069427 lr 0.00083682 rank 0
2022-08-24 09:12:57,670 DEBUG TRAIN Batch 100/2500 loss 48.372391 loss_att 31.254835 loss_ctc 88.313354 loss_ctc_origin 53.921066 loss_ctc0 168.562012 lr 0.00083675 rank 0
2022-08-24 09:13:29,788 DEBUG TRAIN Batch 100/2600 loss 57.728771 loss_att 35.248413 loss_ctc 110.182930 loss_ctc_origin 65.339790 loss_ctc0 214.816910 lr 0.00083668 rank 0
2022-08-24 09:13:59,992 DEBUG TRAIN Batch 100/2700 loss 18.962336 loss_att 8.945740 loss_ctc 42.334393 loss_ctc_origin 29.344109 loss_ctc0 72.645050 lr 0.00083660 rank 0
2022-08-24 09:14:32,171 DEBUG TRAIN Batch 100/2800 loss 22.896580 loss_att 10.356533 loss_ctc 52.156685 loss_ctc_origin 38.364128 loss_ctc0 84.339325 lr 0.00083653 rank 0
2022-08-24 09:15:02,888 DEBUG TRAIN Batch 100/2900 loss 27.517647 loss_att 12.270684 loss_ctc 63.093891 loss_ctc_origin 47.185314 loss_ctc0 100.213898 lr 0.00083646 rank 0
2022-08-24 09:15:41,980 DEBUG TRAIN Batch 100/3000 loss 41.728149 loss_att 24.650822 loss_ctc 81.575249 loss_ctc_origin 46.543583 loss_ctc0 163.315796 lr 0.00083639 rank 0
2022-08-24 09:16:13,209 DEBUG TRAIN Batch 100/3100 loss 60.087486 loss_att 39.693848 loss_ctc 107.672630 loss_ctc_origin 73.573959 loss_ctc0 187.236191 lr 0.00083631 rank 0
2022-08-24 09:16:42,835 WARNING NaN or Inf found in input tensor.
2022-08-24 09:16:44,537 DEBUG TRAIN Batch 100/3200 loss 19.039177 loss_att 10.592711 loss_ctc 38.747597 loss_ctc_origin 26.653706 loss_ctc0 66.966675 lr 0.00083624 rank 0
2022-08-24 09:17:15,384 DEBUG TRAIN Batch 100/3300 loss 20.738239 loss_att 9.556975 loss_ctc 46.827850 loss_ctc_origin 32.733421 loss_ctc0 79.714844 lr 0.00083617 rank 0
2022-08-24 09:17:45,582 DEBUG TRAIN Batch 100/3400 loss 23.706699 loss_att 10.080156 loss_ctc 55.501968 loss_ctc_origin 38.667522 loss_ctc0 94.782333 lr 0.00083609 rank 0
2022-08-24 09:18:16,189 DEBUG TRAIN Batch 100/3500 loss 51.881874 loss_att 35.238316 loss_ctc 90.716843 loss_ctc_origin 56.880451 loss_ctc0 169.668427 lr 0.00083602 rank 0
2022-08-24 09:18:46,524 DEBUG TRAIN Batch 100/3600 loss 62.784180 loss_att 36.711906 loss_ctc 123.619476 loss_ctc_origin 77.727287 loss_ctc0 230.701263 lr 0.00083595 rank 0
2022-08-24 09:19:17,124 DEBUG TRAIN Batch 100/3700 loss 21.930302 loss_att 11.447191 loss_ctc 46.390892 loss_ctc_origin 34.716637 loss_ctc0 73.630814 lr 0.00083587 rank 0
2022-08-24 09:19:48,278 DEBUG TRAIN Batch 100/3800 loss 22.436226 loss_att 10.481735 loss_ctc 50.330032 loss_ctc_origin 36.732941 loss_ctc0 82.056572 lr 0.00083580 rank 0
2022-08-24 09:20:20,149 DEBUG TRAIN Batch 100/3900 loss 23.786343 loss_att 11.359426 loss_ctc 52.782478 loss_ctc_origin 34.056591 loss_ctc0 96.476212 lr 0.00083573 rank 0
2022-08-24 09:20:50,317 DEBUG TRAIN Batch 100/4000 loss 57.418144 loss_att 41.709438 loss_ctc 94.071793 loss_ctc_origin 61.133980 loss_ctc0 170.926682 lr 0.00083565 rank 0
2022-08-24 09:21:21,613 DEBUG TRAIN Batch 100/4100 loss 58.872093 loss_att 34.731186 loss_ctc 115.200874 loss_ctc_origin 67.629395 loss_ctc0 226.200974 lr 0.00083558 rank 0
2022-08-24 09:21:53,080 DEBUG TRAIN Batch 100/4200 loss 23.080917 loss_att 14.889441 loss_ctc 42.194359 loss_ctc_origin 31.982868 loss_ctc0 66.021164 lr 0.00083551 rank 0
2022-08-24 09:22:25,340 DEBUG TRAIN Batch 100/4300 loss 24.089314 loss_att 11.580256 loss_ctc 53.277115 loss_ctc_origin 39.819801 loss_ctc0 84.677513 lr 0.00083544 rank 0
2022-08-24 09:22:44,324 WARNING NaN or Inf found in input tensor.
2022-08-24 09:22:56,925 DEBUG TRAIN Batch 100/4400 loss 25.092182 loss_att 12.148975 loss_ctc 55.292999 loss_ctc_origin 36.168736 loss_ctc0 99.916275 lr 0.00083536 rank 0
2022-08-24 09:23:06,318 WARNING NaN or Inf found in input tensor.
2022-08-24 09:23:35,212 DEBUG TRAIN Batch 100/4500 loss 45.246613 loss_att 30.753084 loss_ctc 79.064850 loss_ctc_origin 48.622837 loss_ctc0 150.096222 lr 0.00083529 rank 0
2022-08-24 09:24:06,748 DEBUG TRAIN Batch 100/4600 loss 63.908825 loss_att 39.982708 loss_ctc 119.736427 loss_ctc_origin 73.463364 loss_ctc0 227.706909 lr 0.00083522 rank 0
2022-08-24 09:24:37,676 DEBUG TRAIN Batch 100/4700 loss 21.417625 loss_att 13.670808 loss_ctc 39.493534 loss_ctc_origin 29.716099 loss_ctc0 62.307549 lr 0.00083514 rank 0
2022-08-24 09:25:09,131 DEBUG TRAIN Batch 100/4800 loss 21.818562 loss_att 10.615412 loss_ctc 47.959244 loss_ctc_origin 34.691406 loss_ctc0 78.917542 lr 0.00083507 rank 0
2022-08-24 09:25:40,748 DEBUG TRAIN Batch 100/4900 loss 27.650631 loss_att 13.551336 loss_ctc 60.548981 loss_ctc_origin 45.398865 loss_ctc0 95.899246 lr 0.00083500 rank 0
2022-08-24 09:26:12,628 DEBUG TRAIN Batch 100/5000 loss 41.869621 loss_att 23.144562 loss_ctc 85.561432 loss_ctc_origin 45.412598 loss_ctc0 179.242035 lr 0.00083493 rank 0
2022-08-24 09:26:44,780 DEBUG TRAIN Batch 100/5100 loss 72.626434 loss_att 45.471149 loss_ctc 135.988770 loss_ctc_origin 89.065399 loss_ctc0 245.476624 lr 0.00083485 rank 0
2022-08-24 09:27:15,381 DEBUG TRAIN Batch 100/5200 loss 25.109337 loss_att 13.874231 loss_ctc 51.324585 loss_ctc_origin 41.612373 loss_ctc0 73.986404 lr 0.00083478 rank 0
2022-08-24 09:27:46,681 DEBUG TRAIN Batch 100/5300 loss 20.902348 loss_att 9.954598 loss_ctc 46.447090 loss_ctc_origin 33.357292 loss_ctc0 76.989944 lr 0.00083471 rank 0
2022-08-24 09:28:18,718 DEBUG TRAIN Batch 100/5400 loss 26.919954 loss_att 13.262879 loss_ctc 58.786457 loss_ctc_origin 42.264374 loss_ctc0 97.337982 lr 0.00083464 rank 0
2022-08-24 09:28:50,110 DEBUG TRAIN Batch 100/5500 loss 30.384104 loss_att 21.134380 loss_ctc 51.966789 loss_ctc_origin 32.587715 loss_ctc0 97.184631 lr 0.00083456 rank 0
2022-08-24 09:29:13,298 WARNING NaN or Inf found in input tensor.
2022-08-24 09:29:20,946 DEBUG TRAIN Batch 100/5600 loss 36.625504 loss_att 21.863449 loss_ctc 71.070297 loss_ctc_origin 45.079094 loss_ctc0 131.716431 lr 0.00083449 rank 0
2022-08-24 09:29:45,990 DEBUG CV Batch 100/0 loss 12.075451 loss_att 8.650406 loss_ctc 20.067223 loss_ctc_origin 12.667331 loss_ctc0 37.333641 history loss 11.365130 rank 0
2022-08-24 09:29:58,010 DEBUG CV Batch 100/100 loss 25.679031 loss_att 19.693275 loss_ctc 39.645798 loss_ctc_origin 29.728952 loss_ctc0 62.785110 history loss 28.607474 rank 0
2022-08-24 09:30:09,131 DEBUG CV Batch 100/200 loss 26.426369 loss_att 20.046503 loss_ctc 41.312721 loss_ctc_origin 31.342999 loss_ctc0 64.575401 history loss 30.350539 rank 0
2022-08-24 09:30:20,061 DEBUG CV Batch 100/300 loss 24.537374 loss_att 18.335253 loss_ctc 39.008991 loss_ctc_origin 23.718437 loss_ctc0 74.686951 history loss 29.282020 rank 0
2022-08-24 09:30:31,809 DEBUG CV Batch 100/400 loss 38.809662 loss_att 31.608437 loss_ctc 55.612518 loss_ctc_origin 37.955437 loss_ctc0 96.812363 history loss 27.661939 rank 0
2022-08-24 09:30:44,083 DEBUG CV Batch 100/500 loss 18.515156 loss_att 13.896761 loss_ctc 29.291409 loss_ctc_origin 23.004614 loss_ctc0 43.960594 history loss 27.276682 rank 0
2022-08-24 09:30:55,923 DEBUG CV Batch 100/600 loss 21.855345 loss_att 15.383696 loss_ctc 36.955856 loss_ctc_origin 25.431122 loss_ctc0 63.846897 history loss 27.130816 rank 0
2022-08-24 09:31:07,308 DEBUG CV Batch 100/700 loss 19.122162 loss_att 12.697595 loss_ctc 34.112816 loss_ctc_origin 20.530514 loss_ctc0 65.804855 history loss 26.754440 rank 0
2022-08-24 09:31:18,864 DEBUG CV Batch 100/800 loss 22.668015 loss_att 17.008339 loss_ctc 35.873928 loss_ctc_origin 20.442207 loss_ctc0 71.881271 history loss 26.687054 rank 0
2022-08-24 09:31:29,809 INFO Epoch 100 CV info cv_loss 26.711286384911084
2022-08-24 09:31:29,810 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/100.pt
2022-08-24 09:31:30,271 INFO Epoch 101 TRAIN info lr 0.0008344292413748788
2022-08-24 09:31:30,274 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 09:31:58,246 DEBUG TRAIN Batch 101/0 loss 28.319963 loss_att 18.043198 loss_ctc 52.299080 loss_ctc_origin 32.384483 loss_ctc0 98.766472 lr 0.00083443 rank 0
2022-08-24 09:32:27,832 DEBUG TRAIN Batch 101/100 loss 48.071587 loss_att 27.498959 loss_ctc 96.074379 loss_ctc_origin 63.692097 loss_ctc0 171.633026 lr 0.00083435 rank 0
2022-08-24 09:32:56,950 DEBUG TRAIN Batch 101/200 loss 22.470848 loss_att 13.339973 loss_ctc 43.776222 loss_ctc_origin 33.856812 loss_ctc0 66.921509 lr 0.00083428 rank 0
2022-08-24 09:33:26,850 DEBUG TRAIN Batch 101/300 loss 21.850077 loss_att 10.448296 loss_ctc 48.454231 loss_ctc_origin 35.709099 loss_ctc0 78.192871 lr 0.00083421 rank 0
2022-08-24 09:33:54,362 DEBUG TRAIN Batch 101/400 loss 23.934210 loss_att 10.633248 loss_ctc 54.969784 loss_ctc_origin 38.355274 loss_ctc0 93.736969 lr 0.00083414 rank 0
2022-08-24 09:34:23,584 DEBUG TRAIN Batch 101/500 loss 44.114239 loss_att 29.583181 loss_ctc 78.020035 loss_ctc_origin 49.478989 loss_ctc0 144.615814 lr 0.00083406 rank 0
2022-08-24 09:34:51,361 DEBUG TRAIN Batch 101/600 loss 52.972733 loss_att 31.655014 loss_ctc 102.714066 loss_ctc_origin 64.325928 loss_ctc0 192.286392 lr 0.00083399 rank 0
2022-08-24 09:35:18,097 WARNING NaN or Inf found in input tensor.
2022-08-24 09:35:19,753 DEBUG TRAIN Batch 101/700 loss 20.369947 loss_att 11.564884 loss_ctc 40.915092 loss_ctc_origin 27.982647 loss_ctc0 71.090805 lr 0.00083392 rank 0
2022-08-24 09:35:48,962 DEBUG TRAIN Batch 101/800 loss 22.765812 loss_att 10.436434 loss_ctc 51.534363 loss_ctc_origin 37.211082 loss_ctc0 84.955338 lr 0.00083385 rank 0
2022-08-24 09:36:17,889 DEBUG TRAIN Batch 101/900 loss 23.835354 loss_att 10.282071 loss_ctc 55.459679 loss_ctc_origin 38.107258 loss_ctc0 95.948654 lr 0.00083377 rank 0
2022-08-24 09:36:34,031 WARNING NaN or Inf found in input tensor.
2022-08-24 09:36:46,457 DEBUG TRAIN Batch 101/1000 loss 45.701424 loss_att 30.721687 loss_ctc 80.654137 loss_ctc_origin 53.198746 loss_ctc0 144.716721 lr 0.00083370 rank 0
2022-08-24 09:36:47,119 WARNING NaN or Inf found in input tensor.
2022-08-24 09:37:13,750 DEBUG TRAIN Batch 101/1100 loss 46.426311 loss_att 29.414955 loss_ctc 86.119476 loss_ctc_origin 56.489540 loss_ctc0 155.255997 lr 0.00083363 rank 0
2022-08-24 09:37:40,927 DEBUG TRAIN Batch 101/1200 loss 23.026768 loss_att 13.599581 loss_ctc 45.023533 loss_ctc_origin 35.657990 loss_ctc0 66.876465 lr 0.00083356 rank 0
2022-08-24 09:38:09,020 DEBUG TRAIN Batch 101/1300 loss 21.835197 loss_att 9.596857 loss_ctc 50.391323 loss_ctc_origin 36.510567 loss_ctc0 82.779755 lr 0.00083348 rank 0
2022-08-24 09:38:36,747 DEBUG TRAIN Batch 101/1400 loss 26.291019 loss_att 12.288465 loss_ctc 58.963642 loss_ctc_origin 41.659592 loss_ctc0 99.339752 lr 0.00083341 rank 0
2022-08-24 09:39:09,913 DEBUG TRAIN Batch 101/1500 loss 44.884727 loss_att 28.072567 loss_ctc 84.113106 loss_ctc_origin 50.726791 loss_ctc0 162.014496 lr 0.00083334 rank 0
2022-08-24 09:39:37,375 DEBUG TRAIN Batch 101/1600 loss 45.899155 loss_att 30.363480 loss_ctc 82.149055 loss_ctc_origin 55.882339 loss_ctc0 143.438049 lr 0.00083327 rank 0
2022-08-24 09:40:04,285 DEBUG TRAIN Batch 101/1700 loss 20.978455 loss_att 11.671297 loss_ctc 42.695152 loss_ctc_origin 31.920853 loss_ctc0 67.835175 lr 0.00083319 rank 0
2022-08-24 09:40:31,746 DEBUG TRAIN Batch 101/1800 loss 23.909801 loss_att 10.480610 loss_ctc 55.244576 loss_ctc_origin 41.650082 loss_ctc0 86.965057 lr 0.00083312 rank 0
2022-08-24 09:40:35,550 WARNING NaN or Inf found in input tensor.
2022-08-24 09:40:54,683 WARNING NaN or Inf found in input tensor.
2022-08-24 09:40:59,239 DEBUG TRAIN Batch 101/1900 loss 24.642151 loss_att 10.957845 loss_ctc 56.572197 loss_ctc_origin 41.330116 loss_ctc0 92.137054 lr 0.00083305 rank 0
2022-08-24 09:41:26,375 DEBUG TRAIN Batch 101/2000 loss 42.868225 loss_att 28.361416 loss_ctc 76.717453 loss_ctc_origin 43.676186 loss_ctc0 153.813751 lr 0.00083298 rank 0
2022-08-24 09:41:34,215 WARNING NaN or Inf found in input tensor.
2022-08-24 09:41:53,233 DEBUG TRAIN Batch 101/2100 loss 44.335831 loss_att 23.511383 loss_ctc 92.926208 loss_ctc_origin 52.708767 loss_ctc0 186.766907 lr 0.00083291 rank 0
2022-08-24 09:42:21,285 DEBUG TRAIN Batch 101/2200 loss 21.585438 loss_att 13.140976 loss_ctc 41.289185 loss_ctc_origin 31.963623 loss_ctc0 63.048817 lr 0.00083283 rank 0
2022-08-24 09:42:49,990 DEBUG TRAIN Batch 101/2300 loss 22.507730 loss_att 10.044588 loss_ctc 51.588394 loss_ctc_origin 38.406822 loss_ctc0 82.345398 lr 0.00083276 rank 0
2022-08-24 09:43:17,666 DEBUG TRAIN Batch 101/2400 loss 25.134487 loss_att 10.994100 loss_ctc 58.128723 loss_ctc_origin 40.019646 loss_ctc0 100.383240 lr 0.00083269 rank 0
2022-08-24 09:43:46,000 DEBUG TRAIN Batch 101/2500 loss 43.440517 loss_att 29.280224 loss_ctc 76.481201 loss_ctc_origin 48.348625 loss_ctc0 142.123871 lr 0.00083262 rank 0
2022-08-24 09:44:13,917 DEBUG TRAIN Batch 101/2600 loss 49.366470 loss_att 31.916992 loss_ctc 90.081924 loss_ctc_origin 60.781136 loss_ctc0 158.450439 lr 0.00083254 rank 0
2022-08-24 09:44:41,465 DEBUG TRAIN Batch 101/2700 loss 23.260712 loss_att 14.642239 loss_ctc 43.370476 loss_ctc_origin 32.299744 loss_ctc0 69.202179 lr 0.00083247 rank 0
2022-08-24 09:45:08,711 DEBUG TRAIN Batch 101/2800 loss 20.732964 loss_att 9.780664 loss_ctc 46.288330 loss_ctc_origin 30.054144 loss_ctc0 84.168091 lr 0.00083240 rank 0
2022-08-24 09:45:31,855 WARNING NaN or Inf found in input tensor.
2022-08-24 09:45:36,027 DEBUG TRAIN Batch 101/2900 loss 24.776716 loss_att 10.460228 loss_ctc 58.181854 loss_ctc_origin 41.972191 loss_ctc0 96.004395 lr 0.00083233 rank 0
2022-08-24 09:46:09,765 DEBUG TRAIN Batch 101/3000 loss 43.112061 loss_att 28.583580 loss_ctc 77.011841 loss_ctc_origin 45.522232 loss_ctc0 150.487579 lr 0.00083226 rank 0
2022-08-24 09:46:38,003 DEBUG TRAIN Batch 101/3100 loss 46.032738 loss_att 25.795895 loss_ctc 93.252029 loss_ctc_origin 55.966705 loss_ctc0 180.251114 lr 0.00083218 rank 0
2022-08-24 09:47:03,752 WARNING NaN or Inf found in input tensor.
2022-08-24 09:47:05,336 DEBUG TRAIN Batch 101/3200 loss 19.483459 loss_att 9.379435 loss_ctc 43.059513 loss_ctc_origin 31.664373 loss_ctc0 69.648170 lr 0.00083211 rank 0
2022-08-24 09:47:32,101 DEBUG TRAIN Batch 101/3300 loss 23.526493 loss_att 11.043217 loss_ctc 52.654133 loss_ctc_origin 39.264748 loss_ctc0 83.896027 lr 0.00083204 rank 0
2022-08-24 09:48:00,053 DEBUG TRAIN Batch 101/3400 loss 28.603573 loss_att 13.936356 loss_ctc 62.827080 loss_ctc_origin 46.875080 loss_ctc0 100.048409 lr 0.00083197 rank 0
2022-08-24 09:48:28,644 DEBUG TRAIN Batch 101/3500 loss 41.776455 loss_att 26.930986 loss_ctc 76.415878 loss_ctc_origin 46.955215 loss_ctc0 145.157440 lr 0.00083190 rank 0
2022-08-24 09:48:57,121 DEBUG TRAIN Batch 101/3600 loss 47.069229 loss_att 25.315208 loss_ctc 97.828613 loss_ctc_origin 57.477646 loss_ctc0 191.980850 lr 0.00083182 rank 0
2022-08-24 09:49:25,081 DEBUG TRAIN Batch 101/3700 loss 18.726189 loss_att 9.362700 loss_ctc 40.574326 loss_ctc_origin 28.994408 loss_ctc0 67.594131 lr 0.00083175 rank 0
2022-08-24 09:49:30,454 WARNING NaN or Inf found in input tensor.
2022-08-24 09:49:53,304 DEBUG TRAIN Batch 101/3800 loss 21.156534 loss_att 9.515462 loss_ctc 48.319035 loss_ctc_origin 33.607216 loss_ctc0 82.646606 lr 0.00083168 rank 0
2022-08-24 09:50:21,701 DEBUG TRAIN Batch 101/3900 loss 27.004299 loss_att 13.114786 loss_ctc 59.413166 loss_ctc_origin 41.638863 loss_ctc0 100.886536 lr 0.00083161 rank 0
2022-08-24 09:50:49,059 DEBUG TRAIN Batch 101/4000 loss 47.224152 loss_att 32.778244 loss_ctc 80.931259 loss_ctc_origin 51.580921 loss_ctc0 149.415375 lr 0.00083154 rank 0
2022-08-24 09:51:16,187 DEBUG TRAIN Batch 101/4100 loss 45.458202 loss_att 26.372730 loss_ctc 89.990967 loss_ctc_origin 55.953896 loss_ctc0 169.410797 lr 0.00083146 rank 0
2022-08-24 09:51:43,944 DEBUG TRAIN Batch 101/4200 loss 22.692326 loss_att 15.442760 loss_ctc 39.607979 loss_ctc_origin 29.326969 loss_ctc0 63.596996 lr 0.00083139 rank 0
2022-08-24 09:52:12,445 DEBUG TRAIN Batch 101/4300 loss 21.232351 loss_att 9.950677 loss_ctc 47.556259 loss_ctc_origin 32.334305 loss_ctc0 83.074150 lr 0.00083132 rank 0
2022-08-24 09:52:35,409 WARNING NaN or Inf found in input tensor.
2022-08-24 09:52:39,850 DEBUG TRAIN Batch 101/4400 loss 21.346657 loss_att 9.024288 loss_ctc 50.098850 loss_ctc_origin 35.257099 loss_ctc0 84.729599 lr 0.00083125 rank 0
2022-08-24 09:53:14,511 DEBUG TRAIN Batch 101/4500 loss 43.077431 loss_att 28.254375 loss_ctc 77.664558 loss_ctc_origin 48.070824 loss_ctc0 146.716614 lr 0.00083118 rank 0
2022-08-24 09:53:41,920 DEBUG TRAIN Batch 101/4600 loss 58.796402 loss_att 37.186485 loss_ctc 109.219543 loss_ctc_origin 70.176636 loss_ctc0 200.319656 lr 0.00083111 rank 0
2022-08-24 09:54:09,895 DEBUG TRAIN Batch 101/4700 loss 23.202999 loss_att 11.597488 loss_ctc 50.282528 loss_ctc_origin 39.413147 loss_ctc0 75.644417 lr 0.00083103 rank 0
2022-08-24 09:54:37,205 DEBUG TRAIN Batch 101/4800 loss 20.609955 loss_att 10.268898 loss_ctc 44.739090 loss_ctc_origin 31.394207 loss_ctc0 75.877151 lr 0.00083096 rank 0
2022-08-24 09:55:05,088 DEBUG TRAIN Batch 101/4900 loss 21.055855 loss_att 9.133246 loss_ctc 48.875275 loss_ctc_origin 30.802408 loss_ctc0 91.045288 lr 0.00083089 rank 0
2022-08-24 09:55:33,561 DEBUG TRAIN Batch 101/5000 loss 40.091736 loss_att 25.807417 loss_ctc 73.421822 loss_ctc_origin 46.213947 loss_ctc0 136.906860 lr 0.00083082 rank 0
2022-08-24 09:56:01,088 DEBUG TRAIN Batch 101/5100 loss 50.515587 loss_att 31.580276 loss_ctc 94.697968 loss_ctc_origin 54.026546 loss_ctc0 189.597961 lr 0.00083075 rank 0
2022-08-24 09:56:29,191 DEBUG TRAIN Batch 101/5200 loss 19.304850 loss_att 10.700236 loss_ctc 39.382278 loss_ctc_origin 27.905153 loss_ctc0 66.162231 lr 0.00083068 rank 0
2022-08-24 09:56:58,217 DEBUG TRAIN Batch 101/5300 loss 20.761238 loss_att 9.215879 loss_ctc 47.700409 loss_ctc_origin 33.322350 loss_ctc0 81.249207 lr 0.00083060 rank 0
2022-08-24 09:57:26,477 DEBUG TRAIN Batch 101/5400 loss 21.483377 loss_att 10.047447 loss_ctc 48.167210 loss_ctc_origin 31.614527 loss_ctc0 86.790131 lr 0.00083053 rank 0
2022-08-24 09:57:54,985 DEBUG TRAIN Batch 101/5500 loss 36.719948 loss_att 22.715986 loss_ctc 69.395866 loss_ctc_origin 38.526581 loss_ctc0 141.424194 lr 0.00083046 rank 0
2022-08-24 09:58:23,988 WARNING NaN or Inf found in input tensor.
2022-08-24 09:58:24,030 DEBUG TRAIN Batch 101/5600 loss nan loss_att 34.398933 loss_ctc nan loss_ctc_origin 66.350563 loss_ctc0 nan lr 0.00083039 rank 0
2022-08-24 09:58:46,664 DEBUG CV Batch 101/0 loss 13.270654 loss_att 9.982807 loss_ctc 20.942295 loss_ctc_origin 14.030014 loss_ctc0 37.070953 history loss 12.490027 rank 0
2022-08-24 09:58:57,074 DEBUG CV Batch 101/100 loss 25.171473 loss_att 19.602150 loss_ctc 38.166557 loss_ctc_origin 26.432619 loss_ctc0 65.545738 history loss 28.564720 rank 0
2022-08-24 09:59:06,510 DEBUG CV Batch 101/200 loss 25.732067 loss_att 19.963232 loss_ctc 39.192680 loss_ctc_origin 28.551315 loss_ctc0 64.022530 history loss 30.098541 rank 0
2022-08-24 09:59:16,314 DEBUG CV Batch 101/300 loss 24.788052 loss_att 18.869432 loss_ctc 38.598160 loss_ctc_origin 23.250484 loss_ctc0 74.409409 history loss 29.121705 rank 0
2022-08-24 09:59:26,379 DEBUG CV Batch 101/400 loss 39.062450 loss_att 32.049938 loss_ctc 55.424980 loss_ctc_origin 37.569817 loss_ctc0 97.087029 history loss 27.398922 rank 0
2022-08-24 09:59:36,655 DEBUG CV Batch 101/500 loss 17.448999 loss_att 13.441935 loss_ctc 26.798817 loss_ctc_origin 19.894485 loss_ctc0 42.908916 history loss 26.981333 rank 0
2022-08-24 09:59:47,061 DEBUG CV Batch 101/600 loss 19.249014 loss_att 13.205841 loss_ctc 33.349751 loss_ctc_origin 21.697128 loss_ctc0 60.539207 history loss 26.817166 rank 0
2022-08-24 09:59:56,723 DEBUG CV Batch 101/700 loss 19.505262 loss_att 13.375714 loss_ctc 33.807541 loss_ctc_origin 20.567791 loss_ctc0 64.700294 history loss 26.455010 rank 0
2022-08-24 10:00:07,047 DEBUG CV Batch 101/800 loss 23.678307 loss_att 18.011719 loss_ctc 36.900345 loss_ctc_origin 22.262503 loss_ctc0 71.055305 history loss 26.409832 rank 0
2022-08-24 10:00:17,247 INFO Epoch 101 CV info cv_loss 26.447992183312273
2022-08-24 10:00:17,247 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/101.pt
2022-08-24 10:00:17,683 INFO Epoch 102 TRAIN info lr 0.0008303288271676223
2022-08-24 10:00:17,686 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 10:00:44,800 DEBUG TRAIN Batch 102/0 loss 41.408245 loss_att 28.349483 loss_ctc 71.878685 loss_ctc_origin 47.385105 loss_ctc0 129.030365 lr 0.00083033 rank 0
2022-08-24 10:01:20,448 DEBUG TRAIN Batch 102/100 loss 53.639896 loss_att 31.321831 loss_ctc 105.715378 loss_ctc_origin 59.126541 loss_ctc0 214.422668 lr 0.00083025 rank 0
2022-08-24 10:01:55,218 WARNING NaN or Inf found in input tensor.
2022-08-24 10:01:57,109 DEBUG TRAIN Batch 102/200 loss 23.157913 loss_att 13.022192 loss_ctc 46.807926 loss_ctc_origin 36.258236 loss_ctc0 71.423874 lr 0.00083018 rank 0
2022-08-24 10:02:33,176 DEBUG TRAIN Batch 102/300 loss 21.226952 loss_att 9.533477 loss_ctc 48.511726 loss_ctc_origin 32.662430 loss_ctc0 85.493408 lr 0.00083011 rank 0
2022-08-24 10:03:09,648 DEBUG TRAIN Batch 102/400 loss 24.976080 loss_att 10.768705 loss_ctc 58.126617 loss_ctc_origin 40.179859 loss_ctc0 100.002388 lr 0.00083004 rank 0
2022-08-24 10:03:45,588 DEBUG TRAIN Batch 102/500 loss 46.726944 loss_att 29.717709 loss_ctc 86.415161 loss_ctc_origin 51.290314 loss_ctc0 168.373138 lr 0.00082997 rank 0
2022-08-24 10:04:21,755 DEBUG TRAIN Batch 102/600 loss 41.664848 loss_att 23.528496 loss_ctc 83.983002 loss_ctc_origin 48.585678 loss_ctc0 166.576736 lr 0.00082990 rank 0
2022-08-24 10:04:56,616 DEBUG TRAIN Batch 102/700 loss 30.910830 loss_att 18.245842 loss_ctc 60.462467 loss_ctc_origin 52.171352 loss_ctc0 79.808395 lr 0.00082983 rank 0
2022-08-24 10:05:33,380 DEBUG TRAIN Batch 102/800 loss 18.137575 loss_att 8.799163 loss_ctc 39.927200 loss_ctc_origin 25.785316 loss_ctc0 72.924927 lr 0.00082975 rank 0
2022-08-24 10:06:09,630 DEBUG TRAIN Batch 102/900 loss 27.178276 loss_att 13.042373 loss_ctc 60.162052 loss_ctc_origin 44.050076 loss_ctc0 97.756660 lr 0.00082968 rank 0
2022-08-24 10:06:45,927 DEBUG TRAIN Batch 102/1000 loss 42.109573 loss_att 26.921322 loss_ctc 77.548828 loss_ctc_origin 48.057590 loss_ctc0 146.361710 lr 0.00082961 rank 0
2022-08-24 10:07:21,116 DEBUG TRAIN Batch 102/1100 loss 41.707985 loss_att 27.333572 loss_ctc 75.248276 loss_ctc_origin 49.737251 loss_ctc0 134.773987 lr 0.00082954 rank 0
2022-08-24 10:07:52,591 DEBUG TRAIN Batch 102/1200 loss 21.250473 loss_att 13.342813 loss_ctc 39.701675 loss_ctc_origin 29.988791 loss_ctc0 62.365074 lr 0.00082947 rank 0
2022-08-24 10:08:23,322 DEBUG TRAIN Batch 102/1300 loss 20.331650 loss_att 8.479424 loss_ctc 47.986839 loss_ctc_origin 35.992844 loss_ctc0 75.972824 lr 0.00082940 rank 0
2022-08-24 10:08:54,719 DEBUG TRAIN Batch 102/1400 loss 21.912128 loss_att 9.784217 loss_ctc 50.210587 loss_ctc_origin 32.719788 loss_ctc0 91.022446 lr 0.00082933 rank 0
2022-08-24 10:09:33,170 DEBUG TRAIN Batch 102/1500 loss 42.006081 loss_att 28.146111 loss_ctc 74.346016 loss_ctc_origin 48.450417 loss_ctc0 134.769073 lr 0.00082925 rank 0
2022-08-24 10:10:05,069 DEBUG TRAIN Batch 102/1600 loss 46.783001 loss_att 29.030102 loss_ctc 88.206429 loss_ctc_origin 56.866817 loss_ctc0 161.332184 lr 0.00082918 rank 0
2022-08-24 10:10:35,945 DEBUG TRAIN Batch 102/1700 loss 19.671097 loss_att 11.509436 loss_ctc 38.714970 loss_ctc_origin 28.798431 loss_ctc0 61.853561 lr 0.00082911 rank 0
2022-08-24 10:11:07,956 DEBUG TRAIN Batch 102/1800 loss 20.947668 loss_att 9.797636 loss_ctc 46.964409 loss_ctc_origin 32.772465 loss_ctc0 80.078941 lr 0.00082904 rank 0
2022-08-24 10:11:41,258 DEBUG TRAIN Batch 102/1900 loss 21.711285 loss_att 9.706055 loss_ctc 49.723484 loss_ctc_origin 32.746513 loss_ctc0 89.336411 lr 0.00082897 rank 0
2022-08-24 10:12:13,966 DEBUG TRAIN Batch 102/2000 loss 47.510979 loss_att 32.311489 loss_ctc 82.976456 loss_ctc_origin 54.079849 loss_ctc0 150.401886 lr 0.00082890 rank 0
2022-08-24 10:12:45,429 DEBUG TRAIN Batch 102/2100 loss 49.683308 loss_att 30.220058 loss_ctc 95.097549 loss_ctc_origin 62.397793 loss_ctc0 171.396988 lr 0.00082883 rank 0
2022-08-24 10:13:17,067 DEBUG TRAIN Batch 102/2200 loss 21.641092 loss_att 12.521478 loss_ctc 42.920189 loss_ctc_origin 32.270615 loss_ctc0 67.769196 lr 0.00082876 rank 0
2022-08-24 10:13:48,632 DEBUG TRAIN Batch 102/2300 loss 18.383972 loss_att 8.271743 loss_ctc 41.979172 loss_ctc_origin 26.977768 loss_ctc0 76.982445 lr 0.00082869 rank 0
2022-08-24 10:14:21,878 DEBUG TRAIN Batch 102/2400 loss 24.214405 loss_att 11.481861 loss_ctc 53.923676 loss_ctc_origin 37.719727 loss_ctc0 91.732880 lr 0.00082861 rank 0
2022-08-24 10:14:54,462 DEBUG TRAIN Batch 102/2500 loss 41.578297 loss_att 26.934921 loss_ctc 75.746170 loss_ctc_origin 45.377701 loss_ctc0 146.605927 lr 0.00082854 rank 0
2022-08-24 10:15:25,420 DEBUG TRAIN Batch 102/2600 loss 43.134125 loss_att 24.453838 loss_ctc 86.721451 loss_ctc_origin 48.799088 loss_ctc0 175.206955 lr 0.00082847 rank 0
2022-08-24 10:15:57,645 DEBUG TRAIN Batch 102/2700 loss 19.727057 loss_att 10.484585 loss_ctc 41.292820 loss_ctc_origin 29.727434 loss_ctc0 68.278717 lr 0.00082840 rank 0
2022-08-24 10:16:29,137 DEBUG TRAIN Batch 102/2800 loss 21.343775 loss_att 10.582455 loss_ctc 46.453518 loss_ctc_origin 33.935276 loss_ctc0 75.662750 lr 0.00082833 rank 0
2022-08-24 10:17:00,853 DEBUG TRAIN Batch 102/2900 loss 24.944815 loss_att 11.751320 loss_ctc 55.729637 loss_ctc_origin 37.686188 loss_ctc0 97.831009 lr 0.00082826 rank 0
2022-08-24 10:17:40,498 DEBUG TRAIN Batch 102/3000 loss 45.199196 loss_att 29.153473 loss_ctc 82.639206 loss_ctc_origin 50.723431 loss_ctc0 157.109360 lr 0.00082819 rank 0
2022-08-24 10:17:42,266 WARNING NaN or Inf found in input tensor.
2022-08-24 10:17:56,650 WARNING NaN or Inf found in input tensor.
2022-08-24 10:18:12,463 DEBUG TRAIN Batch 102/3100 loss 41.567310 loss_att 28.005692 loss_ctc 73.211090 loss_ctc_origin 52.333694 loss_ctc0 121.925018 lr 0.00082812 rank 0
2022-08-24 10:18:43,403 DEBUG TRAIN Batch 102/3200 loss 21.474308 loss_att 12.314266 loss_ctc 42.847740 loss_ctc_origin 31.917730 loss_ctc0 68.351097 lr 0.00082805 rank 0
2022-08-24 10:19:14,646 DEBUG TRAIN Batch 102/3300 loss 19.825970 loss_att 9.183708 loss_ctc 44.657913 loss_ctc_origin 30.944332 loss_ctc0 76.656265 lr 0.00082797 rank 0
2022-08-24 10:19:46,984 DEBUG TRAIN Batch 102/3400 loss 19.762482 loss_att 8.387384 loss_ctc 46.304375 loss_ctc_origin 28.114998 loss_ctc0 88.746246 lr 0.00082790 rank 0
2022-08-24 10:20:19,320 DEBUG TRAIN Batch 102/3500 loss 45.632210 loss_att 29.860703 loss_ctc 82.432396 loss_ctc_origin 49.525475 loss_ctc0 159.215210 lr 0.00082783 rank 0
2022-08-24 10:20:51,269 DEBUG TRAIN Batch 102/3600 loss 40.449692 loss_att 26.214571 loss_ctc 73.664978 loss_ctc_origin 52.127808 loss_ctc0 123.918388 lr 0.00082776 rank 0
2022-08-24 10:21:23,189 DEBUG TRAIN Batch 102/3700 loss 19.877478 loss_att 10.126482 loss_ctc 42.629799 loss_ctc_origin 32.208279 loss_ctc0 66.946671 lr 0.00082769 rank 0
2022-08-24 10:21:54,270 DEBUG TRAIN Batch 102/3800 loss 22.419001 loss_att 10.313591 loss_ctc 50.664955 loss_ctc_origin 37.460552 loss_ctc0 81.475220 lr 0.00082762 rank 0
2022-08-24 10:22:27,343 DEBUG TRAIN Batch 102/3900 loss 24.958839 loss_att 11.771176 loss_ctc 55.730053 loss_ctc_origin 38.453651 loss_ctc0 96.041656 lr 0.00082755 rank 0
2022-08-24 10:22:30,371 WARNING NaN or Inf found in input tensor.
2022-08-24 10:22:57,841 DEBUG TRAIN Batch 102/4000 loss 41.668404 loss_att 28.072882 loss_ctc 73.391289 loss_ctc_origin 45.663639 loss_ctc0 138.089142 lr 0.00082748 rank 0
2022-08-24 10:23:29,347 DEBUG TRAIN Batch 102/4100 loss 40.194336 loss_att 28.338766 loss_ctc 67.857330 loss_ctc_origin 49.541763 loss_ctc0 110.593643 lr 0.00082741 rank 0
2022-08-24 10:24:01,387 DEBUG TRAIN Batch 102/4200 loss 23.354549 loss_att 12.531292 loss_ctc 48.608818 loss_ctc_origin 37.221405 loss_ctc0 75.179451 lr 0.00082734 rank 0
2022-08-24 10:24:14,304 WARNING NaN or Inf found in input tensor.
2022-08-24 10:24:32,746 DEBUG TRAIN Batch 102/4300 loss 23.000307 loss_att 10.934299 loss_ctc 51.154324 loss_ctc_origin 38.556877 loss_ctc0 80.548363 lr 0.00082727 rank 0
2022-08-24 10:24:59,530 WARNING NaN or Inf found in input tensor.
2022-08-24 10:25:04,509 DEBUG TRAIN Batch 102/4400 loss 29.937283 loss_att 14.210056 loss_ctc 66.634140 loss_ctc_origin 52.052521 loss_ctc0 100.657913 lr 0.00082720 rank 0
2022-08-24 10:25:14,566 WARNING NaN or Inf found in input tensor.
2022-08-24 10:25:42,087 DEBUG TRAIN Batch 102/4500 loss 44.220657 loss_att 31.990728 loss_ctc 72.757156 loss_ctc_origin 45.134094 loss_ctc0 137.210968 lr 0.00082712 rank 0
2022-08-24 10:26:12,934 DEBUG TRAIN Batch 102/4600 loss 48.007729 loss_att 32.021557 loss_ctc 85.308792 loss_ctc_origin 60.505333 loss_ctc0 143.183533 lr 0.00082705 rank 0
2022-08-24 10:26:44,069 DEBUG TRAIN Batch 102/4700 loss 19.472179 loss_att 10.896893 loss_ctc 39.481178 loss_ctc_origin 30.607059 loss_ctc0 60.187447 lr 0.00082698 rank 0
2022-08-24 10:27:14,209 DEBUG TRAIN Batch 102/4800 loss 21.898891 loss_att 9.472805 loss_ctc 50.893089 loss_ctc_origin 36.872955 loss_ctc0 83.606735 lr 0.00082691 rank 0
2022-08-24 10:27:44,999 DEBUG TRAIN Batch 102/4900 loss 27.292339 loss_att 12.853460 loss_ctc 60.983055 loss_ctc_origin 44.407326 loss_ctc0 99.659752 lr 0.00082684 rank 0
2022-08-24 10:28:15,520 DEBUG TRAIN Batch 102/5000 loss 36.858063 loss_att 23.860786 loss_ctc 67.185043 loss_ctc_origin 40.079956 loss_ctc0 130.430237 lr 0.00082677 rank 0
2022-08-24 10:28:23,740 WARNING NaN or Inf found in input tensor.
2022-08-24 10:28:45,025 DEBUG TRAIN Batch 102/5100 loss 50.928192 loss_att 32.543953 loss_ctc 93.824745 loss_ctc_origin 66.497650 loss_ctc0 157.587967 lr 0.00082670 rank 0
2022-08-24 10:29:15,658 DEBUG TRAIN Batch 102/5200 loss 26.126278 loss_att 16.102072 loss_ctc 49.516087 loss_ctc_origin 38.111717 loss_ctc0 76.126282 lr 0.00082663 rank 0
2022-08-24 10:29:45,882 DEBUG TRAIN Batch 102/5300 loss 23.959553 loss_att 11.248366 loss_ctc 53.618988 loss_ctc_origin 39.788483 loss_ctc0 85.890160 lr 0.00082656 rank 0
2022-08-24 10:30:14,984 DEBUG TRAIN Batch 102/5400 loss 26.635435 loss_att 12.910563 loss_ctc 58.660133 loss_ctc_origin 41.900478 loss_ctc0 97.765991 lr 0.00082649 rank 0
2022-08-24 10:30:44,811 DEBUG TRAIN Batch 102/5500 loss 40.061310 loss_att 26.809395 loss_ctc 70.982437 loss_ctc_origin 42.505192 loss_ctc0 137.429337 lr 0.00082642 rank 0
2022-08-24 10:31:14,791 WARNING NaN or Inf found in input tensor.
2022-08-24 10:31:14,855 DEBUG TRAIN Batch 102/5600 loss nan loss_att 23.743898 loss_ctc nan loss_ctc_origin 52.192966 loss_ctc0 nan lr 0.00082635 rank 0
2022-08-24 10:31:37,942 DEBUG CV Batch 102/0 loss 14.217540 loss_att 10.891327 loss_ctc 21.978703 loss_ctc_origin 16.038990 loss_ctc0 35.838032 history loss 13.381214 rank 0
2022-08-24 10:31:48,707 DEBUG CV Batch 102/100 loss 25.440285 loss_att 19.947182 loss_ctc 38.257523 loss_ctc_origin 27.753778 loss_ctc0 62.766262 history loss 29.508816 rank 0
2022-08-24 10:31:58,496 DEBUG CV Batch 102/200 loss 26.987009 loss_att 20.743309 loss_ctc 41.555641 loss_ctc_origin 30.110182 loss_ctc0 68.261711 history loss 30.950673 rank 0
2022-08-24 10:32:08,280 DEBUG CV Batch 102/300 loss 23.937447 loss_att 18.069889 loss_ctc 37.628410 loss_ctc_origin 21.973909 loss_ctc0 74.155579 history loss 30.035747 rank 0
2022-08-24 10:32:19,108 DEBUG CV Batch 102/400 loss 39.983780 loss_att 32.946926 loss_ctc 56.403099 loss_ctc_origin 38.910469 loss_ctc0 97.219231 history loss 28.277114 rank 0
2022-08-24 10:32:29,737 DEBUG CV Batch 102/500 loss 18.586937 loss_att 14.323810 loss_ctc 28.534233 loss_ctc_origin 22.337566 loss_ctc0 42.993118 history loss 27.909860 rank 0
2022-08-24 10:32:40,215 DEBUG CV Batch 102/600 loss 20.360405 loss_att 13.954359 loss_ctc 35.307846 loss_ctc_origin 23.954113 loss_ctc0 61.799877 history loss 27.785902 rank 0
2022-08-24 10:32:50,445 DEBUG CV Batch 102/700 loss 20.883101 loss_att 14.547155 loss_ctc 35.666973 loss_ctc_origin 22.930891 loss_ctc0 65.384491 history loss 27.438512 rank 0
2022-08-24 10:33:00,763 DEBUG CV Batch 102/800 loss 24.145248 loss_att 19.073025 loss_ctc 35.980438 loss_ctc_origin 20.826345 loss_ctc0 71.339981 history loss 27.393236 rank 0
2022-08-24 10:33:11,307 INFO Epoch 102 CV info cv_loss 27.421135995129593
2022-08-24 10:33:11,307 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/102.pt
2022-08-24 10:33:11,755 INFO Epoch 103 TRAIN info lr 0.0008262882736167646
2022-08-24 10:33:11,759 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 10:33:38,832 DEBUG TRAIN Batch 103/0 loss 40.067406 loss_att 26.978523 loss_ctc 70.608139 loss_ctc_origin 44.385998 loss_ctc0 131.793121 lr 0.00082629 rank 0
2022-08-24 10:34:07,208 DEBUG TRAIN Batch 103/100 loss 34.570667 loss_att 22.609819 loss_ctc 62.479309 loss_ctc_origin 41.703606 loss_ctc0 110.955940 lr 0.00082621 rank 0
2022-08-24 10:34:35,240 DEBUG TRAIN Batch 103/200 loss 20.493883 loss_att 10.456000 loss_ctc 43.915611 loss_ctc_origin 33.485821 loss_ctc0 68.251785 lr 0.00082614 rank 0
2022-08-24 10:35:01,974 DEBUG TRAIN Batch 103/300 loss 18.903299 loss_att 7.851624 loss_ctc 44.690540 loss_ctc_origin 30.436266 loss_ctc0 77.950516 lr 0.00082607 rank 0
2022-08-24 10:35:26,077 WARNING NaN or Inf found in input tensor.
2022-08-24 10:35:30,509 DEBUG TRAIN Batch 103/400 loss 25.446081 loss_att 11.729710 loss_ctc 57.450947 loss_ctc_origin 42.794964 loss_ctc0 91.648239 lr 0.00082600 rank 0
2022-08-24 10:35:59,282 DEBUG TRAIN Batch 103/500 loss 40.708363 loss_att 28.069790 loss_ctc 70.198364 loss_ctc_origin 45.714832 loss_ctc0 127.326622 lr 0.00082593 rank 0
2022-08-24 10:36:26,958 DEBUG TRAIN Batch 103/600 loss 47.254852 loss_att 30.846428 loss_ctc 85.541183 loss_ctc_origin 60.955399 loss_ctc0 142.908005 lr 0.00082586 rank 0
2022-08-24 10:36:54,966 DEBUG TRAIN Batch 103/700 loss 19.350765 loss_att 10.112577 loss_ctc 40.906532 loss_ctc_origin 30.468445 loss_ctc0 65.262062 lr 0.00082579 rank 0
2022-08-24 10:37:23,360 DEBUG TRAIN Batch 103/800 loss 23.010273 loss_att 10.276740 loss_ctc 52.721851 loss_ctc_origin 39.509869 loss_ctc0 83.549805 lr 0.00082572 rank 0
2022-08-24 10:37:40,688 WARNING NaN or Inf found in input tensor.
2022-08-24 10:37:52,292 DEBUG TRAIN Batch 103/900 loss 19.060810 loss_att 7.703073 loss_ctc 45.562195 loss_ctc_origin 29.010803 loss_ctc0 84.182114 lr 0.00082565 rank 0
2022-08-24 10:38:21,433 DEBUG TRAIN Batch 103/1000 loss 39.702564 loss_att 26.586166 loss_ctc 70.307495 loss_ctc_origin 44.096882 loss_ctc0 131.465576 lr 0.00082558 rank 0
2022-08-24 10:38:49,160 DEBUG TRAIN Batch 103/1100 loss 37.411861 loss_att 22.684998 loss_ctc 71.774536 loss_ctc_origin 48.921146 loss_ctc0 125.099121 lr 0.00082551 rank 0
2022-08-24 10:39:16,224 WARNING NaN or Inf found in input tensor.
2022-08-24 10:39:17,845 DEBUG TRAIN Batch 103/1200 loss 18.425198 loss_att 10.325940 loss_ctc 37.323463 loss_ctc_origin 25.065828 loss_ctc0 65.924606 lr 0.00082544 rank 0
2022-08-24 10:39:46,973 DEBUG TRAIN Batch 103/1300 loss 24.418949 loss_att 11.455388 loss_ctc 54.667259 loss_ctc_origin 43.103149 loss_ctc0 81.650185 lr 0.00082537 rank 0
2022-08-24 10:40:16,474 DEBUG TRAIN Batch 103/1400 loss 24.525362 loss_att 11.329820 loss_ctc 55.314957 loss_ctc_origin 36.881538 loss_ctc0 98.326271 lr 0.00082530 rank 0
2022-08-24 10:40:50,159 DEBUG TRAIN Batch 103/1500 loss 40.778915 loss_att 27.617048 loss_ctc 71.489929 loss_ctc_origin 43.215576 loss_ctc0 137.463409 lr 0.00082523 rank 0
2022-08-24 10:41:18,635 DEBUG TRAIN Batch 103/1600 loss 38.918045 loss_att 23.574757 loss_ctc 74.719055 loss_ctc_origin 53.342106 loss_ctc0 124.598602 lr 0.00082516 rank 0
2022-08-24 10:41:45,250 WARNING NaN or Inf found in input tensor.
2022-08-24 10:41:46,892 DEBUG TRAIN Batch 103/1700 loss 19.664423 loss_att 10.449637 loss_ctc 41.165588 loss_ctc_origin 29.465057 loss_ctc0 68.466827 lr 0.00082509 rank 0
2022-08-24 10:42:15,128 DEBUG TRAIN Batch 103/1800 loss 22.920053 loss_att 9.990961 loss_ctc 53.087933 loss_ctc_origin 40.293213 loss_ctc0 82.942276 lr 0.00082502 rank 0
2022-08-24 10:42:25,822 WARNING NaN or Inf found in input tensor.
2022-08-24 10:42:38,611 WARNING NaN or Inf found in input tensor.
2022-08-24 10:42:43,200 DEBUG TRAIN Batch 103/1900 loss 26.056593 loss_att 12.378900 loss_ctc 57.971207 loss_ctc_origin 40.005428 loss_ctc0 99.891357 lr 0.00082495 rank 0
2022-08-24 10:43:12,986 DEBUG TRAIN Batch 103/2000 loss 34.176826 loss_att 24.069525 loss_ctc 57.760521 loss_ctc_origin 38.488235 loss_ctc0 102.729187 lr 0.00082488 rank 0
2022-08-24 10:43:40,230 DEBUG TRAIN Batch 103/2100 loss 50.861298 loss_att 33.038254 loss_ctc 92.448395 loss_ctc_origin 62.130482 loss_ctc0 163.190186 lr 0.00082481 rank 0
2022-08-24 10:44:08,101 DEBUG TRAIN Batch 103/2200 loss 21.891344 loss_att 13.878407 loss_ctc 40.588196 loss_ctc_origin 30.396566 loss_ctc0 64.368668 lr 0.00082474 rank 0
2022-08-24 10:44:36,305 DEBUG TRAIN Batch 103/2300 loss 23.538279 loss_att 10.971687 loss_ctc 52.860321 loss_ctc_origin 40.778446 loss_ctc0 81.051361 lr 0.00082467 rank 0
2022-08-24 10:44:53,656 WARNING NaN or Inf found in input tensor.
2022-08-24 10:45:05,042 DEBUG TRAIN Batch 103/2400 loss 24.294607 loss_att 11.786745 loss_ctc 53.479618 loss_ctc_origin 35.008148 loss_ctc0 96.579712 lr 0.00082460 rank 0
2022-08-24 10:45:33,842 DEBUG TRAIN Batch 103/2500 loss 45.559532 loss_att 30.470829 loss_ctc 80.766510 loss_ctc_origin 50.409645 loss_ctc0 151.599197 lr 0.00082453 rank 0
2022-08-24 10:46:01,533 DEBUG TRAIN Batch 103/2600 loss 43.749798 loss_att 29.518219 loss_ctc 76.956818 loss_ctc_origin 53.634315 loss_ctc0 131.375977 lr 0.00082446 rank 0
2022-08-24 10:46:29,454 DEBUG TRAIN Batch 103/2700 loss 20.413349 loss_att 11.633074 loss_ctc 40.900658 loss_ctc_origin 30.542576 loss_ctc0 65.069519 lr 0.00082439 rank 0
2022-08-24 10:46:57,200 DEBUG TRAIN Batch 103/2800 loss 22.789398 loss_att 11.038177 loss_ctc 50.208916 loss_ctc_origin 34.554058 loss_ctc0 86.736923 lr 0.00082432 rank 0
2022-08-24 10:47:26,748 DEBUG TRAIN Batch 103/2900 loss 21.538607 loss_att 9.334187 loss_ctc 50.015583 loss_ctc_origin 32.774010 loss_ctc0 90.245918 lr 0.00082425 rank 0
2022-08-24 10:48:01,271 DEBUG TRAIN Batch 103/3000 loss 43.374924 loss_att 27.910250 loss_ctc 79.459167 loss_ctc_origin 48.891151 loss_ctc0 150.784546 lr 0.00082418 rank 0
2022-08-24 10:48:29,395 DEBUG TRAIN Batch 103/3100 loss 49.299835 loss_att 31.874495 loss_ctc 89.958969 loss_ctc_origin 67.997673 loss_ctc0 141.201996 lr 0.00082411 rank 0
2022-08-24 10:48:55,258 WARNING NaN or Inf found in input tensor.
2022-08-24 10:48:56,836 DEBUG TRAIN Batch 103/3200 loss 23.407135 loss_att 11.706978 loss_ctc 50.707504 loss_ctc_origin 44.267609 loss_ctc0 65.733932 lr 0.00082404 rank 0
2022-08-24 10:49:24,676 DEBUG TRAIN Batch 103/3300 loss 21.007299 loss_att 10.291399 loss_ctc 46.011066 loss_ctc_origin 32.124619 loss_ctc0 78.412781 lr 0.00082397 rank 0
2022-08-24 10:49:51,949 DEBUG TRAIN Batch 103/3400 loss 22.157169 loss_att 9.642960 loss_ctc 51.356991 loss_ctc_origin 34.127914 loss_ctc0 91.558167 lr 0.00082390 rank 0
2022-08-24 10:50:19,942 DEBUG TRAIN Batch 103/3500 loss 40.869659 loss_att 23.091728 loss_ctc 82.351501 loss_ctc_origin 47.844398 loss_ctc0 162.868073 lr 0.00082383 rank 0
2022-08-24 10:50:48,024 DEBUG TRAIN Batch 103/3600 loss 53.369144 loss_att 35.961224 loss_ctc 93.987625 loss_ctc_origin 66.355568 loss_ctc0 158.462402 lr 0.00082376 rank 0
2022-08-24 10:51:15,668 DEBUG TRAIN Batch 103/3700 loss 21.080631 loss_att 12.317813 loss_ctc 41.527206 loss_ctc_origin 30.414684 loss_ctc0 67.456413 lr 0.00082369 rank 0
2022-08-24 10:51:43,640 DEBUG TRAIN Batch 103/3800 loss 21.812834 loss_att 9.848351 loss_ctc 49.729958 loss_ctc_origin 34.720955 loss_ctc0 84.750969 lr 0.00082362 rank 0
2022-08-24 10:52:11,398 DEBUG TRAIN Batch 103/3900 loss 25.266457 loss_att 11.482122 loss_ctc 57.429905 loss_ctc_origin 39.360043 loss_ctc0 99.592918 lr 0.00082355 rank 0
2022-08-24 10:52:40,322 DEBUG TRAIN Batch 103/4000 loss 38.971832 loss_att 24.923481 loss_ctc 71.751328 loss_ctc_origin 38.422783 loss_ctc0 149.517914 lr 0.00082348 rank 0
2022-08-24 10:53:08,017 DEBUG TRAIN Batch 103/4100 loss 51.327927 loss_att 33.458836 loss_ctc 93.022476 loss_ctc_origin 60.789795 loss_ctc0 168.232040 lr 0.00082341 rank 0
2022-08-24 10:53:35,541 DEBUG TRAIN Batch 103/4200 loss 22.104130 loss_att 12.346379 loss_ctc 44.872215 loss_ctc_origin 33.123886 loss_ctc0 72.284981 lr 0.00082334 rank 0
2022-08-24 10:54:03,780 DEBUG TRAIN Batch 103/4300 loss 24.682457 loss_att 12.178948 loss_ctc 53.857307 loss_ctc_origin 40.142185 loss_ctc0 85.859253 lr 0.00082327 rank 0
2022-08-24 10:54:31,920 DEBUG TRAIN Batch 103/4400 loss 26.364403 loss_att 13.081198 loss_ctc 57.358540 loss_ctc_origin 39.983925 loss_ctc0 97.899307 lr 0.00082320 rank 0
2022-08-24 10:55:04,201 DEBUG TRAIN Batch 103/4500 loss 49.933792 loss_att 31.714455 loss_ctc 92.445587 loss_ctc_origin 57.358429 loss_ctc0 174.315628 lr 0.00082313 rank 0
2022-08-24 10:55:32,413 DEBUG TRAIN Batch 103/4600 loss 58.708794 loss_att 38.273933 loss_ctc 106.390121 loss_ctc_origin 63.996536 loss_ctc0 205.308502 lr 0.00082306 rank 0
2022-08-24 10:56:00,241 DEBUG TRAIN Batch 103/4700 loss 19.387732 loss_att 10.314768 loss_ctc 40.557976 loss_ctc_origin 29.270462 loss_ctc0 66.895508 lr 0.00082299 rank 0
2022-08-24 10:56:27,366 DEBUG TRAIN Batch 103/4800 loss 19.457306 loss_att 8.827787 loss_ctc 44.259518 loss_ctc_origin 32.075897 loss_ctc0 72.687965 lr 0.00082292 rank 0
2022-08-24 10:56:55,543 DEBUG TRAIN Batch 103/4900 loss 25.695812 loss_att 12.662862 loss_ctc 56.106026 loss_ctc_origin 37.281620 loss_ctc0 100.029633 lr 0.00082285 rank 0
2022-08-24 10:57:23,626 DEBUG TRAIN Batch 103/5000 loss 52.271942 loss_att 33.520035 loss_ctc 96.026382 loss_ctc_origin 60.987404 loss_ctc0 177.783997 lr 0.00082278 rank 0
2022-08-24 10:57:51,533 DEBUG TRAIN Batch 103/5100 loss 61.441902 loss_att 37.632366 loss_ctc 116.997482 loss_ctc_origin 79.210037 loss_ctc0 205.168198 lr 0.00082271 rank 0
2022-08-24 10:58:19,616 DEBUG TRAIN Batch 103/5200 loss 24.272018 loss_att 15.455198 loss_ctc 44.844597 loss_ctc_origin 35.636139 loss_ctc0 66.330994 lr 0.00082264 rank 0
2022-08-24 10:58:47,302 DEBUG TRAIN Batch 103/5300 loss 23.817665 loss_att 10.699033 loss_ctc 54.427803 loss_ctc_origin 41.152184 loss_ctc0 85.404243 lr 0.00082257 rank 0
2022-08-24 10:59:15,422 DEBUG TRAIN Batch 103/5400 loss 23.929888 loss_att 11.186041 loss_ctc 53.665527 loss_ctc_origin 35.728424 loss_ctc0 95.518761 lr 0.00082250 rank 0
2022-08-24 10:59:43,760 DEBUG TRAIN Batch 103/5500 loss 51.969826 loss_att 35.963768 loss_ctc 89.317291 loss_ctc_origin 57.558399 loss_ctc0 163.421356 lr 0.00082243 rank 0
2022-08-24 11:00:11,476 DEBUG TRAIN Batch 103/5600 loss 47.343292 loss_att 30.829033 loss_ctc 85.876556 loss_ctc_origin 54.481026 loss_ctc0 159.132782 lr 0.00082236 rank 0
2022-08-24 11:00:24,553 WARNING NaN or Inf found in input tensor.
2022-08-24 11:00:33,872 DEBUG CV Batch 103/0 loss 13.454012 loss_att 9.995720 loss_ctc 21.523357 loss_ctc_origin 14.300284 loss_ctc0 38.377197 history loss 12.662599 rank 0
2022-08-24 11:00:44,333 DEBUG CV Batch 103/100 loss 28.852802 loss_att 21.352003 loss_ctc 46.354664 loss_ctc_origin 31.796820 loss_ctc0 80.322960 history loss 29.017181 rank 0
2022-08-24 11:00:53,858 DEBUG CV Batch 103/200 loss 25.911743 loss_att 19.715261 loss_ctc 40.370201 loss_ctc_origin 28.097984 loss_ctc0 69.005371 history loss 30.678708 rank 0
2022-08-24 11:01:03,515 DEBUG CV Batch 103/300 loss 24.503531 loss_att 18.238380 loss_ctc 39.122215 loss_ctc_origin 24.121212 loss_ctc0 74.124550 history loss 29.703292 rank 0
2022-08-24 11:01:13,806 DEBUG CV Batch 103/400 loss 39.482780 loss_att 32.009109 loss_ctc 56.921341 loss_ctc_origin 39.625793 loss_ctc0 97.277618 history loss 28.029947 rank 0
2022-08-24 11:01:24,020 DEBUG CV Batch 103/500 loss 17.148117 loss_att 12.946775 loss_ctc 26.951250 loss_ctc_origin 19.915596 loss_ctc0 43.367775 history loss 27.695140 rank 0
2022-08-24 11:01:34,447 DEBUG CV Batch 103/600 loss 20.223381 loss_att 14.196390 loss_ctc 34.286362 loss_ctc_origin 21.922504 loss_ctc0 63.135361 history loss 27.604254 rank 0
2022-08-24 11:01:44,311 DEBUG CV Batch 103/700 loss 19.707968 loss_att 13.349781 loss_ctc 34.543736 loss_ctc_origin 21.474676 loss_ctc0 65.038200 history loss 27.254023 rank 0
2022-08-24 11:01:54,379 DEBUG CV Batch 103/800 loss 23.491089 loss_att 18.094566 loss_ctc 36.082973 loss_ctc_origin 21.291306 loss_ctc0 70.596863 history loss 27.203264 rank 0
2022-08-24 11:02:04,474 INFO Epoch 103 CV info cv_loss 27.21599769765354
2022-08-24 11:02:04,474 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/103.pt
2022-08-24 11:02:04,907 INFO Epoch 104 TRAIN info lr 0.000822306138277068
2022-08-24 11:02:04,910 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 11:02:31,312 DEBUG TRAIN Batch 104/0 loss 50.640240 loss_att 33.320129 loss_ctc 91.053825 loss_ctc_origin 55.574184 loss_ctc0 173.839645 lr 0.00082230 rank 0
2022-08-24 11:02:59,739 DEBUG TRAIN Batch 104/100 loss 46.569286 loss_att 28.625237 loss_ctc 88.438736 loss_ctc_origin 55.602257 loss_ctc0 165.057190 lr 0.00082223 rank 0
2022-08-24 11:03:27,518 DEBUG TRAIN Batch 104/200 loss 23.199039 loss_att 13.580985 loss_ctc 45.641163 loss_ctc_origin 35.271835 loss_ctc0 69.836258 lr 0.00082216 rank 0
2022-08-24 11:03:55,818 DEBUG TRAIN Batch 104/300 loss 20.400017 loss_att 9.058865 loss_ctc 46.862701 loss_ctc_origin 32.162739 loss_ctc0 81.162621 lr 0.00082209 rank 0
2022-08-24 11:04:24,069 DEBUG TRAIN Batch 104/400 loss 26.441345 loss_att 12.946968 loss_ctc 57.928223 loss_ctc_origin 39.939053 loss_ctc0 99.902954 lr 0.00082203 rank 0
2022-08-24 11:04:52,445 DEBUG TRAIN Batch 104/500 loss 45.663460 loss_att 29.851587 loss_ctc 82.557831 loss_ctc_origin 49.259254 loss_ctc0 160.254501 lr 0.00082196 rank 0
2022-08-24 11:05:20,252 DEBUG TRAIN Batch 104/600 loss 52.545303 loss_att 34.162685 loss_ctc 95.438080 loss_ctc_origin 61.215073 loss_ctc0 175.291748 lr 0.00082189 rank 0
2022-08-24 11:05:49,228 DEBUG TRAIN Batch 104/700 loss 23.960257 loss_att 13.976881 loss_ctc 47.254799 loss_ctc_origin 37.408325 loss_ctc0 70.229904 lr 0.00082182 rank 0
2022-08-24 11:05:54,639 WARNING NaN or Inf found in input tensor.
2022-08-24 11:06:17,437 DEBUG TRAIN Batch 104/800 loss 23.647255 loss_att 10.659954 loss_ctc 53.950958 loss_ctc_origin 39.888992 loss_ctc0 86.762207 lr 0.00082175 rank 0
2022-08-24 11:06:45,391 DEBUG TRAIN Batch 104/900 loss 22.311895 loss_att 9.287378 loss_ctc 52.702431 loss_ctc_origin 34.160782 loss_ctc0 95.966278 lr 0.00082168 rank 0
2022-08-24 11:07:13,601 DEBUG TRAIN Batch 104/1000 loss 45.461449 loss_att 27.388250 loss_ctc 87.632240 loss_ctc_origin 59.009144 loss_ctc0 154.419464 lr 0.00082161 rank 0
2022-08-24 11:07:40,969 DEBUG TRAIN Batch 104/1100 loss 54.643162 loss_att 36.474667 loss_ctc 97.036316 loss_ctc_origin 70.522400 loss_ctc0 158.902115 lr 0.00082154 rank 0
2022-08-24 11:08:08,720 DEBUG TRAIN Batch 104/1200 loss 24.607611 loss_att 14.078770 loss_ctc 49.174904 loss_ctc_origin 40.176514 loss_ctc0 70.171143 lr 0.00082147 rank 0
2022-08-24 11:08:20,831 WARNING NaN or Inf found in input tensor.
2022-08-24 11:08:37,478 DEBUG TRAIN Batch 104/1300 loss 21.814579 loss_att 10.029823 loss_ctc 49.312340 loss_ctc_origin 36.433655 loss_ctc0 79.362610 lr 0.00082140 rank 0
2022-08-24 11:09:05,733 DEBUG TRAIN Batch 104/1400 loss 24.691040 loss_att 12.034470 loss_ctc 54.223034 loss_ctc_origin 35.999954 loss_ctc0 96.743546 lr 0.00082133 rank 0
2022-08-24 11:09:40,801 DEBUG TRAIN Batch 104/1500 loss 44.034752 loss_att 29.019623 loss_ctc 79.070045 loss_ctc_origin 50.629326 loss_ctc0 145.431717 lr 0.00082126 rank 0
2022-08-24 11:10:09,371 DEBUG TRAIN Batch 104/1600 loss 49.343231 loss_att 33.498005 loss_ctc 86.315430 loss_ctc_origin 63.739998 loss_ctc0 138.991425 lr 0.00082119 rank 0
2022-08-24 11:10:38,006 DEBUG TRAIN Batch 104/1700 loss 25.566208 loss_att 14.572365 loss_ctc 51.218506 loss_ctc_origin 41.236732 loss_ctc0 74.509315 lr 0.00082112 rank 0
2022-08-24 11:11:06,014 DEBUG TRAIN Batch 104/1800 loss 23.485250 loss_att 9.902077 loss_ctc 55.179321 loss_ctc_origin 39.787415 loss_ctc0 91.093773 lr 0.00082106 rank 0
2022-08-24 11:11:34,804 DEBUG TRAIN Batch 104/1900 loss 29.447292 loss_att 13.059181 loss_ctc 67.686218 loss_ctc_origin 50.202217 loss_ctc0 108.482216 lr 0.00082099 rank 0
2022-08-24 11:12:05,300 DEBUG TRAIN Batch 104/2000 loss 32.878353 loss_att 24.002773 loss_ctc 53.588036 loss_ctc_origin 37.571632 loss_ctc0 90.959641 lr 0.00082092 rank 0
2022-08-24 11:12:33,394 DEBUG TRAIN Batch 104/2100 loss 47.910286 loss_att 29.425426 loss_ctc 91.041626 loss_ctc_origin 61.202827 loss_ctc0 160.665466 lr 0.00082085 rank 0
2022-08-24 11:13:01,402 DEBUG TRAIN Batch 104/2200 loss 23.784431 loss_att 15.031750 loss_ctc 44.207359 loss_ctc_origin 33.750092 loss_ctc0 68.607651 lr 0.00082078 rank 0
2022-08-24 11:13:30,693 DEBUG TRAIN Batch 104/2300 loss 22.473392 loss_att 9.666114 loss_ctc 52.357040 loss_ctc_origin 36.473763 loss_ctc0 89.418015 lr 0.00082071 rank 0
2022-08-24 11:13:59,447 DEBUG TRAIN Batch 104/2400 loss 24.567091 loss_att 10.954746 loss_ctc 56.329231 loss_ctc_origin 39.943398 loss_ctc0 94.562836 lr 0.00082064 rank 0
2022-08-24 11:14:28,148 DEBUG TRAIN Batch 104/2500 loss 23.164385 loss_att 15.405395 loss_ctc 41.268692 loss_ctc_origin 25.754297 loss_ctc0 77.468941 lr 0.00082057 rank 0
2022-08-24 11:14:55,723 DEBUG TRAIN Batch 104/2600 loss 43.689613 loss_att 27.044130 loss_ctc 82.529068 loss_ctc_origin 56.374603 loss_ctc0 143.556137 lr 0.00082050 rank 0
2022-08-24 11:15:22,476 WARNING NaN or Inf found in input tensor.
2022-08-24 11:15:24,232 DEBUG TRAIN Batch 104/2700 loss 23.367722 loss_att 12.202173 loss_ctc 49.420666 loss_ctc_origin 38.807068 loss_ctc0 74.185722 lr 0.00082043 rank 0
2022-08-24 11:15:52,128 DEBUG TRAIN Batch 104/2800 loss 19.064232 loss_att 8.381748 loss_ctc 43.990021 loss_ctc_origin 28.722307 loss_ctc0 79.614685 lr 0.00082036 rank 0
2022-08-24 11:16:21,122 DEBUG TRAIN Batch 104/2900 loss 21.618153 loss_att 9.112093 loss_ctc 50.798958 loss_ctc_origin 34.300835 loss_ctc0 89.294579 lr 0.00082030 rank 0
2022-08-24 11:16:54,629 DEBUG TRAIN Batch 104/3000 loss 37.655716 loss_att 25.608795 loss_ctc 65.765198 loss_ctc_origin 42.809189 loss_ctc0 119.329208 lr 0.00082023 rank 0
2022-08-24 11:17:23,415 DEBUG TRAIN Batch 104/3100 loss 50.679104 loss_att 27.332832 loss_ctc 105.153732 loss_ctc_origin 49.880257 loss_ctc0 234.125153 lr 0.00082016 rank 0
2022-08-24 11:17:52,534 DEBUG TRAIN Batch 104/3200 loss 21.814871 loss_att 11.778019 loss_ctc 45.234192 loss_ctc_origin 35.061558 loss_ctc0 68.970337 lr 0.00082009 rank 0
2022-08-24 11:18:21,387 DEBUG TRAIN Batch 104/3300 loss 26.801538 loss_att 14.078279 loss_ctc 56.489143 loss_ctc_origin 43.433022 loss_ctc0 86.953423 lr 0.00082002 rank 0
2022-08-24 11:18:31,935 WARNING NaN or Inf found in input tensor.
2022-08-24 11:18:49,440 DEBUG TRAIN Batch 104/3400 loss 28.145088 loss_att 13.348396 loss_ctc 62.670696 loss_ctc_origin 44.720997 loss_ctc0 104.553329 lr 0.00081995 rank 0
2022-08-24 11:19:18,943 DEBUG TRAIN Batch 104/3500 loss 41.083000 loss_att 23.054140 loss_ctc 83.150330 loss_ctc_origin 42.195347 loss_ctc0 178.711960 lr 0.00081988 rank 0
2022-08-24 11:19:47,521 DEBUG TRAIN Batch 104/3600 loss 45.181580 loss_att 20.546740 loss_ctc 102.662872 loss_ctc_origin 46.877556 loss_ctc0 232.828598 lr 0.00081981 rank 0
2022-08-24 11:20:14,916 DEBUG TRAIN Batch 104/3700 loss 20.005844 loss_att 11.325965 loss_ctc 40.258896 loss_ctc_origin 29.515669 loss_ctc0 65.326416 lr 0.00081974 rank 0
2022-08-24 11:20:43,074 DEBUG TRAIN Batch 104/3800 loss 22.292746 loss_att 10.461388 loss_ctc 49.899246 loss_ctc_origin 36.344246 loss_ctc0 81.527588 lr 0.00081967 rank 0
2022-08-24 11:21:11,589 DEBUG TRAIN Batch 104/3900 loss 24.963827 loss_att 11.793880 loss_ctc 55.693699 loss_ctc_origin 37.877754 loss_ctc0 97.264236 lr 0.00081961 rank 0
2022-08-24 11:21:40,869 DEBUG TRAIN Batch 104/4000 loss 48.919098 loss_att 30.668600 loss_ctc 91.503586 loss_ctc_origin 49.938377 loss_ctc0 188.489059 lr 0.00081954 rank 0
2022-08-24 11:22:08,855 DEBUG TRAIN Batch 104/4100 loss 42.865002 loss_att 22.364319 loss_ctc 90.699921 loss_ctc_origin 44.006054 loss_ctc0 199.652283 lr 0.00081947 rank 0
2022-08-24 11:22:37,267 DEBUG TRAIN Batch 104/4200 loss 22.029270 loss_att 12.158518 loss_ctc 45.061028 loss_ctc_origin 34.342674 loss_ctc0 70.070526 lr 0.00081940 rank 0
2022-08-24 11:23:03,432 WARNING NaN or Inf found in input tensor.
2022-08-24 11:23:06,188 DEBUG TRAIN Batch 104/4300 loss 21.362862 loss_att 9.731175 loss_ctc 48.503456 loss_ctc_origin 34.153748 loss_ctc0 81.986115 lr 0.00081933 rank 0
2022-08-24 11:23:33,274 DEBUG TRAIN Batch 104/4400 loss 22.998827 loss_att 9.943466 loss_ctc 53.461330 loss_ctc_origin 36.089142 loss_ctc0 93.996429 lr 0.00081926 rank 0
2022-08-24 11:24:08,243 DEBUG TRAIN Batch 104/4500 loss 39.043446 loss_att 22.031620 loss_ctc 78.737709 loss_ctc_origin 45.504593 loss_ctc0 156.281647 lr 0.00081919 rank 0
2022-08-24 11:24:23,222 WARNING NaN or Inf found in input tensor.
2022-08-24 11:24:36,272 DEBUG TRAIN Batch 104/4600 loss 46.584286 loss_att 28.597742 loss_ctc 88.552887 loss_ctc_origin 53.341202 loss_ctc0 170.713470 lr 0.00081912 rank 0
2022-08-24 11:25:04,407 DEBUG TRAIN Batch 104/4700 loss 20.507786 loss_att 10.680902 loss_ctc 43.437176 loss_ctc_origin 33.730507 loss_ctc0 66.086067 lr 0.00081906 rank 0
2022-08-24 11:25:32,513 DEBUG TRAIN Batch 104/4800 loss 23.274511 loss_att 10.597963 loss_ctc 52.853123 loss_ctc_origin 40.136574 loss_ctc0 82.525063 lr 0.00081899 rank 0
2022-08-24 11:26:00,053 DEBUG TRAIN Batch 104/4900 loss 27.717125 loss_att 13.647305 loss_ctc 60.546700 loss_ctc_origin 45.100735 loss_ctc0 96.587280 lr 0.00081892 rank 0
2022-08-24 11:26:28,457 DEBUG TRAIN Batch 104/5000 loss 42.741665 loss_att 26.646580 loss_ctc 80.296860 loss_ctc_origin 48.739014 loss_ctc0 153.931824 lr 0.00081885 rank 0
2022-08-24 11:26:56,435 DEBUG TRAIN Batch 104/5100 loss 41.061249 loss_att 27.111359 loss_ctc 73.610985 loss_ctc_origin 48.134426 loss_ctc0 133.056274 lr 0.00081878 rank 0
2022-08-24 11:27:25,391 DEBUG TRAIN Batch 104/5200 loss 24.603073 loss_att 13.739244 loss_ctc 49.952003 loss_ctc_origin 39.975685 loss_ctc0 73.230072 lr 0.00081871 rank 0
2022-08-24 11:27:52,861 DEBUG TRAIN Batch 104/5300 loss 21.802855 loss_att 10.199377 loss_ctc 48.877632 loss_ctc_origin 35.796032 loss_ctc0 79.401367 lr 0.00081864 rank 0
2022-08-24 11:28:09,654 WARNING NaN or Inf found in input tensor.
2022-08-24 11:28:21,017 DEBUG TRAIN Batch 104/5400 loss 21.342506 loss_att 9.398056 loss_ctc 49.212891 loss_ctc_origin 30.821386 loss_ctc0 92.126389 lr 0.00081858 rank 0
2022-08-24 11:28:49,756 WARNING NaN or Inf found in input tensor.
2022-08-24 11:28:49,799 DEBUG TRAIN Batch 104/5500 loss inf loss_att 32.838177 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00081851 rank 0
2022-08-24 11:29:17,110 DEBUG TRAIN Batch 104/5600 loss 50.581589 loss_att 27.819494 loss_ctc 103.693146 loss_ctc_origin 57.019936 loss_ctc0 212.597290 lr 0.00081844 rank 0
2022-08-24 11:29:39,769 DEBUG CV Batch 104/0 loss 12.167309 loss_att 8.831541 loss_ctc 19.950764 loss_ctc_origin 13.764297 loss_ctc0 34.385849 history loss 11.451585 rank 0
2022-08-24 11:29:50,324 DEBUG CV Batch 104/100 loss 23.162104 loss_att 18.185795 loss_ctc 34.773491 loss_ctc_origin 24.166134 loss_ctc0 59.523983 history loss 28.078041 rank 0
2022-08-24 11:30:00,141 DEBUG CV Batch 104/200 loss 25.739830 loss_att 19.926376 loss_ctc 39.304558 loss_ctc_origin 28.657776 loss_ctc0 64.147057 history loss 29.601278 rank 0
2022-08-24 11:30:10,191 DEBUG CV Batch 104/300 loss 24.272491 loss_att 18.831577 loss_ctc 36.967957 loss_ctc_origin 21.310162 loss_ctc0 73.502808 history loss 28.618501 rank 0
2022-08-24 11:30:20,722 DEBUG CV Batch 104/400 loss 39.949455 loss_att 32.917236 loss_ctc 56.357967 loss_ctc_origin 39.249626 loss_ctc0 96.277428 history loss 27.006558 rank 0
2022-08-24 11:30:31,312 DEBUG CV Batch 104/500 loss 17.128681 loss_att 12.871934 loss_ctc 27.061092 loss_ctc_origin 20.423309 loss_ctc0 42.549255 history loss 26.675657 rank 0
2022-08-24 11:30:41,492 DEBUG CV Batch 104/600 loss 19.892717 loss_att 13.988976 loss_ctc 33.668114 loss_ctc_origin 20.839468 loss_ctc0 63.601612 history loss 26.506272 rank 0
2022-08-24 11:30:51,342 DEBUG CV Batch 104/700 loss 20.042934 loss_att 13.821563 loss_ctc 34.559467 loss_ctc_origin 21.462757 loss_ctc0 65.118454 history loss 26.147183 rank 0
2022-08-24 11:31:01,372 DEBUG CV Batch 104/800 loss 22.902935 loss_att 17.475210 loss_ctc 35.567627 loss_ctc_origin 20.676256 loss_ctc0 70.314148 history loss 26.095018 rank 0
2022-08-24 11:31:11,479 INFO Epoch 104 CV info cv_loss 26.16895154935829
2022-08-24 11:31:11,479 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/104.pt
2022-08-24 11:31:11,933 INFO Epoch 105 TRAIN info lr 0.0008183810269003939
2022-08-24 11:31:11,937 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 11:31:38,207 DEBUG TRAIN Batch 105/0 loss 50.486816 loss_att 35.581837 loss_ctc 85.265106 loss_ctc_origin 54.601772 loss_ctc0 156.812881 lr 0.00081838 rank 0
2022-08-24 11:32:06,520 DEBUG TRAIN Batch 105/100 loss 43.687325 loss_att 26.186474 loss_ctc 84.522644 loss_ctc_origin 52.121864 loss_ctc0 160.124435 lr 0.00081831 rank 0
2022-08-24 11:32:34,686 DEBUG TRAIN Batch 105/200 loss 18.270187 loss_att 9.749147 loss_ctc 38.152615 loss_ctc_origin 27.931328 loss_ctc0 62.002281 lr 0.00081824 rank 0
2022-08-24 11:33:03,212 DEBUG TRAIN Batch 105/300 loss 21.279680 loss_att 9.392141 loss_ctc 49.017273 loss_ctc_origin 34.536304 loss_ctc0 82.806198 lr 0.00081817 rank 0
2022-08-24 11:33:31,560 DEBUG TRAIN Batch 105/400 loss 28.792759 loss_att 14.459903 loss_ctc 62.236088 loss_ctc_origin 45.165199 loss_ctc0 102.068161 lr 0.00081810 rank 0
2022-08-24 11:33:59,753 DEBUG TRAIN Batch 105/500 loss 54.211472 loss_att 37.618969 loss_ctc 92.927307 loss_ctc_origin 59.260315 loss_ctc0 171.483612 lr 0.00081804 rank 0
2022-08-24 11:34:26,938 DEBUG TRAIN Batch 105/600 loss 41.204597 loss_att 25.027931 loss_ctc 78.950157 loss_ctc_origin 56.411491 loss_ctc0 131.540375 lr 0.00081797 rank 0
2022-08-24 11:34:55,379 DEBUG TRAIN Batch 105/700 loss 20.381668 loss_att 11.771378 loss_ctc 40.472340 loss_ctc_origin 29.968966 loss_ctc0 64.980209 lr 0.00081790 rank 0
2022-08-24 11:35:23,981 DEBUG TRAIN Batch 105/800 loss 22.010334 loss_att 9.897917 loss_ctc 50.272636 loss_ctc_origin 35.618755 loss_ctc0 84.465027 lr 0.00081783 rank 0
2022-08-24 11:35:52,594 DEBUG TRAIN Batch 105/900 loss 24.940147 loss_att 10.881630 loss_ctc 57.743355 loss_ctc_origin 43.463360 loss_ctc0 91.063339 lr 0.00081776 rank 0
2022-08-24 11:35:55,202 WARNING NaN or Inf found in input tensor.
2022-08-24 11:36:20,592 DEBUG TRAIN Batch 105/1000 loss 51.066376 loss_att 34.023739 loss_ctc 90.832520 loss_ctc_origin 54.888084 loss_ctc0 174.702850 lr 0.00081769 rank 0
2022-08-24 11:36:46,799 DEBUG TRAIN Batch 105/1100 loss 53.721458 loss_att 31.481943 loss_ctc 105.613663 loss_ctc_origin 53.478844 loss_ctc0 227.261566 lr 0.00081763 rank 0
2022-08-24 11:37:13,756 DEBUG TRAIN Batch 105/1200 loss 17.090103 loss_att 9.337675 loss_ctc 35.179100 loss_ctc_origin 23.911377 loss_ctc0 61.470463 lr 0.00081756 rank 0
2022-08-24 11:37:40,729 DEBUG TRAIN Batch 105/1300 loss 20.095661 loss_att 9.772396 loss_ctc 44.183273 loss_ctc_origin 31.427221 loss_ctc0 73.947388 lr 0.00081749 rank 0
2022-08-24 11:38:09,434 DEBUG TRAIN Batch 105/1400 loss 24.454361 loss_att 11.841393 loss_ctc 53.884621 loss_ctc_origin 35.899147 loss_ctc0 95.850716 lr 0.00081742 rank 0
2022-08-24 11:38:43,441 DEBUG TRAIN Batch 105/1500 loss 55.955971 loss_att 40.800472 loss_ctc 91.318802 loss_ctc_origin 62.511871 loss_ctc0 158.534973 lr 0.00081735 rank 0
2022-08-24 11:39:11,808 DEBUG TRAIN Batch 105/1600 loss 47.751659 loss_att 29.265766 loss_ctc 90.885406 loss_ctc_origin 65.445053 loss_ctc0 150.246216 lr 0.00081728 rank 0
2022-08-24 11:39:38,759 DEBUG TRAIN Batch 105/1700 loss 22.072186 loss_att 12.842798 loss_ctc 43.607422 loss_ctc_origin 34.206375 loss_ctc0 65.543190 lr 0.00081722 rank 0
2022-08-24 11:40:06,973 DEBUG TRAIN Batch 105/1800 loss 21.164551 loss_att 10.394163 loss_ctc 46.295456 loss_ctc_origin 31.605776 loss_ctc0 80.571381 lr 0.00081715 rank 0
2022-08-24 11:40:34,854 DEBUG TRAIN Batch 105/1900 loss 24.528042 loss_att 11.857342 loss_ctc 54.093010 loss_ctc_origin 35.940475 loss_ctc0 96.448929 lr 0.00081708 rank 0
2022-08-24 11:41:03,399 DEBUG TRAIN Batch 105/2000 loss 43.530895 loss_att 27.823849 loss_ctc 80.180664 loss_ctc_origin 53.190804 loss_ctc0 143.157013 lr 0.00081701 rank 0
2022-08-24 11:41:31,060 DEBUG TRAIN Batch 105/2100 loss 46.758003 loss_att 26.817987 loss_ctc 93.284698 loss_ctc_origin 53.963776 loss_ctc0 185.033493 lr 0.00081694 rank 0
2022-08-24 11:41:58,679 DEBUG TRAIN Batch 105/2200 loss 25.309765 loss_att 14.529808 loss_ctc 50.462997 loss_ctc_origin 41.741600 loss_ctc0 70.812927 lr 0.00081688 rank 0
2022-08-24 11:42:25,816 DEBUG TRAIN Batch 105/2300 loss 17.089590 loss_att 7.607801 loss_ctc 39.213760 loss_ctc_origin 24.771027 loss_ctc0 72.913467 lr 0.00081681 rank 0
2022-08-24 11:42:53,563 DEBUG TRAIN Batch 105/2400 loss 22.876368 loss_att 9.873329 loss_ctc 53.216789 loss_ctc_origin 34.060745 loss_ctc0 97.914230 lr 0.00081674 rank 0
2022-08-24 11:43:20,653 DEBUG TRAIN Batch 105/2500 loss 42.772293 loss_att 30.162222 loss_ctc 72.195786 loss_ctc_origin 48.461704 loss_ctc0 127.575317 lr 0.00081667 rank 0
2022-08-24 11:43:41,579 WARNING NaN or Inf found in input tensor.
2022-08-24 11:43:48,819 DEBUG TRAIN Batch 105/2600 loss 41.109604 loss_att 24.898512 loss_ctc 78.935478 loss_ctc_origin 45.541203 loss_ctc0 156.855453 lr 0.00081660 rank 0
2022-08-24 11:44:16,033 DEBUG TRAIN Batch 105/2700 loss 24.694525 loss_att 14.414730 loss_ctc 48.680710 loss_ctc_origin 38.647125 loss_ctc0 72.092407 lr 0.00081653 rank 0
2022-08-24 11:44:44,303 DEBUG TRAIN Batch 105/2800 loss 22.661243 loss_att 9.414001 loss_ctc 53.571476 loss_ctc_origin 40.021606 loss_ctc0 85.187836 lr 0.00081647 rank 0
2022-08-24 11:45:11,521 DEBUG TRAIN Batch 105/2900 loss 21.960083 loss_att 9.358100 loss_ctc 51.364708 loss_ctc_origin 33.844143 loss_ctc0 92.246033 lr 0.00081640 rank 0
2022-08-24 11:45:44,816 DEBUG TRAIN Batch 105/3000 loss 54.888718 loss_att 34.037621 loss_ctc 103.541275 loss_ctc_origin 63.962151 loss_ctc0 195.892563 lr 0.00081633 rank 0
2022-08-24 11:46:11,596 WARNING NaN or Inf found in input tensor.
2022-08-24 11:46:12,424 DEBUG TRAIN Batch 105/3100 loss 49.312557 loss_att 31.818346 loss_ctc 90.132378 loss_ctc_origin 64.345917 loss_ctc0 150.300781 lr 0.00081626 rank 0
2022-08-24 11:46:39,802 DEBUG TRAIN Batch 105/3200 loss 23.671417 loss_att 15.128440 loss_ctc 43.605030 loss_ctc_origin 32.055477 loss_ctc0 70.553986 lr 0.00081619 rank 0
2022-08-24 11:47:07,724 DEBUG TRAIN Batch 105/3300 loss 21.368509 loss_att 10.351102 loss_ctc 47.075790 loss_ctc_origin 31.690681 loss_ctc0 82.974380 lr 0.00081613 rank 0
2022-08-24 11:47:36,160 DEBUG TRAIN Batch 105/3400 loss 28.242592 loss_att 13.381640 loss_ctc 62.918148 loss_ctc_origin 47.500866 loss_ctc0 98.891800 lr 0.00081606 rank 0
2022-08-24 11:48:04,698 DEBUG TRAIN Batch 105/3500 loss 49.881374 loss_att 34.008698 loss_ctc 86.917618 loss_ctc_origin 56.064926 loss_ctc0 158.907242 lr 0.00081599 rank 0
2022-08-24 11:48:12,471 WARNING NaN or Inf found in input tensor.
2022-08-24 11:48:25,288 WARNING NaN or Inf found in input tensor.
2022-08-24 11:48:32,013 DEBUG TRAIN Batch 105/3600 loss 49.734245 loss_att 30.166111 loss_ctc 95.393219 loss_ctc_origin 57.188938 loss_ctc0 184.536514 lr 0.00081592 rank 0
2022-08-24 11:49:00,154 DEBUG TRAIN Batch 105/3700 loss 29.642799 loss_att 20.119705 loss_ctc 51.863350 loss_ctc_origin 42.874725 loss_ctc0 72.836807 lr 0.00081586 rank 0
2022-08-24 11:49:28,052 DEBUG TRAIN Batch 105/3800 loss 21.165710 loss_att 10.008821 loss_ctc 47.198456 loss_ctc_origin 34.350929 loss_ctc0 77.176018 lr 0.00081579 rank 0
2022-08-24 11:49:44,247 WARNING NaN or Inf found in input tensor.
2022-08-24 11:49:51,556 WARNING NaN or Inf found in input tensor.
2022-08-24 11:49:56,218 DEBUG TRAIN Batch 105/3900 loss 26.745350 loss_att 12.381411 loss_ctc 60.261200 loss_ctc_origin 43.412647 loss_ctc0 99.574486 lr 0.00081572 rank 0
2022-08-24 11:50:23,943 DEBUG TRAIN Batch 105/4000 loss 43.006474 loss_att 28.256268 loss_ctc 77.423622 loss_ctc_origin 48.242378 loss_ctc0 145.513184 lr 0.00081565 rank 0
2022-08-24 11:50:53,076 DEBUG TRAIN Batch 105/4100 loss 43.474106 loss_att 27.219082 loss_ctc 81.402496 loss_ctc_origin 51.374191 loss_ctc0 151.468536 lr 0.00081558 rank 0
2022-08-24 11:51:20,911 DEBUG TRAIN Batch 105/4200 loss 21.951437 loss_att 11.229560 loss_ctc 46.969147 loss_ctc_origin 36.895500 loss_ctc0 70.474319 lr 0.00081552 rank 0
2022-08-24 11:51:48,093 DEBUG TRAIN Batch 105/4300 loss 20.854734 loss_att 10.472454 loss_ctc 45.080055 loss_ctc_origin 31.405769 loss_ctc0 76.986732 lr 0.00081545 rank 0
2022-08-24 11:52:16,367 DEBUG TRAIN Batch 105/4400 loss 22.897274 loss_att 10.623603 loss_ctc 51.535835 loss_ctc_origin 33.052574 loss_ctc0 94.663452 lr 0.00081538 rank 0
2022-08-24 11:52:51,912 DEBUG TRAIN Batch 105/4500 loss 43.217045 loss_att 28.775822 loss_ctc 76.913231 loss_ctc_origin 46.241417 loss_ctc0 148.480789 lr 0.00081531 rank 0
2022-08-24 11:53:19,721 DEBUG TRAIN Batch 105/4600 loss 45.922611 loss_att 31.580196 loss_ctc 79.388245 loss_ctc_origin 58.529106 loss_ctc0 128.059555 lr 0.00081524 rank 0
2022-08-24 11:53:47,687 DEBUG TRAIN Batch 105/4700 loss 22.591080 loss_att 12.694836 loss_ctc 45.682312 loss_ctc_origin 33.965164 loss_ctc0 73.022316 lr 0.00081518 rank 0
2022-08-24 11:54:16,265 DEBUG TRAIN Batch 105/4800 loss 24.770172 loss_att 11.950211 loss_ctc 54.683418 loss_ctc_origin 42.767876 loss_ctc0 82.486351 lr 0.00081511 rank 0
2022-08-24 11:54:44,081 DEBUG TRAIN Batch 105/4900 loss 26.218878 loss_att 12.418900 loss_ctc 58.418823 loss_ctc_origin 40.207111 loss_ctc0 100.912811 lr 0.00081504 rank 0
2022-08-24 11:55:12,549 DEBUG TRAIN Batch 105/5000 loss 37.523193 loss_att 24.197886 loss_ctc 68.615578 loss_ctc_origin 39.851921 loss_ctc0 135.730774 lr 0.00081497 rank 0
2022-08-24 11:55:39,973 DEBUG TRAIN Batch 105/5100 loss 47.660393 loss_att 27.998322 loss_ctc 93.538559 loss_ctc_origin 54.430565 loss_ctc0 184.790527 lr 0.00081491 rank 0
2022-08-24 11:56:07,752 DEBUG TRAIN Batch 105/5200 loss 27.151321 loss_att 15.134123 loss_ctc 55.191452 loss_ctc_origin 45.610302 loss_ctc0 77.547462 lr 0.00081484 rank 0
2022-08-24 11:56:35,275 DEBUG TRAIN Batch 105/5300 loss 21.773958 loss_att 9.595350 loss_ctc 50.190712 loss_ctc_origin 37.083061 loss_ctc0 80.775223 lr 0.00081477 rank 0
2022-08-24 11:57:03,234 DEBUG TRAIN Batch 105/5400 loss 24.392410 loss_att 10.723464 loss_ctc 56.286613 loss_ctc_origin 40.053398 loss_ctc0 94.164116 lr 0.00081470 rank 0
2022-08-24 11:57:32,195 DEBUG TRAIN Batch 105/5500 loss 52.934578 loss_att 37.244156 loss_ctc 89.545563 loss_ctc_origin 60.686550 loss_ctc0 156.883270 lr 0.00081464 rank 0
2022-08-24 11:57:59,739 DEBUG TRAIN Batch 105/5600 loss 45.407776 loss_att 30.413406 loss_ctc 80.394638 loss_ctc_origin 56.956131 loss_ctc0 135.084503 lr 0.00081457 rank 0
2022-08-24 11:58:22,131 DEBUG CV Batch 105/0 loss 13.140290 loss_att 9.665255 loss_ctc 21.248707 loss_ctc_origin 15.010750 loss_ctc0 35.803936 history loss 12.367332 rank 0
2022-08-24 11:58:32,371 DEBUG CV Batch 105/100 loss 22.843193 loss_att 17.445805 loss_ctc 35.437096 loss_ctc_origin 23.500793 loss_ctc0 63.288467 history loss 27.804556 rank 0
2022-08-24 11:58:41,905 DEBUG CV Batch 105/200 loss 25.206741 loss_att 19.508980 loss_ctc 38.501514 loss_ctc_origin 27.996971 loss_ctc0 63.012112 history loss 29.288132 rank 0
2022-08-24 11:58:51,543 DEBUG CV Batch 105/300 loss 23.859558 loss_att 18.293562 loss_ctc 36.846886 loss_ctc_origin 21.208870 loss_ctc0 73.335579 history loss 28.363774 rank 0
2022-08-24 11:59:01,642 DEBUG CV Batch 105/400 loss 39.463615 loss_att 31.906393 loss_ctc 57.097130 loss_ctc_origin 40.062508 loss_ctc0 96.844574 history loss 26.695127 rank 0
2022-08-24 11:59:12,048 DEBUG CV Batch 105/500 loss 17.545662 loss_att 13.330386 loss_ctc 27.381304 loss_ctc_origin 20.446545 loss_ctc0 43.562408 history loss 26.370908 rank 0
2022-08-24 11:59:22,168 DEBUG CV Batch 105/600 loss 20.866421 loss_att 14.315194 loss_ctc 36.152618 loss_ctc_origin 23.527508 loss_ctc0 65.611206 history loss 26.237476 rank 0
2022-08-24 11:59:31,997 DEBUG CV Batch 105/700 loss 19.666386 loss_att 13.308885 loss_ctc 34.500553 loss_ctc_origin 21.329376 loss_ctc0 65.233299 history loss 25.893566 rank 0
2022-08-24 11:59:41,983 DEBUG CV Batch 105/800 loss 23.130367 loss_att 17.691292 loss_ctc 35.821541 loss_ctc_origin 20.455456 loss_ctc0 71.675743 history loss 25.854893 rank 0
2022-08-24 11:59:51,950 INFO Epoch 105 CV info cv_loss 25.931945016381295
2022-08-24 11:59:51,950 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/105.pt
2022-08-24 11:59:52,391 INFO Epoch 106 TRAIN info lr 0.0008145115913847184
2022-08-24 11:59:52,395 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 12:00:18,015 DEBUG TRAIN Batch 106/0 loss 44.644554 loss_att 29.747599 loss_ctc 79.404114 loss_ctc_origin 54.181572 loss_ctc0 138.256714 lr 0.00081451 rank 0
2022-08-24 12:00:45,217 DEBUG TRAIN Batch 106/100 loss 46.058743 loss_att 29.041870 loss_ctc 85.764771 loss_ctc_origin 56.095222 loss_ctc0 154.993713 lr 0.00081444 rank 0
2022-08-24 12:00:51,603 WARNING NaN or Inf found in input tensor.
2022-08-24 12:01:13,171 DEBUG TRAIN Batch 106/200 loss 20.930069 loss_att 10.761292 loss_ctc 44.657211 loss_ctc_origin 33.500854 loss_ctc0 70.688705 lr 0.00081437 rank 0
2022-08-24 12:01:40,299 DEBUG TRAIN Batch 106/300 loss 19.686802 loss_att 8.804045 loss_ctc 45.079903 loss_ctc_origin 31.011578 loss_ctc0 77.905998 lr 0.00081431 rank 0
2022-08-24 12:02:08,078 DEBUG TRAIN Batch 106/400 loss 20.889727 loss_att 10.042608 loss_ctc 46.199665 loss_ctc_origin 27.645893 loss_ctc0 89.491798 lr 0.00081424 rank 0
2022-08-24 12:02:36,676 DEBUG TRAIN Batch 106/500 loss 43.051819 loss_att 27.217548 loss_ctc 79.998444 loss_ctc_origin 43.977646 loss_ctc0 164.046967 lr 0.00081417 rank 0
2022-08-24 12:03:03,920 DEBUG TRAIN Batch 106/600 loss 50.373413 loss_att 30.645094 loss_ctc 96.406166 loss_ctc_origin 66.240067 loss_ctc0 166.793732 lr 0.00081410 rank 0
2022-08-24 12:03:30,187 WARNING NaN or Inf found in input tensor.
2022-08-24 12:03:31,882 DEBUG TRAIN Batch 106/700 loss 27.139858 loss_att 15.428352 loss_ctc 54.466705 loss_ctc_origin 44.479698 loss_ctc0 77.769722 lr 0.00081404 rank 0
2022-08-24 12:03:58,843 DEBUG TRAIN Batch 106/800 loss 20.193413 loss_att 8.789606 loss_ctc 46.802296 loss_ctc_origin 33.411053 loss_ctc0 78.048523 lr 0.00081397 rank 0
2022-08-24 12:04:27,541 DEBUG TRAIN Batch 106/900 loss 27.203079 loss_att 12.259738 loss_ctc 62.070877 loss_ctc_origin 45.462959 loss_ctc0 100.822685 lr 0.00081390 rank 0
2022-08-24 12:04:55,952 WARNING NaN or Inf found in input tensor.
2022-08-24 12:04:55,995 DEBUG TRAIN Batch 106/1000 loss inf loss_att 29.082813 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00081383 rank 0
2022-08-24 12:05:24,249 DEBUG TRAIN Batch 106/1100 loss 43.750965 loss_att 27.358526 loss_ctc 81.999985 loss_ctc_origin 53.874844 loss_ctc0 147.625290 lr 0.00081377 rank 0
2022-08-24 12:05:44,218 WARNING NaN or Inf found in input tensor.
2022-08-24 12:05:52,803 DEBUG TRAIN Batch 106/1200 loss 21.057808 loss_att 10.910614 loss_ctc 44.734592 loss_ctc_origin 33.304726 loss_ctc0 71.404282 lr 0.00081370 rank 0
2022-08-24 12:06:22,350 DEBUG TRAIN Batch 106/1300 loss 20.740677 loss_att 9.040682 loss_ctc 48.040661 loss_ctc_origin 31.414814 loss_ctc0 86.834297 lr 0.00081363 rank 0
2022-08-24 12:06:45,818 WARNING NaN or Inf found in input tensor.
2022-08-24 12:06:50,311 DEBUG TRAIN Batch 106/1400 loss 24.130564 loss_att 11.320109 loss_ctc 54.021622 loss_ctc_origin 36.152363 loss_ctc0 95.716553 lr 0.00081356 rank 0
2022-08-24 12:07:23,644 DEBUG TRAIN Batch 106/1500 loss 49.921768 loss_att 33.785976 loss_ctc 87.571945 loss_ctc_origin 58.979507 loss_ctc0 154.287628 lr 0.00081350 rank 0
2022-08-24 12:07:51,595 DEBUG TRAIN Batch 106/1600 loss 43.433491 loss_att 28.982521 loss_ctc 77.152420 loss_ctc_origin 53.133842 loss_ctc0 133.195755 lr 0.00081343 rank 0
2022-08-24 12:08:19,562 DEBUG TRAIN Batch 106/1700 loss 22.697872 loss_att 13.327238 loss_ctc 44.562683 loss_ctc_origin 33.627110 loss_ctc0 70.079010 lr 0.00081336 rank 0
2022-08-24 12:08:47,723 DEBUG TRAIN Batch 106/1800 loss 21.091530 loss_att 9.398962 loss_ctc 48.374187 loss_ctc_origin 34.759865 loss_ctc0 80.140938 lr 0.00081330 rank 0
2022-08-24 12:09:15,571 DEBUG TRAIN Batch 106/1900 loss 28.508646 loss_att 12.737437 loss_ctc 65.308128 loss_ctc_origin 47.407829 loss_ctc0 107.075500 lr 0.00081323 rank 0
2022-08-24 12:09:44,991 DEBUG TRAIN Batch 106/2000 loss 49.225002 loss_att 32.363934 loss_ctc 88.567497 loss_ctc_origin 60.227333 loss_ctc0 154.694534 lr 0.00081316 rank 0
2022-08-24 12:10:13,789 DEBUG TRAIN Batch 106/2100 loss 46.917473 loss_att 30.446888 loss_ctc 85.348831 loss_ctc_origin 60.528015 loss_ctc0 143.264084 lr 0.00081309 rank 0
2022-08-24 12:10:41,707 DEBUG TRAIN Batch 106/2200 loss 18.567600 loss_att 10.131013 loss_ctc 38.252968 loss_ctc_origin 27.128689 loss_ctc0 64.209625 lr 0.00081303 rank 0
2022-08-24 12:11:10,416 DEBUG TRAIN Batch 106/2300 loss 22.066208 loss_att 9.393749 loss_ctc 51.635281 loss_ctc_origin 35.822739 loss_ctc0 88.531212 lr 0.00081296 rank 0
2022-08-24 12:11:38,517 DEBUG TRAIN Batch 106/2400 loss 27.751266 loss_att 14.447553 loss_ctc 58.793262 loss_ctc_origin 40.756531 loss_ctc0 100.878967 lr 0.00081289 rank 0
2022-08-24 12:12:07,462 DEBUG TRAIN Batch 106/2500 loss 40.907795 loss_att 24.310297 loss_ctc 79.635284 loss_ctc_origin 47.277500 loss_ctc0 155.136780 lr 0.00081283 rank 0
2022-08-24 12:12:35,524 DEBUG TRAIN Batch 106/2600 loss 58.392082 loss_att 35.025902 loss_ctc 112.913162 loss_ctc_origin 79.256264 loss_ctc0 191.445923 lr 0.00081276 rank 0
2022-08-24 12:13:02,513 DEBUG TRAIN Batch 106/2700 loss 23.417500 loss_att 14.205816 loss_ctc 44.911430 loss_ctc_origin 34.496071 loss_ctc0 69.213928 lr 0.00081269 rank 0
2022-08-24 12:13:30,742 DEBUG TRAIN Batch 106/2800 loss 25.659500 loss_att 12.308920 loss_ctc 56.810852 loss_ctc_origin 43.158943 loss_ctc0 88.665298 lr 0.00081262 rank 0
2022-08-24 12:13:59,491 DEBUG TRAIN Batch 106/2900 loss 24.936417 loss_att 11.475046 loss_ctc 56.346283 loss_ctc_origin 39.102146 loss_ctc0 96.582596 lr 0.00081256 rank 0
2022-08-24 12:14:33,384 DEBUG TRAIN Batch 106/3000 loss 40.178268 loss_att 25.582949 loss_ctc 74.234016 loss_ctc_origin 42.979340 loss_ctc0 147.161591 lr 0.00081249 rank 0
2022-08-24 12:15:01,691 DEBUG TRAIN Batch 106/3100 loss 45.786831 loss_att 24.802261 loss_ctc 94.750824 loss_ctc_origin 53.113777 loss_ctc0 191.903931 lr 0.00081242 rank 0
2022-08-24 12:15:28,680 DEBUG TRAIN Batch 106/3200 loss 22.570307 loss_att 13.793148 loss_ctc 43.050343 loss_ctc_origin 32.468758 loss_ctc0 67.740707 lr 0.00081236 rank 0
2022-08-24 12:15:55,854 DEBUG TRAIN Batch 106/3300 loss 24.345343 loss_att 12.291174 loss_ctc 52.471733 loss_ctc_origin 39.065266 loss_ctc0 83.753487 lr 0.00081229 rank 0
2022-08-24 12:16:20,412 WARNING NaN or Inf found in input tensor.
2022-08-24 12:16:24,845 DEBUG TRAIN Batch 106/3400 loss 20.366241 loss_att 8.712934 loss_ctc 47.557293 loss_ctc_origin 28.623230 loss_ctc0 91.736771 lr 0.00081222 rank 0
2022-08-24 12:16:53,825 DEBUG TRAIN Batch 106/3500 loss 45.715286 loss_att 31.466976 loss_ctc 78.961349 loss_ctc_origin 50.564098 loss_ctc0 145.221588 lr 0.00081216 rank 0
2022-08-24 12:17:21,125 DEBUG TRAIN Batch 106/3600 loss 38.494133 loss_att 21.873623 loss_ctc 77.275322 loss_ctc_origin 49.533058 loss_ctc0 142.007263 lr 0.00081209 rank 0
2022-08-24 12:17:49,251 DEBUG TRAIN Batch 106/3700 loss 22.805010 loss_att 11.242600 loss_ctc 49.783962 loss_ctc_origin 38.758743 loss_ctc0 75.509468 lr 0.00081202 rank 0
2022-08-24 12:18:18,215 DEBUG TRAIN Batch 106/3800 loss 19.695656 loss_att 9.037800 loss_ctc 44.563984 loss_ctc_origin 30.980965 loss_ctc0 76.257698 lr 0.00081195 rank 0
2022-08-24 12:18:41,437 WARNING NaN or Inf found in input tensor.
2022-08-24 12:18:46,035 DEBUG TRAIN Batch 106/3900 loss 27.529129 loss_att 12.102921 loss_ctc 63.523605 loss_ctc_origin 45.763073 loss_ctc0 104.964844 lr 0.00081189 rank 0
2022-08-24 12:19:13,445 DEBUG TRAIN Batch 106/4000 loss 48.249626 loss_att 31.345375 loss_ctc 87.692879 loss_ctc_origin 51.099461 loss_ctc0 173.077515 lr 0.00081182 rank 0
2022-08-24 12:19:41,802 DEBUG TRAIN Batch 106/4100 loss 47.259796 loss_att 27.751888 loss_ctc 92.778244 loss_ctc_origin 62.465393 loss_ctc0 163.508240 lr 0.00081175 rank 0
2022-08-24 12:20:09,446 DEBUG TRAIN Batch 106/4200 loss 19.878426 loss_att 12.128777 loss_ctc 37.960938 loss_ctc_origin 28.366858 loss_ctc0 60.347122 lr 0.00081169 rank 0
2022-08-24 12:20:35,953 DEBUG TRAIN Batch 106/4300 loss 18.740019 loss_att 8.301780 loss_ctc 43.095909 loss_ctc_origin 28.524399 loss_ctc0 77.096100 lr 0.00081162 rank 0
2022-08-24 12:20:53,087 WARNING NaN or Inf found in input tensor.
2022-08-24 12:21:04,065 DEBUG TRAIN Batch 106/4400 loss 25.909456 loss_att 11.801847 loss_ctc 58.827206 loss_ctc_origin 38.739265 loss_ctc0 105.699066 lr 0.00081155 rank 0
2022-08-24 12:21:39,022 DEBUG TRAIN Batch 106/4500 loss 46.831715 loss_att 29.778391 loss_ctc 86.622803 loss_ctc_origin 52.874535 loss_ctc0 165.368744 lr 0.00081149 rank 0
2022-08-24 12:21:54,160 WARNING NaN or Inf found in input tensor.
2022-08-24 12:22:07,081 DEBUG TRAIN Batch 106/4600 loss 43.550102 loss_att 27.567099 loss_ctc 80.843781 loss_ctc_origin 51.819656 loss_ctc0 148.566742 lr 0.00081142 rank 0
2022-08-24 12:22:35,345 DEBUG TRAIN Batch 106/4700 loss 19.579227 loss_att 10.892618 loss_ctc 39.847984 loss_ctc_origin 29.499447 loss_ctc0 63.994579 lr 0.00081135 rank 0
2022-08-24 12:23:03,571 DEBUG TRAIN Batch 106/4800 loss 21.399710 loss_att 9.973305 loss_ctc 48.061317 loss_ctc_origin 34.293518 loss_ctc0 80.186172 lr 0.00081129 rank 0
2022-08-24 12:23:31,592 DEBUG TRAIN Batch 106/4900 loss 23.044657 loss_att 10.103075 loss_ctc 53.241680 loss_ctc_origin 35.620758 loss_ctc0 94.357162 lr 0.00081122 rank 0
2022-08-24 12:24:00,581 DEBUG TRAIN Batch 106/5000 loss 40.010052 loss_att 26.556290 loss_ctc 71.402161 loss_ctc_origin 46.065895 loss_ctc0 130.520111 lr 0.00081115 rank 0
2022-08-24 12:24:08,479 WARNING NaN or Inf found in input tensor.
2022-08-24 12:24:28,316 DEBUG TRAIN Batch 106/5100 loss 48.496170 loss_att 32.161064 loss_ctc 86.611404 loss_ctc_origin 58.906548 loss_ctc0 151.256073 lr 0.00081109 rank 0
2022-08-24 12:24:55,353 DEBUG TRAIN Batch 106/5200 loss 25.434626 loss_att 15.907710 loss_ctc 47.664093 loss_ctc_origin 38.057030 loss_ctc0 70.080566 lr 0.00081102 rank 0
2022-08-24 12:25:24,452 DEBUG TRAIN Batch 106/5300 loss 18.634007 loss_att 7.487076 loss_ctc 44.643513 loss_ctc_origin 29.698231 loss_ctc0 79.515839 lr 0.00081095 rank 0
2022-08-24 12:25:53,068 DEBUG TRAIN Batch 106/5400 loss 24.066038 loss_att 10.742601 loss_ctc 55.154057 loss_ctc_origin 38.358120 loss_ctc0 94.344574 lr 0.00081089 rank 0
2022-08-24 12:26:21,263 DEBUG TRAIN Batch 106/5500 loss 43.820732 loss_att 28.238798 loss_ctc 80.178574 loss_ctc_origin 50.851467 loss_ctc0 148.608490 lr 0.00081082 rank 0
2022-08-24 12:26:48,541 DEBUG TRAIN Batch 106/5600 loss 39.303398 loss_att 24.866108 loss_ctc 72.990417 loss_ctc_origin 46.070641 loss_ctc0 135.803238 lr 0.00081075 rank 0
2022-08-24 12:27:11,945 DEBUG CV Batch 106/0 loss 13.335283 loss_att 9.817327 loss_ctc 21.543846 loss_ctc_origin 15.638404 loss_ctc0 35.323208 history loss 12.550855 rank 0
2022-08-24 12:27:22,425 DEBUG CV Batch 106/100 loss 25.937283 loss_att 19.995850 loss_ctc 39.800629 loss_ctc_origin 29.060265 loss_ctc0 64.861481 history loss 28.308781 rank 0
2022-08-24 12:27:32,010 DEBUG CV Batch 106/200 loss 25.082012 loss_att 19.051462 loss_ctc 39.153297 loss_ctc_origin 28.552200 loss_ctc0 63.889191 history loss 29.705911 rank 0
2022-08-24 12:27:42,020 DEBUG CV Batch 106/300 loss 24.296188 loss_att 18.526413 loss_ctc 37.758995 loss_ctc_origin 22.237309 loss_ctc0 73.976257 history loss 28.691678 rank 0
2022-08-24 12:27:52,275 DEBUG CV Batch 106/400 loss 38.788479 loss_att 31.479223 loss_ctc 55.843410 loss_ctc_origin 37.950294 loss_ctc0 97.594009 history loss 27.015173 rank 0
2022-08-24 12:28:03,029 DEBUG CV Batch 106/500 loss 17.493040 loss_att 13.323676 loss_ctc 27.221554 loss_ctc_origin 20.511055 loss_ctc0 42.879379 history loss 26.659610 rank 0
2022-08-24 12:28:13,522 DEBUG CV Batch 106/600 loss 20.074081 loss_att 13.736898 loss_ctc 34.860840 loss_ctc_origin 22.970108 loss_ctc0 62.605881 history loss 26.549475 rank 0
2022-08-24 12:28:23,470 DEBUG CV Batch 106/700 loss 19.623833 loss_att 13.276304 loss_ctc 34.434727 loss_ctc_origin 21.093582 loss_ctc0 65.564064 history loss 26.206656 rank 0
2022-08-24 12:28:34,064 DEBUG CV Batch 106/800 loss 22.470634 loss_att 17.107477 loss_ctc 34.984665 loss_ctc_origin 19.626078 loss_ctc0 70.821365 history loss 26.161423 rank 0
2022-08-24 12:28:44,193 INFO Epoch 106 CV info cv_loss 26.221239425585694
2022-08-24 12:28:44,193 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/106.pt
2022-08-24 12:28:44,624 INFO Epoch 107 TRAIN info lr 0.0008106965278288236
2022-08-24 12:28:44,627 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 12:29:10,374 DEBUG TRAIN Batch 107/0 loss 34.849258 loss_att 21.958855 loss_ctc 64.926872 loss_ctc_origin 37.083511 loss_ctc0 129.894714 lr 0.00081069 rank 0
2022-08-24 12:29:11,124 WARNING NaN or Inf found in input tensor.
2022-08-24 12:29:38,672 DEBUG TRAIN Batch 107/100 loss 48.348713 loss_att 32.029510 loss_ctc 86.426849 loss_ctc_origin 60.597061 loss_ctc0 146.696350 lr 0.00081063 rank 0
2022-08-24 12:30:05,691 DEBUG TRAIN Batch 107/200 loss 20.678156 loss_att 11.659136 loss_ctc 41.722534 loss_ctc_origin 30.348881 loss_ctc0 68.261047 lr 0.00081056 rank 0
2022-08-24 12:30:33,171 DEBUG TRAIN Batch 107/300 loss 19.259073 loss_att 8.394905 loss_ctc 44.608799 loss_ctc_origin 28.227989 loss_ctc0 82.830688 lr 0.00081049 rank 0
2022-08-24 12:31:01,046 DEBUG TRAIN Batch 107/400 loss 25.639364 loss_att 11.825949 loss_ctc 57.870667 loss_ctc_origin 41.607624 loss_ctc0 95.817772 lr 0.00081043 rank 0
2022-08-24 12:31:29,215 DEBUG TRAIN Batch 107/500 loss 54.027313 loss_att 37.854698 loss_ctc 91.763412 loss_ctc_origin 66.168068 loss_ctc0 151.485901 lr 0.00081036 rank 0
2022-08-24 12:31:56,447 DEBUG TRAIN Batch 107/600 loss 43.550217 loss_att 27.486851 loss_ctc 81.031403 loss_ctc_origin 53.668308 loss_ctc0 144.878632 lr 0.00081029 rank 0
2022-08-24 12:32:24,087 DEBUG TRAIN Batch 107/700 loss 22.708931 loss_att 14.330267 loss_ctc 42.259140 loss_ctc_origin 32.725941 loss_ctc0 64.503281 lr 0.00081023 rank 0
2022-08-24 12:32:51,560 DEBUG TRAIN Batch 107/800 loss 21.956928 loss_att 10.169912 loss_ctc 49.459965 loss_ctc_origin 35.560432 loss_ctc0 81.892204 lr 0.00081016 rank 0
2022-08-24 12:33:19,746 DEBUG TRAIN Batch 107/900 loss 22.326851 loss_att 10.621117 loss_ctc 49.640228 loss_ctc_origin 32.373810 loss_ctc0 89.928543 lr 0.00081010 rank 0
2022-08-24 12:33:48,116 DEBUG TRAIN Batch 107/1000 loss 44.724426 loss_att 29.785442 loss_ctc 79.582062 loss_ctc_origin 53.478745 loss_ctc0 140.489792 lr 0.00081003 rank 0
2022-08-24 12:34:15,108 WARNING NaN or Inf found in input tensor.
2022-08-24 12:34:15,896 DEBUG TRAIN Batch 107/1100 loss 46.769821 loss_att 32.990681 loss_ctc 78.921143 loss_ctc_origin 52.917202 loss_ctc0 139.597015 lr 0.00080996 rank 0
2022-08-24 12:34:43,426 DEBUG TRAIN Batch 107/1200 loss 20.678923 loss_att 11.959380 loss_ctc 41.024521 loss_ctc_origin 29.539438 loss_ctc0 67.823051 lr 0.00080990 rank 0
2022-08-24 12:35:12,107 DEBUG TRAIN Batch 107/1300 loss 20.329441 loss_att 8.744312 loss_ctc 47.361404 loss_ctc_origin 32.743080 loss_ctc0 81.470825 lr 0.00080983 rank 0
2022-08-24 12:35:39,956 DEBUG TRAIN Batch 107/1400 loss 22.434311 loss_att 9.919453 loss_ctc 51.635647 loss_ctc_origin 34.417007 loss_ctc0 91.812469 lr 0.00080976 rank 0
2022-08-24 12:36:13,565 DEBUG TRAIN Batch 107/1500 loss 48.993187 loss_att 33.400490 loss_ctc 85.376144 loss_ctc_origin 53.667046 loss_ctc0 159.364044 lr 0.00080970 rank 0
2022-08-24 12:36:41,651 DEBUG TRAIN Batch 107/1600 loss 39.136192 loss_att 22.103970 loss_ctc 78.878052 loss_ctc_origin 47.503632 loss_ctc0 152.085037 lr 0.00080963 rank 0
2022-08-24 12:37:10,203 DEBUG TRAIN Batch 107/1700 loss 20.419514 loss_att 11.803912 loss_ctc 40.522579 loss_ctc_origin 29.839138 loss_ctc0 65.450607 lr 0.00080956 rank 0
2022-08-24 12:37:38,057 DEBUG TRAIN Batch 107/1800 loss 23.082584 loss_att 10.931424 loss_ctc 51.435291 loss_ctc_origin 38.533379 loss_ctc0 81.539757 lr 0.00080950 rank 0
2022-08-24 12:38:05,819 DEBUG TRAIN Batch 107/1900 loss 28.189590 loss_att 12.935150 loss_ctc 63.783287 loss_ctc_origin 48.453659 loss_ctc0 99.552414 lr 0.00080943 rank 0
2022-08-24 12:38:34,540 DEBUG TRAIN Batch 107/2000 loss 47.140152 loss_att 29.870781 loss_ctc 87.435349 loss_ctc_origin 49.532463 loss_ctc0 175.875397 lr 0.00080937 rank 0
2022-08-24 12:39:01,286 DEBUG TRAIN Batch 107/2100 loss 40.652370 loss_att 21.467636 loss_ctc 85.416748 loss_ctc_origin 51.581478 loss_ctc0 164.365692 lr 0.00080930 rank 0
2022-08-24 12:39:29,692 DEBUG TRAIN Batch 107/2200 loss 23.609711 loss_att 13.571108 loss_ctc 47.033119 loss_ctc_origin 36.508675 loss_ctc0 71.590149 lr 0.00080923 rank 0
2022-08-24 12:39:57,644 DEBUG TRAIN Batch 107/2300 loss 19.521021 loss_att 8.901398 loss_ctc 44.300137 loss_ctc_origin 31.102795 loss_ctc0 75.093933 lr 0.00080917 rank 0
2022-08-24 12:40:26,666 DEBUG TRAIN Batch 107/2400 loss 26.808620 loss_att 11.956007 loss_ctc 61.464722 loss_ctc_origin 45.257301 loss_ctc0 99.282036 lr 0.00080910 rank 0
2022-08-24 12:40:55,046 DEBUG TRAIN Batch 107/2500 loss 49.240562 loss_att 31.387991 loss_ctc 90.896553 loss_ctc_origin 58.198025 loss_ctc0 167.193115 lr 0.00080903 rank 0
2022-08-24 12:41:22,289 DEBUG TRAIN Batch 107/2600 loss 49.117950 loss_att 28.532066 loss_ctc 97.151672 loss_ctc_origin 60.176170 loss_ctc0 183.427856 lr 0.00080897 rank 0
2022-08-24 12:41:50,222 DEBUG TRAIN Batch 107/2700 loss 20.924257 loss_att 11.035683 loss_ctc 43.997597 loss_ctc_origin 33.498993 loss_ctc0 68.494331 lr 0.00080890 rank 0
2022-08-24 12:42:18,771 DEBUG TRAIN Batch 107/2800 loss 23.105961 loss_att 9.205332 loss_ctc 55.540764 loss_ctc_origin 43.177322 loss_ctc0 84.388794 lr 0.00080884 rank 0
2022-08-24 12:42:35,758 WARNING NaN or Inf found in input tensor.
2022-08-24 12:42:46,936 DEBUG TRAIN Batch 107/2900 loss 26.084232 loss_att 12.204420 loss_ctc 58.470455 loss_ctc_origin 43.100937 loss_ctc0 94.332657 lr 0.00080877 rank 0
2022-08-24 12:43:22,052 DEBUG TRAIN Batch 107/3000 loss 49.871155 loss_att 33.202919 loss_ctc 88.763702 loss_ctc_origin 58.426018 loss_ctc0 159.551636 lr 0.00080870 rank 0
2022-08-24 12:43:49,908 DEBUG TRAIN Batch 107/3100 loss 47.359383 loss_att 27.503326 loss_ctc 93.690170 loss_ctc_origin 58.509605 loss_ctc0 175.778137 lr 0.00080864 rank 0
2022-08-24 12:44:17,755 DEBUG TRAIN Batch 107/3200 loss 21.497475 loss_att 11.895008 loss_ctc 43.903233 loss_ctc_origin 33.173325 loss_ctc0 68.939682 lr 0.00080857 rank 0
2022-08-24 12:44:44,448 WARNING NaN or Inf found in input tensor.
2022-08-24 12:44:47,028 DEBUG TRAIN Batch 107/3300 loss 20.488020 loss_att 8.860845 loss_ctc 47.618095 loss_ctc_origin 34.404789 loss_ctc0 78.449150 lr 0.00080850 rank 0
2022-08-24 12:45:15,229 DEBUG TRAIN Batch 107/3400 loss 25.011147 loss_att 11.960802 loss_ctc 55.461945 loss_ctc_origin 40.058701 loss_ctc0 91.402847 lr 0.00080844 rank 0
2022-08-24 12:45:42,614 DEBUG TRAIN Batch 107/3500 loss 45.573112 loss_att 30.727535 loss_ctc 80.212799 loss_ctc_origin 50.124168 loss_ctc0 150.419586 lr 0.00080837 rank 0
2022-08-24 12:46:10,203 DEBUG TRAIN Batch 107/3600 loss 47.054058 loss_att 30.342295 loss_ctc 86.048164 loss_ctc_origin 51.357437 loss_ctc0 166.993179 lr 0.00080831 rank 0
2022-08-24 12:46:38,576 DEBUG TRAIN Batch 107/3700 loss 20.034821 loss_att 11.947323 loss_ctc 38.905647 loss_ctc_origin 28.627596 loss_ctc0 62.887760 lr 0.00080824 rank 0
2022-08-24 12:47:07,179 DEBUG TRAIN Batch 107/3800 loss 20.856350 loss_att 10.059526 loss_ctc 46.048935 loss_ctc_origin 33.429970 loss_ctc0 75.493179 lr 0.00080817 rank 0
2022-08-24 12:47:23,420 WARNING NaN or Inf found in input tensor.
2022-08-24 12:47:34,674 DEBUG TRAIN Batch 107/3900 loss 26.689384 loss_att 12.015898 loss_ctc 60.927513 loss_ctc_origin 44.050598 loss_ctc0 100.306976 lr 0.00080811 rank 0
2022-08-24 12:48:01,822 DEBUG TRAIN Batch 107/4000 loss 45.778870 loss_att 30.737474 loss_ctc 80.875450 loss_ctc_origin 47.424114 loss_ctc0 158.928558 lr 0.00080804 rank 0
2022-08-24 12:48:30,695 DEBUG TRAIN Batch 107/4100 loss 32.745995 loss_att 20.623121 loss_ctc 61.032700 loss_ctc_origin 39.019165 loss_ctc0 112.397614 lr 0.00080798 rank 0
2022-08-24 12:48:58,285 DEBUG TRAIN Batch 107/4200 loss 22.189457 loss_att 12.544929 loss_ctc 44.693356 loss_ctc_origin 34.829063 loss_ctc0 67.710037 lr 0.00080791 rank 0
2022-08-24 12:49:25,458 DEBUG TRAIN Batch 107/4300 loss 21.678341 loss_att 9.076778 loss_ctc 51.081985 loss_ctc_origin 34.990799 loss_ctc0 88.628082 lr 0.00080785 rank 0
2022-08-24 12:49:53,553 DEBUG TRAIN Batch 107/4400 loss 24.011551 loss_att 10.441273 loss_ctc 55.675529 loss_ctc_origin 37.043751 loss_ctc0 99.149673 lr 0.00080778 rank 0
2022-08-24 12:50:27,935 DEBUG TRAIN Batch 107/4500 loss 53.455627 loss_att 34.808552 loss_ctc 96.965477 loss_ctc_origin 64.870728 loss_ctc0 171.853226 lr 0.00080771 rank 0
2022-08-24 12:50:56,668 DEBUG TRAIN Batch 107/4600 loss 52.502235 loss_att 29.491716 loss_ctc 106.193451 loss_ctc_origin 60.558750 loss_ctc0 212.674408 lr 0.00080765 rank 0
2022-08-24 12:51:24,332 DEBUG TRAIN Batch 107/4700 loss 17.363876 loss_att 10.067286 loss_ctc 34.389252 loss_ctc_origin 24.894646 loss_ctc0 56.543331 lr 0.00080758 rank 0
2022-08-24 12:51:52,095 DEBUG TRAIN Batch 107/4800 loss 23.039738 loss_att 10.266209 loss_ctc 52.844639 loss_ctc_origin 38.578201 loss_ctc0 86.132996 lr 0.00080752 rank 0
2022-08-24 12:52:19,097 DEBUG TRAIN Batch 107/4900 loss 22.486656 loss_att 10.195766 loss_ctc 51.165394 loss_ctc_origin 33.938934 loss_ctc0 91.360466 lr 0.00080745 rank 0
2022-08-24 12:52:49,022 DEBUG TRAIN Batch 107/5000 loss 46.441849 loss_att 31.909161 loss_ctc 80.351456 loss_ctc_origin 50.120785 loss_ctc0 150.889679 lr 0.00080738 rank 0
2022-08-24 12:53:09,091 WARNING NaN or Inf found in input tensor.
2022-08-24 12:53:15,826 DEBUG TRAIN Batch 107/5100 loss 53.741005 loss_att 34.521824 loss_ctc 98.585770 loss_ctc_origin 65.866867 loss_ctc0 174.929855 lr 0.00080732 rank 0
2022-08-24 12:53:40,973 WARNING NaN or Inf found in input tensor.
2022-08-24 12:53:42,491 DEBUG TRAIN Batch 107/5200 loss 21.393385 loss_att 12.785353 loss_ctc 41.478790 loss_ctc_origin 29.320408 loss_ctc0 69.848351 lr 0.00080725 rank 0
2022-08-24 12:53:47,705 WARNING NaN or Inf found in input tensor.
2022-08-24 12:54:10,532 DEBUG TRAIN Batch 107/5300 loss 22.870832 loss_att 10.982594 loss_ctc 50.610054 loss_ctc_origin 37.548019 loss_ctc0 81.088127 lr 0.00080719 rank 0
2022-08-24 12:54:38,288 DEBUG TRAIN Batch 107/5400 loss 23.938549 loss_att 10.617401 loss_ctc 55.021225 loss_ctc_origin 37.973270 loss_ctc0 94.799789 lr 0.00080712 rank 0
2022-08-24 12:55:06,570 DEBUG TRAIN Batch 107/5500 loss 46.536144 loss_att 30.434425 loss_ctc 84.106819 loss_ctc_origin 52.814014 loss_ctc0 157.123352 lr 0.00080706 rank 0
2022-08-24 12:55:34,230 DEBUG TRAIN Batch 107/5600 loss 41.079636 loss_att 23.110121 loss_ctc 83.008507 loss_ctc_origin 52.259159 loss_ctc0 154.756989 lr 0.00080699 rank 0
2022-08-24 12:55:56,790 DEBUG CV Batch 107/0 loss 13.525459 loss_att 9.965830 loss_ctc 21.831259 loss_ctc_origin 16.289146 loss_ctc0 34.762856 history loss 12.729844 rank 0
2022-08-24 12:56:07,624 DEBUG CV Batch 107/100 loss 24.711483 loss_att 18.962944 loss_ctc 38.124741 loss_ctc_origin 27.456036 loss_ctc0 63.018379 history loss 27.621489 rank 0
2022-08-24 12:56:16,969 DEBUG CV Batch 107/200 loss 26.470093 loss_att 20.494793 loss_ctc 40.412457 loss_ctc_origin 29.792645 loss_ctc0 65.192017 history loss 29.232776 rank 0
2022-08-24 12:56:26,627 DEBUG CV Batch 107/300 loss 24.178940 loss_att 18.296059 loss_ctc 37.905666 loss_ctc_origin 22.791714 loss_ctc0 73.171547 history loss 28.324649 rank 0
2022-08-24 12:56:36,882 DEBUG CV Batch 107/400 loss 38.757896 loss_att 31.114935 loss_ctc 56.591476 loss_ctc_origin 39.549053 loss_ctc0 96.357117 history loss 26.688222 rank 0
2022-08-24 12:56:47,290 DEBUG CV Batch 107/500 loss 16.876757 loss_att 12.670657 loss_ctc 26.690989 loss_ctc_origin 19.870661 loss_ctc0 42.605087 history loss 26.324131 rank 0
2022-08-24 12:56:57,684 DEBUG CV Batch 107/600 loss 19.945078 loss_att 13.352899 loss_ctc 35.326828 loss_ctc_origin 23.579319 loss_ctc0 62.737682 history loss 26.218982 rank 0
2022-08-24 12:57:07,289 DEBUG CV Batch 107/700 loss 19.093243 loss_att 12.546457 loss_ctc 34.369072 loss_ctc_origin 21.281744 loss_ctc0 64.906174 history loss 25.859279 rank 0
2022-08-24 12:57:17,582 DEBUG CV Batch 107/800 loss 22.163561 loss_att 16.924355 loss_ctc 34.388374 loss_ctc_origin 19.460213 loss_ctc0 69.220749 history loss 25.796499 rank 0
2022-08-24 12:57:27,860 INFO Epoch 107 CV info cv_loss 25.84622301282874
2022-08-24 12:57:27,860 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/107.pt
2022-08-24 12:57:28,291 INFO Epoch 108 TRAIN info lr 0.0008069345746862872
2022-08-24 12:57:28,294 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 12:57:54,378 DEBUG TRAIN Batch 108/0 loss 47.729416 loss_att 31.766857 loss_ctc 84.975388 loss_ctc_origin 52.909451 loss_ctc0 159.795898 lr 0.00080693 rank 0
2022-08-24 12:58:22,332 DEBUG TRAIN Batch 108/100 loss 44.081787 loss_att 26.711170 loss_ctc 84.613220 loss_ctc_origin 53.622116 loss_ctc0 156.925812 lr 0.00080687 rank 0
2022-08-24 12:58:49,693 DEBUG TRAIN Batch 108/200 loss 22.994263 loss_att 13.597713 loss_ctc 44.919544 loss_ctc_origin 35.385952 loss_ctc0 67.164589 lr 0.00080680 rank 0
2022-08-24 12:59:17,515 DEBUG TRAIN Batch 108/300 loss 19.477005 loss_att 9.365831 loss_ctc 43.069740 loss_ctc_origin 30.557896 loss_ctc0 72.264038 lr 0.00080673 rank 0
2022-08-24 12:59:45,865 DEBUG TRAIN Batch 108/400 loss 24.714197 loss_att 11.420740 loss_ctc 55.732262 loss_ctc_origin 38.031395 loss_ctc0 97.034286 lr 0.00080667 rank 0
2022-08-24 13:00:14,705 DEBUG TRAIN Batch 108/500 loss 40.105766 loss_att 24.775730 loss_ctc 75.875854 loss_ctc_origin 47.642479 loss_ctc0 141.753723 lr 0.00080660 rank 0
2022-08-24 13:00:42,184 DEBUG TRAIN Batch 108/600 loss 46.811954 loss_att 30.099709 loss_ctc 85.807190 loss_ctc_origin 60.110161 loss_ctc0 145.766922 lr 0.00080654 rank 0
2022-08-24 13:01:09,903 WARNING NaN or Inf found in input tensor.
2022-08-24 13:01:11,472 DEBUG TRAIN Batch 108/700 loss 19.473097 loss_att 9.933413 loss_ctc 41.732357 loss_ctc_origin 31.528461 loss_ctc0 65.541443 lr 0.00080647 rank 0
2022-08-24 13:01:38,776 DEBUG TRAIN Batch 108/800 loss 22.274345 loss_att 9.831442 loss_ctc 51.307785 loss_ctc_origin 37.159630 loss_ctc0 84.320145 lr 0.00080641 rank 0
2022-08-24 13:02:06,544 DEBUG TRAIN Batch 108/900 loss 22.013046 loss_att 9.790634 loss_ctc 50.532005 loss_ctc_origin 33.051140 loss_ctc0 91.320694 lr 0.00080634 rank 0
2022-08-24 13:02:35,155 DEBUG TRAIN Batch 108/1000 loss 43.911182 loss_att 27.806396 loss_ctc 81.489014 loss_ctc_origin 47.575550 loss_ctc0 160.620422 lr 0.00080628 rank 0
2022-08-24 13:03:02,379 DEBUG TRAIN Batch 108/1100 loss 44.025524 loss_att 31.131939 loss_ctc 74.110558 loss_ctc_origin 53.945412 loss_ctc0 121.162567 lr 0.00080621 rank 0
2022-08-24 13:03:30,086 DEBUG TRAIN Batch 108/1200 loss 18.113455 loss_att 8.929285 loss_ctc 39.543182 loss_ctc_origin 28.281185 loss_ctc0 65.821167 lr 0.00080614 rank 0
2022-08-24 13:03:58,367 DEBUG TRAIN Batch 108/1300 loss 20.219582 loss_att 9.280043 loss_ctc 45.745171 loss_ctc_origin 31.403395 loss_ctc0 79.209320 lr 0.00080608 rank 0
2022-08-24 13:04:27,955 DEBUG TRAIN Batch 108/1400 loss 26.588791 loss_att 11.391368 loss_ctc 62.049446 loss_ctc_origin 42.989792 loss_ctc0 106.521980 lr 0.00080601 rank 0
2022-08-24 13:05:02,532 DEBUG TRAIN Batch 108/1500 loss 50.586220 loss_att 33.342632 loss_ctc 90.821251 loss_ctc_origin 59.729980 loss_ctc0 163.367538 lr 0.00080595 rank 0
2022-08-24 13:05:30,293 DEBUG TRAIN Batch 108/1600 loss 44.699287 loss_att 29.960749 loss_ctc 79.089211 loss_ctc_origin 55.354927 loss_ctc0 134.469208 lr 0.00080588 rank 0
2022-08-24 13:05:57,436 DEBUG TRAIN Batch 108/1700 loss 19.891531 loss_att 11.273376 loss_ctc 40.000557 loss_ctc_origin 28.458855 loss_ctc0 66.931198 lr 0.00080582 rank 0
2022-08-24 13:06:24,689 DEBUG TRAIN Batch 108/1800 loss 23.608240 loss_att 11.349632 loss_ctc 52.211655 loss_ctc_origin 39.835846 loss_ctc0 81.088531 lr 0.00080575 rank 0
2022-08-24 13:06:52,306 DEBUG TRAIN Batch 108/1900 loss 27.408863 loss_att 13.907957 loss_ctc 58.910976 loss_ctc_origin 42.260368 loss_ctc0 97.762390 lr 0.00080569 rank 0
2022-08-24 13:07:20,669 DEBUG TRAIN Batch 108/2000 loss 46.246902 loss_att 32.318943 loss_ctc 78.745468 loss_ctc_origin 51.288712 loss_ctc0 142.811218 lr 0.00080562 rank 0
2022-08-24 13:07:49,094 DEBUG TRAIN Batch 108/2100 loss 38.177025 loss_att 26.584404 loss_ctc 65.226471 loss_ctc_origin 46.788574 loss_ctc0 108.248215 lr 0.00080556 rank 0
2022-08-24 13:08:16,264 DEBUG TRAIN Batch 108/2200 loss 21.640514 loss_att 11.672865 loss_ctc 44.898361 loss_ctc_origin 32.316971 loss_ctc0 74.254929 lr 0.00080549 rank 0
2022-08-24 13:08:45,063 DEBUG TRAIN Batch 108/2300 loss 23.200018 loss_att 10.754761 loss_ctc 52.238949 loss_ctc_origin 41.253735 loss_ctc0 77.871117 lr 0.00080543 rank 0
2022-08-24 13:09:13,489 DEBUG TRAIN Batch 108/2400 loss 24.514862 loss_att 11.627924 loss_ctc 54.584381 loss_ctc_origin 36.895157 loss_ctc0 95.859230 lr 0.00080536 rank 0
2022-08-24 13:09:41,571 DEBUG TRAIN Batch 108/2500 loss 40.830551 loss_att 29.320501 loss_ctc 67.687332 loss_ctc_origin 41.382484 loss_ctc0 129.065308 lr 0.00080529 rank 0
2022-08-24 13:10:09,561 DEBUG TRAIN Batch 108/2600 loss 46.396641 loss_att 29.587696 loss_ctc 85.617508 loss_ctc_origin 52.080666 loss_ctc0 163.870117 lr 0.00080523 rank 0
2022-08-24 13:10:36,704 DEBUG TRAIN Batch 108/2700 loss 23.956017 loss_att 14.908109 loss_ctc 45.067802 loss_ctc_origin 35.267044 loss_ctc0 67.936241 lr 0.00080516 rank 0
2022-08-24 13:11:03,719 DEBUG TRAIN Batch 108/2800 loss 22.285452 loss_att 9.792793 loss_ctc 51.434990 loss_ctc_origin 37.536530 loss_ctc0 83.864731 lr 0.00080510 rank 0
2022-08-24 13:11:30,704 DEBUG TRAIN Batch 108/2900 loss 23.615475 loss_att 10.316042 loss_ctc 54.647484 loss_ctc_origin 37.239532 loss_ctc0 95.266037 lr 0.00080503 rank 0
2022-08-24 13:11:40,580 WARNING NaN or Inf found in input tensor.
2022-08-24 13:12:05,513 DEBUG TRAIN Batch 108/3000 loss 41.963196 loss_att 26.391556 loss_ctc 78.297020 loss_ctc_origin 48.985867 loss_ctc0 146.689697 lr 0.00080497 rank 0
2022-08-24 13:12:34,048 DEBUG TRAIN Batch 108/3100 loss 40.143944 loss_att 26.272133 loss_ctc 72.511490 loss_ctc_origin 50.813568 loss_ctc0 123.139984 lr 0.00080490 rank 0
2022-08-24 13:13:01,450 DEBUG TRAIN Batch 108/3200 loss 23.418266 loss_att 13.129970 loss_ctc 47.424286 loss_ctc_origin 37.066437 loss_ctc0 71.592606 lr 0.00080484 rank 0
2022-08-24 13:13:30,174 DEBUG TRAIN Batch 108/3300 loss 23.506756 loss_att 11.218586 loss_ctc 52.179146 loss_ctc_origin 39.303665 loss_ctc0 82.221924 lr 0.00080477 rank 0
2022-08-24 13:13:58,178 DEBUG TRAIN Batch 108/3400 loss 19.502132 loss_att 8.759830 loss_ctc 44.567505 loss_ctc_origin 26.462715 loss_ctc0 86.812012 lr 0.00080471 rank 0
2022-08-24 13:14:27,024 DEBUG TRAIN Batch 108/3500 loss 42.670380 loss_att 27.158203 loss_ctc 78.865463 loss_ctc_origin 48.266220 loss_ctc0 150.263687 lr 0.00080464 rank 0
2022-08-24 13:14:54,768 DEBUG TRAIN Batch 108/3600 loss 40.674358 loss_att 24.518543 loss_ctc 78.371262 loss_ctc_origin 46.738991 loss_ctc0 152.179886 lr 0.00080458 rank 0
2022-08-24 13:15:22,914 DEBUG TRAIN Batch 108/3700 loss 20.272556 loss_att 12.217142 loss_ctc 39.068527 loss_ctc_origin 27.906754 loss_ctc0 65.112656 lr 0.00080451 rank 0
2022-08-24 13:15:51,017 DEBUG TRAIN Batch 108/3800 loss 19.043365 loss_att 8.573847 loss_ctc 43.472244 loss_ctc_origin 29.242353 loss_ctc0 76.675316 lr 0.00080445 rank 0
2022-08-24 13:16:18,390 DEBUG TRAIN Batch 108/3900 loss 22.199959 loss_att 9.993858 loss_ctc 50.680862 loss_ctc_origin 31.548410 loss_ctc0 95.323250 lr 0.00080438 rank 0
2022-08-24 13:16:45,740 DEBUG TRAIN Batch 108/4000 loss 38.085045 loss_att 22.962212 loss_ctc 73.371658 loss_ctc_origin 46.829971 loss_ctc0 135.302246 lr 0.00080432 rank 0
2022-08-24 13:17:13,625 WARNING NaN or Inf found in input tensor.
2022-08-24 13:17:13,667 DEBUG TRAIN Batch 108/4100 loss nan loss_att 28.848331 loss_ctc nan loss_ctc_origin 48.770332 loss_ctc0 nan lr 0.00080425 rank 0
2022-08-24 13:17:41,299 DEBUG TRAIN Batch 108/4200 loss 24.423201 loss_att 15.722044 loss_ctc 44.725899 loss_ctc_origin 35.773544 loss_ctc0 65.614716 lr 0.00080419 rank 0
2022-08-24 13:18:09,167 DEBUG TRAIN Batch 108/4300 loss 21.023455 loss_att 9.318472 loss_ctc 48.335079 loss_ctc_origin 35.121635 loss_ctc0 79.166451 lr 0.00080412 rank 0
2022-08-24 13:18:36,686 DEBUG TRAIN Batch 108/4400 loss 26.591854 loss_att 12.032961 loss_ctc 60.562599 loss_ctc_origin 43.797195 loss_ctc0 99.681870 lr 0.00080406 rank 0
2022-08-24 13:19:10,039 DEBUG TRAIN Batch 108/4500 loss 45.650112 loss_att 32.561829 loss_ctc 76.189438 loss_ctc_origin 52.958588 loss_ctc0 130.394745 lr 0.00080399 rank 0
2022-08-24 13:19:38,182 DEBUG TRAIN Batch 108/4600 loss 49.308273 loss_att 27.578711 loss_ctc 100.010574 loss_ctc_origin 60.724846 loss_ctc0 191.677246 lr 0.00080393 rank 0
2022-08-24 13:20:06,389 DEBUG TRAIN Batch 108/4700 loss 27.068596 loss_att 17.807674 loss_ctc 48.677406 loss_ctc_origin 39.756104 loss_ctc0 69.493790 lr 0.00080386 rank 0
2022-08-24 13:20:34,968 DEBUG TRAIN Batch 108/4800 loss 23.257942 loss_att 11.416052 loss_ctc 50.889015 loss_ctc_origin 37.349892 loss_ctc0 82.480293 lr 0.00080380 rank 0
2022-08-24 13:21:02,810 DEBUG TRAIN Batch 108/4900 loss 22.631550 loss_att 10.100378 loss_ctc 51.870949 loss_ctc_origin 33.992126 loss_ctc0 93.588203 lr 0.00080373 rank 0
2022-08-24 13:21:31,308 DEBUG TRAIN Batch 108/5000 loss 50.713654 loss_att 36.557617 loss_ctc 83.744400 loss_ctc_origin 56.112869 loss_ctc0 148.217972 lr 0.00080367 rank 0
2022-08-24 13:21:58,655 DEBUG TRAIN Batch 108/5100 loss 40.094803 loss_att 22.535631 loss_ctc 81.066200 loss_ctc_origin 44.476433 loss_ctc0 166.442322 lr 0.00080360 rank 0
2022-08-24 13:22:27,055 DEBUG TRAIN Batch 108/5200 loss 20.609907 loss_att 12.106354 loss_ctc 40.451530 loss_ctc_origin 29.728714 loss_ctc0 65.471436 lr 0.00080354 rank 0
2022-08-24 13:22:54,457 DEBUG TRAIN Batch 108/5300 loss 17.079634 loss_att 7.734530 loss_ctc 38.884872 loss_ctc_origin 26.385540 loss_ctc0 68.049988 lr 0.00080347 rank 0
2022-08-24 13:23:23,070 DEBUG TRAIN Batch 108/5400 loss 27.668863 loss_att 12.202620 loss_ctc 63.756760 loss_ctc_origin 45.889820 loss_ctc0 105.446281 lr 0.00080341 rank 0
2022-08-24 13:23:50,786 DEBUG TRAIN Batch 108/5500 loss 37.709602 loss_att 24.192383 loss_ctc 69.249786 loss_ctc_origin 40.155052 loss_ctc0 137.137512 lr 0.00080334 rank 0
2022-08-24 13:24:19,213 DEBUG TRAIN Batch 108/5600 loss 50.126492 loss_att 28.905487 loss_ctc 99.642166 loss_ctc_origin 53.666359 loss_ctc0 206.919037 lr 0.00080328 rank 0
2022-08-24 13:24:41,613 DEBUG CV Batch 108/0 loss 13.706652 loss_att 10.021486 loss_ctc 22.305368 loss_ctc_origin 16.388416 loss_ctc0 36.111588 history loss 12.900378 rank 0
2022-08-24 13:24:52,036 DEBUG CV Batch 108/100 loss 26.190441 loss_att 20.565098 loss_ctc 39.316246 loss_ctc_origin 29.267021 loss_ctc0 62.764435 history loss 28.460638 rank 0
2022-08-24 13:25:01,590 DEBUG CV Batch 108/200 loss 24.840572 loss_att 18.883198 loss_ctc 38.741112 loss_ctc_origin 28.140129 loss_ctc0 63.476742 history loss 29.763247 rank 0
2022-08-24 13:25:11,092 DEBUG CV Batch 108/300 loss 23.992111 loss_att 18.152138 loss_ctc 37.618717 loss_ctc_origin 22.339550 loss_ctc0 73.270111 history loss 28.777078 rank 0
2022-08-24 13:25:21,658 DEBUG CV Batch 108/400 loss 39.902279 loss_att 32.800827 loss_ctc 56.472328 loss_ctc_origin 38.948608 loss_ctc0 97.361015 history loss 27.029115 rank 0
2022-08-24 13:25:32,196 DEBUG CV Batch 108/500 loss 17.707451 loss_att 13.686590 loss_ctc 27.089462 loss_ctc_origin 20.231834 loss_ctc0 43.090591 history loss 26.659837 rank 0
2022-08-24 13:25:42,232 DEBUG CV Batch 108/600 loss 18.627970 loss_att 12.929332 loss_ctc 31.924791 loss_ctc_origin 20.927525 loss_ctc0 57.585075 history loss 26.523235 rank 0
2022-08-24 13:25:51,926 DEBUG CV Batch 108/700 loss 19.404488 loss_att 12.883764 loss_ctc 34.619511 loss_ctc_origin 21.342323 loss_ctc0 65.599609 history loss 26.169875 rank 0
2022-08-24 13:26:01,762 DEBUG CV Batch 108/800 loss 22.545769 loss_att 17.296543 loss_ctc 34.793957 loss_ctc_origin 19.498047 loss_ctc0 70.484406 history loss 26.126309 rank 0
2022-08-24 13:26:11,871 INFO Epoch 108 CV info cv_loss 26.197696996515642
2022-08-24 13:26:11,871 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/108.pt
2022-08-24 13:26:12,328 INFO Epoch 109 TRAIN info lr 0.0008032245110128348
2022-08-24 13:26:12,331 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 13:26:38,713 DEBUG TRAIN Batch 109/0 loss 45.186516 loss_att 29.977303 loss_ctc 80.674683 loss_ctc_origin 55.057014 loss_ctc0 140.449234 lr 0.00080322 rank 0
2022-08-24 13:27:06,691 DEBUG TRAIN Batch 109/100 loss 46.396034 loss_att 24.876221 loss_ctc 96.608925 loss_ctc_origin 53.325081 loss_ctc0 197.604553 lr 0.00080316 rank 0
2022-08-24 13:27:35,044 DEBUG TRAIN Batch 109/200 loss 18.840652 loss_att 11.213423 loss_ctc 36.637520 loss_ctc_origin 25.344696 loss_ctc0 62.987438 lr 0.00080309 rank 0
2022-08-24 13:28:02,881 DEBUG TRAIN Batch 109/300 loss 22.498390 loss_att 10.761638 loss_ctc 49.884144 loss_ctc_origin 37.316753 loss_ctc0 79.208054 lr 0.00080303 rank 0
2022-08-24 13:28:31,427 DEBUG TRAIN Batch 109/400 loss 24.630926 loss_att 11.000197 loss_ctc 56.435959 loss_ctc_origin 39.602699 loss_ctc0 95.713562 lr 0.00080296 rank 0
2022-08-24 13:29:00,292 DEBUG TRAIN Batch 109/500 loss 45.392624 loss_att 31.925005 loss_ctc 76.817062 loss_ctc_origin 51.057774 loss_ctc0 136.922058 lr 0.00080290 rank 0
2022-08-24 13:29:29,117 DEBUG TRAIN Batch 109/600 loss 39.306149 loss_att 22.094114 loss_ctc 79.467560 loss_ctc_origin 51.322418 loss_ctc0 145.139557 lr 0.00080283 rank 0
2022-08-24 13:29:57,802 DEBUG TRAIN Batch 109/700 loss 21.410742 loss_att 12.506721 loss_ctc 42.186790 loss_ctc_origin 31.230740 loss_ctc0 67.750900 lr 0.00080277 rank 0
2022-08-24 13:30:26,540 DEBUG TRAIN Batch 109/800 loss 21.560120 loss_att 10.453977 loss_ctc 47.474449 loss_ctc_origin 33.383198 loss_ctc0 80.354034 lr 0.00080270 rank 0
2022-08-24 13:30:54,695 DEBUG TRAIN Batch 109/900 loss 24.177683 loss_att 10.715433 loss_ctc 55.589600 loss_ctc_origin 35.925262 loss_ctc0 101.473045 lr 0.00080264 rank 0
2022-08-24 13:31:23,481 DEBUG TRAIN Batch 109/1000 loss 41.212097 loss_att 28.847340 loss_ctc 70.063187 loss_ctc_origin 46.639107 loss_ctc0 124.719391 lr 0.00080257 rank 0
2022-08-24 13:31:51,150 DEBUG TRAIN Batch 109/1100 loss 51.680580 loss_att 31.843376 loss_ctc 97.967377 loss_ctc_origin 60.406456 loss_ctc0 185.609512 lr 0.00080251 rank 0
2022-08-24 13:32:19,635 DEBUG TRAIN Batch 109/1200 loss 15.347277 loss_att 7.402313 loss_ctc 33.885525 loss_ctc_origin 21.663206 loss_ctc0 62.404266 lr 0.00080245 rank 0
2022-08-24 13:32:48,809 DEBUG TRAIN Batch 109/1300 loss 20.386896 loss_att 8.673018 loss_ctc 47.719276 loss_ctc_origin 34.753479 loss_ctc0 77.972809 lr 0.00080238 rank 0
2022-08-24 13:33:15,488 DEBUG TRAIN Batch 109/1400 loss 23.383348 loss_att 9.976833 loss_ctc 54.665215 loss_ctc_origin 38.456787 loss_ctc0 92.484879 lr 0.00080232 rank 0
2022-08-24 13:33:50,987 DEBUG TRAIN Batch 109/1500 loss 46.446068 loss_att 29.203651 loss_ctc 86.678360 loss_ctc_origin 54.229286 loss_ctc0 162.392853 lr 0.00080225 rank 0
2022-08-24 13:34:19,248 DEBUG TRAIN Batch 109/1600 loss 51.524780 loss_att 33.080971 loss_ctc 94.560333 loss_ctc_origin 54.130688 loss_ctc0 188.896179 lr 0.00080219 rank 0
2022-08-24 13:34:46,358 DEBUG TRAIN Batch 109/1700 loss 23.705395 loss_att 14.744628 loss_ctc 44.613853 loss_ctc_origin 35.028954 loss_ctc0 66.978615 lr 0.00080212 rank 0
2022-08-24 13:34:51,797 WARNING NaN or Inf found in input tensor.
2022-08-24 13:35:14,929 DEBUG TRAIN Batch 109/1800 loss 20.084610 loss_att 9.290246 loss_ctc 45.271461 loss_ctc_origin 30.714699 loss_ctc0 79.237251 lr 0.00080206 rank 0
2022-08-24 13:35:43,077 DEBUG TRAIN Batch 109/1900 loss 29.635990 loss_att 14.042110 loss_ctc 66.021706 loss_ctc_origin 51.293228 loss_ctc0 100.388153 lr 0.00080199 rank 0
2022-08-24 13:36:10,918 DEBUG TRAIN Batch 109/2000 loss 48.503967 loss_att 32.229046 loss_ctc 86.478775 loss_ctc_origin 59.234283 loss_ctc0 150.049255 lr 0.00080193 rank 0
2022-08-24 13:36:38,860 DEBUG TRAIN Batch 109/2100 loss 52.389343 loss_att 31.534479 loss_ctc 101.050690 loss_ctc_origin 63.493313 loss_ctc0 188.684540 lr 0.00080187 rank 0
2022-08-24 13:37:06,889 DEBUG TRAIN Batch 109/2200 loss 19.881210 loss_att 10.912069 loss_ctc 40.809208 loss_ctc_origin 29.072489 loss_ctc0 68.194885 lr 0.00080180 rank 0
2022-08-24 13:37:35,036 DEBUG TRAIN Batch 109/2300 loss 21.115822 loss_att 9.349281 loss_ctc 48.571083 loss_ctc_origin 35.163712 loss_ctc0 79.854950 lr 0.00080174 rank 0
2022-08-24 13:38:03,306 DEBUG TRAIN Batch 109/2400 loss 26.577858 loss_att 12.441544 loss_ctc 59.562592 loss_ctc_origin 42.073208 loss_ctc0 100.371155 lr 0.00080167 rank 0
2022-08-24 13:38:32,093 DEBUG TRAIN Batch 109/2500 loss 50.369881 loss_att 33.993675 loss_ctc 88.581024 loss_ctc_origin 60.257267 loss_ctc0 154.669785 lr 0.00080161 rank 0
2022-08-24 13:38:59,336 DEBUG TRAIN Batch 109/2600 loss 49.378681 loss_att 29.371199 loss_ctc 96.062805 loss_ctc_origin 53.516815 loss_ctc0 195.336792 lr 0.00080154 rank 0
2022-08-24 13:39:27,280 DEBUG TRAIN Batch 109/2700 loss 25.155897 loss_att 15.366087 loss_ctc 47.998787 loss_ctc_origin 38.197422 loss_ctc0 70.868629 lr 0.00080148 rank 0
2022-08-24 13:39:55,210 DEBUG TRAIN Batch 109/2800 loss 20.907480 loss_att 9.022756 loss_ctc 48.638504 loss_ctc_origin 32.732491 loss_ctc0 85.752525 lr 0.00080141 rank 0
2022-08-24 13:40:23,769 DEBUG TRAIN Batch 109/2900 loss 22.912434 loss_att 10.862316 loss_ctc 51.029373 loss_ctc_origin 31.415714 loss_ctc0 96.794571 lr 0.00080135 rank 0
2022-08-24 13:40:57,921 DEBUG TRAIN Batch 109/3000 loss 40.527618 loss_att 25.259186 loss_ctc 76.153954 loss_ctc_origin 45.459114 loss_ctc0 147.775238 lr 0.00080129 rank 0
2022-08-24 13:41:25,590 DEBUG TRAIN Batch 109/3100 loss 44.238235 loss_att 23.370022 loss_ctc 92.930740 loss_ctc_origin 48.712315 loss_ctc0 196.107071 lr 0.00080122 rank 0
2022-08-24 13:41:52,498 DEBUG TRAIN Batch 109/3200 loss 20.796961 loss_att 12.645411 loss_ctc 39.817242 loss_ctc_origin 28.700512 loss_ctc0 65.756271 lr 0.00080116 rank 0
2022-08-24 13:42:20,130 DEBUG TRAIN Batch 109/3300 loss 23.585632 loss_att 10.818727 loss_ctc 53.375076 loss_ctc_origin 39.910271 loss_ctc0 84.792946 lr 0.00080109 rank 0
2022-08-24 13:42:48,143 DEBUG TRAIN Batch 109/3400 loss 22.349121 loss_att 9.834595 loss_ctc 51.549683 loss_ctc_origin 34.769051 loss_ctc0 90.704483 lr 0.00080103 rank 0
2022-08-24 13:43:16,394 DEBUG TRAIN Batch 109/3500 loss 47.168446 loss_att 31.836212 loss_ctc 82.943649 loss_ctc_origin 56.331402 loss_ctc0 145.038879 lr 0.00080096 rank 0
2022-08-24 13:43:24,194 WARNING NaN or Inf found in input tensor.
2022-08-24 13:43:43,176 DEBUG TRAIN Batch 109/3600 loss 47.994019 loss_att 27.946842 loss_ctc 94.770767 loss_ctc_origin 54.973938 loss_ctc0 187.630035 lr 0.00080090 rank 0
2022-08-24 13:44:11,009 DEBUG TRAIN Batch 109/3700 loss 19.768526 loss_att 11.288454 loss_ctc 39.555359 loss_ctc_origin 27.989132 loss_ctc0 66.543228 lr 0.00080084 rank 0
2022-08-24 13:44:37,818 DEBUG TRAIN Batch 109/3800 loss 23.222038 loss_att 10.403914 loss_ctc 53.130989 loss_ctc_origin 38.527519 loss_ctc0 87.205750 lr 0.00080077 rank 0
2022-08-24 13:45:06,757 DEBUG TRAIN Batch 109/3900 loss 23.513517 loss_att 10.600924 loss_ctc 53.642899 loss_ctc_origin 35.178925 loss_ctc0 96.725502 lr 0.00080071 rank 0
2022-08-24 13:45:34,353 DEBUG TRAIN Batch 109/4000 loss 39.345146 loss_att 26.799320 loss_ctc 68.618744 loss_ctc_origin 44.508896 loss_ctc0 124.875069 lr 0.00080064 rank 0
2022-08-24 13:46:02,988 DEBUG TRAIN Batch 109/4100 loss 37.446999 loss_att 21.382807 loss_ctc 74.930115 loss_ctc_origin 38.004429 loss_ctc0 161.090027 lr 0.00080058 rank 0
2022-08-24 13:46:30,632 DEBUG TRAIN Batch 109/4200 loss 21.710392 loss_att 13.775152 loss_ctc 40.225945 loss_ctc_origin 29.026825 loss_ctc0 66.357224 lr 0.00080052 rank 0
2022-08-24 13:46:59,043 DEBUG TRAIN Batch 109/4300 loss 20.856333 loss_att 8.543207 loss_ctc 49.586956 loss_ctc_origin 32.763504 loss_ctc0 88.841675 lr 0.00080045 rank 0
2022-08-24 13:47:25,662 DEBUG TRAIN Batch 109/4400 loss 25.987825 loss_att 12.151143 loss_ctc 58.273415 loss_ctc_origin 42.748264 loss_ctc0 94.498764 lr 0.00080039 rank 0
2022-08-24 13:47:59,026 DEBUG TRAIN Batch 109/4500 loss 45.580967 loss_att 28.457092 loss_ctc 85.536674 loss_ctc_origin 51.431442 loss_ctc0 165.115540 lr 0.00080032 rank 0
2022-08-24 13:48:26,358 DEBUG TRAIN Batch 109/4600 loss 54.582634 loss_att 31.850061 loss_ctc 107.625290 loss_ctc_origin 63.661251 loss_ctc0 210.208054 lr 0.00080026 rank 0
2022-08-24 13:48:54,025 DEBUG TRAIN Batch 109/4700 loss 21.617428 loss_att 12.023748 loss_ctc 44.002678 loss_ctc_origin 32.368534 loss_ctc0 71.149017 lr 0.00080019 rank 0
2022-08-24 13:49:21,906 DEBUG TRAIN Batch 109/4800 loss 26.021196 loss_att 12.634421 loss_ctc 57.257000 loss_ctc_origin 43.145149 loss_ctc0 90.184647 lr 0.00080013 rank 0
2022-08-24 13:49:50,152 DEBUG TRAIN Batch 109/4900 loss 23.082258 loss_att 9.318045 loss_ctc 55.198753 loss_ctc_origin 38.947166 loss_ctc0 93.119118 lr 0.00080007 rank 0
2022-08-24 13:50:17,767 DEBUG TRAIN Batch 109/5000 loss 56.342762 loss_att 38.877842 loss_ctc 97.094238 loss_ctc_origin 70.412842 loss_ctc0 159.350815 lr 0.00080000 rank 0
2022-08-24 13:50:25,573 WARNING NaN or Inf found in input tensor.
2022-08-24 13:50:38,305 WARNING NaN or Inf found in input tensor.
2022-08-24 13:50:45,318 DEBUG TRAIN Batch 109/5100 loss 60.241058 loss_att 32.295540 loss_ctc 125.447266 loss_ctc_origin 64.316086 loss_ctc0 268.086670 lr 0.00079994 rank 0
2022-08-24 13:51:12,335 WARNING NaN or Inf found in input tensor.
2022-08-24 13:51:13,999 DEBUG TRAIN Batch 109/5200 loss 18.342197 loss_att 10.278139 loss_ctc 37.158337 loss_ctc_origin 25.217628 loss_ctc0 65.019989 lr 0.00079987 rank 0
2022-08-24 13:51:42,818 DEBUG TRAIN Batch 109/5300 loss 21.831383 loss_att 10.402679 loss_ctc 48.498360 loss_ctc_origin 32.975842 loss_ctc0 84.717560 lr 0.00079981 rank 0
2022-08-24 13:52:07,293 WARNING NaN or Inf found in input tensor.
2022-08-24 13:52:11,581 DEBUG TRAIN Batch 109/5400 loss 23.777908 loss_att 10.734417 loss_ctc 54.212723 loss_ctc_origin 36.805809 loss_ctc0 94.828842 lr 0.00079975 rank 0
2022-08-24 13:52:39,955 DEBUG TRAIN Batch 109/5500 loss 49.430923 loss_att 34.074257 loss_ctc 85.263145 loss_ctc_origin 51.824875 loss_ctc0 163.285767 lr 0.00079968 rank 0
2022-08-24 13:53:07,154 DEBUG TRAIN Batch 109/5600 loss 46.985344 loss_att 25.877644 loss_ctc 96.236641 loss_ctc_origin 49.940598 loss_ctc0 204.260742 lr 0.00079962 rank 0
2022-08-24 13:53:29,409 DEBUG CV Batch 109/0 loss 13.420005 loss_att 9.980766 loss_ctc 21.444893 loss_ctc_origin 15.809562 loss_ctc0 34.593998 history loss 12.630593 rank 0
2022-08-24 13:53:40,023 DEBUG CV Batch 109/100 loss 21.815350 loss_att 17.610992 loss_ctc 31.625519 loss_ctc_origin 21.475132 loss_ctc0 55.309750 history loss 27.461824 rank 0
2022-08-24 13:53:49,601 DEBUG CV Batch 109/200 loss 24.347065 loss_att 18.845070 loss_ctc 37.185059 loss_ctc_origin 26.745594 loss_ctc0 61.543804 history loss 28.615752 rank 0
2022-08-24 13:53:59,581 DEBUG CV Batch 109/300 loss 24.483408 loss_att 18.852711 loss_ctc 37.621700 loss_ctc_origin 22.519745 loss_ctc0 72.859596 history loss 27.713821 rank 0
2022-08-24 13:54:10,154 DEBUG CV Batch 109/400 loss 38.875320 loss_att 31.280340 loss_ctc 56.596939 loss_ctc_origin 39.498093 loss_ctc0 96.494247 history loss 26.097904 rank 0
2022-08-24 13:54:20,407 DEBUG CV Batch 109/500 loss 17.607841 loss_att 13.618254 loss_ctc 26.916876 loss_ctc_origin 20.104471 loss_ctc0 42.812485 history loss 25.768820 rank 0
2022-08-24 13:54:30,783 DEBUG CV Batch 109/600 loss 19.491226 loss_att 13.773827 loss_ctc 32.831821 loss_ctc_origin 20.594439 loss_ctc0 61.385712 history loss 25.636617 rank 0
2022-08-24 13:54:40,193 DEBUG CV Batch 109/700 loss 18.567890 loss_att 12.264172 loss_ctc 33.276569 loss_ctc_origin 20.042278 loss_ctc0 64.156578 history loss 25.277607 rank 0
2022-08-24 13:54:50,468 DEBUG CV Batch 109/800 loss 21.539352 loss_att 16.265091 loss_ctc 33.845963 loss_ctc_origin 18.364491 loss_ctc0 69.969391 history loss 25.232581 rank 0
2022-08-24 13:55:00,596 INFO Epoch 109 CV info cv_loss 25.31273437849332
2022-08-24 13:55:00,596 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/109.pt
2022-08-24 13:55:01,036 INFO Epoch 110 TRAIN info lr 0.0007995651548015278
2022-08-24 13:55:01,039 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 13:55:26,663 DEBUG TRAIN Batch 110/0 loss 55.136024 loss_att 40.965805 loss_ctc 88.199867 loss_ctc_origin 56.937782 loss_ctc0 161.144730 lr 0.00079956 rank 0
2022-08-24 13:55:53,827 DEBUG TRAIN Batch 110/100 loss 47.755531 loss_att 24.667305 loss_ctc 101.628067 loss_ctc_origin 54.501343 loss_ctc0 211.590408 lr 0.00079950 rank 0
2022-08-24 13:56:21,613 DEBUG TRAIN Batch 110/200 loss 21.348070 loss_att 12.234291 loss_ctc 42.613552 loss_ctc_origin 30.472683 loss_ctc0 70.942245 lr 0.00079943 rank 0
2022-08-24 13:56:49,054 DEBUG TRAIN Batch 110/300 loss 19.372911 loss_att 9.266511 loss_ctc 42.954510 loss_ctc_origin 30.987225 loss_ctc0 70.878174 lr 0.00079937 rank 0
2022-08-24 13:57:12,221 WARNING NaN or Inf found in input tensor.
2022-08-24 13:57:16,693 DEBUG TRAIN Batch 110/400 loss 25.634274 loss_att 12.160441 loss_ctc 57.073212 loss_ctc_origin 41.014862 loss_ctc0 94.542686 lr 0.00079931 rank 0
2022-08-24 13:57:45,140 DEBUG TRAIN Batch 110/500 loss 43.043087 loss_att 25.279160 loss_ctc 84.492249 loss_ctc_origin 48.315109 loss_ctc0 168.905579 lr 0.00079924 rank 0
2022-08-24 13:58:13,557 DEBUG TRAIN Batch 110/600 loss 52.867760 loss_att 29.549347 loss_ctc 107.277382 loss_ctc_origin 58.613052 loss_ctc0 220.827469 lr 0.00079918 rank 0
2022-08-24 13:58:40,373 DEBUG TRAIN Batch 110/700 loss 22.399967 loss_att 12.510133 loss_ctc 45.476250 loss_ctc_origin 35.837479 loss_ctc0 67.966705 lr 0.00079912 rank 0
2022-08-24 13:59:08,131 DEBUG TRAIN Batch 110/800 loss 19.835443 loss_att 8.688299 loss_ctc 45.845444 loss_ctc_origin 30.942837 loss_ctc0 80.618202 lr 0.00079905 rank 0
2022-08-24 13:59:31,847 WARNING NaN or Inf found in input tensor.
2022-08-24 13:59:36,283 DEBUG TRAIN Batch 110/900 loss 22.116793 loss_att 10.154169 loss_ctc 50.029579 loss_ctc_origin 34.222218 loss_ctc0 86.913414 lr 0.00079899 rank 0
2022-08-24 14:00:05,273 DEBUG TRAIN Batch 110/1000 loss 54.034420 loss_att 35.945992 loss_ctc 96.240753 loss_ctc_origin 61.186134 loss_ctc0 178.034882 lr 0.00079892 rank 0
2022-08-24 14:00:18,241 WARNING NaN or Inf found in input tensor.
2022-08-24 14:00:31,755 DEBUG TRAIN Batch 110/1100 loss 52.795799 loss_att 29.861919 loss_ctc 106.308189 loss_ctc_origin 58.874981 loss_ctc0 216.985672 lr 0.00079886 rank 0
2022-08-24 14:00:59,404 DEBUG TRAIN Batch 110/1200 loss 23.314320 loss_att 14.239548 loss_ctc 44.488785 loss_ctc_origin 35.672829 loss_ctc0 65.059341 lr 0.00079880 rank 0
2022-08-24 14:01:28,411 DEBUG TRAIN Batch 110/1300 loss 21.510443 loss_att 9.506468 loss_ctc 49.519714 loss_ctc_origin 34.260170 loss_ctc0 85.125313 lr 0.00079873 rank 0
2022-08-24 14:01:56,639 DEBUG TRAIN Batch 110/1400 loss 24.122679 loss_att 11.149792 loss_ctc 54.392746 loss_ctc_origin 38.574104 loss_ctc0 91.302910 lr 0.00079867 rank 0
2022-08-24 14:02:30,556 DEBUG TRAIN Batch 110/1500 loss 44.300995 loss_att 28.600788 loss_ctc 80.934799 loss_ctc_origin 50.011078 loss_ctc0 153.090149 lr 0.00079861 rank 0
2022-08-24 14:02:37,922 WARNING NaN or Inf found in input tensor.
2022-08-24 14:02:58,065 DEBUG TRAIN Batch 110/1600 loss 51.580193 loss_att 29.067776 loss_ctc 104.109161 loss_ctc_origin 57.759087 loss_ctc0 212.259338 lr 0.00079854 rank 0
2022-08-24 14:03:26,280 DEBUG TRAIN Batch 110/1700 loss 21.120716 loss_att 12.178761 loss_ctc 41.985275 loss_ctc_origin 32.989536 loss_ctc0 62.975334 lr 0.00079848 rank 0
2022-08-24 14:03:54,526 DEBUG TRAIN Batch 110/1800 loss 18.212585 loss_att 8.158354 loss_ctc 41.672459 loss_ctc_origin 28.446390 loss_ctc0 72.533279 lr 0.00079841 rank 0
2022-08-24 14:04:22,701 DEBUG TRAIN Batch 110/1900 loss 25.646673 loss_att 10.991142 loss_ctc 59.842911 loss_ctc_origin 43.741463 loss_ctc0 97.412949 lr 0.00079835 rank 0
2022-08-24 14:04:52,191 DEBUG TRAIN Batch 110/2000 loss 46.941246 loss_att 33.375519 loss_ctc 78.594604 loss_ctc_origin 51.948978 loss_ctc0 140.767731 lr 0.00079829 rank 0
2022-08-24 14:05:18,763 DEBUG TRAIN Batch 110/2100 loss 37.235664 loss_att 21.245558 loss_ctc 74.545914 loss_ctc_origin 42.802101 loss_ctc0 148.614807 lr 0.00079822 rank 0
2022-08-24 14:05:46,309 DEBUG TRAIN Batch 110/2200 loss 23.569828 loss_att 12.501300 loss_ctc 49.396397 loss_ctc_origin 43.028419 loss_ctc0 64.255005 lr 0.00079816 rank 0
2022-08-24 14:06:15,075 DEBUG TRAIN Batch 110/2300 loss 23.555538 loss_att 10.588923 loss_ctc 53.810966 loss_ctc_origin 40.488953 loss_ctc0 84.895660 lr 0.00079810 rank 0
2022-08-24 14:06:43,369 DEBUG TRAIN Batch 110/2400 loss 25.137487 loss_att 11.759695 loss_ctc 56.352333 loss_ctc_origin 39.031704 loss_ctc0 96.767128 lr 0.00079803 rank 0
2022-08-24 14:07:10,599 DEBUG TRAIN Batch 110/2500 loss 42.262238 loss_att 27.231421 loss_ctc 77.334145 loss_ctc_origin 45.676476 loss_ctc0 151.202026 lr 0.00079797 rank 0
2022-08-24 14:07:31,294 WARNING NaN or Inf found in input tensor.
2022-08-24 14:07:38,144 DEBUG TRAIN Batch 110/2600 loss 45.198845 loss_att 22.691416 loss_ctc 97.716171 loss_ctc_origin 50.242516 loss_ctc0 208.488037 lr 0.00079791 rank 0
2022-08-24 14:07:51,305 WARNING NaN or Inf found in input tensor.
2022-08-24 14:08:06,218 DEBUG TRAIN Batch 110/2700 loss 21.716511 loss_att 11.575681 loss_ctc 45.378441 loss_ctc_origin 34.978165 loss_ctc0 69.645744 lr 0.00079784 rank 0
2022-08-24 14:08:33,820 DEBUG TRAIN Batch 110/2800 loss 20.810793 loss_att 9.614347 loss_ctc 46.935833 loss_ctc_origin 33.548523 loss_ctc0 78.172890 lr 0.00079778 rank 0
2022-08-24 14:09:01,709 DEBUG TRAIN Batch 110/2900 loss 25.440922 loss_att 11.802149 loss_ctc 57.264717 loss_ctc_origin 39.930969 loss_ctc0 97.710129 lr 0.00079772 rank 0
2022-08-24 14:09:35,696 DEBUG TRAIN Batch 110/3000 loss 39.843151 loss_att 23.431728 loss_ctc 78.136467 loss_ctc_origin 45.456665 loss_ctc0 154.389343 lr 0.00079765 rank 0
2022-08-24 14:10:04,738 DEBUG TRAIN Batch 110/3100 loss 49.599110 loss_att 28.529575 loss_ctc 98.761353 loss_ctc_origin 53.849930 loss_ctc0 203.554672 lr 0.00079759 rank 0
2022-08-24 14:10:33,271 DEBUG TRAIN Batch 110/3200 loss 21.711079 loss_att 12.308698 loss_ctc 43.649963 loss_ctc_origin 33.838089 loss_ctc0 66.544334 lr 0.00079753 rank 0
2022-08-24 14:11:01,544 DEBUG TRAIN Batch 110/3300 loss 22.463345 loss_att 11.424198 loss_ctc 48.221352 loss_ctc_origin 35.795582 loss_ctc0 77.214806 lr 0.00079746 rank 0
2022-08-24 14:11:29,890 DEBUG TRAIN Batch 110/3400 loss 29.281937 loss_att 13.551247 loss_ctc 65.986877 loss_ctc_origin 47.739559 loss_ctc0 108.563965 lr 0.00079740 rank 0
2022-08-24 14:11:56,487 DEBUG TRAIN Batch 110/3500 loss 53.757717 loss_att 37.153782 loss_ctc 92.500229 loss_ctc_origin 62.652870 loss_ctc0 162.144073 lr 0.00079734 rank 0
2022-08-24 14:12:24,576 DEBUG TRAIN Batch 110/3600 loss 49.540344 loss_att 25.321880 loss_ctc 106.050102 loss_ctc_origin 53.481873 loss_ctc0 228.709290 lr 0.00079727 rank 0
2022-08-24 14:12:44,531 WARNING NaN or Inf found in input tensor.
2022-08-24 14:12:53,203 DEBUG TRAIN Batch 110/3700 loss 19.606079 loss_att 11.141239 loss_ctc 39.357376 loss_ctc_origin 28.748587 loss_ctc0 64.111221 lr 0.00079721 rank 0
2022-08-24 14:13:22,467 DEBUG TRAIN Batch 110/3800 loss 23.110790 loss_att 9.661102 loss_ctc 54.493393 loss_ctc_origin 39.973053 loss_ctc0 88.374176 lr 0.00079715 rank 0
2022-08-24 14:13:49,799 DEBUG TRAIN Batch 110/3900 loss 21.275604 loss_att 9.942410 loss_ctc 47.719719 loss_ctc_origin 31.052353 loss_ctc0 86.610229 lr 0.00079708 rank 0
2022-08-24 14:14:18,375 DEBUG TRAIN Batch 110/4000 loss 53.153526 loss_att 35.448559 loss_ctc 94.465103 loss_ctc_origin 56.875183 loss_ctc0 182.174927 lr 0.00079702 rank 0
2022-08-24 14:14:30,869 WARNING NaN or Inf found in input tensor.
2022-08-24 14:14:45,332 DEBUG TRAIN Batch 110/4100 loss 54.714020 loss_att 31.712578 loss_ctc 108.384041 loss_ctc_origin 57.464024 loss_ctc0 227.197418 lr 0.00079696 rank 0
2022-08-24 14:15:13,396 DEBUG TRAIN Batch 110/4200 loss 20.153313 loss_att 10.402534 loss_ctc 42.905128 loss_ctc_origin 32.781700 loss_ctc0 66.526466 lr 0.00079689 rank 0
2022-08-24 14:15:41,581 DEBUG TRAIN Batch 110/4300 loss 18.386665 loss_att 7.706447 loss_ctc 43.307175 loss_ctc_origin 28.468491 loss_ctc0 77.930779 lr 0.00079683 rank 0
2022-08-24 14:16:05,857 WARNING NaN or Inf found in input tensor.
2022-08-24 14:16:09,909 DEBUG TRAIN Batch 110/4400 loss 19.698463 loss_att 8.365097 loss_ctc 46.142982 loss_ctc_origin 30.208714 loss_ctc0 83.322937 lr 0.00079677 rank 0
2022-08-24 14:16:43,420 DEBUG TRAIN Batch 110/4500 loss 52.469376 loss_att 35.840961 loss_ctc 91.268997 loss_ctc_origin 55.179550 loss_ctc0 175.477707 lr 0.00079670 rank 0
2022-08-24 14:17:10,958 DEBUG TRAIN Batch 110/4600 loss 54.995285 loss_att 30.116865 loss_ctc 113.044922 loss_ctc_origin 61.613911 loss_ctc0 233.050598 lr 0.00079664 rank 0
2022-08-24 14:17:38,946 DEBUG TRAIN Batch 110/4700 loss 20.824133 loss_att 10.983306 loss_ctc 43.786060 loss_ctc_origin 33.361015 loss_ctc0 68.111160 lr 0.00079658 rank 0
2022-08-24 14:18:07,583 DEBUG TRAIN Batch 110/4800 loss 23.558704 loss_att 10.437249 loss_ctc 54.175434 loss_ctc_origin 39.298656 loss_ctc0 88.887909 lr 0.00079651 rank 0
2022-08-24 14:18:34,283 DEBUG TRAIN Batch 110/4900 loss 22.770111 loss_att 10.363188 loss_ctc 51.719593 loss_ctc_origin 33.347641 loss_ctc0 94.587479 lr 0.00079645 rank 0
2022-08-24 14:19:01,589 DEBUG TRAIN Batch 110/5000 loss 43.344147 loss_att 28.367208 loss_ctc 78.290337 loss_ctc_origin 43.922462 loss_ctc0 158.482040 lr 0.00079639 rank 0
2022-08-24 14:19:28,268 DEBUG TRAIN Batch 110/5100 loss 44.004208 loss_att 20.597244 loss_ctc 98.620453 loss_ctc_origin 47.506065 loss_ctc0 217.887329 lr 0.00079632 rank 0
2022-08-24 14:19:57,484 DEBUG TRAIN Batch 110/5200 loss 20.742638 loss_att 10.887020 loss_ctc 43.739075 loss_ctc_origin 31.346588 loss_ctc0 72.654869 lr 0.00079626 rank 0
2022-08-24 14:20:25,429 DEBUG TRAIN Batch 110/5300 loss 20.916431 loss_att 9.953232 loss_ctc 46.497227 loss_ctc_origin 33.742950 loss_ctc0 76.257202 lr 0.00079620 rank 0
2022-08-24 14:20:49,170 WARNING NaN or Inf found in input tensor.
2022-08-24 14:20:53,440 DEBUG TRAIN Batch 110/5400 loss 26.089533 loss_att 12.024458 loss_ctc 58.908043 loss_ctc_origin 44.286701 loss_ctc0 93.024506 lr 0.00079613 rank 0
2022-08-24 14:21:22,418 DEBUG TRAIN Batch 110/5500 loss 42.447590 loss_att 26.357994 loss_ctc 79.989975 loss_ctc_origin 48.356583 loss_ctc0 153.801224 lr 0.00079607 rank 0
2022-08-24 14:21:49,924 DEBUG TRAIN Batch 110/5600 loss 55.462208 loss_att 30.535078 loss_ctc 113.625504 loss_ctc_origin 59.359451 loss_ctc0 240.246277 lr 0.00079601 rank 0
2022-08-24 14:22:11,815 DEBUG CV Batch 110/0 loss 13.984922 loss_att 10.595577 loss_ctc 21.893394 loss_ctc_origin 16.145479 loss_ctc0 35.305199 history loss 13.162280 rank 0
2022-08-24 14:22:22,108 DEBUG CV Batch 110/100 loss 22.014015 loss_att 17.708622 loss_ctc 32.059929 loss_ctc_origin 22.276333 loss_ctc0 54.888313 history loss 27.696002 rank 0
2022-08-24 14:22:31,882 DEBUG CV Batch 110/200 loss 25.609154 loss_att 20.095425 loss_ctc 38.474518 loss_ctc_origin 28.365051 loss_ctc0 62.063274 history loss 28.958685 rank 0
2022-08-24 14:22:41,874 DEBUG CV Batch 110/300 loss 24.004728 loss_att 18.432793 loss_ctc 37.005909 loss_ctc_origin 21.492374 loss_ctc0 73.204155 history loss 27.928937 rank 0
2022-08-24 14:22:52,244 DEBUG CV Batch 110/400 loss 38.870468 loss_att 31.743971 loss_ctc 55.498962 loss_ctc_origin 37.951702 loss_ctc0 96.442574 history loss 26.233363 rank 0
2022-08-24 14:23:02,986 DEBUG CV Batch 110/500 loss 16.902679 loss_att 12.810905 loss_ctc 26.450153 loss_ctc_origin 19.364624 loss_ctc0 42.983055 history loss 25.862814 rank 0
2022-08-24 14:23:13,307 DEBUG CV Batch 110/600 loss 19.214355 loss_att 13.406799 loss_ctc 32.765316 loss_ctc_origin 21.357569 loss_ctc0 59.383392 history loss 25.682248 rank 0
2022-08-24 14:23:23,261 DEBUG CV Batch 110/700 loss 18.966793 loss_att 12.722934 loss_ctc 33.535797 loss_ctc_origin 20.398928 loss_ctc0 64.188499 history loss 25.332374 rank 0
2022-08-24 14:23:33,695 DEBUG CV Batch 110/800 loss 22.654491 loss_att 17.493469 loss_ctc 34.696877 loss_ctc_origin 19.217506 loss_ctc0 70.815407 history loss 25.292979 rank 0
2022-08-24 14:23:43,555 INFO Epoch 110 CV info cv_loss 25.365950612568543
2022-08-24 14:23:43,555 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/110.pt
2022-08-24 14:23:43,990 INFO Epoch 111 TRAIN info lr 0.0007959553614006289
2022-08-24 14:23:43,993 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 14:24:10,636 DEBUG TRAIN Batch 111/0 loss 54.700287 loss_att 37.104473 loss_ctc 95.757179 loss_ctc_origin 58.344681 loss_ctc0 183.053009 lr 0.00079595 rank 0
2022-08-24 14:24:38,663 DEBUG TRAIN Batch 111/100 loss 46.155273 loss_att 26.105042 loss_ctc 92.939148 loss_ctc_origin 48.689651 loss_ctc0 196.187973 lr 0.00079589 rank 0
2022-08-24 14:24:51,755 WARNING NaN or Inf found in input tensor.
2022-08-24 14:25:03,908 WARNING NaN or Inf found in input tensor.
2022-08-24 14:25:05,514 DEBUG TRAIN Batch 111/200 loss 24.136253 loss_att 14.354427 loss_ctc 46.960510 loss_ctc_origin 37.265564 loss_ctc0 69.582054 lr 0.00079583 rank 0
2022-08-24 14:25:33,719 DEBUG TRAIN Batch 111/300 loss 15.891235 loss_att 7.052658 loss_ctc 36.514580 loss_ctc_origin 22.223129 loss_ctc0 69.861290 lr 0.00079576 rank 0
2022-08-24 14:25:57,374 WARNING NaN or Inf found in input tensor.
2022-08-24 14:26:01,887 DEBUG TRAIN Batch 111/400 loss 22.103954 loss_att 9.648427 loss_ctc 51.166855 loss_ctc_origin 32.654106 loss_ctc0 94.363274 lr 0.00079570 rank 0
2022-08-24 14:26:30,188 DEBUG TRAIN Batch 111/500 loss 44.130226 loss_att 26.408672 loss_ctc 85.480515 loss_ctc_origin 46.855263 loss_ctc0 175.606110 lr 0.00079564 rank 0
2022-08-24 14:26:58,188 DEBUG TRAIN Batch 111/600 loss 51.044113 loss_att 26.888315 loss_ctc 107.407623 loss_ctc_origin 54.453972 loss_ctc0 230.966125 lr 0.00079557 rank 0
2022-08-24 14:27:27,032 DEBUG TRAIN Batch 111/700 loss 19.100157 loss_att 10.270456 loss_ctc 39.702793 loss_ctc_origin 28.748428 loss_ctc0 65.262978 lr 0.00079551 rank 0
2022-08-24 14:27:55,848 DEBUG TRAIN Batch 111/800 loss 18.863081 loss_att 7.705892 loss_ctc 44.896519 loss_ctc_origin 30.024158 loss_ctc0 79.598694 lr 0.00079545 rank 0
2022-08-24 14:28:23,588 DEBUG TRAIN Batch 111/900 loss 25.633095 loss_att 12.152277 loss_ctc 57.088333 loss_ctc_origin 37.639603 loss_ctc0 102.468712 lr 0.00079539 rank 0
2022-08-24 14:28:51,799 DEBUG TRAIN Batch 111/1000 loss 42.774490 loss_att 27.082872 loss_ctc 79.388260 loss_ctc_origin 44.080902 loss_ctc0 161.772079 lr 0.00079532 rank 0
2022-08-24 14:29:19,645 DEBUG TRAIN Batch 111/1100 loss 48.819496 loss_att 23.356903 loss_ctc 108.232208 loss_ctc_origin 52.557327 loss_ctc0 238.140274 lr 0.00079526 rank 0
2022-08-24 14:29:47,652 DEBUG TRAIN Batch 111/1200 loss 19.839245 loss_att 9.819633 loss_ctc 43.218338 loss_ctc_origin 30.646393 loss_ctc0 72.552879 lr 0.00079520 rank 0
2022-08-24 14:30:17,741 DEBUG TRAIN Batch 111/1300 loss 24.755100 loss_att 10.579060 loss_ctc 57.832527 loss_ctc_origin 45.782356 loss_ctc0 85.949585 lr 0.00079513 rank 0
2022-08-24 14:30:45,585 DEBUG TRAIN Batch 111/1400 loss 18.673880 loss_att 8.677227 loss_ctc 41.999397 loss_ctc_origin 23.520206 loss_ctc0 85.117508 lr 0.00079507 rank 0
2022-08-24 14:31:19,659 DEBUG TRAIN Batch 111/1500 loss 47.211292 loss_att 30.152035 loss_ctc 87.016220 loss_ctc_origin 54.985909 loss_ctc0 161.753601 lr 0.00079501 rank 0
2022-08-24 14:31:48,571 WARNING NaN or Inf found in input tensor.
2022-08-24 14:31:48,615 DEBUG TRAIN Batch 111/1600 loss nan loss_att 28.045765 loss_ctc nan loss_ctc_origin 56.051399 loss_ctc0 nan lr 0.00079495 rank 0
2022-08-24 14:32:16,752 DEBUG TRAIN Batch 111/1700 loss 21.470051 loss_att 11.921954 loss_ctc 43.748940 loss_ctc_origin 31.914776 loss_ctc0 71.361977 lr 0.00079488 rank 0
2022-08-24 14:32:44,863 DEBUG TRAIN Batch 111/1800 loss 17.772461 loss_att 7.600135 loss_ctc 41.507885 loss_ctc_origin 27.459164 loss_ctc0 74.288231 lr 0.00079482 rank 0
2022-08-24 14:33:12,842 DEBUG TRAIN Batch 111/1900 loss 21.324093 loss_att 9.241429 loss_ctc 49.516975 loss_ctc_origin 32.176247 loss_ctc0 89.978668 lr 0.00079476 rank 0
2022-08-24 14:33:41,324 DEBUG TRAIN Batch 111/2000 loss 44.149502 loss_att 28.063129 loss_ctc 81.684372 loss_ctc_origin 48.652306 loss_ctc0 158.759201 lr 0.00079470 rank 0
2022-08-24 14:34:02,704 WARNING NaN or Inf found in input tensor.
2022-08-24 14:34:09,588 DEBUG TRAIN Batch 111/2100 loss 50.089966 loss_att 27.200542 loss_ctc 103.498627 loss_ctc_origin 53.860401 loss_ctc0 219.321121 lr 0.00079463 rank 0
2022-08-24 14:34:38,390 DEBUG TRAIN Batch 111/2200 loss 22.094139 loss_att 11.680563 loss_ctc 46.392487 loss_ctc_origin 35.753296 loss_ctc0 71.217270 lr 0.00079457 rank 0
2022-08-24 14:35:07,953 DEBUG TRAIN Batch 111/2300 loss 20.803406 loss_att 9.657459 loss_ctc 46.810616 loss_ctc_origin 33.099781 loss_ctc0 78.802559 lr 0.00079451 rank 0
2022-08-24 14:35:37,534 DEBUG TRAIN Batch 111/2400 loss 28.588058 loss_att 13.166230 loss_ctc 64.572327 loss_ctc_origin 46.736610 loss_ctc0 106.189011 lr 0.00079444 rank 0
2022-08-24 14:36:06,040 DEBUG TRAIN Batch 111/2500 loss 44.848755 loss_att 28.003124 loss_ctc 84.155228 loss_ctc_origin 56.028358 loss_ctc0 149.784607 lr 0.00079438 rank 0
2022-08-24 14:36:33,820 DEBUG TRAIN Batch 111/2600 loss 46.350952 loss_att 26.010914 loss_ctc 93.811043 loss_ctc_origin 49.385380 loss_ctc0 197.470917 lr 0.00079432 rank 0
2022-08-24 14:37:01,094 DEBUG TRAIN Batch 111/2700 loss 23.292690 loss_att 11.593925 loss_ctc 50.589806 loss_ctc_origin 40.564301 loss_ctc0 73.982651 lr 0.00079426 rank 0
2022-08-24 14:37:29,957 DEBUG TRAIN Batch 111/2800 loss 23.708229 loss_att 10.036967 loss_ctc 55.607838 loss_ctc_origin 40.988266 loss_ctc0 89.720169 lr 0.00079419 rank 0
2022-08-24 14:37:58,324 DEBUG TRAIN Batch 111/2900 loss 25.610575 loss_att 11.688778 loss_ctc 58.094765 loss_ctc_origin 42.753593 loss_ctc0 93.890823 lr 0.00079413 rank 0
2022-08-24 14:38:33,035 DEBUG TRAIN Batch 111/3000 loss 48.597359 loss_att 31.052046 loss_ctc 89.536423 loss_ctc_origin 57.006996 loss_ctc0 165.438416 lr 0.00079407 rank 0
2022-08-24 14:39:01,258 DEBUG TRAIN Batch 111/3100 loss 45.708691 loss_att 22.310806 loss_ctc 100.303757 loss_ctc_origin 50.360931 loss_ctc0 216.837006 lr 0.00079401 rank 0
2022-08-24 14:39:30,165 DEBUG TRAIN Batch 111/3200 loss 22.091270 loss_att 12.228926 loss_ctc 45.103409 loss_ctc_origin 34.103863 loss_ctc0 70.769020 lr 0.00079394 rank 0
2022-08-24 14:39:58,809 DEBUG TRAIN Batch 111/3300 loss 23.312763 loss_att 11.269716 loss_ctc 51.413208 loss_ctc_origin 38.307629 loss_ctc0 81.992889 lr 0.00079388 rank 0
2022-08-24 14:40:26,991 DEBUG TRAIN Batch 111/3400 loss 20.068672 loss_att 9.149061 loss_ctc 45.547760 loss_ctc_origin 27.705803 loss_ctc0 87.178993 lr 0.00079382 rank 0
2022-08-24 14:40:56,323 DEBUG TRAIN Batch 111/3500 loss 46.158924 loss_att 31.337017 loss_ctc 80.743370 loss_ctc_origin 51.387337 loss_ctc0 149.240784 lr 0.00079376 rank 0
2022-08-24 14:41:24,670 DEBUG TRAIN Batch 111/3600 loss 52.178959 loss_att 31.096859 loss_ctc 101.370522 loss_ctc_origin 62.093918 loss_ctc0 193.015930 lr 0.00079369 rank 0
2022-08-24 14:41:53,430 DEBUG TRAIN Batch 111/3700 loss 22.534483 loss_att 14.138308 loss_ctc 42.125557 loss_ctc_origin 31.686686 loss_ctc0 66.482925 lr 0.00079363 rank 0
2022-08-24 14:41:58,968 WARNING NaN or Inf found in input tensor.
2022-08-24 14:42:21,562 DEBUG TRAIN Batch 111/3800 loss 20.884371 loss_att 9.610361 loss_ctc 47.190392 loss_ctc_origin 34.561123 loss_ctc0 76.658676 lr 0.00079357 rank 0
2022-08-24 14:42:49,964 DEBUG TRAIN Batch 111/3900 loss 20.898647 loss_att 8.897350 loss_ctc 48.901672 loss_ctc_origin 29.871807 loss_ctc0 93.304688 lr 0.00079351 rank 0
2022-08-24 14:43:18,467 DEBUG TRAIN Batch 111/4000 loss 50.254189 loss_att 33.830067 loss_ctc 88.577133 loss_ctc_origin 56.265038 loss_ctc0 163.972031 lr 0.00079344 rank 0
2022-08-24 14:43:19,140 WARNING NaN or Inf found in input tensor.
2022-08-24 14:43:46,280 DEBUG TRAIN Batch 111/4100 loss 51.478699 loss_att 30.503822 loss_ctc 100.420074 loss_ctc_origin 63.200310 loss_ctc0 187.266190 lr 0.00079338 rank 0
2022-08-24 14:44:13,348 DEBUG TRAIN Batch 111/4200 loss 21.501770 loss_att 11.550341 loss_ctc 44.721771 loss_ctc_origin 32.916531 loss_ctc0 72.267326 lr 0.00079332 rank 0
2022-08-24 14:44:41,437 DEBUG TRAIN Batch 111/4300 loss 21.507645 loss_att 9.980742 loss_ctc 48.403755 loss_ctc_origin 34.391312 loss_ctc0 81.099464 lr 0.00079326 rank 0
2022-08-24 14:45:10,194 DEBUG TRAIN Batch 111/4400 loss 25.098948 loss_att 11.408623 loss_ctc 57.043034 loss_ctc_origin 39.369255 loss_ctc0 98.281853 lr 0.00079319 rank 0
2022-08-24 14:45:19,787 WARNING NaN or Inf found in input tensor.
2022-08-24 14:45:44,417 DEBUG TRAIN Batch 111/4500 loss 52.472076 loss_att 36.973038 loss_ctc 88.636490 loss_ctc_origin 65.977264 loss_ctc0 141.507996 lr 0.00079313 rank 0
2022-08-24 14:46:12,541 DEBUG TRAIN Batch 111/4600 loss 50.103260 loss_att 30.528498 loss_ctc 95.777702 loss_ctc_origin 58.216473 loss_ctc0 183.420563 lr 0.00079307 rank 0
2022-08-24 14:46:37,681 WARNING NaN or Inf found in input tensor.
2022-08-24 14:46:39,310 DEBUG TRAIN Batch 111/4700 loss 21.300236 loss_att 12.305254 loss_ctc 42.288521 loss_ctc_origin 33.234673 loss_ctc0 63.414173 lr 0.00079301 rank 0
2022-08-24 14:47:07,172 DEBUG TRAIN Batch 111/4800 loss 24.958942 loss_att 11.397486 loss_ctc 56.602341 loss_ctc_origin 43.358368 loss_ctc0 87.504951 lr 0.00079294 rank 0
2022-08-24 14:47:17,789 WARNING NaN or Inf found in input tensor.
2022-08-24 14:47:36,644 DEBUG TRAIN Batch 111/4900 loss 26.947281 loss_att 12.731045 loss_ctc 60.118500 loss_ctc_origin 47.097927 loss_ctc0 90.499840 lr 0.00079288 rank 0
2022-08-24 14:48:05,366 DEBUG TRAIN Batch 111/5000 loss 55.952820 loss_att 38.810997 loss_ctc 95.950409 loss_ctc_origin 65.073586 loss_ctc0 167.996338 lr 0.00079282 rank 0
2022-08-24 14:48:31,413 DEBUG TRAIN Batch 111/5100 loss 49.151306 loss_att 27.053366 loss_ctc 100.713173 loss_ctc_origin 53.843849 loss_ctc0 210.074921 lr 0.00079276 rank 0
2022-08-24 14:49:00,508 DEBUG TRAIN Batch 111/5200 loss 23.856323 loss_att 11.968113 loss_ctc 51.595482 loss_ctc_origin 40.551155 loss_ctc0 77.365570 lr 0.00079270 rank 0
2022-08-24 14:49:28,841 DEBUG TRAIN Batch 111/5300 loss 16.423304 loss_att 7.172903 loss_ctc 38.007572 loss_ctc_origin 21.974289 loss_ctc0 75.418564 lr 0.00079263 rank 0
2022-08-24 14:49:56,093 DEBUG TRAIN Batch 111/5400 loss 23.233561 loss_att 9.954495 loss_ctc 54.218040 loss_ctc_origin 37.190151 loss_ctc0 93.949783 lr 0.00079257 rank 0
2022-08-24 14:50:24,719 DEBUG TRAIN Batch 111/5500 loss 39.822590 loss_att 26.831436 loss_ctc 70.135277 loss_ctc_origin 43.602871 loss_ctc0 132.044220 lr 0.00079251 rank 0
2022-08-24 14:50:52,079 DEBUG TRAIN Batch 111/5600 loss 36.656307 loss_att 24.904930 loss_ctc 64.076187 loss_ctc_origin 45.969124 loss_ctc0 106.325989 lr 0.00079245 rank 0
2022-08-24 14:51:14,813 DEBUG CV Batch 111/0 loss 13.649700 loss_att 10.261164 loss_ctc 21.556284 loss_ctc_origin 15.836488 loss_ctc0 34.902473 history loss 12.846777 rank 0
2022-08-24 14:51:25,150 DEBUG CV Batch 111/100 loss 23.491821 loss_att 18.267879 loss_ctc 35.681015 loss_ctc_origin 26.004204 loss_ctc0 58.260246 history loss 28.196749 rank 0
2022-08-24 14:51:34,546 DEBUG CV Batch 111/200 loss 25.553566 loss_att 19.830372 loss_ctc 38.907684 loss_ctc_origin 28.803989 loss_ctc0 62.482971 history loss 29.909369 rank 0
2022-08-24 14:51:44,359 DEBUG CV Batch 111/300 loss 24.322237 loss_att 18.728039 loss_ctc 37.375366 loss_ctc_origin 22.048195 loss_ctc0 73.138763 history loss 28.895654 rank 0
2022-08-24 14:51:54,665 DEBUG CV Batch 111/400 loss 38.555401 loss_att 31.297970 loss_ctc 55.489403 loss_ctc_origin 37.679024 loss_ctc0 97.046951 history loss 27.051920 rank 0
2022-08-24 14:52:05,093 DEBUG CV Batch 111/500 loss 17.758739 loss_att 13.724274 loss_ctc 27.172489 loss_ctc_origin 20.320347 loss_ctc0 43.160820 history loss 26.656276 rank 0
2022-08-24 14:52:15,431 DEBUG CV Batch 111/600 loss 22.152714 loss_att 15.149534 loss_ctc 38.493469 loss_ctc_origin 26.384367 loss_ctc0 66.748047 history loss 26.475608 rank 0
2022-08-24 14:52:25,203 DEBUG CV Batch 111/700 loss 19.376671 loss_att 13.154474 loss_ctc 33.895126 loss_ctc_origin 20.479935 loss_ctc0 65.197235 history loss 26.130052 rank 0
2022-08-24 14:52:35,308 DEBUG CV Batch 111/800 loss 23.392330 loss_att 18.186882 loss_ctc 35.538376 loss_ctc_origin 20.274845 loss_ctc0 71.153282 history loss 26.094254 rank 0
2022-08-24 14:52:45,322 INFO Epoch 111 CV info cv_loss 26.16851479301418
2022-08-24 14:52:45,323 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/111.pt
2022-08-24 14:52:45,750 INFO Epoch 112 TRAIN info lr 0.0007923940220093374
2022-08-24 14:52:45,754 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 14:53:11,562 DEBUG TRAIN Batch 112/0 loss 34.960754 loss_att 23.481438 loss_ctc 61.745819 loss_ctc_origin 40.068821 loss_ctc0 112.325485 lr 0.00079239 rank 0
2022-08-24 14:53:39,320 DEBUG TRAIN Batch 112/100 loss 32.683243 loss_att 23.289242 loss_ctc 54.602577 loss_ctc_origin 38.296986 loss_ctc0 92.648956 lr 0.00079233 rank 0
2022-08-24 14:54:08,041 DEBUG TRAIN Batch 112/200 loss 22.950468 loss_att 12.147934 loss_ctc 48.156380 loss_ctc_origin 37.185432 loss_ctc0 73.755264 lr 0.00079227 rank 0
2022-08-24 14:54:36,204 DEBUG TRAIN Batch 112/300 loss 20.606922 loss_att 9.203507 loss_ctc 47.214886 loss_ctc_origin 35.340466 loss_ctc0 74.921867 lr 0.00079221 rank 0
2022-08-24 14:55:03,373 DEBUG TRAIN Batch 112/400 loss 25.663980 loss_att 11.899712 loss_ctc 57.780605 loss_ctc_origin 41.536987 loss_ctc0 95.682373 lr 0.00079214 rank 0
2022-08-24 14:55:32,062 DEBUG TRAIN Batch 112/500 loss 53.874664 loss_att 37.349403 loss_ctc 92.433609 loss_ctc_origin 62.057476 loss_ctc0 163.311249 lr 0.00079208 rank 0
2022-08-24 14:55:39,852 WARNING NaN or Inf found in input tensor.
2022-08-24 14:55:57,774 DEBUG TRAIN Batch 112/600 loss 51.825531 loss_att 32.267574 loss_ctc 97.460770 loss_ctc_origin 62.461784 loss_ctc0 179.125061 lr 0.00079202 rank 0
2022-08-24 14:56:25,564 DEBUG TRAIN Batch 112/700 loss 19.117874 loss_att 10.246551 loss_ctc 39.817623 loss_ctc_origin 28.507347 loss_ctc0 66.208267 lr 0.00079196 rank 0
2022-08-24 14:56:31,004 WARNING NaN or Inf found in input tensor.
2022-08-24 14:56:52,848 DEBUG TRAIN Batch 112/800 loss 21.734129 loss_att 9.059433 loss_ctc 51.308418 loss_ctc_origin 36.954117 loss_ctc0 84.801788 lr 0.00079189 rank 0
2022-08-24 14:57:21,019 DEBUG TRAIN Batch 112/900 loss 21.884323 loss_att 9.139595 loss_ctc 51.622017 loss_ctc_origin 36.248772 loss_ctc0 87.492928 lr 0.00079183 rank 0
2022-08-24 14:57:47,594 DEBUG TRAIN Batch 112/1000 loss 47.440746 loss_att 31.027946 loss_ctc 85.737274 loss_ctc_origin 58.751484 loss_ctc0 148.704132 lr 0.00079177 rank 0
2022-08-24 14:58:14,892 DEBUG TRAIN Batch 112/1100 loss 48.082108 loss_att 31.156519 loss_ctc 87.575150 loss_ctc_origin 60.729832 loss_ctc0 150.214233 lr 0.00079171 rank 0
2022-08-24 14:58:41,830 DEBUG TRAIN Batch 112/1200 loss 20.659397 loss_att 10.819184 loss_ctc 43.619896 loss_ctc_origin 33.672997 loss_ctc0 66.829338 lr 0.00079165 rank 0
2022-08-24 14:59:10,808 DEBUG TRAIN Batch 112/1300 loss 21.102558 loss_att 8.796663 loss_ctc 49.816307 loss_ctc_origin 33.741318 loss_ctc0 87.324615 lr 0.00079158 rank 0
2022-08-24 14:59:38,299 DEBUG TRAIN Batch 112/1400 loss 26.092758 loss_att 12.743742 loss_ctc 57.240463 loss_ctc_origin 38.475464 loss_ctc0 101.025459 lr 0.00079152 rank 0
2022-08-24 15:00:11,485 DEBUG TRAIN Batch 112/1500 loss 50.271374 loss_att 33.748844 loss_ctc 88.823936 loss_ctc_origin 61.311615 loss_ctc0 153.019348 lr 0.00079146 rank 0
2022-08-24 15:00:19,399 WARNING NaN or Inf found in input tensor.
2022-08-24 15:00:39,810 DEBUG TRAIN Batch 112/1600 loss 50.049812 loss_att 32.434372 loss_ctc 91.152504 loss_ctc_origin 62.386089 loss_ctc0 158.274139 lr 0.00079140 rank 0
2022-08-24 15:01:07,186 DEBUG TRAIN Batch 112/1700 loss 19.996401 loss_att 11.108696 loss_ctc 40.734375 loss_ctc_origin 31.842085 loss_ctc0 61.483055 lr 0.00079134 rank 0
2022-08-24 15:01:35,264 DEBUG TRAIN Batch 112/1800 loss 19.321846 loss_att 8.323028 loss_ctc 44.985756 loss_ctc_origin 30.799223 loss_ctc0 78.087662 lr 0.00079127 rank 0
2022-08-24 15:02:03,121 DEBUG TRAIN Batch 112/1900 loss 26.024340 loss_att 12.006899 loss_ctc 58.731697 loss_ctc_origin 42.605583 loss_ctc0 96.359291 lr 0.00079121 rank 0
2022-08-24 15:02:31,443 DEBUG TRAIN Batch 112/2000 loss 45.412392 loss_att 31.406839 loss_ctc 78.092010 loss_ctc_origin 55.693008 loss_ctc0 130.356354 lr 0.00079115 rank 0
2022-08-24 15:02:58,652 DEBUG TRAIN Batch 112/2100 loss 46.142311 loss_att 31.801208 loss_ctc 79.604889 loss_ctc_origin 58.006050 loss_ctc0 130.002167 lr 0.00079109 rank 0
2022-08-24 15:03:25,978 DEBUG TRAIN Batch 112/2200 loss 27.310894 loss_att 14.477364 loss_ctc 57.255791 loss_ctc_origin 49.903210 loss_ctc0 74.411804 lr 0.00079103 rank 0
2022-08-24 15:03:53,726 DEBUG TRAIN Batch 112/2300 loss 22.775793 loss_att 10.205881 loss_ctc 52.105583 loss_ctc_origin 40.282661 loss_ctc0 79.692390 lr 0.00079096 rank 0
2022-08-24 15:04:22,547 DEBUG TRAIN Batch 112/2400 loss 26.197342 loss_att 12.006140 loss_ctc 59.310150 loss_ctc_origin 43.659660 loss_ctc0 95.827950 lr 0.00079090 rank 0
2022-08-24 15:04:49,443 DEBUG TRAIN Batch 112/2500 loss 42.596733 loss_att 28.795353 loss_ctc 74.799957 loss_ctc_origin 42.862488 loss_ctc0 149.320709 lr 0.00079084 rank 0
2022-08-24 15:05:02,711 WARNING NaN or Inf found in input tensor.
2022-08-24 15:05:17,003 DEBUG TRAIN Batch 112/2600 loss 33.996063 loss_att 21.573444 loss_ctc 62.982178 loss_ctc_origin 45.107246 loss_ctc0 104.690353 lr 0.00079078 rank 0
2022-08-24 15:05:43,053 DEBUG TRAIN Batch 112/2700 loss 20.350948 loss_att 10.244681 loss_ctc 43.932236 loss_ctc_origin 35.127926 loss_ctc0 64.475632 lr 0.00079072 rank 0
2022-08-24 15:06:11,349 DEBUG TRAIN Batch 112/2800 loss 26.257607 loss_att 12.519464 loss_ctc 58.313263 loss_ctc_origin 44.095863 loss_ctc0 91.487198 lr 0.00079066 rank 0
2022-08-24 15:06:39,997 DEBUG TRAIN Batch 112/2900 loss 22.591311 loss_att 11.589921 loss_ctc 48.261219 loss_ctc_origin 32.355675 loss_ctc0 85.374153 lr 0.00079059 rank 0
2022-08-24 15:07:13,856 DEBUG TRAIN Batch 112/3000 loss 37.850788 loss_att 23.612953 loss_ctc 71.072403 loss_ctc_origin 43.267937 loss_ctc0 135.949478 lr 0.00079053 rank 0
2022-08-24 15:07:41,861 DEBUG TRAIN Batch 112/3100 loss 34.350220 loss_att 25.264194 loss_ctc 55.550941 loss_ctc_origin 43.247849 loss_ctc0 84.258156 lr 0.00079047 rank 0
2022-08-24 15:08:09,605 DEBUG TRAIN Batch 112/3200 loss 21.031723 loss_att 12.603276 loss_ctc 40.698097 loss_ctc_origin 29.664555 loss_ctc0 66.443024 lr 0.00079041 rank 0
2022-08-24 15:08:37,632 DEBUG TRAIN Batch 112/3300 loss 21.684332 loss_att 10.481483 loss_ctc 47.824306 loss_ctc_origin 35.092430 loss_ctc0 77.532013 lr 0.00079035 rank 0
2022-08-24 15:09:00,695 WARNING NaN or Inf found in input tensor.
2022-08-24 15:09:05,002 DEBUG TRAIN Batch 112/3400 loss 24.607639 loss_att 11.112400 loss_ctc 56.096523 loss_ctc_origin 38.973518 loss_ctc0 96.050201 lr 0.00079029 rank 0
2022-08-24 15:09:33,649 DEBUG TRAIN Batch 112/3500 loss 35.615562 loss_att 23.595718 loss_ctc 63.661865 loss_ctc_origin 39.472420 loss_ctc0 120.103905 lr 0.00079022 rank 0
2022-08-24 15:09:54,347 WARNING NaN or Inf found in input tensor.
2022-08-24 15:10:01,415 DEBUG TRAIN Batch 112/3600 loss 35.356766 loss_att 24.863956 loss_ctc 59.839993 loss_ctc_origin 42.119846 loss_ctc0 101.186996 lr 0.00079016 rank 0
2022-08-24 15:10:29,251 DEBUG TRAIN Batch 112/3700 loss 23.132204 loss_att 14.459005 loss_ctc 43.369667 loss_ctc_origin 33.912437 loss_ctc0 65.436523 lr 0.00079010 rank 0
2022-08-24 15:10:46,804 WARNING NaN or Inf found in input tensor.
2022-08-24 15:10:56,310 DEBUG TRAIN Batch 112/3800 loss 22.597721 loss_att 9.268389 loss_ctc 53.699493 loss_ctc_origin 39.437286 loss_ctc0 86.977982 lr 0.00079004 rank 0
2022-08-24 15:11:24,813 DEBUG TRAIN Batch 112/3900 loss 25.594381 loss_att 11.073534 loss_ctc 59.476353 loss_ctc_origin 42.387779 loss_ctc0 99.349686 lr 0.00078998 rank 0
2022-08-24 15:11:52,041 DEBUG TRAIN Batch 112/4000 loss 44.094582 loss_att 28.829508 loss_ctc 79.713089 loss_ctc_origin 45.918007 loss_ctc0 158.568268 lr 0.00078992 rank 0
2022-08-24 15:12:19,584 DEBUG TRAIN Batch 112/4100 loss 37.365356 loss_att 24.609543 loss_ctc 67.128922 loss_ctc_origin 45.455116 loss_ctc0 117.701149 lr 0.00078985 rank 0
2022-08-24 15:12:38,593 WARNING NaN or Inf found in input tensor.
2022-08-24 15:12:46,780 DEBUG TRAIN Batch 112/4200 loss 18.902309 loss_att 11.366804 loss_ctc 36.485153 loss_ctc_origin 23.714214 loss_ctc0 66.284012 lr 0.00078979 rank 0
2022-08-24 15:13:15,066 DEBUG TRAIN Batch 112/4300 loss 18.678970 loss_att 7.787058 loss_ctc 44.093430 loss_ctc_origin 29.850018 loss_ctc0 77.328056 lr 0.00078973 rank 0
2022-08-24 15:13:42,952 DEBUG TRAIN Batch 112/4400 loss 23.421379 loss_att 9.564735 loss_ctc 55.753548 loss_ctc_origin 39.084419 loss_ctc0 94.648186 lr 0.00078967 rank 0
2022-08-24 15:14:14,170 DEBUG TRAIN Batch 112/4500 loss 35.521774 loss_att 23.039431 loss_ctc 64.647232 loss_ctc_origin 36.223339 loss_ctc0 130.969635 lr 0.00078961 rank 0
2022-08-24 15:14:42,474 DEBUG TRAIN Batch 112/4600 loss 48.302288 loss_att 30.478355 loss_ctc 89.891464 loss_ctc_origin 61.874214 loss_ctc0 155.265045 lr 0.00078955 rank 0
2022-08-24 15:15:09,828 DEBUG TRAIN Batch 112/4700 loss 17.657082 loss_att 9.636083 loss_ctc 36.372742 loss_ctc_origin 24.983757 loss_ctc0 62.947029 lr 0.00078948 rank 0
2022-08-24 15:15:34,320 WARNING NaN or Inf found in input tensor.
2022-08-24 15:15:36,951 DEBUG TRAIN Batch 112/4800 loss 18.253311 loss_att 7.587162 loss_ctc 43.140991 loss_ctc_origin 27.605280 loss_ctc0 79.390976 lr 0.00078942 rank 0
2022-08-24 15:16:04,789 DEBUG TRAIN Batch 112/4900 loss 25.073025 loss_att 11.026524 loss_ctc 57.848190 loss_ctc_origin 38.744144 loss_ctc0 102.424286 lr 0.00078936 rank 0
2022-08-24 15:16:32,561 DEBUG TRAIN Batch 112/5000 loss 47.185043 loss_att 30.465530 loss_ctc 86.197243 loss_ctc_origin 52.128319 loss_ctc0 165.691391 lr 0.00078930 rank 0
2022-08-24 15:17:00,894 DEBUG TRAIN Batch 112/5100 loss 35.531868 loss_att 20.528049 loss_ctc 70.540779 loss_ctc_origin 44.748466 loss_ctc0 130.722839 lr 0.00078924 rank 0
2022-08-24 15:17:28,777 DEBUG TRAIN Batch 112/5200 loss 20.542927 loss_att 10.519788 loss_ctc 43.930244 loss_ctc_origin 30.562984 loss_ctc0 75.120522 lr 0.00078918 rank 0
2022-08-24 15:17:34,253 WARNING NaN or Inf found in input tensor.
2022-08-24 15:17:57,176 DEBUG TRAIN Batch 112/5300 loss 22.249716 loss_att 10.673088 loss_ctc 49.261848 loss_ctc_origin 36.009583 loss_ctc0 80.183792 lr 0.00078912 rank 0
2022-08-24 15:18:25,256 DEBUG TRAIN Batch 112/5400 loss 26.242718 loss_att 11.335094 loss_ctc 61.027168 loss_ctc_origin 42.468422 loss_ctc0 104.330902 lr 0.00078905 rank 0
2022-08-24 15:18:53,586 DEBUG TRAIN Batch 112/5500 loss 42.180424 loss_att 26.638588 loss_ctc 78.444710 loss_ctc_origin 49.348759 loss_ctc0 146.335251 lr 0.00078899 rank 0
2022-08-24 15:19:20,570 DEBUG TRAIN Batch 112/5600 loss 43.475658 loss_att 22.573126 loss_ctc 92.248230 loss_ctc_origin 45.732491 loss_ctc0 200.784943 lr 0.00078893 rank 0
2022-08-24 15:19:43,258 DEBUG CV Batch 112/0 loss 14.147619 loss_att 10.988079 loss_ctc 21.519878 loss_ctc_origin 15.662786 loss_ctc0 35.186424 history loss 13.315406 rank 0
2022-08-24 15:19:53,555 DEBUG CV Batch 112/100 loss 24.311504 loss_att 19.360676 loss_ctc 35.863434 loss_ctc_origin 24.498699 loss_ctc0 62.381142 history loss 29.107376 rank 0
2022-08-24 15:20:03,205 DEBUG CV Batch 112/200 loss 26.504574 loss_att 20.527288 loss_ctc 40.451576 loss_ctc_origin 30.133656 loss_ctc0 64.526718 history loss 30.471893 rank 0
2022-08-24 15:20:13,048 DEBUG CV Batch 112/300 loss 25.869190 loss_att 19.865431 loss_ctc 39.877960 loss_ctc_origin 24.937588 loss_ctc0 74.738831 history loss 29.504743 rank 0
2022-08-24 15:20:23,407 DEBUG CV Batch 112/400 loss 39.119236 loss_att 31.905846 loss_ctc 55.950481 loss_ctc_origin 37.768692 loss_ctc0 98.374657 history loss 27.730369 rank 0
2022-08-24 15:20:33,821 DEBUG CV Batch 112/500 loss 18.040125 loss_att 13.976750 loss_ctc 27.521332 loss_ctc_origin 20.648567 loss_ctc0 43.557785 history loss 27.330420 rank 0
2022-08-24 15:20:44,139 DEBUG CV Batch 112/600 loss 22.840132 loss_att 15.342162 loss_ctc 40.335392 loss_ctc_origin 25.217434 loss_ctc0 75.610626 history loss 27.177015 rank 0
2022-08-24 15:20:53,961 DEBUG CV Batch 112/700 loss 19.919685 loss_att 13.730906 loss_ctc 34.360176 loss_ctc_origin 21.295349 loss_ctc0 64.844780 history loss 26.820962 rank 0
2022-08-24 15:21:03,892 DEBUG CV Batch 112/800 loss 23.565334 loss_att 18.242571 loss_ctc 35.985115 loss_ctc_origin 20.443342 loss_ctc0 72.249245 history loss 26.759855 rank 0
2022-08-24 15:21:13,674 INFO Epoch 112 CV info cv_loss 26.808623195085588
2022-08-24 15:21:13,674 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/112.pt
2022-08-24 15:21:14,129 INFO Epoch 113 TRAIN info lr 0.0007888800622469057
2022-08-24 15:21:14,133 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 15:21:39,713 DEBUG TRAIN Batch 113/0 loss 55.437210 loss_att 35.096893 loss_ctc 102.897949 loss_ctc_origin 66.881973 loss_ctc0 186.935211 lr 0.00078888 rank 0
2022-08-24 15:22:06,996 DEBUG TRAIN Batch 113/100 loss 46.901669 loss_att 24.420906 loss_ctc 99.356781 loss_ctc_origin 48.257519 loss_ctc0 218.588409 lr 0.00078882 rank 0
2022-08-24 15:22:34,412 DEBUG TRAIN Batch 113/200 loss 17.150457 loss_att 9.151928 loss_ctc 35.813690 loss_ctc_origin 25.466574 loss_ctc0 59.956959 lr 0.00078875 rank 0
2022-08-24 15:23:02,467 DEBUG TRAIN Batch 113/300 loss 22.414124 loss_att 11.517202 loss_ctc 47.840275 loss_ctc_origin 33.344654 loss_ctc0 81.663391 lr 0.00078869 rank 0
2022-08-24 15:23:31,142 DEBUG TRAIN Batch 113/400 loss 28.247749 loss_att 12.347414 loss_ctc 65.348526 loss_ctc_origin 48.111721 loss_ctc0 105.567749 lr 0.00078863 rank 0
2022-08-24 15:23:58,976 DEBUG TRAIN Batch 113/500 loss 55.300396 loss_att 37.022163 loss_ctc 97.949600 loss_ctc_origin 59.328094 loss_ctc0 188.066437 lr 0.00078857 rank 0
2022-08-24 15:24:26,288 DEBUG TRAIN Batch 113/600 loss 52.299805 loss_att 29.531361 loss_ctc 105.426178 loss_ctc_origin 62.359051 loss_ctc0 205.916138 lr 0.00078851 rank 0
2022-08-24 15:24:52,673 DEBUG TRAIN Batch 113/700 loss 19.989229 loss_att 11.694443 loss_ctc 39.343731 loss_ctc_origin 29.371672 loss_ctc0 62.611870 lr 0.00078845 rank 0
2022-08-24 15:25:20,592 DEBUG TRAIN Batch 113/800 loss 20.729973 loss_att 9.560088 loss_ctc 46.793034 loss_ctc_origin 33.257153 loss_ctc0 78.376755 lr 0.00078839 rank 0
2022-08-24 15:25:44,655 WARNING NaN or Inf found in input tensor.
2022-08-24 15:25:49,211 DEBUG TRAIN Batch 113/900 loss 23.376858 loss_att 9.746324 loss_ctc 55.181435 loss_ctc_origin 35.718231 loss_ctc0 100.595581 lr 0.00078833 rank 0
2022-08-24 15:26:18,749 DEBUG TRAIN Batch 113/1000 loss 56.521881 loss_att 37.321789 loss_ctc 101.322098 loss_ctc_origin 62.434414 loss_ctc0 192.060013 lr 0.00078826 rank 0
2022-08-24 15:26:44,953 DEBUG TRAIN Batch 113/1100 loss 46.244831 loss_att 26.130596 loss_ctc 93.178047 loss_ctc_origin 60.609524 loss_ctc0 169.171265 lr 0.00078820 rank 0
2022-08-24 15:27:11,994 DEBUG TRAIN Batch 113/1200 loss 20.784895 loss_att 11.897857 loss_ctc 41.521317 loss_ctc_origin 32.365791 loss_ctc0 62.884209 lr 0.00078814 rank 0
2022-08-24 15:27:41,463 DEBUG TRAIN Batch 113/1300 loss 22.148727 loss_att 9.591480 loss_ctc 51.448967 loss_ctc_origin 36.239826 loss_ctc0 86.936966 lr 0.00078808 rank 0
2022-08-24 15:28:09,352 DEBUG TRAIN Batch 113/1400 loss 26.546707 loss_att 12.512882 loss_ctc 59.292294 loss_ctc_origin 40.830624 loss_ctc0 102.369522 lr 0.00078802 rank 0
2022-08-24 15:28:43,412 DEBUG TRAIN Batch 113/1500 loss 48.998009 loss_att 29.228947 loss_ctc 95.125809 loss_ctc_origin 63.849640 loss_ctc0 168.103516 lr 0.00078796 rank 0
2022-08-24 15:28:44,200 WARNING NaN or Inf found in input tensor.
2022-08-24 15:29:11,943 DEBUG TRAIN Batch 113/1600 loss 58.083282 loss_att 36.120750 loss_ctc 109.329193 loss_ctc_origin 61.294785 loss_ctc0 221.409470 lr 0.00078790 rank 0
2022-08-24 15:29:40,220 DEBUG TRAIN Batch 113/1700 loss 17.238512 loss_att 8.779131 loss_ctc 36.977066 loss_ctc_origin 24.761311 loss_ctc0 65.480492 lr 0.00078784 rank 0
2022-08-24 15:30:08,129 DEBUG TRAIN Batch 113/1800 loss 20.129389 loss_att 8.741037 loss_ctc 46.702206 loss_ctc_origin 33.105904 loss_ctc0 78.426910 lr 0.00078778 rank 0
2022-08-24 15:30:36,257 DEBUG TRAIN Batch 113/1900 loss 23.815731 loss_att 10.571755 loss_ctc 54.718338 loss_ctc_origin 37.329823 loss_ctc0 95.291534 lr 0.00078771 rank 0
2022-08-24 15:31:05,435 DEBUG TRAIN Batch 113/2000 loss 47.632431 loss_att 29.247839 loss_ctc 90.529816 loss_ctc_origin 52.911674 loss_ctc0 178.305466 lr 0.00078765 rank 0
2022-08-24 15:31:33,345 DEBUG TRAIN Batch 113/2100 loss 52.489185 loss_att 27.163811 loss_ctc 111.581726 loss_ctc_origin 67.468117 loss_ctc0 214.513474 lr 0.00078759 rank 0
2022-08-24 15:32:01,344 DEBUG TRAIN Batch 113/2200 loss 18.138380 loss_att 9.718092 loss_ctc 37.785721 loss_ctc_origin 25.444618 loss_ctc0 66.581619 lr 0.00078753 rank 0
2022-08-24 15:32:28,693 DEBUG TRAIN Batch 113/2300 loss 25.290754 loss_att 12.003893 loss_ctc 56.293427 loss_ctc_origin 45.107201 loss_ctc0 82.394623 lr 0.00078747 rank 0
2022-08-24 15:32:56,895 DEBUG TRAIN Batch 113/2400 loss 24.805481 loss_att 11.540730 loss_ctc 55.756561 loss_ctc_origin 39.647617 loss_ctc0 93.344101 lr 0.00078741 rank 0
2022-08-24 15:33:25,195 DEBUG TRAIN Batch 113/2500 loss 55.348991 loss_att 38.309784 loss_ctc 95.107147 loss_ctc_origin 58.645557 loss_ctc0 180.184174 lr 0.00078735 rank 0
2022-08-24 15:33:38,074 WARNING NaN or Inf found in input tensor.
2022-08-24 15:33:52,308 DEBUG TRAIN Batch 113/2600 loss 46.042236 loss_att 27.649269 loss_ctc 88.959152 loss_ctc_origin 50.351040 loss_ctc0 179.044739 lr 0.00078729 rank 0
2022-08-24 15:34:19,569 DEBUG TRAIN Batch 113/2700 loss 21.589279 loss_att 13.637056 loss_ctc 40.144463 loss_ctc_origin 30.491737 loss_ctc0 62.667488 lr 0.00078723 rank 0
2022-08-24 15:34:47,992 DEBUG TRAIN Batch 113/2800 loss 20.671638 loss_att 8.914486 loss_ctc 48.104996 loss_ctc_origin 35.148155 loss_ctc0 78.337631 lr 0.00078716 rank 0
2022-08-24 15:35:10,706 WARNING NaN or Inf found in input tensor.
2022-08-24 15:35:14,906 DEBUG TRAIN Batch 113/2900 loss 26.954441 loss_att 12.635132 loss_ctc 60.366165 loss_ctc_origin 43.065666 loss_ctc0 100.733994 lr 0.00078710 rank 0
2022-08-24 15:35:48,227 DEBUG TRAIN Batch 113/3000 loss 51.600761 loss_att 34.417774 loss_ctc 91.694397 loss_ctc_origin 58.335754 loss_ctc0 169.531219 lr 0.00078704 rank 0
2022-08-24 15:36:16,663 DEBUG TRAIN Batch 113/3100 loss 52.381393 loss_att 27.172060 loss_ctc 111.203178 loss_ctc_origin 58.850929 loss_ctc0 233.358429 lr 0.00078698 rank 0
2022-08-24 15:36:44,511 DEBUG TRAIN Batch 113/3200 loss 20.341232 loss_att 12.496420 loss_ctc 38.645794 loss_ctc_origin 28.703815 loss_ctc0 61.843742 lr 0.00078692 rank 0
2022-08-24 15:36:49,646 WARNING NaN or Inf found in input tensor.
2022-08-24 15:37:12,582 DEBUG TRAIN Batch 113/3300 loss 21.017178 loss_att 9.810122 loss_ctc 47.166969 loss_ctc_origin 33.790867 loss_ctc0 78.377869 lr 0.00078686 rank 0
2022-08-24 15:37:41,063 DEBUG TRAIN Batch 113/3400 loss 22.995153 loss_att 11.331839 loss_ctc 50.209557 loss_ctc_origin 33.091812 loss_ctc0 90.150948 lr 0.00078680 rank 0
2022-08-24 15:38:09,608 DEBUG TRAIN Batch 113/3500 loss 40.643295 loss_att 26.386818 loss_ctc 73.908417 loss_ctc_origin 46.600861 loss_ctc0 137.626053 lr 0.00078674 rank 0
2022-08-24 15:38:35,530 DEBUG TRAIN Batch 113/3600 loss 31.230074 loss_att 21.373537 loss_ctc 54.228661 loss_ctc_origin 34.991608 loss_ctc0 99.115112 lr 0.00078668 rank 0
2022-08-24 15:39:03,125 DEBUG TRAIN Batch 113/3700 loss 20.682186 loss_att 11.395629 loss_ctc 42.350819 loss_ctc_origin 31.956114 loss_ctc0 66.605125 lr 0.00078662 rank 0
2022-08-24 15:39:31,987 DEBUG TRAIN Batch 113/3800 loss 23.000031 loss_att 10.968452 loss_ctc 51.073715 loss_ctc_origin 39.276360 loss_ctc0 78.600883 lr 0.00078656 rank 0
2022-08-24 15:39:48,493 WARNING NaN or Inf found in input tensor.
2022-08-24 15:39:59,967 DEBUG TRAIN Batch 113/3900 loss 25.360262 loss_att 11.125941 loss_ctc 58.573677 loss_ctc_origin 41.741177 loss_ctc0 97.849518 lr 0.00078650 rank 0
2022-08-24 15:40:27,558 DEBUG TRAIN Batch 113/4000 loss 42.576454 loss_att 27.503456 loss_ctc 77.746780 loss_ctc_origin 45.720192 loss_ctc0 152.475464 lr 0.00078643 rank 0
2022-08-24 15:40:41,546 WARNING NaN or Inf found in input tensor.
2022-08-24 15:40:55,776 DEBUG TRAIN Batch 113/4100 loss 38.409431 loss_att 19.683731 loss_ctc 82.102730 loss_ctc_origin 37.526146 loss_ctc0 186.114746 lr 0.00078637 rank 0
2022-08-24 15:41:23,135 DEBUG TRAIN Batch 113/4200 loss 16.770704 loss_att 9.191255 loss_ctc 34.456085 loss_ctc_origin 24.532560 loss_ctc0 57.610977 lr 0.00078631 rank 0
2022-08-24 15:41:51,728 DEBUG TRAIN Batch 113/4300 loss 20.585838 loss_att 8.398260 loss_ctc 49.023521 loss_ctc_origin 33.034531 loss_ctc0 86.331169 lr 0.00078625 rank 0
2022-08-24 15:42:21,529 DEBUG TRAIN Batch 113/4400 loss 23.320667 loss_att 9.328230 loss_ctc 55.969685 loss_ctc_origin 38.388527 loss_ctc0 96.992378 lr 0.00078619 rank 0
2022-08-24 15:42:55,937 DEBUG TRAIN Batch 113/4500 loss 50.419250 loss_att 35.367210 loss_ctc 85.540680 loss_ctc_origin 59.716465 loss_ctc0 145.797165 lr 0.00078613 rank 0
2022-08-24 15:43:24,351 DEBUG TRAIN Batch 113/4600 loss 42.026424 loss_att 23.684895 loss_ctc 84.823326 loss_ctc_origin 42.875690 loss_ctc0 182.701141 lr 0.00078607 rank 0
2022-08-24 15:43:51,717 DEBUG TRAIN Batch 113/4700 loss 24.339275 loss_att 13.243569 loss_ctc 50.229256 loss_ctc_origin 38.887054 loss_ctc0 76.694382 lr 0.00078601 rank 0
2022-08-24 15:44:19,137 DEBUG TRAIN Batch 113/4800 loss 21.584290 loss_att 10.137802 loss_ctc 48.292755 loss_ctc_origin 34.678490 loss_ctc0 80.059372 lr 0.00078595 rank 0
2022-08-24 15:44:47,111 DEBUG TRAIN Batch 113/4900 loss 23.892136 loss_att 10.874317 loss_ctc 54.267040 loss_ctc_origin 38.361248 loss_ctc0 91.380554 lr 0.00078589 rank 0
2022-08-24 15:45:16,600 DEBUG TRAIN Batch 113/5000 loss 46.558823 loss_att 31.829971 loss_ctc 80.926132 loss_ctc_origin 47.337822 loss_ctc0 159.298859 lr 0.00078583 rank 0
2022-08-24 15:45:44,553 DEBUG TRAIN Batch 113/5100 loss 36.492859 loss_att 19.174377 loss_ctc 76.902641 loss_ctc_origin 43.380905 loss_ctc0 155.120026 lr 0.00078577 rank 0
2022-08-24 15:46:12,746 DEBUG TRAIN Batch 113/5200 loss 21.653015 loss_att 12.270206 loss_ctc 43.546234 loss_ctc_origin 32.750626 loss_ctc0 68.735977 lr 0.00078571 rank 0
2022-08-24 15:46:40,871 DEBUG TRAIN Batch 113/5300 loss 21.891497 loss_att 10.077408 loss_ctc 49.457703 loss_ctc_origin 33.881031 loss_ctc0 85.803268 lr 0.00078565 rank 0
2022-08-24 15:47:04,029 WARNING NaN or Inf found in input tensor.
2022-08-24 15:47:08,538 DEBUG TRAIN Batch 113/5400 loss 23.476461 loss_att 9.951822 loss_ctc 55.033947 loss_ctc_origin 37.531372 loss_ctc0 95.873291 lr 0.00078558 rank 0
2022-08-24 15:47:11,216 WARNING NaN or Inf found in input tensor.
2022-08-24 15:47:37,959 DEBUG TRAIN Batch 113/5500 loss 53.700890 loss_att 37.787514 loss_ctc 90.832092 loss_ctc_origin 60.578037 loss_ctc0 161.424896 lr 0.00078552 rank 0
2022-08-24 15:48:05,839 DEBUG TRAIN Batch 113/5600 loss 56.797783 loss_att 30.661636 loss_ctc 117.782135 loss_ctc_origin 62.955322 loss_ctc0 245.711365 lr 0.00078546 rank 0
2022-08-24 15:48:28,064 DEBUG CV Batch 113/0 loss 13.705078 loss_att 10.834951 loss_ctc 20.402039 loss_ctc_origin 14.460176 loss_ctc0 34.266380 history loss 12.898897 rank 0
2022-08-24 15:48:38,953 DEBUG CV Batch 113/100 loss 21.647789 loss_att 17.186253 loss_ctc 32.058044 loss_ctc_origin 22.395140 loss_ctc0 54.604824 history loss 27.747573 rank 0
2022-08-24 15:48:48,736 DEBUG CV Batch 113/200 loss 27.573559 loss_att 21.478683 loss_ctc 41.794937 loss_ctc_origin 32.500790 loss_ctc0 63.481274 history loss 29.282024 rank 0
2022-08-24 15:48:58,808 DEBUG CV Batch 113/300 loss 24.846149 loss_att 19.122650 loss_ctc 38.200981 loss_ctc_origin 22.990612 loss_ctc0 73.691833 history loss 28.420027 rank 0
2022-08-24 15:49:09,602 DEBUG CV Batch 113/400 loss 39.929565 loss_att 32.707890 loss_ctc 56.780136 loss_ctc_origin 39.715645 loss_ctc0 96.597275 history loss 26.727880 rank 0
2022-08-24 15:49:20,415 DEBUG CV Batch 113/500 loss 18.102436 loss_att 14.242795 loss_ctc 27.108269 loss_ctc_origin 20.207640 loss_ctc0 43.209740 history loss 26.401623 rank 0
2022-08-24 15:49:30,978 DEBUG CV Batch 113/600 loss 18.580368 loss_att 13.312028 loss_ctc 30.873161 loss_ctc_origin 20.308695 loss_ctc0 55.523582 history loss 26.228094 rank 0
2022-08-24 15:49:41,142 DEBUG CV Batch 113/700 loss 19.838173 loss_att 13.879830 loss_ctc 33.740974 loss_ctc_origin 20.698236 loss_ctc0 64.174026 history loss 25.874531 rank 0
2022-08-24 15:49:51,484 DEBUG CV Batch 113/800 loss 22.689320 loss_att 17.624912 loss_ctc 34.506268 loss_ctc_origin 19.180077 loss_ctc0 70.267380 history loss 25.828796 rank 0
2022-08-24 15:50:01,825 INFO Epoch 113 CV info cv_loss 25.904500476046103
2022-08-24 15:50:01,825 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/113.pt
2022-08-24 15:50:02,271 INFO Epoch 114 TRAIN info lr 0.0007854124407909417
2022-08-24 15:50:02,275 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 15:50:28,972 WARNING NaN or Inf found in input tensor.
2022-08-24 15:50:29,035 DEBUG TRAIN Batch 114/0 loss inf loss_att 36.051407 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00078541 rank 0
2022-08-24 15:50:57,896 DEBUG TRAIN Batch 114/100 loss 55.698898 loss_att 33.995914 loss_ctc 106.339188 loss_ctc_origin 61.955776 loss_ctc0 209.900497 lr 0.00078535 rank 0
2022-08-24 15:51:26,890 DEBUG TRAIN Batch 114/200 loss 19.849958 loss_att 11.089375 loss_ctc 40.291321 loss_ctc_origin 29.417568 loss_ctc0 65.663414 lr 0.00078529 rank 0
2022-08-24 15:51:55,217 DEBUG TRAIN Batch 114/300 loss 16.845055 loss_att 7.091525 loss_ctc 39.603287 loss_ctc_origin 25.592331 loss_ctc0 72.295517 lr 0.00078523 rank 0
2022-08-24 15:52:24,145 DEBUG TRAIN Batch 114/400 loss 29.938648 loss_att 13.546191 loss_ctc 68.187714 loss_ctc_origin 52.662647 loss_ctc0 104.412865 lr 0.00078517 rank 0
2022-08-24 15:52:52,885 DEBUG TRAIN Batch 114/500 loss 39.649532 loss_att 25.329636 loss_ctc 73.062622 loss_ctc_origin 42.789955 loss_ctc0 143.698822 lr 0.00078511 rank 0
2022-08-24 15:53:20,538 DEBUG TRAIN Batch 114/600 loss 30.025459 loss_att 19.271023 loss_ctc 55.119141 loss_ctc_origin 37.190308 loss_ctc0 96.953087 lr 0.00078505 rank 0
2022-08-24 15:53:48,645 DEBUG TRAIN Batch 114/700 loss 23.865469 loss_att 13.662304 loss_ctc 47.672852 loss_ctc_origin 37.206711 loss_ctc0 72.093842 lr 0.00078499 rank 0
2022-08-24 15:54:16,767 DEBUG TRAIN Batch 114/800 loss 23.076389 loss_att 10.272560 loss_ctc 52.951992 loss_ctc_origin 40.388535 loss_ctc0 82.266724 lr 0.00078493 rank 0
2022-08-24 15:54:45,214 DEBUG TRAIN Batch 114/900 loss 23.844322 loss_att 10.710135 loss_ctc 54.490757 loss_ctc_origin 37.026371 loss_ctc0 95.240990 lr 0.00078487 rank 0
2022-08-24 15:55:13,933 DEBUG TRAIN Batch 114/1000 loss 42.131622 loss_att 25.964619 loss_ctc 79.854630 loss_ctc_origin 45.240143 loss_ctc0 160.621765 lr 0.00078481 rank 0
2022-08-24 15:55:28,664 WARNING NaN or Inf found in input tensor.
2022-08-24 15:55:42,861 DEBUG TRAIN Batch 114/1100 loss 45.910652 loss_att 22.921661 loss_ctc 99.551628 loss_ctc_origin 49.352646 loss_ctc0 216.682587 lr 0.00078474 rank 0
2022-08-24 15:56:11,575 DEBUG TRAIN Batch 114/1200 loss 18.199717 loss_att 9.649595 loss_ctc 38.150002 loss_ctc_origin 26.754448 loss_ctc0 64.739616 lr 0.00078468 rank 0
2022-08-24 15:56:39,709 DEBUG TRAIN Batch 114/1300 loss 17.926441 loss_att 7.670862 loss_ctc 41.856125 loss_ctc_origin 27.792377 loss_ctc0 74.671524 lr 0.00078462 rank 0
2022-08-24 15:56:55,992 WARNING NaN or Inf found in input tensor.
2022-08-24 15:57:07,306 DEBUG TRAIN Batch 114/1400 loss 22.487886 loss_att 9.416086 loss_ctc 52.988754 loss_ctc_origin 35.141556 loss_ctc0 94.632210 lr 0.00078456 rank 0
2022-08-24 15:57:42,768 DEBUG TRAIN Batch 114/1500 loss 41.733868 loss_att 24.495039 loss_ctc 81.957802 loss_ctc_origin 48.378098 loss_ctc0 160.310440 lr 0.00078450 rank 0
2022-08-24 15:58:11,100 DEBUG TRAIN Batch 114/1600 loss 44.613148 loss_att 26.366055 loss_ctc 87.189697 loss_ctc_origin 53.406811 loss_ctc0 166.016434 lr 0.00078444 rank 0
2022-08-24 15:58:39,113 DEBUG TRAIN Batch 114/1700 loss 23.976402 loss_att 14.701557 loss_ctc 45.617706 loss_ctc_origin 35.401649 loss_ctc0 69.455170 lr 0.00078438 rank 0
2022-08-24 15:59:07,498 DEBUG TRAIN Batch 114/1800 loss 21.120665 loss_att 9.523064 loss_ctc 48.181732 loss_ctc_origin 34.357201 loss_ctc0 80.438965 lr 0.00078432 rank 0
2022-08-24 15:59:31,313 WARNING NaN or Inf found in input tensor.
2022-08-24 15:59:35,963 DEBUG TRAIN Batch 114/1900 loss 27.460711 loss_att 12.944424 loss_ctc 61.332047 loss_ctc_origin 43.398750 loss_ctc0 103.176392 lr 0.00078426 rank 0
2022-08-24 16:00:05,029 DEBUG TRAIN Batch 114/2000 loss 42.768261 loss_att 28.308046 loss_ctc 76.508759 loss_ctc_origin 43.959785 loss_ctc0 152.456360 lr 0.00078420 rank 0
2022-08-24 16:00:32,521 DEBUG TRAIN Batch 114/2100 loss 42.591473 loss_att 23.564682 loss_ctc 86.987312 loss_ctc_origin 45.642017 loss_ctc0 183.459656 lr 0.00078414 rank 0
2022-08-24 16:01:02,056 DEBUG TRAIN Batch 114/2200 loss 25.867081 loss_att 13.878839 loss_ctc 53.839645 loss_ctc_origin 43.823471 loss_ctc0 77.210709 lr 0.00078408 rank 0
2022-08-24 16:01:30,310 DEBUG TRAIN Batch 114/2300 loss 19.587366 loss_att 8.913378 loss_ctc 44.493336 loss_ctc_origin 31.793873 loss_ctc0 74.125412 lr 0.00078402 rank 0
2022-08-24 16:01:59,269 DEBUG TRAIN Batch 114/2400 loss 23.675165 loss_att 10.242073 loss_ctc 55.019043 loss_ctc_origin 38.640030 loss_ctc0 93.236740 lr 0.00078396 rank 0
2022-08-24 16:02:27,842 DEBUG TRAIN Batch 114/2500 loss 45.574585 loss_att 28.690716 loss_ctc 84.970276 loss_ctc_origin 51.582310 loss_ctc0 162.875519 lr 0.00078390 rank 0
2022-08-24 16:02:56,648 DEBUG TRAIN Batch 114/2600 loss 42.057163 loss_att 26.179005 loss_ctc 79.106201 loss_ctc_origin 53.740612 loss_ctc0 138.292572 lr 0.00078384 rank 0
2022-08-24 16:03:25,314 DEBUG TRAIN Batch 114/2700 loss 21.698231 loss_att 13.795097 loss_ctc 40.138878 loss_ctc_origin 30.588547 loss_ctc0 62.422989 lr 0.00078378 rank 0
2022-08-24 16:03:53,127 DEBUG TRAIN Batch 114/2800 loss 19.255051 loss_att 8.666092 loss_ctc 43.962616 loss_ctc_origin 28.552372 loss_ctc0 79.919846 lr 0.00078372 rank 0
2022-08-24 16:04:21,515 DEBUG TRAIN Batch 114/2900 loss 28.972095 loss_att 13.704993 loss_ctc 64.595337 loss_ctc_origin 47.776016 loss_ctc0 103.840424 lr 0.00078366 rank 0
2022-08-24 16:04:57,492 DEBUG TRAIN Batch 114/3000 loss 39.256218 loss_att 23.330795 loss_ctc 76.415543 loss_ctc_origin 45.464958 loss_ctc0 148.633575 lr 0.00078360 rank 0
2022-08-24 16:05:26,156 DEBUG TRAIN Batch 114/3100 loss 42.341694 loss_att 24.644474 loss_ctc 83.635208 loss_ctc_origin 45.343609 loss_ctc0 172.982269 lr 0.00078354 rank 0
2022-08-24 16:05:54,389 DEBUG TRAIN Batch 114/3200 loss 20.569548 loss_att 11.721927 loss_ctc 41.213993 loss_ctc_origin 31.002125 loss_ctc0 65.041687 lr 0.00078348 rank 0
2022-08-24 16:06:23,528 DEBUG TRAIN Batch 114/3300 loss 19.816662 loss_att 7.742003 loss_ctc 47.990868 loss_ctc_origin 33.262341 loss_ctc0 82.357422 lr 0.00078342 rank 0
2022-08-24 16:06:52,078 DEBUG TRAIN Batch 114/3400 loss 21.904022 loss_att 10.465612 loss_ctc 48.593643 loss_ctc_origin 29.872299 loss_ctc0 92.276779 lr 0.00078336 rank 0
2022-08-24 16:07:20,382 DEBUG TRAIN Batch 114/3500 loss 47.872555 loss_att 31.304718 loss_ctc 86.530838 loss_ctc_origin 59.510796 loss_ctc0 149.577606 lr 0.00078330 rank 0
2022-08-24 16:07:49,146 DEBUG TRAIN Batch 114/3600 loss 56.624466 loss_att 34.744473 loss_ctc 107.677788 loss_ctc_origin 68.967377 loss_ctc0 198.002075 lr 0.00078324 rank 0
2022-08-24 16:08:17,586 DEBUG TRAIN Batch 114/3700 loss 26.524063 loss_att 13.947162 loss_ctc 55.870159 loss_ctc_origin 47.423653 loss_ctc0 75.578674 lr 0.00078318 rank 0
2022-08-24 16:08:46,277 DEBUG TRAIN Batch 114/3800 loss 23.145336 loss_att 10.407232 loss_ctc 52.867577 loss_ctc_origin 40.047802 loss_ctc0 82.780380 lr 0.00078312 rank 0
2022-08-24 16:09:14,213 DEBUG TRAIN Batch 114/3900 loss 24.771982 loss_att 11.185949 loss_ctc 56.472725 loss_ctc_origin 40.306000 loss_ctc0 94.195084 lr 0.00078306 rank 0
2022-08-24 16:09:43,906 DEBUG TRAIN Batch 114/4000 loss 48.509048 loss_att 30.366726 loss_ctc 90.841125 loss_ctc_origin 53.062679 loss_ctc0 178.990814 lr 0.00078300 rank 0
2022-08-24 16:10:11,833 DEBUG TRAIN Batch 114/4100 loss 49.823822 loss_att 29.952423 loss_ctc 96.190414 loss_ctc_origin 57.390488 loss_ctc0 186.723572 lr 0.00078294 rank 0
2022-08-24 16:10:39,798 DEBUG TRAIN Batch 114/4200 loss 23.457075 loss_att 12.913428 loss_ctc 48.058914 loss_ctc_origin 37.870930 loss_ctc0 71.830879 lr 0.00078288 rank 0
2022-08-24 16:11:08,191 DEBUG TRAIN Batch 114/4300 loss 23.787645 loss_att 11.149593 loss_ctc 53.276432 loss_ctc_origin 40.807652 loss_ctc0 82.370255 lr 0.00078282 rank 0
2022-08-24 16:11:36,104 DEBUG TRAIN Batch 114/4400 loss 22.042408 loss_att 9.217828 loss_ctc 51.966431 loss_ctc_origin 33.201511 loss_ctc0 95.751244 lr 0.00078276 rank 0
2022-08-24 16:11:44,903 WARNING NaN or Inf found in input tensor.
2022-08-24 16:12:10,638 DEBUG TRAIN Batch 114/4500 loss 37.079880 loss_att 23.738981 loss_ctc 68.208633 loss_ctc_origin 36.908134 loss_ctc0 141.243134 lr 0.00078270 rank 0
2022-08-24 16:12:37,932 DEBUG TRAIN Batch 114/4600 loss 43.600941 loss_att 27.820198 loss_ctc 80.422668 loss_ctc_origin 44.911602 loss_ctc0 163.281830 lr 0.00078264 rank 0
2022-08-24 16:13:05,696 DEBUG TRAIN Batch 114/4700 loss 22.738892 loss_att 12.502750 loss_ctc 46.623222 loss_ctc_origin 35.950237 loss_ctc0 71.526848 lr 0.00078258 rank 0
2022-08-24 16:13:34,032 DEBUG TRAIN Batch 114/4800 loss 25.741055 loss_att 12.027613 loss_ctc 57.739082 loss_ctc_origin 45.195320 loss_ctc0 87.007858 lr 0.00078252 rank 0
2022-08-24 16:14:02,740 DEBUG TRAIN Batch 114/4900 loss 22.360434 loss_att 10.132078 loss_ctc 50.893265 loss_ctc_origin 33.803852 loss_ctc0 90.768555 lr 0.00078246 rank 0
2022-08-24 16:14:31,573 DEBUG TRAIN Batch 114/5000 loss 34.341930 loss_att 22.452045 loss_ctc 62.084988 loss_ctc_origin 34.678940 loss_ctc0 126.032433 lr 0.00078240 rank 0
2022-08-24 16:14:39,154 WARNING NaN or Inf found in input tensor.
2022-08-24 16:14:59,827 DEBUG TRAIN Batch 114/5100 loss 50.884171 loss_att 26.393394 loss_ctc 108.029312 loss_ctc_origin 59.364315 loss_ctc0 221.580978 lr 0.00078234 rank 0
2022-08-24 16:15:27,505 DEBUG TRAIN Batch 114/5200 loss 23.916656 loss_att 13.598583 loss_ctc 47.992165 loss_ctc_origin 37.563972 loss_ctc0 72.324615 lr 0.00078228 rank 0
2022-08-24 16:15:45,325 WARNING NaN or Inf found in input tensor.
2022-08-24 16:15:55,842 DEBUG TRAIN Batch 114/5300 loss 20.289061 loss_att 8.773495 loss_ctc 47.158714 loss_ctc_origin 32.559341 loss_ctc0 81.223915 lr 0.00078222 rank 0
2022-08-24 16:16:25,008 DEBUG TRAIN Batch 114/5400 loss 25.420757 loss_att 11.123734 loss_ctc 58.780479 loss_ctc_origin 41.237362 loss_ctc0 99.714424 lr 0.00078216 rank 0
2022-08-24 16:16:54,198 DEBUG TRAIN Batch 114/5500 loss 41.655113 loss_att 23.900867 loss_ctc 83.081696 loss_ctc_origin 47.707436 loss_ctc0 165.621643 lr 0.00078210 rank 0
2022-08-24 16:17:22,610 DEBUG TRAIN Batch 114/5600 loss 46.710060 loss_att 24.277363 loss_ctc 99.053009 loss_ctc_origin 48.545448 loss_ctc0 216.903992 lr 0.00078204 rank 0
2022-08-24 16:17:45,886 DEBUG CV Batch 114/0 loss 13.550978 loss_att 10.625707 loss_ctc 20.376610 loss_ctc_origin 14.335768 loss_ctc0 34.471905 history loss 12.753861 rank 0
2022-08-24 16:17:56,272 DEBUG CV Batch 114/100 loss 22.228477 loss_att 17.954136 loss_ctc 32.201942 loss_ctc_origin 21.577690 loss_ctc0 56.991859 history loss 27.758129 rank 0
2022-08-24 16:18:05,807 DEBUG CV Batch 114/200 loss 26.030771 loss_att 20.222626 loss_ctc 39.583111 loss_ctc_origin 29.894129 loss_ctc0 62.190735 history loss 29.133295 rank 0
2022-08-24 16:18:15,788 DEBUG CV Batch 114/300 loss 24.869366 loss_att 19.057991 loss_ctc 38.429241 loss_ctc_origin 23.206451 loss_ctc0 73.949081 history loss 28.238465 rank 0
2022-08-24 16:18:26,263 DEBUG CV Batch 114/400 loss 40.106419 loss_att 32.917679 loss_ctc 56.880138 loss_ctc_origin 39.656086 loss_ctc0 97.069588 history loss 26.558184 rank 0
2022-08-24 16:18:37,268 DEBUG CV Batch 114/500 loss 17.848339 loss_att 13.604301 loss_ctc 27.751091 loss_ctc_origin 21.178242 loss_ctc0 43.087738 history loss 26.208380 rank 0
2022-08-24 16:18:48,112 DEBUG CV Batch 114/600 loss 18.646395 loss_att 12.697705 loss_ctc 32.526669 loss_ctc_origin 20.852341 loss_ctc0 59.766762 history loss 25.994978 rank 0
2022-08-24 16:18:58,487 DEBUG CV Batch 114/700 loss 20.109257 loss_att 14.049655 loss_ctc 34.248329 loss_ctc_origin 21.117685 loss_ctc0 64.886505 history loss 25.678173 rank 0
2022-08-24 16:19:08,922 DEBUG CV Batch 114/800 loss 23.011292 loss_att 17.895470 loss_ctc 34.948208 loss_ctc_origin 19.631950 loss_ctc0 70.686142 history loss 25.670276 rank 0
2022-08-24 16:19:19,171 INFO Epoch 114 CV info cv_loss 25.767961551200038
2022-08-24 16:19:19,171 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/114.pt
2022-08-24 16:19:19,646 INFO Epoch 115 TRAIN info lr 0.0007819901480809802
2022-08-24 16:19:19,650 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 16:19:46,275 DEBUG TRAIN Batch 115/0 loss 53.036552 loss_att 35.789436 loss_ctc 93.279831 loss_ctc_origin 54.404152 loss_ctc0 183.989761 lr 0.00078199 rank 0
2022-08-24 16:20:14,719 DEBUG TRAIN Batch 115/100 loss 49.954330 loss_att 29.800930 loss_ctc 96.978935 loss_ctc_origin 56.055107 loss_ctc0 192.467865 lr 0.00078193 rank 0
2022-08-24 16:20:42,355 DEBUG TRAIN Batch 115/200 loss 25.190351 loss_att 15.613726 loss_ctc 47.535812 loss_ctc_origin 38.212360 loss_ctc0 69.290535 lr 0.00078187 rank 0
2022-08-24 16:21:10,739 DEBUG TRAIN Batch 115/300 loss 18.431435 loss_att 7.199751 loss_ctc 44.638695 loss_ctc_origin 28.488766 loss_ctc0 82.321861 lr 0.00078181 rank 0
2022-08-24 16:21:38,444 DEBUG TRAIN Batch 115/400 loss 23.269310 loss_att 10.490704 loss_ctc 53.086060 loss_ctc_origin 35.395844 loss_ctc0 94.363235 lr 0.00078175 rank 0
2022-08-24 16:21:40,979 WARNING NaN or Inf found in input tensor.
2022-08-24 16:22:07,349 DEBUG TRAIN Batch 115/500 loss 52.300819 loss_att 35.003105 loss_ctc 92.662155 loss_ctc_origin 55.998474 loss_ctc0 178.210724 lr 0.00078169 rank 0
2022-08-24 16:22:35,359 DEBUG TRAIN Batch 115/600 loss 46.038563 loss_att 24.806728 loss_ctc 95.579506 loss_ctc_origin 47.841568 loss_ctc0 206.968018 lr 0.00078163 rank 0
2022-08-24 16:23:02,063 WARNING NaN or Inf found in input tensor.
2022-08-24 16:23:03,604 DEBUG TRAIN Batch 115/700 loss 19.897911 loss_att 10.988864 loss_ctc 40.685688 loss_ctc_origin 28.081087 loss_ctc0 70.096420 lr 0.00078157 rank 0
2022-08-24 16:23:31,758 DEBUG TRAIN Batch 115/800 loss 21.415770 loss_att 8.893987 loss_ctc 50.633259 loss_ctc_origin 37.702950 loss_ctc0 80.803978 lr 0.00078151 rank 0
2022-08-24 16:23:49,919 WARNING NaN or Inf found in input tensor.
2022-08-24 16:24:01,604 DEBUG TRAIN Batch 115/900 loss 22.396082 loss_att 9.683381 loss_ctc 52.059052 loss_ctc_origin 34.877121 loss_ctc0 92.150223 lr 0.00078145 rank 0
2022-08-24 16:24:29,480 DEBUG TRAIN Batch 115/1000 loss 52.100060 loss_att 35.242790 loss_ctc 91.433693 loss_ctc_origin 62.443844 loss_ctc0 159.076675 lr 0.00078139 rank 0
2022-08-24 16:24:57,546 DEBUG TRAIN Batch 115/1100 loss 42.698315 loss_att 26.180796 loss_ctc 81.239189 loss_ctc_origin 50.512413 loss_ctc0 152.934998 lr 0.00078133 rank 0
2022-08-24 16:25:26,440 DEBUG TRAIN Batch 115/1200 loss 18.879517 loss_att 10.430927 loss_ctc 38.592888 loss_ctc_origin 30.808319 loss_ctc0 56.756882 lr 0.00078127 rank 0
2022-08-24 16:25:54,060 DEBUG TRAIN Batch 115/1300 loss 22.155695 loss_att 10.671336 loss_ctc 48.952530 loss_ctc_origin 35.924873 loss_ctc0 79.350388 lr 0.00078121 rank 0
2022-08-24 16:26:22,227 DEBUG TRAIN Batch 115/1400 loss 25.072239 loss_att 11.373990 loss_ctc 57.034821 loss_ctc_origin 39.682446 loss_ctc0 97.523689 lr 0.00078115 rank 0
2022-08-24 16:26:55,472 DEBUG TRAIN Batch 115/1500 loss 45.714962 loss_att 27.687136 loss_ctc 87.779884 loss_ctc_origin 49.963463 loss_ctc0 176.018204 lr 0.00078109 rank 0
2022-08-24 16:27:23,944 DEBUG TRAIN Batch 115/1600 loss 37.224438 loss_att 22.457544 loss_ctc 71.680527 loss_ctc_origin 43.395752 loss_ctc0 137.678345 lr 0.00078103 rank 0
2022-08-24 16:27:51,542 DEBUG TRAIN Batch 115/1700 loss 23.332405 loss_att 12.597414 loss_ctc 48.380714 loss_ctc_origin 38.327827 loss_ctc0 71.837448 lr 0.00078097 rank 0
2022-08-24 16:28:19,912 DEBUG TRAIN Batch 115/1800 loss 23.272625 loss_att 10.077165 loss_ctc 54.062035 loss_ctc_origin 40.113766 loss_ctc0 86.607986 lr 0.00078091 rank 0
2022-08-24 16:28:48,292 DEBUG TRAIN Batch 115/1900 loss 24.488312 loss_att 10.474833 loss_ctc 57.186432 loss_ctc_origin 37.771099 loss_ctc0 102.488861 lr 0.00078085 rank 0
2022-08-24 16:29:17,177 DEBUG TRAIN Batch 115/2000 loss 50.671959 loss_att 31.436197 loss_ctc 95.555389 loss_ctc_origin 59.020657 loss_ctc0 180.803070 lr 0.00078080 rank 0
2022-08-24 16:29:37,954 WARNING NaN or Inf found in input tensor.
2022-08-24 16:29:45,297 DEBUG TRAIN Batch 115/2100 loss 52.506863 loss_att 28.920773 loss_ctc 107.541061 loss_ctc_origin 52.542206 loss_ctc0 235.871704 lr 0.00078074 rank 0
2022-08-24 16:30:13,977 DEBUG TRAIN Batch 115/2200 loss 19.471869 loss_att 9.309397 loss_ctc 43.184299 loss_ctc_origin 31.189526 loss_ctc0 71.172104 lr 0.00078068 rank 0
2022-08-24 16:30:42,024 DEBUG TRAIN Batch 115/2300 loss 21.884159 loss_att 10.295610 loss_ctc 48.924103 loss_ctc_origin 35.463554 loss_ctc0 80.332047 lr 0.00078062 rank 0
2022-08-24 16:31:09,958 DEBUG TRAIN Batch 115/2400 loss 23.027706 loss_att 10.056927 loss_ctc 53.292854 loss_ctc_origin 38.139351 loss_ctc0 88.651016 lr 0.00078056 rank 0
2022-08-24 16:31:38,418 DEBUG TRAIN Batch 115/2500 loss 50.833828 loss_att 33.347450 loss_ctc 91.635376 loss_ctc_origin 58.729729 loss_ctc0 168.415207 lr 0.00078050 rank 0
2022-08-24 16:32:04,947 DEBUG TRAIN Batch 115/2600 loss 51.345978 loss_att 27.714319 loss_ctc 106.486511 loss_ctc_origin 56.478661 loss_ctc0 223.171478 lr 0.00078044 rank 0
2022-08-24 16:32:32,591 DEBUG TRAIN Batch 115/2700 loss 22.237663 loss_att 12.096561 loss_ctc 45.900230 loss_ctc_origin 32.983849 loss_ctc0 76.038445 lr 0.00078038 rank 0
2022-08-24 16:33:02,473 DEBUG TRAIN Batch 115/2800 loss 26.358677 loss_att 12.861079 loss_ctc 57.853065 loss_ctc_origin 45.253929 loss_ctc0 87.251053 lr 0.00078032 rank 0
2022-08-24 16:33:31,064 DEBUG TRAIN Batch 115/2900 loss 25.241110 loss_att 11.396657 loss_ctc 57.544830 loss_ctc_origin 39.627335 loss_ctc0 99.352325 lr 0.00078026 rank 0
2022-08-24 16:34:05,508 DEBUG TRAIN Batch 115/3000 loss 40.644947 loss_att 24.925997 loss_ctc 77.322495 loss_ctc_origin 46.718372 loss_ctc0 148.732101 lr 0.00078020 rank 0
2022-08-24 16:34:34,120 DEBUG TRAIN Batch 115/3100 loss 46.243778 loss_att 27.785379 loss_ctc 89.313370 loss_ctc_origin 44.946918 loss_ctc0 192.835083 lr 0.00078014 rank 0
2022-08-24 16:35:02,288 DEBUG TRAIN Batch 115/3200 loss 21.809185 loss_att 11.615719 loss_ctc 45.593933 loss_ctc_origin 32.864281 loss_ctc0 75.296455 lr 0.00078008 rank 0
2022-08-24 16:35:30,265 DEBUG TRAIN Batch 115/3300 loss 21.829002 loss_att 9.716277 loss_ctc 50.092026 loss_ctc_origin 36.702950 loss_ctc0 81.333206 lr 0.00078002 rank 0
2022-08-24 16:35:58,556 DEBUG TRAIN Batch 115/3400 loss 23.436253 loss_att 10.261377 loss_ctc 54.177624 loss_ctc_origin 38.338326 loss_ctc0 91.135979 lr 0.00077996 rank 0
2022-08-24 16:36:27,923 DEBUG TRAIN Batch 115/3500 loss 50.314808 loss_att 32.150139 loss_ctc 92.699036 loss_ctc_origin 57.009624 loss_ctc0 175.974304 lr 0.00077990 rank 0
2022-08-24 16:36:55,637 DEBUG TRAIN Batch 115/3600 loss 40.602364 loss_att 23.802444 loss_ctc 79.802170 loss_ctc_origin 45.059536 loss_ctc0 160.868317 lr 0.00077984 rank 0
2022-08-24 16:37:22,388 WARNING NaN or Inf found in input tensor.
2022-08-24 16:37:23,888 DEBUG TRAIN Batch 115/3700 loss 19.077293 loss_att 9.668800 loss_ctc 41.030441 loss_ctc_origin 30.466970 loss_ctc0 65.678528 lr 0.00077979 rank 0
2022-08-24 16:37:54,341 DEBUG TRAIN Batch 115/3800 loss 21.607391 loss_att 9.878654 loss_ctc 48.974442 loss_ctc_origin 36.037415 loss_ctc0 79.160828 lr 0.00077973 rank 0
2022-08-24 16:38:22,536 DEBUG TRAIN Batch 115/3900 loss 18.994583 loss_att 7.911378 loss_ctc 44.855396 loss_ctc_origin 28.104837 loss_ctc0 83.940033 lr 0.00077967 rank 0
2022-08-24 16:38:50,931 DEBUG TRAIN Batch 115/4000 loss 50.914436 loss_att 32.966011 loss_ctc 92.794098 loss_ctc_origin 56.855461 loss_ctc0 176.650925 lr 0.00077961 rank 0
2022-08-24 16:39:19,735 DEBUG TRAIN Batch 115/4100 loss 49.581413 loss_att 31.854610 loss_ctc 90.943954 loss_ctc_origin 63.927357 loss_ctc0 153.982666 lr 0.00077955 rank 0
2022-08-24 16:39:46,650 DEBUG TRAIN Batch 115/4200 loss 20.284256 loss_att 10.774485 loss_ctc 42.473724 loss_ctc_origin 31.418079 loss_ctc0 68.270226 lr 0.00077949 rank 0
2022-08-24 16:40:15,037 DEBUG TRAIN Batch 115/4300 loss 20.283888 loss_att 8.691275 loss_ctc 47.333317 loss_ctc_origin 32.369106 loss_ctc0 82.249802 lr 0.00077943 rank 0
2022-08-24 16:40:43,739 DEBUG TRAIN Batch 115/4400 loss 22.444210 loss_att 9.820347 loss_ctc 51.899887 loss_ctc_origin 34.890472 loss_ctc0 91.588524 lr 0.00077937 rank 0
2022-08-24 16:41:17,054 DEBUG TRAIN Batch 115/4500 loss 51.026867 loss_att 33.869034 loss_ctc 91.061813 loss_ctc_origin 58.642563 loss_ctc0 166.706726 lr 0.00077931 rank 0
2022-08-24 16:41:32,313 WARNING NaN or Inf found in input tensor.
2022-08-24 16:41:44,887 DEBUG TRAIN Batch 115/4600 loss 41.285999 loss_att 26.373732 loss_ctc 76.081284 loss_ctc_origin 52.661362 loss_ctc0 130.727753 lr 0.00077925 rank 0
2022-08-24 16:42:12,824 DEBUG TRAIN Batch 115/4700 loss 19.101908 loss_att 9.604567 loss_ctc 41.262367 loss_ctc_origin 29.484314 loss_ctc0 68.744492 lr 0.00077919 rank 0
2022-08-24 16:42:41,386 DEBUG TRAIN Batch 115/4800 loss 21.187340 loss_att 8.647474 loss_ctc 50.447025 loss_ctc_origin 36.801403 loss_ctc0 82.286804 lr 0.00077913 rank 0
2022-08-24 16:43:04,981 WARNING NaN or Inf found in input tensor.
2022-08-24 16:43:09,184 DEBUG TRAIN Batch 115/4900 loss 24.971153 loss_att 11.380539 loss_ctc 56.682587 loss_ctc_origin 39.049492 loss_ctc0 97.826477 lr 0.00077908 rank 0
2022-08-24 16:43:18,561 WARNING NaN or Inf found in input tensor.
2022-08-24 16:43:37,532 DEBUG TRAIN Batch 115/5000 loss 48.770992 loss_att 31.152596 loss_ctc 89.880585 loss_ctc_origin 58.994808 loss_ctc0 161.947388 lr 0.00077902 rank 0
2022-08-24 16:44:05,347 DEBUG TRAIN Batch 115/5100 loss 47.560310 loss_att 32.406868 loss_ctc 82.918335 loss_ctc_origin 58.596062 loss_ctc0 139.670319 lr 0.00077896 rank 0
2022-08-24 16:44:30,515 WARNING NaN or Inf found in input tensor.
2022-08-24 16:44:32,029 DEBUG TRAIN Batch 115/5200 loss 19.174717 loss_att 9.756094 loss_ctc 41.151505 loss_ctc_origin 31.121719 loss_ctc0 64.554337 lr 0.00077890 rank 0
2022-08-24 16:44:37,164 WARNING NaN or Inf found in input tensor.
2022-08-24 16:44:59,848 DEBUG TRAIN Batch 115/5300 loss 23.201427 loss_att 11.763996 loss_ctc 49.888767 loss_ctc_origin 35.965935 loss_ctc0 82.375374 lr 0.00077884 rank 0
2022-08-24 16:45:28,079 DEBUG TRAIN Batch 115/5400 loss 28.137997 loss_att 13.682463 loss_ctc 61.867577 loss_ctc_origin 44.894428 loss_ctc0 101.471588 lr 0.00077878 rank 0
2022-08-24 16:45:57,578 DEBUG TRAIN Batch 115/5500 loss 48.745518 loss_att 32.570908 loss_ctc 86.486275 loss_ctc_origin 56.902134 loss_ctc0 155.515930 lr 0.00077872 rank 0
2022-08-24 16:46:25,220 DEBUG TRAIN Batch 115/5600 loss 39.284863 loss_att 23.003672 loss_ctc 77.274307 loss_ctc_origin 50.193439 loss_ctc0 140.462997 lr 0.00077866 rank 0
2022-08-24 16:46:48,377 DEBUG CV Batch 115/0 loss 13.914030 loss_att 10.958029 loss_ctc 20.811367 loss_ctc_origin 14.922061 loss_ctc0 34.553085 history loss 13.095558 rank 0
2022-08-24 16:46:59,095 DEBUG CV Batch 115/100 loss 23.087982 loss_att 18.333920 loss_ctc 34.180794 loss_ctc_origin 23.482180 loss_ctc0 59.144226 history loss 29.167249 rank 0
2022-08-24 16:47:08,793 DEBUG CV Batch 115/200 loss 26.477493 loss_att 20.247631 loss_ctc 41.013832 loss_ctc_origin 31.470821 loss_ctc0 63.280853 history loss 30.778759 rank 0
2022-08-24 16:47:18,850 DEBUG CV Batch 115/300 loss 24.438349 loss_att 18.422615 loss_ctc 38.475060 loss_ctc_origin 23.445290 loss_ctc0 73.544525 history loss 29.697912 rank 0
2022-08-24 16:47:29,242 DEBUG CV Batch 115/400 loss 40.813141 loss_att 33.488144 loss_ctc 57.904793 loss_ctc_origin 41.462105 loss_ctc0 96.271065 history loss 27.865189 rank 0
2022-08-24 16:47:39,911 DEBUG CV Batch 115/500 loss 17.872356 loss_att 13.521080 loss_ctc 28.025331 loss_ctc_origin 21.247637 loss_ctc0 43.839951 history loss 27.461781 rank 0
2022-08-24 16:47:50,770 DEBUG CV Batch 115/600 loss 26.581026 loss_att 18.410265 loss_ctc 45.646133 loss_ctc_origin 28.442034 loss_ctc0 85.789032 history loss 27.299109 rank 0
2022-08-24 16:48:00,526 DEBUG CV Batch 115/700 loss 20.393593 loss_att 14.400951 loss_ctc 34.376427 loss_ctc_origin 21.352198 loss_ctc0 64.766296 history loss 26.932756 rank 0
2022-08-24 16:48:10,919 DEBUG CV Batch 115/800 loss 22.993561 loss_att 17.849712 loss_ctc 34.995872 loss_ctc_origin 19.970583 loss_ctc0 70.054871 history loss 26.864357 rank 0
2022-08-24 16:48:21,198 INFO Epoch 115 CV info cv_loss 26.912138097990315
2022-08-24 16:48:21,199 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/115.pt
2022-08-24 16:48:21,662 INFO Epoch 116 TRAIN info lr 0.0007786122050836558
2022-08-24 16:48:21,666 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 16:48:47,955 DEBUG TRAIN Batch 116/0 loss 38.643799 loss_att 24.126654 loss_ctc 72.517136 loss_ctc_origin 45.878403 loss_ctc0 134.674164 lr 0.00077861 rank 0
2022-08-24 16:49:16,107 DEBUG TRAIN Batch 116/100 loss 45.494362 loss_att 25.576735 loss_ctc 91.968834 loss_ctc_origin 53.399143 loss_ctc0 181.964783 lr 0.00077855 rank 0
2022-08-24 16:49:42,775 WARNING NaN or Inf found in input tensor.
2022-08-24 16:49:44,358 DEBUG TRAIN Batch 116/200 loss 22.680071 loss_att 13.899453 loss_ctc 43.168179 loss_ctc_origin 33.424782 loss_ctc0 65.902771 lr 0.00077849 rank 0
2022-08-24 16:49:49,909 WARNING NaN or Inf found in input tensor.
2022-08-24 16:50:12,871 DEBUG TRAIN Batch 116/300 loss 19.953606 loss_att 8.701757 loss_ctc 46.207916 loss_ctc_origin 32.731796 loss_ctc0 77.652206 lr 0.00077843 rank 0
2022-08-24 16:50:41,832 DEBUG TRAIN Batch 116/400 loss 24.718184 loss_att 11.443525 loss_ctc 55.692387 loss_ctc_origin 39.636337 loss_ctc0 93.156502 lr 0.00077837 rank 0
2022-08-24 16:51:10,962 DEBUG TRAIN Batch 116/500 loss 41.282066 loss_att 27.549454 loss_ctc 73.324829 loss_ctc_origin 46.042660 loss_ctc0 136.983200 lr 0.00077832 rank 0
2022-08-24 16:51:39,056 DEBUG TRAIN Batch 116/600 loss 40.706017 loss_att 24.337337 loss_ctc 78.899597 loss_ctc_origin 52.046822 loss_ctc0 141.556061 lr 0.00077826 rank 0
2022-08-24 16:52:06,859 DEBUG TRAIN Batch 116/700 loss 23.646538 loss_att 11.545774 loss_ctc 51.881653 loss_ctc_origin 42.046005 loss_ctc0 74.831497 lr 0.00077820 rank 0
2022-08-24 16:52:25,035 WARNING NaN or Inf found in input tensor.
2022-08-24 16:52:35,210 DEBUG TRAIN Batch 116/800 loss 24.306572 loss_att 11.805943 loss_ctc 53.474709 loss_ctc_origin 40.572605 loss_ctc0 83.579620 lr 0.00077814 rank 0
2022-08-24 16:53:02,515 DEBUG TRAIN Batch 116/900 loss 24.927195 loss_att 12.130732 loss_ctc 54.785606 loss_ctc_origin 37.931961 loss_ctc0 94.110771 lr 0.00077808 rank 0
2022-08-24 16:53:31,188 DEBUG TRAIN Batch 116/1000 loss 50.668056 loss_att 34.279579 loss_ctc 88.907837 loss_ctc_origin 60.938942 loss_ctc0 154.168579 lr 0.00077802 rank 0
2022-08-24 16:53:52,690 WARNING NaN or Inf found in input tensor.
2022-08-24 16:54:00,018 DEBUG TRAIN Batch 116/1100 loss 37.013592 loss_att 21.398726 loss_ctc 73.448273 loss_ctc_origin 44.325150 loss_ctc0 141.402222 lr 0.00077796 rank 0
2022-08-24 16:54:28,138 DEBUG TRAIN Batch 116/1200 loss 25.723797 loss_att 13.922162 loss_ctc 53.260948 loss_ctc_origin 44.255489 loss_ctc0 74.273682 lr 0.00077790 rank 0
2022-08-24 16:54:57,326 DEBUG TRAIN Batch 116/1300 loss 21.923555 loss_att 9.419324 loss_ctc 51.100094 loss_ctc_origin 36.499577 loss_ctc0 85.167961 lr 0.00077784 rank 0
2022-08-24 16:55:25,623 DEBUG TRAIN Batch 116/1400 loss 23.693623 loss_att 10.762346 loss_ctc 53.866600 loss_ctc_origin 36.600430 loss_ctc0 94.154327 lr 0.00077779 rank 0
2022-08-24 16:55:58,790 DEBUG TRAIN Batch 116/1500 loss 44.955948 loss_att 29.745220 loss_ctc 80.447639 loss_ctc_origin 50.222046 loss_ctc0 150.974030 lr 0.00077773 rank 0
2022-08-24 16:56:27,135 DEBUG TRAIN Batch 116/1600 loss 40.090424 loss_att 23.477131 loss_ctc 78.854767 loss_ctc_origin 49.459881 loss_ctc0 147.442825 lr 0.00077767 rank 0
2022-08-24 16:56:55,298 DEBUG TRAIN Batch 116/1700 loss 21.493114 loss_att 11.675485 loss_ctc 44.400917 loss_ctc_origin 34.061043 loss_ctc0 68.527283 lr 0.00077761 rank 0
2022-08-24 16:57:23,224 DEBUG TRAIN Batch 116/1800 loss 23.885120 loss_att 10.403394 loss_ctc 55.342484 loss_ctc_origin 40.704842 loss_ctc0 89.496979 lr 0.00077755 rank 0
2022-08-24 16:57:51,832 DEBUG TRAIN Batch 116/1900 loss 26.620659 loss_att 11.887399 loss_ctc 60.998268 loss_ctc_origin 41.053513 loss_ctc0 107.536026 lr 0.00077749 rank 0
2022-08-24 16:58:20,377 DEBUG TRAIN Batch 116/2000 loss 47.479362 loss_att 28.824917 loss_ctc 91.006409 loss_ctc_origin 52.354603 loss_ctc0 181.193954 lr 0.00077743 rank 0
2022-08-24 16:58:48,224 DEBUG TRAIN Batch 116/2100 loss 57.538078 loss_att 36.261368 loss_ctc 107.183731 loss_ctc_origin 66.678902 loss_ctc0 201.695007 lr 0.00077737 rank 0
2022-08-24 16:59:15,502 DEBUG TRAIN Batch 116/2200 loss 21.810593 loss_att 11.664677 loss_ctc 45.484390 loss_ctc_origin 35.370865 loss_ctc0 69.082611 lr 0.00077732 rank 0
2022-08-24 16:59:44,635 DEBUG TRAIN Batch 116/2300 loss 20.069557 loss_att 9.078907 loss_ctc 45.714409 loss_ctc_origin 32.901230 loss_ctc0 75.611832 lr 0.00077726 rank 0
2022-08-24 17:00:12,739 DEBUG TRAIN Batch 116/2400 loss 22.755077 loss_att 10.617031 loss_ctc 51.077187 loss_ctc_origin 36.142189 loss_ctc0 85.925507 lr 0.00077720 rank 0
2022-08-24 17:00:40,089 DEBUG TRAIN Batch 116/2500 loss 50.561020 loss_att 33.721336 loss_ctc 89.853622 loss_ctc_origin 52.903069 loss_ctc0 176.071594 lr 0.00077714 rank 0
2022-08-24 17:01:07,918 DEBUG TRAIN Batch 116/2600 loss 52.888344 loss_att 32.235283 loss_ctc 101.078827 loss_ctc_origin 54.878170 loss_ctc0 208.880341 lr 0.00077708 rank 0
2022-08-24 17:01:34,727 WARNING NaN or Inf found in input tensor.
2022-08-24 17:01:36,295 DEBUG TRAIN Batch 116/2700 loss 21.110518 loss_att 10.678238 loss_ctc 45.452503 loss_ctc_origin 34.582287 loss_ctc0 70.816345 lr 0.00077702 rank 0
2022-08-24 17:02:04,961 DEBUG TRAIN Batch 116/2800 loss 21.172329 loss_att 9.484169 loss_ctc 48.444698 loss_ctc_origin 33.663464 loss_ctc0 82.934242 lr 0.00077696 rank 0
2022-08-24 17:02:33,240 DEBUG TRAIN Batch 116/2900 loss 23.150211 loss_att 11.134653 loss_ctc 51.186516 loss_ctc_origin 33.338478 loss_ctc0 92.831932 lr 0.00077690 rank 0
2022-08-24 17:03:06,799 DEBUG TRAIN Batch 116/3000 loss 58.794754 loss_att 42.064796 loss_ctc 97.831314 loss_ctc_origin 66.390274 loss_ctc0 171.193741 lr 0.00077685 rank 0
2022-08-24 17:03:35,561 DEBUG TRAIN Batch 116/3100 loss -484793536.000000 loss_att 33.789230 loss_ctc -1615978496.000000 loss_ctc_origin 65.042206 loss_ctc0 -5386594816.000000 lr 0.00077679 rank 0
2022-08-24 17:04:03,967 DEBUG TRAIN Batch 116/3200 loss 22.180552 loss_att 13.201527 loss_ctc 43.131607 loss_ctc_origin 31.379103 loss_ctc0 70.554123 lr 0.00077673 rank 0
2022-08-24 17:04:31,705 DEBUG TRAIN Batch 116/3300 loss 23.856518 loss_att 11.160789 loss_ctc 53.479885 loss_ctc_origin 38.760078 loss_ctc0 87.826096 lr 0.00077667 rank 0
2022-08-24 17:04:59,605 DEBUG TRAIN Batch 116/3400 loss 25.091351 loss_att 10.916947 loss_ctc 58.164955 loss_ctc_origin 41.404610 loss_ctc0 97.272415 lr 0.00077661 rank 0
2022-08-24 17:05:28,185 DEBUG TRAIN Batch 116/3500 loss 54.050308 loss_att 39.582832 loss_ctc 87.807739 loss_ctc_origin 56.407463 loss_ctc0 161.075058 lr 0.00077655 rank 0
2022-08-24 17:05:55,659 DEBUG TRAIN Batch 116/3600 loss 52.959000 loss_att 34.429192 loss_ctc 96.195221 loss_ctc_origin 63.651375 loss_ctc0 172.130844 lr 0.00077649 rank 0
2022-08-24 17:06:22,030 WARNING NaN or Inf found in input tensor.
2022-08-24 17:06:23,584 DEBUG TRAIN Batch 116/3700 loss 21.729227 loss_att 12.281364 loss_ctc 43.774239 loss_ctc_origin 34.601055 loss_ctc0 65.178329 lr 0.00077644 rank 0
2022-08-24 17:06:52,777 DEBUG TRAIN Batch 116/3800 loss 21.378674 loss_att 9.705475 loss_ctc 48.616135 loss_ctc_origin 35.811939 loss_ctc0 78.492584 lr 0.00077638 rank 0
2022-08-24 17:07:22,311 DEBUG TRAIN Batch 116/3900 loss 24.538658 loss_att 10.159117 loss_ctc 58.090919 loss_ctc_origin 39.844589 loss_ctc0 100.665695 lr 0.00077632 rank 0
2022-08-24 17:07:51,267 DEBUG TRAIN Batch 116/4000 loss 47.903843 loss_att 31.638531 loss_ctc 85.856239 loss_ctc_origin 53.078114 loss_ctc0 162.338531 lr 0.00077626 rank 0
2022-08-24 17:08:19,466 DEBUG TRAIN Batch 116/4100 loss 52.623131 loss_att 32.016235 loss_ctc 100.705894 loss_ctc_origin 54.273819 loss_ctc0 209.047394 lr 0.00077620 rank 0
2022-08-24 17:08:47,165 DEBUG TRAIN Batch 116/4200 loss 25.632502 loss_att 14.537127 loss_ctc 51.521709 loss_ctc_origin 42.155525 loss_ctc0 73.376137 lr 0.00077614 rank 0
2022-08-24 17:09:00,331 WARNING NaN or Inf found in input tensor.
2022-08-24 17:09:16,609 DEBUG TRAIN Batch 116/4300 loss 22.362020 loss_att 10.268923 loss_ctc 50.579247 loss_ctc_origin 36.351135 loss_ctc0 83.778168 lr 0.00077609 rank 0
2022-08-24 17:09:34,858 WARNING NaN or Inf found in input tensor.
2022-08-24 17:09:46,389 DEBUG TRAIN Batch 116/4400 loss 26.531986 loss_att 11.831554 loss_ctc 60.832989 loss_ctc_origin 45.586624 loss_ctc0 96.407837 lr 0.00077603 rank 0
2022-08-24 17:10:19,616 DEBUG TRAIN Batch 116/4500 loss 51.079689 loss_att 35.814903 loss_ctc 86.697510 loss_ctc_origin 57.041191 loss_ctc0 155.895569 lr 0.00077597 rank 0
2022-08-24 17:10:48,356 DEBUG TRAIN Batch 116/4600 loss 49.795952 loss_att 30.812708 loss_ctc 94.090187 loss_ctc_origin 62.941372 loss_ctc0 166.770752 lr 0.00077591 rank 0
2022-08-24 17:11:17,114 DEBUG TRAIN Batch 116/4700 loss 20.418543 loss_att 10.512568 loss_ctc 43.532482 loss_ctc_origin 31.571894 loss_ctc0 71.440521 lr 0.00077585 rank 0
2022-08-24 17:11:45,870 DEBUG TRAIN Batch 116/4800 loss 24.631207 loss_att 11.953407 loss_ctc 54.212738 loss_ctc_origin 41.072426 loss_ctc0 84.873459 lr 0.00077579 rank 0
2022-08-24 17:12:09,215 WARNING NaN or Inf found in input tensor.
2022-08-24 17:12:13,458 DEBUG TRAIN Batch 116/4900 loss 25.028751 loss_att 10.936267 loss_ctc 57.911209 loss_ctc_origin 41.588127 loss_ctc0 95.998398 lr 0.00077573 rank 0
2022-08-24 17:12:43,146 DEBUG TRAIN Batch 116/5000 loss 50.977226 loss_att 35.730141 loss_ctc 86.553757 loss_ctc_origin 53.272541 loss_ctc0 164.209930 lr 0.00077568 rank 0
2022-08-24 17:13:10,592 DEBUG TRAIN Batch 116/5100 loss 65.322159 loss_att 39.040527 loss_ctc 126.645950 loss_ctc_origin 69.994362 loss_ctc0 258.832977 lr 0.00077562 rank 0
2022-08-24 17:13:38,440 DEBUG TRAIN Batch 116/5200 loss 20.581837 loss_att 11.095864 loss_ctc 42.715771 loss_ctc_origin 32.054256 loss_ctc0 67.592636 lr 0.00077556 rank 0
2022-08-24 17:14:05,806 DEBUG TRAIN Batch 116/5300 loss 23.456146 loss_att 11.465378 loss_ctc 51.434601 loss_ctc_origin 36.067818 loss_ctc0 87.290421 lr 0.00077550 rank 0
2022-08-24 17:14:35,136 DEBUG TRAIN Batch 116/5400 loss 23.847507 loss_att 10.876422 loss_ctc 54.113373 loss_ctc_origin 36.967773 loss_ctc0 94.119766 lr 0.00077544 rank 0
2022-08-24 17:15:03,851 DEBUG TRAIN Batch 116/5500 loss 50.130035 loss_att 33.085129 loss_ctc 89.901489 loss_ctc_origin 60.151176 loss_ctc0 159.318878 lr 0.00077538 rank 0
2022-08-24 17:15:31,463 DEBUG TRAIN Batch 116/5600 loss 60.210297 loss_att 35.338802 loss_ctc 118.243782 loss_ctc_origin 68.748421 loss_ctc0 233.732941 lr 0.00077533 rank 0
2022-08-24 17:15:54,317 DEBUG CV Batch 116/0 loss 12.917953 loss_att 9.841655 loss_ctc 20.095985 loss_ctc_origin 13.477932 loss_ctc0 35.538105 history loss 12.158074 rank 0
2022-08-24 17:16:05,093 DEBUG CV Batch 116/100 loss 21.790169 loss_att 17.256884 loss_ctc 32.367828 loss_ctc_origin 22.213451 loss_ctc0 56.061371 history loss 27.813263 rank 0
2022-08-24 17:16:14,917 DEBUG CV Batch 116/200 loss 25.742779 loss_att 19.244911 loss_ctc 40.904465 loss_ctc_origin 31.208042 loss_ctc0 63.529457 history loss 29.405279 rank 0
2022-08-24 17:16:24,853 DEBUG CV Batch 116/300 loss 24.102938 loss_att 18.088390 loss_ctc 38.136883 loss_ctc_origin 23.276943 loss_ctc0 72.810074 history loss 28.510040 rank 0
2022-08-24 17:16:35,658 DEBUG CV Batch 116/400 loss 39.870743 loss_att 32.473278 loss_ctc 57.131500 loss_ctc_origin 40.238396 loss_ctc0 96.548752 history loss 26.818916 rank 0
2022-08-24 17:16:46,249 DEBUG CV Batch 116/500 loss 17.968302 loss_att 13.738932 loss_ctc 27.836830 loss_ctc_origin 21.552437 loss_ctc0 42.500412 history loss 26.478119 rank 0
2022-08-24 17:16:56,881 DEBUG CV Batch 116/600 loss 22.490345 loss_att 15.228600 loss_ctc 39.434418 loss_ctc_origin 24.628860 loss_ctc0 73.980713 history loss 26.329346 rank 0
2022-08-24 17:17:06,895 DEBUG CV Batch 116/700 loss 20.271566 loss_att 13.859699 loss_ctc 35.232590 loss_ctc_origin 22.399153 loss_ctc0 65.177277 history loss 25.966352 rank 0
2022-08-24 17:17:17,292 DEBUG CV Batch 116/800 loss 22.802820 loss_att 17.858372 loss_ctc 34.339867 loss_ctc_origin 18.776772 loss_ctc0 70.653755 history loss 25.931352 rank 0
2022-08-24 17:17:27,712 INFO Epoch 116 CV info cv_loss 25.974751637354228
2022-08-24 17:17:27,712 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/116.pt
2022-08-24 17:17:28,161 INFO Epoch 117 TRAIN info lr 0.0007752776621160502
2022-08-24 17:17:28,165 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 17:17:54,552 DEBUG TRAIN Batch 117/0 loss 49.503376 loss_att 31.680801 loss_ctc 91.089378 loss_ctc_origin 53.952087 loss_ctc0 177.743057 lr 0.00077528 rank 0
2022-08-24 17:18:23,012 DEBUG TRAIN Batch 117/100 loss 60.492683 loss_att 34.333584 loss_ctc 121.530579 loss_ctc_origin 68.714203 loss_ctc0 244.768799 lr 0.00077522 rank 0
2022-08-24 17:18:50,912 DEBUG TRAIN Batch 117/200 loss 16.295425 loss_att 8.113863 loss_ctc 35.385735 loss_ctc_origin 23.149586 loss_ctc0 63.936741 lr 0.00077516 rank 0
2022-08-24 17:19:18,653 DEBUG TRAIN Batch 117/300 loss 19.538326 loss_att 7.917429 loss_ctc 46.653755 loss_ctc_origin 32.989471 loss_ctc0 78.537079 lr 0.00077510 rank 0
2022-08-24 17:19:47,059 DEBUG TRAIN Batch 117/400 loss 28.545174 loss_att 13.776685 loss_ctc 63.004978 loss_ctc_origin 48.062172 loss_ctc0 97.871521 lr 0.00077504 rank 0
2022-08-24 17:20:15,936 DEBUG TRAIN Batch 117/500 loss 43.992119 loss_att 26.431232 loss_ctc 84.967514 loss_ctc_origin 45.998722 loss_ctc0 175.894684 lr 0.00077498 rank 0
2022-08-24 17:20:35,745 WARNING NaN or Inf found in input tensor.
2022-08-24 17:20:42,920 DEBUG TRAIN Batch 117/600 loss 49.790688 loss_att 25.317734 loss_ctc 106.894249 loss_ctc_origin 57.289268 loss_ctc0 222.639191 lr 0.00077493 rank 0
2022-08-24 17:21:10,944 DEBUG TRAIN Batch 117/700 loss 21.156223 loss_att 11.285271 loss_ctc 44.188446 loss_ctc_origin 33.869316 loss_ctc0 68.266418 lr 0.00077487 rank 0
2022-08-24 17:21:38,845 DEBUG TRAIN Batch 117/800 loss 22.324024 loss_att 10.498087 loss_ctc 49.917877 loss_ctc_origin 35.135979 loss_ctc0 84.408981 lr 0.00077481 rank 0
2022-08-24 17:22:07,365 DEBUG TRAIN Batch 117/900 loss 20.491594 loss_att 8.808737 loss_ctc 47.751595 loss_ctc_origin 29.293764 loss_ctc0 90.819862 lr 0.00077475 rank 0
2022-08-24 17:22:35,490 DEBUG TRAIN Batch 117/1000 loss 38.590664 loss_att 25.662003 loss_ctc 68.757538 loss_ctc_origin 39.999191 loss_ctc0 135.860336 lr 0.00077469 rank 0
2022-08-24 17:23:04,115 DEBUG TRAIN Batch 117/1100 loss 56.279404 loss_att 32.947731 loss_ctc 110.719971 loss_ctc_origin 59.634521 loss_ctc0 229.919342 lr 0.00077464 rank 0
2022-08-24 17:23:31,623 DEBUG TRAIN Batch 117/1200 loss 18.363626 loss_att 10.851067 loss_ctc 35.892929 loss_ctc_origin 25.248507 loss_ctc0 60.729919 lr 0.00077458 rank 0
2022-08-24 17:23:43,988 WARNING NaN or Inf found in input tensor.
2022-08-24 17:24:00,899 DEBUG TRAIN Batch 117/1300 loss 19.773796 loss_att 7.284223 loss_ctc 48.916130 loss_ctc_origin 33.364693 loss_ctc0 85.202820 lr 0.00077452 rank 0
2022-08-24 17:24:28,452 DEBUG TRAIN Batch 117/1400 loss 22.745710 loss_att 9.578274 loss_ctc 53.469727 loss_ctc_origin 34.969116 loss_ctc0 96.637817 lr 0.00077446 rank 0
2022-08-24 17:24:36,433 WARNING NaN or Inf found in input tensor.
2022-08-24 17:25:02,260 DEBUG TRAIN Batch 117/1500 loss 56.737461 loss_att 35.964996 loss_ctc 105.206543 loss_ctc_origin 61.814171 loss_ctc0 206.455414 lr 0.00077440 rank 0
2022-08-24 17:25:10,241 WARNING NaN or Inf found in input tensor.
2022-08-24 17:25:29,853 DEBUG TRAIN Batch 117/1600 loss 58.297596 loss_att 34.191132 loss_ctc 114.546005 loss_ctc_origin 60.103065 loss_ctc0 241.579529 lr 0.00077435 rank 0
2022-08-24 17:25:58,926 DEBUG TRAIN Batch 117/1700 loss 22.342646 loss_att 11.442690 loss_ctc 47.775875 loss_ctc_origin 37.657307 loss_ctc0 71.385864 lr 0.00077429 rank 0
2022-08-24 17:26:26,927 DEBUG TRAIN Batch 117/1800 loss 20.928537 loss_att 10.443130 loss_ctc 45.394485 loss_ctc_origin 30.419182 loss_ctc0 80.336861 lr 0.00077423 rank 0
2022-08-24 17:26:55,432 DEBUG TRAIN Batch 117/1900 loss 26.760323 loss_att 12.042384 loss_ctc 61.102180 loss_ctc_origin 46.460426 loss_ctc0 95.266273 lr 0.00077417 rank 0
2022-08-24 17:27:24,643 DEBUG TRAIN Batch 117/2000 loss 46.752728 loss_att 30.600447 loss_ctc 84.441376 loss_ctc_origin 51.054840 loss_ctc0 162.343292 lr 0.00077411 rank 0
2022-08-24 17:27:53,252 DEBUG TRAIN Batch 117/2100 loss 44.591820 loss_att 29.168142 loss_ctc 80.580391 loss_ctc_origin 53.934967 loss_ctc0 142.753052 lr 0.00077406 rank 0
2022-08-24 17:28:20,428 DEBUG TRAIN Batch 117/2200 loss 18.885603 loss_att 10.259184 loss_ctc 39.013916 loss_ctc_origin 29.373798 loss_ctc0 61.507530 lr 0.00077400 rank 0
2022-08-24 17:28:48,640 DEBUG TRAIN Batch 117/2300 loss 23.086136 loss_att 10.547769 loss_ctc 52.342323 loss_ctc_origin 38.713638 loss_ctc0 84.142586 lr 0.00077394 rank 0
2022-08-24 17:29:17,636 DEBUG TRAIN Batch 117/2400 loss 24.881689 loss_att 11.548449 loss_ctc 55.992580 loss_ctc_origin 40.413189 loss_ctc0 92.344490 lr 0.00077388 rank 0
2022-08-24 17:29:46,637 DEBUG TRAIN Batch 117/2500 loss 48.585369 loss_att 32.374939 loss_ctc 86.409706 loss_ctc_origin 57.133606 loss_ctc0 154.720612 lr 0.00077382 rank 0
2022-08-24 17:29:47,324 WARNING NaN or Inf found in input tensor.
2022-08-24 17:30:15,387 DEBUG TRAIN Batch 117/2600 loss 51.498669 loss_att 27.592953 loss_ctc 107.278671 loss_ctc_origin 60.947426 loss_ctc0 215.384918 lr 0.00077377 rank 0
2022-08-24 17:30:43,668 DEBUG TRAIN Batch 117/2700 loss 23.248779 loss_att 14.726162 loss_ctc 43.134880 loss_ctc_origin 33.124664 loss_ctc0 66.492043 lr 0.00077371 rank 0
2022-08-24 17:31:11,930 DEBUG TRAIN Batch 117/2800 loss 23.776060 loss_att 10.857994 loss_ctc 53.918213 loss_ctc_origin 40.543133 loss_ctc0 85.126732 lr 0.00077365 rank 0
2022-08-24 17:31:39,743 DEBUG TRAIN Batch 117/2900 loss 26.670622 loss_att 12.463584 loss_ctc 59.820377 loss_ctc_origin 42.664749 loss_ctc0 99.850174 lr 0.00077359 rank 0
2022-08-24 17:32:15,315 DEBUG TRAIN Batch 117/3000 loss 40.693684 loss_att 24.507980 loss_ctc 78.460320 loss_ctc_origin 48.557533 loss_ctc0 148.233490 lr 0.00077353 rank 0
2022-08-24 17:32:44,036 DEBUG TRAIN Batch 117/3100 loss 41.043915 loss_att 23.505417 loss_ctc 81.967072 loss_ctc_origin 54.387970 loss_ctc0 146.318298 lr 0.00077348 rank 0
2022-08-24 17:33:12,359 DEBUG TRAIN Batch 117/3200 loss 24.745558 loss_att 14.790710 loss_ctc 47.973534 loss_ctc_origin 36.791847 loss_ctc0 74.064133 lr 0.00077342 rank 0
2022-08-24 17:33:40,994 DEBUG TRAIN Batch 117/3300 loss 20.379101 loss_att 9.043245 loss_ctc 46.829426 loss_ctc_origin 31.201536 loss_ctc0 83.294495 lr 0.00077336 rank 0
2022-08-24 17:34:08,998 DEBUG TRAIN Batch 117/3400 loss 26.245308 loss_att 12.015944 loss_ctc 59.447151 loss_ctc_origin 41.072861 loss_ctc0 102.320488 lr 0.00077330 rank 0
2022-08-24 17:34:37,395 DEBUG TRAIN Batch 117/3500 loss 50.001488 loss_att 33.024742 loss_ctc 89.613899 loss_ctc_origin 60.556778 loss_ctc0 157.413849 lr 0.00077324 rank 0
2022-08-24 17:35:05,502 DEBUG TRAIN Batch 117/3600 loss 40.225277 loss_att 25.831783 loss_ctc 73.810089 loss_ctc_origin 52.683388 loss_ctc0 123.105705 lr 0.00077319 rank 0
2022-08-24 17:35:34,186 DEBUG TRAIN Batch 117/3700 loss 22.658203 loss_att 12.183205 loss_ctc 47.099869 loss_ctc_origin 35.362053 loss_ctc0 74.488098 lr 0.00077313 rank 0
2022-08-24 17:36:02,321 DEBUG TRAIN Batch 117/3800 loss 19.712265 loss_att 9.406803 loss_ctc 43.758339 loss_ctc_origin 28.678471 loss_ctc0 78.944695 lr 0.00077307 rank 0
2022-08-24 17:36:30,466 DEBUG TRAIN Batch 117/3900 loss 27.721975 loss_att 12.107517 loss_ctc 64.155708 loss_ctc_origin 48.447609 loss_ctc0 100.807945 lr 0.00077301 rank 0
2022-08-24 17:36:33,205 WARNING NaN or Inf found in input tensor.
2022-08-24 17:36:58,129 DEBUG TRAIN Batch 117/4000 loss 44.974506 loss_att 26.962666 loss_ctc 87.002136 loss_ctc_origin 52.988396 loss_ctc0 166.367523 lr 0.00077296 rank 0
2022-08-24 17:37:26,336 DEBUG TRAIN Batch 117/4100 loss 45.019951 loss_att 28.025105 loss_ctc 84.674599 loss_ctc_origin 55.335037 loss_ctc0 153.133575 lr 0.00077290 rank 0
2022-08-24 17:37:53,135 DEBUG TRAIN Batch 117/4200 loss 17.594849 loss_att 9.752337 loss_ctc 35.894035 loss_ctc_origin 24.415266 loss_ctc0 62.677818 lr 0.00077284 rank 0
2022-08-24 17:38:22,745 DEBUG TRAIN Batch 117/4300 loss 22.779392 loss_att 10.738793 loss_ctc 50.874123 loss_ctc_origin 38.011589 loss_ctc0 80.886703 lr 0.00077278 rank 0
2022-08-24 17:38:51,010 DEBUG TRAIN Batch 117/4400 loss 22.770447 loss_att 8.855219 loss_ctc 55.239304 loss_ctc_origin 36.468933 loss_ctc0 99.036835 lr 0.00077273 rank 0
2022-08-24 17:39:23,897 DEBUG TRAIN Batch 117/4500 loss 46.661278 loss_att 32.478115 loss_ctc 79.755318 loss_ctc_origin 53.480927 loss_ctc0 141.062225 lr 0.00077267 rank 0
2022-08-24 17:39:31,841 WARNING NaN or Inf found in input tensor.
2022-08-24 17:39:51,946 DEBUG TRAIN Batch 117/4600 loss 36.671783 loss_att 24.390005 loss_ctc 65.329254 loss_ctc_origin 46.947739 loss_ctc0 108.219452 lr 0.00077261 rank 0
2022-08-24 17:40:19,837 DEBUG TRAIN Batch 117/4700 loss 20.350601 loss_att 10.998158 loss_ctc 42.172966 loss_ctc_origin 30.877787 loss_ctc0 68.528389 lr 0.00077255 rank 0
2022-08-24 17:40:47,586 DEBUG TRAIN Batch 117/4800 loss 21.084497 loss_att 9.447454 loss_ctc 48.237595 loss_ctc_origin 34.599297 loss_ctc0 80.060287 lr 0.00077249 rank 0
2022-08-24 17:41:14,996 DEBUG TRAIN Batch 117/4900 loss 25.695011 loss_att 11.729351 loss_ctc 58.281548 loss_ctc_origin 42.706657 loss_ctc0 94.622955 lr 0.00077244 rank 0
2022-08-24 17:41:44,693 DEBUG TRAIN Batch 117/5000 loss 53.884575 loss_att 34.732971 loss_ctc 98.571640 loss_ctc_origin 60.133766 loss_ctc0 188.260010 lr 0.00077238 rank 0
2022-08-24 17:42:12,477 DEBUG TRAIN Batch 117/5100 loss 46.476753 loss_att 28.101534 loss_ctc 89.352264 loss_ctc_origin 51.450790 loss_ctc0 177.789032 lr 0.00077232 rank 0
2022-08-24 17:42:40,815 DEBUG TRAIN Batch 117/5200 loss 22.333729 loss_att 13.593590 loss_ctc 42.727390 loss_ctc_origin 32.440258 loss_ctc0 66.730698 lr 0.00077226 rank 0
2022-08-24 17:43:08,977 DEBUG TRAIN Batch 117/5300 loss 23.829136 loss_att 10.358046 loss_ctc 55.261681 loss_ctc_origin 41.555969 loss_ctc0 87.241669 lr 0.00077221 rank 0
2022-08-24 17:43:37,296 DEBUG TRAIN Batch 117/5400 loss 21.443750 loss_att 10.182098 loss_ctc 47.720936 loss_ctc_origin 31.491276 loss_ctc0 85.590141 lr 0.00077215 rank 0
2022-08-24 17:44:06,053 DEBUG TRAIN Batch 117/5500 loss 45.760857 loss_att 31.233833 loss_ctc 79.657242 loss_ctc_origin 55.675354 loss_ctc0 135.614960 lr 0.00077209 rank 0
2022-08-24 17:44:34,896 DEBUG TRAIN Batch 117/5600 loss 59.516479 loss_att 41.557343 loss_ctc 101.421127 loss_ctc_origin 73.314697 loss_ctc0 167.002808 lr 0.00077203 rank 0
2022-08-24 17:44:58,284 DEBUG CV Batch 117/0 loss 13.622457 loss_att 10.553055 loss_ctc 20.784393 loss_ctc_origin 14.763066 loss_ctc0 34.834152 history loss 12.821136 rank 0
2022-08-24 17:45:08,747 DEBUG CV Batch 117/100 loss 23.440998 loss_att 18.662340 loss_ctc 34.591198 loss_ctc_origin 25.052704 loss_ctc0 56.847683 history loss 28.204190 rank 0
2022-08-24 17:45:19,061 DEBUG CV Batch 117/200 loss 26.100952 loss_att 19.673439 loss_ctc 41.098480 loss_ctc_origin 31.689774 loss_ctc0 63.052132 history loss 29.481038 rank 0
2022-08-24 17:45:29,000 DEBUG CV Batch 117/300 loss 24.120861 loss_att 18.531754 loss_ctc 37.162109 loss_ctc_origin 21.912657 loss_ctc0 72.744156 history loss 28.641557 rank 0
2022-08-24 17:45:39,528 DEBUG CV Batch 117/400 loss 40.030655 loss_att 32.555038 loss_ctc 57.473751 loss_ctc_origin 40.124046 loss_ctc0 97.956390 history loss 26.945267 rank 0
2022-08-24 17:45:50,269 DEBUG CV Batch 117/500 loss 17.565952 loss_att 13.165664 loss_ctc 27.833294 loss_ctc_origin 21.276768 loss_ctc0 43.131855 history loss 26.633099 rank 0
2022-08-24 17:46:00,761 DEBUG CV Batch 117/600 loss 20.719513 loss_att 14.155389 loss_ctc 36.035805 loss_ctc_origin 24.399908 loss_ctc0 63.186222 history loss 26.518222 rank 0
2022-08-24 17:46:10,819 DEBUG CV Batch 117/700 loss 20.324684 loss_att 14.118914 loss_ctc 34.804810 loss_ctc_origin 22.089558 loss_ctc0 64.473724 history loss 26.156370 rank 0
2022-08-24 17:46:21,565 DEBUG CV Batch 117/800 loss 23.265217 loss_att 18.375477 loss_ctc 34.674610 loss_ctc_origin 19.393438 loss_ctc0 70.330673 history loss 26.105934 rank 0
2022-08-24 17:46:31,900 INFO Epoch 117 CV info cv_loss 26.154106978853573
2022-08-24 17:46:31,901 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/117.pt
2022-08-24 17:46:32,341 INFO Epoch 118 TRAIN info lr 0.000771985597723999
2022-08-24 17:46:32,344 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 17:46:58,513 DEBUG TRAIN Batch 118/0 loss 57.797485 loss_att 42.028412 loss_ctc 94.591995 loss_ctc_origin 69.327194 loss_ctc0 153.543213 lr 0.00077198 rank 0
2022-08-24 17:47:27,177 DEBUG TRAIN Batch 118/100 loss 53.325050 loss_att 30.832863 loss_ctc 105.806824 loss_ctc_origin 65.571648 loss_ctc0 199.688889 lr 0.00077193 rank 0
2022-08-24 17:47:53,680 WARNING NaN or Inf found in input tensor.
2022-08-24 17:47:55,346 DEBUG TRAIN Batch 118/200 loss 23.804478 loss_att 11.086378 loss_ctc 53.480042 loss_ctc_origin 43.428692 loss_ctc0 76.933182 lr 0.00077187 rank 0
2022-08-24 17:48:23,196 DEBUG TRAIN Batch 118/300 loss 20.590569 loss_att 9.352073 loss_ctc 46.813728 loss_ctc_origin 32.597149 loss_ctc0 79.985741 lr 0.00077181 rank 0
2022-08-24 17:48:52,084 DEBUG TRAIN Batch 118/400 loss 25.629202 loss_att 10.321707 loss_ctc 61.346687 loss_ctc_origin 40.732998 loss_ctc0 109.445290 lr 0.00077175 rank 0
2022-08-24 17:49:21,418 DEBUG TRAIN Batch 118/500 loss 52.622330 loss_att 37.943825 loss_ctc 86.872177 loss_ctc_origin 56.409775 loss_ctc0 157.951111 lr 0.00077170 rank 0
2022-08-24 17:49:49,155 DEBUG TRAIN Batch 118/600 loss 52.971054 loss_att 36.680641 loss_ctc 90.982010 loss_ctc_origin 61.387375 loss_ctc0 160.036163 lr 0.00077164 rank 0
2022-08-24 17:50:17,019 DEBUG TRAIN Batch 118/700 loss 20.636793 loss_att 10.994955 loss_ctc 43.134415 loss_ctc_origin 32.217461 loss_ctc0 68.607300 lr 0.00077158 rank 0
2022-08-24 17:50:45,900 DEBUG TRAIN Batch 118/800 loss 21.548944 loss_att 9.129031 loss_ctc 50.528740 loss_ctc_origin 36.466782 loss_ctc0 83.339966 lr 0.00077152 rank 0
2022-08-24 17:51:14,544 DEBUG TRAIN Batch 118/900 loss 22.678810 loss_att 9.216060 loss_ctc 54.091888 loss_ctc_origin 35.488113 loss_ctc0 97.500702 lr 0.00077147 rank 0
2022-08-24 17:51:43,157 DEBUG TRAIN Batch 118/1000 loss 48.153294 loss_att 32.827621 loss_ctc 83.913193 loss_ctc_origin 57.109642 loss_ctc0 146.454819 lr 0.00077141 rank 0
2022-08-24 17:52:12,429 DEBUG TRAIN Batch 118/1100 loss 59.870983 loss_att 38.905155 loss_ctc 108.791245 loss_ctc_origin 68.851967 loss_ctc0 201.982895 lr 0.00077135 rank 0
2022-08-24 17:52:39,374 DEBUG TRAIN Batch 118/1200 loss 21.272964 loss_att 11.044893 loss_ctc 45.138458 loss_ctc_origin 32.554535 loss_ctc0 74.500938 lr 0.00077129 rank 0
2022-08-24 17:53:07,658 DEBUG TRAIN Batch 118/1300 loss 24.589029 loss_att 11.102679 loss_ctc 56.057175 loss_ctc_origin 43.151009 loss_ctc0 86.171562 lr 0.00077124 rank 0
2022-08-24 17:53:34,961 DEBUG TRAIN Batch 118/1400 loss 25.934759 loss_att 12.760405 loss_ctc 56.674915 loss_ctc_origin 39.692474 loss_ctc0 96.300613 lr 0.00077118 rank 0
2022-08-24 17:54:11,416 DEBUG TRAIN Batch 118/1500 loss 53.682934 loss_att 35.694115 loss_ctc 95.656845 loss_ctc_origin 62.388039 loss_ctc0 173.284058 lr 0.00077112 rank 0
2022-08-24 17:54:40,749 DEBUG TRAIN Batch 118/1600 loss 57.989189 loss_att 33.246681 loss_ctc 115.721710 loss_ctc_origin 74.458321 loss_ctc0 212.002945 lr 0.00077106 rank 0
2022-08-24 17:55:09,013 DEBUG TRAIN Batch 118/1700 loss 20.779505 loss_att 10.839012 loss_ctc 43.973984 loss_ctc_origin 32.814743 loss_ctc0 70.012207 lr 0.00077101 rank 0
2022-08-24 17:55:38,246 DEBUG TRAIN Batch 118/1800 loss 21.257385 loss_att 10.471443 loss_ctc 46.424583 loss_ctc_origin 33.463467 loss_ctc0 76.667183 lr 0.00077095 rank 0
2022-08-24 17:56:07,082 DEBUG TRAIN Batch 118/1900 loss 23.945198 loss_att 10.350176 loss_ctc 55.666916 loss_ctc_origin 39.726624 loss_ctc0 92.860931 lr 0.00077089 rank 0
2022-08-24 17:56:37,480 DEBUG TRAIN Batch 118/2000 loss 50.792583 loss_att 34.336769 loss_ctc 89.189484 loss_ctc_origin 63.825542 loss_ctc0 148.372009 lr 0.00077084 rank 0
2022-08-24 17:57:04,697 DEBUG TRAIN Batch 118/2100 loss 51.895405 loss_att 31.530922 loss_ctc 99.412529 loss_ctc_origin 58.654594 loss_ctc0 194.514374 lr 0.00077078 rank 0
2022-08-24 17:57:33,311 DEBUG TRAIN Batch 118/2200 loss 25.074219 loss_att 15.533921 loss_ctc 47.334915 loss_ctc_origin 36.991348 loss_ctc0 71.469902 lr 0.00077072 rank 0
2022-08-24 17:58:03,459 DEBUG TRAIN Batch 118/2300 loss 21.178461 loss_att 9.196249 loss_ctc 49.136955 loss_ctc_origin 35.990311 loss_ctc0 79.812469 lr 0.00077066 rank 0
2022-08-24 17:58:32,058 DEBUG TRAIN Batch 118/2400 loss 26.597450 loss_att 12.023208 loss_ctc 60.604019 loss_ctc_origin 43.677689 loss_ctc0 100.098793 lr 0.00077061 rank 0
2022-08-24 17:59:01,867 DEBUG TRAIN Batch 118/2500 loss 46.797340 loss_att 27.376850 loss_ctc 92.111809 loss_ctc_origin 54.400902 loss_ctc0 180.103912 lr 0.00077055 rank 0
2022-08-24 17:59:29,064 DEBUG TRAIN Batch 118/2600 loss 53.730591 loss_att 30.596672 loss_ctc 107.709732 loss_ctc_origin 57.877754 loss_ctc0 223.984329 lr 0.00077049 rank 0
2022-08-24 17:59:56,888 DEBUG TRAIN Batch 118/2700 loss 19.471594 loss_att 10.697748 loss_ctc 39.943897 loss_ctc_origin 29.026747 loss_ctc0 65.417252 lr 0.00077044 rank 0
2022-08-24 18:00:25,940 DEBUG TRAIN Batch 118/2800 loss 20.672632 loss_att 9.457256 loss_ctc 46.841843 loss_ctc_origin 32.237064 loss_ctc0 80.919662 lr 0.00077038 rank 0
2022-08-24 18:00:54,387 DEBUG TRAIN Batch 118/2900 loss 23.484150 loss_att 11.218498 loss_ctc 52.104004 loss_ctc_origin 36.306721 loss_ctc0 88.964340 lr 0.00077032 rank 0
2022-08-24 18:01:28,547 DEBUG TRAIN Batch 118/3000 loss 50.796009 loss_att 32.521759 loss_ctc 93.435928 loss_ctc_origin 56.907104 loss_ctc0 178.669830 lr 0.00077026 rank 0
2022-08-24 18:01:57,156 DEBUG TRAIN Batch 118/3100 loss 60.760670 loss_att 36.812542 loss_ctc 116.639633 loss_ctc_origin 67.797859 loss_ctc0 230.603745 lr 0.00077021 rank 0
2022-08-24 18:02:25,559 DEBUG TRAIN Batch 118/3200 loss 19.422430 loss_att 9.925411 loss_ctc 41.582138 loss_ctc_origin 30.138870 loss_ctc0 68.283096 lr 0.00077015 rank 0
2022-08-24 18:02:53,554 DEBUG TRAIN Batch 118/3300 loss 22.107872 loss_att 9.906825 loss_ctc 50.576984 loss_ctc_origin 39.834011 loss_ctc0 75.643921 lr 0.00077009 rank 0
2022-08-24 18:03:22,108 DEBUG TRAIN Batch 118/3400 loss 25.682653 loss_att 11.462057 loss_ctc 58.864044 loss_ctc_origin 41.846729 loss_ctc0 98.571106 lr 0.00077004 rank 0
2022-08-24 18:03:51,427 DEBUG TRAIN Batch 118/3500 loss 46.013695 loss_att 29.865635 loss_ctc 83.692497 loss_ctc_origin 51.401974 loss_ctc0 159.037048 lr 0.00076998 rank 0
2022-08-24 18:03:52,173 WARNING NaN or Inf found in input tensor.
2022-08-24 18:04:20,020 WARNING NaN or Inf found in input tensor.
2022-08-24 18:04:20,064 DEBUG TRAIN Batch 118/3600 loss nan loss_att 35.971184 loss_ctc nan loss_ctc_origin 63.192486 loss_ctc0 nan lr 0.00076992 rank 0
2022-08-24 18:04:48,736 DEBUG TRAIN Batch 118/3700 loss 21.272655 loss_att 12.556454 loss_ctc 41.610458 loss_ctc_origin 29.229614 loss_ctc0 70.499084 lr 0.00076986 rank 0
2022-08-24 18:05:16,240 DEBUG TRAIN Batch 118/3800 loss 20.658049 loss_att 9.579622 loss_ctc 46.507706 loss_ctc_origin 33.633926 loss_ctc0 76.546524 lr 0.00076981 rank 0
2022-08-24 18:05:46,219 DEBUG TRAIN Batch 118/3900 loss 26.972878 loss_att 13.097822 loss_ctc 59.348000 loss_ctc_origin 41.580120 loss_ctc0 100.806381 lr 0.00076975 rank 0
2022-08-24 18:05:48,188 WARNING NaN or Inf found in input tensor.
2022-08-24 18:06:15,445 DEBUG TRAIN Batch 118/4000 loss 47.204399 loss_att 31.572008 loss_ctc 83.679977 loss_ctc_origin 54.517448 loss_ctc0 151.725861 lr 0.00076969 rank 0
2022-08-24 18:06:43,920 DEBUG TRAIN Batch 118/4100 loss 65.349197 loss_att 39.021210 loss_ctc 126.781174 loss_ctc_origin 77.286758 loss_ctc0 242.268143 lr 0.00076964 rank 0
2022-08-24 18:07:11,510 DEBUG TRAIN Batch 118/4200 loss 19.848654 loss_att 11.244990 loss_ctc 39.923866 loss_ctc_origin 27.657913 loss_ctc0 68.544418 lr 0.00076958 rank 0
2022-08-24 18:07:39,539 DEBUG TRAIN Batch 118/4300 loss 25.163385 loss_att 11.890308 loss_ctc 56.133896 loss_ctc_origin 42.169662 loss_ctc0 88.717102 lr 0.00076952 rank 0
2022-08-24 18:08:03,777 WARNING NaN or Inf found in input tensor.
2022-08-24 18:08:07,991 DEBUG TRAIN Batch 118/4400 loss 22.248882 loss_att 9.684841 loss_ctc 51.564976 loss_ctc_origin 34.565662 loss_ctc0 91.230042 lr 0.00076947 rank 0
2022-08-24 18:08:43,393 DEBUG TRAIN Batch 118/4500 loss 46.213394 loss_att 31.730152 loss_ctc 80.007629 loss_ctc_origin 51.692223 loss_ctc0 146.076920 lr 0.00076941 rank 0
2022-08-24 18:08:51,206 WARNING NaN or Inf found in input tensor.
2022-08-24 18:09:11,577 DEBUG TRAIN Batch 118/4600 loss 51.676971 loss_att 28.358894 loss_ctc 106.085823 loss_ctc_origin 60.255516 loss_ctc0 213.023209 lr 0.00076935 rank 0
2022-08-24 18:09:39,592 DEBUG TRAIN Batch 118/4700 loss 23.224543 loss_att 12.348906 loss_ctc 48.601028 loss_ctc_origin 37.708431 loss_ctc0 74.017090 lr 0.00076929 rank 0
2022-08-24 18:10:08,296 DEBUG TRAIN Batch 118/4800 loss 23.141689 loss_att 10.135460 loss_ctc 53.489555 loss_ctc_origin 40.822029 loss_ctc0 83.047119 lr 0.00076924 rank 0
2022-08-24 18:10:36,329 DEBUG TRAIN Batch 118/4900 loss 24.584831 loss_att 11.571267 loss_ctc 54.949810 loss_ctc_origin 38.723251 loss_ctc0 92.811775 lr 0.00076918 rank 0
2022-08-24 18:11:05,615 DEBUG TRAIN Batch 118/5000 loss 50.757683 loss_att 29.736908 loss_ctc 99.806152 loss_ctc_origin 63.912674 loss_ctc0 183.557587 lr 0.00076912 rank 0
2022-08-24 18:11:34,377 DEBUG TRAIN Batch 118/5100 loss 50.920296 loss_att 30.413475 loss_ctc 98.769547 loss_ctc_origin 60.378166 loss_ctc0 188.349442 lr 0.00076907 rank 0
2022-08-24 18:12:02,691 DEBUG TRAIN Batch 118/5200 loss 22.696301 loss_att 14.516619 loss_ctc 41.782227 loss_ctc_origin 34.076653 loss_ctc0 59.761890 lr 0.00076901 rank 0
2022-08-24 18:12:32,175 DEBUG TRAIN Batch 118/5300 loss 21.169561 loss_att 9.336321 loss_ctc 48.780457 loss_ctc_origin 34.428699 loss_ctc0 82.267883 lr 0.00076895 rank 0
2022-08-24 18:12:35,175 WARNING NaN or Inf found in input tensor.
2022-08-24 18:13:00,816 DEBUG TRAIN Batch 118/5400 loss 23.429298 loss_att 10.469755 loss_ctc 53.668228 loss_ctc_origin 35.795555 loss_ctc0 95.371124 lr 0.00076890 rank 0
2022-08-24 18:13:29,743 DEBUG TRAIN Batch 118/5500 loss 52.773216 loss_att 34.605343 loss_ctc 95.164917 loss_ctc_origin 59.856613 loss_ctc0 177.550964 lr 0.00076884 rank 0
2022-08-24 18:13:58,441 DEBUG TRAIN Batch 118/5600 loss 53.537781 loss_att 28.676750 loss_ctc 111.546860 loss_ctc_origin 63.439735 loss_ctc0 223.796814 lr 0.00076878 rank 0
2022-08-24 18:14:21,754 DEBUG CV Batch 118/0 loss 14.516197 loss_att 11.170924 loss_ctc 22.321835 loss_ctc_origin 17.012409 loss_ctc0 34.710487 history loss 13.662303 rank 0
2022-08-24 18:14:32,763 DEBUG CV Batch 118/100 loss 21.741810 loss_att 16.984194 loss_ctc 32.842918 loss_ctc_origin 23.608582 loss_ctc0 54.389702 history loss 27.722585 rank 0
2022-08-24 18:14:42,904 DEBUG CV Batch 118/200 loss 25.211926 loss_att 19.160969 loss_ctc 39.330826 loss_ctc_origin 29.538322 loss_ctc0 62.180008 history loss 29.148487 rank 0
2022-08-24 18:14:53,390 DEBUG CV Batch 118/300 loss 24.451084 loss_att 18.417467 loss_ctc 38.529526 loss_ctc_origin 23.521593 loss_ctc0 73.548027 history loss 28.202827 rank 0
2022-08-24 18:15:04,206 DEBUG CV Batch 118/400 loss 39.682968 loss_att 32.309044 loss_ctc 56.888786 loss_ctc_origin 39.853584 loss_ctc0 96.637581 history loss 26.514669 rank 0
2022-08-24 18:15:14,996 DEBUG CV Batch 118/500 loss 17.984707 loss_att 13.511059 loss_ctc 28.423222 loss_ctc_origin 22.036861 loss_ctc0 43.324722 history loss 26.174837 rank 0
2022-08-24 18:15:25,687 DEBUG CV Batch 118/600 loss 17.816202 loss_att 12.367323 loss_ctc 30.530254 loss_ctc_origin 19.928230 loss_ctc0 55.268303 history loss 26.033976 rank 0
2022-08-24 18:15:35,834 DEBUG CV Batch 118/700 loss 20.654491 loss_att 14.312606 loss_ctc 35.452229 loss_ctc_origin 22.803768 loss_ctc0 64.965294 history loss 25.675387 rank 0
2022-08-24 18:15:46,294 DEBUG CV Batch 118/800 loss 23.149120 loss_att 17.999825 loss_ctc 35.164143 loss_ctc_origin 20.072926 loss_ctc0 70.376976 history loss 25.645851 rank 0
2022-08-24 18:15:56,766 INFO Epoch 118 CV info cv_loss 25.725832570844744
2022-08-24 18:15:56,766 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/118.pt
2022-08-24 18:15:57,227 INFO Epoch 119 TRAIN info lr 0.0007687351176123538
2022-08-24 18:15:57,230 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 18:16:24,035 DEBUG TRAIN Batch 119/0 loss 50.319168 loss_att 34.386448 loss_ctc 87.495514 loss_ctc_origin 57.484509 loss_ctc0 157.521179 lr 0.00076873 rank 0
2022-08-24 18:16:52,829 DEBUG TRAIN Batch 119/100 loss 50.184689 loss_att 28.328308 loss_ctc 101.182907 loss_ctc_origin 55.037899 loss_ctc0 208.854584 lr 0.00076868 rank 0
2022-08-24 18:17:21,071 DEBUG TRAIN Batch 119/200 loss 22.400494 loss_att 11.832123 loss_ctc 47.060020 loss_ctc_origin 36.579155 loss_ctc0 71.515373 lr 0.00076862 rank 0
2022-08-24 18:17:49,208 DEBUG TRAIN Batch 119/300 loss 22.557362 loss_att 10.391150 loss_ctc 50.945187 loss_ctc_origin 36.360409 loss_ctc0 84.976334 lr 0.00076856 rank 0
2022-08-24 18:18:17,627 DEBUG TRAIN Batch 119/400 loss 28.253651 loss_att 12.966588 loss_ctc 63.923462 loss_ctc_origin 47.240871 loss_ctc0 102.849495 lr 0.00076851 rank 0
2022-08-24 18:18:47,013 DEBUG TRAIN Batch 119/500 loss 52.875053 loss_att 37.697365 loss_ctc 88.289658 loss_ctc_origin 57.608856 loss_ctc0 159.878204 lr 0.00076845 rank 0
2022-08-24 18:19:15,592 DEBUG TRAIN Batch 119/600 loss 54.325672 loss_att 31.356806 loss_ctc 107.919693 loss_ctc_origin 61.684631 loss_ctc0 215.801514 lr 0.00076839 rank 0
2022-08-24 18:19:43,888 DEBUG TRAIN Batch 119/700 loss 19.633532 loss_att 9.097432 loss_ctc 44.217762 loss_ctc_origin 31.961750 loss_ctc0 72.815125 lr 0.00076834 rank 0
2022-08-24 18:20:11,214 DEBUG TRAIN Batch 119/800 loss 19.418997 loss_att 8.906576 loss_ctc 43.947975 loss_ctc_origin 29.259220 loss_ctc0 78.221741 lr 0.00076828 rank 0
2022-08-24 18:20:40,215 DEBUG TRAIN Batch 119/900 loss 24.929962 loss_att 9.895566 loss_ctc 60.010223 loss_ctc_origin 44.918938 loss_ctc0 95.223228 lr 0.00076822 rank 0
2022-08-24 18:21:09,127 DEBUG TRAIN Batch 119/1000 loss 55.132641 loss_att 38.345581 loss_ctc 94.302444 loss_ctc_origin 62.814133 loss_ctc0 167.775177 lr 0.00076817 rank 0
2022-08-24 18:21:09,829 WARNING NaN or Inf found in input tensor.
2022-08-24 18:21:22,422 WARNING NaN or Inf found in input tensor.
2022-08-24 18:21:36,306 DEBUG TRAIN Batch 119/1100 loss 64.599037 loss_att 38.833790 loss_ctc 124.717949 loss_ctc_origin 75.002136 loss_ctc0 240.721512 lr 0.00076811 rank 0
2022-08-24 18:22:05,538 DEBUG TRAIN Batch 119/1200 loss 19.234100 loss_att 9.890417 loss_ctc 41.036030 loss_ctc_origin 29.377819 loss_ctc0 68.238525 lr 0.00076805 rank 0
2022-08-24 18:22:17,508 WARNING NaN or Inf found in input tensor.
2022-08-24 18:22:33,813 DEBUG TRAIN Batch 119/1300 loss 20.604786 loss_att 8.899319 loss_ctc 47.917542 loss_ctc_origin 31.809372 loss_ctc0 85.503265 lr 0.00076800 rank 0
2022-08-24 18:23:01,081 DEBUG TRAIN Batch 119/1400 loss 24.419655 loss_att 11.020868 loss_ctc 55.683487 loss_ctc_origin 39.353142 loss_ctc0 93.787628 lr 0.00076794 rank 0
2022-08-24 18:23:36,558 DEBUG TRAIN Batch 119/1500 loss 59.551445 loss_att 40.698036 loss_ctc 103.542725 loss_ctc_origin 65.423050 loss_ctc0 192.488617 lr 0.00076788 rank 0
2022-08-24 18:24:05,114 DEBUG TRAIN Batch 119/1600 loss 50.567673 loss_att 28.652962 loss_ctc 101.701996 loss_ctc_origin 55.117844 loss_ctc0 210.398346 lr 0.00076783 rank 0
2022-08-24 18:24:33,964 DEBUG TRAIN Batch 119/1700 loss 19.701988 loss_att 9.276216 loss_ctc 44.028786 loss_ctc_origin 31.452312 loss_ctc0 73.373886 lr 0.00076777 rank 0
2022-08-24 18:25:02,456 DEBUG TRAIN Batch 119/1800 loss 21.978970 loss_att 9.640757 loss_ctc 50.768131 loss_ctc_origin 36.369637 loss_ctc0 84.364616 lr 0.00076771 rank 0
2022-08-24 18:25:31,587 DEBUG TRAIN Batch 119/1900 loss 25.962700 loss_att 12.205002 loss_ctc 58.063992 loss_ctc_origin 41.566917 loss_ctc0 96.557159 lr 0.00076766 rank 0
2022-08-24 18:26:00,780 DEBUG TRAIN Batch 119/2000 loss 38.334686 loss_att 23.180185 loss_ctc 73.695183 loss_ctc_origin 47.473385 loss_ctc0 134.879379 lr 0.00076760 rank 0
2022-08-24 18:26:29,345 DEBUG TRAIN Batch 119/2100 loss 63.008793 loss_att 37.362137 loss_ctc 122.850983 loss_ctc_origin 74.113075 loss_ctc0 236.572754 lr 0.00076754 rank 0
2022-08-24 18:26:58,379 DEBUG TRAIN Batch 119/2200 loss 21.174253 loss_att 10.846903 loss_ctc 45.271400 loss_ctc_origin 34.024563 loss_ctc0 71.514023 lr 0.00076749 rank 0
2022-08-24 18:27:26,230 DEBUG TRAIN Batch 119/2300 loss 20.765884 loss_att 9.313793 loss_ctc 47.487427 loss_ctc_origin 34.528328 loss_ctc0 77.725319 lr 0.00076743 rank 0
2022-08-24 18:27:54,406 DEBUG TRAIN Batch 119/2400 loss 23.734411 loss_att 11.337254 loss_ctc 52.661110 loss_ctc_origin 36.282486 loss_ctc0 90.877892 lr 0.00076737 rank 0
2022-08-24 18:28:23,738 DEBUG TRAIN Batch 119/2500 loss 53.394104 loss_att 35.273727 loss_ctc 95.674973 loss_ctc_origin 64.790421 loss_ctc0 167.738922 lr 0.00076732 rank 0
2022-08-24 18:28:53,109 DEBUG TRAIN Batch 119/2600 loss 62.000774 loss_att 37.049217 loss_ctc 120.221069 loss_ctc_origin 72.902969 loss_ctc0 230.629944 lr 0.00076726 rank 0
2022-08-24 18:29:21,982 DEBUG TRAIN Batch 119/2700 loss 19.705723 loss_att 10.823322 loss_ctc 40.431320 loss_ctc_origin 30.864964 loss_ctc0 62.752823 lr 0.00076720 rank 0
2022-08-24 18:29:50,329 DEBUG TRAIN Batch 119/2800 loss 20.031942 loss_att 7.901052 loss_ctc 48.337353 loss_ctc_origin 34.410538 loss_ctc0 80.833252 lr 0.00076715 rank 0
2022-08-24 18:30:19,764 DEBUG TRAIN Batch 119/2900 loss 24.049843 loss_att 10.361880 loss_ctc 55.988426 loss_ctc_origin 38.096916 loss_ctc0 97.735275 lr 0.00076709 rank 0
2022-08-24 18:30:56,145 DEBUG TRAIN Batch 119/3000 loss 42.216751 loss_att 29.015362 loss_ctc 73.019989 loss_ctc_origin 43.937866 loss_ctc0 140.878265 lr 0.00076703 rank 0
2022-08-24 18:31:25,248 DEBUG TRAIN Batch 119/3100 loss 50.395245 loss_att 30.601572 loss_ctc 96.580475 loss_ctc_origin 57.924000 loss_ctc0 186.778915 lr 0.00076698 rank 0
2022-08-24 18:31:53,720 DEBUG TRAIN Batch 119/3200 loss 23.732861 loss_att 13.491152 loss_ctc 47.630180 loss_ctc_origin 36.516350 loss_ctc0 73.562439 lr 0.00076692 rank 0
2022-08-24 18:32:21,993 DEBUG TRAIN Batch 119/3300 loss 23.289474 loss_att 10.450761 loss_ctc 53.246475 loss_ctc_origin 40.747559 loss_ctc0 82.410614 lr 0.00076687 rank 0
2022-08-24 18:32:51,086 DEBUG TRAIN Batch 119/3400 loss 26.469471 loss_att 12.016570 loss_ctc 60.192902 loss_ctc_origin 43.016548 loss_ctc0 100.271065 lr 0.00076681 rank 0
2022-08-24 18:33:19,368 DEBUG TRAIN Batch 119/3500 loss 46.109898 loss_att 30.214457 loss_ctc 83.199257 loss_ctc_origin 53.375679 loss_ctc0 152.787598 lr 0.00076675 rank 0
2022-08-24 18:33:47,352 DEBUG TRAIN Batch 119/3600 loss 53.703484 loss_att 30.166954 loss_ctc 108.622055 loss_ctc_origin 63.218582 loss_ctc0 214.563477 lr 0.00076670 rank 0
2022-08-24 18:34:16,275 DEBUG TRAIN Batch 119/3700 loss 22.786089 loss_att 12.569936 loss_ctc 46.623779 loss_ctc_origin 37.723232 loss_ctc0 67.391724 lr 0.00076664 rank 0
2022-08-24 18:34:44,266 DEBUG TRAIN Batch 119/3800 loss 23.734604 loss_att 11.305983 loss_ctc 52.734718 loss_ctc_origin 41.837692 loss_ctc0 78.161118 lr 0.00076658 rank 0
2022-08-24 18:35:12,740 DEBUG TRAIN Batch 119/3900 loss 26.789082 loss_att 12.366011 loss_ctc 60.442913 loss_ctc_origin 43.227989 loss_ctc0 100.611069 lr 0.00076653 rank 0
2022-08-24 18:35:41,449 DEBUG TRAIN Batch 119/4000 loss 43.258968 loss_att 26.587801 loss_ctc 82.158356 loss_ctc_origin 53.721058 loss_ctc0 148.512054 lr 0.00076647 rank 0
2022-08-24 18:36:10,477 DEBUG TRAIN Batch 119/4100 loss 35.010651 loss_att 21.065338 loss_ctc 67.549713 loss_ctc_origin 38.240494 loss_ctc0 135.937897 lr 0.00076642 rank 0
2022-08-24 18:36:40,136 DEBUG TRAIN Batch 119/4200 loss 20.373192 loss_att 11.526655 loss_ctc 41.015110 loss_ctc_origin 30.573650 loss_ctc0 65.378517 lr 0.00076636 rank 0
2022-08-24 18:37:09,625 DEBUG TRAIN Batch 119/4300 loss 25.076752 loss_att 12.455168 loss_ctc 54.527107 loss_ctc_origin 41.636482 loss_ctc0 84.605225 lr 0.00076630 rank 0
2022-08-24 18:37:27,119 WARNING NaN or Inf found in input tensor.
2022-08-24 18:37:39,332 DEBUG TRAIN Batch 119/4400 loss 25.500496 loss_att 11.897336 loss_ctc 57.241203 loss_ctc_origin 38.464767 loss_ctc0 101.052887 lr 0.00076625 rank 0
2022-08-24 18:38:13,956 DEBUG TRAIN Batch 119/4500 loss 48.945892 loss_att 32.518562 loss_ctc 87.276337 loss_ctc_origin 53.086304 loss_ctc0 167.053085 lr 0.00076619 rank 0
2022-08-24 18:38:28,879 WARNING NaN or Inf found in input tensor.
2022-08-24 18:38:43,154 DEBUG TRAIN Batch 119/4600 loss 53.704205 loss_att 28.688377 loss_ctc 112.074471 loss_ctc_origin 60.888878 loss_ctc0 231.507507 lr 0.00076613 rank 0
2022-08-24 18:39:10,271 WARNING NaN or Inf found in input tensor.
2022-08-24 18:39:11,903 DEBUG TRAIN Batch 119/4700 loss 21.529898 loss_att 11.524189 loss_ctc 44.876553 loss_ctc_origin 34.305817 loss_ctc0 69.541603 lr 0.00076608 rank 0
2022-08-24 18:39:40,212 DEBUG TRAIN Batch 119/4800 loss 22.434008 loss_att 11.032817 loss_ctc 49.036785 loss_ctc_origin 35.544998 loss_ctc0 80.517616 lr 0.00076602 rank 0
2022-08-24 18:40:09,464 DEBUG TRAIN Batch 119/4900 loss 23.871555 loss_att 10.562749 loss_ctc 54.925430 loss_ctc_origin 36.912319 loss_ctc0 96.956017 lr 0.00076597 rank 0
2022-08-24 18:40:39,416 DEBUG TRAIN Batch 119/5000 loss 40.176491 loss_att 25.571762 loss_ctc 74.254189 loss_ctc_origin 40.724991 loss_ctc0 152.488983 lr 0.00076591 rank 0
2022-08-24 18:40:47,497 WARNING NaN or Inf found in input tensor.
2022-08-24 18:41:01,214 WARNING NaN or Inf found in input tensor.
2022-08-24 18:41:08,562 DEBUG TRAIN Batch 119/5100 loss 59.072006 loss_att 33.946701 loss_ctc 117.697708 loss_ctc_origin 69.068054 loss_ctc0 231.166870 lr 0.00076585 rank 0
2022-08-24 18:41:37,664 DEBUG TRAIN Batch 119/5200 loss 18.411598 loss_att 10.933978 loss_ctc 35.859375 loss_ctc_origin 23.807669 loss_ctc0 63.980015 lr 0.00076580 rank 0
2022-08-24 18:42:06,284 DEBUG TRAIN Batch 119/5300 loss 19.870466 loss_att 9.257722 loss_ctc 44.633537 loss_ctc_origin 30.345970 loss_ctc0 77.971191 lr 0.00076574 rank 0
2022-08-24 18:42:23,385 WARNING NaN or Inf found in input tensor.
2022-08-24 18:42:30,535 WARNING NaN or Inf found in input tensor.
2022-08-24 18:42:35,023 DEBUG TRAIN Batch 119/5400 loss 22.233814 loss_att 9.970223 loss_ctc 50.848862 loss_ctc_origin 35.617817 loss_ctc0 86.387970 lr 0.00076568 rank 0
2022-08-24 18:43:04,896 DEBUG TRAIN Batch 119/5500 loss 50.576622 loss_att 32.336498 loss_ctc 93.136917 loss_ctc_origin 62.008621 loss_ctc0 165.769608 lr 0.00076563 rank 0
2022-08-24 18:43:19,075 WARNING NaN or Inf found in input tensor.
2022-08-24 18:43:34,967 DEBUG TRAIN Batch 119/5600 loss 59.993469 loss_att 34.957123 loss_ctc 118.411606 loss_ctc_origin 69.502731 loss_ctc0 232.532288 lr 0.00076557 rank 0
2022-08-24 18:43:59,223 DEBUG CV Batch 119/0 loss 13.117905 loss_att 9.860390 loss_ctc 20.718773 loss_ctc_origin 14.718241 loss_ctc0 34.720013 history loss 12.346263 rank 0
2022-08-24 18:44:10,251 DEBUG CV Batch 119/100 loss 21.698700 loss_att 17.459110 loss_ctc 31.591072 loss_ctc_origin 21.705948 loss_ctc0 54.656364 history loss 27.937384 rank 0
2022-08-24 18:44:20,354 DEBUG CV Batch 119/200 loss 24.953842 loss_att 19.322750 loss_ctc 38.093056 loss_ctc_origin 27.809969 loss_ctc0 62.086926 history loss 29.245087 rank 0
2022-08-24 18:44:30,472 DEBUG CV Batch 119/300 loss 25.397083 loss_att 19.659374 loss_ctc 38.785076 loss_ctc_origin 23.711493 loss_ctc0 73.956764 history loss 28.302886 rank 0
2022-08-24 18:44:41,520 DEBUG CV Batch 119/400 loss 39.876556 loss_att 32.908813 loss_ctc 56.134628 loss_ctc_origin 38.827770 loss_ctc0 96.517288 history loss 26.668295 rank 0
2022-08-24 18:44:52,258 DEBUG CV Batch 119/500 loss 17.579123 loss_att 13.194499 loss_ctc 27.809910 loss_ctc_origin 21.113867 loss_ctc0 43.434010 history loss 26.378264 rank 0
2022-08-24 18:45:03,056 DEBUG CV Batch 119/600 loss 18.250837 loss_att 12.718275 loss_ctc 31.160151 loss_ctc_origin 20.811876 loss_ctc0 55.306118 history loss 26.190197 rank 0
2022-08-24 18:45:13,192 DEBUG CV Batch 119/700 loss 20.073956 loss_att 13.966659 loss_ctc 34.324310 loss_ctc_origin 20.958189 loss_ctc0 65.511932 history loss 25.822679 rank 0
2022-08-24 18:45:23,549 DEBUG CV Batch 119/800 loss 24.052242 loss_att 19.279625 loss_ctc 35.188351 loss_ctc_origin 19.957296 loss_ctc0 70.727478 history loss 25.798279 rank 0
2022-08-24 18:45:34,005 INFO Epoch 119 CV info cv_loss 25.91454050843295
2022-08-24 18:45:34,005 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/119.pt
2022-08-24 18:45:34,457 INFO Epoch 120 TRAIN info lr 0.0007655253536243755
2022-08-24 18:45:34,460 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 18:46:02,038 DEBUG TRAIN Batch 120/0 loss 44.147255 loss_att 28.594368 loss_ctc 80.437317 loss_ctc_origin 46.892403 loss_ctc0 158.708771 lr 0.00076552 rank 0
2022-08-24 18:46:30,536 DEBUG TRAIN Batch 120/100 loss 54.589340 loss_att 29.288044 loss_ctc 113.625687 loss_ctc_origin 58.593887 loss_ctc0 242.033234 lr 0.00076547 rank 0
2022-08-24 18:46:59,394 DEBUG TRAIN Batch 120/200 loss 21.164524 loss_att 11.856495 loss_ctc 42.883259 loss_ctc_origin 31.773716 loss_ctc0 68.805527 lr 0.00076541 rank 0
2022-08-24 18:47:28,257 DEBUG TRAIN Batch 120/300 loss 20.369452 loss_att 7.964485 loss_ctc 49.314373 loss_ctc_origin 33.992020 loss_ctc0 85.066528 lr 0.00076535 rank 0
2022-08-24 18:47:57,461 DEBUG TRAIN Batch 120/400 loss 25.537821 loss_att 11.501609 loss_ctc 58.288979 loss_ctc_origin 39.887169 loss_ctc0 101.226524 lr 0.00076530 rank 0
2022-08-24 18:48:07,195 WARNING NaN or Inf found in input tensor.
2022-08-24 18:48:26,432 DEBUG TRAIN Batch 120/500 loss 51.967148 loss_att 33.844627 loss_ctc 94.253021 loss_ctc_origin 61.522491 loss_ctc0 170.624268 lr 0.00076524 rank 0
2022-08-24 18:48:55,000 DEBUG TRAIN Batch 120/600 loss 60.147980 loss_att 36.705200 loss_ctc 114.847794 loss_ctc_origin 61.180752 loss_ctc0 240.070892 lr 0.00076519 rank 0
2022-08-24 18:49:22,016 DEBUG TRAIN Batch 120/700 loss 19.086468 loss_att 8.941397 loss_ctc 42.758301 loss_ctc_origin 30.390396 loss_ctc0 71.616745 lr 0.00076513 rank 0
2022-08-24 18:49:52,149 DEBUG TRAIN Batch 120/800 loss 19.651848 loss_att 9.025066 loss_ctc 44.447670 loss_ctc_origin 29.555019 loss_ctc0 79.197182 lr 0.00076507 rank 0
2022-08-24 18:50:09,608 WARNING NaN or Inf found in input tensor.
2022-08-24 18:50:21,286 DEBUG TRAIN Batch 120/900 loss 23.377132 loss_att 11.042211 loss_ctc 52.158611 loss_ctc_origin 36.927757 loss_ctc0 87.697266 lr 0.00076502 rank 0
2022-08-24 18:50:50,898 DEBUG TRAIN Batch 120/1000 loss 50.185440 loss_att 33.036327 loss_ctc 90.200035 loss_ctc_origin 57.282700 loss_ctc0 167.007141 lr 0.00076496 rank 0
2022-08-24 18:51:18,821 DEBUG TRAIN Batch 120/1100 loss 59.179840 loss_att 34.437908 loss_ctc 116.911011 loss_ctc_origin 63.724503 loss_ctc0 241.012833 lr 0.00076491 rank 0
2022-08-24 18:51:45,782 WARNING NaN or Inf found in input tensor.
2022-08-24 18:51:47,395 DEBUG TRAIN Batch 120/1200 loss 21.997070 loss_att 12.523760 loss_ctc 44.101456 loss_ctc_origin 34.253994 loss_ctc0 67.078873 lr 0.00076485 rank 0
2022-08-24 18:52:16,429 DEBUG TRAIN Batch 120/1300 loss 22.618488 loss_att 10.254572 loss_ctc 51.467625 loss_ctc_origin 38.789398 loss_ctc0 81.050148 lr 0.00076480 rank 0
2022-08-24 18:52:45,358 DEBUG TRAIN Batch 120/1400 loss 23.450378 loss_att 11.494479 loss_ctc 51.347481 loss_ctc_origin 33.754848 loss_ctc0 92.396957 lr 0.00076474 rank 0
2022-08-24 18:53:19,835 DEBUG TRAIN Batch 120/1500 loss 46.588272 loss_att 31.140497 loss_ctc 82.633087 loss_ctc_origin 49.382828 loss_ctc0 160.217010 lr 0.00076468 rank 0
2022-08-24 18:53:49,116 DEBUG TRAIN Batch 120/1600 loss 55.269966 loss_att 30.050858 loss_ctc 114.114548 loss_ctc_origin 63.379440 loss_ctc0 232.496445 lr 0.00076463 rank 0
2022-08-24 18:54:17,176 DEBUG TRAIN Batch 120/1700 loss 22.349686 loss_att 11.950269 loss_ctc 46.614990 loss_ctc_origin 35.522335 loss_ctc0 72.497849 lr 0.00076457 rank 0
2022-08-24 18:54:46,217 DEBUG TRAIN Batch 120/1800 loss 18.408421 loss_att 7.913346 loss_ctc 42.896927 loss_ctc_origin 29.125504 loss_ctc0 75.030243 lr 0.00076452 rank 0
2022-08-24 18:55:15,401 DEBUG TRAIN Batch 120/1900 loss 22.388844 loss_att 9.794716 loss_ctc 51.775139 loss_ctc_origin 33.370010 loss_ctc0 94.720444 lr 0.00076446 rank 0
2022-08-24 18:55:45,143 DEBUG TRAIN Batch 120/2000 loss 48.608723 loss_att 34.306381 loss_ctc 81.980850 loss_ctc_origin 55.143566 loss_ctc0 144.601166 lr 0.00076440 rank 0
2022-08-24 18:56:13,596 DEBUG TRAIN Batch 120/2100 loss 58.840496 loss_att 34.705109 loss_ctc 115.156403 loss_ctc_origin 67.790009 loss_ctc0 225.677994 lr 0.00076435 rank 0
2022-08-24 18:56:41,766 WARNING NaN or Inf found in input tensor.
2022-08-24 18:56:43,345 DEBUG TRAIN Batch 120/2200 loss 20.648346 loss_att 10.707277 loss_ctc 43.844173 loss_ctc_origin 32.249352 loss_ctc0 70.898758 lr 0.00076429 rank 0
2022-08-24 18:57:12,622 DEBUG TRAIN Batch 120/2300 loss 22.745853 loss_att 11.323203 loss_ctc 49.398705 loss_ctc_origin 35.882420 loss_ctc0 80.936707 lr 0.00076424 rank 0
2022-08-24 18:57:42,035 DEBUG TRAIN Batch 120/2400 loss 25.936375 loss_att 12.251974 loss_ctc 57.866638 loss_ctc_origin 38.894585 loss_ctc0 102.134750 lr 0.00076418 rank 0
2022-08-24 18:58:10,132 DEBUG TRAIN Batch 120/2500 loss 46.814560 loss_att 31.850191 loss_ctc 81.731415 loss_ctc_origin 47.169788 loss_ctc0 162.375183 lr 0.00076413 rank 0
2022-08-24 18:58:39,501 DEBUG TRAIN Batch 120/2600 loss 48.858967 loss_att 27.384583 loss_ctc 98.965866 loss_ctc_origin 47.330196 loss_ctc0 219.449097 lr 0.00076407 rank 0
2022-08-24 18:59:08,558 DEBUG TRAIN Batch 120/2700 loss 22.484699 loss_att 12.120337 loss_ctc 46.668209 loss_ctc_origin 34.614304 loss_ctc0 74.793983 lr 0.00076401 rank 0
2022-08-24 18:59:36,514 DEBUG TRAIN Batch 120/2800 loss 20.533117 loss_att 9.500526 loss_ctc 46.275826 loss_ctc_origin 31.643148 loss_ctc0 80.418732 lr 0.00076396 rank 0
2022-08-24 19:00:05,101 DEBUG TRAIN Batch 120/2900 loss 24.004047 loss_att 10.632652 loss_ctc 55.203972 loss_ctc_origin 38.034279 loss_ctc0 95.266586 lr 0.00076390 rank 0
2022-08-24 19:00:40,420 DEBUG TRAIN Batch 120/3000 loss 43.101231 loss_att 27.078196 loss_ctc 80.488312 loss_ctc_origin 44.932453 loss_ctc0 163.451965 lr 0.00076385 rank 0
2022-08-24 19:01:10,184 DEBUG TRAIN Batch 120/3100 loss 62.118347 loss_att 35.212929 loss_ctc 124.897644 loss_ctc_origin 79.813240 loss_ctc0 230.094604 lr 0.00076379 rank 0
2022-08-24 19:01:39,035 DEBUG TRAIN Batch 120/3200 loss 22.414419 loss_att 12.220197 loss_ctc 46.200939 loss_ctc_origin 35.626228 loss_ctc0 70.875259 lr 0.00076373 rank 0
2022-08-24 19:01:44,410 WARNING NaN or Inf found in input tensor.
2022-08-24 19:02:08,254 DEBUG TRAIN Batch 120/3300 loss 22.220291 loss_att 10.910622 loss_ctc 48.609516 loss_ctc_origin 33.972172 loss_ctc0 82.763321 lr 0.00076368 rank 0
2022-08-24 19:02:36,727 DEBUG TRAIN Batch 120/3400 loss 21.184353 loss_att 8.631769 loss_ctc 50.473717 loss_ctc_origin 33.852798 loss_ctc0 89.255859 lr 0.00076362 rank 0
2022-08-24 19:03:04,929 DEBUG TRAIN Batch 120/3500 loss 42.312572 loss_att 27.441570 loss_ctc 77.011574 loss_ctc_origin 46.073917 loss_ctc0 149.199432 lr 0.00076357 rank 0
2022-08-24 19:03:33,499 DEBUG TRAIN Batch 120/3600 loss 48.689701 loss_att 27.869680 loss_ctc 97.269745 loss_ctc_origin 54.839153 loss_ctc0 196.274475 lr 0.00076351 rank 0
2022-08-24 19:04:02,190 DEBUG TRAIN Batch 120/3700 loss 22.323963 loss_att 14.142282 loss_ctc 41.414551 loss_ctc_origin 32.004528 loss_ctc0 63.371269 lr 0.00076346 rank 0
2022-08-24 19:04:31,302 DEBUG TRAIN Batch 120/3800 loss 18.271370 loss_att 8.389698 loss_ctc 41.328606 loss_ctc_origin 28.864849 loss_ctc0 70.410698 lr 0.00076340 rank 0
2022-08-24 19:04:58,740 DEBUG TRAIN Batch 120/3900 loss 25.141159 loss_att 11.356170 loss_ctc 57.306129 loss_ctc_origin 39.442551 loss_ctc0 98.987808 lr 0.00076335 rank 0
2022-08-24 19:05:26,113 DEBUG TRAIN Batch 120/4000 loss 51.355145 loss_att 34.406456 loss_ctc 90.902084 loss_ctc_origin 53.739624 loss_ctc0 177.614502 lr 0.00076329 rank 0
2022-08-24 19:05:38,315 WARNING NaN or Inf found in input tensor.
2022-08-24 19:05:52,182 DEBUG TRAIN Batch 120/4100 loss 54.506344 loss_att 29.537985 loss_ctc 112.765839 loss_ctc_origin 61.355690 loss_ctc0 232.722839 lr 0.00076323 rank 0
2022-08-24 19:06:20,105 DEBUG TRAIN Batch 120/4200 loss 22.882828 loss_att 14.106014 loss_ctc 43.362061 loss_ctc_origin 32.551186 loss_ctc0 68.587440 lr 0.00076318 rank 0
2022-08-24 19:06:47,987 DEBUG TRAIN Batch 120/4300 loss 19.439934 loss_att 8.904753 loss_ctc 44.022018 loss_ctc_origin 31.531178 loss_ctc0 73.167320 lr 0.00076312 rank 0
2022-08-24 19:07:16,070 DEBUG TRAIN Batch 120/4400 loss 27.138865 loss_att 12.795244 loss_ctc 60.607307 loss_ctc_origin 43.903011 loss_ctc0 99.583992 lr 0.00076307 rank 0
2022-08-24 19:07:47,000 DEBUG TRAIN Batch 120/4500 loss 45.256348 loss_att 28.579977 loss_ctc 84.167877 loss_ctc_origin 51.717999 loss_ctc0 159.884262 lr 0.00076301 rank 0
2022-08-24 19:08:13,704 DEBUG TRAIN Batch 120/4600 loss 57.993744 loss_att 36.990181 loss_ctc 107.002045 loss_ctc_origin 70.773209 loss_ctc0 191.535995 lr 0.00076296 rank 0
2022-08-24 19:08:41,460 DEBUG TRAIN Batch 120/4700 loss 26.467884 loss_att 14.100735 loss_ctc 55.324566 loss_ctc_origin 46.845272 loss_ctc0 75.109581 lr 0.00076290 rank 0
2022-08-24 19:09:09,723 DEBUG TRAIN Batch 120/4800 loss 21.673611 loss_att 8.951213 loss_ctc 51.359200 loss_ctc_origin 35.063698 loss_ctc0 89.382034 lr 0.00076285 rank 0
2022-08-24 19:09:33,203 WARNING NaN or Inf found in input tensor.
2022-08-24 19:09:37,636 DEBUG TRAIN Batch 120/4900 loss 23.050585 loss_att 10.226706 loss_ctc 52.972969 loss_ctc_origin 37.286884 loss_ctc0 89.573822 lr 0.00076279 rank 0
2022-08-24 19:10:05,970 DEBUG TRAIN Batch 120/5000 loss 51.259338 loss_att 33.232826 loss_ctc 93.321205 loss_ctc_origin 59.951057 loss_ctc0 171.184875 lr 0.00076273 rank 0
2022-08-24 19:10:32,782 DEBUG TRAIN Batch 120/5100 loss 47.068634 loss_att 25.706005 loss_ctc 96.914764 loss_ctc_origin 53.244984 loss_ctc0 198.810913 lr 0.00076268 rank 0
2022-08-24 19:11:00,011 DEBUG TRAIN Batch 120/5200 loss 23.755287 loss_att 12.554371 loss_ctc 49.890755 loss_ctc_origin 39.755913 loss_ctc0 73.538727 lr 0.00076262 rank 0
2022-08-24 19:11:27,123 DEBUG TRAIN Batch 120/5300 loss 19.644640 loss_att 9.543695 loss_ctc 43.213509 loss_ctc_origin 29.701239 loss_ctc0 74.742134 lr 0.00076257 rank 0
2022-08-24 19:11:54,559 DEBUG TRAIN Batch 120/5400 loss 23.304914 loss_att 11.225094 loss_ctc 51.491161 loss_ctc_origin 33.579029 loss_ctc0 93.286133 lr 0.00076251 rank 0
2022-08-24 19:12:20,863 DEBUG TRAIN Batch 120/5500 loss 46.719170 loss_att 30.515036 loss_ctc 84.528816 loss_ctc_origin 55.316650 loss_ctc0 152.690536 lr 0.00076246 rank 0
2022-08-24 19:12:47,392 DEBUG TRAIN Batch 120/5600 loss 54.245415 loss_att 33.872269 loss_ctc 101.782745 loss_ctc_origin 60.368217 loss_ctc0 198.416626 lr 0.00076240 rank 0
2022-08-24 19:13:10,319 DEBUG CV Batch 120/0 loss 12.774330 loss_att 9.589163 loss_ctc 20.206387 loss_ctc_origin 13.926435 loss_ctc0 34.859604 history loss 12.022899 rank 0
2022-08-24 19:13:21,396 DEBUG CV Batch 120/100 loss 22.166565 loss_att 18.075960 loss_ctc 31.711311 loss_ctc_origin 22.048401 loss_ctc0 54.258102 history loss 27.516603 rank 0
2022-08-24 19:13:30,619 DEBUG CV Batch 120/200 loss 26.163189 loss_att 20.347376 loss_ctc 39.733414 loss_ctc_origin 30.178926 loss_ctc0 62.027225 history loss 28.788684 rank 0
2022-08-24 19:13:39,938 DEBUG CV Batch 120/300 loss 23.386230 loss_att 17.832153 loss_ctc 36.345741 loss_ctc_origin 20.986340 loss_ctc0 72.184341 history loss 27.885564 rank 0
2022-08-24 19:13:49,960 DEBUG CV Batch 120/400 loss 39.157265 loss_att 31.945219 loss_ctc 55.985374 loss_ctc_origin 38.658691 loss_ctc0 96.414307 history loss 26.188137 rank 0
2022-08-24 19:13:59,579 DEBUG CV Batch 120/500 loss 17.363098 loss_att 13.227503 loss_ctc 27.012825 loss_ctc_origin 20.119953 loss_ctc0 43.096195 history loss 25.835382 rank 0
2022-08-24 19:14:09,365 DEBUG CV Batch 120/600 loss 17.833294 loss_att 12.269464 loss_ctc 30.815563 loss_ctc_origin 20.548203 loss_ctc0 54.772736 history loss 25.638464 rank 0
2022-08-24 19:14:18,799 DEBUG CV Batch 120/700 loss 19.510529 loss_att 13.452877 loss_ctc 33.645050 loss_ctc_origin 20.490868 loss_ctc0 64.338150 history loss 25.295221 rank 0
2022-08-24 19:14:28,253 DEBUG CV Batch 120/800 loss 23.238804 loss_att 18.647888 loss_ctc 33.950939 loss_ctc_origin 18.633253 loss_ctc0 69.692207 history loss 25.259433 rank 0
2022-08-24 19:14:38,199 INFO Epoch 120 CV info cv_loss 25.380941595877758
2022-08-24 19:14:38,199 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/120.pt
2022-08-24 19:14:38,656 INFO Epoch 121 TRAIN info lr 0.0007623554627676176
2022-08-24 19:14:38,660 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 19:15:06,593 DEBUG TRAIN Batch 121/0 loss 47.782562 loss_att 32.878326 loss_ctc 82.559105 loss_ctc_origin 52.677334 loss_ctc0 152.283234 lr 0.00076235 rank 0
2022-08-24 19:15:35,581 DEBUG TRAIN Batch 121/100 loss 56.847839 loss_att 31.094820 loss_ctc 116.938210 loss_ctc_origin 71.557968 loss_ctc0 222.825424 lr 0.00076230 rank 0
2022-08-24 19:16:04,290 DEBUG TRAIN Batch 121/200 loss 21.962849 loss_att 11.794640 loss_ctc 45.688667 loss_ctc_origin 36.201340 loss_ctc0 67.825768 lr 0.00076224 rank 0
2022-08-24 19:16:09,964 WARNING NaN or Inf found in input tensor.
2022-08-24 19:16:33,394 DEBUG TRAIN Batch 121/300 loss 23.393911 loss_att 10.695402 loss_ctc 53.023766 loss_ctc_origin 40.030098 loss_ctc0 83.342316 lr 0.00076219 rank 0
2022-08-24 19:17:02,029 DEBUG TRAIN Batch 121/400 loss 23.360092 loss_att 9.254948 loss_ctc 56.272091 loss_ctc_origin 38.328674 loss_ctc0 98.140060 lr 0.00076213 rank 0
2022-08-24 19:17:30,953 DEBUG TRAIN Batch 121/500 loss 49.578457 loss_att 32.759041 loss_ctc 88.823761 loss_ctc_origin 62.331188 loss_ctc0 150.639771 lr 0.00076208 rank 0
2022-08-24 19:17:58,448 DEBUG TRAIN Batch 121/600 loss 65.378792 loss_att 42.433823 loss_ctc 118.917038 loss_ctc_origin 77.871689 loss_ctc0 214.689514 lr 0.00076202 rank 0
2022-08-24 19:18:27,119 DEBUG TRAIN Batch 121/700 loss 18.299538 loss_att 9.977989 loss_ctc 37.716484 loss_ctc_origin 27.375223 loss_ctc0 61.846088 lr 0.00076197 rank 0
2022-08-24 19:18:54,869 DEBUG TRAIN Batch 121/800 loss 19.851305 loss_att 8.498320 loss_ctc 46.341606 loss_ctc_origin 32.467953 loss_ctc0 78.713470 lr 0.00076191 rank 0
2022-08-24 19:19:13,110 WARNING NaN or Inf found in input tensor.
2022-08-24 19:19:24,633 DEBUG TRAIN Batch 121/900 loss 23.056717 loss_att 10.787001 loss_ctc 51.686050 loss_ctc_origin 33.812790 loss_ctc0 93.390327 lr 0.00076186 rank 0
2022-08-24 19:19:54,322 DEBUG TRAIN Batch 121/1000 loss 45.028603 loss_att 30.222128 loss_ctc 79.577042 loss_ctc_origin 51.767334 loss_ctc0 144.466354 lr 0.00076180 rank 0
2022-08-24 19:20:22,846 DEBUG TRAIN Batch 121/1100 loss 62.222374 loss_att 37.948235 loss_ctc 118.862022 loss_ctc_origin 75.177361 loss_ctc0 220.792877 lr 0.00076174 rank 0
2022-08-24 19:20:51,304 DEBUG TRAIN Batch 121/1200 loss 21.213720 loss_att 10.443850 loss_ctc 46.343418 loss_ctc_origin 34.196144 loss_ctc0 74.687057 lr 0.00076169 rank 0
2022-08-24 19:21:18,873 DEBUG TRAIN Batch 121/1300 loss 19.150152 loss_att 8.574070 loss_ctc 43.827675 loss_ctc_origin 28.645880 loss_ctc0 79.251862 lr 0.00076163 rank 0
2022-08-24 19:21:47,558 DEBUG TRAIN Batch 121/1400 loss 25.087429 loss_att 11.752975 loss_ctc 56.201153 loss_ctc_origin 37.581474 loss_ctc0 99.647064 lr 0.00076158 rank 0
2022-08-24 19:22:23,850 DEBUG TRAIN Batch 121/1500 loss 49.535042 loss_att 36.164680 loss_ctc 80.732559 loss_ctc_origin 53.377155 loss_ctc0 144.561829 lr 0.00076152 rank 0
2022-08-24 19:22:52,112 DEBUG TRAIN Batch 121/1600 loss 54.023582 loss_att 32.698853 loss_ctc 103.781281 loss_ctc_origin 60.383186 loss_ctc0 205.043488 lr 0.00076147 rank 0
2022-08-24 19:23:19,688 DEBUG TRAIN Batch 121/1700 loss 18.679794 loss_att 10.234249 loss_ctc 38.386063 loss_ctc_origin 27.700821 loss_ctc0 63.318298 lr 0.00076141 rank 0
2022-08-24 19:23:25,143 WARNING NaN or Inf found in input tensor.
2022-08-24 19:23:48,013 DEBUG TRAIN Batch 121/1800 loss 19.898205 loss_att 8.708899 loss_ctc 46.006584 loss_ctc_origin 31.764080 loss_ctc0 79.239090 lr 0.00076136 rank 0
2022-08-24 19:24:15,593 DEBUG TRAIN Batch 121/1900 loss 25.101749 loss_att 11.108066 loss_ctc 57.753677 loss_ctc_origin 41.323212 loss_ctc0 96.091431 lr 0.00076130 rank 0
2022-08-24 19:24:44,981 DEBUG TRAIN Batch 121/2000 loss 47.796936 loss_att 28.671026 loss_ctc 92.424057 loss_ctc_origin 57.375786 loss_ctc0 174.203354 lr 0.00076125 rank 0
2022-08-24 19:25:12,974 DEBUG TRAIN Batch 121/2100 loss 31.544289 loss_att 16.744247 loss_ctc 66.077721 loss_ctc_origin 44.470192 loss_ctc0 116.495285 lr 0.00076119 rank 0
2022-08-24 19:25:41,365 DEBUG TRAIN Batch 121/2200 loss 19.849649 loss_att 8.722325 loss_ctc 45.813404 loss_ctc_origin 34.790726 loss_ctc0 71.532982 lr 0.00076114 rank 0
2022-08-24 19:26:10,907 DEBUG TRAIN Batch 121/2300 loss 19.065178 loss_att 9.266279 loss_ctc 41.929276 loss_ctc_origin 28.883976 loss_ctc0 72.368301 lr 0.00076108 rank 0
2022-08-24 19:26:39,234 DEBUG TRAIN Batch 121/2400 loss 22.229027 loss_att 9.511271 loss_ctc 51.903793 loss_ctc_origin 34.510815 loss_ctc0 92.487411 lr 0.00076103 rank 0
2022-08-24 19:27:08,993 DEBUG TRAIN Batch 121/2500 loss 43.732422 loss_att 32.027084 loss_ctc 71.044876 loss_ctc_origin 44.662331 loss_ctc0 132.604141 lr 0.00076097 rank 0
2022-08-24 19:27:37,394 DEBUG TRAIN Batch 121/2600 loss 44.323563 loss_att 25.681301 loss_ctc 87.822174 loss_ctc_origin 46.790112 loss_ctc0 183.563629 lr 0.00076092 rank 0
2022-08-24 19:28:06,450 DEBUG TRAIN Batch 121/2700 loss 26.884632 loss_att 16.498230 loss_ctc 51.119572 loss_ctc_origin 41.538254 loss_ctc0 73.475983 lr 0.00076086 rank 0
2022-08-24 19:28:35,715 DEBUG TRAIN Batch 121/2800 loss 20.667389 loss_att 9.626064 loss_ctc 46.430473 loss_ctc_origin 31.742847 loss_ctc0 80.701591 lr 0.00076081 rank 0
2022-08-24 19:29:04,347 DEBUG TRAIN Batch 121/2900 loss 21.272316 loss_att 9.121737 loss_ctc 49.623669 loss_ctc_origin 30.786865 loss_ctc0 93.576202 lr 0.00076075 rank 0
2022-08-24 19:29:41,125 DEBUG TRAIN Batch 121/3000 loss 44.774754 loss_att 28.226009 loss_ctc 83.388489 loss_ctc_origin 48.604744 loss_ctc0 164.550568 lr 0.00076070 rank 0
2022-08-24 19:30:09,721 DEBUG TRAIN Batch 121/3100 loss 57.842201 loss_att 35.289665 loss_ctc 110.464790 loss_ctc_origin 55.083588 loss_ctc0 239.687592 lr 0.00076064 rank 0
2022-08-24 19:30:38,467 DEBUG TRAIN Batch 121/3200 loss 21.509756 loss_att 12.067263 loss_ctc 43.542240 loss_ctc_origin 32.652271 loss_ctc0 68.952164 lr 0.00076059 rank 0
2022-08-24 19:31:06,616 DEBUG TRAIN Batch 121/3300 loss 19.606705 loss_att 7.614314 loss_ctc 47.588947 loss_ctc_origin 33.313972 loss_ctc0 80.897217 lr 0.00076053 rank 0
2022-08-24 19:31:35,330 DEBUG TRAIN Batch 121/3400 loss 21.745800 loss_att 10.897476 loss_ctc 47.058552 loss_ctc_origin 29.875748 loss_ctc0 87.151756 lr 0.00076048 rank 0
2022-08-24 19:32:04,456 DEBUG TRAIN Batch 121/3500 loss 42.656143 loss_att 26.631504 loss_ctc 80.046974 loss_ctc_origin 44.685295 loss_ctc0 162.557556 lr 0.00076042 rank 0
2022-08-24 19:32:32,758 DEBUG TRAIN Batch 121/3600 loss 49.780518 loss_att 26.949326 loss_ctc 103.053299 loss_ctc_origin 53.830399 loss_ctc0 217.906738 lr 0.00076037 rank 0
2022-08-24 19:33:02,896 DEBUG TRAIN Batch 121/3700 loss 22.128563 loss_att 11.523832 loss_ctc 46.872929 loss_ctc_origin 35.962376 loss_ctc0 72.330887 lr 0.00076031 rank 0
2022-08-24 19:33:31,578 DEBUG TRAIN Batch 121/3800 loss 24.428543 loss_att 11.941141 loss_ctc 53.565811 loss_ctc_origin 41.557228 loss_ctc0 81.585831 lr 0.00076026 rank 0
2022-08-24 19:33:59,492 DEBUG TRAIN Batch 121/3900 loss 21.233351 loss_att 9.948026 loss_ctc 47.565773 loss_ctc_origin 31.162054 loss_ctc0 85.841103 lr 0.00076020 rank 0
2022-08-24 19:34:29,506 DEBUG TRAIN Batch 121/4000 loss 59.580124 loss_att 44.218987 loss_ctc 95.422775 loss_ctc_origin 63.732445 loss_ctc0 169.366898 lr 0.00076015 rank 0
2022-08-24 19:34:58,676 DEBUG TRAIN Batch 121/4100 loss 63.138161 loss_att 39.997116 loss_ctc 117.133926 loss_ctc_origin 72.959412 loss_ctc0 220.207779 lr 0.00076009 rank 0
2022-08-24 19:35:27,051 DEBUG TRAIN Batch 121/4200 loss 25.709805 loss_att 12.202559 loss_ctc 57.226707 loss_ctc_origin 47.361176 loss_ctc0 80.246292 lr 0.00076004 rank 0
2022-08-24 19:35:56,149 DEBUG TRAIN Batch 121/4300 loss 19.313660 loss_att 9.065344 loss_ctc 43.226395 loss_ctc_origin 27.942640 loss_ctc0 78.888489 lr 0.00075998 rank 0
2022-08-24 19:36:25,094 DEBUG TRAIN Batch 121/4400 loss 25.373039 loss_att 11.184654 loss_ctc 58.479271 loss_ctc_origin 41.470722 loss_ctc0 98.165878 lr 0.00075993 rank 0
2022-08-24 19:37:02,051 DEBUG TRAIN Batch 121/4500 loss 50.630951 loss_att 32.917591 loss_ctc 91.962128 loss_ctc_origin 56.009502 loss_ctc0 175.851593 lr 0.00075987 rank 0
2022-08-24 19:37:02,843 WARNING NaN or Inf found in input tensor.
2022-08-24 19:37:17,185 WARNING NaN or Inf found in input tensor.
2022-08-24 19:37:31,082 DEBUG TRAIN Batch 121/4600 loss 56.982483 loss_att 31.367512 loss_ctc 116.750732 loss_ctc_origin 65.912155 loss_ctc0 235.374084 lr 0.00075982 rank 0
2022-08-24 19:37:58,381 WARNING NaN or Inf found in input tensor.
2022-08-24 19:37:59,933 DEBUG TRAIN Batch 121/4700 loss 22.174164 loss_att 13.971235 loss_ctc 41.314331 loss_ctc_origin 30.756611 loss_ctc0 65.949005 lr 0.00075976 rank 0
2022-08-24 19:38:28,604 DEBUG TRAIN Batch 121/4800 loss 20.267612 loss_att 8.618857 loss_ctc 47.448036 loss_ctc_origin 33.922745 loss_ctc0 79.007050 lr 0.00075971 rank 0
2022-08-24 19:38:57,044 DEBUG TRAIN Batch 121/4900 loss 25.830748 loss_att 11.559118 loss_ctc 59.131210 loss_ctc_origin 42.188293 loss_ctc0 98.664688 lr 0.00075965 rank 0
2022-08-24 19:39:26,816 DEBUG TRAIN Batch 121/5000 loss 46.693638 loss_att 30.819399 loss_ctc 83.733521 loss_ctc_origin 51.559441 loss_ctc0 158.806366 lr 0.00075960 rank 0
2022-08-24 19:39:56,014 DEBUG TRAIN Batch 121/5100 loss 51.740623 loss_att 27.932693 loss_ctc 107.292450 loss_ctc_origin 57.884975 loss_ctc0 222.576569 lr 0.00075954 rank 0
2022-08-24 19:40:26,016 DEBUG TRAIN Batch 121/5200 loss 22.348770 loss_att 13.292046 loss_ctc 43.481121 loss_ctc_origin 33.242275 loss_ctc0 67.371758 lr 0.00075949 rank 0
2022-08-24 19:40:54,002 DEBUG TRAIN Batch 121/5300 loss 18.615213 loss_att 7.624487 loss_ctc 44.260239 loss_ctc_origin 29.910786 loss_ctc0 77.742302 lr 0.00075943 rank 0
2022-08-24 19:41:22,824 DEBUG TRAIN Batch 121/5400 loss 24.607271 loss_att 9.828741 loss_ctc 59.090504 loss_ctc_origin 42.249451 loss_ctc0 98.386292 lr 0.00075938 rank 0
2022-08-24 19:41:51,733 DEBUG TRAIN Batch 121/5500 loss 43.193226 loss_att 26.273155 loss_ctc 82.673386 loss_ctc_origin 51.964180 loss_ctc0 154.328186 lr 0.00075933 rank 0
2022-08-24 19:42:22,582 DEBUG TRAIN Batch 121/5600 loss 60.402481 loss_att 35.051926 loss_ctc 119.553772 loss_ctc_origin 71.438675 loss_ctc0 231.822327 lr 0.00075927 rank 0
2022-08-24 19:42:45,536 DEBUG CV Batch 121/0 loss 13.202200 loss_att 9.976346 loss_ctc 20.729191 loss_ctc_origin 15.065632 loss_ctc0 33.944160 history loss 12.425600 rank 0
2022-08-24 19:42:56,708 DEBUG CV Batch 121/100 loss 21.622820 loss_att 17.232819 loss_ctc 31.866154 loss_ctc_origin 22.404272 loss_ctc0 53.943882 history loss 27.390407 rank 0
2022-08-24 19:43:06,571 DEBUG CV Batch 121/200 loss 25.362099 loss_att 19.399124 loss_ctc 39.275703 loss_ctc_origin 29.141525 loss_ctc0 62.922127 history loss 28.665935 rank 0
2022-08-24 19:43:16,768 DEBUG CV Batch 121/300 loss 23.434258 loss_att 17.794882 loss_ctc 36.592796 loss_ctc_origin 21.050213 loss_ctc0 72.858826 history loss 27.676212 rank 0
2022-08-24 19:43:27,799 DEBUG CV Batch 121/400 loss 39.432129 loss_att 31.859222 loss_ctc 57.102249 loss_ctc_origin 40.442295 loss_ctc0 95.975464 history loss 26.026284 rank 0
2022-08-24 19:43:39,389 DEBUG CV Batch 121/500 loss 17.815773 loss_att 13.542521 loss_ctc 27.786697 loss_ctc_origin 20.985315 loss_ctc0 43.656586 history loss 25.691225 rank 0
2022-08-24 19:43:50,302 DEBUG CV Batch 121/600 loss 17.927322 loss_att 12.534896 loss_ctc 30.509653 loss_ctc_origin 19.701824 loss_ctc0 55.727921 history loss 25.535520 rank 0
2022-08-24 19:44:00,593 DEBUG CV Batch 121/700 loss 19.487766 loss_att 13.422614 loss_ctc 33.639782 loss_ctc_origin 20.528122 loss_ctc0 64.233650 history loss 25.192323 rank 0
2022-08-24 19:44:11,061 DEBUG CV Batch 121/800 loss 23.049992 loss_att 18.167770 loss_ctc 34.441841 loss_ctc_origin 18.995403 loss_ctc0 70.483528 history loss 25.151103 rank 0
2022-08-24 19:44:21,456 INFO Epoch 121 CV info cv_loss 25.264456328738632
2022-08-24 19:44:21,457 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/121.pt
2022-08-24 19:44:21,941 INFO Epoch 122 TRAIN info lr 0.0007592246262838129
2022-08-24 19:44:21,944 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 19:44:49,288 DEBUG TRAIN Batch 122/0 loss 42.773590 loss_att 29.118259 loss_ctc 74.636032 loss_ctc_origin 42.147457 loss_ctc0 150.442719 lr 0.00075922 rank 0
2022-08-24 19:45:19,235 DEBUG TRAIN Batch 122/100 loss 54.878471 loss_att 31.642323 loss_ctc 109.096146 loss_ctc_origin 64.211952 loss_ctc0 213.825928 lr 0.00075917 rank 0
2022-08-24 19:45:48,435 DEBUG TRAIN Batch 122/200 loss 22.791874 loss_att 11.810715 loss_ctc 48.414574 loss_ctc_origin 38.417522 loss_ctc0 71.741020 lr 0.00075911 rank 0
2022-08-24 19:46:17,584 DEBUG TRAIN Batch 122/300 loss 22.744190 loss_att 9.509098 loss_ctc 53.626068 loss_ctc_origin 41.301373 loss_ctc0 82.383682 lr 0.00075906 rank 0
2022-08-24 19:46:46,930 DEBUG TRAIN Batch 122/400 loss 22.148502 loss_att 8.189497 loss_ctc 54.719513 loss_ctc_origin 36.089993 loss_ctc0 98.188385 lr 0.00075900 rank 0
2022-08-24 19:47:16,585 DEBUG TRAIN Batch 122/500 loss 51.576084 loss_att 34.882637 loss_ctc 90.527458 loss_ctc_origin 58.764065 loss_ctc0 164.642029 lr 0.00075895 rank 0
2022-08-24 19:47:24,565 WARNING NaN or Inf found in input tensor.
2022-08-24 19:47:43,996 DEBUG TRAIN Batch 122/600 loss 52.990501 loss_att 25.420094 loss_ctc 117.321457 loss_ctc_origin 56.572151 loss_ctc0 259.069824 lr 0.00075889 rank 0
2022-08-24 19:48:12,536 DEBUG TRAIN Batch 122/700 loss 21.278843 loss_att 12.677794 loss_ctc 41.347958 loss_ctc_origin 30.984337 loss_ctc0 65.529739 lr 0.00075884 rank 0
2022-08-24 19:48:42,301 DEBUG TRAIN Batch 122/800 loss 18.629848 loss_att 7.348450 loss_ctc 44.953110 loss_ctc_origin 29.323809 loss_ctc0 81.421478 lr 0.00075879 rank 0
2022-08-24 19:49:10,690 DEBUG TRAIN Batch 122/900 loss 25.439907 loss_att 11.772202 loss_ctc 57.331219 loss_ctc_origin 40.188309 loss_ctc0 97.331345 lr 0.00075873 rank 0
2022-08-24 19:49:39,603 DEBUG TRAIN Batch 122/1000 loss 49.893322 loss_att 33.038372 loss_ctc 89.221535 loss_ctc_origin 57.138344 loss_ctc0 164.082306 lr 0.00075868 rank 0
2022-08-24 19:50:08,556 DEBUG TRAIN Batch 122/1100 loss -73328549888.000000 loss_att 35.571342 loss_ctc -244428488704.000000 loss_ctc_origin 65.012695 loss_ctc0 -814761574400.000000 lr 0.00075862 rank 0
2022-08-24 19:50:38,422 DEBUG TRAIN Batch 122/1200 loss 20.322044 loss_att 11.273064 loss_ctc 41.436329 loss_ctc_origin 30.485323 loss_ctc0 66.988678 lr 0.00075857 rank 0
2022-08-24 19:50:51,084 WARNING NaN or Inf found in input tensor.
2022-08-24 19:51:08,241 DEBUG TRAIN Batch 122/1300 loss 23.933290 loss_att 10.397627 loss_ctc 55.516502 loss_ctc_origin 41.588898 loss_ctc0 88.014236 lr 0.00075851 rank 0
2022-08-24 19:51:32,446 WARNING NaN or Inf found in input tensor.
2022-08-24 19:51:36,723 DEBUG TRAIN Batch 122/1400 loss 24.836788 loss_att 10.766004 loss_ctc 57.668617 loss_ctc_origin 38.802753 loss_ctc0 101.688965 lr 0.00075846 rank 0
2022-08-24 19:52:13,825 DEBUG TRAIN Batch 122/1500 loss 41.255196 loss_att 25.789091 loss_ctc 77.342766 loss_ctc_origin 44.432228 loss_ctc0 154.134003 lr 0.00075840 rank 0
2022-08-24 19:52:42,937 DEBUG TRAIN Batch 122/1600 loss 47.863640 loss_att 24.907034 loss_ctc 101.429047 loss_ctc_origin 53.406315 loss_ctc0 213.482071 lr 0.00075835 rank 0
2022-08-24 19:53:11,085 DEBUG TRAIN Batch 122/1700 loss 22.407564 loss_att 12.736263 loss_ctc 44.973930 loss_ctc_origin 33.845345 loss_ctc0 70.940628 lr 0.00075829 rank 0
2022-08-24 19:53:38,279 DEBUG TRAIN Batch 122/1800 loss 19.464447 loss_att 8.038668 loss_ctc 46.124596 loss_ctc_origin 32.011177 loss_ctc0 79.055908 lr 0.00075824 rank 0
2022-08-24 19:53:48,564 WARNING NaN or Inf found in input tensor.
2022-08-24 19:54:06,016 DEBUG TRAIN Batch 122/1900 loss 19.422062 loss_att 8.003498 loss_ctc 46.065372 loss_ctc_origin 27.633736 loss_ctc0 89.072525 lr 0.00075819 rank 0
2022-08-24 19:54:36,391 DEBUG TRAIN Batch 122/2000 loss 46.666069 loss_att 31.493324 loss_ctc 82.069138 loss_ctc_origin 48.212151 loss_ctc0 161.068756 lr 0.00075813 rank 0
2022-08-24 19:55:03,986 DEBUG TRAIN Batch 122/2100 loss 56.792770 loss_att 30.660503 loss_ctc 117.768051 loss_ctc_origin 64.583679 loss_ctc0 241.864929 lr 0.00075808 rank 0
2022-08-24 19:55:32,704 DEBUG TRAIN Batch 122/2200 loss 22.418634 loss_att 12.327396 loss_ctc 45.964855 loss_ctc_origin 35.827255 loss_ctc0 69.619255 lr 0.00075802 rank 0
2022-08-24 19:56:01,143 DEBUG TRAIN Batch 122/2300 loss 22.888754 loss_att 10.781993 loss_ctc 51.137863 loss_ctc_origin 37.637493 loss_ctc0 82.638718 lr 0.00075797 rank 0
2022-08-24 19:56:29,438 DEBUG TRAIN Batch 122/2400 loss 25.161880 loss_att 10.627083 loss_ctc 59.076408 loss_ctc_origin 42.348434 loss_ctc0 98.108337 lr 0.00075791 rank 0
2022-08-24 19:56:59,332 DEBUG TRAIN Batch 122/2500 loss 47.017654 loss_att 32.711548 loss_ctc 80.398560 loss_ctc_origin 51.012688 loss_ctc0 148.965591 lr 0.00075786 rank 0
2022-08-24 19:57:28,104 DEBUG TRAIN Batch 122/2600 loss 50.890835 loss_att 27.316429 loss_ctc 105.897781 loss_ctc_origin 55.145279 loss_ctc0 224.320282 lr 0.00075780 rank 0
2022-08-24 19:57:56,089 DEBUG TRAIN Batch 122/2700 loss 20.113918 loss_att 11.230055 loss_ctc 40.842934 loss_ctc_origin 31.434427 loss_ctc0 62.796108 lr 0.00075775 rank 0
2022-08-24 19:58:26,367 DEBUG TRAIN Batch 122/2800 loss 22.632364 loss_att 8.593676 loss_ctc 55.389301 loss_ctc_origin 40.606239 loss_ctc0 89.883110 lr 0.00075770 rank 0
2022-08-24 19:58:55,559 DEBUG TRAIN Batch 122/2900 loss 25.555466 loss_att 10.884426 loss_ctc 59.787888 loss_ctc_origin 41.284958 loss_ctc0 102.961395 lr 0.00075764 rank 0
2022-08-24 19:59:30,217 DEBUG TRAIN Batch 122/3000 loss 48.537189 loss_att 33.866470 loss_ctc 82.768860 loss_ctc_origin 51.689903 loss_ctc0 155.286438 lr 0.00075759 rank 0
2022-08-24 20:00:00,165 DEBUG TRAIN Batch 122/3100 loss 60.604019 loss_att 36.434837 loss_ctc 116.998787 loss_ctc_origin 67.189201 loss_ctc0 233.221146 lr 0.00075753 rank 0
2022-08-24 20:00:29,814 DEBUG TRAIN Batch 122/3200 loss 21.617119 loss_att 11.655733 loss_ctc 44.860352 loss_ctc_origin 34.427040 loss_ctc0 69.204742 lr 0.00075748 rank 0
2022-08-24 20:00:59,050 DEBUG TRAIN Batch 122/3300 loss 21.972076 loss_att 9.126986 loss_ctc 51.943954 loss_ctc_origin 37.954193 loss_ctc0 84.586731 lr 0.00075742 rank 0
2022-08-24 20:01:28,028 DEBUG TRAIN Batch 122/3400 loss 24.340147 loss_att 11.042011 loss_ctc 55.369125 loss_ctc_origin 38.964622 loss_ctc0 93.646294 lr 0.00075737 rank 0
2022-08-24 20:01:58,070 DEBUG TRAIN Batch 122/3500 loss 44.472370 loss_att 26.740261 loss_ctc 85.847290 loss_ctc_origin 46.468239 loss_ctc0 177.731720 lr 0.00075732 rank 0
2022-08-24 20:02:26,187 DEBUG TRAIN Batch 122/3600 loss 50.795494 loss_att 27.707851 loss_ctc 104.666656 loss_ctc_origin 55.596096 loss_ctc0 219.164612 lr 0.00075726 rank 0
2022-08-24 20:02:53,368 WARNING NaN or Inf found in input tensor.
2022-08-24 20:02:54,868 DEBUG TRAIN Batch 122/3700 loss 21.933399 loss_att 13.841412 loss_ctc 40.814705 loss_ctc_origin 31.054602 loss_ctc0 63.588272 lr 0.00075721 rank 0
2022-08-24 20:03:23,277 DEBUG TRAIN Batch 122/3800 loss 23.482479 loss_att 11.139345 loss_ctc 52.283123 loss_ctc_origin 37.616188 loss_ctc0 86.505966 lr 0.00075715 rank 0
2022-08-24 20:03:52,191 DEBUG TRAIN Batch 122/3900 loss 22.952011 loss_att 10.240519 loss_ctc 52.612160 loss_ctc_origin 34.024467 loss_ctc0 95.983429 lr 0.00075710 rank 0
2022-08-24 20:04:21,749 DEBUG TRAIN Batch 122/4000 loss 47.078373 loss_att 32.039639 loss_ctc 82.168755 loss_ctc_origin 50.852650 loss_ctc0 155.239655 lr 0.00075704 rank 0
2022-08-24 20:04:36,751 WARNING NaN or Inf found in input tensor.
2022-08-24 20:04:50,995 DEBUG TRAIN Batch 122/4100 loss 54.371696 loss_att 33.528519 loss_ctc 103.005783 loss_ctc_origin 56.497883 loss_ctc0 211.524200 lr 0.00075699 rank 0
2022-08-24 20:05:19,369 DEBUG TRAIN Batch 122/4200 loss 20.718315 loss_att 11.891325 loss_ctc 41.314621 loss_ctc_origin 30.678226 loss_ctc0 66.132866 lr 0.00075694 rank 0
2022-08-24 20:05:48,070 DEBUG TRAIN Batch 122/4300 loss 18.917459 loss_att 8.565351 loss_ctc 43.072380 loss_ctc_origin 29.763281 loss_ctc0 74.126945 lr 0.00075688 rank 0
2022-08-24 20:06:17,448 DEBUG TRAIN Batch 122/4400 loss 24.808191 loss_att 11.611020 loss_ctc 55.601585 loss_ctc_origin 39.435013 loss_ctc0 93.323586 lr 0.00075683 rank 0
2022-08-24 20:06:52,255 DEBUG TRAIN Batch 122/4500 loss 38.365242 loss_att 23.794498 loss_ctc 72.363640 loss_ctc_origin 42.715942 loss_ctc0 141.541595 lr 0.00075677 rank 0
2022-08-24 20:07:21,466 DEBUG TRAIN Batch 122/4600 loss 59.020782 loss_att 36.596199 loss_ctc 111.344803 loss_ctc_origin 65.573692 loss_ctc0 218.144043 lr 0.00075672 rank 0
2022-08-24 20:07:49,909 DEBUG TRAIN Batch 122/4700 loss 22.214401 loss_att 13.875368 loss_ctc 41.672146 loss_ctc_origin 29.915085 loss_ctc0 69.105286 lr 0.00075666 rank 0
2022-08-24 20:07:55,298 WARNING NaN or Inf found in input tensor.
2022-08-24 20:08:19,224 DEBUG TRAIN Batch 122/4800 loss 20.639711 loss_att 8.653610 loss_ctc 48.607277 loss_ctc_origin 34.207554 loss_ctc0 82.206619 lr 0.00075661 rank 0
2022-08-24 20:08:48,081 DEBUG TRAIN Batch 122/4900 loss 22.724602 loss_att 10.457216 loss_ctc 51.348503 loss_ctc_origin 34.319466 loss_ctc0 91.082916 lr 0.00075656 rank 0
2022-08-24 20:09:18,182 DEBUG TRAIN Batch 122/5000 loss 42.969177 loss_att 27.920471 loss_ctc 78.082825 loss_ctc_origin 49.915108 loss_ctc0 143.807495 lr 0.00075650 rank 0
2022-08-24 20:09:47,237 DEBUG TRAIN Batch 122/5100 loss 56.774361 loss_att 34.669746 loss_ctc 108.351791 loss_ctc_origin 61.784000 loss_ctc0 217.009964 lr 0.00075645 rank 0
2022-08-24 20:10:15,186 DEBUG TRAIN Batch 122/5200 loss 22.094654 loss_att 12.265006 loss_ctc 45.030499 loss_ctc_origin 33.801537 loss_ctc0 71.231407 lr 0.00075639 rank 0
2022-08-24 20:10:45,467 DEBUG TRAIN Batch 122/5300 loss 20.409790 loss_att 9.676035 loss_ctc 45.455219 loss_ctc_origin 29.401768 loss_ctc0 82.913269 lr 0.00075634 rank 0
2022-08-24 20:11:09,236 WARNING NaN or Inf found in input tensor.
2022-08-24 20:11:13,585 DEBUG TRAIN Batch 122/5400 loss 22.373766 loss_att 9.296848 loss_ctc 52.886574 loss_ctc_origin 36.954117 loss_ctc0 90.062294 lr 0.00075629 rank 0
2022-08-24 20:11:44,209 DEBUG TRAIN Batch 122/5500 loss 43.517101 loss_att 25.959450 loss_ctc 84.484955 loss_ctc_origin 46.788296 loss_ctc0 172.443817 lr 0.00075623 rank 0
2022-08-24 20:11:56,499 WARNING NaN or Inf found in input tensor.
2022-08-24 20:12:10,665 DEBUG TRAIN Batch 122/5600 loss 54.527531 loss_att 33.500305 loss_ctc 103.591057 loss_ctc_origin 60.153942 loss_ctc0 204.944321 lr 0.00075618 rank 0
2022-08-24 20:12:34,305 DEBUG CV Batch 122/0 loss 13.404107 loss_att 10.218571 loss_ctc 20.837025 loss_ctc_origin 14.891516 loss_ctc0 34.709877 history loss 12.615630 rank 0
2022-08-24 20:12:45,069 DEBUG CV Batch 122/100 loss 21.226948 loss_att 17.247097 loss_ctc 30.513266 loss_ctc_origin 20.631390 loss_ctc0 53.570976 history loss 27.619154 rank 0
2022-08-24 20:12:55,041 DEBUG CV Batch 122/200 loss 25.289427 loss_att 19.949711 loss_ctc 37.748764 loss_ctc_origin 27.394802 loss_ctc0 61.908005 history loss 28.778679 rank 0
2022-08-24 20:13:05,609 DEBUG CV Batch 122/300 loss 23.942982 loss_att 18.172539 loss_ctc 37.407349 loss_ctc_origin 22.466049 loss_ctc0 72.270370 history loss 27.855783 rank 0
2022-08-24 20:13:16,504 DEBUG CV Batch 122/400 loss 39.246399 loss_att 31.281204 loss_ctc 57.831860 loss_ctc_origin 41.140526 loss_ctc0 96.778297 history loss 26.178954 rank 0
2022-08-24 20:13:28,040 DEBUG CV Batch 122/500 loss 17.257431 loss_att 12.912828 loss_ctc 27.394836 loss_ctc_origin 20.815166 loss_ctc0 42.747398 history loss 25.842931 rank 0
2022-08-24 20:13:38,879 DEBUG CV Batch 122/600 loss 17.456707 loss_att 12.092115 loss_ctc 29.974083 loss_ctc_origin 19.288363 loss_ctc0 54.907425 history loss 25.641801 rank 0
2022-08-24 20:13:49,558 DEBUG CV Batch 122/700 loss 19.496841 loss_att 13.518738 loss_ctc 33.445751 loss_ctc_origin 20.130074 loss_ctc0 64.515663 history loss 25.303070 rank 0
2022-08-24 20:14:00,523 DEBUG CV Batch 122/800 loss 22.484879 loss_att 17.546837 loss_ctc 34.006977 loss_ctc_origin 18.736879 loss_ctc0 69.637199 history loss 25.259710 rank 0
2022-08-24 20:14:11,059 INFO Epoch 122 CV info cv_loss 25.3534294086349
2022-08-24 20:14:11,060 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/122.pt
2022-08-24 20:14:11,541 INFO Epoch 123 TRAIN info lr 0.000756132048760439
2022-08-24 20:14:11,544 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 20:14:38,393 DEBUG TRAIN Batch 123/0 loss 52.842377 loss_att 34.329052 loss_ctc 96.040131 loss_ctc_origin 55.353565 loss_ctc0 190.975464 lr 0.00075613 rank 0
2022-08-24 20:15:08,418 DEBUG TRAIN Batch 123/100 loss 48.178478 loss_att 26.034843 loss_ctc 99.846954 loss_ctc_origin 50.796997 loss_ctc0 214.296829 lr 0.00075608 rank 0
2022-08-24 20:15:22,013 WARNING NaN or Inf found in input tensor.
2022-08-24 20:15:38,099 DEBUG TRAIN Batch 123/200 loss 17.818907 loss_att 8.165399 loss_ctc 40.343758 loss_ctc_origin 28.187038 loss_ctc0 68.709442 lr 0.00075602 rank 0
2022-08-24 20:16:06,511 DEBUG TRAIN Batch 123/300 loss 21.958595 loss_att 9.732418 loss_ctc 50.486336 loss_ctc_origin 34.671738 loss_ctc0 87.387070 lr 0.00075597 rank 0
2022-08-24 20:16:35,645 DEBUG TRAIN Batch 123/400 loss 22.563316 loss_att 9.647334 loss_ctc 52.700611 loss_ctc_origin 36.315830 loss_ctc0 90.931763 lr 0.00075591 rank 0
2022-08-24 20:17:03,689 DEBUG TRAIN Batch 123/500 loss 44.091671 loss_att 28.034092 loss_ctc 81.559357 loss_ctc_origin 47.827286 loss_ctc0 160.267532 lr 0.00075586 rank 0
2022-08-24 20:17:31,564 DEBUG TRAIN Batch 123/600 loss 48.512524 loss_att 26.086866 loss_ctc 100.839050 loss_ctc_origin 50.744797 loss_ctc0 217.725616 lr 0.00075581 rank 0
2022-08-24 20:18:00,030 DEBUG TRAIN Batch 123/700 loss 22.887566 loss_att 12.996262 loss_ctc 45.967278 loss_ctc_origin 34.984764 loss_ctc0 71.593140 lr 0.00075575 rank 0
2022-08-24 20:18:27,863 DEBUG TRAIN Batch 123/800 loss 16.351112 loss_att 7.907565 loss_ctc 36.052719 loss_ctc_origin 21.424101 loss_ctc0 70.186157 lr 0.00075570 rank 0
2022-08-24 20:18:58,567 DEBUG TRAIN Batch 123/900 loss 23.775372 loss_att 9.486519 loss_ctc 57.116028 loss_ctc_origin 41.622936 loss_ctc0 93.266571 lr 0.00075564 rank 0
2022-08-24 20:19:26,246 DEBUG TRAIN Batch 123/1000 loss 47.637428 loss_att 32.600861 loss_ctc 82.722748 loss_ctc_origin 55.137177 loss_ctc0 147.089081 lr 0.00075559 rank 0
2022-08-24 20:19:55,299 DEBUG TRAIN Batch 123/1100 loss 42.722672 loss_att 23.583298 loss_ctc 87.381203 loss_ctc_origin 45.359795 loss_ctc0 185.431152 lr 0.00075554 rank 0
2022-08-24 20:20:24,903 DEBUG TRAIN Batch 123/1200 loss 22.784767 loss_att 11.338204 loss_ctc 49.493416 loss_ctc_origin 39.125374 loss_ctc0 73.685516 lr 0.00075548 rank 0
2022-08-24 20:20:53,738 DEBUG TRAIN Batch 123/1300 loss 20.822990 loss_att 9.857143 loss_ctc 46.409966 loss_ctc_origin 32.373966 loss_ctc0 79.160629 lr 0.00075543 rank 0
2022-08-24 20:21:23,317 DEBUG TRAIN Batch 123/1400 loss 24.061295 loss_att 10.733276 loss_ctc 55.159996 loss_ctc_origin 36.787148 loss_ctc0 98.029968 lr 0.00075537 rank 0
2022-08-24 20:21:57,654 DEBUG TRAIN Batch 123/1500 loss 35.491386 loss_att 21.945150 loss_ctc 67.099266 loss_ctc_origin 38.905098 loss_ctc0 132.885666 lr 0.00075532 rank 0
2022-08-24 20:22:26,775 DEBUG TRAIN Batch 123/1600 loss 52.990257 loss_att 30.901461 loss_ctc 104.530777 loss_ctc_origin 65.160355 loss_ctc0 196.395081 lr 0.00075527 rank 0
2022-08-24 20:22:55,628 DEBUG TRAIN Batch 123/1700 loss 18.940216 loss_att 10.079225 loss_ctc 39.615860 loss_ctc_origin 28.042503 loss_ctc0 66.620354 lr 0.00075521 rank 0
2022-08-24 20:23:25,399 DEBUG TRAIN Batch 123/1800 loss 27.475180 loss_att 13.569840 loss_ctc 59.920967 loss_ctc_origin 47.407532 loss_ctc0 89.118988 lr 0.00075516 rank 0
2022-08-24 20:23:54,358 DEBUG TRAIN Batch 123/1900 loss 27.493370 loss_att 12.444777 loss_ctc 62.606750 loss_ctc_origin 46.586208 loss_ctc0 99.988014 lr 0.00075511 rank 0
2022-08-24 20:24:23,698 DEBUG TRAIN Batch 123/2000 loss 40.899315 loss_att 25.308830 loss_ctc 77.277115 loss_ctc_origin 47.467178 loss_ctc0 146.833618 lr 0.00075505 rank 0
2022-08-24 20:24:52,482 DEBUG TRAIN Batch 123/2100 loss 55.325741 loss_att 26.271570 loss_ctc 123.118797 loss_ctc_origin 64.933243 loss_ctc0 258.885071 lr 0.00075500 rank 0
2022-08-24 20:25:21,883 DEBUG TRAIN Batch 123/2200 loss 21.739737 loss_att 12.093536 loss_ctc 44.247536 loss_ctc_origin 31.502815 loss_ctc0 73.985214 lr 0.00075494 rank 0
2022-08-24 20:25:50,943 DEBUG TRAIN Batch 123/2300 loss 17.391256 loss_att 6.977554 loss_ctc 41.689892 loss_ctc_origin 27.230457 loss_ctc0 75.428574 lr 0.00075489 rank 0
2022-08-24 20:26:19,359 DEBUG TRAIN Batch 123/2400 loss 27.936344 loss_att 12.875814 loss_ctc 63.077579 loss_ctc_origin 48.086071 loss_ctc0 98.057770 lr 0.00075484 rank 0
2022-08-24 20:26:48,583 DEBUG TRAIN Batch 123/2500 loss 46.411972 loss_att 29.462557 loss_ctc 85.960602 loss_ctc_origin 53.651527 loss_ctc0 161.348450 lr 0.00075478 rank 0
2022-08-24 20:27:16,653 DEBUG TRAIN Batch 123/2600 loss 54.246914 loss_att 28.410982 loss_ctc 114.530746 loss_ctc_origin 55.813202 loss_ctc0 251.538330 lr 0.00075473 rank 0
2022-08-24 20:27:46,174 DEBUG TRAIN Batch 123/2700 loss 22.003559 loss_att 12.320062 loss_ctc 44.598385 loss_ctc_origin 35.041039 loss_ctc0 66.898857 lr 0.00075468 rank 0
2022-08-24 20:28:14,581 DEBUG TRAIN Batch 123/2800 loss 19.160133 loss_att 7.926657 loss_ctc 45.371574 loss_ctc_origin 31.857721 loss_ctc0 76.903885 lr 0.00075462 rank 0
2022-08-24 20:28:42,814 DEBUG TRAIN Batch 123/2900 loss 27.575293 loss_att 12.343737 loss_ctc 63.115585 loss_ctc_origin 47.108948 loss_ctc0 100.464401 lr 0.00075457 rank 0
2022-08-24 20:29:18,911 DEBUG TRAIN Batch 123/3000 loss 38.964840 loss_att 24.492355 loss_ctc 72.733971 loss_ctc_origin 42.313625 loss_ctc0 143.714767 lr 0.00075451 rank 0
2022-08-24 20:29:48,182 DEBUG TRAIN Batch 123/3100 loss 52.185844 loss_att 30.590385 loss_ctc 102.575256 loss_ctc_origin 55.414200 loss_ctc0 212.617722 lr 0.00075446 rank 0
2022-08-24 20:30:17,467 DEBUG TRAIN Batch 123/3200 loss 23.479307 loss_att 13.766983 loss_ctc 46.141396 loss_ctc_origin 36.493069 loss_ctc0 68.654152 lr 0.00075441 rank 0
2022-08-24 20:30:46,322 DEBUG TRAIN Batch 123/3300 loss 21.932821 loss_att 9.946827 loss_ctc 49.900139 loss_ctc_origin 34.802738 loss_ctc0 85.127411 lr 0.00075435 rank 0
2022-08-24 20:31:15,668 DEBUG TRAIN Batch 123/3400 loss 26.765898 loss_att 12.385932 loss_ctc 60.319149 loss_ctc_origin 42.319565 loss_ctc0 102.318176 lr 0.00075430 rank 0
2022-08-24 20:31:44,991 DEBUG TRAIN Batch 123/3500 loss 41.288048 loss_att 27.139492 loss_ctc 74.301346 loss_ctc_origin 40.906525 loss_ctc0 152.222580 lr 0.00075425 rank 0
2022-08-24 20:32:05,841 WARNING NaN or Inf found in input tensor.
2022-08-24 20:32:12,610 DEBUG TRAIN Batch 123/3600 loss 50.008518 loss_att 28.039740 loss_ctc 101.268997 loss_ctc_origin 55.712143 loss_ctc0 207.568314 lr 0.00075419 rank 0
2022-08-24 20:32:40,133 WARNING NaN or Inf found in input tensor.
2022-08-24 20:32:41,722 DEBUG TRAIN Batch 123/3700 loss 21.405750 loss_att 13.434738 loss_ctc 40.004776 loss_ctc_origin 30.761353 loss_ctc0 61.572762 lr 0.00075414 rank 0
2022-08-24 20:33:09,915 DEBUG TRAIN Batch 123/3800 loss 24.008286 loss_att 11.757949 loss_ctc 52.592403 loss_ctc_origin 39.994041 loss_ctc0 81.988579 lr 0.00075408 rank 0
2022-08-24 20:33:38,051 DEBUG TRAIN Batch 123/3900 loss 23.512405 loss_att 9.748273 loss_ctc 55.628708 loss_ctc_origin 38.431862 loss_ctc0 95.754669 lr 0.00075403 rank 0
2022-08-24 20:34:07,361 DEBUG TRAIN Batch 123/4000 loss 46.073463 loss_att 31.160259 loss_ctc 80.870941 loss_ctc_origin 51.168777 loss_ctc0 150.175980 lr 0.00075398 rank 0
2022-08-24 20:34:35,163 DEBUG TRAIN Batch 123/4100 loss 51.342308 loss_att 29.315880 loss_ctc 102.737305 loss_ctc_origin 55.590946 loss_ctc0 212.745453 lr 0.00075392 rank 0
2022-08-24 20:35:02,733 DEBUG TRAIN Batch 123/4200 loss 23.282227 loss_att 12.469797 loss_ctc 48.511230 loss_ctc_origin 38.442116 loss_ctc0 72.005829 lr 0.00075387 rank 0
2022-08-24 20:35:31,813 DEBUG TRAIN Batch 123/4300 loss 18.065536 loss_att 7.916113 loss_ctc 41.747524 loss_ctc_origin 25.374035 loss_ctc0 79.952332 lr 0.00075382 rank 0
2022-08-24 20:35:49,805 WARNING NaN or Inf found in input tensor.
2022-08-24 20:36:00,625 DEBUG TRAIN Batch 123/4400 loss 25.179440 loss_att 11.562851 loss_ctc 56.951485 loss_ctc_origin 40.624962 loss_ctc0 95.046692 lr 0.00075376 rank 0
2022-08-24 20:36:36,330 DEBUG TRAIN Batch 123/4500 loss 46.302643 loss_att 30.660231 loss_ctc 82.801605 loss_ctc_origin 52.041332 loss_ctc0 154.575562 lr 0.00075371 rank 0
2022-08-24 20:37:04,569 DEBUG TRAIN Batch 123/4600 loss 51.654747 loss_att 28.196236 loss_ctc 106.391281 loss_ctc_origin 53.140331 loss_ctc0 230.643494 lr 0.00075366 rank 0
2022-08-24 20:37:31,945 DEBUG TRAIN Batch 123/4700 loss 26.245773 loss_att 14.134850 loss_ctc 54.504593 loss_ctc_origin 45.490692 loss_ctc0 75.537018 lr 0.00075360 rank 0
2022-08-24 20:38:00,585 DEBUG TRAIN Batch 123/4800 loss 22.139376 loss_att 9.436262 loss_ctc 51.779972 loss_ctc_origin 37.321503 loss_ctc0 85.516396 lr 0.00075355 rank 0
2022-08-24 20:38:25,526 WARNING NaN or Inf found in input tensor.
2022-08-24 20:38:29,918 DEBUG TRAIN Batch 123/4900 loss 23.530949 loss_att 10.501743 loss_ctc 53.932426 loss_ctc_origin 36.635727 loss_ctc0 94.291397 lr 0.00075350 rank 0
2022-08-24 20:38:59,901 DEBUG TRAIN Batch 123/5000 loss 44.055546 loss_att 28.827011 loss_ctc 79.588791 loss_ctc_origin 50.142754 loss_ctc0 148.296204 lr 0.00075344 rank 0
2022-08-24 20:39:28,650 DEBUG TRAIN Batch 123/5100 loss 54.221554 loss_att 31.468714 loss_ctc 107.311508 loss_ctc_origin 59.793709 loss_ctc0 218.186356 lr 0.00075339 rank 0
2022-08-24 20:39:57,977 DEBUG TRAIN Batch 123/5200 loss 19.809885 loss_att 11.083272 loss_ctc 40.171982 loss_ctc_origin 26.995926 loss_ctc0 70.916107 lr 0.00075334 rank 0
2022-08-24 20:40:26,244 DEBUG TRAIN Batch 123/5300 loss 19.278275 loss_att 7.839873 loss_ctc 45.967873 loss_ctc_origin 31.096241 loss_ctc0 80.668350 lr 0.00075328 rank 0
2022-08-24 20:40:50,274 WARNING NaN or Inf found in input tensor.
2022-08-24 20:40:54,431 DEBUG TRAIN Batch 123/5400 loss 25.624439 loss_att 12.631227 loss_ctc 55.941933 loss_ctc_origin 39.807514 loss_ctc0 93.588913 lr 0.00075323 rank 0
2022-08-24 20:41:23,536 DEBUG TRAIN Batch 123/5500 loss 46.992844 loss_att 29.551842 loss_ctc 87.688507 loss_ctc_origin 55.282845 loss_ctc0 163.301727 lr 0.00075318 rank 0
2022-08-24 20:41:51,716 DEBUG TRAIN Batch 123/5600 loss 53.895096 loss_att 32.746849 loss_ctc 103.241005 loss_ctc_origin 54.272079 loss_ctc0 217.501831 lr 0.00075312 rank 0
2022-08-24 20:42:14,506 DEBUG CV Batch 123/0 loss 12.280017 loss_att 9.172656 loss_ctc 19.530525 loss_ctc_origin 13.179453 loss_ctc0 34.349697 history loss 11.557663 rank 0
2022-08-24 20:42:25,725 DEBUG CV Batch 123/100 loss 21.250656 loss_att 16.860207 loss_ctc 31.495037 loss_ctc_origin 21.961882 loss_ctc0 53.739067 history loss 27.031320 rank 0
2022-08-24 20:42:35,548 DEBUG CV Batch 123/200 loss 26.588011 loss_att 20.882637 loss_ctc 39.900551 loss_ctc_origin 30.268925 loss_ctc0 62.374344 history loss 28.542091 rank 0
2022-08-24 20:42:45,537 DEBUG CV Batch 123/300 loss 23.420803 loss_att 17.860952 loss_ctc 36.393787 loss_ctc_origin 20.992111 loss_ctc0 72.331032 history loss 27.628229 rank 0
2022-08-24 20:42:56,473 DEBUG CV Batch 123/400 loss 39.429005 loss_att 31.972607 loss_ctc 56.827263 loss_ctc_origin 39.589851 loss_ctc0 97.047882 history loss 26.036762 rank 0
2022-08-24 20:43:07,427 DEBUG CV Batch 123/500 loss 17.422077 loss_att 13.187197 loss_ctc 27.303467 loss_ctc_origin 20.523592 loss_ctc0 43.123177 history loss 25.745856 rank 0
2022-08-24 20:43:18,340 DEBUG CV Batch 123/600 loss 19.009228 loss_att 13.528211 loss_ctc 31.798265 loss_ctc_origin 21.640734 loss_ctc0 55.499168 history loss 25.570739 rank 0
2022-08-24 20:43:28,504 DEBUG CV Batch 123/700 loss 19.299963 loss_att 13.099396 loss_ctc 33.767952 loss_ctc_origin 20.478039 loss_ctc0 64.777740 history loss 25.209353 rank 0
2022-08-24 20:43:39,465 DEBUG CV Batch 123/800 loss 22.703417 loss_att 17.923264 loss_ctc 33.857105 loss_ctc_origin 18.374409 loss_ctc0 69.983398 history loss 25.156258 rank 0
2022-08-24 20:43:50,013 INFO Epoch 123 CV info cv_loss 25.250485922192432
2022-08-24 20:43:50,013 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/123.pt
2022-08-24 20:43:50,474 INFO Epoch 124 TRAIN info lr 0.0007530769572817684
2022-08-24 20:43:50,478 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 20:44:18,069 DEBUG TRAIN Batch 124/0 loss 38.256592 loss_att 22.899307 loss_ctc 74.090263 loss_ctc_origin 40.028641 loss_ctc0 153.567383 lr 0.00075307 rank 0
2022-08-24 20:44:47,267 DEBUG TRAIN Batch 124/100 loss 50.991600 loss_att 28.760464 loss_ctc 102.864243 loss_ctc_origin 52.567982 loss_ctc0 220.222168 lr 0.00075302 rank 0
2022-08-24 20:45:16,203 DEBUG TRAIN Batch 124/200 loss 20.514929 loss_att 10.751629 loss_ctc 43.295959 loss_ctc_origin 33.523834 loss_ctc0 66.097572 lr 0.00075297 rank 0
2022-08-24 20:45:44,456 DEBUG TRAIN Batch 124/300 loss 23.522850 loss_att 11.004457 loss_ctc 52.732430 loss_ctc_origin 39.469555 loss_ctc0 83.679138 lr 0.00075291 rank 0
2022-08-24 20:46:13,900 DEBUG TRAIN Batch 124/400 loss 23.257889 loss_att 9.788925 loss_ctc 54.685471 loss_ctc_origin 37.978722 loss_ctc0 93.667892 lr 0.00075286 rank 0
2022-08-24 20:46:43,737 DEBUG TRAIN Batch 124/500 loss 50.927292 loss_att 33.994896 loss_ctc 90.436218 loss_ctc_origin 57.193909 loss_ctc0 168.001617 lr 0.00075281 rank 0
2022-08-24 20:47:12,134 DEBUG TRAIN Batch 124/600 loss 47.234238 loss_att 25.993402 loss_ctc 96.796188 loss_ctc_origin 47.612389 loss_ctc0 211.558380 lr 0.00075275 rank 0
2022-08-24 20:47:40,461 DEBUG TRAIN Batch 124/700 loss 20.057783 loss_att 11.173098 loss_ctc 40.788712 loss_ctc_origin 29.959684 loss_ctc0 66.056442 lr 0.00075270 rank 0
2022-08-24 20:48:08,964 DEBUG TRAIN Batch 124/800 loss 20.666348 loss_att 9.050216 loss_ctc 47.770653 loss_ctc_origin 32.166092 loss_ctc0 84.181290 lr 0.00075265 rank 0
2022-08-24 20:48:38,272 DEBUG TRAIN Batch 124/900 loss 21.268879 loss_att 9.577579 loss_ctc 48.548576 loss_ctc_origin 30.785851 loss_ctc0 89.994934 lr 0.00075259 rank 0
2022-08-24 20:48:40,988 WARNING NaN or Inf found in input tensor.
2022-08-24 20:48:54,158 WARNING NaN or Inf found in input tensor.
2022-08-24 20:49:07,174 DEBUG TRAIN Batch 124/1000 loss 38.505905 loss_att 22.481361 loss_ctc 75.896507 loss_ctc_origin 44.836025 loss_ctc0 148.370972 lr 0.00075254 rank 0
2022-08-24 20:49:35,189 DEBUG TRAIN Batch 124/1100 loss 54.802933 loss_att 30.632280 loss_ctc 111.201118 loss_ctc_origin 60.184990 loss_ctc0 230.238739 lr 0.00075249 rank 0
2022-08-24 20:50:03,764 DEBUG TRAIN Batch 124/1200 loss 18.903648 loss_att 10.429565 loss_ctc 38.676506 loss_ctc_origin 28.430237 loss_ctc0 62.584476 lr 0.00075244 rank 0
2022-08-24 20:50:33,268 DEBUG TRAIN Batch 124/1300 loss 20.452135 loss_att 9.820229 loss_ctc 45.259914 loss_ctc_origin 33.642464 loss_ctc0 72.367294 lr 0.00075238 rank 0
2022-08-24 20:51:01,727 DEBUG TRAIN Batch 124/1400 loss 25.148325 loss_att 11.399419 loss_ctc 57.229103 loss_ctc_origin 40.395699 loss_ctc0 96.507042 lr 0.00075233 rank 0
2022-08-24 20:51:36,742 DEBUG TRAIN Batch 124/1500 loss 47.111023 loss_att 34.481224 loss_ctc 76.580559 loss_ctc_origin 50.025661 loss_ctc0 138.541977 lr 0.00075228 rank 0
2022-08-24 20:52:05,189 DEBUG TRAIN Batch 124/1600 loss 43.520222 loss_att 18.873756 loss_ctc 101.028633 loss_ctc_origin 47.557190 loss_ctc0 225.795319 lr 0.00075222 rank 0
2022-08-24 20:52:33,749 DEBUG TRAIN Batch 124/1700 loss 21.092865 loss_att 10.094254 loss_ctc 46.756287 loss_ctc_origin 35.166504 loss_ctc0 73.799103 lr 0.00075217 rank 0
2022-08-24 20:53:02,170 DEBUG TRAIN Batch 124/1800 loss 16.042974 loss_att 6.558002 loss_ctc 38.174576 loss_ctc_origin 23.122166 loss_ctc0 73.296860 lr 0.00075212 rank 0
2022-08-24 20:53:31,419 DEBUG TRAIN Batch 124/1900 loss 23.637951 loss_att 10.633904 loss_ctc 53.980728 loss_ctc_origin 34.064846 loss_ctc0 100.451118 lr 0.00075206 rank 0
2022-08-24 20:54:00,459 DEBUG TRAIN Batch 124/2000 loss 42.097488 loss_att 26.716545 loss_ctc 77.986359 loss_ctc_origin 47.820236 loss_ctc0 148.373962 lr 0.00075201 rank 0
2022-08-24 20:54:29,872 DEBUG TRAIN Batch 124/2100 loss 52.082771 loss_att 29.159063 loss_ctc 105.571426 loss_ctc_origin 56.765816 loss_ctc0 219.451187 lr 0.00075196 rank 0
2022-08-24 20:54:58,244 DEBUG TRAIN Batch 124/2200 loss 18.247444 loss_att 9.268375 loss_ctc 39.198605 loss_ctc_origin 27.595320 loss_ctc0 66.272934 lr 0.00075190 rank 0
2022-08-24 20:55:27,370 DEBUG TRAIN Batch 124/2300 loss 17.079020 loss_att 7.241549 loss_ctc 40.033112 loss_ctc_origin 25.762499 loss_ctc0 73.331207 lr 0.00075185 rank 0
2022-08-24 20:55:57,927 DEBUG TRAIN Batch 124/2400 loss 25.851147 loss_att 11.019741 loss_ctc 60.457764 loss_ctc_origin 43.457199 loss_ctc0 100.125740 lr 0.00075180 rank 0
2022-08-24 20:56:26,167 DEBUG TRAIN Batch 124/2500 loss 44.379280 loss_att 31.042986 loss_ctc 75.497292 loss_ctc_origin 47.796951 loss_ctc0 140.131409 lr 0.00075174 rank 0
2022-08-24 20:56:55,758 DEBUG TRAIN Batch 124/2600 loss 49.063095 loss_att 25.011894 loss_ctc 105.182556 loss_ctc_origin 54.208328 loss_ctc0 224.122437 lr 0.00075169 rank 0
2022-08-24 20:57:24,179 DEBUG TRAIN Batch 124/2700 loss 22.016071 loss_att 13.152739 loss_ctc 42.697182 loss_ctc_origin 32.866009 loss_ctc0 65.636589 lr 0.00075164 rank 0
2022-08-24 20:57:36,503 WARNING NaN or Inf found in input tensor.
2022-08-24 20:57:53,858 DEBUG TRAIN Batch 124/2800 loss 19.053602 loss_att 7.797036 loss_ctc 45.318920 loss_ctc_origin 30.273333 loss_ctc0 80.425293 lr 0.00075158 rank 0
2022-08-24 20:58:23,309 DEBUG TRAIN Batch 124/2900 loss 24.615587 loss_att 10.906030 loss_ctc 56.604553 loss_ctc_origin 36.955330 loss_ctc0 102.452744 lr 0.00075153 rank 0
2022-08-24 20:58:57,254 DEBUG TRAIN Batch 124/3000 loss 45.711376 loss_att 30.522678 loss_ctc 81.151665 loss_ctc_origin 53.985752 loss_ctc0 144.538788 lr 0.00075148 rank 0
2022-08-24 20:59:05,048 WARNING NaN or Inf found in input tensor.
2022-08-24 20:59:26,141 DEBUG TRAIN Batch 124/3100 loss 50.241257 loss_att 28.517853 loss_ctc 100.929199 loss_ctc_origin 55.943367 loss_ctc0 205.896149 lr 0.00075143 rank 0
2022-08-24 20:59:54,851 DEBUG TRAIN Batch 124/3200 loss 21.536182 loss_att 10.529219 loss_ctc 47.219093 loss_ctc_origin 37.997780 loss_ctc0 68.735489 lr 0.00075137 rank 0
2022-08-24 21:00:24,446 DEBUG TRAIN Batch 124/3300 loss 19.293478 loss_att 7.986349 loss_ctc 45.676781 loss_ctc_origin 30.602192 loss_ctc0 80.850815 lr 0.00075132 rank 0
2022-08-24 21:00:53,713 DEBUG TRAIN Batch 124/3400 loss 20.641644 loss_att 8.736759 loss_ctc 48.419708 loss_ctc_origin 32.575432 loss_ctc0 85.389694 lr 0.00075127 rank 0
2022-08-24 21:01:22,198 DEBUG TRAIN Batch 124/3500 loss 46.761597 loss_att 31.195549 loss_ctc 83.082367 loss_ctc_origin 55.319302 loss_ctc0 147.862839 lr 0.00075121 rank 0
2022-08-24 21:01:50,331 DEBUG TRAIN Batch 124/3600 loss 57.443985 loss_att 34.180573 loss_ctc 111.725273 loss_ctc_origin 67.769264 loss_ctc0 214.289291 lr 0.00075116 rank 0
2022-08-24 21:02:19,493 DEBUG TRAIN Batch 124/3700 loss 24.091457 loss_att 12.711164 loss_ctc 50.645477 loss_ctc_origin 40.174286 loss_ctc0 75.078247 lr 0.00075111 rank 0
2022-08-24 21:02:49,352 DEBUG TRAIN Batch 124/3800 loss 21.865723 loss_att 9.722081 loss_ctc 50.200886 loss_ctc_origin 37.035797 loss_ctc0 80.919418 lr 0.00075105 rank 0
2022-08-24 21:03:18,707 DEBUG TRAIN Batch 124/3900 loss 22.466637 loss_att 9.481173 loss_ctc 52.766052 loss_ctc_origin 34.645027 loss_ctc0 95.048447 lr 0.00075100 rank 0
2022-08-24 21:03:47,943 DEBUG TRAIN Batch 124/4000 loss 41.850945 loss_att 25.422451 loss_ctc 80.184097 loss_ctc_origin 54.312714 loss_ctc0 140.550659 lr 0.00075095 rank 0
2022-08-24 21:04:01,732 WARNING NaN or Inf found in input tensor.
2022-08-24 21:04:16,312 DEBUG TRAIN Batch 124/4100 loss 50.062920 loss_att 28.655762 loss_ctc 100.012962 loss_ctc_origin 52.387974 loss_ctc0 211.137924 lr 0.00075090 rank 0
2022-08-24 21:04:44,872 DEBUG TRAIN Batch 124/4200 loss 18.967545 loss_att 9.343935 loss_ctc 41.422630 loss_ctc_origin 30.263603 loss_ctc0 67.460350 lr 0.00075084 rank 0
2022-08-24 21:05:13,393 DEBUG TRAIN Batch 124/4300 loss 17.079258 loss_att 7.505619 loss_ctc 39.417747 loss_ctc_origin 24.953838 loss_ctc0 73.166862 lr 0.00075079 rank 0
2022-08-24 21:05:42,553 DEBUG TRAIN Batch 124/4400 loss 25.079245 loss_att 10.573112 loss_ctc 58.926888 loss_ctc_origin 42.970985 loss_ctc0 96.157318 lr 0.00075074 rank 0
2022-08-24 21:06:17,570 DEBUG TRAIN Batch 124/4500 loss 43.333290 loss_att 29.599127 loss_ctc 75.379662 loss_ctc_origin 51.601318 loss_ctc0 130.862457 lr 0.00075068 rank 0
2022-08-24 21:06:46,164 DEBUG TRAIN Batch 124/4600 loss 54.676079 loss_att 32.955933 loss_ctc 105.356415 loss_ctc_origin 59.532951 loss_ctc0 212.277832 lr 0.00075063 rank 0
2022-08-24 21:07:13,221 WARNING NaN or Inf found in input tensor.
2022-08-24 21:07:14,948 DEBUG TRAIN Batch 124/4700 loss 19.518887 loss_att 11.693199 loss_ctc 37.778824 loss_ctc_origin 27.673384 loss_ctc0 61.358185 lr 0.00075058 rank 0
2022-08-24 21:07:43,918 DEBUG TRAIN Batch 124/4800 loss 21.723709 loss_att 10.374579 loss_ctc 48.205009 loss_ctc_origin 35.881302 loss_ctc0 76.960335 lr 0.00075053 rank 0
2022-08-24 21:08:12,968 DEBUG TRAIN Batch 124/4900 loss 23.420630 loss_att 10.887823 loss_ctc 52.663841 loss_ctc_origin 35.207542 loss_ctc0 93.395203 lr 0.00075047 rank 0
2022-08-24 21:08:43,140 DEBUG TRAIN Batch 124/5000 loss 39.064507 loss_att 24.568125 loss_ctc 72.889389 loss_ctc_origin 43.697411 loss_ctc0 141.003998 lr 0.00075042 rank 0
2022-08-24 21:09:11,611 DEBUG TRAIN Batch 124/5100 loss 47.599930 loss_att 24.572575 loss_ctc 101.330414 loss_ctc_origin 56.954880 loss_ctc0 204.873337 lr 0.00075037 rank 0
2022-08-24 21:09:39,204 DEBUG TRAIN Batch 124/5200 loss 18.120625 loss_att 10.334549 loss_ctc 36.288136 loss_ctc_origin 27.009863 loss_ctc0 57.937435 lr 0.00075031 rank 0
2022-08-24 21:10:07,765 DEBUG TRAIN Batch 124/5300 loss 19.939758 loss_att 9.149405 loss_ctc 45.117249 loss_ctc_origin 30.877054 loss_ctc0 78.344360 lr 0.00075026 rank 0
2022-08-24 21:10:25,629 WARNING NaN or Inf found in input tensor.
2022-08-24 21:10:37,017 DEBUG TRAIN Batch 124/5400 loss 24.156540 loss_att 10.050380 loss_ctc 57.070908 loss_ctc_origin 38.510319 loss_ctc0 100.378952 lr 0.00075021 rank 0
2022-08-24 21:11:06,799 DEBUG TRAIN Batch 124/5500 loss 40.024220 loss_att 26.227468 loss_ctc 72.216637 loss_ctc_origin 43.069839 loss_ctc0 140.225830 lr 0.00075016 rank 0
2022-08-24 21:11:35,343 DEBUG TRAIN Batch 124/5600 loss 45.587929 loss_att 24.827129 loss_ctc 94.029800 loss_ctc_origin 49.094490 loss_ctc0 198.878845 lr 0.00075010 rank 0
2022-08-24 21:11:57,417 DEBUG CV Batch 124/0 loss 13.026276 loss_att 9.861843 loss_ctc 20.409952 loss_ctc_origin 14.569086 loss_ctc0 34.038639 history loss 12.260024 rank 0
2022-08-24 21:12:08,458 DEBUG CV Batch 124/100 loss 20.756886 loss_att 16.318935 loss_ctc 31.112103 loss_ctc_origin 21.564960 loss_ctc0 53.388763 history loss 26.684410 rank 0
2022-08-24 21:12:18,862 DEBUG CV Batch 124/200 loss 25.906202 loss_att 20.012402 loss_ctc 39.658401 loss_ctc_origin 30.339470 loss_ctc0 61.402565 history loss 28.100468 rank 0
2022-08-24 21:12:29,615 DEBUG CV Batch 124/300 loss 22.745718 loss_att 17.220356 loss_ctc 35.638229 loss_ctc_origin 20.315964 loss_ctc0 71.390190 history loss 27.071442 rank 0
2022-08-24 21:12:40,045 DEBUG CV Batch 124/400 loss 38.112282 loss_att 30.781075 loss_ctc 55.218437 loss_ctc_origin 37.920197 loss_ctc0 95.580994 history loss 25.454226 rank 0
2022-08-24 21:12:51,521 DEBUG CV Batch 124/500 loss 16.962635 loss_att 12.580375 loss_ctc 27.187906 loss_ctc_origin 20.654228 loss_ctc0 42.433155 history loss 25.127977 rank 0
2022-08-24 21:13:02,444 DEBUG CV Batch 124/600 loss 17.768597 loss_att 12.633324 loss_ctc 29.750900 loss_ctc_origin 19.125008 loss_ctc0 54.544647 history loss 24.935386 rank 0
2022-08-24 21:13:12,581 DEBUG CV Batch 124/700 loss 19.191460 loss_att 13.144644 loss_ctc 33.300697 loss_ctc_origin 20.170574 loss_ctc0 63.937645 history loss 24.597542 rank 0
2022-08-24 21:13:23,268 DEBUG CV Batch 124/800 loss 22.595726 loss_att 17.702070 loss_ctc 34.014252 loss_ctc_origin 18.867203 loss_ctc0 69.357361 history loss 24.580659 rank 0
2022-08-24 21:13:33,857 INFO Epoch 124 CV info cv_loss 24.686523559979285
2022-08-24 21:13:33,858 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/124.pt
2022-08-24 21:13:34,317 INFO Epoch 125 TRAIN info lr 0.0007500586006173493
2022-08-24 21:13:34,321 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 21:14:01,643 DEBUG TRAIN Batch 125/0 loss 41.967079 loss_att 29.188976 loss_ctc 71.782654 loss_ctc_origin 45.686588 loss_ctc0 132.673462 lr 0.00075006 rank 0
2022-08-24 21:14:30,211 DEBUG TRAIN Batch 125/100 loss 42.055534 loss_att 22.497318 loss_ctc 87.691376 loss_ctc_origin 42.660744 loss_ctc0 192.762848 lr 0.00075000 rank 0
2022-08-24 21:14:58,920 DEBUG TRAIN Batch 125/200 loss 19.698877 loss_att 10.626167 loss_ctc 40.868530 loss_ctc_origin 29.632187 loss_ctc0 67.086670 lr 0.00074995 rank 0
2022-08-24 21:15:26,413 DEBUG TRAIN Batch 125/300 loss 21.045645 loss_att 9.235361 loss_ctc 48.602974 loss_ctc_origin 34.366627 loss_ctc0 81.821121 lr 0.00074990 rank 0
2022-08-24 21:15:49,722 WARNING NaN or Inf found in input tensor.
2022-08-24 21:15:54,094 DEBUG TRAIN Batch 125/400 loss 21.583366 loss_att 8.430309 loss_ctc 52.273830 loss_ctc_origin 32.302948 loss_ctc0 98.872559 lr 0.00074985 rank 0
2022-08-24 21:16:23,741 DEBUG TRAIN Batch 125/500 loss 51.564270 loss_att 34.208908 loss_ctc 92.060120 loss_ctc_origin 56.843658 loss_ctc0 174.231842 lr 0.00074979 rank 0
2022-08-24 21:16:24,463 WARNING NaN or Inf found in input tensor.
2022-08-24 21:16:52,376 DEBUG TRAIN Batch 125/600 loss 49.522217 loss_att 26.140541 loss_ctc 104.079468 loss_ctc_origin 57.375816 loss_ctc0 213.054657 lr 0.00074974 rank 0
2022-08-24 21:17:20,773 DEBUG TRAIN Batch 125/700 loss 19.766396 loss_att 9.638324 loss_ctc 43.398560 loss_ctc_origin 31.243784 loss_ctc0 71.759705 lr 0.00074969 rank 0
2022-08-24 21:17:50,149 DEBUG TRAIN Batch 125/800 loss 18.285122 loss_att 7.900941 loss_ctc 42.514877 loss_ctc_origin 28.197668 loss_ctc0 75.921707 lr 0.00074963 rank 0
2022-08-24 21:18:15,319 WARNING NaN or Inf found in input tensor.
2022-08-24 21:18:19,609 DEBUG TRAIN Batch 125/900 loss 22.622168 loss_att 10.053026 loss_ctc 51.950161 loss_ctc_origin 36.329060 loss_ctc0 88.399391 lr 0.00074958 rank 0
2022-08-24 21:18:49,448 DEBUG TRAIN Batch 125/1000 loss 48.384468 loss_att 33.084427 loss_ctc 84.084557 loss_ctc_origin 54.246052 loss_ctc0 153.707733 lr 0.00074953 rank 0
2022-08-24 21:19:18,174 DEBUG TRAIN Batch 125/1100 loss 45.245956 loss_att 23.666050 loss_ctc 95.599075 loss_ctc_origin 49.211559 loss_ctc0 203.836624 lr 0.00074948 rank 0
2022-08-24 21:19:45,750 DEBUG TRAIN Batch 125/1200 loss 23.584837 loss_att 13.424110 loss_ctc 47.293198 loss_ctc_origin 38.267960 loss_ctc0 68.352081 lr 0.00074942 rank 0
2022-08-24 21:19:57,574 WARNING NaN or Inf found in input tensor.
2022-08-24 21:20:14,186 DEBUG TRAIN Batch 125/1300 loss 19.830620 loss_att 8.117887 loss_ctc 47.160328 loss_ctc_origin 33.324509 loss_ctc0 79.443901 lr 0.00074937 rank 0
2022-08-24 21:20:41,418 DEBUG TRAIN Batch 125/1400 loss 21.207109 loss_att 8.225353 loss_ctc 51.497871 loss_ctc_origin 32.975254 loss_ctc0 94.717316 lr 0.00074932 rank 0
2022-08-24 21:21:16,528 DEBUG TRAIN Batch 125/1500 loss 41.745602 loss_att 27.163671 loss_ctc 75.770103 loss_ctc_origin 48.441093 loss_ctc0 139.537796 lr 0.00074927 rank 0
2022-08-24 21:21:44,852 DEBUG TRAIN Batch 125/1600 loss 53.834801 loss_att 31.103247 loss_ctc 106.875092 loss_ctc_origin 64.026375 loss_ctc0 206.855423 lr 0.00074921 rank 0
2022-08-24 21:22:12,659 DEBUG TRAIN Batch 125/1700 loss 18.547659 loss_att 9.861553 loss_ctc 38.815239 loss_ctc_origin 25.826790 loss_ctc0 69.121620 lr 0.00074916 rank 0
2022-08-24 21:22:39,854 DEBUG TRAIN Batch 125/1800 loss 18.375353 loss_att 7.627937 loss_ctc 43.452652 loss_ctc_origin 28.936451 loss_ctc0 77.323776 lr 0.00074911 rank 0
2022-08-24 21:23:08,331 DEBUG TRAIN Batch 125/1900 loss 22.444614 loss_att 10.133610 loss_ctc 51.170292 loss_ctc_origin 32.363098 loss_ctc0 95.053741 lr 0.00074906 rank 0
2022-08-24 21:23:37,591 DEBUG TRAIN Batch 125/2000 loss 40.447075 loss_att 25.331381 loss_ctc 75.717033 loss_ctc_origin 42.411793 loss_ctc0 153.429260 lr 0.00074900 rank 0
2022-08-24 21:24:04,837 DEBUG TRAIN Batch 125/2100 loss 50.872322 loss_att 26.830708 loss_ctc 106.969421 loss_ctc_origin 56.194214 loss_ctc0 225.444885 lr 0.00074895 rank 0
2022-08-24 21:24:34,340 DEBUG TRAIN Batch 125/2200 loss 22.370600 loss_att 12.995430 loss_ctc 44.245995 loss_ctc_origin 34.727577 loss_ctc0 66.455627 lr 0.00074890 rank 0
2022-08-24 21:25:04,186 DEBUG TRAIN Batch 125/2300 loss 20.146189 loss_att 9.134085 loss_ctc 45.841099 loss_ctc_origin 30.045563 loss_ctc0 82.697350 lr 0.00074885 rank 0
2022-08-24 21:25:31,623 DEBUG TRAIN Batch 125/2400 loss 24.021708 loss_att 11.354374 loss_ctc 53.578819 loss_ctc_origin 36.633198 loss_ctc0 93.118591 lr 0.00074879 rank 0
2022-08-24 21:26:02,610 DEBUG TRAIN Batch 125/2500 loss 40.911926 loss_att 25.309898 loss_ctc 77.316658 loss_ctc_origin 43.203468 loss_ctc0 156.914093 lr 0.00074874 rank 0
2022-08-24 21:26:30,080 DEBUG TRAIN Batch 125/2600 loss 51.139877 loss_att 28.703403 loss_ctc 103.491638 loss_ctc_origin 54.297035 loss_ctc0 218.279037 lr 0.00074869 rank 0
2022-08-24 21:26:58,602 DEBUG TRAIN Batch 125/2700 loss 20.655094 loss_att 10.369741 loss_ctc 44.654251 loss_ctc_origin 32.263870 loss_ctc0 73.565132 lr 0.00074864 rank 0
2022-08-24 21:27:26,613 DEBUG TRAIN Batch 125/2800 loss 21.876835 loss_att 9.922113 loss_ctc 49.771179 loss_ctc_origin 36.399506 loss_ctc0 80.971748 lr 0.00074858 rank 0
2022-08-24 21:27:50,932 WARNING NaN or Inf found in input tensor.
2022-08-24 21:27:51,794 WARNING NaN or Inf found in input tensor.
2022-08-24 21:27:55,486 DEBUG TRAIN Batch 125/2900 loss 24.096720 loss_att 11.141916 loss_ctc 54.324593 loss_ctc_origin 38.613361 loss_ctc0 90.984131 lr 0.00074853 rank 0
2022-08-24 21:28:29,665 DEBUG TRAIN Batch 125/3000 loss 49.302994 loss_att 34.443081 loss_ctc 83.976120 loss_ctc_origin 51.584991 loss_ctc0 159.555435 lr 0.00074848 rank 0
2022-08-24 21:28:37,721 WARNING NaN or Inf found in input tensor.
2022-08-24 21:28:58,501 DEBUG TRAIN Batch 125/3100 loss 54.533932 loss_att 30.072250 loss_ctc 111.611183 loss_ctc_origin 53.746449 loss_ctc0 246.628891 lr 0.00074843 rank 0
2022-08-24 21:29:25,851 WARNING NaN or Inf found in input tensor.
2022-08-24 21:29:27,464 DEBUG TRAIN Batch 125/3200 loss 25.680826 loss_att 14.816346 loss_ctc 51.031281 loss_ctc_origin 43.761269 loss_ctc0 67.994637 lr 0.00074837 rank 0
2022-08-24 21:29:55,465 DEBUG TRAIN Batch 125/3300 loss 19.699600 loss_att 7.993103 loss_ctc 47.014763 loss_ctc_origin 33.296848 loss_ctc0 79.023239 lr 0.00074832 rank 0
2022-08-24 21:30:25,494 DEBUG TRAIN Batch 125/3400 loss 21.329147 loss_att 9.197935 loss_ctc 49.635311 loss_ctc_origin 30.947216 loss_ctc0 93.240860 lr 0.00074827 rank 0
2022-08-24 21:30:55,151 DEBUG TRAIN Batch 125/3500 loss 50.035480 loss_att 30.391136 loss_ctc 95.872284 loss_ctc_origin 57.320244 loss_ctc0 185.827042 lr 0.00074822 rank 0
2022-08-24 21:31:25,227 DEBUG TRAIN Batch 125/3600 loss 50.355350 loss_att 27.644341 loss_ctc 103.347702 loss_ctc_origin 49.094276 loss_ctc0 229.938995 lr 0.00074816 rank 0
2022-08-24 21:31:53,585 DEBUG TRAIN Batch 125/3700 loss 25.281807 loss_att 15.571324 loss_ctc 47.939602 loss_ctc_origin 38.883018 loss_ctc0 69.071625 lr 0.00074811 rank 0
2022-08-24 21:31:59,232 WARNING NaN or Inf found in input tensor.
2022-08-24 21:32:20,823 DEBUG TRAIN Batch 125/3800 loss 20.383297 loss_att 8.663578 loss_ctc 47.729301 loss_ctc_origin 33.694397 loss_ctc0 80.477417 lr 0.00074806 rank 0
2022-08-24 21:32:50,668 DEBUG TRAIN Batch 125/3900 loss 26.932552 loss_att 12.706402 loss_ctc 60.126904 loss_ctc_origin 43.371464 loss_ctc0 99.222931 lr 0.00074801 rank 0
2022-08-24 21:33:20,063 DEBUG TRAIN Batch 125/4000 loss 43.721058 loss_att 29.807602 loss_ctc 76.185791 loss_ctc_origin 43.922169 loss_ctc0 151.467590 lr 0.00074796 rank 0
2022-08-24 21:33:47,828 DEBUG TRAIN Batch 125/4100 loss 48.293739 loss_att 26.808636 loss_ctc 98.425636 loss_ctc_origin 52.323208 loss_ctc0 205.997971 lr 0.00074790 rank 0
2022-08-24 21:34:17,123 DEBUG TRAIN Batch 125/4200 loss 16.208847 loss_att 7.748864 loss_ctc 35.948807 loss_ctc_origin 22.854557 loss_ctc0 66.502060 lr 0.00074785 rank 0
2022-08-24 21:34:45,132 DEBUG TRAIN Batch 125/4300 loss 19.020487 loss_att 7.464489 loss_ctc 45.984482 loss_ctc_origin 31.418938 loss_ctc0 79.970757 lr 0.00074780 rank 0
2022-08-24 21:35:13,100 DEBUG TRAIN Batch 125/4400 loss 20.084351 loss_att 8.950035 loss_ctc 46.064415 loss_ctc_origin 28.614180 loss_ctc0 86.781616 lr 0.00074775 rank 0
2022-08-24 21:35:48,489 DEBUG TRAIN Batch 125/4500 loss 39.354530 loss_att 26.658237 loss_ctc 68.979202 loss_ctc_origin 38.215439 loss_ctc0 140.761322 lr 0.00074769 rank 0
2022-08-24 21:36:17,660 DEBUG TRAIN Batch 125/4600 loss 51.168243 loss_att 30.057808 loss_ctc 100.425934 loss_ctc_origin 59.590378 loss_ctc0 195.708908 lr 0.00074764 rank 0
2022-08-24 21:36:46,167 DEBUG TRAIN Batch 125/4700 loss 19.475801 loss_att 10.834845 loss_ctc 39.638035 loss_ctc_origin 27.818586 loss_ctc0 67.216743 lr 0.00074759 rank 0
2022-08-24 21:37:14,487 DEBUG TRAIN Batch 125/4800 loss 15.785847 loss_att 7.589026 loss_ctc 34.911758 loss_ctc_origin 21.911812 loss_ctc0 65.244972 lr 0.00074754 rank 0
2022-08-24 21:37:43,119 DEBUG TRAIN Batch 125/4900 loss 24.217257 loss_att 11.647677 loss_ctc 53.546272 loss_ctc_origin 36.447006 loss_ctc0 93.444565 lr 0.00074749 rank 0
2022-08-24 21:38:13,252 DEBUG TRAIN Batch 125/5000 loss 43.558163 loss_att 27.223021 loss_ctc 81.673492 loss_ctc_origin 53.058331 loss_ctc0 148.442184 lr 0.00074743 rank 0
2022-08-24 21:38:41,781 DEBUG TRAIN Batch 125/5100 loss 48.958958 loss_att 26.807701 loss_ctc 100.645218 loss_ctc_origin 45.636337 loss_ctc0 228.999268 lr 0.00074738 rank 0
2022-08-24 21:39:10,098 DEBUG TRAIN Batch 125/5200 loss 21.813627 loss_att 11.607786 loss_ctc 45.627254 loss_ctc_origin 35.726051 loss_ctc0 68.730057 lr 0.00074733 rank 0
2022-08-24 21:39:37,641 DEBUG TRAIN Batch 125/5300 loss 20.444237 loss_att 9.600197 loss_ctc 45.746998 loss_ctc_origin 32.958042 loss_ctc0 75.587891 lr 0.00074728 rank 0
2022-08-24 21:40:06,881 DEBUG TRAIN Batch 125/5400 loss 21.809837 loss_att 9.587327 loss_ctc 50.329025 loss_ctc_origin 31.560179 loss_ctc0 94.123001 lr 0.00074722 rank 0
2022-08-24 21:40:37,260 DEBUG TRAIN Batch 125/5500 loss 50.073891 loss_att 34.615334 loss_ctc 86.143860 loss_ctc_origin 58.700302 loss_ctc0 150.178818 lr 0.00074717 rank 0
2022-08-24 21:40:58,190 WARNING NaN or Inf found in input tensor.
2022-08-24 21:41:05,204 DEBUG TRAIN Batch 125/5600 loss 55.598618 loss_att 30.408615 loss_ctc 114.375290 loss_ctc_origin 69.017212 loss_ctc0 220.210785 lr 0.00074712 rank 0
2022-08-24 21:41:27,720 DEBUG CV Batch 125/0 loss 13.324492 loss_att 9.791542 loss_ctc 21.568043 loss_ctc_origin 15.785269 loss_ctc0 35.061176 history loss 12.540699 rank 0
2022-08-24 21:41:38,607 DEBUG CV Batch 125/100 loss 21.463051 loss_att 17.069246 loss_ctc 31.715260 loss_ctc_origin 21.823650 loss_ctc0 54.795685 history loss 27.829214 rank 0
2022-08-24 21:41:48,383 DEBUG CV Batch 125/200 loss 25.094351 loss_att 19.254377 loss_ctc 38.720955 loss_ctc_origin 28.547329 loss_ctc0 62.459412 history loss 28.953799 rank 0
2022-08-24 21:41:58,548 DEBUG CV Batch 125/300 loss 23.118450 loss_att 17.352354 loss_ctc 36.572678 loss_ctc_origin 20.680742 loss_ctc0 73.653854 history loss 27.864050 rank 0
2022-08-24 21:42:09,056 DEBUG CV Batch 125/400 loss 38.959381 loss_att 31.589462 loss_ctc 56.155849 loss_ctc_origin 38.719803 loss_ctc0 96.839958 history loss 26.175795 rank 0
2022-08-24 21:42:19,646 DEBUG CV Batch 125/500 loss 17.565508 loss_att 13.283200 loss_ctc 27.557560 loss_ctc_origin 20.749239 loss_ctc0 43.443642 history loss 25.803847 rank 0
2022-08-24 21:42:30,010 DEBUG CV Batch 125/600 loss 18.270275 loss_att 12.931459 loss_ctc 30.727516 loss_ctc_origin 20.250792 loss_ctc0 55.173203 history loss 25.644534 rank 0
2022-08-24 21:42:40,086 DEBUG CV Batch 125/700 loss 20.058666 loss_att 13.962889 loss_ctc 34.282150 loss_ctc_origin 21.506266 loss_ctc0 64.092545 history loss 25.275402 rank 0
2022-08-24 21:42:50,748 DEBUG CV Batch 125/800 loss 22.988482 loss_att 17.925102 loss_ctc 34.803032 loss_ctc_origin 19.560549 loss_ctc0 70.368828 history loss 25.228469 rank 0
2022-08-24 21:43:01,012 INFO Epoch 125 CV info cv_loss 25.326615780406833
2022-08-24 21:43:01,012 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/125.pt
2022-08-24 21:43:01,521 INFO Epoch 126 TRAIN info lr 0.0007470762484459798
2022-08-24 21:43:01,525 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 21:43:29,384 DEBUG TRAIN Batch 126/0 loss 45.250046 loss_att 30.117546 loss_ctc 80.559219 loss_ctc_origin 50.558144 loss_ctc0 150.561722 lr 0.00074707 rank 0
2022-08-24 21:43:58,839 DEBUG TRAIN Batch 126/100 loss 57.864788 loss_att 33.984257 loss_ctc 113.586029 loss_ctc_origin 64.184265 loss_ctc0 228.856812 lr 0.00074702 rank 0
2022-08-24 21:44:26,972 DEBUG TRAIN Batch 126/200 loss 19.415098 loss_att 10.666664 loss_ctc 39.828110 loss_ctc_origin 28.734375 loss_ctc0 65.713501 lr 0.00074697 rank 0
2022-08-24 21:44:55,707 DEBUG TRAIN Batch 126/300 loss 23.241020 loss_att 9.426095 loss_ctc 55.475845 loss_ctc_origin 42.360168 loss_ctc0 86.079086 lr 0.00074692 rank 0
2022-08-24 21:45:24,497 DEBUG TRAIN Batch 126/400 loss 25.174551 loss_att 11.663500 loss_ctc 56.700336 loss_ctc_origin 38.645142 loss_ctc0 98.829117 lr 0.00074687 rank 0
2022-08-24 21:45:55,625 DEBUG TRAIN Batch 126/500 loss 55.265175 loss_att 37.753456 loss_ctc 96.125839 loss_ctc_origin 60.446339 loss_ctc0 179.378021 lr 0.00074681 rank 0
2022-08-24 21:46:22,985 WARNING NaN or Inf found in input tensor.
2022-08-24 21:46:23,030 DEBUG TRAIN Batch 126/600 loss nan loss_att 26.751183 loss_ctc nan loss_ctc_origin 55.236313 loss_ctc0 nan lr 0.00074676 rank 0
2022-08-24 21:46:52,108 DEBUG TRAIN Batch 126/700 loss 19.339422 loss_att 10.397164 loss_ctc 40.204689 loss_ctc_origin 27.977631 loss_ctc0 68.734497 lr 0.00074671 rank 0
2022-08-24 21:46:57,512 WARNING NaN or Inf found in input tensor.
2022-08-24 21:47:20,617 DEBUG TRAIN Batch 126/800 loss 22.501308 loss_att 10.338474 loss_ctc 50.881256 loss_ctc_origin 38.449787 loss_ctc0 79.888023 lr 0.00074666 rank 0
2022-08-24 21:47:49,379 DEBUG TRAIN Batch 126/900 loss 23.702402 loss_att 10.444360 loss_ctc 54.637829 loss_ctc_origin 38.284386 loss_ctc0 92.795860 lr 0.00074661 rank 0
2022-08-24 21:48:19,319 DEBUG TRAIN Batch 126/1000 loss 31.649530 loss_att 19.155083 loss_ctc 60.803238 loss_ctc_origin 33.229286 loss_ctc0 125.142464 lr 0.00074655 rank 0
2022-08-24 21:48:41,194 WARNING NaN or Inf found in input tensor.
2022-08-24 21:48:48,534 DEBUG TRAIN Batch 126/1100 loss 56.967857 loss_att 33.060127 loss_ctc 112.752548 loss_ctc_origin 64.302887 loss_ctc0 225.801727 lr 0.00074650 rank 0
2022-08-24 21:49:15,016 WARNING NaN or Inf found in input tensor.
2022-08-24 21:49:16,722 DEBUG TRAIN Batch 126/1200 loss 18.833529 loss_att 10.504644 loss_ctc 38.267593 loss_ctc_origin 25.733450 loss_ctc0 67.513931 lr 0.00074645 rank 0
2022-08-24 21:49:45,051 DEBUG TRAIN Batch 126/1300 loss 21.173044 loss_att 9.651207 loss_ctc 48.057327 loss_ctc_origin 35.069031 loss_ctc0 78.363358 lr 0.00074640 rank 0
2022-08-24 21:50:01,917 WARNING NaN or Inf found in input tensor.
2022-08-24 21:50:12,758 DEBUG TRAIN Batch 126/1400 loss 24.442730 loss_att 10.871765 loss_ctc 56.108311 loss_ctc_origin 37.400902 loss_ctc0 99.758926 lr 0.00074635 rank 0
2022-08-24 21:50:48,344 DEBUG TRAIN Batch 126/1500 loss 49.677109 loss_att 33.211510 loss_ctc 88.096832 loss_ctc_origin 52.927368 loss_ctc0 170.158920 lr 0.00074629 rank 0
2022-08-24 21:51:16,846 DEBUG TRAIN Batch 126/1600 loss 51.745472 loss_att 27.709019 loss_ctc 107.830521 loss_ctc_origin 56.043709 loss_ctc0 228.666428 lr 0.00074624 rank 0
2022-08-24 21:51:44,669 DEBUG TRAIN Batch 126/1700 loss 20.351246 loss_att 13.079123 loss_ctc 37.319534 loss_ctc_origin 27.578880 loss_ctc0 60.047722 lr 0.00074619 rank 0
2022-08-24 21:52:13,643 DEBUG TRAIN Batch 126/1800 loss 18.663742 loss_att 7.767849 loss_ctc 44.087486 loss_ctc_origin 29.673252 loss_ctc0 77.720703 lr 0.00074614 rank 0
2022-08-24 21:52:42,986 DEBUG TRAIN Batch 126/1900 loss 24.201008 loss_att 11.050237 loss_ctc 54.886139 loss_ctc_origin 38.682365 loss_ctc0 92.694931 lr 0.00074609 rank 0
2022-08-24 21:53:12,330 DEBUG TRAIN Batch 126/2000 loss 44.453568 loss_att 29.488316 loss_ctc 79.372482 loss_ctc_origin 52.106968 loss_ctc0 142.992020 lr 0.00074603 rank 0
2022-08-24 21:53:41,208 DEBUG TRAIN Batch 126/2100 loss 46.454998 loss_att 24.389336 loss_ctc 97.941544 loss_ctc_origin 48.881241 loss_ctc0 212.415573 lr 0.00074598 rank 0
2022-08-24 21:54:08,313 DEBUG TRAIN Batch 126/2200 loss 22.079865 loss_att 11.838540 loss_ctc 45.976288 loss_ctc_origin 34.612862 loss_ctc0 72.490952 lr 0.00074593 rank 0
2022-08-24 21:54:35,498 DEBUG TRAIN Batch 126/2300 loss 17.443283 loss_att 7.275174 loss_ctc 41.168865 loss_ctc_origin 27.948875 loss_ctc0 72.015503 lr 0.00074588 rank 0
2022-08-24 21:55:05,525 DEBUG TRAIN Batch 126/2400 loss 22.724548 loss_att 9.620333 loss_ctc 53.301048 loss_ctc_origin 38.002586 loss_ctc0 88.997452 lr 0.00074583 rank 0
2022-08-24 21:55:34,494 DEBUG TRAIN Batch 126/2500 loss 41.088806 loss_att 27.408007 loss_ctc 73.010666 loss_ctc_origin 40.354713 loss_ctc0 149.207901 lr 0.00074577 rank 0
2022-08-24 21:55:59,380 DEBUG TRAIN Batch 126/2600 loss 50.915466 loss_att 25.303284 loss_ctc 110.677223 loss_ctc_origin 49.746727 loss_ctc0 252.848373 lr 0.00074572 rank 0
2022-08-24 21:56:26,304 DEBUG TRAIN Batch 126/2700 loss 20.665531 loss_att 12.380350 loss_ctc 39.997623 loss_ctc_origin 29.208103 loss_ctc0 65.173172 lr 0.00074567 rank 0
2022-08-24 21:56:45,082 WARNING NaN or Inf found in input tensor.
2022-08-24 21:56:55,044 DEBUG TRAIN Batch 126/2800 loss 19.772758 loss_att 7.942414 loss_ctc 47.376892 loss_ctc_origin 35.145672 loss_ctc0 75.916397 lr 0.00074562 rank 0
2022-08-24 21:57:23,464 DEBUG TRAIN Batch 126/2900 loss 21.397455 loss_att 9.247233 loss_ctc 49.747971 loss_ctc_origin 30.259533 loss_ctc0 95.220993 lr 0.00074557 rank 0
2022-08-24 21:57:58,741 DEBUG TRAIN Batch 126/3000 loss 41.554569 loss_att 25.786129 loss_ctc 78.347595 loss_ctc_origin 42.489449 loss_ctc0 162.016602 lr 0.00074552 rank 0
2022-08-24 21:58:27,849 WARNING NaN or Inf found in input tensor.
2022-08-24 21:58:27,898 DEBUG TRAIN Batch 126/3100 loss nan loss_att 32.953537 loss_ctc nan loss_ctc_origin 61.168518 loss_ctc0 nan lr 0.00074546 rank 0
2022-08-24 21:58:55,507 DEBUG TRAIN Batch 126/3200 loss 22.983597 loss_att 12.873113 loss_ctc 46.574722 loss_ctc_origin 35.367474 loss_ctc0 72.724976 lr 0.00074541 rank 0
2022-08-24 21:59:22,920 DEBUG TRAIN Batch 126/3300 loss 16.232409 loss_att 6.761031 loss_ctc 38.332291 loss_ctc_origin 25.334999 loss_ctc0 68.659302 lr 0.00074536 rank 0
2022-08-24 21:59:50,562 DEBUG TRAIN Batch 126/3400 loss 22.053953 loss_att 10.053328 loss_ctc 50.055408 loss_ctc_origin 31.428963 loss_ctc0 93.517113 lr 0.00074531 rank 0
2022-08-24 22:00:19,483 DEBUG TRAIN Batch 126/3500 loss 46.018410 loss_att 28.436375 loss_ctc 87.043152 loss_ctc_origin 50.324707 loss_ctc0 172.719498 lr 0.00074526 rank 0
2022-08-24 22:00:47,453 DEBUG TRAIN Batch 126/3600 loss 51.206657 loss_att 24.338011 loss_ctc 113.900162 loss_ctc_origin 55.872993 loss_ctc0 249.296890 lr 0.00074520 rank 0
2022-08-24 22:01:15,082 DEBUG TRAIN Batch 126/3700 loss 25.164619 loss_att 14.732977 loss_ctc 49.505116 loss_ctc_origin 38.565166 loss_ctc0 75.031662 lr 0.00074515 rank 0
2022-08-24 22:01:43,141 DEBUG TRAIN Batch 126/3800 loss 20.442417 loss_att 8.912756 loss_ctc 47.344959 loss_ctc_origin 31.385288 loss_ctc0 84.584190 lr 0.00074510 rank 0
2022-08-24 22:02:10,842 DEBUG TRAIN Batch 126/3900 loss 21.606258 loss_att 9.399657 loss_ctc 50.088326 loss_ctc_origin 33.152206 loss_ctc0 89.605927 lr 0.00074505 rank 0
2022-08-24 22:02:40,237 DEBUG TRAIN Batch 126/4000 loss 52.812645 loss_att 33.234982 loss_ctc 98.493851 loss_ctc_origin 57.038925 loss_ctc0 195.222015 lr 0.00074500 rank 0
2022-08-24 22:03:07,952 DEBUG TRAIN Batch 126/4100 loss 62.768379 loss_att 35.776268 loss_ctc 125.749969 loss_ctc_origin 73.016083 loss_ctc0 248.795685 lr 0.00074495 rank 0
2022-08-24 22:03:35,340 WARNING NaN or Inf found in input tensor.
2022-08-24 22:03:37,241 DEBUG TRAIN Batch 126/4200 loss 19.487572 loss_att 10.491455 loss_ctc 40.478512 loss_ctc_origin 29.802895 loss_ctc0 65.388283 lr 0.00074489 rank 0
2022-08-24 22:04:08,048 DEBUG TRAIN Batch 126/4300 loss 20.063484 loss_att 8.415650 loss_ctc 47.241760 loss_ctc_origin 34.986656 loss_ctc0 75.836990 lr 0.00074484 rank 0
2022-08-24 22:04:22,102 WARNING NaN or Inf found in input tensor.
2022-08-24 22:04:35,635 DEBUG TRAIN Batch 126/4400 loss 21.060417 loss_att 8.584213 loss_ctc 50.171562 loss_ctc_origin 31.681440 loss_ctc0 93.315170 lr 0.00074479 rank 0
2022-08-24 22:05:05,758 DEBUG TRAIN Batch 126/4500 loss 52.695374 loss_att 35.328964 loss_ctc 93.216988 loss_ctc_origin 56.105755 loss_ctc0 179.809860 lr 0.00074474 rank 0
2022-08-24 22:05:32,865 DEBUG TRAIN Batch 126/4600 loss 54.896027 loss_att 29.307194 loss_ctc 114.603287 loss_ctc_origin 54.536179 loss_ctc0 254.759857 lr 0.00074469 rank 0
2022-08-24 22:05:59,408 DEBUG TRAIN Batch 126/4700 loss 18.423756 loss_att 10.591899 loss_ctc 36.698090 loss_ctc_origin 26.261650 loss_ctc0 61.049782 lr 0.00074464 rank 0
2022-08-24 22:06:26,575 DEBUG TRAIN Batch 126/4800 loss 20.761992 loss_att 9.123211 loss_ctc 47.919144 loss_ctc_origin 34.787979 loss_ctc0 78.558533 lr 0.00074458 rank 0
2022-08-24 22:06:38,316 WARNING NaN or Inf found in input tensor.
2022-08-24 22:06:53,247 DEBUG TRAIN Batch 126/4900 loss 27.373360 loss_att 13.730114 loss_ctc 59.207603 loss_ctc_origin 46.452644 loss_ctc0 88.969170 lr 0.00074453 rank 0
2022-08-24 22:06:55,946 WARNING NaN or Inf found in input tensor.
2022-08-24 22:07:21,136 DEBUG TRAIN Batch 126/5000 loss 46.848091 loss_att 28.966959 loss_ctc 88.570724 loss_ctc_origin 51.463158 loss_ctc0 175.155060 lr 0.00074448 rank 0
2022-08-24 22:07:47,231 DEBUG TRAIN Batch 126/5100 loss 57.535053 loss_att 30.027876 loss_ctc 121.718460 loss_ctc_origin 66.981010 loss_ctc0 249.439148 lr 0.00074443 rank 0
2022-08-24 22:08:14,393 DEBUG TRAIN Batch 126/5200 loss 16.842648 loss_att 8.449696 loss_ctc 36.426201 loss_ctc_origin 24.293049 loss_ctc0 64.736877 lr 0.00074438 rank 0
2022-08-24 22:08:43,850 DEBUG TRAIN Batch 126/5300 loss 18.621630 loss_att 8.470616 loss_ctc 42.307327 loss_ctc_origin 28.552961 loss_ctc0 74.400856 lr 0.00074433 rank 0
2022-08-24 22:08:48,364 WARNING NaN or Inf found in input tensor.
2022-08-24 22:09:11,729 DEBUG TRAIN Batch 126/5400 loss 24.433775 loss_att 11.065964 loss_ctc 55.625336 loss_ctc_origin 38.850105 loss_ctc0 94.767540 lr 0.00074428 rank 0
2022-08-24 22:09:36,833 DEBUG TRAIN Batch 126/5500 loss 32.934799 loss_att 19.113348 loss_ctc 65.184860 loss_ctc_origin 30.990784 loss_ctc0 144.971024 lr 0.00074422 rank 0
2022-08-24 22:10:03,436 DEBUG TRAIN Batch 126/5600 loss 53.517616 loss_att 29.301308 loss_ctc 110.022339 loss_ctc_origin 53.192833 loss_ctc0 242.624512 lr 0.00074417 rank 0
2022-08-24 22:10:25,069 DEBUG CV Batch 126/0 loss 12.993727 loss_att 9.651301 loss_ctc 20.792717 loss_ctc_origin 14.860698 loss_ctc0 34.634094 history loss 12.229390 rank 0
2022-08-24 22:10:35,187 DEBUG CV Batch 126/100 loss 22.077408 loss_att 17.620129 loss_ctc 32.477722 loss_ctc_origin 22.919037 loss_ctc0 54.781322 history loss 27.731589 rank 0
2022-08-24 22:10:44,579 DEBUG CV Batch 126/200 loss 25.759922 loss_att 20.400383 loss_ctc 38.265514 loss_ctc_origin 27.535664 loss_ctc0 63.301834 history loss 28.959379 rank 0
2022-08-24 22:10:53,687 DEBUG CV Batch 126/300 loss 23.962973 loss_att 18.461826 loss_ctc 36.798981 loss_ctc_origin 21.318226 loss_ctc0 72.920738 history loss 27.948980 rank 0
2022-08-24 22:11:04,012 DEBUG CV Batch 126/400 loss 39.107834 loss_att 31.530230 loss_ctc 56.788910 loss_ctc_origin 39.430885 loss_ctc0 97.290955 history loss 26.234853 rank 0
2022-08-24 22:11:14,046 DEBUG CV Batch 126/500 loss 17.225319 loss_att 12.704170 loss_ctc 27.774662 loss_ctc_origin 21.238424 loss_ctc0 43.025887 history loss 25.851118 rank 0
2022-08-24 22:11:24,580 DEBUG CV Batch 126/600 loss 17.455532 loss_att 11.844828 loss_ctc 30.547173 loss_ctc_origin 20.300417 loss_ctc0 54.456268 history loss 25.692741 rank 0
2022-08-24 22:11:35,361 DEBUG CV Batch 126/700 loss 20.522049 loss_att 14.488121 loss_ctc 34.601212 loss_ctc_origin 21.660965 loss_ctc0 64.795120 history loss 25.339140 rank 0
2022-08-24 22:11:44,725 DEBUG CV Batch 126/800 loss 22.469971 loss_att 17.413160 loss_ctc 34.269199 loss_ctc_origin 18.915218 loss_ctc0 70.095154 history loss 25.282980 rank 0
2022-08-24 22:11:53,220 INFO Epoch 126 CV info cv_loss 25.356912472995766
2022-08-24 22:11:53,221 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/126.pt
2022-08-24 22:11:53,671 INFO Epoch 127 TRAIN info lr 0.0007441291906133572
2022-08-24 22:11:53,674 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 22:12:19,558 DEBUG TRAIN Batch 127/0 loss 38.658192 loss_att 22.114161 loss_ctc 77.260933 loss_ctc_origin 42.051140 loss_ctc0 159.417114 lr 0.00074413 rank 0
2022-08-24 22:12:27,533 WARNING NaN or Inf found in input tensor.
2022-08-24 22:12:47,688 DEBUG TRAIN Batch 127/100 loss 48.943523 loss_att 24.534245 loss_ctc 105.898506 loss_ctc_origin 54.303894 loss_ctc0 226.285934 lr 0.00074408 rank 0
2022-08-24 22:13:13,292 WARNING NaN or Inf found in input tensor.
2022-08-24 22:13:14,997 DEBUG TRAIN Batch 127/200 loss 21.072283 loss_att 11.493167 loss_ctc 43.423553 loss_ctc_origin 30.744133 loss_ctc0 73.008865 lr 0.00074402 rank 0
2022-08-24 22:13:20,565 WARNING NaN or Inf found in input tensor.
2022-08-24 22:13:43,317 DEBUG TRAIN Batch 127/300 loss 21.462128 loss_att 9.173126 loss_ctc 50.136467 loss_ctc_origin 35.522373 loss_ctc0 84.236008 lr 0.00074397 rank 0
2022-08-24 22:14:10,646 DEBUG TRAIN Batch 127/400 loss 20.422050 loss_att 7.699673 loss_ctc 50.107597 loss_ctc_origin 31.132515 loss_ctc0 94.382782 lr 0.00074392 rank 0
2022-08-24 22:14:38,435 DEBUG TRAIN Batch 127/500 loss 47.263229 loss_att 32.855835 loss_ctc 80.880478 loss_ctc_origin 49.629467 loss_ctc0 153.799515 lr 0.00074387 rank 0
2022-08-24 22:15:05,299 DEBUG TRAIN Batch 127/600 loss 51.209106 loss_att 29.113796 loss_ctc 102.764816 loss_ctc_origin 52.619560 loss_ctc0 219.770416 lr 0.00074382 rank 0
2022-08-24 22:15:30,186 WARNING NaN or Inf found in input tensor.
2022-08-24 22:15:31,617 DEBUG TRAIN Batch 127/700 loss 24.542072 loss_att 15.413031 loss_ctc 45.843163 loss_ctc_origin 35.178421 loss_ctc0 70.727562 lr 0.00074377 rank 0
2022-08-24 22:15:58,498 DEBUG TRAIN Batch 127/800 loss 19.739559 loss_att 8.892614 loss_ctc 45.049095 loss_ctc_origin 31.694088 loss_ctc0 76.210770 lr 0.00074372 rank 0
2022-08-24 22:16:26,473 DEBUG TRAIN Batch 127/900 loss 25.482405 loss_att 11.022785 loss_ctc 59.221512 loss_ctc_origin 39.951134 loss_ctc0 104.185730 lr 0.00074366 rank 0
2022-08-24 22:16:53,476 DEBUG TRAIN Batch 127/1000 loss 43.031578 loss_att 30.279644 loss_ctc 72.786079 loss_ctc_origin 44.511261 loss_ctc0 138.760651 lr 0.00074361 rank 0
2022-08-24 22:17:20,998 DEBUG TRAIN Batch 127/1100 loss 52.243744 loss_att 26.081223 loss_ctc 113.289619 loss_ctc_origin 54.886620 loss_ctc0 249.563293 lr 0.00074356 rank 0
2022-08-24 22:17:48,434 DEBUG TRAIN Batch 127/1200 loss 23.743784 loss_att 14.685666 loss_ctc 44.879391 loss_ctc_origin 35.028931 loss_ctc0 67.863800 lr 0.00074351 rank 0
2022-08-24 22:18:16,048 DEBUG TRAIN Batch 127/1300 loss 21.616234 loss_att 9.801492 loss_ctc 49.183968 loss_ctc_origin 37.166664 loss_ctc0 77.224335 lr 0.00074346 rank 0
2022-08-24 22:18:43,352 DEBUG TRAIN Batch 127/1400 loss 23.989132 loss_att 10.591520 loss_ctc 55.250225 loss_ctc_origin 38.273064 loss_ctc0 94.863602 lr 0.00074341 rank 0
2022-08-24 22:19:17,621 DEBUG TRAIN Batch 127/1500 loss 42.300240 loss_att 25.950993 loss_ctc 80.448486 loss_ctc_origin 43.317696 loss_ctc0 167.087006 lr 0.00074336 rank 0
2022-08-24 22:19:46,052 DEBUG TRAIN Batch 127/1600 loss 51.129429 loss_att 25.612614 loss_ctc 110.668655 loss_ctc_origin 55.559937 loss_ctc0 239.255676 lr 0.00074330 rank 0
2022-08-24 22:20:14,524 DEBUG TRAIN Batch 127/1700 loss 18.041660 loss_att 9.144827 loss_ctc 38.800941 loss_ctc_origin 25.950672 loss_ctc0 68.784897 lr 0.00074325 rank 0
2022-08-24 22:20:42,708 DEBUG TRAIN Batch 127/1800 loss 20.688309 loss_att 8.950183 loss_ctc 48.077267 loss_ctc_origin 33.817413 loss_ctc0 81.350250 lr 0.00074320 rank 0
2022-08-24 22:21:10,637 DEBUG TRAIN Batch 127/1900 loss 21.697039 loss_att 8.746651 loss_ctc 51.914608 loss_ctc_origin 34.466499 loss_ctc0 92.626862 lr 0.00074315 rank 0
2022-08-24 22:21:38,267 DEBUG TRAIN Batch 127/2000 loss 52.245991 loss_att 35.040604 loss_ctc 92.391891 loss_ctc_origin 55.143433 loss_ctc0 179.304962 lr 0.00074310 rank 0
2022-08-24 22:21:46,118 WARNING NaN or Inf found in input tensor.
2022-08-24 22:22:05,491 DEBUG TRAIN Batch 127/2100 loss 56.972931 loss_att 31.616474 loss_ctc 116.138000 loss_ctc_origin 70.187622 loss_ctc0 223.355545 lr 0.00074305 rank 0
2022-08-24 22:22:32,359 DEBUG TRAIN Batch 127/2200 loss 20.083069 loss_att 11.720932 loss_ctc 39.594719 loss_ctc_origin 29.302103 loss_ctc0 63.610809 lr 0.00074300 rank 0
2022-08-24 22:22:59,624 DEBUG TRAIN Batch 127/2300 loss 22.438339 loss_att 9.514524 loss_ctc 52.593910 loss_ctc_origin 38.727077 loss_ctc0 84.949844 lr 0.00074295 rank 0
2022-08-24 22:23:27,727 DEBUG TRAIN Batch 127/2400 loss 21.390369 loss_att 8.861640 loss_ctc 50.624069 loss_ctc_origin 33.378639 loss_ctc0 90.863403 lr 0.00074289 rank 0
2022-08-24 22:23:54,912 DEBUG TRAIN Batch 127/2500 loss 46.429596 loss_att 27.173489 loss_ctc 91.360504 loss_ctc_origin 52.026443 loss_ctc0 183.139984 lr 0.00074284 rank 0
2022-08-24 22:24:21,979 DEBUG TRAIN Batch 127/2600 loss 56.197411 loss_att 31.455032 loss_ctc 113.929634 loss_ctc_origin 60.157154 loss_ctc0 239.398743 lr 0.00074279 rank 0
2022-08-24 22:24:50,569 DEBUG TRAIN Batch 127/2700 loss 20.980648 loss_att 11.395164 loss_ctc 43.346771 loss_ctc_origin 33.422997 loss_ctc0 66.502243 lr 0.00074274 rank 0
2022-08-24 22:25:18,473 DEBUG TRAIN Batch 127/2800 loss 16.111315 loss_att 6.288149 loss_ctc 39.032036 loss_ctc_origin 24.456310 loss_ctc0 73.042053 lr 0.00074269 rank 0
2022-08-24 22:25:44,584 DEBUG TRAIN Batch 127/2900 loss 29.485123 loss_att 13.383599 loss_ctc 67.055344 loss_ctc_origin 51.445625 loss_ctc0 103.478012 lr 0.00074264 rank 0
2022-08-24 22:26:18,350 DEBUG TRAIN Batch 127/3000 loss 43.399773 loss_att 29.134533 loss_ctc 76.685333 loss_ctc_origin 47.442486 loss_ctc0 144.918640 lr 0.00074259 rank 0
2022-08-24 22:26:46,612 DEBUG TRAIN Batch 127/3100 loss 50.222103 loss_att 26.835056 loss_ctc 104.791878 loss_ctc_origin 54.308167 loss_ctc0 222.587189 lr 0.00074254 rank 0
2022-08-24 22:27:14,624 WARNING NaN or Inf found in input tensor.
2022-08-24 22:27:16,295 DEBUG TRAIN Batch 127/3200 loss 19.677456 loss_att 9.890104 loss_ctc 42.514610 loss_ctc_origin 31.120562 loss_ctc0 69.100723 lr 0.00074248 rank 0
2022-08-24 22:27:44,294 DEBUG TRAIN Batch 127/3300 loss 19.696718 loss_att 8.016816 loss_ctc 46.949821 loss_ctc_origin 32.589390 loss_ctc0 80.457497 lr 0.00074243 rank 0
2022-08-24 22:28:07,286 WARNING NaN or Inf found in input tensor.
2022-08-24 22:28:11,687 DEBUG TRAIN Batch 127/3400 loss 22.248230 loss_att 9.405626 loss_ctc 52.214306 loss_ctc_origin 33.877979 loss_ctc0 94.999069 lr 0.00074238 rank 0
2022-08-24 22:28:40,778 DEBUG TRAIN Batch 127/3500 loss 43.400558 loss_att 28.093975 loss_ctc 79.115921 loss_ctc_origin 48.127586 loss_ctc0 151.422028 lr 0.00074233 rank 0
2022-08-24 22:29:08,150 DEBUG TRAIN Batch 127/3600 loss 46.540245 loss_att 25.716515 loss_ctc 95.128937 loss_ctc_origin 51.529449 loss_ctc0 196.861084 lr 0.00074228 rank 0
2022-08-24 22:29:36,670 DEBUG TRAIN Batch 127/3700 loss 22.198616 loss_att 11.677216 loss_ctc 46.748550 loss_ctc_origin 37.290699 loss_ctc0 68.816864 lr 0.00074223 rank 0
2022-08-24 22:30:05,149 DEBUG TRAIN Batch 127/3800 loss 20.393238 loss_att 8.459116 loss_ctc 48.239525 loss_ctc_origin 33.848824 loss_ctc0 81.817825 lr 0.00074218 rank 0
2022-08-24 22:30:32,077 DEBUG TRAIN Batch 127/3900 loss 23.372829 loss_att 10.284615 loss_ctc 53.911995 loss_ctc_origin 37.996105 loss_ctc0 91.049072 lr 0.00074213 rank 0
2022-08-24 22:31:00,891 DEBUG TRAIN Batch 127/4000 loss 40.859032 loss_att 24.686470 loss_ctc 78.595009 loss_ctc_origin 44.283112 loss_ctc0 158.656097 lr 0.00074208 rank 0
2022-08-24 22:31:14,083 WARNING NaN or Inf found in input tensor.
2022-08-24 22:31:28,152 DEBUG TRAIN Batch 127/4100 loss 44.537205 loss_att 22.550613 loss_ctc 95.839249 loss_ctc_origin 50.066109 loss_ctc0 202.643250 lr 0.00074202 rank 0
2022-08-24 22:31:56,207 DEBUG TRAIN Batch 127/4200 loss 21.151653 loss_att 11.359535 loss_ctc 43.999924 loss_ctc_origin 33.620529 loss_ctc0 68.218506 lr 0.00074197 rank 0
2022-08-24 22:32:22,728 DEBUG TRAIN Batch 127/4300 loss 20.906397 loss_att 8.690727 loss_ctc 49.409622 loss_ctc_origin 36.128071 loss_ctc0 80.399902 lr 0.00074192 rank 0
2022-08-24 22:32:52,417 DEBUG TRAIN Batch 127/4400 loss 23.615803 loss_att 10.784029 loss_ctc 53.556602 loss_ctc_origin 37.347588 loss_ctc0 91.377640 lr 0.00074187 rank 0
2022-08-24 22:33:25,195 DEBUG TRAIN Batch 127/4500 loss 43.467690 loss_att 28.426285 loss_ctc 78.564293 loss_ctc_origin 46.843239 loss_ctc0 152.580078 lr 0.00074182 rank 0
2022-08-24 22:33:33,873 WARNING NaN or Inf found in input tensor.
2022-08-24 22:33:53,103 DEBUG TRAIN Batch 127/4600 loss 45.605930 loss_att 21.366028 loss_ctc 102.165695 loss_ctc_origin 48.441788 loss_ctc0 227.521484 lr 0.00074177 rank 0
2022-08-24 22:34:20,965 DEBUG TRAIN Batch 127/4700 loss 19.206375 loss_att 9.899391 loss_ctc 40.922668 loss_ctc_origin 31.239033 loss_ctc0 63.517822 lr 0.00074172 rank 0
2022-08-24 22:34:48,973 DEBUG TRAIN Batch 127/4800 loss 19.712511 loss_att 8.888611 loss_ctc 44.968277 loss_ctc_origin 31.822645 loss_ctc0 75.641418 lr 0.00074167 rank 0
2022-08-24 22:35:17,618 DEBUG TRAIN Batch 127/4900 loss 22.376329 loss_att 9.828043 loss_ctc 51.655663 loss_ctc_origin 34.902077 loss_ctc0 90.747353 lr 0.00074162 rank 0
2022-08-24 22:35:45,712 DEBUG TRAIN Batch 127/5000 loss 50.122757 loss_att 35.416618 loss_ctc 84.437073 loss_ctc_origin 52.943027 loss_ctc0 157.923157 lr 0.00074157 rank 0
2022-08-24 22:36:13,746 DEBUG TRAIN Batch 127/5100 loss 44.094219 loss_att 20.870441 loss_ctc 98.283035 loss_ctc_origin 44.424923 loss_ctc0 223.951935 lr 0.00074151 rank 0
2022-08-24 22:36:41,477 DEBUG TRAIN Batch 127/5200 loss 18.762735 loss_att 9.601286 loss_ctc 40.139450 loss_ctc_origin 28.064220 loss_ctc0 68.314987 lr 0.00074146 rank 0
2022-08-24 22:37:09,975 DEBUG TRAIN Batch 127/5300 loss 20.383530 loss_att 8.561028 loss_ctc 47.969368 loss_ctc_origin 33.149345 loss_ctc0 82.549423 lr 0.00074141 rank 0
2022-08-24 22:37:38,560 DEBUG TRAIN Batch 127/5400 loss 24.177055 loss_att 10.779655 loss_ctc 55.437660 loss_ctc_origin 37.569332 loss_ctc0 97.130417 lr 0.00074136 rank 0
2022-08-24 22:38:05,619 DEBUG TRAIN Batch 127/5500 loss 41.141258 loss_att 26.136795 loss_ctc 76.151672 loss_ctc_origin 41.507103 loss_ctc0 156.988998 lr 0.00074131 rank 0
2022-08-24 22:38:35,973 DEBUG TRAIN Batch 127/5600 loss 48.906525 loss_att 24.967047 loss_ctc 104.765312 loss_ctc_origin 55.145702 loss_ctc0 220.544403 lr 0.00074126 rank 0
2022-08-24 22:39:02,268 DEBUG CV Batch 127/0 loss 12.722319 loss_att 9.273457 loss_ctc 20.769665 loss_ctc_origin 15.046703 loss_ctc0 34.123245 history loss 11.973947 rank 0
2022-08-24 22:39:13,330 DEBUG CV Batch 127/100 loss 21.120029 loss_att 16.819548 loss_ctc 31.154484 loss_ctc_origin 21.446487 loss_ctc0 53.806473 history loss 26.855357 rank 0
2022-08-24 22:39:24,163 DEBUG CV Batch 127/200 loss 24.368301 loss_att 18.998730 loss_ctc 36.897301 loss_ctc_origin 26.094368 loss_ctc0 62.104137 history loss 28.006138 rank 0
2022-08-24 22:39:34,988 DEBUG CV Batch 127/300 loss 22.870607 loss_att 17.111856 loss_ctc 36.307693 loss_ctc_origin 21.032127 loss_ctc0 71.950684 history loss 27.039012 rank 0
2022-08-24 22:39:44,368 DEBUG CV Batch 127/400 loss 37.357059 loss_att 30.319756 loss_ctc 53.777431 loss_ctc_origin 35.852791 loss_ctc0 95.601593 history loss 25.393975 rank 0
2022-08-24 22:39:53,380 DEBUG CV Batch 127/500 loss 16.590065 loss_att 12.323837 loss_ctc 26.544594 loss_ctc_origin 19.711327 loss_ctc0 42.488880 history loss 25.069744 rank 0
2022-08-24 22:40:03,714 DEBUG CV Batch 127/600 loss 16.605576 loss_att 11.464588 loss_ctc 28.601213 loss_ctc_origin 17.743675 loss_ctc0 53.935471 history loss 24.902085 rank 0
2022-08-24 22:40:14,029 DEBUG CV Batch 127/700 loss 19.319876 loss_att 13.403608 loss_ctc 33.124500 loss_ctc_origin 19.821583 loss_ctc0 64.164642 history loss 24.547868 rank 0
2022-08-24 22:40:24,331 DEBUG CV Batch 127/800 loss 22.060009 loss_att 17.261318 loss_ctc 33.256950 loss_ctc_origin 17.956774 loss_ctc0 68.957367 history loss 24.500570 rank 0
2022-08-24 22:40:34,568 INFO Epoch 127 CV info cv_loss 24.59392108386049
2022-08-24 22:40:34,568 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/127.pt
2022-08-24 22:40:35,034 INFO Epoch 128 TRAIN info lr 0.0007412167364216876
2022-08-24 22:40:35,038 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 22:41:01,072 DEBUG TRAIN Batch 128/0 loss 43.762581 loss_att 27.589943 loss_ctc 81.498734 loss_ctc_origin 49.571781 loss_ctc0 155.994965 lr 0.00074121 rank 0
2022-08-24 22:41:30,268 DEBUG TRAIN Batch 128/100 loss 49.401283 loss_att 25.443983 loss_ctc 105.301651 loss_ctc_origin 54.861206 loss_ctc0 222.996002 lr 0.00074116 rank 0
2022-08-24 22:41:59,362 DEBUG TRAIN Batch 128/200 loss 21.108141 loss_att 10.968479 loss_ctc 44.767349 loss_ctc_origin 33.949440 loss_ctc0 70.009140 lr 0.00074111 rank 0
2022-08-24 22:42:27,375 DEBUG TRAIN Batch 128/300 loss 18.709150 loss_att 8.559014 loss_ctc 42.392799 loss_ctc_origin 26.437962 loss_ctc0 79.620758 lr 0.00074106 rank 0
2022-08-24 22:42:56,800 DEBUG TRAIN Batch 128/400 loss 22.588524 loss_att 9.127134 loss_ctc 53.998428 loss_ctc_origin 37.102203 loss_ctc0 93.422958 lr 0.00074101 rank 0
2022-08-24 22:43:26,067 DEBUG TRAIN Batch 128/500 loss 48.059235 loss_att 31.526924 loss_ctc 86.634628 loss_ctc_origin 53.954750 loss_ctc0 162.887665 lr 0.00074096 rank 0
2022-08-24 22:43:52,296 DEBUG TRAIN Batch 128/600 loss 46.394974 loss_att 23.748358 loss_ctc 99.237076 loss_ctc_origin 52.677666 loss_ctc0 207.875671 lr 0.00074091 rank 0
2022-08-24 22:44:18,683 DEBUG TRAIN Batch 128/700 loss 19.493923 loss_att 11.115091 loss_ctc 39.044533 loss_ctc_origin 27.836105 loss_ctc0 65.197533 lr 0.00074086 rank 0
2022-08-24 22:44:47,573 DEBUG TRAIN Batch 128/800 loss 22.738462 loss_att 9.691001 loss_ctc 53.182541 loss_ctc_origin 36.804165 loss_ctc0 91.398758 lr 0.00074081 rank 0
2022-08-24 22:45:15,113 DEBUG TRAIN Batch 128/900 loss 22.195271 loss_att 9.417433 loss_ctc 52.010223 loss_ctc_origin 34.679131 loss_ctc0 92.449448 lr 0.00074076 rank 0
2022-08-24 22:45:43,107 DEBUG TRAIN Batch 128/1000 loss 40.503693 loss_att 26.205391 loss_ctc 73.866402 loss_ctc_origin 43.591267 loss_ctc0 144.508377 lr 0.00074071 rank 0
2022-08-24 22:46:10,820 WARNING NaN or Inf found in input tensor.
2022-08-24 22:46:11,600 DEBUG TRAIN Batch 128/1100 loss 50.819981 loss_att 26.175571 loss_ctc 108.323601 loss_ctc_origin 60.812717 loss_ctc0 219.182312 lr 0.00074066 rank 0
2022-08-24 22:46:38,960 DEBUG TRAIN Batch 128/1200 loss 16.595030 loss_att 8.544500 loss_ctc 35.379597 loss_ctc_origin 21.885998 loss_ctc0 66.864662 lr 0.00074060 rank 0
2022-08-24 22:47:08,298 DEBUG TRAIN Batch 128/1300 loss 24.384590 loss_att 10.892576 loss_ctc 55.865952 loss_ctc_origin 43.515079 loss_ctc0 84.684647 lr 0.00074055 rank 0
2022-08-24 22:47:34,551 DEBUG TRAIN Batch 128/1400 loss 23.556276 loss_att 10.399384 loss_ctc 54.255688 loss_ctc_origin 36.302803 loss_ctc0 96.145744 lr 0.00074050 rank 0
2022-08-24 22:48:08,357 DEBUG TRAIN Batch 128/1500 loss 42.858704 loss_att 27.265112 loss_ctc 79.243752 loss_ctc_origin 44.834579 loss_ctc0 159.531815 lr 0.00074045 rank 0
2022-08-24 22:48:36,032 DEBUG TRAIN Batch 128/1600 loss 51.744705 loss_att 29.488480 loss_ctc 103.675903 loss_ctc_origin 57.493225 loss_ctc0 211.435486 lr 0.00074040 rank 0
2022-08-24 22:49:01,792 WARNING NaN or Inf found in input tensor.
2022-08-24 22:49:03,396 DEBUG TRAIN Batch 128/1700 loss 18.802616 loss_att 8.721157 loss_ctc 42.326023 loss_ctc_origin 29.296276 loss_ctc0 72.728767 lr 0.00074035 rank 0
2022-08-24 22:49:31,245 DEBUG TRAIN Batch 128/1800 loss 17.476528 loss_att 7.533394 loss_ctc 40.677170 loss_ctc_origin 26.852757 loss_ctc0 72.934128 lr 0.00074030 rank 0
2022-08-24 22:49:42,087 WARNING NaN or Inf found in input tensor.
2022-08-24 22:50:00,680 DEBUG TRAIN Batch 128/1900 loss 22.594496 loss_att 10.037106 loss_ctc 51.895073 loss_ctc_origin 35.771210 loss_ctc0 89.517410 lr 0.00074025 rank 0
2022-08-24 22:50:28,260 DEBUG TRAIN Batch 128/2000 loss 48.336121 loss_att 32.518635 loss_ctc 85.243591 loss_ctc_origin 54.063393 loss_ctc0 157.997375 lr 0.00074020 rank 0
2022-08-24 22:50:36,159 WARNING NaN or Inf found in input tensor.
2022-08-24 22:50:58,238 DEBUG TRAIN Batch 128/2100 loss 52.008331 loss_att 30.610458 loss_ctc 101.936691 loss_ctc_origin 55.272732 loss_ctc0 210.819244 lr 0.00074015 rank 0
2022-08-24 22:51:25,303 DEBUG TRAIN Batch 128/2200 loss 21.332083 loss_att 12.711537 loss_ctc 41.446686 loss_ctc_origin 30.556282 loss_ctc0 66.857620 lr 0.00074010 rank 0
2022-08-24 22:51:54,836 DEBUG TRAIN Batch 128/2300 loss 22.386408 loss_att 9.060990 loss_ctc 53.479046 loss_ctc_origin 38.551559 loss_ctc0 88.309845 lr 0.00074005 rank 0
2022-08-24 22:52:21,616 DEBUG TRAIN Batch 128/2400 loss 23.649590 loss_att 10.826500 loss_ctc 53.570129 loss_ctc_origin 36.767021 loss_ctc0 92.777374 lr 0.00074000 rank 0
2022-08-24 22:52:49,052 DEBUG TRAIN Batch 128/2500 loss 41.548851 loss_att 27.447121 loss_ctc 74.452896 loss_ctc_origin 46.728188 loss_ctc0 139.143890 lr 0.00073995 rank 0
2022-08-24 22:53:18,060 DEBUG TRAIN Batch 128/2600 loss 53.593895 loss_att 31.792845 loss_ctc 104.463013 loss_ctc_origin 54.770386 loss_ctc0 220.412476 lr 0.00073989 rank 0
2022-08-24 22:53:44,809 DEBUG TRAIN Batch 128/2700 loss 18.586906 loss_att 7.515573 loss_ctc 44.420021 loss_ctc_origin 31.744535 loss_ctc0 73.996155 lr 0.00073984 rank 0
2022-08-24 22:53:56,952 WARNING NaN or Inf found in input tensor.
2022-08-24 22:54:12,789 DEBUG TRAIN Batch 128/2800 loss 16.837420 loss_att 7.422537 loss_ctc 38.805477 loss_ctc_origin 25.748272 loss_ctc0 69.272285 lr 0.00073979 rank 0
2022-08-24 22:54:40,475 DEBUG TRAIN Batch 128/2900 loss 23.282539 loss_att 10.057016 loss_ctc 54.142090 loss_ctc_origin 36.512993 loss_ctc0 95.276642 lr 0.00073974 rank 0
2022-08-24 22:55:15,575 DEBUG TRAIN Batch 128/3000 loss 33.743633 loss_att 22.094719 loss_ctc 60.924431 loss_ctc_origin 34.466690 loss_ctc0 122.659157 lr 0.00073969 rank 0
2022-08-24 22:55:44,273 DEBUG TRAIN Batch 128/3100 loss 48.462425 loss_att 27.248085 loss_ctc 97.962547 loss_ctc_origin 53.290253 loss_ctc0 202.197891 lr 0.00073964 rank 0
2022-08-24 22:56:12,949 DEBUG TRAIN Batch 128/3200 loss 20.358480 loss_att 10.703899 loss_ctc 42.885834 loss_ctc_origin 30.350554 loss_ctc0 72.134819 lr 0.00073959 rank 0
2022-08-24 22:56:38,548 WARNING NaN or Inf found in input tensor.
2022-08-24 22:56:42,061 DEBUG TRAIN Batch 128/3300 loss 19.780804 loss_att 8.788584 loss_ctc 45.429317 loss_ctc_origin 32.761864 loss_ctc0 74.986710 lr 0.00073954 rank 0
2022-08-24 22:57:09,037 DEBUG TRAIN Batch 128/3400 loss 26.487232 loss_att 11.433792 loss_ctc 61.611923 loss_ctc_origin 44.234871 loss_ctc0 102.158371 lr 0.00073949 rank 0
2022-08-24 22:57:37,159 DEBUG TRAIN Batch 128/3500 loss 48.426132 loss_att 29.611794 loss_ctc 92.326256 loss_ctc_origin 55.592236 loss_ctc0 178.038956 lr 0.00073944 rank 0
2022-08-24 22:58:04,838 DEBUG TRAIN Batch 128/3600 loss 57.589783 loss_att 29.388138 loss_ctc 123.393631 loss_ctc_origin 62.102451 loss_ctc0 266.406403 lr 0.00073939 rank 0
2022-08-24 22:58:32,259 DEBUG TRAIN Batch 128/3700 loss 20.334408 loss_att 10.752165 loss_ctc 42.692970 loss_ctc_origin 31.851040 loss_ctc0 67.990807 lr 0.00073934 rank 0
2022-08-24 22:59:00,761 DEBUG TRAIN Batch 128/3800 loss 23.741077 loss_att 10.802456 loss_ctc 53.931190 loss_ctc_origin 38.938652 loss_ctc0 88.913788 lr 0.00073929 rank 0
2022-08-24 22:59:28,630 DEBUG TRAIN Batch 128/3900 loss 23.074993 loss_att 10.166418 loss_ctc 53.195000 loss_ctc_origin 35.135117 loss_ctc0 95.334732 lr 0.00073924 rank 0
2022-08-24 22:59:57,150 DEBUG TRAIN Batch 128/4000 loss 44.124611 loss_att 28.057999 loss_ctc 81.613373 loss_ctc_origin 48.823494 loss_ctc0 158.123077 lr 0.00073919 rank 0
2022-08-24 23:00:23,852 DEBUG TRAIN Batch 128/4100 loss 61.681660 loss_att 31.325777 loss_ctc 132.512054 loss_ctc_origin 71.664543 loss_ctc0 274.489563 lr 0.00073914 rank 0
2022-08-24 23:00:51,508 DEBUG TRAIN Batch 128/4200 loss 19.896233 loss_att 12.234099 loss_ctc 37.774540 loss_ctc_origin 27.738686 loss_ctc0 61.191528 lr 0.00073909 rank 0
2022-08-24 23:01:17,527 DEBUG TRAIN Batch 128/4300 loss 22.360680 loss_att 9.572891 loss_ctc 52.198853 loss_ctc_origin 38.078510 loss_ctc0 85.146324 lr 0.00073904 rank 0
2022-08-24 23:01:45,064 DEBUG TRAIN Batch 128/4400 loss 22.145329 loss_att 8.965826 loss_ctc 52.897499 loss_ctc_origin 32.899940 loss_ctc0 99.558456 lr 0.00073899 rank 0
2022-08-24 23:02:17,671 DEBUG TRAIN Batch 128/4500 loss 48.241341 loss_att 31.763935 loss_ctc 86.688622 loss_ctc_origin 57.811707 loss_ctc0 154.068085 lr 0.00073893 rank 0
2022-08-24 23:02:46,029 DEBUG TRAIN Batch 128/4600 loss 59.677406 loss_att 33.143250 loss_ctc 121.590431 loss_ctc_origin 71.695351 loss_ctc0 238.012268 lr 0.00073888 rank 0
2022-08-24 23:03:14,009 DEBUG TRAIN Batch 128/4700 loss 21.822855 loss_att 12.362495 loss_ctc 43.897026 loss_ctc_origin 34.532909 loss_ctc0 65.746635 lr 0.00073883 rank 0
2022-08-24 23:03:41,578 DEBUG TRAIN Batch 128/4800 loss 24.362034 loss_att 11.819680 loss_ctc 53.627529 loss_ctc_origin 39.681709 loss_ctc0 86.167770 lr 0.00073878 rank 0
2022-08-24 23:04:11,055 DEBUG TRAIN Batch 128/4900 loss 22.841574 loss_att 10.206985 loss_ctc 52.322277 loss_ctc_origin 38.367985 loss_ctc0 84.882286 lr 0.00073873 rank 0
2022-08-24 23:04:39,572 DEBUG TRAIN Batch 128/5000 loss 43.457893 loss_att 29.587795 loss_ctc 75.821457 loss_ctc_origin 44.430290 loss_ctc0 149.067520 lr 0.00073868 rank 0
2022-08-24 23:05:06,495 DEBUG TRAIN Batch 128/5100 loss 47.164494 loss_att 22.596264 loss_ctc 104.490356 loss_ctc_origin 50.065041 loss_ctc0 231.482727 lr 0.00073863 rank 0
2022-08-24 23:05:33,479 WARNING NaN or Inf found in input tensor.
2022-08-24 23:05:35,252 DEBUG TRAIN Batch 128/5200 loss 21.625828 loss_att 12.184857 loss_ctc 43.654762 loss_ctc_origin 33.452087 loss_ctc0 67.460999 lr 0.00073858 rank 0
2022-08-24 23:06:01,044 DEBUG TRAIN Batch 128/5300 loss 23.076344 loss_att 10.162230 loss_ctc 53.209274 loss_ctc_origin 37.571621 loss_ctc0 89.697128 lr 0.00073853 rank 0
2022-08-24 23:06:29,166 DEBUG TRAIN Batch 128/5400 loss 26.945158 loss_att 11.126041 loss_ctc 63.856430 loss_ctc_origin 45.704666 loss_ctc0 106.210541 lr 0.00073848 rank 0
2022-08-24 23:06:57,199 DEBUG TRAIN Batch 128/5500 loss 46.413895 loss_att 30.759811 loss_ctc 82.940094 loss_ctc_origin 48.155022 loss_ctc0 164.105270 lr 0.00073843 rank 0
2022-08-24 23:07:25,223 DEBUG TRAIN Batch 128/5600 loss 53.155670 loss_att 30.008636 loss_ctc 107.165405 loss_ctc_origin 59.130180 loss_ctc0 219.247589 lr 0.00073838 rank 0
2022-08-24 23:07:48,041 DEBUG CV Batch 128/0 loss 13.149914 loss_att 9.603525 loss_ctc 21.424822 loss_ctc_origin 15.703938 loss_ctc0 34.773552 history loss 12.376389 rank 0
2022-08-24 23:07:59,073 DEBUG CV Batch 128/100 loss 21.166580 loss_att 17.165257 loss_ctc 30.503006 loss_ctc_origin 20.235241 loss_ctc0 54.461128 history loss 27.149739 rank 0
2022-08-24 23:08:08,449 DEBUG CV Batch 128/200 loss 23.494919 loss_att 18.321507 loss_ctc 35.566212 loss_ctc_origin 24.324427 loss_ctc0 61.797043 history loss 28.350047 rank 0
2022-08-24 23:08:18,328 DEBUG CV Batch 128/300 loss 23.086527 loss_att 17.315517 loss_ctc 36.552216 loss_ctc_origin 21.152901 loss_ctc0 72.483948 history loss 27.462082 rank 0
2022-08-24 23:08:29,640 DEBUG CV Batch 128/400 loss 37.703491 loss_att 30.821012 loss_ctc 53.762600 loss_ctc_origin 35.566151 loss_ctc0 96.220978 history loss 25.782286 rank 0
2022-08-24 23:08:39,674 DEBUG CV Batch 128/500 loss 16.831827 loss_att 12.628340 loss_ctc 26.639965 loss_ctc_origin 19.682528 loss_ctc0 42.873989 history loss 25.443092 rank 0
2022-08-24 23:08:50,813 DEBUG CV Batch 128/600 loss 17.602348 loss_att 12.335114 loss_ctc 29.892563 loss_ctc_origin 19.322060 loss_ctc0 54.557072 history loss 25.241749 rank 0
2022-08-24 23:09:00,931 DEBUG CV Batch 128/700 loss 18.966150 loss_att 12.985092 loss_ctc 32.921951 loss_ctc_origin 19.563210 loss_ctc0 64.092346 history loss 24.886256 rank 0
2022-08-24 23:09:11,128 DEBUG CV Batch 128/800 loss 22.450043 loss_att 17.762682 loss_ctc 33.387222 loss_ctc_origin 18.012468 loss_ctc0 69.261650 history loss 24.826840 rank 0
2022-08-24 23:09:21,341 INFO Epoch 128 CV info cv_loss 24.930120207604904
2022-08-24 23:09:21,341 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/128.pt
2022-08-24 23:09:21,805 INFO Epoch 129 TRAIN info lr 0.0007383382139496432
2022-08-24 23:09:21,809 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 23:09:48,134 DEBUG TRAIN Batch 129/0 loss 43.095802 loss_att 27.562435 loss_ctc 79.340317 loss_ctc_origin 46.799938 loss_ctc0 155.267868 lr 0.00073834 rank 0
2022-08-24 23:10:16,758 DEBUG TRAIN Batch 129/100 loss 47.544292 loss_att 25.347473 loss_ctc 99.336868 loss_ctc_origin 43.294945 loss_ctc0 230.101334 lr 0.00073829 rank 0
2022-08-24 23:10:45,284 DEBUG TRAIN Batch 129/200 loss 20.373074 loss_att 10.821145 loss_ctc 42.660904 loss_ctc_origin 30.488369 loss_ctc0 71.063477 lr 0.00073824 rank 0
2022-08-24 23:11:13,045 DEBUG TRAIN Batch 129/300 loss 19.024258 loss_att 7.762296 loss_ctc 45.302162 loss_ctc_origin 30.680752 loss_ctc0 79.418785 lr 0.00073819 rank 0
2022-08-24 23:11:42,209 DEBUG TRAIN Batch 129/400 loss 28.380470 loss_att 13.486823 loss_ctc 63.132317 loss_ctc_origin 45.535938 loss_ctc0 104.190521 lr 0.00073814 rank 0
2022-08-24 23:12:10,689 DEBUG TRAIN Batch 129/500 loss 37.162849 loss_att 24.460205 loss_ctc 66.802345 loss_ctc_origin 37.432457 loss_ctc0 135.332077 lr 0.00073808 rank 0
2022-08-24 23:12:39,016 DEBUG TRAIN Batch 129/600 loss 47.837578 loss_att 26.243916 loss_ctc 98.222794 loss_ctc_origin 47.114876 loss_ctc0 217.474609 lr 0.00073803 rank 0
2022-08-24 23:13:06,815 DEBUG TRAIN Batch 129/700 loss 17.370686 loss_att 8.069790 loss_ctc 39.072777 loss_ctc_origin 27.337959 loss_ctc0 66.454010 lr 0.00073798 rank 0
2022-08-24 23:13:35,380 DEBUG TRAIN Batch 129/800 loss 19.399462 loss_att 8.281372 loss_ctc 45.341667 loss_ctc_origin 28.997757 loss_ctc0 83.477463 lr 0.00073793 rank 0
2022-08-24 23:14:03,399 DEBUG TRAIN Batch 129/900 loss 23.446716 loss_att 9.462366 loss_ctc 56.076859 loss_ctc_origin 39.123356 loss_ctc0 95.635033 lr 0.00073788 rank 0
2022-08-24 23:14:32,046 DEBUG TRAIN Batch 129/1000 loss 40.300674 loss_att 26.460127 loss_ctc 72.595291 loss_ctc_origin 44.059280 loss_ctc0 139.179321 lr 0.00073783 rank 0
2022-08-24 23:14:53,452 WARNING NaN or Inf found in input tensor.
2022-08-24 23:15:00,874 DEBUG TRAIN Batch 129/1100 loss 45.353916 loss_att 22.790754 loss_ctc 98.001289 loss_ctc_origin 53.601559 loss_ctc0 201.600647 lr 0.00073778 rank 0
2022-08-24 23:15:27,641 WARNING NaN or Inf found in input tensor.
2022-08-24 23:15:29,259 DEBUG TRAIN Batch 129/1200 loss 18.520494 loss_att 9.352836 loss_ctc 39.911697 loss_ctc_origin 29.518162 loss_ctc0 64.163277 lr 0.00073773 rank 0
2022-08-24 23:15:57,276 DEBUG TRAIN Batch 129/1300 loss 18.639736 loss_att 7.995517 loss_ctc 43.476242 loss_ctc_origin 30.724106 loss_ctc0 73.231216 lr 0.00073768 rank 0
2022-08-24 23:16:25,296 DEBUG TRAIN Batch 129/1400 loss 21.787106 loss_att 9.182673 loss_ctc 51.197449 loss_ctc_origin 33.676964 loss_ctc0 92.078583 lr 0.00073763 rank 0
2022-08-24 23:16:58,411 DEBUG TRAIN Batch 129/1500 loss 40.329987 loss_att 25.931376 loss_ctc 73.926750 loss_ctc_origin 44.885513 loss_ctc0 141.689636 lr 0.00073758 rank 0
2022-08-24 23:17:26,999 DEBUG TRAIN Batch 129/1600 loss 46.004044 loss_att 25.408087 loss_ctc 94.061279 loss_ctc_origin 48.267994 loss_ctc0 200.912277 lr 0.00073753 rank 0
2022-08-24 23:17:54,404 DEBUG TRAIN Batch 129/1700 loss 20.248188 loss_att 11.157321 loss_ctc 41.460209 loss_ctc_origin 28.842627 loss_ctc0 70.901230 lr 0.00073748 rank 0
2022-08-24 23:18:22,847 DEBUG TRAIN Batch 129/1800 loss 20.657141 loss_att 8.564190 loss_ctc 48.874023 loss_ctc_origin 35.062035 loss_ctc0 81.101990 lr 0.00073743 rank 0
2022-08-24 23:18:51,622 DEBUG TRAIN Batch 129/1900 loss 24.472441 loss_att 10.021006 loss_ctc 58.192451 loss_ctc_origin 41.417671 loss_ctc0 97.333611 lr 0.00073738 rank 0
2022-08-24 23:19:20,757 DEBUG TRAIN Batch 129/2000 loss 42.679138 loss_att 28.297010 loss_ctc 76.237427 loss_ctc_origin 54.309525 loss_ctc0 127.402527 lr 0.00073733 rank 0
2022-08-24 23:19:48,894 DEBUG TRAIN Batch 129/2100 loss 46.324265 loss_att 25.791035 loss_ctc 94.235123 loss_ctc_origin 50.094379 loss_ctc0 197.230194 lr 0.00073728 rank 0
2022-08-24 23:20:14,224 WARNING NaN or Inf found in input tensor.
2022-08-24 23:20:15,762 DEBUG TRAIN Batch 129/2200 loss 22.042618 loss_att 11.745390 loss_ctc 46.069481 loss_ctc_origin 34.670074 loss_ctc0 72.668091 lr 0.00073723 rank 0
2022-08-24 23:20:44,435 DEBUG TRAIN Batch 129/2300 loss 17.051994 loss_att 6.588398 loss_ctc 41.467049 loss_ctc_origin 26.313530 loss_ctc0 76.825264 lr 0.00073718 rank 0
2022-08-24 23:21:01,498 WARNING NaN or Inf found in input tensor.
2022-08-24 23:21:12,780 DEBUG TRAIN Batch 129/2400 loss 20.722992 loss_att 8.448606 loss_ctc 49.363220 loss_ctc_origin 30.679789 loss_ctc0 92.957886 lr 0.00073713 rank 0
2022-08-24 23:21:40,850 DEBUG TRAIN Batch 129/2500 loss 41.814461 loss_att 27.143810 loss_ctc 76.045975 loss_ctc_origin 49.101402 loss_ctc0 138.916641 lr 0.00073708 rank 0
2022-08-24 23:21:41,549 WARNING NaN or Inf found in input tensor.
2022-08-24 23:22:01,071 WARNING NaN or Inf found in input tensor.
2022-08-24 23:22:07,891 DEBUG TRAIN Batch 129/2600 loss 39.131969 loss_att 17.877771 loss_ctc 88.725090 loss_ctc_origin 46.037601 loss_ctc0 188.329224 lr 0.00073703 rank 0
2022-08-24 23:22:34,814 DEBUG TRAIN Batch 129/2700 loss 21.324478 loss_att 11.861387 loss_ctc 43.405022 loss_ctc_origin 32.987778 loss_ctc0 67.711929 lr 0.00073698 rank 0
2022-08-24 23:23:02,825 DEBUG TRAIN Batch 129/2800 loss 20.518835 loss_att 9.098855 loss_ctc 47.165451 loss_ctc_origin 31.789963 loss_ctc0 83.041588 lr 0.00073693 rank 0
2022-08-24 23:23:29,683 DEBUG TRAIN Batch 129/2900 loss 24.529957 loss_att 10.484533 loss_ctc 57.302608 loss_ctc_origin 39.749565 loss_ctc0 98.259705 lr 0.00073688 rank 0
2022-08-24 23:24:02,470 DEBUG TRAIN Batch 129/3000 loss 43.095997 loss_att 27.626492 loss_ctc 79.191513 loss_ctc_origin 47.027481 loss_ctc0 154.240936 lr 0.00073683 rank 0
2022-08-24 23:24:31,177 DEBUG TRAIN Batch 129/3100 loss 49.902390 loss_att 26.027378 loss_ctc 105.610756 loss_ctc_origin 55.162560 loss_ctc0 223.323212 lr 0.00073678 rank 0
2022-08-24 23:24:59,595 DEBUG TRAIN Batch 129/3200 loss 21.191475 loss_att 13.565474 loss_ctc 38.985474 loss_ctc_origin 28.684162 loss_ctc0 63.021866 lr 0.00073673 rank 0
2022-08-24 23:25:27,832 DEBUG TRAIN Batch 129/3300 loss 21.539549 loss_att 9.698685 loss_ctc 49.168228 loss_ctc_origin 38.333263 loss_ctc0 74.449814 lr 0.00073668 rank 0
2022-08-24 23:25:56,433 DEBUG TRAIN Batch 129/3400 loss 21.082561 loss_att 8.914156 loss_ctc 49.475502 loss_ctc_origin 32.566048 loss_ctc0 88.930893 lr 0.00073663 rank 0
2022-08-24 23:26:25,056 DEBUG TRAIN Batch 129/3500 loss 43.000847 loss_att 28.072802 loss_ctc 77.832947 loss_ctc_origin 53.169064 loss_ctc0 135.382004 lr 0.00073658 rank 0
2022-08-24 23:26:51,893 DEBUG TRAIN Batch 129/3600 loss 55.059982 loss_att 30.093279 loss_ctc 113.315620 loss_ctc_origin 57.246368 loss_ctc0 244.143860 lr 0.00073653 rank 0
2022-08-24 23:27:20,204 DEBUG TRAIN Batch 129/3700 loss 21.218634 loss_att 10.454189 loss_ctc 46.335670 loss_ctc_origin 33.304325 loss_ctc0 76.742142 lr 0.00073648 rank 0
2022-08-24 23:27:47,885 DEBUG TRAIN Batch 129/3800 loss 18.554661 loss_att 8.175932 loss_ctc 42.771690 loss_ctc_origin 29.750519 loss_ctc0 73.154419 lr 0.00073643 rank 0
2022-08-24 23:28:16,221 DEBUG TRAIN Batch 129/3900 loss 23.193157 loss_att 10.256090 loss_ctc 53.379639 loss_ctc_origin 35.048973 loss_ctc0 96.151184 lr 0.00073638 rank 0
2022-08-24 23:28:44,614 DEBUG TRAIN Batch 129/4000 loss 34.846409 loss_att 21.307968 loss_ctc 66.436096 loss_ctc_origin 36.853161 loss_ctc0 135.462952 lr 0.00073633 rank 0
2022-08-24 23:29:11,852 DEBUG TRAIN Batch 129/4100 loss 51.766754 loss_att 25.950075 loss_ctc 112.005661 loss_ctc_origin 64.353561 loss_ctc0 223.193878 lr 0.00073628 rank 0
2022-08-24 23:29:39,366 DEBUG TRAIN Batch 129/4200 loss 19.537802 loss_att 10.781661 loss_ctc 39.968796 loss_ctc_origin 28.540630 loss_ctc0 66.634521 lr 0.00073623 rank 0
2022-08-24 23:30:08,572 DEBUG TRAIN Batch 129/4300 loss 17.916374 loss_att 7.175168 loss_ctc 42.979187 loss_ctc_origin 27.753584 loss_ctc0 78.505585 lr 0.00073618 rank 0
2022-08-24 23:30:36,482 DEBUG TRAIN Batch 129/4400 loss 25.265369 loss_att 11.535975 loss_ctc 57.300625 loss_ctc_origin 38.989872 loss_ctc0 100.025711 lr 0.00073613 rank 0
2022-08-24 23:30:44,812 WARNING NaN or Inf found in input tensor.
2022-08-24 23:31:10,033 DEBUG TRAIN Batch 129/4500 loss 48.515831 loss_att 31.723267 loss_ctc 87.698486 loss_ctc_origin 60.786568 loss_ctc0 150.492950 lr 0.00073608 rank 0
2022-08-24 23:31:38,140 DEBUG TRAIN Batch 129/4600 loss 46.520126 loss_att 23.745897 loss_ctc 99.659988 loss_ctc_origin 49.365974 loss_ctc0 217.012680 lr 0.00073603 rank 0
2022-08-24 23:32:05,556 DEBUG TRAIN Batch 129/4700 loss 17.063465 loss_att 10.094925 loss_ctc 33.323395 loss_ctc_origin 23.746784 loss_ctc0 55.668816 lr 0.00073598 rank 0
2022-08-24 23:32:33,489 DEBUG TRAIN Batch 129/4800 loss 16.411535 loss_att 7.353901 loss_ctc 37.546013 loss_ctc_origin 22.869024 loss_ctc0 71.792313 lr 0.00073593 rank 0
2022-08-24 23:33:01,263 DEBUG TRAIN Batch 129/4900 loss 21.760223 loss_att 9.535300 loss_ctc 50.285042 loss_ctc_origin 32.010372 loss_ctc0 92.925941 lr 0.00073588 rank 0
2022-08-24 23:33:22,210 WARNING NaN or Inf found in input tensor.
2022-08-24 23:33:29,395 DEBUG TRAIN Batch 129/5000 loss 34.627651 loss_att 25.324436 loss_ctc 56.335152 loss_ctc_origin 31.761799 loss_ctc0 113.672958 lr 0.00073583 rank 0
2022-08-24 23:33:49,328 WARNING NaN or Inf found in input tensor.
2022-08-24 23:33:56,142 DEBUG TRAIN Batch 129/5100 loss 45.701916 loss_att 24.903929 loss_ctc 94.230545 loss_ctc_origin 51.445145 loss_ctc0 194.063141 lr 0.00073578 rank 0
2022-08-24 23:34:23,361 DEBUG TRAIN Batch 129/5200 loss 21.129108 loss_att 11.357105 loss_ctc 43.930450 loss_ctc_origin 34.439346 loss_ctc0 66.076355 lr 0.00073573 rank 0
2022-08-24 23:34:50,444 DEBUG TRAIN Batch 129/5300 loss 18.762672 loss_att 8.397321 loss_ctc 42.948490 loss_ctc_origin 28.028240 loss_ctc0 77.762405 lr 0.00073568 rank 0
2022-08-24 23:35:18,604 DEBUG TRAIN Batch 129/5400 loss 19.151363 loss_att 8.325536 loss_ctc 44.411629 loss_ctc_origin 28.315250 loss_ctc0 81.969849 lr 0.00073563 rank 0
2022-08-24 23:35:45,857 DEBUG TRAIN Batch 129/5500 loss 42.992462 loss_att 29.173094 loss_ctc 75.237656 loss_ctc_origin 43.763802 loss_ctc0 148.676651 lr 0.00073558 rank 0
2022-08-24 23:36:13,386 DEBUG TRAIN Batch 129/5600 loss 49.979477 loss_att 29.536072 loss_ctc 97.680756 loss_ctc_origin 55.818184 loss_ctc0 195.360092 lr 0.00073553 rank 0
2022-08-24 23:36:35,762 DEBUG CV Batch 129/0 loss 13.772013 loss_att 10.423697 loss_ctc 21.584751 loss_ctc_origin 16.108376 loss_ctc0 34.362961 history loss 12.961894 rank 0
2022-08-24 23:36:46,101 DEBUG CV Batch 129/100 loss 20.771301 loss_att 16.486664 loss_ctc 30.768785 loss_ctc_origin 20.776373 loss_ctc0 54.084415 history loss 27.276283 rank 0
2022-08-24 23:36:55,539 DEBUG CV Batch 129/200 loss 24.946600 loss_att 19.583109 loss_ctc 37.461414 loss_ctc_origin 26.825954 loss_ctc0 62.277489 history loss 28.221110 rank 0
2022-08-24 23:37:05,572 DEBUG CV Batch 129/300 loss 23.340746 loss_att 17.796843 loss_ctc 36.276520 loss_ctc_origin 20.782360 loss_ctc0 72.429550 history loss 27.332837 rank 0
2022-08-24 23:37:15,616 DEBUG CV Batch 129/400 loss 38.474754 loss_att 31.055027 loss_ctc 55.787460 loss_ctc_origin 38.884281 loss_ctc0 95.228210 history loss 25.652298 rank 0
2022-08-24 23:37:26,636 DEBUG CV Batch 129/500 loss 17.047922 loss_att 12.992155 loss_ctc 26.511379 loss_ctc_origin 19.505039 loss_ctc0 42.859509 history loss 25.309124 rank 0
2022-08-24 23:37:37,466 DEBUG CV Batch 129/600 loss 16.859224 loss_att 11.673655 loss_ctc 28.958885 loss_ctc_origin 18.163391 loss_ctc0 54.148369 history loss 25.105680 rank 0
2022-08-24 23:37:47,398 DEBUG CV Batch 129/700 loss 19.218876 loss_att 13.439875 loss_ctc 32.703209 loss_ctc_origin 19.396946 loss_ctc0 63.751148 history loss 24.745428 rank 0
2022-08-24 23:37:57,935 DEBUG CV Batch 129/800 loss 22.620775 loss_att 17.781528 loss_ctc 33.912350 loss_ctc_origin 18.877647 loss_ctc0 68.993317 history loss 24.688262 rank 0
2022-08-24 23:38:08,298 INFO Epoch 129 CV info cv_loss 24.772306742468125
2022-08-24 23:38:08,299 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/129.pt
2022-08-24 23:38:08,798 INFO Epoch 130 TRAIN info lr 0.0007354929694011464
2022-08-24 23:38:08,802 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-24 23:38:36,489 DEBUG TRAIN Batch 130/0 loss 42.688766 loss_att 28.567741 loss_ctc 75.637817 loss_ctc_origin 43.003342 loss_ctc0 151.784927 lr 0.00073549 rank 0
2022-08-24 23:38:44,597 WARNING NaN or Inf found in input tensor.
2022-08-24 23:39:04,854 WARNING NaN or Inf found in input tensor.
2022-08-24 23:39:04,904 DEBUG TRAIN Batch 130/100 loss nan loss_att 30.686050 loss_ctc nan loss_ctc_origin 57.054443 loss_ctc0 nan lr 0.00073544 rank 0
2022-08-24 23:39:33,327 DEBUG TRAIN Batch 130/200 loss 20.026518 loss_att 10.518086 loss_ctc 42.212856 loss_ctc_origin 32.144669 loss_ctc0 65.705292 lr 0.00073539 rank 0
2022-08-24 23:39:38,418 WARNING NaN or Inf found in input tensor.
2022-08-24 23:40:01,688 DEBUG TRAIN Batch 130/300 loss 19.907555 loss_att 7.854203 loss_ctc 48.032043 loss_ctc_origin 31.896059 loss_ctc0 85.682663 lr 0.00073534 rank 0
2022-08-24 23:40:30,618 DEBUG TRAIN Batch 130/400 loss 23.237041 loss_att 9.537296 loss_ctc 55.203110 loss_ctc_origin 36.424957 loss_ctc0 99.018799 lr 0.00073529 rank 0
2022-08-24 23:40:59,348 DEBUG TRAIN Batch 130/500 loss 43.461800 loss_att 27.640936 loss_ctc 80.377136 loss_ctc_origin 52.160637 loss_ctc0 146.215637 lr 0.00073524 rank 0
2022-08-24 23:41:27,975 DEBUG TRAIN Batch 130/600 loss 45.480797 loss_att 27.732025 loss_ctc 86.894592 loss_ctc_origin 45.116993 loss_ctc0 184.375641 lr 0.00073519 rank 0
2022-08-24 23:41:56,657 DEBUG TRAIN Batch 130/700 loss 20.057026 loss_att 11.224350 loss_ctc 40.666599 loss_ctc_origin 29.107924 loss_ctc0 67.636841 lr 0.00073514 rank 0
2022-08-24 23:42:25,755 DEBUG TRAIN Batch 130/800 loss 19.388783 loss_att 9.136887 loss_ctc 43.309875 loss_ctc_origin 29.154627 loss_ctc0 76.338783 lr 0.00073509 rank 0
2022-08-24 23:42:53,631 DEBUG TRAIN Batch 130/900 loss 21.383011 loss_att 8.859377 loss_ctc 50.604820 loss_ctc_origin 33.576096 loss_ctc0 90.338501 lr 0.00073504 rank 0
2022-08-24 23:43:21,947 DEBUG TRAIN Batch 130/1000 loss 38.964188 loss_att 22.630667 loss_ctc 77.075729 loss_ctc_origin 47.273415 loss_ctc0 146.614471 lr 0.00073499 rank 0
2022-08-24 23:43:50,273 DEBUG TRAIN Batch 130/1100 loss 45.467461 loss_att 26.571138 loss_ctc 89.558868 loss_ctc_origin 48.543602 loss_ctc0 185.261139 lr 0.00073494 rank 0
2022-08-24 23:44:18,096 DEBUG TRAIN Batch 130/1200 loss 20.206480 loss_att 10.467836 loss_ctc 42.929977 loss_ctc_origin 32.401688 loss_ctc0 67.495995 lr 0.00073489 rank 0
2022-08-24 23:44:46,514 DEBUG TRAIN Batch 130/1300 loss 19.545612 loss_att 8.643502 loss_ctc 44.983871 loss_ctc_origin 31.571247 loss_ctc0 76.279999 lr 0.00073485 rank 0
2022-08-24 23:45:14,106 DEBUG TRAIN Batch 130/1400 loss 23.953346 loss_att 11.524755 loss_ctc 52.953392 loss_ctc_origin 36.841988 loss_ctc0 90.546677 lr 0.00073480 rank 0
2022-08-24 23:45:49,371 DEBUG TRAIN Batch 130/1500 loss 42.885902 loss_att 29.767357 loss_ctc 73.495834 loss_ctc_origin 50.610199 loss_ctc0 126.895630 lr 0.00073475 rank 0
2022-08-24 23:46:17,366 DEBUG TRAIN Batch 130/1600 loss 51.276749 loss_att 28.962029 loss_ctc 103.344421 loss_ctc_origin 55.055996 loss_ctc0 216.017395 lr 0.00073470 rank 0
2022-08-24 23:46:45,744 DEBUG TRAIN Batch 130/1700 loss 17.927221 loss_att 9.257553 loss_ctc 38.156448 loss_ctc_origin 26.284784 loss_ctc0 65.856987 lr 0.00073465 rank 0
2022-08-24 23:47:14,445 DEBUG TRAIN Batch 130/1800 loss 19.969206 loss_att 8.475283 loss_ctc 46.788361 loss_ctc_origin 33.034859 loss_ctc0 78.879868 lr 0.00073460 rank 0
2022-08-24 23:47:25,492 WARNING NaN or Inf found in input tensor.
2022-08-24 23:47:37,985 WARNING NaN or Inf found in input tensor.
2022-08-24 23:47:42,625 DEBUG TRAIN Batch 130/1900 loss 23.720322 loss_att 10.323200 loss_ctc 54.980267 loss_ctc_origin 37.021740 loss_ctc0 96.883492 lr 0.00073455 rank 0
2022-08-24 23:48:11,931 DEBUG TRAIN Batch 130/2000 loss 45.040298 loss_att 31.004299 loss_ctc 77.790970 loss_ctc_origin 50.877666 loss_ctc0 140.588669 lr 0.00073450 rank 0
2022-08-24 23:48:39,368 DEBUG TRAIN Batch 130/2100 loss 50.943096 loss_att 26.143074 loss_ctc 108.809807 loss_ctc_origin 54.365990 loss_ctc0 235.845367 lr 0.00073445 rank 0
2022-08-24 23:49:05,373 WARNING NaN or Inf found in input tensor.
2022-08-24 23:49:06,807 DEBUG TRAIN Batch 130/2200 loss 22.423355 loss_att 11.175880 loss_ctc 48.667458 loss_ctc_origin 39.075111 loss_ctc0 71.049599 lr 0.00073440 rank 0
2022-08-24 23:49:34,229 DEBUG TRAIN Batch 130/2300 loss 18.514694 loss_att 7.260917 loss_ctc 44.773502 loss_ctc_origin 31.263699 loss_ctc0 76.296379 lr 0.00073435 rank 0
2022-08-24 23:50:04,073 DEBUG TRAIN Batch 130/2400 loss 23.043076 loss_att 10.594957 loss_ctc 52.088684 loss_ctc_origin 35.030598 loss_ctc0 91.890877 lr 0.00073430 rank 0
2022-08-24 23:50:19,317 WARNING NaN or Inf found in input tensor.
2022-08-24 23:50:32,060 DEBUG TRAIN Batch 130/2500 loss 50.002434 loss_att 33.465424 loss_ctc 88.588791 loss_ctc_origin 58.522179 loss_ctc0 158.744217 lr 0.00073425 rank 0
2022-08-24 23:50:59,218 DEBUG TRAIN Batch 130/2600 loss 46.887611 loss_att 25.557537 loss_ctc 96.657776 loss_ctc_origin 49.320530 loss_ctc0 207.111328 lr 0.00073420 rank 0
2022-08-24 23:51:28,661 DEBUG TRAIN Batch 130/2700 loss 18.673592 loss_att 10.774545 loss_ctc 37.104698 loss_ctc_origin 26.981876 loss_ctc0 60.724609 lr 0.00073415 rank 0
2022-08-24 23:51:55,904 DEBUG TRAIN Batch 130/2800 loss 18.466711 loss_att 7.823188 loss_ctc 43.301598 loss_ctc_origin 29.378944 loss_ctc0 75.787781 lr 0.00073410 rank 0
2022-08-24 23:52:23,045 DEBUG TRAIN Batch 130/2900 loss 21.430397 loss_att 9.211625 loss_ctc 49.940865 loss_ctc_origin 32.639626 loss_ctc0 90.310417 lr 0.00073405 rank 0
2022-08-24 23:52:56,369 DEBUG TRAIN Batch 130/3000 loss 43.927830 loss_att 30.649273 loss_ctc 74.911125 loss_ctc_origin 51.357185 loss_ctc0 129.870316 lr 0.00073400 rank 0
2022-08-24 23:53:25,102 DEBUG TRAIN Batch 130/3100 loss 44.741814 loss_att 25.660479 loss_ctc 89.264923 loss_ctc_origin 43.110397 loss_ctc0 196.958817 lr 0.00073395 rank 0
2022-08-24 23:53:52,296 DEBUG TRAIN Batch 130/3200 loss 19.745409 loss_att 11.505445 loss_ctc 38.971992 loss_ctc_origin 26.111671 loss_ctc0 68.979416 lr 0.00073390 rank 0
2022-08-24 23:54:18,984 DEBUG TRAIN Batch 130/3300 loss 22.182444 loss_att 9.882095 loss_ctc 50.883255 loss_ctc_origin 36.814125 loss_ctc0 83.711212 lr 0.00073386 rank 0
2022-08-24 23:54:46,658 DEBUG TRAIN Batch 130/3400 loss 23.973875 loss_att 10.899733 loss_ctc 54.480206 loss_ctc_origin 38.476479 loss_ctc0 91.822235 lr 0.00073381 rank 0
2022-08-24 23:55:15,101 DEBUG TRAIN Batch 130/3500 loss 42.251743 loss_att 27.545767 loss_ctc 76.565689 loss_ctc_origin 48.595409 loss_ctc0 141.829681 lr 0.00073376 rank 0
2022-08-24 23:55:35,714 WARNING NaN or Inf found in input tensor.
2022-08-24 23:55:42,849 DEBUG TRAIN Batch 130/3600 loss 43.163460 loss_att 22.081608 loss_ctc 92.354446 loss_ctc_origin 45.564651 loss_ctc0 201.530609 lr 0.00073371 rank 0
2022-08-24 23:56:10,572 DEBUG TRAIN Batch 130/3700 loss 23.469803 loss_att 14.927518 loss_ctc 43.401794 loss_ctc_origin 32.316761 loss_ctc0 69.266869 lr 0.00073366 rank 0
2022-08-24 23:56:38,218 DEBUG TRAIN Batch 130/3800 loss 19.302544 loss_att 8.319923 loss_ctc 44.928654 loss_ctc_origin 30.310902 loss_ctc0 79.036743 lr 0.00073361 rank 0
2022-08-24 23:57:06,695 DEBUG TRAIN Batch 130/3900 loss 23.167156 loss_att 10.759985 loss_ctc 52.117222 loss_ctc_origin 36.409996 loss_ctc0 88.767410 lr 0.00073356 rank 0
2022-08-24 23:57:34,859 DEBUG TRAIN Batch 130/4000 loss 41.655495 loss_att 25.255363 loss_ctc 79.922470 loss_ctc_origin 47.123619 loss_ctc0 156.453110 lr 0.00073351 rank 0
2022-08-24 23:58:03,608 DEBUG TRAIN Batch 130/4100 loss 48.346531 loss_att 27.086685 loss_ctc 97.952835 loss_ctc_origin 51.283127 loss_ctc0 206.848816 lr 0.00073346 rank 0
2022-08-24 23:58:33,476 DEBUG TRAIN Batch 130/4200 loss 16.738756 loss_att 8.418030 loss_ctc 36.153786 loss_ctc_origin 24.327511 loss_ctc0 63.748432 lr 0.00073341 rank 0
2022-08-24 23:59:01,794 DEBUG TRAIN Batch 130/4300 loss 16.837782 loss_att 7.762256 loss_ctc 38.014011 loss_ctc_origin 23.297092 loss_ctc0 72.353485 lr 0.00073336 rank 0
2022-08-24 23:59:29,104 DEBUG TRAIN Batch 130/4400 loss 20.240036 loss_att 8.355645 loss_ctc 47.970284 loss_ctc_origin 28.284946 loss_ctc0 93.902733 lr 0.00073331 rank 0
2022-08-25 00:00:05,206 DEBUG TRAIN Batch 130/4500 loss 35.018471 loss_att 22.335108 loss_ctc 64.612991 loss_ctc_origin 39.207188 loss_ctc0 123.893196 lr 0.00073326 rank 0
2022-08-25 00:00:12,826 WARNING NaN or Inf found in input tensor.
2022-08-25 00:00:33,453 DEBUG TRAIN Batch 130/4600 loss 49.140434 loss_att 27.770039 loss_ctc 99.004684 loss_ctc_origin 57.775829 loss_ctc0 195.205353 lr 0.00073321 rank 0
2022-08-25 00:01:01,599 DEBUG TRAIN Batch 130/4700 loss 23.234995 loss_att 13.292071 loss_ctc 46.435146 loss_ctc_origin 35.668411 loss_ctc0 71.557526 lr 0.00073316 rank 0
2022-08-25 00:01:30,030 DEBUG TRAIN Batch 130/4800 loss 22.181337 loss_att 9.574202 loss_ctc 51.597988 loss_ctc_origin 39.504051 loss_ctc0 79.817169 lr 0.00073312 rank 0
2022-08-25 00:01:58,846 DEBUG TRAIN Batch 130/4900 loss 19.289268 loss_att 8.158163 loss_ctc 45.261848 loss_ctc_origin 27.902952 loss_ctc0 85.765945 lr 0.00073307 rank 0
2022-08-25 00:02:28,080 DEBUG TRAIN Batch 130/5000 loss 36.027405 loss_att 22.649899 loss_ctc 67.241577 loss_ctc_origin 37.874062 loss_ctc0 135.765778 lr 0.00073302 rank 0
2022-08-25 00:02:35,703 WARNING NaN or Inf found in input tensor.
2022-08-25 00:02:56,104 DEBUG TRAIN Batch 130/5100 loss 51.270836 loss_att 31.029606 loss_ctc 98.500366 loss_ctc_origin 52.083599 loss_ctc0 206.806137 lr 0.00073297 rank 0
2022-08-25 00:03:24,000 DEBUG TRAIN Batch 130/5200 loss 17.629065 loss_att 9.277576 loss_ctc 37.115868 loss_ctc_origin 25.019480 loss_ctc0 65.340767 lr 0.00073292 rank 0
2022-08-25 00:03:51,480 DEBUG TRAIN Batch 130/5300 loss 22.529379 loss_att 10.829720 loss_ctc 49.828579 loss_ctc_origin 35.189240 loss_ctc0 83.987038 lr 0.00073287 rank 0
2022-08-25 00:04:22,128 DEBUG TRAIN Batch 130/5400 loss 23.114662 loss_att 10.333192 loss_ctc 52.938095 loss_ctc_origin 35.192070 loss_ctc0 94.345474 lr 0.00073282 rank 0
2022-08-25 00:04:50,025 DEBUG TRAIN Batch 130/5500 loss 43.063362 loss_att 28.777779 loss_ctc 76.396378 loss_ctc_origin 44.365341 loss_ctc0 151.135452 lr 0.00073277 rank 0
2022-08-25 00:05:17,833 DEBUG TRAIN Batch 130/5600 loss 44.003815 loss_att 22.958019 loss_ctc 93.110672 loss_ctc_origin 51.043816 loss_ctc0 191.266647 lr 0.00073272 rank 0
2022-08-25 00:05:41,081 DEBUG CV Batch 130/0 loss 13.485658 loss_att 10.146564 loss_ctc 21.276875 loss_ctc_origin 15.722412 loss_ctc0 34.237289 history loss 12.692384 rank 0
2022-08-25 00:05:51,590 DEBUG CV Batch 130/100 loss 20.472095 loss_att 16.269766 loss_ctc 30.277531 loss_ctc_origin 20.252739 loss_ctc0 53.668709 history loss 27.090207 rank 0
2022-08-25 00:06:01,137 DEBUG CV Batch 130/200 loss 25.106318 loss_att 19.526997 loss_ctc 38.124733 loss_ctc_origin 27.969316 loss_ctc0 61.820698 history loss 28.353390 rank 0
2022-08-25 00:06:11,070 DEBUG CV Batch 130/300 loss 23.707867 loss_att 17.855091 loss_ctc 37.364346 loss_ctc_origin 22.413326 loss_ctc0 72.250061 history loss 27.451086 rank 0
2022-08-25 00:06:22,113 DEBUG CV Batch 130/400 loss 39.258064 loss_att 32.179424 loss_ctc 55.774887 loss_ctc_origin 38.852306 loss_ctc0 95.260902 history loss 25.827280 rank 0
2022-08-25 00:06:33,270 DEBUG CV Batch 130/500 loss 17.152138 loss_att 12.726145 loss_ctc 27.479454 loss_ctc_origin 21.078632 loss_ctc0 42.414703 history loss 25.513328 rank 0
2022-08-25 00:06:43,953 DEBUG CV Batch 130/600 loss 17.607311 loss_att 12.300414 loss_ctc 29.990068 loss_ctc_origin 19.593983 loss_ctc0 54.247597 history loss 25.321557 rank 0
2022-08-25 00:06:54,565 DEBUG CV Batch 130/700 loss 18.576061 loss_att 12.792446 loss_ctc 32.071159 loss_ctc_origin 18.548508 loss_ctc0 63.624012 history loss 24.982026 rank 0
2022-08-25 00:07:05,538 DEBUG CV Batch 130/800 loss 23.320652 loss_att 18.312260 loss_ctc 35.006897 loss_ctc_origin 20.140221 loss_ctc0 69.695808 history loss 24.978322 rank 0
2022-08-25 00:07:16,247 INFO Epoch 130 CV info cv_loss 25.077247441235162
2022-08-25 00:07:16,248 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/130.pt
2022-08-25 00:07:16,739 INFO Epoch 131 TRAIN info lr 0.0007326803664815474
2022-08-25 00:07:16,742 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 00:07:43,848 DEBUG TRAIN Batch 131/0 loss 41.613716 loss_att 24.594854 loss_ctc 81.324394 loss_ctc_origin 47.501358 loss_ctc0 160.244812 lr 0.00073268 rank 0
2022-08-25 00:07:59,057 WARNING NaN or Inf found in input tensor.
2022-08-25 00:08:12,635 DEBUG TRAIN Batch 131/100 loss 47.721802 loss_att 28.586416 loss_ctc 92.371033 loss_ctc_origin 50.038097 loss_ctc0 191.147858 lr 0.00073263 rank 0
2022-08-25 00:08:41,059 DEBUG TRAIN Batch 131/200 loss 22.080484 loss_att 11.807720 loss_ctc 46.050266 loss_ctc_origin 34.415333 loss_ctc0 73.198441 lr 0.00073258 rank 0
2022-08-25 00:09:09,595 DEBUG TRAIN Batch 131/300 loss 17.598164 loss_att 7.200120 loss_ctc 41.860260 loss_ctc_origin 27.975182 loss_ctc0 74.258781 lr 0.00073253 rank 0
2022-08-25 00:09:38,401 DEBUG TRAIN Batch 131/400 loss 20.485596 loss_att 9.049383 loss_ctc 47.170090 loss_ctc_origin 30.779182 loss_ctc0 85.415543 lr 0.00073248 rank 0
2022-08-25 00:10:07,506 DEBUG TRAIN Batch 131/500 loss 42.735138 loss_att 26.424580 loss_ctc 80.793106 loss_ctc_origin 50.668495 loss_ctc0 151.083862 lr 0.00073243 rank 0
2022-08-25 00:10:34,504 DEBUG TRAIN Batch 131/600 loss 45.732174 loss_att 25.132675 loss_ctc 93.797668 loss_ctc_origin 48.353119 loss_ctc0 199.834961 lr 0.00073238 rank 0
2022-08-25 00:11:03,168 DEBUG TRAIN Batch 131/700 loss 17.573254 loss_att 9.296449 loss_ctc 36.885796 loss_ctc_origin 26.823864 loss_ctc0 60.363632 lr 0.00073233 rank 0
2022-08-25 00:11:32,166 DEBUG TRAIN Batch 131/800 loss 27.163521 loss_att 11.729599 loss_ctc 63.176003 loss_ctc_origin 48.900814 loss_ctc0 96.484779 lr 0.00073229 rank 0
2022-08-25 00:12:02,700 DEBUG TRAIN Batch 131/900 loss 22.034002 loss_att 9.426436 loss_ctc 51.451653 loss_ctc_origin 34.970261 loss_ctc0 89.908234 lr 0.00073224 rank 0
2022-08-25 00:12:29,631 DEBUG TRAIN Batch 131/1000 loss 39.523834 loss_att 25.535950 loss_ctc 72.162239 loss_ctc_origin 44.512810 loss_ctc0 136.677567 lr 0.00073219 rank 0
2022-08-25 00:12:57,917 DEBUG TRAIN Batch 131/1100 loss 45.866913 loss_att 22.494602 loss_ctc 100.402298 loss_ctc_origin 52.861591 loss_ctc0 211.330627 lr 0.00073214 rank 0
2022-08-25 00:13:27,677 DEBUG TRAIN Batch 131/1200 loss 22.724895 loss_att 14.241531 loss_ctc 42.519409 loss_ctc_origin 33.295132 loss_ctc0 64.042717 lr 0.00073209 rank 0
2022-08-25 00:13:55,453 DEBUG TRAIN Batch 131/1300 loss 19.013456 loss_att 8.214875 loss_ctc 44.210144 loss_ctc_origin 27.739498 loss_ctc0 82.641647 lr 0.00073204 rank 0
2022-08-25 00:14:23,960 DEBUG TRAIN Batch 131/1400 loss 24.736118 loss_att 10.505959 loss_ctc 57.939827 loss_ctc_origin 41.691422 loss_ctc0 95.852768 lr 0.00073199 rank 0
2022-08-25 00:14:59,125 DEBUG TRAIN Batch 131/1500 loss 40.531780 loss_att 27.961046 loss_ctc 69.863487 loss_ctc_origin 42.521645 loss_ctc0 133.661118 lr 0.00073194 rank 0
2022-08-25 00:15:27,199 DEBUG TRAIN Batch 131/1600 loss 41.716232 loss_att 20.539814 loss_ctc 91.127869 loss_ctc_origin 41.817318 loss_ctc0 206.185822 lr 0.00073189 rank 0
2022-08-25 00:15:55,443 DEBUG TRAIN Batch 131/1700 loss 19.138865 loss_att 9.671753 loss_ctc 41.228790 loss_ctc_origin 30.565208 loss_ctc0 66.110474 lr 0.00073184 rank 0
2022-08-25 00:16:23,560 DEBUG TRAIN Batch 131/1800 loss 19.672489 loss_att 8.579001 loss_ctc 45.557293 loss_ctc_origin 31.666218 loss_ctc0 77.969803 lr 0.00073180 rank 0
2022-08-25 00:16:51,482 DEBUG TRAIN Batch 131/1900 loss 19.974560 loss_att 8.208776 loss_ctc 47.428051 loss_ctc_origin 30.570465 loss_ctc0 86.762421 lr 0.00073175 rank 0
2022-08-25 00:16:54,050 WARNING NaN or Inf found in input tensor.
2022-08-25 00:17:21,029 DEBUG TRAIN Batch 131/2000 loss 47.066109 loss_att 30.232559 loss_ctc 86.344391 loss_ctc_origin 49.876015 loss_ctc0 171.437286 lr 0.00073170 rank 0
2022-08-25 00:17:48,391 DEBUG TRAIN Batch 131/2100 loss 52.865166 loss_att 30.875952 loss_ctc 104.173325 loss_ctc_origin 59.455933 loss_ctc0 208.513916 lr 0.00073165 rank 0
2022-08-25 00:18:17,615 DEBUG TRAIN Batch 131/2200 loss 19.777088 loss_att 10.978296 loss_ctc 40.307602 loss_ctc_origin 30.172050 loss_ctc0 63.957226 lr 0.00073160 rank 0
2022-08-25 00:18:45,710 DEBUG TRAIN Batch 131/2300 loss 18.348433 loss_att 7.762017 loss_ctc 43.050064 loss_ctc_origin 27.453285 loss_ctc0 79.442543 lr 0.00073155 rank 0
2022-08-25 00:19:14,033 DEBUG TRAIN Batch 131/2400 loss 19.954376 loss_att 8.144093 loss_ctc 47.511703 loss_ctc_origin 32.441982 loss_ctc0 82.674377 lr 0.00073150 rank 0
2022-08-25 00:19:42,666 DEBUG TRAIN Batch 131/2500 loss 42.032578 loss_att 27.518440 loss_ctc 75.898895 loss_ctc_origin 48.760239 loss_ctc0 139.222412 lr 0.00073145 rank 0
2022-08-25 00:20:11,738 DEBUG TRAIN Batch 131/2600 loss 49.978897 loss_att 27.347019 loss_ctc 102.786606 loss_ctc_origin 54.929604 loss_ctc0 214.452942 lr 0.00073140 rank 0
2022-08-25 00:20:39,991 DEBUG TRAIN Batch 131/2700 loss 21.475407 loss_att 11.885423 loss_ctc 43.852039 loss_ctc_origin 33.676022 loss_ctc0 67.596077 lr 0.00073135 rank 0
2022-08-25 00:21:08,084 DEBUG TRAIN Batch 131/2800 loss 17.319124 loss_att 6.366928 loss_ctc 42.874245 loss_ctc_origin 27.426167 loss_ctc0 78.919754 lr 0.00073131 rank 0
2022-08-25 00:21:36,717 DEBUG TRAIN Batch 131/2900 loss 22.930450 loss_att 9.542339 loss_ctc 54.169373 loss_ctc_origin 36.062168 loss_ctc0 96.419510 lr 0.00073126 rank 0
2022-08-25 00:22:11,913 DEBUG TRAIN Batch 131/3000 loss 32.506454 loss_att 19.192940 loss_ctc 63.571316 loss_ctc_origin 33.784370 loss_ctc0 133.074188 lr 0.00073121 rank 0
2022-08-25 00:22:39,885 DEBUG TRAIN Batch 131/3100 loss 41.287193 loss_att 19.670805 loss_ctc 91.725433 loss_ctc_origin 42.827152 loss_ctc0 205.821426 lr 0.00073116 rank 0
2022-08-25 00:23:08,072 DEBUG TRAIN Batch 131/3200 loss 19.246437 loss_att 8.689860 loss_ctc 43.878448 loss_ctc_origin 33.680553 loss_ctc0 67.673531 lr 0.00073111 rank 0
2022-08-25 00:23:36,788 DEBUG TRAIN Batch 131/3300 loss 18.799271 loss_att 7.685527 loss_ctc 44.731339 loss_ctc_origin 29.421082 loss_ctc0 80.455269 lr 0.00073106 rank 0
2022-08-25 00:23:40,511 WARNING NaN or Inf found in input tensor.
2022-08-25 00:23:59,720 WARNING NaN or Inf found in input tensor.
2022-08-25 00:24:04,137 DEBUG TRAIN Batch 131/3400 loss 23.778391 loss_att 10.351513 loss_ctc 55.107769 loss_ctc_origin 36.354530 loss_ctc0 98.865318 lr 0.00073101 rank 0
2022-08-25 00:24:33,218 DEBUG TRAIN Batch 131/3500 loss 43.460068 loss_att 29.916256 loss_ctc 75.062286 loss_ctc_origin 50.469894 loss_ctc0 132.444534 lr 0.00073096 rank 0
2022-08-25 00:25:00,863 DEBUG TRAIN Batch 131/3600 loss 53.574722 loss_att 31.400471 loss_ctc 105.314636 loss_ctc_origin 64.612427 loss_ctc0 200.286438 lr 0.00073091 rank 0
2022-08-25 00:25:28,764 DEBUG TRAIN Batch 131/3700 loss 24.378965 loss_att 14.003063 loss_ctc 48.589401 loss_ctc_origin 35.806602 loss_ctc0 78.415924 lr 0.00073087 rank 0
2022-08-25 00:25:56,785 DEBUG TRAIN Batch 131/3800 loss 18.891689 loss_att 7.903149 loss_ctc 44.531616 loss_ctc_origin 31.200886 loss_ctc0 75.636658 lr 0.00073082 rank 0
2022-08-25 00:26:24,380 DEBUG TRAIN Batch 131/3900 loss 21.888483 loss_att 9.210560 loss_ctc 51.470303 loss_ctc_origin 36.756664 loss_ctc0 85.802124 lr 0.00073077 rank 0
2022-08-25 00:26:51,818 DEBUG TRAIN Batch 131/4000 loss 38.355747 loss_att 25.509878 loss_ctc 68.329437 loss_ctc_origin 39.315880 loss_ctc0 136.027725 lr 0.00073072 rank 0
2022-08-25 00:27:20,775 DEBUG TRAIN Batch 131/4100 loss 43.571407 loss_att 24.174269 loss_ctc 88.831398 loss_ctc_origin 43.339317 loss_ctc0 194.979568 lr 0.00073067 rank 0
2022-08-25 00:27:46,856 DEBUG TRAIN Batch 131/4200 loss 21.404079 loss_att 11.526714 loss_ctc 44.451263 loss_ctc_origin 33.618198 loss_ctc0 69.728424 lr 0.00073062 rank 0
2022-08-25 00:28:16,707 DEBUG TRAIN Batch 131/4300 loss 20.234852 loss_att 9.327616 loss_ctc 45.685066 loss_ctc_origin 32.245373 loss_ctc0 77.044342 lr 0.00073057 rank 0
2022-08-25 00:28:46,002 DEBUG TRAIN Batch 131/4400 loss 21.674652 loss_att 9.144770 loss_ctc 50.911041 loss_ctc_origin 31.736431 loss_ctc0 95.651794 lr 0.00073052 rank 0
2022-08-25 00:29:22,922 DEBUG TRAIN Batch 131/4500 loss 35.691132 loss_att 22.361328 loss_ctc 66.794014 loss_ctc_origin 39.429520 loss_ctc0 130.644501 lr 0.00073048 rank 0
2022-08-25 00:29:51,958 DEBUG TRAIN Batch 131/4600 loss 49.132565 loss_att 26.650702 loss_ctc 101.590240 loss_ctc_origin 52.074764 loss_ctc0 217.126343 lr 0.00073043 rank 0
2022-08-25 00:30:19,611 DEBUG TRAIN Batch 131/4700 loss 19.646801 loss_att 9.546821 loss_ctc 43.213417 loss_ctc_origin 32.718277 loss_ctc0 67.702080 lr 0.00073038 rank 0
2022-08-25 00:30:48,063 DEBUG TRAIN Batch 131/4800 loss 18.611824 loss_att 8.401670 loss_ctc 42.435516 loss_ctc_origin 27.945633 loss_ctc0 76.245239 lr 0.00073033 rank 0
2022-08-25 00:31:16,443 DEBUG TRAIN Batch 131/4900 loss 23.122404 loss_att 9.663317 loss_ctc 54.526936 loss_ctc_origin 36.728416 loss_ctc0 96.056816 lr 0.00073028 rank 0
2022-08-25 00:31:45,165 DEBUG TRAIN Batch 131/5000 loss 36.941521 loss_att 23.379448 loss_ctc 68.586357 loss_ctc_origin 40.722267 loss_ctc0 133.602570 lr 0.00073023 rank 0
2022-08-25 00:32:13,363 DEBUG TRAIN Batch 131/5100 loss 51.538582 loss_att 28.914892 loss_ctc 104.327179 loss_ctc_origin 55.758450 loss_ctc0 217.654205 lr 0.00073018 rank 0
2022-08-25 00:32:42,062 DEBUG TRAIN Batch 131/5200 loss 21.300648 loss_att 11.626194 loss_ctc 43.874371 loss_ctc_origin 34.710526 loss_ctc0 65.256676 lr 0.00073014 rank 0
2022-08-25 00:33:10,666 DEBUG TRAIN Batch 131/5300 loss 20.986040 loss_att 9.578524 loss_ctc 47.603577 loss_ctc_origin 33.527550 loss_ctc0 80.447639 lr 0.00073009 rank 0
2022-08-25 00:33:39,242 DEBUG TRAIN Batch 131/5400 loss 23.408419 loss_att 10.599875 loss_ctc 53.295017 loss_ctc_origin 36.591927 loss_ctc0 92.268898 lr 0.00073004 rank 0
2022-08-25 00:33:41,751 WARNING NaN or Inf found in input tensor.
2022-08-25 00:34:08,017 DEBUG TRAIN Batch 131/5500 loss 49.399609 loss_att 35.322453 loss_ctc 82.246307 loss_ctc_origin 58.556396 loss_ctc0 137.522766 lr 0.00072999 rank 0
2022-08-25 00:34:36,523 DEBUG TRAIN Batch 131/5600 loss 50.845062 loss_att 27.531227 loss_ctc 105.244003 loss_ctc_origin 58.311279 loss_ctc0 214.753693 lr 0.00072994 rank 0
2022-08-25 00:34:58,493 DEBUG CV Batch 131/0 loss 12.823453 loss_att 9.312975 loss_ctc 21.014566 loss_ctc_origin 15.146204 loss_ctc0 34.707413 history loss 12.069132 rank 0
2022-08-25 00:35:09,574 DEBUG CV Batch 131/100 loss 20.932728 loss_att 16.794800 loss_ctc 30.587887 loss_ctc_origin 20.738300 loss_ctc0 53.570255 history loss 27.263895 rank 0
2022-08-25 00:35:19,371 DEBUG CV Batch 131/200 loss 25.022663 loss_att 19.125931 loss_ctc 38.781708 loss_ctc_origin 28.816643 loss_ctc0 62.033516 history loss 28.335691 rank 0
2022-08-25 00:35:29,390 DEBUG CV Batch 131/300 loss 23.680794 loss_att 17.755249 loss_ctc 37.507065 loss_ctc_origin 22.606800 loss_ctc0 72.274353 history loss 27.470972 rank 0
2022-08-25 00:35:39,855 DEBUG CV Batch 131/400 loss 39.322868 loss_att 32.010696 loss_ctc 56.384598 loss_ctc_origin 39.718781 loss_ctc0 95.271492 history loss 25.797115 rank 0
2022-08-25 00:35:50,679 DEBUG CV Batch 131/500 loss 17.107937 loss_att 12.719110 loss_ctc 27.348534 loss_ctc_origin 20.730228 loss_ctc0 42.791241 history loss 25.446683 rank 0
2022-08-25 00:36:01,564 DEBUG CV Batch 131/600 loss 17.178036 loss_att 11.807238 loss_ctc 29.709902 loss_ctc_origin 19.047863 loss_ctc0 54.587990 history loss 25.290887 rank 0
2022-08-25 00:36:11,791 DEBUG CV Batch 131/700 loss 19.087589 loss_att 13.328624 loss_ctc 32.525173 loss_ctc_origin 19.158714 loss_ctc0 63.713573 history loss 24.918783 rank 0
2022-08-25 00:36:22,426 DEBUG CV Batch 131/800 loss 22.883278 loss_att 18.032372 loss_ctc 34.202057 loss_ctc_origin 19.102552 loss_ctc0 69.434227 history loss 24.870778 rank 0
2022-08-25 00:36:32,943 INFO Epoch 131 CV info cv_loss 24.934928551633483
2022-08-25 00:36:32,943 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/131.pt
2022-08-25 00:36:33,427 INFO Epoch 132 TRAIN info lr 0.0007298997857998448
2022-08-25 00:36:33,431 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 00:37:01,214 DEBUG TRAIN Batch 132/0 loss 37.614483 loss_att 21.207092 loss_ctc 75.898399 loss_ctc_origin 40.982559 loss_ctc0 157.368698 lr 0.00072990 rank 0
2022-08-25 00:37:30,261 DEBUG TRAIN Batch 132/100 loss 50.867950 loss_att 27.618662 loss_ctc 105.116280 loss_ctc_origin 61.998077 loss_ctc0 205.725403 lr 0.00072985 rank 0
2022-08-25 00:37:56,845 WARNING NaN or Inf found in input tensor.
2022-08-25 00:37:58,518 DEBUG TRAIN Batch 132/200 loss 21.483307 loss_att 13.570957 loss_ctc 39.945457 loss_ctc_origin 29.395607 loss_ctc0 64.561768 lr 0.00072980 rank 0
2022-08-25 00:38:27,973 DEBUG TRAIN Batch 132/300 loss 18.874178 loss_att 7.235234 loss_ctc 46.031712 loss_ctc_origin 30.811047 loss_ctc0 81.546593 lr 0.00072975 rank 0
2022-08-25 00:38:56,731 DEBUG TRAIN Batch 132/400 loss 20.356922 loss_att 7.867042 loss_ctc 49.499977 loss_ctc_origin 31.761482 loss_ctc0 90.889793 lr 0.00072970 rank 0
2022-08-25 00:39:25,771 DEBUG TRAIN Batch 132/500 loss 38.679909 loss_att 25.214319 loss_ctc 70.099617 loss_ctc_origin 44.640411 loss_ctc0 129.504425 lr 0.00072965 rank 0
2022-08-25 00:39:54,959 DEBUG TRAIN Batch 132/600 loss 45.760025 loss_att 25.117443 loss_ctc 93.926041 loss_ctc_origin 48.895458 loss_ctc0 198.997375 lr 0.00072961 rank 0
2022-08-25 00:40:23,674 DEBUG TRAIN Batch 132/700 loss 23.494045 loss_att 13.587584 loss_ctc 46.609123 loss_ctc_origin 37.476307 loss_ctc0 67.919022 lr 0.00072956 rank 0
2022-08-25 00:40:52,209 DEBUG TRAIN Batch 132/800 loss 19.390705 loss_att 7.478170 loss_ctc 47.186619 loss_ctc_origin 32.467926 loss_ctc0 81.530228 lr 0.00072951 rank 0
2022-08-25 00:41:22,428 DEBUG TRAIN Batch 132/900 loss 22.334513 loss_att 9.708197 loss_ctc 51.795914 loss_ctc_origin 32.777130 loss_ctc0 96.173080 lr 0.00072946 rank 0
2022-08-25 00:41:51,355 DEBUG TRAIN Batch 132/1000 loss 35.420654 loss_att 23.110661 loss_ctc 64.143982 loss_ctc_origin 40.527000 loss_ctc0 119.250275 lr 0.00072941 rank 0
2022-08-25 00:42:20,141 DEBUG TRAIN Batch 132/1100 loss 42.688446 loss_att 22.855732 loss_ctc 88.964767 loss_ctc_origin 39.600883 loss_ctc0 204.147171 lr 0.00072936 rank 0
2022-08-25 00:42:48,582 DEBUG TRAIN Batch 132/1200 loss 23.612780 loss_att 13.276406 loss_ctc 47.730980 loss_ctc_origin 37.792152 loss_ctc0 70.921570 lr 0.00072932 rank 0
2022-08-25 00:43:18,541 DEBUG TRAIN Batch 132/1300 loss 18.456348 loss_att 7.763669 loss_ctc 43.405930 loss_ctc_origin 28.134983 loss_ctc0 79.038139 lr 0.00072927 rank 0
2022-08-25 00:43:47,446 DEBUG TRAIN Batch 132/1400 loss 24.814957 loss_att 10.861015 loss_ctc 57.374153 loss_ctc_origin 40.396183 loss_ctc0 96.989410 lr 0.00072922 rank 0
2022-08-25 00:44:22,429 DEBUG TRAIN Batch 132/1500 loss 40.883629 loss_att 25.845062 loss_ctc 75.973610 loss_ctc_origin 46.298035 loss_ctc0 145.216614 lr 0.00072917 rank 0
2022-08-25 00:44:51,539 DEBUG TRAIN Batch 132/1600 loss 47.360779 loss_att 26.918417 loss_ctc 95.059616 loss_ctc_origin 49.812675 loss_ctc0 200.635803 lr 0.00072912 rank 0
2022-08-25 00:45:18,182 WARNING NaN or Inf found in input tensor.
2022-08-25 00:45:19,782 DEBUG TRAIN Batch 132/1700 loss 20.357330 loss_att 11.236175 loss_ctc 41.640022 loss_ctc_origin 29.128811 loss_ctc0 70.832848 lr 0.00072907 rank 0
2022-08-25 00:45:49,377 DEBUG TRAIN Batch 132/1800 loss 18.514072 loss_att 7.515703 loss_ctc 44.176933 loss_ctc_origin 27.978809 loss_ctc0 81.972542 lr 0.00072902 rank 0
2022-08-25 00:46:18,084 DEBUG TRAIN Batch 132/1900 loss 23.382973 loss_att 9.652262 loss_ctc 55.421295 loss_ctc_origin 37.077164 loss_ctc0 98.224274 lr 0.00072898 rank 0
2022-08-25 00:46:47,712 DEBUG TRAIN Batch 132/2000 loss 52.665840 loss_att 32.575443 loss_ctc 99.543427 loss_ctc_origin 63.560303 loss_ctc0 183.504059 lr 0.00072893 rank 0
2022-08-25 00:47:16,685 DEBUG TRAIN Batch 132/2100 loss 53.973061 loss_att 29.738811 loss_ctc 110.519646 loss_ctc_origin 54.781628 loss_ctc0 240.575012 lr 0.00072888 rank 0
2022-08-25 00:47:37,210 WARNING NaN or Inf found in input tensor.
2022-08-25 00:47:46,395 DEBUG TRAIN Batch 132/2200 loss 20.269642 loss_att 10.808249 loss_ctc 42.346222 loss_ctc_origin 31.739616 loss_ctc0 67.094971 lr 0.00072883 rank 0
2022-08-25 00:48:14,431 DEBUG TRAIN Batch 132/2300 loss 21.608896 loss_att 10.142251 loss_ctc 48.364399 loss_ctc_origin 33.930199 loss_ctc0 82.044197 lr 0.00072878 rank 0
2022-08-25 00:48:43,279 DEBUG TRAIN Batch 132/2400 loss 22.947456 loss_att 9.407113 loss_ctc 54.541588 loss_ctc_origin 37.557045 loss_ctc0 94.172195 lr 0.00072873 rank 0
2022-08-25 00:49:12,323 DEBUG TRAIN Batch 132/2500 loss 47.320869 loss_att 31.846016 loss_ctc 83.428848 loss_ctc_origin 52.732231 loss_ctc0 155.054291 lr 0.00072869 rank 0
2022-08-25 00:49:32,865 WARNING NaN or Inf found in input tensor.
2022-08-25 00:49:39,998 DEBUG TRAIN Batch 132/2600 loss 52.867043 loss_att 29.106983 loss_ctc 108.307190 loss_ctc_origin 55.445774 loss_ctc0 231.650482 lr 0.00072864 rank 0
2022-08-25 00:50:09,622 DEBUG TRAIN Batch 132/2700 loss 20.395624 loss_att 9.413454 loss_ctc 46.020683 loss_ctc_origin 33.911461 loss_ctc0 74.275543 lr 0.00072859 rank 0
2022-08-25 00:50:37,643 DEBUG TRAIN Batch 132/2800 loss 18.873211 loss_att 8.338036 loss_ctc 43.455284 loss_ctc_origin 29.993793 loss_ctc0 74.865425 lr 0.00072854 rank 0
2022-08-25 00:51:05,209 DEBUG TRAIN Batch 132/2900 loss 22.514290 loss_att 10.040941 loss_ctc 51.618767 loss_ctc_origin 33.713734 loss_ctc0 93.397171 lr 0.00072849 rank 0
2022-08-25 00:51:39,918 DEBUG TRAIN Batch 132/3000 loss 35.329880 loss_att 19.879704 loss_ctc 71.380280 loss_ctc_origin 41.832489 loss_ctc0 140.325104 lr 0.00072844 rank 0
2022-08-25 00:52:08,893 DEBUG TRAIN Batch 132/3100 loss 52.830948 loss_att 29.408497 loss_ctc 107.483337 loss_ctc_origin 56.575584 loss_ctc0 226.268097 lr 0.00072840 rank 0
2022-08-25 00:52:21,920 WARNING NaN or Inf found in input tensor.
2022-08-25 00:52:38,941 DEBUG TRAIN Batch 132/3200 loss 18.812366 loss_att 8.711061 loss_ctc 42.382076 loss_ctc_origin 29.696194 loss_ctc0 71.982468 lr 0.00072835 rank 0
2022-08-25 00:53:06,521 DEBUG TRAIN Batch 132/3300 loss 18.373352 loss_att 8.088582 loss_ctc 42.371151 loss_ctc_origin 27.541903 loss_ctc0 76.972733 lr 0.00072830 rank 0
2022-08-25 00:53:35,069 DEBUG TRAIN Batch 132/3400 loss 23.661289 loss_att 10.392385 loss_ctc 54.622063 loss_ctc_origin 37.022232 loss_ctc0 95.688332 lr 0.00072825 rank 0
2022-08-25 00:53:38,000 WARNING NaN or Inf found in input tensor.
2022-08-25 00:54:03,477 DEBUG TRAIN Batch 132/3500 loss 37.581055 loss_att 22.699409 loss_ctc 72.304893 loss_ctc_origin 37.804695 loss_ctc0 152.805359 lr 0.00072820 rank 0
2022-08-25 00:54:31,292 DEBUG TRAIN Batch 132/3600 loss 48.899147 loss_att 24.820381 loss_ctc 105.082932 loss_ctc_origin 53.285873 loss_ctc0 225.942719 lr 0.00072815 rank 0
2022-08-25 00:54:59,587 DEBUG TRAIN Batch 132/3700 loss 18.857393 loss_att 9.117734 loss_ctc 41.583263 loss_ctc_origin 29.320356 loss_ctc0 70.196709 lr 0.00072811 rank 0
2022-08-25 00:55:27,588 DEBUG TRAIN Batch 132/3800 loss 19.285324 loss_att 7.730309 loss_ctc 46.247025 loss_ctc_origin 32.131172 loss_ctc0 79.184006 lr 0.00072806 rank 0
2022-08-25 00:55:56,575 DEBUG TRAIN Batch 132/3900 loss 23.914131 loss_att 11.164239 loss_ctc 53.663879 loss_ctc_origin 35.215034 loss_ctc0 96.711182 lr 0.00072801 rank 0
2022-08-25 00:56:26,290 DEBUG TRAIN Batch 132/4000 loss 47.252449 loss_att 31.891380 loss_ctc 83.094948 loss_ctc_origin 48.082748 loss_ctc0 164.790070 lr 0.00072796 rank 0
2022-08-25 00:56:54,158 DEBUG TRAIN Batch 132/4100 loss 50.671104 loss_att 25.358370 loss_ctc 109.734146 loss_ctc_origin 56.618729 loss_ctc0 233.670120 lr 0.00072791 rank 0
2022-08-25 00:57:22,672 DEBUG TRAIN Batch 132/4200 loss 20.789223 loss_att 9.977969 loss_ctc 46.015484 loss_ctc_origin 34.984764 loss_ctc0 71.753830 lr 0.00072786 rank 0
2022-08-25 00:57:51,045 DEBUG TRAIN Batch 132/4300 loss 21.967289 loss_att 10.278143 loss_ctc 49.241962 loss_ctc_origin 33.679073 loss_ctc0 85.555367 lr 0.00072782 rank 0
2022-08-25 00:58:18,967 DEBUG TRAIN Batch 132/4400 loss 21.870100 loss_att 9.840805 loss_ctc 49.938454 loss_ctc_origin 32.953289 loss_ctc0 89.570503 lr 0.00072777 rank 0
2022-08-25 00:58:54,335 DEBUG TRAIN Batch 132/4500 loss 47.918217 loss_att 30.392570 loss_ctc 88.811386 loss_ctc_origin 56.909119 loss_ctc0 163.250015 lr 0.00072772 rank 0
2022-08-25 00:59:23,053 DEBUG TRAIN Batch 132/4600 loss 51.363754 loss_att 29.847050 loss_ctc 101.569389 loss_ctc_origin 48.622688 loss_ctc0 225.111694 lr 0.00072767 rank 0
2022-08-25 00:59:50,851 DEBUG TRAIN Batch 132/4700 loss 19.511826 loss_att 10.300901 loss_ctc 41.003983 loss_ctc_origin 29.940130 loss_ctc0 66.819641 lr 0.00072762 rank 0
2022-08-25 01:00:19,901 DEBUG TRAIN Batch 132/4800 loss 18.902063 loss_att 8.369778 loss_ctc 43.477394 loss_ctc_origin 30.130247 loss_ctc0 74.620735 lr 0.00072758 rank 0
2022-08-25 01:00:48,787 DEBUG TRAIN Batch 132/4900 loss 22.770445 loss_att 9.671967 loss_ctc 53.333557 loss_ctc_origin 35.261505 loss_ctc0 95.501671 lr 0.00072753 rank 0
2022-08-25 01:01:16,182 DEBUG TRAIN Batch 132/5000 loss 48.401459 loss_att 31.868286 loss_ctc 86.978859 loss_ctc_origin 51.559578 loss_ctc0 169.623840 lr 0.00072748 rank 0
2022-08-25 01:01:43,305 DEBUG TRAIN Batch 132/5100 loss 51.737576 loss_att 28.390739 loss_ctc 106.213524 loss_ctc_origin 61.586845 loss_ctc0 210.342438 lr 0.00072743 rank 0
2022-08-25 01:02:12,654 DEBUG TRAIN Batch 132/5200 loss 21.824366 loss_att 13.113659 loss_ctc 42.149349 loss_ctc_origin 31.820827 loss_ctc0 66.249237 lr 0.00072738 rank 0
2022-08-25 01:02:31,045 WARNING NaN or Inf found in input tensor.
2022-08-25 01:02:41,847 DEBUG TRAIN Batch 132/5300 loss 20.335398 loss_att 9.393042 loss_ctc 45.867558 loss_ctc_origin 29.790438 loss_ctc0 83.380836 lr 0.00072734 rank 0
2022-08-25 01:03:05,547 WARNING NaN or Inf found in input tensor.
2022-08-25 01:03:10,055 DEBUG TRAIN Batch 132/5400 loss 21.769861 loss_att 9.136868 loss_ctc 51.246841 loss_ctc_origin 36.254082 loss_ctc0 86.229950 lr 0.00072729 rank 0
2022-08-25 01:03:37,822 DEBUG TRAIN Batch 132/5500 loss 46.484821 loss_att 30.083261 loss_ctc 84.755127 loss_ctc_origin 53.501770 loss_ctc0 157.679626 lr 0.00072724 rank 0
2022-08-25 01:04:04,760 DEBUG TRAIN Batch 132/5600 loss 50.518707 loss_att 25.769003 loss_ctc 108.268005 loss_ctc_origin 56.375805 loss_ctc0 229.349823 lr 0.00072719 rank 0
2022-08-25 01:04:11,783 WARNING NaN or Inf found in input tensor.
2022-08-25 01:04:27,803 DEBUG CV Batch 132/0 loss 12.502645 loss_att 9.139841 loss_ctc 20.349188 loss_ctc_origin 14.268739 loss_ctc0 34.536900 history loss 11.767196 rank 0
2022-08-25 01:04:38,767 DEBUG CV Batch 132/100 loss 21.022835 loss_att 16.844610 loss_ctc 30.772028 loss_ctc_origin 20.977999 loss_ctc0 53.624763 history loss 26.806956 rank 0
2022-08-25 01:04:48,616 DEBUG CV Batch 132/200 loss 24.955324 loss_att 19.335855 loss_ctc 38.067417 loss_ctc_origin 27.718800 loss_ctc0 62.214188 history loss 28.187137 rank 0
2022-08-25 01:04:58,429 DEBUG CV Batch 132/300 loss 22.564840 loss_att 17.004057 loss_ctc 35.540001 loss_ctc_origin 20.023661 loss_ctc0 71.744789 history loss 27.250209 rank 0
2022-08-25 01:05:08,965 DEBUG CV Batch 132/400 loss 37.710350 loss_att 30.580124 loss_ctc 54.347538 loss_ctc_origin 36.687088 loss_ctc0 95.555252 history loss 25.581772 rank 0
2022-08-25 01:05:19,067 DEBUG CV Batch 132/500 loss 16.994616 loss_att 12.526646 loss_ctc 27.419878 loss_ctc_origin 20.979071 loss_ctc0 42.448425 history loss 25.247350 rank 0
2022-08-25 01:05:29,544 DEBUG CV Batch 132/600 loss 17.700020 loss_att 12.681502 loss_ctc 29.409889 loss_ctc_origin 18.874157 loss_ctc0 53.993263 history loss 25.028545 rank 0
2022-08-25 01:05:39,616 DEBUG CV Batch 132/700 loss 20.065794 loss_att 14.086312 loss_ctc 34.017918 loss_ctc_origin 21.206470 loss_ctc0 63.911289 history loss 24.667259 rank 0
2022-08-25 01:05:49,415 DEBUG CV Batch 132/800 loss 22.142752 loss_att 17.513700 loss_ctc 32.943871 loss_ctc_origin 17.402878 loss_ctc0 69.206192 history loss 24.616126 rank 0
2022-08-25 01:05:59,576 INFO Epoch 132 CV info cv_loss 24.71368046090451
2022-08-25 01:05:59,576 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/132.pt
2022-08-25 01:06:00,044 INFO Epoch 133 TRAIN info lr 0.0007271506242956729
2022-08-25 01:06:00,048 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 01:06:27,493 DEBUG TRAIN Batch 133/0 loss 43.653210 loss_att 28.816710 loss_ctc 78.271713 loss_ctc_origin 46.670975 loss_ctc0 152.006760 lr 0.00072715 rank 0
2022-08-25 01:06:56,158 DEBUG TRAIN Batch 133/100 loss 52.915524 loss_att 28.048771 loss_ctc 110.937943 loss_ctc_origin 59.193146 loss_ctc0 231.675781 lr 0.00072710 rank 0
2022-08-25 01:07:23,740 DEBUG TRAIN Batch 133/200 loss 18.430994 loss_att 9.385624 loss_ctc 39.536858 loss_ctc_origin 29.584541 loss_ctc0 62.758919 lr 0.00072705 rank 0
2022-08-25 01:07:52,104 DEBUG TRAIN Batch 133/300 loss 19.359112 loss_att 8.429919 loss_ctc 44.860558 loss_ctc_origin 29.367632 loss_ctc0 81.010712 lr 0.00072700 rank 0
2022-08-25 01:08:21,274 DEBUG TRAIN Batch 133/400 loss 22.239449 loss_att 9.453147 loss_ctc 52.074150 loss_ctc_origin 33.082207 loss_ctc0 96.388672 lr 0.00072696 rank 0
2022-08-25 01:08:49,457 DEBUG TRAIN Batch 133/500 loss 41.026283 loss_att 26.761581 loss_ctc 74.310577 loss_ctc_origin 47.108894 loss_ctc0 137.781174 lr 0.00072691 rank 0
2022-08-25 01:09:17,710 DEBUG TRAIN Batch 133/600 loss 49.967628 loss_att 24.993975 loss_ctc 108.239479 loss_ctc_origin 53.534492 loss_ctc0 235.884445 lr 0.00072686 rank 0
2022-08-25 01:09:43,817 DEBUG TRAIN Batch 133/700 loss 19.817135 loss_att 11.473722 loss_ctc 39.285103 loss_ctc_origin 29.527447 loss_ctc0 62.052967 lr 0.00072681 rank 0
2022-08-25 01:10:11,787 DEBUG TRAIN Batch 133/800 loss 21.109285 loss_att 9.988726 loss_ctc 47.057259 loss_ctc_origin 32.182041 loss_ctc0 81.766090 lr 0.00072676 rank 0
2022-08-25 01:10:41,475 DEBUG TRAIN Batch 133/900 loss 25.095798 loss_att 10.834711 loss_ctc 58.371666 loss_ctc_origin 41.685783 loss_ctc0 97.305397 lr 0.00072672 rank 0
2022-08-25 01:11:09,842 DEBUG TRAIN Batch 133/1000 loss 41.744354 loss_att 27.030466 loss_ctc 76.076767 loss_ctc_origin 46.134735 loss_ctc0 145.941513 lr 0.00072667 rank 0
2022-08-25 01:11:37,100 DEBUG TRAIN Batch 133/1100 loss 48.002945 loss_att 26.139433 loss_ctc 99.017807 loss_ctc_origin 49.598015 loss_ctc0 214.330658 lr 0.00072662 rank 0
2022-08-25 01:12:04,778 DEBUG TRAIN Batch 133/1200 loss 21.301785 loss_att 11.621044 loss_ctc 43.890175 loss_ctc_origin 33.136471 loss_ctc0 68.982155 lr 0.00072657 rank 0
2022-08-25 01:12:32,201 DEBUG TRAIN Batch 133/1300 loss 20.492254 loss_att 8.924303 loss_ctc 47.484138 loss_ctc_origin 33.892208 loss_ctc0 79.198639 lr 0.00072652 rank 0
2022-08-25 01:13:02,743 DEBUG TRAIN Batch 133/1400 loss 22.107756 loss_att 9.235749 loss_ctc 52.142437 loss_ctc_origin 32.183762 loss_ctc0 98.712677 lr 0.00072648 rank 0
2022-08-25 01:13:34,721 DEBUG TRAIN Batch 133/1500 loss 45.657547 loss_att 32.774124 loss_ctc 75.718872 loss_ctc_origin 48.919746 loss_ctc0 138.250153 lr 0.00072643 rank 0
2022-08-25 01:14:03,452 DEBUG TRAIN Batch 133/1600 loss 48.416359 loss_att 25.707880 loss_ctc 101.402802 loss_ctc_origin 54.113747 loss_ctc0 211.743927 lr 0.00072638 rank 0
2022-08-25 01:14:31,501 DEBUG TRAIN Batch 133/1700 loss 22.159729 loss_att 12.236351 loss_ctc 45.314278 loss_ctc_origin 33.748161 loss_ctc0 72.301888 lr 0.00072633 rank 0
2022-08-25 01:14:59,504 DEBUG TRAIN Batch 133/1800 loss 17.194101 loss_att 7.287589 loss_ctc 40.309296 loss_ctc_origin 26.073578 loss_ctc0 73.525963 lr 0.00072629 rank 0
2022-08-25 01:15:28,241 DEBUG TRAIN Batch 133/1900 loss 23.377153 loss_att 10.033484 loss_ctc 54.512375 loss_ctc_origin 36.147240 loss_ctc0 97.364349 lr 0.00072624 rank 0
2022-08-25 01:15:56,514 DEBUG TRAIN Batch 133/2000 loss 42.118500 loss_att 23.827957 loss_ctc 84.796440 loss_ctc_origin 52.904182 loss_ctc0 159.211700 lr 0.00072619 rank 0
2022-08-25 01:16:24,099 DEBUG TRAIN Batch 133/2100 loss 56.857941 loss_att 33.849915 loss_ctc 110.543320 loss_ctc_origin 62.530708 loss_ctc0 222.572754 lr 0.00072614 rank 0
2022-08-25 01:16:51,402 DEBUG TRAIN Batch 133/2200 loss 22.650188 loss_att 11.863079 loss_ctc 47.820110 loss_ctc_origin 40.064827 loss_ctc0 65.915771 lr 0.00072609 rank 0
2022-08-25 01:17:19,398 DEBUG TRAIN Batch 133/2300 loss 20.471687 loss_att 9.904245 loss_ctc 45.129051 loss_ctc_origin 32.237289 loss_ctc0 75.209824 lr 0.00072605 rank 0
2022-08-25 01:17:47,737 DEBUG TRAIN Batch 133/2400 loss 23.017651 loss_att 10.471689 loss_ctc 52.291557 loss_ctc_origin 34.432323 loss_ctc0 93.963104 lr 0.00072600 rank 0
2022-08-25 01:18:17,079 DEBUG TRAIN Batch 133/2500 loss 42.419144 loss_att 26.377151 loss_ctc 79.850456 loss_ctc_origin 46.893379 loss_ctc0 156.750305 lr 0.00072595 rank 0
2022-08-25 01:18:44,036 DEBUG TRAIN Batch 133/2600 loss 52.212456 loss_att 30.515387 loss_ctc 102.838943 loss_ctc_origin 50.451378 loss_ctc0 225.076584 lr 0.00072590 rank 0
2022-08-25 01:19:11,681 DEBUG TRAIN Batch 133/2700 loss 16.749172 loss_att 7.609284 loss_ctc 38.075581 loss_ctc_origin 25.768997 loss_ctc0 66.790939 lr 0.00072585 rank 0
2022-08-25 01:19:40,015 DEBUG TRAIN Batch 133/2800 loss 22.837965 loss_att 9.748715 loss_ctc 53.379543 loss_ctc_origin 38.993904 loss_ctc0 86.946030 lr 0.00072581 rank 0
2022-08-25 01:20:08,457 DEBUG TRAIN Batch 133/2900 loss 23.949085 loss_att 9.954714 loss_ctc 56.602615 loss_ctc_origin 39.896500 loss_ctc0 95.583549 lr 0.00072576 rank 0
2022-08-25 01:20:41,733 DEBUG TRAIN Batch 133/3000 loss 46.066139 loss_att 29.270348 loss_ctc 85.256310 loss_ctc_origin 55.985367 loss_ctc0 153.555176 lr 0.00072571 rank 0
2022-08-25 01:21:10,196 DEBUG TRAIN Batch 133/3100 loss 53.016579 loss_att 29.145287 loss_ctc 108.716263 loss_ctc_origin 57.131866 loss_ctc0 229.079865 lr 0.00072566 rank 0
2022-08-25 01:21:38,075 DEBUG TRAIN Batch 133/3200 loss 22.028118 loss_att 12.063911 loss_ctc 45.277931 loss_ctc_origin 34.637966 loss_ctc0 70.104523 lr 0.00072562 rank 0
2022-08-25 01:22:05,986 DEBUG TRAIN Batch 133/3300 loss 22.306719 loss_att 11.179009 loss_ctc 48.271370 loss_ctc_origin 34.014366 loss_ctc0 81.537704 lr 0.00072557 rank 0
2022-08-25 01:22:34,121 DEBUG TRAIN Batch 133/3400 loss 22.130592 loss_att 9.278622 loss_ctc 52.118523 loss_ctc_origin 33.490677 loss_ctc0 95.583488 lr 0.00072552 rank 0
2022-08-25 01:23:01,638 DEBUG TRAIN Batch 133/3500 loss 53.698814 loss_att 36.376762 loss_ctc 94.116928 loss_ctc_origin 64.335838 loss_ctc0 163.606125 lr 0.00072547 rank 0
2022-08-25 01:23:22,251 WARNING NaN or Inf found in input tensor.
2022-08-25 01:23:29,501 DEBUG TRAIN Batch 133/3600 loss 59.526066 loss_att 34.000549 loss_ctc 119.085602 loss_ctc_origin 65.018562 loss_ctc0 245.242020 lr 0.00072542 rank 0
2022-08-25 01:23:56,915 DEBUG TRAIN Batch 133/3700 loss 18.963428 loss_att 9.933781 loss_ctc 40.032608 loss_ctc_origin 27.359390 loss_ctc0 69.603455 lr 0.00072538 rank 0
2022-08-25 01:24:23,823 DEBUG TRAIN Batch 133/3800 loss 18.804253 loss_att 7.794815 loss_ctc 44.492935 loss_ctc_origin 30.340504 loss_ctc0 77.515274 lr 0.00072533 rank 0
2022-08-25 01:24:52,259 DEBUG TRAIN Batch 133/3900 loss 25.917738 loss_att 12.051866 loss_ctc 58.271435 loss_ctc_origin 40.996727 loss_ctc0 98.579086 lr 0.00072528 rank 0
2022-08-25 01:24:55,184 WARNING NaN or Inf found in input tensor.
2022-08-25 01:25:21,579 DEBUG TRAIN Batch 133/4000 loss 53.973114 loss_att 36.297207 loss_ctc 95.216888 loss_ctc_origin 58.518192 loss_ctc0 180.847168 lr 0.00072523 rank 0
2022-08-25 01:25:48,686 DEBUG TRAIN Batch 133/4100 loss 56.268494 loss_att 31.731724 loss_ctc 113.520966 loss_ctc_origin 63.979465 loss_ctc0 229.117783 lr 0.00072519 rank 0
2022-08-25 01:26:17,155 DEBUG TRAIN Batch 133/4200 loss 21.765980 loss_att 12.919647 loss_ctc 42.407421 loss_ctc_origin 32.272099 loss_ctc0 66.056503 lr 0.00072514 rank 0
2022-08-25 01:26:45,549 DEBUG TRAIN Batch 133/4300 loss 20.598200 loss_att 8.681495 loss_ctc 48.403843 loss_ctc_origin 31.926136 loss_ctc0 86.851822 lr 0.00072509 rank 0
2022-08-25 01:27:13,151 DEBUG TRAIN Batch 133/4400 loss 23.379230 loss_att 10.072702 loss_ctc 54.427795 loss_ctc_origin 36.473923 loss_ctc0 96.320168 lr 0.00072504 rank 0
2022-08-25 01:27:47,162 DEBUG TRAIN Batch 133/4500 loss 46.422859 loss_att 30.012844 loss_ctc 84.712891 loss_ctc_origin 53.789513 loss_ctc0 156.867432 lr 0.00072500 rank 0
2022-08-25 01:28:15,866 DEBUG TRAIN Batch 133/4600 loss 52.446899 loss_att 28.914200 loss_ctc 107.356537 loss_ctc_origin 56.691830 loss_ctc0 225.574188 lr 0.00072495 rank 0
2022-08-25 01:28:43,772 DEBUG TRAIN Batch 133/4700 loss 17.671429 loss_att 9.752880 loss_ctc 36.148041 loss_ctc_origin 25.944714 loss_ctc0 59.955795 lr 0.00072490 rank 0
2022-08-25 01:29:12,313 DEBUG TRAIN Batch 133/4800 loss 21.870741 loss_att 9.870604 loss_ctc 49.871059 loss_ctc_origin 35.899536 loss_ctc0 82.471275 lr 0.00072485 rank 0
2022-08-25 01:29:40,212 DEBUG TRAIN Batch 133/4900 loss 21.092403 loss_att 8.973257 loss_ctc 49.370407 loss_ctc_origin 32.817665 loss_ctc0 87.993469 lr 0.00072481 rank 0
2022-08-25 01:30:09,234 DEBUG TRAIN Batch 133/5000 loss 50.955147 loss_att 34.747311 loss_ctc 88.773438 loss_ctc_origin 56.096413 loss_ctc0 165.019836 lr 0.00072476 rank 0
2022-08-25 01:30:37,183 DEBUG TRAIN Batch 133/5100 loss 54.620975 loss_att 28.728676 loss_ctc 115.036331 loss_ctc_origin 61.206039 loss_ctc0 240.640350 lr 0.00072471 rank 0
2022-08-25 01:31:05,507 DEBUG TRAIN Batch 133/5200 loss 21.353355 loss_att 13.557575 loss_ctc 39.543507 loss_ctc_origin 29.809719 loss_ctc0 62.255676 lr 0.00072466 rank 0
2022-08-25 01:31:35,728 DEBUG TRAIN Batch 133/5300 loss 18.557610 loss_att 8.081945 loss_ctc 43.000824 loss_ctc_origin 29.870876 loss_ctc0 73.637375 lr 0.00072461 rank 0
2022-08-25 01:32:04,794 DEBUG TRAIN Batch 133/5400 loss 27.411259 loss_att 12.849706 loss_ctc 61.388214 loss_ctc_origin 45.276234 loss_ctc0 98.982826 lr 0.00072457 rank 0
2022-08-25 01:32:30,773 DEBUG TRAIN Batch 133/5500 loss 46.020851 loss_att 27.553314 loss_ctc 89.111763 loss_ctc_origin 56.075531 loss_ctc0 166.196289 lr 0.00072452 rank 0
2022-08-25 01:32:58,961 DEBUG TRAIN Batch 133/5600 loss 49.036049 loss_att 25.460072 loss_ctc 104.046661 loss_ctc_origin 42.428856 loss_ctc0 247.821533 lr 0.00072447 rank 0
2022-08-25 01:33:23,247 DEBUG CV Batch 133/0 loss 13.575420 loss_att 10.312416 loss_ctc 21.189095 loss_ctc_origin 15.441934 loss_ctc0 34.599136 history loss 12.776866 rank 0
2022-08-25 01:33:33,598 DEBUG CV Batch 133/100 loss 22.007032 loss_att 17.796051 loss_ctc 31.832657 loss_ctc_origin 22.400879 loss_ctc0 53.840137 history loss 27.012253 rank 0
2022-08-25 01:33:43,179 DEBUG CV Batch 133/200 loss 25.020248 loss_att 19.378284 loss_ctc 38.184830 loss_ctc_origin 28.254478 loss_ctc0 61.355644 history loss 28.123219 rank 0
2022-08-25 01:33:53,044 DEBUG CV Batch 133/300 loss 23.775028 loss_att 18.283474 loss_ctc 36.588654 loss_ctc_origin 21.518188 loss_ctc0 71.753067 history loss 27.161746 rank 0
2022-08-25 01:34:03,444 DEBUG CV Batch 133/400 loss 37.996872 loss_att 30.635292 loss_ctc 55.173897 loss_ctc_origin 38.381260 loss_ctc0 94.356705 history loss 25.494971 rank 0
2022-08-25 01:34:14,061 DEBUG CV Batch 133/500 loss 17.519531 loss_att 13.012575 loss_ctc 28.035759 loss_ctc_origin 21.764511 loss_ctc0 42.668671 history loss 25.171407 rank 0
2022-08-25 01:34:24,721 DEBUG CV Batch 133/600 loss 17.291204 loss_att 12.298705 loss_ctc 28.940367 loss_ctc_origin 18.267384 loss_ctc0 53.843994 history loss 25.004385 rank 0
2022-08-25 01:34:34,788 DEBUG CV Batch 133/700 loss 18.078194 loss_att 12.129290 loss_ctc 31.958969 loss_ctc_origin 18.337128 loss_ctc0 63.743267 history loss 24.638998 rank 0
2022-08-25 01:34:45,095 DEBUG CV Batch 133/800 loss 22.012716 loss_att 17.429001 loss_ctc 32.708054 loss_ctc_origin 17.026260 loss_ctc0 69.298904 history loss 24.586667 rank 0
2022-08-25 01:34:55,291 INFO Epoch 133 CV info cv_loss 24.66766233451536
2022-08-25 01:34:55,291 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/133.pt
2022-08-25 01:34:55,737 INFO Epoch 134 TRAIN info lr 0.0007244322946898521
2022-08-25 01:34:55,740 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 01:35:21,818 DEBUG TRAIN Batch 134/0 loss 45.818176 loss_att 27.682779 loss_ctc 88.134102 loss_ctc_origin 54.538200 loss_ctc0 166.524536 lr 0.00072443 rank 0
2022-08-25 01:35:50,844 DEBUG TRAIN Batch 134/100 loss 50.573071 loss_att 25.531610 loss_ctc 109.003136 loss_ctc_origin 51.337173 loss_ctc0 243.557037 lr 0.00072438 rank 0
2022-08-25 01:36:18,434 DEBUG TRAIN Batch 134/200 loss 18.408020 loss_att 10.493703 loss_ctc 36.874756 loss_ctc_origin 25.090857 loss_ctc0 64.370522 lr 0.00072434 rank 0
2022-08-25 01:36:46,472 DEBUG TRAIN Batch 134/300 loss 20.777092 loss_att 10.300207 loss_ctc 45.223152 loss_ctc_origin 30.721577 loss_ctc0 79.060165 lr 0.00072429 rank 0
2022-08-25 01:37:14,955 DEBUG TRAIN Batch 134/400 loss 22.682896 loss_att 10.311043 loss_ctc 51.550549 loss_ctc_origin 34.780521 loss_ctc0 90.680611 lr 0.00072424 rank 0
2022-08-25 01:37:43,102 DEBUG TRAIN Batch 134/500 loss 46.135742 loss_att 29.436230 loss_ctc 85.101273 loss_ctc_origin 57.068569 loss_ctc0 150.510910 lr 0.00072419 rank 0
2022-08-25 01:38:10,576 DEBUG TRAIN Batch 134/600 loss 48.032104 loss_att 23.305342 loss_ctc 105.727875 loss_ctc_origin 53.214684 loss_ctc0 228.258636 lr 0.00072415 rank 0
2022-08-25 01:38:39,568 DEBUG TRAIN Batch 134/700 loss 21.430920 loss_att 11.721308 loss_ctc 44.086678 loss_ctc_origin 31.437870 loss_ctc0 73.600555 lr 0.00072410 rank 0
2022-08-25 01:39:06,530 DEBUG TRAIN Batch 134/800 loss 19.417187 loss_att 8.049634 loss_ctc 45.941471 loss_ctc_origin 33.732189 loss_ctc0 74.429794 lr 0.00072405 rank 0
2022-08-25 01:39:34,346 DEBUG TRAIN Batch 134/900 loss 22.971260 loss_att 8.902377 loss_ctc 55.798653 loss_ctc_origin 36.993835 loss_ctc0 99.676559 lr 0.00072400 rank 0
2022-08-25 01:40:02,914 DEBUG TRAIN Batch 134/1000 loss 41.691971 loss_att 25.242920 loss_ctc 80.073090 loss_ctc_origin 44.325481 loss_ctc0 163.484177 lr 0.00072396 rank 0
2022-08-25 01:40:31,924 DEBUG TRAIN Batch 134/1100 loss 51.310455 loss_att 27.378471 loss_ctc 107.151749 loss_ctc_origin 51.698853 loss_ctc0 236.541840 lr 0.00072391 rank 0
2022-08-25 01:41:00,260 DEBUG TRAIN Batch 134/1200 loss 17.807323 loss_att 9.608870 loss_ctc 36.937050 loss_ctc_origin 24.942202 loss_ctc0 64.925026 lr 0.00072386 rank 0
2022-08-25 01:41:28,758 DEBUG TRAIN Batch 134/1300 loss 19.476494 loss_att 8.162608 loss_ctc 45.875561 loss_ctc_origin 29.551693 loss_ctc0 83.964584 lr 0.00072381 rank 0
2022-08-25 01:41:59,473 DEBUG TRAIN Batch 134/1400 loss 22.829094 loss_att 10.368463 loss_ctc 51.903896 loss_ctc_origin 37.190075 loss_ctc0 86.236145 lr 0.00072377 rank 0
2022-08-25 01:42:31,394 DEBUG TRAIN Batch 134/1500 loss 33.809437 loss_att 22.834820 loss_ctc 59.416878 loss_ctc_origin 37.582413 loss_ctc0 110.363968 lr 0.00072372 rank 0
2022-08-25 01:42:59,999 DEBUG TRAIN Batch 134/1600 loss 44.919159 loss_att 26.394691 loss_ctc 88.142914 loss_ctc_origin 51.356705 loss_ctc0 173.977386 lr 0.00072367 rank 0
2022-08-25 01:43:27,656 DEBUG TRAIN Batch 134/1700 loss 20.441147 loss_att 10.655731 loss_ctc 43.273781 loss_ctc_origin 32.458401 loss_ctc0 68.509674 lr 0.00072362 rank 0
2022-08-25 01:43:55,882 DEBUG TRAIN Batch 134/1800 loss 22.375080 loss_att 9.158917 loss_ctc 53.212791 loss_ctc_origin 39.516300 loss_ctc0 85.171265 lr 0.00072358 rank 0
2022-08-25 01:44:24,051 DEBUG TRAIN Batch 134/1900 loss 22.859148 loss_att 9.413313 loss_ctc 54.232758 loss_ctc_origin 35.761703 loss_ctc0 97.331886 lr 0.00072353 rank 0
2022-08-25 01:44:53,189 DEBUG TRAIN Batch 134/2000 loss 40.031807 loss_att 25.173449 loss_ctc 74.701309 loss_ctc_origin 39.242458 loss_ctc0 157.438629 lr 0.00072348 rank 0
2022-08-25 01:45:21,142 DEBUG TRAIN Batch 134/2100 loss 45.423965 loss_att 21.542004 loss_ctc 101.148544 loss_ctc_origin 48.840023 loss_ctc0 223.201736 lr 0.00072343 rank 0
2022-08-25 01:45:47,962 DEBUG TRAIN Batch 134/2200 loss 20.146338 loss_att 10.045591 loss_ctc 43.714745 loss_ctc_origin 31.720409 loss_ctc0 71.701530 lr 0.00072339 rank 0
2022-08-25 01:46:16,183 DEBUG TRAIN Batch 134/2300 loss 19.828697 loss_att 9.444918 loss_ctc 44.057518 loss_ctc_origin 29.591522 loss_ctc0 77.811501 lr 0.00072334 rank 0
2022-08-25 01:46:45,575 DEBUG TRAIN Batch 134/2400 loss 21.181068 loss_att 9.426970 loss_ctc 48.607300 loss_ctc_origin 32.049664 loss_ctc0 87.241776 lr 0.00072329 rank 0
2022-08-25 01:47:13,243 DEBUG TRAIN Batch 134/2500 loss 43.620087 loss_att 28.049995 loss_ctc 79.950294 loss_ctc_origin 48.458023 loss_ctc0 153.432251 lr 0.00072325 rank 0
2022-08-25 01:47:42,709 DEBUG TRAIN Batch 134/2600 loss 53.087006 loss_att 31.160736 loss_ctc 104.248299 loss_ctc_origin 55.057320 loss_ctc0 219.027252 lr 0.00072320 rank 0
2022-08-25 01:48:11,134 DEBUG TRAIN Batch 134/2700 loss 21.430210 loss_att 12.192415 loss_ctc 42.985065 loss_ctc_origin 30.504087 loss_ctc0 72.107346 lr 0.00072315 rank 0
2022-08-25 01:48:40,030 DEBUG TRAIN Batch 134/2800 loss 21.368189 loss_att 9.556804 loss_ctc 48.928085 loss_ctc_origin 31.414509 loss_ctc0 89.793091 lr 0.00072310 rank 0
2022-08-25 01:49:07,925 DEBUG TRAIN Batch 134/2900 loss 26.044197 loss_att 11.930505 loss_ctc 58.976139 loss_ctc_origin 40.005608 loss_ctc0 103.240707 lr 0.00072306 rank 0
2022-08-25 01:49:43,304 DEBUG TRAIN Batch 134/3000 loss 37.159878 loss_att 24.464071 loss_ctc 66.783424 loss_ctc_origin 37.492271 loss_ctc0 135.129456 lr 0.00072301 rank 0
2022-08-25 01:50:12,023 DEBUG TRAIN Batch 134/3100 loss 62.901413 loss_att 39.277985 loss_ctc 118.022751 loss_ctc_origin 66.489304 loss_ctc0 238.267456 lr 0.00072296 rank 0
2022-08-25 01:50:40,428 DEBUG TRAIN Batch 134/3200 loss 20.015181 loss_att 9.523006 loss_ctc 44.496918 loss_ctc_origin 33.606716 loss_ctc0 69.907394 lr 0.00072291 rank 0
2022-08-25 01:51:08,337 DEBUG TRAIN Batch 134/3300 loss 18.103489 loss_att 7.420763 loss_ctc 43.029850 loss_ctc_origin 26.422279 loss_ctc0 81.780846 lr 0.00072287 rank 0
2022-08-25 01:51:37,026 DEBUG TRAIN Batch 134/3400 loss 26.260540 loss_att 12.174444 loss_ctc 59.128098 loss_ctc_origin 40.786968 loss_ctc0 101.924057 lr 0.00072282 rank 0
2022-08-25 01:52:06,088 DEBUG TRAIN Batch 134/3500 loss 45.641090 loss_att 29.407822 loss_ctc 83.518723 loss_ctc_origin 47.784821 loss_ctc0 166.897827 lr 0.00072277 rank 0
2022-08-25 01:52:34,266 DEBUG TRAIN Batch 134/3600 loss 50.172050 loss_att 26.228952 loss_ctc 106.039284 loss_ctc_origin 50.901173 loss_ctc0 234.694855 lr 0.00072273 rank 0
2022-08-25 01:53:02,086 DEBUG TRAIN Batch 134/3700 loss 22.947250 loss_att 15.217765 loss_ctc 40.982712 loss_ctc_origin 31.670315 loss_ctc0 62.711632 lr 0.00072268 rank 0
2022-08-25 01:53:31,184 DEBUG TRAIN Batch 134/3800 loss 20.034533 loss_att 8.332724 loss_ctc 47.338753 loss_ctc_origin 35.718765 loss_ctc0 74.452057 lr 0.00072263 rank 0
2022-08-25 01:53:58,990 DEBUG TRAIN Batch 134/3900 loss 17.314318 loss_att 7.296189 loss_ctc 40.689949 loss_ctc_origin 23.784073 loss_ctc0 80.136986 lr 0.00072258 rank 0
2022-08-25 01:54:27,628 DEBUG TRAIN Batch 134/4000 loss 39.754097 loss_att 23.500095 loss_ctc 77.680099 loss_ctc_origin 42.350723 loss_ctc0 160.115295 lr 0.00072254 rank 0
2022-08-25 01:54:55,983 DEBUG TRAIN Batch 134/4100 loss 48.679001 loss_att 23.786659 loss_ctc 106.761131 loss_ctc_origin 49.845070 loss_ctc0 239.565262 lr 0.00072249 rank 0
2022-08-25 01:55:15,632 WARNING NaN or Inf found in input tensor.
2022-08-25 01:55:24,693 DEBUG TRAIN Batch 134/4200 loss 18.052635 loss_att 10.476216 loss_ctc 35.730942 loss_ctc_origin 24.819313 loss_ctc0 61.191418 lr 0.00072244 rank 0
2022-08-25 01:55:52,558 DEBUG TRAIN Batch 134/4300 loss 20.136116 loss_att 8.792937 loss_ctc 46.603531 loss_ctc_origin 31.792820 loss_ctc0 81.161850 lr 0.00072240 rank 0
2022-08-25 01:56:21,064 DEBUG TRAIN Batch 134/4400 loss 22.962145 loss_att 10.173421 loss_ctc 52.802498 loss_ctc_origin 35.754791 loss_ctc0 92.580475 lr 0.00072235 rank 0
2022-08-25 01:56:54,088 DEBUG TRAIN Batch 134/4500 loss 42.090118 loss_att 27.425335 loss_ctc 76.307938 loss_ctc_origin 47.404564 loss_ctc0 143.749146 lr 0.00072230 rank 0
2022-08-25 01:57:22,642 DEBUG TRAIN Batch 134/4600 loss 49.929657 loss_att 26.248764 loss_ctc 105.185066 loss_ctc_origin 53.816803 loss_ctc0 225.044342 lr 0.00072225 rank 0
2022-08-25 01:57:50,632 DEBUG TRAIN Batch 134/4700 loss 18.048397 loss_att 8.655756 loss_ctc 39.964561 loss_ctc_origin 27.482592 loss_ctc0 69.089149 lr 0.00072221 rank 0
2022-08-25 01:58:18,784 DEBUG TRAIN Batch 134/4800 loss 18.393955 loss_att 8.081675 loss_ctc 42.455940 loss_ctc_origin 27.101830 loss_ctc0 78.282188 lr 0.00072216 rank 0
2022-08-25 01:58:47,128 DEBUG TRAIN Batch 134/4900 loss 23.211777 loss_att 10.747745 loss_ctc 52.294518 loss_ctc_origin 35.186493 loss_ctc0 92.213234 lr 0.00072211 rank 0
2022-08-25 01:59:16,738 DEBUG TRAIN Batch 134/5000 loss 34.896233 loss_att 20.718853 loss_ctc 67.976776 loss_ctc_origin 34.331055 loss_ctc0 146.483459 lr 0.00072207 rank 0
2022-08-25 01:59:46,119 DEBUG TRAIN Batch 134/5100 loss 51.458000 loss_att 25.662081 loss_ctc 111.648468 loss_ctc_origin 62.698277 loss_ctc0 225.865570 lr 0.00072202 rank 0
2022-08-25 02:00:15,565 DEBUG TRAIN Batch 134/5200 loss 20.984684 loss_att 11.739349 loss_ctc 42.557129 loss_ctc_origin 32.395519 loss_ctc0 66.267555 lr 0.00072197 rank 0
2022-08-25 02:00:43,578 DEBUG TRAIN Batch 134/5300 loss 22.090410 loss_att 10.778556 loss_ctc 48.484737 loss_ctc_origin 34.660904 loss_ctc0 80.740349 lr 0.00072192 rank 0
2022-08-25 02:01:07,654 WARNING NaN or Inf found in input tensor.
2022-08-25 02:01:12,017 DEBUG TRAIN Batch 134/5400 loss 21.993010 loss_att 9.011703 loss_ctc 52.282722 loss_ctc_origin 32.864407 loss_ctc0 97.592117 lr 0.00072188 rank 0
2022-08-25 02:01:41,607 DEBUG TRAIN Batch 134/5500 loss 45.385815 loss_att 29.378042 loss_ctc 82.737282 loss_ctc_origin 45.179790 loss_ctc0 170.371429 lr 0.00072183 rank 0
2022-08-25 02:02:08,468 DEBUG TRAIN Batch 134/5600 loss 57.846165 loss_att 31.072142 loss_ctc 120.318878 loss_ctc_origin 62.688107 loss_ctc0 254.790665 lr 0.00072178 rank 0
2022-08-25 02:02:30,721 DEBUG CV Batch 134/0 loss 11.268229 loss_att 8.109291 loss_ctc 18.639084 loss_ctc_origin 12.147980 loss_ctc0 33.784996 history loss 10.605392 rank 0
2022-08-25 02:02:41,274 DEBUG CV Batch 134/100 loss 20.862232 loss_att 16.506691 loss_ctc 31.025162 loss_ctc_origin 21.513302 loss_ctc0 53.219498 history loss 26.462532 rank 0
2022-08-25 02:02:51,005 DEBUG CV Batch 134/200 loss 24.737514 loss_att 19.166733 loss_ctc 37.736000 loss_ctc_origin 27.304226 loss_ctc0 62.076805 history loss 27.973994 rank 0
2022-08-25 02:03:00,405 DEBUG CV Batch 134/300 loss 23.527910 loss_att 18.213810 loss_ctc 35.927475 loss_ctc_origin 20.637903 loss_ctc0 71.603134 history loss 27.088271 rank 0
2022-08-25 02:03:10,590 DEBUG CV Batch 134/400 loss 38.692268 loss_att 31.726395 loss_ctc 54.945976 loss_ctc_origin 37.567295 loss_ctc0 95.496239 history loss 25.501263 rank 0
2022-08-25 02:03:21,178 DEBUG CV Batch 134/500 loss 17.659899 loss_att 13.180490 loss_ctc 28.111851 loss_ctc_origin 22.009617 loss_ctc0 42.350399 history loss 25.160514 rank 0
2022-08-25 02:03:31,434 DEBUG CV Batch 134/600 loss 17.769482 loss_att 12.627457 loss_ctc 29.767540 loss_ctc_origin 19.344183 loss_ctc0 54.088707 history loss 24.947342 rank 0
2022-08-25 02:03:41,154 DEBUG CV Batch 134/700 loss 19.510288 loss_att 13.744875 loss_ctc 32.962917 loss_ctc_origin 19.524754 loss_ctc0 64.318634 history loss 24.637416 rank 0
2022-08-25 02:03:51,393 DEBUG CV Batch 134/800 loss 22.901272 loss_att 18.384958 loss_ctc 33.439335 loss_ctc_origin 17.767380 loss_ctc0 70.007233 history loss 24.605389 rank 0
2022-08-25 02:04:01,411 INFO Epoch 134 CV info cv_loss 24.712958591418847
2022-08-25 02:04:01,411 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/134.pt
2022-08-25 02:04:01,988 INFO Epoch 135 TRAIN info lr 0.0007217442249573677
2022-08-25 02:04:01,992 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 02:04:28,304 DEBUG TRAIN Batch 135/0 loss 38.927139 loss_att 23.014189 loss_ctc 76.057358 loss_ctc_origin 40.981571 loss_ctc0 157.900848 lr 0.00072174 rank 0
2022-08-25 02:04:55,855 DEBUG TRAIN Batch 135/100 loss 50.642982 loss_att 25.783411 loss_ctc 108.648636 loss_ctc_origin 51.132416 loss_ctc0 242.853119 lr 0.00072170 rank 0
2022-08-25 02:05:23,246 DEBUG TRAIN Batch 135/200 loss 18.977579 loss_att 9.389894 loss_ctc 41.348839 loss_ctc_origin 29.013714 loss_ctc0 70.130791 lr 0.00072165 rank 0
2022-08-25 02:05:28,835 WARNING NaN or Inf found in input tensor.
2022-08-25 02:05:50,994 DEBUG TRAIN Batch 135/300 loss 20.479984 loss_att 8.402441 loss_ctc 48.660919 loss_ctc_origin 33.003078 loss_ctc0 85.195877 lr 0.00072160 rank 0
2022-08-25 02:06:18,376 DEBUG TRAIN Batch 135/400 loss 22.986336 loss_att 10.184278 loss_ctc 52.857803 loss_ctc_origin 33.864037 loss_ctc0 97.176590 lr 0.00072155 rank 0
2022-08-25 02:06:46,192 DEBUG TRAIN Batch 135/500 loss 47.557224 loss_att 30.720951 loss_ctc 86.841858 loss_ctc_origin 52.038261 loss_ctc0 168.050247 lr 0.00072151 rank 0
2022-08-25 02:07:12,663 DEBUG TRAIN Batch 135/600 loss 56.420784 loss_att 30.735174 loss_ctc 116.353874 loss_ctc_origin 54.995644 loss_ctc0 259.523071 lr 0.00072146 rank 0
2022-08-25 02:07:40,573 DEBUG TRAIN Batch 135/700 loss 19.780365 loss_att 9.392660 loss_ctc 44.018341 loss_ctc_origin 31.581373 loss_ctc0 73.037933 lr 0.00072141 rank 0
2022-08-25 02:08:08,034 DEBUG TRAIN Batch 135/800 loss 23.372112 loss_att 10.337127 loss_ctc 53.787079 loss_ctc_origin 39.193886 loss_ctc0 87.837852 lr 0.00072137 rank 0
2022-08-25 02:08:35,832 DEBUG TRAIN Batch 135/900 loss 23.890028 loss_att 9.754834 loss_ctc 56.872143 loss_ctc_origin 36.937790 loss_ctc0 103.385628 lr 0.00072132 rank 0
2022-08-25 02:09:02,321 DEBUG TRAIN Batch 135/1000 loss 42.978733 loss_att 24.555595 loss_ctc 85.966049 loss_ctc_origin 47.911816 loss_ctc0 174.759247 lr 0.00072127 rank 0
2022-08-25 02:09:30,028 DEBUG TRAIN Batch 135/1100 loss 54.977562 loss_att 30.990948 loss_ctc 110.946320 loss_ctc_origin 59.427532 loss_ctc0 231.156799 lr 0.00072123 rank 0
2022-08-25 02:09:59,071 DEBUG TRAIN Batch 135/1200 loss 18.608564 loss_att 10.846551 loss_ctc 36.719929 loss_ctc_origin 26.009209 loss_ctc0 61.711609 lr 0.00072118 rank 0
2022-08-25 02:10:26,168 DEBUG TRAIN Batch 135/1300 loss 22.839996 loss_att 9.400873 loss_ctc 54.197945 loss_ctc_origin 41.195694 loss_ctc0 84.536530 lr 0.00072113 rank 0
2022-08-25 02:10:53,381 DEBUG TRAIN Batch 135/1400 loss 22.451080 loss_att 9.624650 loss_ctc 52.379417 loss_ctc_origin 33.647049 loss_ctc0 96.088272 lr 0.00072109 rank 0
2022-08-25 02:11:26,743 DEBUG TRAIN Batch 135/1500 loss 45.252766 loss_att 30.182873 loss_ctc 80.415848 loss_ctc_origin 45.462654 loss_ctc0 161.973297 lr 0.00072104 rank 0
2022-08-25 02:11:54,510 DEBUG TRAIN Batch 135/1600 loss 49.084797 loss_att 24.028496 loss_ctc 107.549500 loss_ctc_origin 49.795437 loss_ctc0 242.308975 lr 0.00072099 rank 0
2022-08-25 02:12:22,127 DEBUG TRAIN Batch 135/1700 loss 15.502949 loss_att 7.579626 loss_ctc 33.990704 loss_ctc_origin 22.244114 loss_ctc0 61.399414 lr 0.00072094 rank 0
2022-08-25 02:12:50,328 DEBUG TRAIN Batch 135/1800 loss 19.428354 loss_att 7.679628 loss_ctc 46.842049 loss_ctc_origin 31.834362 loss_ctc0 81.859970 lr 0.00072090 rank 0
2022-08-25 02:13:18,090 DEBUG TRAIN Batch 135/1900 loss 23.742191 loss_att 10.801844 loss_ctc 53.936333 loss_ctc_origin 37.912514 loss_ctc0 91.325233 lr 0.00072085 rank 0
2022-08-25 02:13:46,915 DEBUG TRAIN Batch 135/2000 loss 45.685646 loss_att 29.606237 loss_ctc 83.204269 loss_ctc_origin 46.554558 loss_ctc0 168.720245 lr 0.00072080 rank 0
2022-08-25 02:13:54,645 WARNING NaN or Inf found in input tensor.
2022-08-25 02:14:15,257 DEBUG TRAIN Batch 135/2100 loss 51.159859 loss_att 27.289070 loss_ctc 106.858368 loss_ctc_origin 52.250656 loss_ctc0 234.276337 lr 0.00072076 rank 0
2022-08-25 02:14:42,181 WARNING NaN or Inf found in input tensor.
2022-08-25 02:14:43,743 DEBUG TRAIN Batch 135/2200 loss 23.441793 loss_att 12.318687 loss_ctc 49.395706 loss_ctc_origin 39.277473 loss_ctc0 73.004913 lr 0.00072071 rank 0
2022-08-25 02:15:11,061 DEBUG TRAIN Batch 135/2300 loss 21.271231 loss_att 10.101208 loss_ctc 47.334618 loss_ctc_origin 34.090290 loss_ctc0 78.238037 lr 0.00072066 rank 0
2022-08-25 02:15:38,619 DEBUG TRAIN Batch 135/2400 loss 26.304132 loss_att 12.311892 loss_ctc 58.952690 loss_ctc_origin 45.541756 loss_ctc0 90.244865 lr 0.00072062 rank 0
2022-08-25 02:16:07,036 DEBUG TRAIN Batch 135/2500 loss 41.448761 loss_att 26.390898 loss_ctc 76.583771 loss_ctc_origin 48.184418 loss_ctc0 142.848907 lr 0.00072057 rank 0
2022-08-25 02:16:19,741 WARNING NaN or Inf found in input tensor.
2022-08-25 02:16:33,747 DEBUG TRAIN Batch 135/2600 loss 52.232395 loss_att 28.399931 loss_ctc 107.841476 loss_ctc_origin 58.111141 loss_ctc0 223.878906 lr 0.00072052 rank 0
2022-08-25 02:17:03,631 DEBUG TRAIN Batch 135/2700 loss 22.068304 loss_att 10.133916 loss_ctc 49.915207 loss_ctc_origin 36.849525 loss_ctc0 80.401794 lr 0.00072048 rank 0
2022-08-25 02:17:14,494 WARNING NaN or Inf found in input tensor.
2022-08-25 02:17:31,643 DEBUG TRAIN Batch 135/2800 loss 20.631952 loss_att 9.360388 loss_ctc 46.932266 loss_ctc_origin 34.934509 loss_ctc0 74.927032 lr 0.00072043 rank 0
2022-08-25 02:17:55,311 WARNING NaN or Inf found in input tensor.
2022-08-25 02:17:59,708 DEBUG TRAIN Batch 135/2900 loss 23.035131 loss_att 9.917500 loss_ctc 53.642937 loss_ctc_origin 33.315960 loss_ctc0 101.072556 lr 0.00072038 rank 0
2022-08-25 02:18:34,111 DEBUG TRAIN Batch 135/3000 loss 47.280731 loss_att 29.867233 loss_ctc 87.912231 loss_ctc_origin 57.270691 loss_ctc0 159.409149 lr 0.00072034 rank 0
2022-08-25 02:19:01,702 DEBUG TRAIN Batch 135/3100 loss 48.574131 loss_att 25.637840 loss_ctc 102.092140 loss_ctc_origin 51.232216 loss_ctc0 220.765289 lr 0.00072029 rank 0
2022-08-25 02:19:29,167 DEBUG TRAIN Batch 135/3200 loss 18.196503 loss_att 9.711194 loss_ctc 37.995556 loss_ctc_origin 24.835932 loss_ctc0 68.701340 lr 0.00072024 rank 0
2022-08-25 02:19:56,084 DEBUG TRAIN Batch 135/3300 loss 20.255648 loss_att 8.474283 loss_ctc 47.745495 loss_ctc_origin 33.179962 loss_ctc0 81.731735 lr 0.00072020 rank 0
2022-08-25 02:20:23,998 DEBUG TRAIN Batch 135/3400 loss 20.971565 loss_att 8.740507 loss_ctc 49.510704 loss_ctc_origin 32.827110 loss_ctc0 88.439079 lr 0.00072015 rank 0
2022-08-25 02:20:51,933 DEBUG TRAIN Batch 135/3500 loss 40.723679 loss_att 27.186022 loss_ctc 72.311539 loss_ctc_origin 40.409275 loss_ctc0 146.750153 lr 0.00072010 rank 0
2022-08-25 02:21:20,001 DEBUG TRAIN Batch 135/3600 loss 43.391670 loss_att 20.416796 loss_ctc 96.999710 loss_ctc_origin 42.649063 loss_ctc0 223.817856 lr 0.00072006 rank 0
2022-08-25 02:21:46,248 DEBUG TRAIN Batch 135/3700 loss 21.483049 loss_att 11.264548 loss_ctc 45.326218 loss_ctc_origin 34.487324 loss_ctc0 70.616974 lr 0.00072001 rank 0
2022-08-25 02:22:14,942 DEBUG TRAIN Batch 135/3800 loss 22.723095 loss_att 9.472679 loss_ctc 53.640732 loss_ctc_origin 38.726971 loss_ctc0 88.439499 lr 0.00071996 rank 0
2022-08-25 02:22:42,422 DEBUG TRAIN Batch 135/3900 loss 23.284679 loss_att 9.574612 loss_ctc 55.274834 loss_ctc_origin 35.302231 loss_ctc0 101.877571 lr 0.00071992 rank 0
2022-08-25 02:23:10,946 DEBUG TRAIN Batch 135/4000 loss 49.766090 loss_att 33.643017 loss_ctc 87.386589 loss_ctc_origin 51.331924 loss_ctc0 171.514130 lr 0.00071987 rank 0
2022-08-25 02:23:39,932 DEBUG TRAIN Batch 135/4100 loss 50.021896 loss_att 26.297892 loss_ctc 105.377914 loss_ctc_origin 51.162857 loss_ctc0 231.879730 lr 0.00071982 rank 0
2022-08-25 02:24:07,126 DEBUG TRAIN Batch 135/4200 loss 18.774883 loss_att 10.142368 loss_ctc 38.917419 loss_ctc_origin 25.720871 loss_ctc0 69.709366 lr 0.00071978 rank 0
2022-08-25 02:24:35,381 DEBUG TRAIN Batch 135/4300 loss 21.579762 loss_att 9.873652 loss_ctc 48.894016 loss_ctc_origin 36.186661 loss_ctc0 78.544510 lr 0.00071973 rank 0
2022-08-25 02:25:04,621 DEBUG TRAIN Batch 135/4400 loss 20.894352 loss_att 8.438457 loss_ctc 49.958111 loss_ctc_origin 30.392992 loss_ctc0 95.610046 lr 0.00071968 rank 0
2022-08-25 02:25:38,203 DEBUG TRAIN Batch 135/4500 loss 46.358963 loss_att 29.218000 loss_ctc 86.354546 loss_ctc_origin 52.441109 loss_ctc0 165.485901 lr 0.00071964 rank 0
2022-08-25 02:26:04,842 DEBUG TRAIN Batch 135/4600 loss 46.326004 loss_att 21.314169 loss_ctc 104.686943 loss_ctc_origin 49.475285 loss_ctc0 233.514145 lr 0.00071959 rank 0
2022-08-25 02:26:31,334 WARNING NaN or Inf found in input tensor.
2022-08-25 02:26:33,158 DEBUG TRAIN Batch 135/4700 loss 21.895088 loss_att 14.014128 loss_ctc 40.283997 loss_ctc_origin 30.684584 loss_ctc0 62.682629 lr 0.00071954 rank 0
2022-08-25 02:27:00,619 DEBUG TRAIN Batch 135/4800 loss 16.081520 loss_att 6.574515 loss_ctc 38.264534 loss_ctc_origin 22.734024 loss_ctc0 74.502396 lr 0.00071950 rank 0
2022-08-25 02:27:27,954 DEBUG TRAIN Batch 135/4900 loss 23.213732 loss_att 10.864647 loss_ctc 52.028259 loss_ctc_origin 33.231903 loss_ctc0 95.886421 lr 0.00071945 rank 0
2022-08-25 02:27:56,342 DEBUG TRAIN Batch 135/5000 loss 41.097183 loss_att 26.633820 loss_ctc 74.845032 loss_ctc_origin 38.828976 loss_ctc0 158.882507 lr 0.00071940 rank 0
2022-08-25 02:28:23,689 DEBUG TRAIN Batch 135/5100 loss 53.788727 loss_att 27.777185 loss_ctc 114.482315 loss_ctc_origin 58.346775 loss_ctc0 245.465240 lr 0.00071936 rank 0
2022-08-25 02:28:52,538 DEBUG TRAIN Batch 135/5200 loss 18.828417 loss_att 10.508664 loss_ctc 38.241173 loss_ctc_origin 27.504547 loss_ctc0 63.293297 lr 0.00071931 rank 0
2022-08-25 02:29:19,932 DEBUG TRAIN Batch 135/5300 loss 18.200045 loss_att 7.307392 loss_ctc 43.616234 loss_ctc_origin 29.376287 loss_ctc0 76.842781 lr 0.00071926 rank 0
2022-08-25 02:29:47,315 DEBUG TRAIN Batch 135/5400 loss 24.890722 loss_att 11.913851 loss_ctc 55.170086 loss_ctc_origin 38.222397 loss_ctc0 94.714691 lr 0.00071922 rank 0
2022-08-25 02:30:13,931 DEBUG TRAIN Batch 135/5500 loss 44.196339 loss_att 29.802067 loss_ctc 77.782974 loss_ctc_origin 44.858170 loss_ctc0 154.607513 lr 0.00071917 rank 0
2022-08-25 02:30:40,467 DEBUG TRAIN Batch 135/5600 loss 43.039864 loss_att 20.759344 loss_ctc 95.027740 loss_ctc_origin 40.558758 loss_ctc0 222.122040 lr 0.00071912 rank 0
2022-08-25 02:31:02,601 DEBUG CV Batch 135/0 loss 12.371008 loss_att 9.220036 loss_ctc 19.723276 loss_ctc_origin 13.854813 loss_ctc0 33.416355 history loss 11.643302 rank 0
2022-08-25 02:31:12,464 DEBUG CV Batch 135/100 loss 20.692692 loss_att 16.316753 loss_ctc 30.903217 loss_ctc_origin 21.091431 loss_ctc0 53.797382 history loss 26.699692 rank 0
2022-08-25 02:31:21,653 DEBUG CV Batch 135/200 loss 25.141239 loss_att 19.563042 loss_ctc 38.157028 loss_ctc_origin 27.726818 loss_ctc0 62.494179 history loss 27.874664 rank 0
2022-08-25 02:31:31,036 DEBUG CV Batch 135/300 loss 22.652704 loss_att 17.024363 loss_ctc 35.785503 loss_ctc_origin 20.500937 loss_ctc0 71.449493 history loss 26.951544 rank 0
2022-08-25 02:31:41,099 DEBUG CV Batch 135/400 loss 38.216110 loss_att 31.178217 loss_ctc 54.637871 loss_ctc_origin 37.463730 loss_ctc0 94.710861 history loss 25.313877 rank 0
2022-08-25 02:31:51,056 DEBUG CV Batch 135/500 loss 17.594257 loss_att 13.101692 loss_ctc 28.076908 loss_ctc_origin 21.880009 loss_ctc0 42.536335 history loss 24.971939 rank 0
2022-08-25 02:32:00,853 DEBUG CV Batch 135/600 loss 17.011366 loss_att 11.636532 loss_ctc 29.552645 loss_ctc_origin 19.261183 loss_ctc0 53.566055 history loss 24.777044 rank 0
2022-08-25 02:32:10,290 DEBUG CV Batch 135/700 loss 19.072147 loss_att 13.108239 loss_ctc 32.987930 loss_ctc_origin 19.930138 loss_ctc0 63.456108 history loss 24.430515 rank 0
2022-08-25 02:32:20,084 DEBUG CV Batch 135/800 loss 22.436518 loss_att 17.788395 loss_ctc 33.282135 loss_ctc_origin 17.877182 loss_ctc0 69.227020 history loss 24.381384 rank 0
2022-08-25 02:32:29,670 INFO Epoch 135 CV info cv_loss 24.468451161190547
2022-08-25 02:32:29,670 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/135.pt
2022-08-25 02:32:30,115 INFO Epoch 136 TRAIN info lr 0.0007190858578216994
2022-08-25 02:32:30,119 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 02:32:55,709 DEBUG TRAIN Batch 136/0 loss 38.033371 loss_att 24.110977 loss_ctc 70.518951 loss_ctc_origin 42.492023 loss_ctc0 135.915131 lr 0.00071908 rank 0
2022-08-25 02:33:22,242 DEBUG TRAIN Batch 136/100 loss 50.845314 loss_att 28.026215 loss_ctc 104.089874 loss_ctc_origin 54.295990 loss_ctc0 220.275589 lr 0.00071904 rank 0
2022-08-25 02:33:49,068 DEBUG TRAIN Batch 136/200 loss 17.916210 loss_att 8.819964 loss_ctc 39.140785 loss_ctc_origin 26.062077 loss_ctc0 69.657776 lr 0.00071899 rank 0
2022-08-25 02:34:16,240 DEBUG TRAIN Batch 136/300 loss 19.535793 loss_att 8.452307 loss_ctc 45.397263 loss_ctc_origin 31.195576 loss_ctc0 78.534523 lr 0.00071894 rank 0
2022-08-25 02:34:45,187 DEBUG TRAIN Batch 136/400 loss 23.546688 loss_att 10.370171 loss_ctc 54.291893 loss_ctc_origin 36.576454 loss_ctc0 95.627907 lr 0.00071890 rank 0
2022-08-25 02:35:12,556 DEBUG TRAIN Batch 136/500 loss 38.061798 loss_att 24.594036 loss_ctc 69.486572 loss_ctc_origin 42.799137 loss_ctc0 131.757233 lr 0.00071885 rank 0
2022-08-25 02:35:40,198 DEBUG TRAIN Batch 136/600 loss 42.200771 loss_att 23.814335 loss_ctc 85.102455 loss_ctc_origin 44.275223 loss_ctc0 180.365982 lr 0.00071881 rank 0
2022-08-25 02:36:06,708 DEBUG TRAIN Batch 136/700 loss 20.805416 loss_att 10.819660 loss_ctc 44.105511 loss_ctc_origin 33.407684 loss_ctc0 69.067108 lr 0.00071876 rank 0
2022-08-25 02:36:33,732 DEBUG TRAIN Batch 136/800 loss 18.200338 loss_att 8.381893 loss_ctc 41.110039 loss_ctc_origin 27.006172 loss_ctc0 74.019066 lr 0.00071871 rank 0
2022-08-25 02:37:00,532 DEBUG TRAIN Batch 136/900 loss 23.108643 loss_att 10.442206 loss_ctc 52.663654 loss_ctc_origin 35.363098 loss_ctc0 93.031616 lr 0.00071867 rank 0
2022-08-25 02:37:27,296 DEBUG TRAIN Batch 136/1000 loss 38.967712 loss_att 26.807140 loss_ctc 67.342377 loss_ctc_origin 38.631096 loss_ctc0 134.335358 lr 0.00071862 rank 0
2022-08-25 02:37:53,715 DEBUG TRAIN Batch 136/1100 loss 42.526829 loss_att 23.952774 loss_ctc 85.866287 loss_ctc_origin 39.268204 loss_ctc0 194.595139 lr 0.00071857 rank 0
2022-08-25 02:38:04,720 WARNING NaN or Inf found in input tensor.
2022-08-25 02:38:20,199 DEBUG TRAIN Batch 136/1200 loss 22.560013 loss_att 12.014915 loss_ctc 47.165241 loss_ctc_origin 35.396721 loss_ctc0 74.625122 lr 0.00071853 rank 0
2022-08-25 02:38:46,694 DEBUG TRAIN Batch 136/1300 loss 19.640169 loss_att 8.954415 loss_ctc 44.573593 loss_ctc_origin 30.278919 loss_ctc0 77.927826 lr 0.00071848 rank 0
2022-08-25 02:39:13,256 DEBUG TRAIN Batch 136/1400 loss 25.967457 loss_att 11.817389 loss_ctc 58.984276 loss_ctc_origin 41.950771 loss_ctc0 98.729111 lr 0.00071843 rank 0
2022-08-25 02:39:46,029 DEBUG TRAIN Batch 136/1500 loss 49.141731 loss_att 33.652794 loss_ctc 85.282578 loss_ctc_origin 54.597771 loss_ctc0 156.880478 lr 0.00071839 rank 0
2022-08-25 02:40:12,947 DEBUG TRAIN Batch 136/1600 loss 37.287231 loss_att 16.396980 loss_ctc 86.031143 loss_ctc_origin 34.716858 loss_ctc0 205.764465 lr 0.00071834 rank 0
2022-08-25 02:40:40,015 DEBUG TRAIN Batch 136/1700 loss 18.980886 loss_att 10.151969 loss_ctc 39.581692 loss_ctc_origin 28.038258 loss_ctc0 66.516373 lr 0.00071830 rank 0
2022-08-25 02:41:07,702 DEBUG TRAIN Batch 136/1800 loss 19.618549 loss_att 8.110929 loss_ctc 46.469658 loss_ctc_origin 30.138535 loss_ctc0 84.575607 lr 0.00071825 rank 0
2022-08-25 02:41:34,147 DEBUG TRAIN Batch 136/1900 loss 23.586069 loss_att 10.431882 loss_ctc 54.279175 loss_ctc_origin 36.231289 loss_ctc0 96.390900 lr 0.00071820 rank 0
2022-08-25 02:42:01,896 DEBUG TRAIN Batch 136/2000 loss 34.460747 loss_att 18.763481 loss_ctc 71.087700 loss_ctc_origin 36.746452 loss_ctc0 151.217270 lr 0.00071816 rank 0
2022-08-25 02:42:29,414 DEBUG TRAIN Batch 136/2100 loss 53.711655 loss_att 29.565125 loss_ctc 110.053558 loss_ctc_origin 56.659222 loss_ctc0 234.640350 lr 0.00071811 rank 0
2022-08-25 02:42:54,681 WARNING NaN or Inf found in input tensor.
2022-08-25 02:42:56,223 DEBUG TRAIN Batch 136/2200 loss 22.057655 loss_att 12.816103 loss_ctc 43.621277 loss_ctc_origin 34.300125 loss_ctc0 65.370621 lr 0.00071806 rank 0
2022-08-25 02:43:23,413 DEBUG TRAIN Batch 136/2300 loss 19.974035 loss_att 9.666351 loss_ctc 44.025295 loss_ctc_origin 30.753399 loss_ctc0 74.993057 lr 0.00071802 rank 0
2022-08-25 02:43:50,376 DEBUG TRAIN Batch 136/2400 loss 25.388939 loss_att 10.413116 loss_ctc 60.332523 loss_ctc_origin 41.851784 loss_ctc0 103.454247 lr 0.00071797 rank 0
2022-08-25 02:44:04,571 WARNING NaN or Inf found in input tensor.
2022-08-25 02:44:17,536 DEBUG TRAIN Batch 136/2500 loss 45.892143 loss_att 27.888206 loss_ctc 87.901337 loss_ctc_origin 53.832718 loss_ctc0 167.394775 lr 0.00071792 rank 0
2022-08-25 02:44:46,300 DEBUG TRAIN Batch 136/2600 loss 56.616707 loss_att 33.191078 loss_ctc 111.276505 loss_ctc_origin 65.744720 loss_ctc0 217.517319 lr 0.00071788 rank 0
2022-08-25 02:45:10,612 DEBUG TRAIN Batch 136/2700 loss 17.869598 loss_att 9.178455 loss_ctc 38.148933 loss_ctc_origin 28.118664 loss_ctc0 61.552902 lr 0.00071783 rank 0
2022-08-25 02:45:39,272 DEBUG TRAIN Batch 136/2800 loss 20.109322 loss_att 8.775494 loss_ctc 46.554920 loss_ctc_origin 31.842182 loss_ctc0 80.884636 lr 0.00071779 rank 0
2022-08-25 02:46:04,178 DEBUG TRAIN Batch 136/2900 loss 22.362406 loss_att 9.827593 loss_ctc 51.610298 loss_ctc_origin 35.626202 loss_ctc0 88.906525 lr 0.00071774 rank 0
2022-08-25 02:46:39,172 DEBUG TRAIN Batch 136/3000 loss 47.377716 loss_att 28.813183 loss_ctc 90.694954 loss_ctc_origin 53.223274 loss_ctc0 178.128876 lr 0.00071769 rank 0
2022-08-25 02:47:07,890 DEBUG TRAIN Batch 136/3100 loss 53.653473 loss_att 30.558899 loss_ctc 107.540817 loss_ctc_origin 51.885979 loss_ctc0 237.402100 lr 0.00071765 rank 0
2022-08-25 02:47:37,187 DEBUG TRAIN Batch 136/3200 loss 18.028175 loss_att 7.968182 loss_ctc 41.501495 loss_ctc_origin 28.251595 loss_ctc0 72.417938 lr 0.00071760 rank 0
2022-08-25 02:48:05,571 DEBUG TRAIN Batch 136/3300 loss 21.892046 loss_att 9.647604 loss_ctc 50.462410 loss_ctc_origin 35.032394 loss_ctc0 86.465782 lr 0.00071756 rank 0
2022-08-25 02:48:33,451 DEBUG TRAIN Batch 136/3400 loss 24.276056 loss_att 11.129191 loss_ctc 54.952072 loss_ctc_origin 35.933323 loss_ctc0 99.329147 lr 0.00071751 rank 0
2022-08-25 02:49:01,563 DEBUG TRAIN Batch 136/3500 loss 41.054325 loss_att 27.450016 loss_ctc 72.797707 loss_ctc_origin 44.128727 loss_ctc0 139.691986 lr 0.00071746 rank 0
2022-08-25 02:49:27,926 DEBUG TRAIN Batch 136/3600 loss 42.747467 loss_att 22.144608 loss_ctc 90.820801 loss_ctc_origin 42.964642 loss_ctc0 202.485168 lr 0.00071742 rank 0
2022-08-25 02:49:54,150 DEBUG TRAIN Batch 136/3700 loss 18.779778 loss_att 10.790791 loss_ctc 37.420750 loss_ctc_origin 25.965916 loss_ctc0 64.148697 lr 0.00071737 rank 0
2022-08-25 02:50:20,849 DEBUG TRAIN Batch 136/3800 loss 18.676315 loss_att 7.934062 loss_ctc 43.741570 loss_ctc_origin 29.454365 loss_ctc0 77.078369 lr 0.00071732 rank 0
2022-08-25 02:50:48,602 DEBUG TRAIN Batch 136/3900 loss 26.900360 loss_att 12.556137 loss_ctc 60.370216 loss_ctc_origin 43.644745 loss_ctc0 99.396317 lr 0.00071728 rank 0
2022-08-25 02:51:15,685 DEBUG TRAIN Batch 136/4000 loss 40.378036 loss_att 24.831339 loss_ctc 76.653664 loss_ctc_origin 41.200951 loss_ctc0 159.376648 lr 0.00071723 rank 0
2022-08-25 02:51:29,101 WARNING NaN or Inf found in input tensor.
2022-08-25 02:51:43,591 DEBUG TRAIN Batch 136/4100 loss 58.701847 loss_att 29.456745 loss_ctc 126.940414 loss_ctc_origin 65.019295 loss_ctc0 271.423035 lr 0.00071719 rank 0
2022-08-25 02:52:08,952 WARNING NaN or Inf found in input tensor.
2022-08-25 02:52:10,487 DEBUG TRAIN Batch 136/4200 loss 21.490780 loss_att 11.660334 loss_ctc 44.428482 loss_ctc_origin 30.429689 loss_ctc0 77.092331 lr 0.00071714 rank 0
2022-08-25 02:52:39,163 DEBUG TRAIN Batch 136/4300 loss 21.843472 loss_att 10.603683 loss_ctc 48.069645 loss_ctc_origin 33.295570 loss_ctc0 82.542488 lr 0.00071709 rank 0
2022-08-25 02:53:04,888 DEBUG TRAIN Batch 136/4400 loss 22.317429 loss_att 8.763875 loss_ctc 53.942383 loss_ctc_origin 35.933205 loss_ctc0 95.963806 lr 0.00071705 rank 0
2022-08-25 02:53:37,625 DEBUG TRAIN Batch 136/4500 loss 47.085258 loss_att 29.955421 loss_ctc 87.054871 loss_ctc_origin 46.362896 loss_ctc0 182.002808 lr 0.00071700 rank 0
2022-08-25 02:54:05,971 DEBUG TRAIN Batch 136/4600 loss 52.270546 loss_att 25.589943 loss_ctc 114.525284 loss_ctc_origin 58.534046 loss_ctc0 245.171509 lr 0.00071696 rank 0
2022-08-25 02:54:31,224 WARNING NaN or Inf found in input tensor.
2022-08-25 02:54:32,812 DEBUG TRAIN Batch 136/4700 loss 21.684153 loss_att 12.391741 loss_ctc 43.366447 loss_ctc_origin 31.965893 loss_ctc0 69.967743 lr 0.00071691 rank 0
2022-08-25 02:54:59,398 DEBUG TRAIN Batch 136/4800 loss 17.385632 loss_att 7.454431 loss_ctc 40.558430 loss_ctc_origin 26.956367 loss_ctc0 72.296570 lr 0.00071686 rank 0
2022-08-25 02:55:26,408 DEBUG TRAIN Batch 136/4900 loss 25.166477 loss_att 10.855349 loss_ctc 58.559109 loss_ctc_origin 40.973083 loss_ctc0 99.593163 lr 0.00071682 rank 0
2022-08-25 02:55:53,042 DEBUG TRAIN Batch 136/5000 loss 42.974167 loss_att 26.374384 loss_ctc 81.706985 loss_ctc_origin 45.427750 loss_ctc0 166.358521 lr 0.00071677 rank 0
2022-08-25 02:56:00,762 WARNING NaN or Inf found in input tensor.
2022-08-25 02:56:18,831 DEBUG TRAIN Batch 136/5100 loss 53.073288 loss_att 28.177166 loss_ctc 111.164230 loss_ctc_origin 55.807205 loss_ctc0 240.330597 lr 0.00071673 rank 0
2022-08-25 02:56:45,822 DEBUG TRAIN Batch 136/5200 loss 21.172161 loss_att 11.440847 loss_ctc 43.878555 loss_ctc_origin 34.352390 loss_ctc0 66.106277 lr 0.00071668 rank 0
2022-08-25 02:57:12,587 DEBUG TRAIN Batch 136/5300 loss 19.117870 loss_att 7.966557 loss_ctc 45.137596 loss_ctc_origin 31.391977 loss_ctc0 77.210709 lr 0.00071663 rank 0
2022-08-25 02:57:41,584 DEBUG TRAIN Batch 136/5400 loss 22.509838 loss_att 9.720251 loss_ctc 52.352203 loss_ctc_origin 34.357708 loss_ctc0 94.339355 lr 0.00071659 rank 0
2022-08-25 02:58:10,556 DEBUG TRAIN Batch 136/5500 loss 47.260971 loss_att 30.279549 loss_ctc 86.884293 loss_ctc_origin 53.062294 loss_ctc0 165.802277 lr 0.00071654 rank 0
2022-08-25 02:58:36,852 DEBUG TRAIN Batch 136/5600 loss 57.019650 loss_att 30.246599 loss_ctc 119.490097 loss_ctc_origin 62.057808 loss_ctc0 253.498779 lr 0.00071650 rank 0
2022-08-25 02:59:00,018 DEBUG CV Batch 136/0 loss 12.196790 loss_att 9.157625 loss_ctc 19.288174 loss_ctc_origin 13.100123 loss_ctc0 33.726959 history loss 11.479332 rank 0
2022-08-25 02:59:10,031 DEBUG CV Batch 136/100 loss 20.838472 loss_att 16.523689 loss_ctc 30.906298 loss_ctc_origin 21.207809 loss_ctc0 53.536102 history loss 26.609274 rank 0
2022-08-25 02:59:19,515 DEBUG CV Batch 136/200 loss 24.528898 loss_att 19.305603 loss_ctc 36.716587 loss_ctc_origin 26.067238 loss_ctc0 61.565067 history loss 27.849388 rank 0
2022-08-25 02:59:29,037 DEBUG CV Batch 136/300 loss 23.234402 loss_att 17.690271 loss_ctc 36.170700 loss_ctc_origin 20.920406 loss_ctc0 71.754715 history loss 27.041968 rank 0
2022-08-25 02:59:38,950 DEBUG CV Batch 136/400 loss 38.868156 loss_att 31.414780 loss_ctc 56.259365 loss_ctc_origin 39.538094 loss_ctc0 95.275665 history loss 25.444713 rank 0
2022-08-25 02:59:48,766 DEBUG CV Batch 136/500 loss 17.006733 loss_att 12.796358 loss_ctc 26.830936 loss_ctc_origin 19.828201 loss_ctc0 43.170654 history loss 25.204190 rank 0
2022-08-25 02:59:58,990 DEBUG CV Batch 136/600 loss 17.619663 loss_att 12.379667 loss_ctc 29.846321 loss_ctc_origin 19.360195 loss_ctc0 54.313942 history loss 25.038962 rank 0
2022-08-25 03:00:08,747 DEBUG CV Batch 136/700 loss 18.759441 loss_att 13.087226 loss_ctc 31.994610 loss_ctc_origin 18.306299 loss_ctc0 63.934002 history loss 24.692179 rank 0
2022-08-25 03:00:18,325 DEBUG CV Batch 136/800 loss 22.693789 loss_att 18.394215 loss_ctc 32.726128 loss_ctc_origin 17.173075 loss_ctc0 69.016586 history loss 24.648101 rank 0
2022-08-25 03:00:28,137 INFO Epoch 136 CV info cv_loss 24.742890459216298
2022-08-25 03:00:28,138 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/136.pt
2022-08-25 03:00:28,600 INFO Epoch 137 TRAIN info lr 0.0007164566502694911
2022-08-25 03:00:28,604 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 03:00:53,990 DEBUG TRAIN Batch 137/0 loss 48.757675 loss_att 33.067455 loss_ctc 85.368179 loss_ctc_origin 51.549976 loss_ctc0 164.277328 lr 0.00071645 rank 0
2022-08-25 03:01:01,922 WARNING NaN or Inf found in input tensor.
2022-08-25 03:01:22,321 DEBUG TRAIN Batch 137/100 loss 51.598343 loss_att 25.419493 loss_ctc 112.682327 loss_ctc_origin 56.488552 loss_ctc0 243.801132 lr 0.00071641 rank 0
2022-08-25 03:01:49,073 DEBUG TRAIN Batch 137/200 loss 16.260307 loss_att 8.841700 loss_ctc 33.570389 loss_ctc_origin 22.768110 loss_ctc0 58.775703 lr 0.00071636 rank 0
2022-08-25 03:01:54,556 WARNING NaN or Inf found in input tensor.
2022-08-25 03:02:16,543 DEBUG TRAIN Batch 137/300 loss 19.407663 loss_att 8.372471 loss_ctc 45.156445 loss_ctc_origin 29.817955 loss_ctc0 80.946251 lr 0.00071632 rank 0
2022-08-25 03:02:43,393 DEBUG TRAIN Batch 137/400 loss 22.611256 loss_att 9.090664 loss_ctc 54.159302 loss_ctc_origin 35.383343 loss_ctc0 97.969879 lr 0.00071627 rank 0
2022-08-25 03:03:11,327 DEBUG TRAIN Batch 137/500 loss 45.752426 loss_att 29.019108 loss_ctc 84.796829 loss_ctc_origin 47.294956 loss_ctc0 172.301208 lr 0.00071623 rank 0
2022-08-25 03:03:38,538 DEBUG TRAIN Batch 137/600 loss 49.498589 loss_att 26.370544 loss_ctc 103.464020 loss_ctc_origin 48.192287 loss_ctc0 232.431381 lr 0.00071618 rank 0
2022-08-25 03:04:04,974 DEBUG TRAIN Batch 137/700 loss 21.269028 loss_att 10.304005 loss_ctc 46.854080 loss_ctc_origin 33.832130 loss_ctc0 77.238632 lr 0.00071613 rank 0
2022-08-25 03:04:32,033 DEBUG TRAIN Batch 137/800 loss 18.410191 loss_att 7.308586 loss_ctc 44.313934 loss_ctc_origin 27.167130 loss_ctc0 84.323151 lr 0.00071609 rank 0
2022-08-25 03:04:59,779 DEBUG TRAIN Batch 137/900 loss 22.044014 loss_att 9.075985 loss_ctc 52.302750 loss_ctc_origin 32.153557 loss_ctc0 99.317535 lr 0.00071604 rank 0
2022-08-25 03:05:27,179 DEBUG TRAIN Batch 137/1000 loss 42.888977 loss_att 27.641762 loss_ctc 78.465805 loss_ctc_origin 45.495972 loss_ctc0 155.395416 lr 0.00071600 rank 0
2022-08-25 03:05:54,209 DEBUG TRAIN Batch 137/1100 loss 52.157761 loss_att 26.800606 loss_ctc 111.324455 loss_ctc_origin 58.291161 loss_ctc0 235.068817 lr 0.00071595 rank 0
2022-08-25 03:06:20,725 DEBUG TRAIN Batch 137/1200 loss 18.999765 loss_att 9.992858 loss_ctc 40.015881 loss_ctc_origin 29.178608 loss_ctc0 65.302849 lr 0.00071590 rank 0
2022-08-25 03:06:48,080 DEBUG TRAIN Batch 137/1300 loss 17.643305 loss_att 7.618670 loss_ctc 41.034119 loss_ctc_origin 28.177311 loss_ctc0 71.033340 lr 0.00071586 rank 0
2022-08-25 03:07:14,623 DEBUG TRAIN Batch 137/1400 loss 23.055916 loss_att 10.093559 loss_ctc 53.301411 loss_ctc_origin 34.869057 loss_ctc0 96.310234 lr 0.00071581 rank 0
2022-08-25 03:07:47,067 DEBUG TRAIN Batch 137/1500 loss 44.394684 loss_att 27.203691 loss_ctc 84.507004 loss_ctc_origin 50.337284 loss_ctc0 164.236359 lr 0.00071577 rank 0
2022-08-25 03:08:13,989 DEBUG TRAIN Batch 137/1600 loss 57.795982 loss_att 30.315186 loss_ctc 121.917847 loss_ctc_origin 62.797432 loss_ctc0 259.865479 lr 0.00071572 rank 0
2022-08-25 03:08:40,384 DEBUG TRAIN Batch 137/1700 loss 22.721979 loss_att 11.805340 loss_ctc 48.194138 loss_ctc_origin 36.942432 loss_ctc0 74.448105 lr 0.00071567 rank 0
2022-08-25 03:09:07,957 DEBUG TRAIN Batch 137/1800 loss 18.901606 loss_att 9.020228 loss_ctc 41.958149 loss_ctc_origin 27.449116 loss_ctc0 75.812561 lr 0.00071563 rank 0
2022-08-25 03:09:35,817 DEBUG TRAIN Batch 137/1900 loss 25.338020 loss_att 11.330576 loss_ctc 58.022057 loss_ctc_origin 39.662102 loss_ctc0 100.861946 lr 0.00071558 rank 0
2022-08-25 03:10:03,400 DEBUG TRAIN Batch 137/2000 loss 40.993027 loss_att 25.336124 loss_ctc 77.525803 loss_ctc_origin 42.992512 loss_ctc0 158.103485 lr 0.00071554 rank 0
2022-08-25 03:10:29,460 DEBUG TRAIN Batch 137/2100 loss 57.182922 loss_att 30.941887 loss_ctc 118.412003 loss_ctc_origin 56.055187 loss_ctc0 263.911224 lr 0.00071549 rank 0
2022-08-25 03:10:56,019 DEBUG TRAIN Batch 137/2200 loss 21.882607 loss_att 11.821501 loss_ctc 45.358521 loss_ctc_origin 36.422325 loss_ctc0 66.209641 lr 0.00071545 rank 0
2022-08-25 03:11:23,646 DEBUG TRAIN Batch 137/2300 loss 18.800865 loss_att 7.930850 loss_ctc 44.164230 loss_ctc_origin 30.101027 loss_ctc0 76.978378 lr 0.00071540 rank 0
2022-08-25 03:11:51,347 DEBUG TRAIN Batch 137/2400 loss 22.432648 loss_att 9.782659 loss_ctc 51.949287 loss_ctc_origin 35.682072 loss_ctc0 89.906128 lr 0.00071535 rank 0
2022-08-25 03:12:18,700 DEBUG TRAIN Batch 137/2500 loss 40.955116 loss_att 25.318171 loss_ctc 77.441315 loss_ctc_origin 47.480820 loss_ctc0 147.349121 lr 0.00071531 rank 0
2022-08-25 03:12:46,709 DEBUG TRAIN Batch 137/2600 loss 46.189121 loss_att 24.136860 loss_ctc 97.644394 loss_ctc_origin 45.794682 loss_ctc0 218.627060 lr 0.00071526 rank 0
2022-08-25 03:13:14,303 DEBUG TRAIN Batch 137/2700 loss 17.721024 loss_att 9.525021 loss_ctc 36.845032 loss_ctc_origin 26.641472 loss_ctc0 60.653336 lr 0.00071522 rank 0
2022-08-25 03:13:23,268 WARNING NaN or Inf found in input tensor.
2022-08-25 03:13:39,832 DEBUG TRAIN Batch 137/2800 loss 20.048883 loss_att 8.148337 loss_ctc 47.816826 loss_ctc_origin 34.143032 loss_ctc0 79.722343 lr 0.00071517 rank 0
2022-08-25 03:13:55,978 WARNING NaN or Inf found in input tensor.
2022-08-25 03:14:06,913 DEBUG TRAIN Batch 137/2900 loss 22.470453 loss_att 9.045520 loss_ctc 53.795296 loss_ctc_origin 37.645332 loss_ctc0 91.478546 lr 0.00071513 rank 0
2022-08-25 03:14:40,472 DEBUG TRAIN Batch 137/3000 loss 43.809517 loss_att 25.101141 loss_ctc 87.462387 loss_ctc_origin 50.652454 loss_ctc0 173.352234 lr 0.00071508 rank 0
2022-08-25 03:15:08,587 DEBUG TRAIN Batch 137/3100 loss 56.223026 loss_att 30.487530 loss_ctc 116.272514 loss_ctc_origin 64.534599 loss_ctc0 236.994324 lr 0.00071503 rank 0
2022-08-25 03:15:35,702 DEBUG TRAIN Batch 137/3200 loss 20.914520 loss_att 10.470412 loss_ctc 45.284103 loss_ctc_origin 34.230797 loss_ctc0 71.075142 lr 0.00071499 rank 0
2022-08-25 03:16:02,280 DEBUG TRAIN Batch 137/3300 loss 19.551023 loss_att 8.130548 loss_ctc 46.198795 loss_ctc_origin 32.261017 loss_ctc0 78.720276 lr 0.00071494 rank 0
2022-08-25 03:16:29,971 DEBUG TRAIN Batch 137/3400 loss 21.673569 loss_att 8.799448 loss_ctc 51.713181 loss_ctc_origin 34.149670 loss_ctc0 92.694710 lr 0.00071490 rank 0
2022-08-25 03:16:57,848 DEBUG TRAIN Batch 137/3500 loss 52.326744 loss_att 34.233833 loss_ctc 94.543533 loss_ctc_origin 55.900585 loss_ctc0 184.710419 lr 0.00071485 rank 0
2022-08-25 03:17:05,187 WARNING NaN or Inf found in input tensor.
2022-08-25 03:17:26,406 DEBUG TRAIN Batch 137/3600 loss 53.457649 loss_att 29.447886 loss_ctc 109.480423 loss_ctc_origin 60.477707 loss_ctc0 223.820114 lr 0.00071481 rank 0
2022-08-25 03:17:54,692 DEBUG TRAIN Batch 137/3700 loss 15.423609 loss_att 8.579807 loss_ctc 31.392479 loss_ctc_origin 18.906429 loss_ctc0 60.526588 lr 0.00071476 rank 0
2022-08-25 03:18:00,083 WARNING NaN or Inf found in input tensor.
2022-08-25 03:18:20,629 DEBUG TRAIN Batch 137/3800 loss 18.948383 loss_att 9.220722 loss_ctc 41.646259 loss_ctc_origin 27.256596 loss_ctc0 75.222137 lr 0.00071471 rank 0
2022-08-25 03:18:48,482 DEBUG TRAIN Batch 137/3900 loss 24.244106 loss_att 10.388432 loss_ctc 56.574013 loss_ctc_origin 38.192257 loss_ctc0 99.464783 lr 0.00071467 rank 0
2022-08-25 03:19:15,391 DEBUG TRAIN Batch 137/4000 loss 50.945908 loss_att 32.171696 loss_ctc 94.752388 loss_ctc_origin 59.772995 loss_ctc0 176.370972 lr 0.00071462 rank 0
2022-08-25 03:19:41,054 DEBUG TRAIN Batch 137/4100 loss 62.997555 loss_att 35.273170 loss_ctc 127.687775 loss_ctc_origin 75.110100 loss_ctc0 250.368988 lr 0.00071458 rank 0
2022-08-25 03:20:09,405 DEBUG TRAIN Batch 137/4200 loss 22.164654 loss_att 12.846955 loss_ctc 43.905952 loss_ctc_origin 34.349453 loss_ctc0 66.204453 lr 0.00071453 rank 0
2022-08-25 03:20:19,252 WARNING NaN or Inf found in input tensor.
2022-08-25 03:20:36,096 DEBUG TRAIN Batch 137/4300 loss 21.652094 loss_att 8.648214 loss_ctc 51.994476 loss_ctc_origin 38.256317 loss_ctc0 84.050179 lr 0.00071449 rank 0
2022-08-25 03:21:02,167 DEBUG TRAIN Batch 137/4400 loss 27.420212 loss_att 12.361420 loss_ctc 62.557388 loss_ctc_origin 44.464848 loss_ctc0 104.773315 lr 0.00071444 rank 0
2022-08-25 03:21:33,981 DEBUG TRAIN Batch 137/4500 loss 44.234528 loss_att 28.541376 loss_ctc 80.851868 loss_ctc_origin 46.387863 loss_ctc0 161.267853 lr 0.00071440 rank 0
2022-08-25 03:22:00,919 DEBUG TRAIN Batch 137/4600 loss 54.443768 loss_att 27.673706 loss_ctc 116.907242 loss_ctc_origin 69.814537 loss_ctc0 226.790222 lr 0.00071435 rank 0
2022-08-25 03:22:27,921 DEBUG TRAIN Batch 137/4700 loss 19.038319 loss_att 9.975906 loss_ctc 40.183945 loss_ctc_origin 28.322708 loss_ctc0 67.860168 lr 0.00071430 rank 0
2022-08-25 03:22:54,863 DEBUG TRAIN Batch 137/4800 loss 18.586586 loss_att 8.119155 loss_ctc 43.010590 loss_ctc_origin 28.647387 loss_ctc0 76.524734 lr 0.00071426 rank 0
2022-08-25 03:23:23,208 DEBUG TRAIN Batch 137/4900 loss 26.732080 loss_att 11.772219 loss_ctc 61.638424 loss_ctc_origin 43.112778 loss_ctc0 104.864929 lr 0.00071421 rank 0
2022-08-25 03:23:43,759 WARNING NaN or Inf found in input tensor.
2022-08-25 03:23:51,305 DEBUG TRAIN Batch 137/5000 loss 40.938362 loss_att 26.344406 loss_ctc 74.990929 loss_ctc_origin 45.360641 loss_ctc0 144.128265 lr 0.00071417 rank 0
2022-08-25 03:24:18,146 DEBUG TRAIN Batch 137/5100 loss 52.211533 loss_att 28.133698 loss_ctc 108.393143 loss_ctc_origin 56.097107 loss_ctc0 230.417221 lr 0.00071412 rank 0
2022-08-25 03:24:44,233 DEBUG TRAIN Batch 137/5200 loss 23.063602 loss_att 12.850231 loss_ctc 46.894798 loss_ctc_origin 36.807388 loss_ctc0 70.432083 lr 0.00071408 rank 0
2022-08-25 03:25:11,562 DEBUG TRAIN Batch 137/5300 loss 18.575891 loss_att 8.610183 loss_ctc 41.829212 loss_ctc_origin 30.834007 loss_ctc0 67.484688 lr 0.00071403 rank 0
2022-08-25 03:25:38,793 DEBUG TRAIN Batch 137/5400 loss 24.945875 loss_att 11.519426 loss_ctc 56.274254 loss_ctc_origin 36.863304 loss_ctc0 101.566467 lr 0.00071399 rank 0
2022-08-25 03:26:05,670 DEBUG TRAIN Batch 137/5500 loss 39.817520 loss_att 25.367044 loss_ctc 73.535286 loss_ctc_origin 42.208092 loss_ctc0 146.632080 lr 0.00071394 rank 0
2022-08-25 03:26:31,818 DEBUG TRAIN Batch 137/5600 loss 50.893257 loss_att 25.676552 loss_ctc 109.732224 loss_ctc_origin 54.202049 loss_ctc0 239.302643 lr 0.00071389 rank 0
2022-08-25 03:26:54,829 DEBUG CV Batch 137/0 loss 12.761953 loss_att 9.764755 loss_ctc 19.755413 loss_ctc_origin 13.679606 loss_ctc0 33.932297 history loss 12.011250 rank 0
2022-08-25 03:27:05,221 DEBUG CV Batch 137/100 loss 21.093212 loss_att 17.005999 loss_ctc 30.630047 loss_ctc_origin 21.052471 loss_ctc0 52.977722 history loss 26.411534 rank 0
2022-08-25 03:27:14,866 DEBUG CV Batch 137/200 loss 24.769644 loss_att 19.157957 loss_ctc 37.863579 loss_ctc_origin 27.443508 loss_ctc0 62.177082 history loss 27.706905 rank 0
2022-08-25 03:27:25,015 DEBUG CV Batch 137/300 loss 22.982050 loss_att 17.007864 loss_ctc 36.921818 loss_ctc_origin 21.849342 loss_ctc0 72.090927 history loss 26.819008 rank 0
2022-08-25 03:27:35,359 DEBUG CV Batch 137/400 loss 38.550758 loss_att 31.351875 loss_ctc 55.348152 loss_ctc_origin 38.408676 loss_ctc0 94.873596 history loss 25.240314 rank 0
2022-08-25 03:27:46,306 DEBUG CV Batch 137/500 loss 16.616203 loss_att 12.284250 loss_ctc 26.724091 loss_ctc_origin 19.974957 loss_ctc0 42.472069 history loss 24.948704 rank 0
2022-08-25 03:27:56,981 DEBUG CV Batch 137/600 loss 17.477852 loss_att 12.605711 loss_ctc 28.846180 loss_ctc_origin 18.181522 loss_ctc0 53.730385 history loss 24.762419 rank 0
2022-08-25 03:28:06,274 DEBUG CV Batch 137/700 loss 19.192797 loss_att 13.359243 loss_ctc 32.804420 loss_ctc_origin 19.481377 loss_ctc0 63.891525 history loss 24.429150 rank 0
2022-08-25 03:28:15,883 DEBUG CV Batch 137/800 loss 22.659046 loss_att 18.008699 loss_ctc 33.509850 loss_ctc_origin 18.143944 loss_ctc0 69.363632 history loss 24.380047 rank 0
2022-08-25 03:28:25,532 INFO Epoch 137 CV info cv_loss 24.474257969145683
2022-08-25 03:28:25,533 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/137.pt
2022-08-25 03:28:25,991 INFO Epoch 138 TRAIN info lr 0.0007138560730845968
2022-08-25 03:28:25,995 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 03:28:53,217 DEBUG TRAIN Batch 138/0 loss 39.401814 loss_att 24.424749 loss_ctc 74.348297 loss_ctc_origin 40.465508 loss_ctc0 153.408127 lr 0.00071385 rank 0
2022-08-25 03:29:21,660 DEBUG TRAIN Batch 138/100 loss 55.224915 loss_att 30.091747 loss_ctc 113.868973 loss_ctc_origin 57.135555 loss_ctc0 246.246948 lr 0.00071381 rank 0
2022-08-25 03:29:51,260 DEBUG TRAIN Batch 138/200 loss 23.063679 loss_att 13.664980 loss_ctc 44.993973 loss_ctc_origin 35.216736 loss_ctc0 67.807526 lr 0.00071376 rank 0
2022-08-25 03:30:19,578 DEBUG TRAIN Batch 138/300 loss 19.959625 loss_att 8.325850 loss_ctc 47.105099 loss_ctc_origin 33.493355 loss_ctc0 78.865829 lr 0.00071372 rank 0
2022-08-25 03:30:48,972 DEBUG TRAIN Batch 138/400 loss 21.990398 loss_att 9.113520 loss_ctc 52.036446 loss_ctc_origin 33.102982 loss_ctc0 96.214523 lr 0.00071367 rank 0
2022-08-25 03:31:18,543 DEBUG TRAIN Batch 138/500 loss 47.529190 loss_att 29.990496 loss_ctc 88.452805 loss_ctc_origin 49.840866 loss_ctc0 178.547333 lr 0.00071363 rank 0
2022-08-25 03:31:45,240 DEBUG TRAIN Batch 138/600 loss 52.199577 loss_att 26.388601 loss_ctc 112.425171 loss_ctc_origin 56.808403 loss_ctc0 242.197617 lr 0.00071358 rank 0
2022-08-25 03:32:10,581 WARNING NaN or Inf found in input tensor.
2022-08-25 03:32:12,126 DEBUG TRAIN Batch 138/700 loss 18.076891 loss_att 10.365238 loss_ctc 36.070747 loss_ctc_origin 25.178741 loss_ctc0 61.485428 lr 0.00071354 rank 0
2022-08-25 03:32:39,517 DEBUG TRAIN Batch 138/800 loss 16.133287 loss_att 6.529310 loss_ctc 38.542564 loss_ctc_origin 24.155365 loss_ctc0 72.112701 lr 0.00071349 rank 0
2022-08-25 03:33:07,053 DEBUG TRAIN Batch 138/900 loss 25.073208 loss_att 11.167809 loss_ctc 57.519142 loss_ctc_origin 40.186180 loss_ctc0 97.962723 lr 0.00071345 rank 0
2022-08-25 03:33:35,709 DEBUG TRAIN Batch 138/1000 loss 47.761429 loss_att 30.266298 loss_ctc 88.583397 loss_ctc_origin 52.784927 loss_ctc0 172.113159 lr 0.00071340 rank 0
2022-08-25 03:34:04,392 DEBUG TRAIN Batch 138/1100 loss 53.974968 loss_att 29.562664 loss_ctc 110.937012 loss_ctc_origin 58.477325 loss_ctc0 233.342926 lr 0.00071335 rank 0
2022-08-25 03:34:33,673 DEBUG TRAIN Batch 138/1200 loss 19.918085 loss_att 9.944182 loss_ctc 43.190521 loss_ctc_origin 31.696068 loss_ctc0 70.010918 lr 0.00071331 rank 0
2022-08-25 03:34:59,747 DEBUG TRAIN Batch 138/1300 loss 20.780411 loss_att 8.810940 loss_ctc 48.709179 loss_ctc_origin 35.337044 loss_ctc0 79.910828 lr 0.00071326 rank 0
2022-08-25 03:35:25,401 DEBUG TRAIN Batch 138/1400 loss 25.629166 loss_att 11.136343 loss_ctc 59.445747 loss_ctc_origin 43.044212 loss_ctc0 97.715996 lr 0.00071322 rank 0
2022-08-25 03:35:33,392 WARNING NaN or Inf found in input tensor.
2022-08-25 03:35:57,844 DEBUG TRAIN Batch 138/1500 loss 38.899792 loss_att 21.967064 loss_ctc 78.409492 loss_ctc_origin 41.019489 loss_ctc0 165.652832 lr 0.00071317 rank 0
2022-08-25 03:36:24,547 DEBUG TRAIN Batch 138/1600 loss 54.783684 loss_att 29.751320 loss_ctc 113.192528 loss_ctc_origin 59.787872 loss_ctc0 237.803375 lr 0.00071313 rank 0
2022-08-25 03:36:51,786 DEBUG TRAIN Batch 138/1700 loss 18.056881 loss_att 8.728765 loss_ctc 39.822483 loss_ctc_origin 28.095715 loss_ctc0 67.184944 lr 0.00071308 rank 0
2022-08-25 03:37:18,154 DEBUG TRAIN Batch 138/1800 loss 19.601116 loss_att 9.140352 loss_ctc 44.009567 loss_ctc_origin 29.399714 loss_ctc0 78.099228 lr 0.00071304 rank 0
2022-08-25 03:37:44,788 DEBUG TRAIN Batch 138/1900 loss 25.092184 loss_att 10.574970 loss_ctc 58.965683 loss_ctc_origin 37.228962 loss_ctc0 109.684692 lr 0.00071299 rank 0
2022-08-25 03:38:13,217 DEBUG TRAIN Batch 138/2000 loss 34.382401 loss_att 19.611797 loss_ctc 68.847145 loss_ctc_origin 42.942116 loss_ctc0 129.292206 lr 0.00071295 rank 0
2022-08-25 03:38:40,117 DEBUG TRAIN Batch 138/2100 loss 44.378250 loss_att 19.266947 loss_ctc 102.971298 loss_ctc_origin 46.523178 loss_ctc0 234.683578 lr 0.00071290 rank 0
2022-08-25 03:39:06,684 DEBUG TRAIN Batch 138/2200 loss 22.930149 loss_att 15.148694 loss_ctc 41.086876 loss_ctc_origin 31.197599 loss_ctc0 64.161858 lr 0.00071286 rank 0
2022-08-25 03:39:34,388 DEBUG TRAIN Batch 138/2300 loss 21.390326 loss_att 9.880795 loss_ctc 48.245899 loss_ctc_origin 33.004948 loss_ctc0 83.808121 lr 0.00071281 rank 0
2022-08-25 03:40:02,691 DEBUG TRAIN Batch 138/2400 loss 20.807228 loss_att 8.269560 loss_ctc 50.061783 loss_ctc_origin 33.865585 loss_ctc0 87.852905 lr 0.00071277 rank 0
2022-08-25 03:40:30,250 DEBUG TRAIN Batch 138/2500 loss 46.076672 loss_att 29.047266 loss_ctc 85.811951 loss_ctc_origin 47.809158 loss_ctc0 174.485138 lr 0.00071272 rank 0
2022-08-25 03:40:57,238 DEBUG TRAIN Batch 138/2600 loss 56.599243 loss_att 27.927603 loss_ctc 123.499741 loss_ctc_origin 64.488968 loss_ctc0 261.191528 lr 0.00071267 rank 0
2022-08-25 03:41:23,877 DEBUG TRAIN Batch 138/2700 loss 17.650028 loss_att 9.089083 loss_ctc 37.625565 loss_ctc_origin 24.236195 loss_ctc0 68.867424 lr 0.00071263 rank 0
2022-08-25 03:41:51,808 DEBUG TRAIN Batch 138/2800 loss 23.019928 loss_att 10.228317 loss_ctc 52.867020 loss_ctc_origin 37.437668 loss_ctc0 88.868835 lr 0.00071258 rank 0
2022-08-25 03:42:19,468 DEBUG TRAIN Batch 138/2900 loss 18.972935 loss_att 7.855357 loss_ctc 44.913948 loss_ctc_origin 25.457996 loss_ctc0 90.311172 lr 0.00071254 rank 0
2022-08-25 03:42:52,148 DEBUG TRAIN Batch 138/3000 loss 39.908020 loss_att 25.010384 loss_ctc 74.669167 loss_ctc_origin 40.221855 loss_ctc0 155.046219 lr 0.00071249 rank 0
2022-08-25 03:43:19,765 DEBUG TRAIN Batch 138/3100 loss 48.884735 loss_att 25.223030 loss_ctc 104.095383 loss_ctc_origin 49.119640 loss_ctc0 232.372101 lr 0.00071245 rank 0
2022-08-25 03:43:47,012 DEBUG TRAIN Batch 138/3200 loss 20.177437 loss_att 8.591247 loss_ctc 47.211880 loss_ctc_origin 34.279587 loss_ctc0 77.387230 lr 0.00071240 rank 0
2022-08-25 03:44:13,889 DEBUG TRAIN Batch 138/3300 loss 21.948576 loss_att 9.061029 loss_ctc 52.019516 loss_ctc_origin 36.190979 loss_ctc0 88.952759 lr 0.00071236 rank 0
2022-08-25 03:44:40,768 DEBUG TRAIN Batch 138/3400 loss 23.462046 loss_att 10.403227 loss_ctc 53.932617 loss_ctc_origin 35.139832 loss_ctc0 97.782455 lr 0.00071231 rank 0
2022-08-25 03:45:09,039 DEBUG TRAIN Batch 138/3500 loss 45.911339 loss_att 29.049812 loss_ctc 85.254898 loss_ctc_origin 49.558388 loss_ctc0 168.546738 lr 0.00071227 rank 0
2022-08-25 03:45:35,453 DEBUG TRAIN Batch 138/3600 loss 51.472015 loss_att 28.556000 loss_ctc 104.942711 loss_ctc_origin 52.882080 loss_ctc0 226.417496 lr 0.00071222 rank 0
2022-08-25 03:46:03,188 DEBUG TRAIN Batch 138/3700 loss 19.346058 loss_att 10.159607 loss_ctc 40.781113 loss_ctc_origin 30.390522 loss_ctc0 65.025818 lr 0.00071218 rank 0
2022-08-25 03:46:30,942 DEBUG TRAIN Batch 138/3800 loss 19.037033 loss_att 8.383389 loss_ctc 43.895535 loss_ctc_origin 29.293335 loss_ctc0 77.967331 lr 0.00071213 rank 0
2022-08-25 03:46:59,417 DEBUG TRAIN Batch 138/3900 loss 23.240082 loss_att 10.445261 loss_ctc 53.094658 loss_ctc_origin 33.925404 loss_ctc0 97.822922 lr 0.00071209 rank 0
2022-08-25 03:47:28,146 DEBUG TRAIN Batch 138/4000 loss 44.306316 loss_att 29.067684 loss_ctc 79.863129 loss_ctc_origin 44.688591 loss_ctc0 161.937057 lr 0.00071204 rank 0
2022-08-25 03:47:55,302 DEBUG TRAIN Batch 138/4100 loss 51.435913 loss_att 27.314396 loss_ctc 107.719452 loss_ctc_origin 51.213921 loss_ctc0 239.565674 lr 0.00071200 rank 0
2022-08-25 03:48:21,379 DEBUG TRAIN Batch 138/4200 loss 20.280186 loss_att 10.635952 loss_ctc 42.783394 loss_ctc_origin 30.785074 loss_ctc0 70.779480 lr 0.00071195 rank 0
2022-08-25 03:48:49,476 DEBUG TRAIN Batch 138/4300 loss 17.159245 loss_att 7.136409 loss_ctc 40.545860 loss_ctc_origin 24.442997 loss_ctc0 78.119202 lr 0.00071191 rank 0
2022-08-25 03:49:15,934 DEBUG TRAIN Batch 138/4400 loss 22.924725 loss_att 10.724010 loss_ctc 51.393055 loss_ctc_origin 32.759323 loss_ctc0 94.871758 lr 0.00071186 rank 0
2022-08-25 03:49:49,050 DEBUG TRAIN Batch 138/4500 loss 43.775162 loss_att 27.688808 loss_ctc 81.309990 loss_ctc_origin 48.654068 loss_ctc0 157.507141 lr 0.00071182 rank 0
2022-08-25 03:50:16,667 DEBUG TRAIN Batch 138/4600 loss 53.485504 loss_att 29.425819 loss_ctc 109.624763 loss_ctc_origin 54.430206 loss_ctc0 238.412048 lr 0.00071177 rank 0
2022-08-25 03:50:44,070 DEBUG TRAIN Batch 138/4700 loss 20.825075 loss_att 10.974379 loss_ctc 43.810032 loss_ctc_origin 34.935490 loss_ctc0 64.517296 lr 0.00071173 rank 0
2022-08-25 03:51:11,548 DEBUG TRAIN Batch 138/4800 loss 24.239042 loss_att 11.052595 loss_ctc 55.007420 loss_ctc_origin 39.985008 loss_ctc0 90.059708 lr 0.00071168 rank 0
2022-08-25 03:51:38,834 DEBUG TRAIN Batch 138/4900 loss 19.725967 loss_att 8.167201 loss_ctc 46.696423 loss_ctc_origin 28.003975 loss_ctc0 90.312134 lr 0.00071164 rank 0
2022-08-25 03:52:06,465 DEBUG TRAIN Batch 138/5000 loss 52.366543 loss_att 35.856033 loss_ctc 90.891068 loss_ctc_origin 56.554264 loss_ctc0 171.010254 lr 0.00071159 rank 0
2022-08-25 03:52:33,036 DEBUG TRAIN Batch 138/5100 loss 49.714073 loss_att 26.591053 loss_ctc 103.667786 loss_ctc_origin 50.019234 loss_ctc0 228.847748 lr 0.00071155 rank 0
2022-08-25 03:53:00,357 DEBUG TRAIN Batch 138/5200 loss 19.864513 loss_att 12.069315 loss_ctc 38.053310 loss_ctc_origin 28.770014 loss_ctc0 59.714333 lr 0.00071150 rank 0
2022-08-25 03:53:27,170 DEBUG TRAIN Batch 138/5300 loss 20.927948 loss_att 10.330724 loss_ctc 45.654808 loss_ctc_origin 30.925541 loss_ctc0 80.023102 lr 0.00071146 rank 0
2022-08-25 03:53:53,489 DEBUG TRAIN Batch 138/5400 loss 23.335278 loss_att 10.233153 loss_ctc 53.906898 loss_ctc_origin 34.699448 loss_ctc0 98.724274 lr 0.00071141 rank 0
2022-08-25 03:53:55,987 WARNING NaN or Inf found in input tensor.
2022-08-25 03:54:21,440 DEBUG TRAIN Batch 138/5500 loss 42.936905 loss_att 28.440533 loss_ctc 76.761780 loss_ctc_origin 51.744186 loss_ctc0 135.136169 lr 0.00071137 rank 0
2022-08-25 03:54:49,611 DEBUG TRAIN Batch 138/5600 loss 50.311600 loss_att 26.959866 loss_ctc 104.798965 loss_ctc_origin 56.562737 loss_ctc0 217.350143 lr 0.00071132 rank 0
2022-08-25 03:55:13,335 DEBUG CV Batch 138/0 loss 12.245897 loss_att 8.926586 loss_ctc 19.990955 loss_ctc_origin 13.833552 loss_ctc0 34.358227 history loss 11.525550 rank 0
2022-08-25 03:55:23,505 DEBUG CV Batch 138/100 loss 21.735424 loss_att 17.296967 loss_ctc 32.091827 loss_ctc_origin 22.833797 loss_ctc0 53.693893 history loss 26.757132 rank 0
2022-08-25 03:55:33,099 DEBUG CV Batch 138/200 loss 24.490498 loss_att 19.146370 loss_ctc 36.960129 loss_ctc_origin 26.154976 loss_ctc0 62.172157 history loss 27.949755 rank 0
2022-08-25 03:55:42,624 DEBUG CV Batch 138/300 loss 22.441185 loss_att 16.542015 loss_ctc 36.205914 loss_ctc_origin 20.907238 loss_ctc0 71.902817 history loss 26.997578 rank 0
2022-08-25 03:55:52,235 DEBUG CV Batch 138/400 loss 38.371750 loss_att 31.278774 loss_ctc 54.922020 loss_ctc_origin 37.492386 loss_ctc0 95.591171 history loss 25.335867 rank 0
2022-08-25 03:56:01,992 DEBUG CV Batch 138/500 loss 16.724762 loss_att 12.429282 loss_ctc 26.747543 loss_ctc_origin 19.781406 loss_ctc0 43.001862 history loss 25.012362 rank 0
2022-08-25 03:56:11,850 DEBUG CV Batch 138/600 loss 17.596268 loss_att 12.412395 loss_ctc 29.691967 loss_ctc_origin 19.182222 loss_ctc0 54.214706 history loss 24.862458 rank 0
2022-08-25 03:56:21,217 DEBUG CV Batch 138/700 loss 19.342085 loss_att 13.549712 loss_ctc 32.857620 loss_ctc_origin 19.505054 loss_ctc0 64.013603 history loss 24.521456 rank 0
2022-08-25 03:56:30,693 DEBUG CV Batch 138/800 loss 22.757439 loss_att 18.084444 loss_ctc 33.661087 loss_ctc_origin 18.526390 loss_ctc0 68.975380 history loss 24.486887 rank 0
2022-08-25 03:56:40,383 INFO Epoch 138 CV info cv_loss 24.57363901186898
2022-08-25 03:56:40,383 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/138.pt
2022-08-25 03:56:40,838 INFO Epoch 139 TRAIN info lr 0.0007112836104005989
2022-08-25 03:56:40,841 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 03:57:08,984 DEBUG TRAIN Batch 139/0 loss 45.731647 loss_att 31.361828 loss_ctc 79.261223 loss_ctc_origin 51.771660 loss_ctc0 143.403534 lr 0.00071128 rank 0
2022-08-25 03:57:39,313 DEBUG TRAIN Batch 139/100 loss 51.320770 loss_att 26.446259 loss_ctc 109.361298 loss_ctc_origin 56.840355 loss_ctc0 231.910156 lr 0.00071124 rank 0
2022-08-25 03:58:08,370 DEBUG TRAIN Batch 139/200 loss 20.514465 loss_att 12.569757 loss_ctc 39.052116 loss_ctc_origin 28.967308 loss_ctc0 62.583336 lr 0.00071119 rank 0
2022-08-25 03:58:13,469 WARNING NaN or Inf found in input tensor.
2022-08-25 03:58:36,536 DEBUG TRAIN Batch 139/300 loss 22.087112 loss_att 10.340557 loss_ctc 49.495735 loss_ctc_origin 35.832874 loss_ctc0 81.375748 lr 0.00071115 rank 0
2022-08-25 03:59:06,632 DEBUG TRAIN Batch 139/400 loss 24.368870 loss_att 9.478249 loss_ctc 59.113655 loss_ctc_origin 40.459175 loss_ctc0 102.640778 lr 0.00071110 rank 0
2022-08-25 03:59:35,900 DEBUG TRAIN Batch 139/500 loss 43.178383 loss_att 28.434307 loss_ctc 77.581223 loss_ctc_origin 48.004272 loss_ctc0 146.594101 lr 0.00071106 rank 0
2022-08-25 04:00:03,790 DEBUG TRAIN Batch 139/600 loss 48.997574 loss_att 26.319912 loss_ctc 101.912109 loss_ctc_origin 56.032501 loss_ctc0 208.964523 lr 0.00071101 rank 0
2022-08-25 04:00:32,809 DEBUG TRAIN Batch 139/700 loss 18.301823 loss_att 9.903569 loss_ctc 37.897743 loss_ctc_origin 27.387703 loss_ctc0 62.421162 lr 0.00071097 rank 0
2022-08-25 04:01:01,742 DEBUG TRAIN Batch 139/800 loss 19.538332 loss_att 8.238668 loss_ctc 45.904213 loss_ctc_origin 31.475161 loss_ctc0 79.572006 lr 0.00071092 rank 0
2022-08-25 04:01:26,801 WARNING NaN or Inf found in input tensor.
2022-08-25 04:01:31,529 DEBUG TRAIN Batch 139/900 loss 22.809771 loss_att 8.730495 loss_ctc 55.661407 loss_ctc_origin 38.730064 loss_ctc0 95.167870 lr 0.00071088 rank 0
2022-08-25 04:02:00,334 DEBUG TRAIN Batch 139/1000 loss 44.244469 loss_att 30.209179 loss_ctc 76.993469 loss_ctc_origin 50.276527 loss_ctc0 139.333008 lr 0.00071083 rank 0
2022-08-25 04:02:12,801 WARNING NaN or Inf found in input tensor.
2022-08-25 04:02:26,363 DEBUG TRAIN Batch 139/1100 loss 51.431595 loss_att 28.984352 loss_ctc 103.808487 loss_ctc_origin 51.644958 loss_ctc0 225.523392 lr 0.00071079 rank 0
2022-08-25 04:02:54,571 DEBUG TRAIN Batch 139/1200 loss 18.755640 loss_att 10.044297 loss_ctc 39.082108 loss_ctc_origin 26.147076 loss_ctc0 69.263847 lr 0.00071074 rank 0
2022-08-25 04:03:25,426 DEBUG TRAIN Batch 139/1300 loss 16.750149 loss_att 6.907882 loss_ctc 39.715439 loss_ctc_origin 25.134129 loss_ctc0 73.738503 lr 0.00071070 rank 0
2022-08-25 04:03:54,501 DEBUG TRAIN Batch 139/1400 loss 24.321596 loss_att 10.162985 loss_ctc 57.358353 loss_ctc_origin 38.373272 loss_ctc0 101.656876 lr 0.00071065 rank 0
2022-08-25 04:04:29,928 DEBUG TRAIN Batch 139/1500 loss 45.330437 loss_att 31.145027 loss_ctc 78.429718 loss_ctc_origin 51.969742 loss_ctc0 140.169647 lr 0.00071061 rank 0
2022-08-25 04:04:58,874 DEBUG TRAIN Batch 139/1600 loss 54.932289 loss_att 32.915672 loss_ctc 106.304398 loss_ctc_origin 61.046196 loss_ctc0 211.906860 lr 0.00071056 rank 0
2022-08-25 04:05:28,223 DEBUG TRAIN Batch 139/1700 loss 21.772919 loss_att 11.401215 loss_ctc 45.973560 loss_ctc_origin 37.154594 loss_ctc0 66.551147 lr 0.00071052 rank 0
2022-08-25 04:05:55,652 DEBUG TRAIN Batch 139/1800 loss 20.326958 loss_att 8.004177 loss_ctc 49.080109 loss_ctc_origin 33.915344 loss_ctc0 84.464554 lr 0.00071047 rank 0
2022-08-25 04:06:24,041 DEBUG TRAIN Batch 139/1900 loss 21.010246 loss_att 8.609414 loss_ctc 49.945518 loss_ctc_origin 31.242212 loss_ctc0 93.586563 lr 0.00071043 rank 0
2022-08-25 04:06:53,444 DEBUG TRAIN Batch 139/2000 loss 46.732964 loss_att 32.695164 loss_ctc 79.487839 loss_ctc_origin 51.259659 loss_ctc0 145.353607 lr 0.00071038 rank 0
2022-08-25 04:07:20,811 DEBUG TRAIN Batch 139/2100 loss 55.080635 loss_att 32.270439 loss_ctc 108.304413 loss_ctc_origin 63.682259 loss_ctc0 212.422775 lr 0.00071034 rank 0
2022-08-25 04:07:48,848 DEBUG TRAIN Batch 139/2200 loss 18.752642 loss_att 10.935045 loss_ctc 36.993698 loss_ctc_origin 26.858704 loss_ctc0 60.642021 lr 0.00071029 rank 0
2022-08-25 04:08:07,668 WARNING NaN or Inf found in input tensor.
2022-08-25 04:08:17,925 DEBUG TRAIN Batch 139/2300 loss 18.675762 loss_att 8.274332 loss_ctc 42.945763 loss_ctc_origin 28.810553 loss_ctc0 75.927917 lr 0.00071025 rank 0
2022-08-25 04:08:42,501 WARNING NaN or Inf found in input tensor.
2022-08-25 04:08:46,946 DEBUG TRAIN Batch 139/2400 loss 17.734421 loss_att 7.504057 loss_ctc 41.605270 loss_ctc_origin 26.344467 loss_ctc0 77.213806 lr 0.00071020 rank 0
2022-08-25 04:09:15,263 DEBUG TRAIN Batch 139/2500 loss 50.185349 loss_att 34.675026 loss_ctc 86.376106 loss_ctc_origin 52.790691 loss_ctc0 164.742065 lr 0.00071016 rank 0
2022-08-25 04:09:29,559 WARNING NaN or Inf found in input tensor.
2022-08-25 04:09:44,613 DEBUG TRAIN Batch 139/2600 loss 46.711193 loss_att 23.979557 loss_ctc 99.751671 loss_ctc_origin 43.959648 loss_ctc0 229.933044 lr 0.00071012 rank 0
2022-08-25 04:10:12,887 DEBUG TRAIN Batch 139/2700 loss 20.759844 loss_att 11.540438 loss_ctc 42.271790 loss_ctc_origin 30.869295 loss_ctc0 68.877609 lr 0.00071007 rank 0
2022-08-25 04:10:41,910 DEBUG TRAIN Batch 139/2800 loss 17.593399 loss_att 7.554827 loss_ctc 41.016731 loss_ctc_origin 26.962299 loss_ctc0 73.810394 lr 0.00071003 rank 0
2022-08-25 04:11:11,391 DEBUG TRAIN Batch 139/2900 loss 21.772867 loss_att 8.979102 loss_ctc 51.624985 loss_ctc_origin 35.622726 loss_ctc0 88.963593 lr 0.00070998 rank 0
2022-08-25 04:11:46,916 DEBUG TRAIN Batch 139/3000 loss 46.007767 loss_att 30.197277 loss_ctc 82.898911 loss_ctc_origin 53.711193 loss_ctc0 151.003571 lr 0.00070994 rank 0
2022-08-25 04:11:54,938 WARNING NaN or Inf found in input tensor.
2022-08-25 04:12:16,186 DEBUG TRAIN Batch 139/3100 loss 51.395992 loss_att 27.000362 loss_ctc 108.319122 loss_ctc_origin 51.833527 loss_ctc0 240.118866 lr 0.00070989 rank 0
2022-08-25 04:12:45,402 DEBUG TRAIN Batch 139/3200 loss 20.353136 loss_att 9.990513 loss_ctc 44.532585 loss_ctc_origin 33.104668 loss_ctc0 71.197723 lr 0.00070985 rank 0
2022-08-25 04:13:14,262 DEBUG TRAIN Batch 139/3300 loss 19.334240 loss_att 7.031767 loss_ctc 48.040009 loss_ctc_origin 31.204792 loss_ctc0 87.322189 lr 0.00070980 rank 0
2022-08-25 04:13:43,374 DEBUG TRAIN Batch 139/3400 loss 21.246584 loss_att 9.079859 loss_ctc 49.635605 loss_ctc_origin 32.175163 loss_ctc0 90.376633 lr 0.00070976 rank 0
2022-08-25 04:14:12,466 DEBUG TRAIN Batch 139/3500 loss 50.314358 loss_att 33.226639 loss_ctc 90.185699 loss_ctc_origin 60.840534 loss_ctc0 158.657745 lr 0.00070971 rank 0
2022-08-25 04:14:20,174 WARNING NaN or Inf found in input tensor.
2022-08-25 04:14:41,014 DEBUG TRAIN Batch 139/3600 loss 53.025326 loss_att 28.345299 loss_ctc 110.612045 loss_ctc_origin 62.541145 loss_ctc0 222.777466 lr 0.00070967 rank 0
2022-08-25 04:15:09,435 DEBUG TRAIN Batch 139/3700 loss 22.878689 loss_att 13.046219 loss_ctc 45.821114 loss_ctc_origin 35.087151 loss_ctc0 70.867020 lr 0.00070962 rank 0
2022-08-25 04:15:38,465 DEBUG TRAIN Batch 139/3800 loss 20.040218 loss_att 8.336466 loss_ctc 47.348972 loss_ctc_origin 31.919479 loss_ctc0 83.351120 lr 0.00070958 rank 0
2022-08-25 04:16:07,328 DEBUG TRAIN Batch 139/3900 loss 25.006702 loss_att 11.076091 loss_ctc 57.511463 loss_ctc_origin 40.797821 loss_ctc0 96.509964 lr 0.00070953 rank 0
2022-08-25 04:16:36,608 DEBUG TRAIN Batch 139/4000 loss 45.922123 loss_att 30.623177 loss_ctc 81.619659 loss_ctc_origin 53.982769 loss_ctc0 146.105728 lr 0.00070949 rank 0
2022-08-25 04:17:05,226 DEBUG TRAIN Batch 139/4100 loss 45.048027 loss_att 24.638123 loss_ctc 92.671143 loss_ctc_origin 52.430504 loss_ctc0 186.565948 lr 0.00070944 rank 0
2022-08-25 04:17:33,734 DEBUG TRAIN Batch 139/4200 loss 20.746696 loss_att 11.832123 loss_ctc 41.547363 loss_ctc_origin 29.984097 loss_ctc0 68.528320 lr 0.00070940 rank 0
2022-08-25 04:18:01,404 DEBUG TRAIN Batch 139/4300 loss 17.774837 loss_att 7.557020 loss_ctc 41.616413 loss_ctc_origin 27.731880 loss_ctc0 74.013657 lr 0.00070936 rank 0
2022-08-25 04:18:30,357 DEBUG TRAIN Batch 139/4400 loss 22.431118 loss_att 11.431330 loss_ctc 48.097290 loss_ctc_origin 30.286572 loss_ctc0 89.655640 lr 0.00070931 rank 0
2022-08-25 04:19:05,391 DEBUG TRAIN Batch 139/4500 loss 43.616039 loss_att 26.640142 loss_ctc 83.226463 loss_ctc_origin 55.020771 loss_ctc0 149.039749 lr 0.00070927 rank 0
2022-08-25 04:19:33,633 DEBUG TRAIN Batch 139/4600 loss 54.899849 loss_att 30.559860 loss_ctc 111.693161 loss_ctc_origin 63.367779 loss_ctc0 224.452377 lr 0.00070922 rank 0
2022-08-25 04:20:02,559 DEBUG TRAIN Batch 139/4700 loss 21.411507 loss_att 12.072573 loss_ctc 43.202347 loss_ctc_origin 32.008713 loss_ctc0 69.320816 lr 0.00070918 rank 0
2022-08-25 04:20:30,918 DEBUG TRAIN Batch 139/4800 loss 19.914318 loss_att 8.135944 loss_ctc 47.397186 loss_ctc_origin 32.966797 loss_ctc0 81.068085 lr 0.00070913 rank 0
2022-08-25 04:20:55,697 WARNING NaN or Inf found in input tensor.
2022-08-25 04:21:00,052 DEBUG TRAIN Batch 139/4900 loss 24.090820 loss_att 10.007932 loss_ctc 56.950890 loss_ctc_origin 37.990906 loss_ctc0 101.190842 lr 0.00070909 rank 0
2022-08-25 04:21:28,761 DEBUG TRAIN Batch 139/5000 loss 42.528793 loss_att 28.599249 loss_ctc 75.031059 loss_ctc_origin 42.884632 loss_ctc0 150.039383 lr 0.00070904 rank 0
2022-08-25 04:21:56,300 DEBUG TRAIN Batch 139/5100 loss 53.669533 loss_att 30.738594 loss_ctc 107.175049 loss_ctc_origin 61.146519 loss_ctc0 214.574921 lr 0.00070900 rank 0
2022-08-25 04:22:24,734 DEBUG TRAIN Batch 139/5200 loss 22.274628 loss_att 12.455012 loss_ctc 45.187057 loss_ctc_origin 34.520279 loss_ctc0 70.076210 lr 0.00070895 rank 0
2022-08-25 04:22:54,219 DEBUG TRAIN Batch 139/5300 loss 18.400623 loss_att 7.648662 loss_ctc 43.488533 loss_ctc_origin 28.315884 loss_ctc0 78.891380 lr 0.00070891 rank 0
2022-08-25 04:23:18,579 WARNING NaN or Inf found in input tensor.
2022-08-25 04:23:23,084 DEBUG TRAIN Batch 139/5400 loss 23.938562 loss_att 9.990734 loss_ctc 56.483498 loss_ctc_origin 38.624138 loss_ctc0 98.155334 lr 0.00070887 rank 0
2022-08-25 04:23:52,333 DEBUG TRAIN Batch 139/5500 loss 43.863792 loss_att 26.478888 loss_ctc 84.428574 loss_ctc_origin 51.462353 loss_ctc0 161.349762 lr 0.00070882 rank 0
2022-08-25 04:24:19,783 DEBUG TRAIN Batch 139/5600 loss 56.258530 loss_att 33.147709 loss_ctc 110.183777 loss_ctc_origin 60.598156 loss_ctc0 225.883560 lr 0.00070878 rank 0
2022-08-25 04:24:43,081 DEBUG CV Batch 139/0 loss 12.229214 loss_att 9.285873 loss_ctc 19.097008 loss_ctc_origin 12.664577 loss_ctc0 34.106010 history loss 11.509848 rank 0
2022-08-25 04:24:53,669 DEBUG CV Batch 139/100 loss 21.156334 loss_att 16.749329 loss_ctc 31.439346 loss_ctc_origin 22.082954 loss_ctc0 53.270927 history loss 26.103212 rank 0
2022-08-25 04:25:02,987 DEBUG CV Batch 139/200 loss 24.395561 loss_att 18.529877 loss_ctc 38.082161 loss_ctc_origin 27.880974 loss_ctc0 61.884926 history loss 27.556413 rank 0
2022-08-25 04:25:13,141 DEBUG CV Batch 139/300 loss 22.135386 loss_att 16.464359 loss_ctc 35.367779 loss_ctc_origin 19.887121 loss_ctc0 71.489311 history loss 26.577442 rank 0
2022-08-25 04:25:23,776 DEBUG CV Batch 139/400 loss 37.830170 loss_att 30.723513 loss_ctc 54.412369 loss_ctc_origin 37.188347 loss_ctc0 94.601753 history loss 24.959457 rank 0
2022-08-25 04:25:34,099 DEBUG CV Batch 139/500 loss 16.397360 loss_att 12.670122 loss_ctc 25.094246 loss_ctc_origin 18.029934 loss_ctc0 41.577641 history loss 24.627855 rank 0
2022-08-25 04:25:44,539 DEBUG CV Batch 139/600 loss 17.093409 loss_att 11.590113 loss_ctc 29.934429 loss_ctc_origin 19.703186 loss_ctc0 53.807335 history loss 24.458594 rank 0
2022-08-25 04:25:54,323 DEBUG CV Batch 139/700 loss 18.455017 loss_att 12.641116 loss_ctc 32.020782 loss_ctc_origin 18.674477 loss_ctc0 63.162163 history loss 24.115116 rank 0
2022-08-25 04:26:05,033 DEBUG CV Batch 139/800 loss 21.892288 loss_att 17.339622 loss_ctc 32.515175 loss_ctc_origin 17.006041 loss_ctc0 68.703156 history loss 24.078630 rank 0
2022-08-25 04:26:15,429 INFO Epoch 139 CV info cv_loss 24.16590277152009
2022-08-25 04:26:15,430 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/139.pt
2022-08-25 04:26:15,917 INFO Epoch 140 TRAIN info lr 0.0007087387592709371
2022-08-25 04:26:15,920 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 04:26:43,959 DEBUG TRAIN Batch 140/0 loss 42.724785 loss_att 28.498131 loss_ctc 75.920319 loss_ctc_origin 46.328522 loss_ctc0 144.967834 lr 0.00070874 rank 0
2022-08-25 04:27:12,402 DEBUG TRAIN Batch 140/100 loss 51.200981 loss_att 27.802654 loss_ctc 105.797073 loss_ctc_origin 60.243942 loss_ctc0 212.087723 lr 0.00070869 rank 0
2022-08-25 04:27:41,045 DEBUG TRAIN Batch 140/200 loss 24.599266 loss_att 15.231028 loss_ctc 46.458488 loss_ctc_origin 37.003521 loss_ctc0 68.520081 lr 0.00070865 rank 0
2022-08-25 04:28:09,446 DEBUG TRAIN Batch 140/300 loss 19.705725 loss_att 8.075259 loss_ctc 46.843475 loss_ctc_origin 33.915199 loss_ctc0 77.009445 lr 0.00070860 rank 0
2022-08-25 04:28:37,328 DEBUG TRAIN Batch 140/400 loss 21.072655 loss_att 9.228743 loss_ctc 48.708450 loss_ctc_origin 30.435036 loss_ctc0 91.346420 lr 0.00070856 rank 0
2022-08-25 04:29:05,376 DEBUG TRAIN Batch 140/500 loss 35.529301 loss_att 23.331280 loss_ctc 63.991348 loss_ctc_origin 38.795639 loss_ctc0 122.781342 lr 0.00070851 rank 0
2022-08-25 04:29:33,920 DEBUG TRAIN Batch 140/600 loss 46.455338 loss_att 24.132832 loss_ctc 98.541183 loss_ctc_origin 54.262466 loss_ctc0 201.858185 lr 0.00070847 rank 0
2022-08-25 04:30:03,006 DEBUG TRAIN Batch 140/700 loss 17.818453 loss_att 9.411097 loss_ctc 37.435616 loss_ctc_origin 26.313866 loss_ctc0 63.386360 lr 0.00070843 rank 0
2022-08-25 04:30:32,075 DEBUG TRAIN Batch 140/800 loss 18.661652 loss_att 7.198019 loss_ctc 45.410126 loss_ctc_origin 28.752182 loss_ctc0 84.278656 lr 0.00070838 rank 0
2022-08-25 04:31:00,386 DEBUG TRAIN Batch 140/900 loss 24.410637 loss_att 11.133936 loss_ctc 55.389603 loss_ctc_origin 38.679695 loss_ctc0 94.379379 lr 0.00070834 rank 0
2022-08-25 04:31:27,519 DEBUG TRAIN Batch 140/1000 loss 39.870087 loss_att 25.494972 loss_ctc 73.412018 loss_ctc_origin 48.998184 loss_ctc0 130.377609 lr 0.00070829 rank 0
2022-08-25 04:31:56,230 DEBUG TRAIN Batch 140/1100 loss 44.203033 loss_att 24.469234 loss_ctc 90.248558 loss_ctc_origin 45.622890 loss_ctc0 194.375107 lr 0.00070825 rank 0
2022-08-25 04:32:24,709 DEBUG TRAIN Batch 140/1200 loss 18.567974 loss_att 9.207105 loss_ctc 40.410000 loss_ctc_origin 27.844975 loss_ctc0 69.728394 lr 0.00070820 rank 0
2022-08-25 04:32:53,517 DEBUG TRAIN Batch 140/1300 loss 18.782104 loss_att 7.826954 loss_ctc 44.344124 loss_ctc_origin 28.371756 loss_ctc0 81.612976 lr 0.00070816 rank 0
2022-08-25 04:33:21,626 DEBUG TRAIN Batch 140/1400 loss 23.879478 loss_att 9.878604 loss_ctc 56.548187 loss_ctc_origin 37.466980 loss_ctc0 101.071007 lr 0.00070811 rank 0
2022-08-25 04:33:55,586 DEBUG TRAIN Batch 140/1500 loss 41.775875 loss_att 29.153496 loss_ctc 71.228096 loss_ctc_origin 49.720154 loss_ctc0 121.413284 lr 0.00070807 rank 0
2022-08-25 04:34:22,737 DEBUG TRAIN Batch 140/1600 loss 51.565506 loss_att 26.932707 loss_ctc 109.042030 loss_ctc_origin 56.405685 loss_ctc0 231.860168 lr 0.00070803 rank 0
2022-08-25 04:34:50,645 DEBUG TRAIN Batch 140/1700 loss 19.235065 loss_att 10.493443 loss_ctc 39.632187 loss_ctc_origin 28.825182 loss_ctc0 64.848526 lr 0.00070798 rank 0
2022-08-25 04:35:18,075 DEBUG TRAIN Batch 140/1800 loss 22.450272 loss_att 9.180436 loss_ctc 53.413219 loss_ctc_origin 38.033379 loss_ctc0 89.299507 lr 0.00070794 rank 0
2022-08-25 04:35:46,140 DEBUG TRAIN Batch 140/1900 loss 22.079826 loss_att 9.881866 loss_ctc 50.541733 loss_ctc_origin 35.798466 loss_ctc0 84.942680 lr 0.00070789 rank 0
2022-08-25 04:36:14,661 DEBUG TRAIN Batch 140/2000 loss 42.683228 loss_att 25.755192 loss_ctc 82.181976 loss_ctc_origin 46.667480 loss_ctc0 165.049133 lr 0.00070785 rank 0
2022-08-25 04:36:41,569 DEBUG TRAIN Batch 140/2100 loss 53.041149 loss_att 28.697395 loss_ctc 109.843231 loss_ctc_origin 58.409420 loss_ctc0 229.855469 lr 0.00070780 rank 0
2022-08-25 04:37:07,641 WARNING NaN or Inf found in input tensor.
2022-08-25 04:37:09,213 DEBUG TRAIN Batch 140/2200 loss 24.134701 loss_att 14.599013 loss_ctc 46.384636 loss_ctc_origin 35.206867 loss_ctc0 72.466095 lr 0.00070776 rank 0
2022-08-25 04:37:36,248 DEBUG TRAIN Batch 140/2300 loss 16.997974 loss_att 7.190558 loss_ctc 39.881943 loss_ctc_origin 25.627174 loss_ctc0 73.143066 lr 0.00070772 rank 0
2022-08-25 04:38:03,426 DEBUG TRAIN Batch 140/2400 loss 22.090172 loss_att 10.196901 loss_ctc 49.841133 loss_ctc_origin 33.532471 loss_ctc0 87.894669 lr 0.00070767 rank 0
2022-08-25 04:38:17,849 WARNING NaN or Inf found in input tensor.
2022-08-25 04:38:30,763 DEBUG TRAIN Batch 140/2500 loss 46.303841 loss_att 30.691416 loss_ctc 82.732834 loss_ctc_origin 55.738903 loss_ctc0 145.718658 lr 0.00070763 rank 0
2022-08-25 04:38:58,812 DEBUG TRAIN Batch 140/2600 loss 57.971813 loss_att 36.812744 loss_ctc 107.342972 loss_ctc_origin 61.201759 loss_ctc0 215.005798 lr 0.00070758 rank 0
2022-08-25 04:39:26,223 DEBUG TRAIN Batch 140/2700 loss 20.235556 loss_att 10.006821 loss_ctc 44.102604 loss_ctc_origin 33.081348 loss_ctc0 69.818863 lr 0.00070754 rank 0
2022-08-25 04:39:52,930 DEBUG TRAIN Batch 140/2800 loss 17.255280 loss_att 7.513960 loss_ctc 39.985023 loss_ctc_origin 23.912899 loss_ctc0 77.486649 lr 0.00070749 rank 0
2022-08-25 04:40:19,447 DEBUG TRAIN Batch 140/2900 loss 22.031496 loss_att 9.491352 loss_ctc 51.291828 loss_ctc_origin 33.679039 loss_ctc0 92.388336 lr 0.00070745 rank 0
2022-08-25 04:40:52,282 DEBUG TRAIN Batch 140/3000 loss 47.476967 loss_att 30.646669 loss_ctc 86.747650 loss_ctc_origin 53.607300 loss_ctc0 164.075134 lr 0.00070741 rank 0
2022-08-25 04:41:19,089 DEBUG TRAIN Batch 140/3100 loss 55.252491 loss_att 30.493237 loss_ctc 113.024078 loss_ctc_origin 66.040405 loss_ctc0 222.652634 lr 0.00070736 rank 0
2022-08-25 04:41:46,131 DEBUG TRAIN Batch 140/3200 loss 20.349813 loss_att 8.491020 loss_ctc 48.020329 loss_ctc_origin 37.111588 loss_ctc0 73.474052 lr 0.00070732 rank 0
2022-08-25 04:42:13,578 DEBUG TRAIN Batch 140/3300 loss 21.590387 loss_att 9.453693 loss_ctc 49.909340 loss_ctc_origin 36.943871 loss_ctc0 80.162094 lr 0.00070727 rank 0
2022-08-25 04:42:40,436 DEBUG TRAIN Batch 140/3400 loss 25.265261 loss_att 10.182764 loss_ctc 60.457748 loss_ctc_origin 43.510063 loss_ctc0 100.002350 lr 0.00070723 rank 0
2022-08-25 04:42:49,595 WARNING NaN or Inf found in input tensor.
2022-08-25 04:43:08,007 DEBUG TRAIN Batch 140/3500 loss 45.927906 loss_att 29.732222 loss_ctc 83.717834 loss_ctc_origin 53.711617 loss_ctc0 153.732330 lr 0.00070718 rank 0
2022-08-25 04:43:15,317 WARNING NaN or Inf found in input tensor.
2022-08-25 04:43:34,902 DEBUG TRAIN Batch 140/3600 loss 45.894409 loss_att 24.104277 loss_ctc 96.738045 loss_ctc_origin 45.168846 loss_ctc0 217.066162 lr 0.00070714 rank 0
2022-08-25 04:44:01,482 DEBUG TRAIN Batch 140/3700 loss 16.790543 loss_att 8.087552 loss_ctc 37.097519 loss_ctc_origin 25.662096 loss_ctc0 63.780174 lr 0.00070710 rank 0
2022-08-25 04:44:28,296 DEBUG TRAIN Batch 140/3800 loss 22.522602 loss_att 10.404198 loss_ctc 50.798874 loss_ctc_origin 36.284523 loss_ctc0 84.665695 lr 0.00070705 rank 0
2022-08-25 04:44:55,792 DEBUG TRAIN Batch 140/3900 loss 25.869841 loss_att 11.703447 loss_ctc 58.924755 loss_ctc_origin 41.073090 loss_ctc0 100.578644 lr 0.00070701 rank 0
2022-08-25 04:45:21,470 DEBUG TRAIN Batch 140/4000 loss 42.984283 loss_att 26.492870 loss_ctc 81.464241 loss_ctc_origin 51.339783 loss_ctc0 151.754639 lr 0.00070696 rank 0
2022-08-25 04:45:48,197 DEBUG TRAIN Batch 140/4100 loss 53.487045 loss_att 35.028664 loss_ctc 96.556595 loss_ctc_origin 59.329330 loss_ctc0 183.420212 lr 0.00070692 rank 0
2022-08-25 04:46:15,712 DEBUG TRAIN Batch 140/4200 loss 19.274797 loss_att 10.244634 loss_ctc 40.345177 loss_ctc_origin 28.333542 loss_ctc0 68.372314 lr 0.00070688 rank 0
2022-08-25 04:46:42,825 DEBUG TRAIN Batch 140/4300 loss 20.860378 loss_att 9.349664 loss_ctc 47.718712 loss_ctc_origin 32.895710 loss_ctc0 82.305717 lr 0.00070683 rank 0
2022-08-25 04:47:10,418 DEBUG TRAIN Batch 140/4400 loss 23.330666 loss_att 9.625296 loss_ctc 55.309856 loss_ctc_origin 37.448341 loss_ctc0 96.986725 lr 0.00070679 rank 0
2022-08-25 04:47:44,382 DEBUG TRAIN Batch 140/4500 loss 45.997765 loss_att 31.053457 loss_ctc 80.867813 loss_ctc_origin 49.722004 loss_ctc0 153.541351 lr 0.00070674 rank 0
2022-08-25 04:48:10,821 DEBUG TRAIN Batch 140/4600 loss 51.063904 loss_att 28.632217 loss_ctc 103.404503 loss_ctc_origin 60.373508 loss_ctc0 203.810150 lr 0.00070670 rank 0
2022-08-25 04:48:37,506 DEBUG TRAIN Batch 140/4700 loss 19.055706 loss_att 9.883188 loss_ctc 40.458244 loss_ctc_origin 30.548748 loss_ctc0 63.580406 lr 0.00070665 rank 0
2022-08-25 04:49:04,677 DEBUG TRAIN Batch 140/4800 loss 23.212431 loss_att 10.376936 loss_ctc 53.161919 loss_ctc_origin 36.624241 loss_ctc0 91.749832 lr 0.00070661 rank 0
2022-08-25 04:49:31,526 DEBUG TRAIN Batch 140/4900 loss 22.161716 loss_att 9.688828 loss_ctc 51.265121 loss_ctc_origin 33.449280 loss_ctc0 92.835411 lr 0.00070657 rank 0
2022-08-25 04:49:59,054 DEBUG TRAIN Batch 140/5000 loss 43.380325 loss_att 26.711079 loss_ctc 82.275238 loss_ctc_origin 50.345589 loss_ctc0 156.777740 lr 0.00070652 rank 0
2022-08-25 04:50:26,065 DEBUG TRAIN Batch 140/5100 loss 50.768829 loss_att 27.443201 loss_ctc 105.195297 loss_ctc_origin 59.262383 loss_ctc0 212.372101 lr 0.00070648 rank 0
2022-08-25 04:50:51,674 DEBUG TRAIN Batch 140/5200 loss 20.742491 loss_att 11.158354 loss_ctc 43.105473 loss_ctc_origin 31.601055 loss_ctc0 69.949112 lr 0.00070643 rank 0
2022-08-25 04:51:18,916 DEBUG TRAIN Batch 140/5300 loss 19.686062 loss_att 8.339948 loss_ctc 46.160332 loss_ctc_origin 31.398319 loss_ctc0 80.605019 lr 0.00070639 rank 0
2022-08-25 04:51:44,508 DEBUG TRAIN Batch 140/5400 loss 19.930317 loss_att 8.065016 loss_ctc 47.616016 loss_ctc_origin 27.801859 loss_ctc0 93.849045 lr 0.00070635 rank 0
2022-08-25 04:52:12,725 DEBUG TRAIN Batch 140/5500 loss 43.501106 loss_att 29.561565 loss_ctc 76.026703 loss_ctc_origin 49.386986 loss_ctc0 138.186050 lr 0.00070630 rank 0
2022-08-25 04:52:39,021 DEBUG TRAIN Batch 140/5600 loss 55.502239 loss_att 32.113495 loss_ctc 110.075966 loss_ctc_origin 67.815338 loss_ctc0 208.684082 lr 0.00070626 rank 0
2022-08-25 04:53:01,652 DEBUG CV Batch 140/0 loss 12.044830 loss_att 8.902462 loss_ctc 19.377024 loss_ctc_origin 12.945504 loss_ctc0 34.383904 history loss 11.336311 rank 0
2022-08-25 04:53:12,292 DEBUG CV Batch 140/100 loss 21.047052 loss_att 16.576950 loss_ctc 31.477291 loss_ctc_origin 22.074024 loss_ctc0 53.418243 history loss 26.271991 rank 0
2022-08-25 04:53:22,408 DEBUG CV Batch 140/200 loss 25.180521 loss_att 19.713127 loss_ctc 37.937775 loss_ctc_origin 27.862616 loss_ctc0 61.446484 history loss 27.587501 rank 0
2022-08-25 04:53:31,102 DEBUG CV Batch 140/300 loss 23.038256 loss_att 17.155260 loss_ctc 36.765244 loss_ctc_origin 21.578011 loss_ctc0 72.202118 history loss 26.680276 rank 0
2022-08-25 04:53:40,607 DEBUG CV Batch 140/400 loss 37.802406 loss_att 30.596230 loss_ctc 54.616821 loss_ctc_origin 37.552235 loss_ctc0 94.434196 history loss 25.082868 rank 0
2022-08-25 04:53:50,199 DEBUG CV Batch 140/500 loss 16.997314 loss_att 13.014391 loss_ctc 26.290800 loss_ctc_origin 19.564049 loss_ctc0 41.986553 history loss 24.797341 rank 0
2022-08-25 04:54:00,026 DEBUG CV Batch 140/600 loss 17.304955 loss_att 12.073607 loss_ctc 29.511427 loss_ctc_origin 19.052206 loss_ctc0 53.916275 history loss 24.636871 rank 0
2022-08-25 04:54:09,507 DEBUG CV Batch 140/700 loss 18.257179 loss_att 12.443237 loss_ctc 31.823046 loss_ctc_origin 18.335869 loss_ctc0 63.293121 history loss 24.289540 rank 0
2022-08-25 04:54:19,467 DEBUG CV Batch 140/800 loss 23.021448 loss_att 18.151716 loss_ctc 34.384155 loss_ctc_origin 19.518482 loss_ctc0 69.070732 history loss 24.247991 rank 0
2022-08-25 04:54:29,814 INFO Epoch 140 CV info cv_loss 24.347213839905503
2022-08-25 04:54:29,814 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/140.pt
2022-08-25 04:54:30,271 INFO Epoch 141 TRAIN info lr 0.0007062210292558347
2022-08-25 04:54:30,274 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 04:54:57,212 DEBUG TRAIN Batch 141/0 loss 39.346504 loss_att 24.870373 loss_ctc 73.124146 loss_ctc_origin 44.610950 loss_ctc0 139.654938 lr 0.00070622 rank 0
2022-08-25 04:55:24,879 DEBUG TRAIN Batch 141/100 loss 53.313950 loss_att 28.336189 loss_ctc 111.595390 loss_ctc_origin 67.315880 loss_ctc0 214.914246 lr 0.00070618 rank 0
2022-08-25 04:55:52,566 DEBUG TRAIN Batch 141/200 loss 19.518761 loss_att 10.425447 loss_ctc 40.736488 loss_ctc_origin 28.746126 loss_ctc0 68.714005 lr 0.00070613 rank 0
2022-08-25 04:56:21,051 DEBUG TRAIN Batch 141/300 loss 21.545464 loss_att 8.507545 loss_ctc 51.967274 loss_ctc_origin 36.821808 loss_ctc0 87.306694 lr 0.00070609 rank 0
2022-08-25 04:56:50,019 DEBUG TRAIN Batch 141/400 loss 18.640118 loss_att 7.518499 loss_ctc 44.590561 loss_ctc_origin 26.358555 loss_ctc0 87.131912 lr 0.00070604 rank 0
2022-08-25 04:57:20,048 DEBUG TRAIN Batch 141/500 loss 41.259209 loss_att 26.722363 loss_ctc 75.178513 loss_ctc_origin 42.786957 loss_ctc0 150.758820 lr 0.00070600 rank 0
2022-08-25 04:57:49,070 DEBUG TRAIN Batch 141/600 loss 51.351299 loss_att 28.691706 loss_ctc 104.223679 loss_ctc_origin 54.192062 loss_ctc0 220.964096 lr 0.00070596 rank 0
2022-08-25 04:58:18,298 DEBUG TRAIN Batch 141/700 loss 18.055998 loss_att 8.968518 loss_ctc 39.260117 loss_ctc_origin 27.471594 loss_ctc0 66.766663 lr 0.00070591 rank 0
2022-08-25 04:58:47,128 DEBUG TRAIN Batch 141/800 loss 19.996361 loss_att 8.498713 loss_ctc 46.824203 loss_ctc_origin 32.138542 loss_ctc0 81.090736 lr 0.00070587 rank 0
2022-08-25 04:59:16,748 DEBUG TRAIN Batch 141/900 loss 24.066412 loss_att 10.570887 loss_ctc 55.555969 loss_ctc_origin 36.305111 loss_ctc0 100.474625 lr 0.00070582 rank 0
2022-08-25 04:59:44,634 DEBUG TRAIN Batch 141/1000 loss 43.358765 loss_att 28.249176 loss_ctc 78.614471 loss_ctc_origin 46.911819 loss_ctc0 152.587311 lr 0.00070578 rank 0
2022-08-25 05:00:13,376 DEBUG TRAIN Batch 141/1100 loss 57.784180 loss_att 32.078403 loss_ctc 117.764320 loss_ctc_origin 58.512009 loss_ctc0 256.019714 lr 0.00070574 rank 0
2022-08-25 05:00:43,271 DEBUG TRAIN Batch 141/1200 loss 16.816109 loss_att 9.448179 loss_ctc 34.007946 loss_ctc_origin 22.513094 loss_ctc0 60.829269 lr 0.00070569 rank 0
2022-08-25 05:01:12,999 DEBUG TRAIN Batch 141/1300 loss 20.613274 loss_att 8.408104 loss_ctc 49.092003 loss_ctc_origin 35.364075 loss_ctc0 81.123840 lr 0.00070565 rank 0
2022-08-25 05:01:42,959 DEBUG TRAIN Batch 141/1400 loss 19.409746 loss_att 8.515833 loss_ctc 44.828873 loss_ctc_origin 28.188589 loss_ctc0 83.656197 lr 0.00070560 rank 0
2022-08-25 05:02:18,122 DEBUG TRAIN Batch 141/1500 loss 53.310333 loss_att 34.132839 loss_ctc 98.057816 loss_ctc_origin 57.268364 loss_ctc0 193.233185 lr 0.00070556 rank 0
2022-08-25 05:02:46,835 DEBUG TRAIN Batch 141/1600 loss 59.222389 loss_att 33.014446 loss_ctc 120.374260 loss_ctc_origin 65.692749 loss_ctc0 247.964447 lr 0.00070552 rank 0
2022-08-25 05:03:15,308 DEBUG TRAIN Batch 141/1700 loss 19.425835 loss_att 9.811553 loss_ctc 41.859161 loss_ctc_origin 31.052784 loss_ctc0 67.074051 lr 0.00070547 rank 0
2022-08-25 05:03:44,654 DEBUG TRAIN Batch 141/1800 loss 16.505770 loss_att 6.554284 loss_ctc 39.725899 loss_ctc_origin 23.197445 loss_ctc0 78.292290 lr 0.00070543 rank 0
2022-08-25 05:04:13,401 DEBUG TRAIN Batch 141/1900 loss 22.153721 loss_att 9.908053 loss_ctc 50.726944 loss_ctc_origin 32.165146 loss_ctc0 94.037796 lr 0.00070538 rank 0
2022-08-25 05:04:42,438 DEBUG TRAIN Batch 141/2000 loss 47.910385 loss_att 31.278542 loss_ctc 86.718010 loss_ctc_origin 50.193932 loss_ctc0 171.940857 lr 0.00070534 rank 0
2022-08-25 05:05:10,801 DEBUG TRAIN Batch 141/2100 loss 58.061394 loss_att 31.996670 loss_ctc 118.879074 loss_ctc_origin 62.265030 loss_ctc0 250.978485 lr 0.00070530 rank 0
2022-08-25 05:05:40,517 DEBUG TRAIN Batch 141/2200 loss 16.598104 loss_att 7.468294 loss_ctc 37.900993 loss_ctc_origin 24.466331 loss_ctc0 69.248535 lr 0.00070525 rank 0
2022-08-25 05:06:08,070 DEBUG TRAIN Batch 141/2300 loss 21.696754 loss_att 10.253133 loss_ctc 48.398537 loss_ctc_origin 35.589348 loss_ctc0 78.286652 lr 0.00070521 rank 0
2022-08-25 05:06:36,945 DEBUG TRAIN Batch 141/2400 loss 18.628979 loss_att 7.301920 loss_ctc 45.058777 loss_ctc_origin 25.898638 loss_ctc0 89.765762 lr 0.00070516 rank 0
2022-08-25 05:07:05,789 DEBUG TRAIN Batch 141/2500 loss 48.977139 loss_att 30.766068 loss_ctc 91.469635 loss_ctc_origin 53.053703 loss_ctc0 181.106812 lr 0.00070512 rank 0
2022-08-25 05:07:34,635 DEBUG TRAIN Batch 141/2600 loss 63.914989 loss_att 40.164410 loss_ctc 119.333008 loss_ctc_origin 61.411816 loss_ctc0 254.482452 lr 0.00070508 rank 0
2022-08-25 05:08:03,100 DEBUG TRAIN Batch 141/2700 loss 17.613668 loss_att 8.431919 loss_ctc 39.037750 loss_ctc_origin 26.590546 loss_ctc0 68.081223 lr 0.00070503 rank 0
2022-08-25 05:08:32,195 DEBUG TRAIN Batch 141/2800 loss 22.976154 loss_att 10.369209 loss_ctc 52.392357 loss_ctc_origin 39.870300 loss_ctc0 81.610489 lr 0.00070499 rank 0
2022-08-25 05:08:59,862 DEBUG TRAIN Batch 141/2900 loss 21.841093 loss_att 9.129221 loss_ctc 51.502129 loss_ctc_origin 32.739197 loss_ctc0 95.282310 lr 0.00070495 rank 0
2022-08-25 05:09:36,742 DEBUG TRAIN Batch 141/3000 loss 45.635590 loss_att 28.667194 loss_ctc 85.228508 loss_ctc_origin 51.079105 loss_ctc0 164.910431 lr 0.00070490 rank 0
2022-08-25 05:10:04,897 DEBUG TRAIN Batch 141/3100 loss 61.712898 loss_att 34.682785 loss_ctc 124.783173 loss_ctc_origin 73.389290 loss_ctc0 244.702209 lr 0.00070486 rank 0
2022-08-25 05:10:32,900 DEBUG TRAIN Batch 141/3200 loss 20.690285 loss_att 10.989557 loss_ctc 43.325310 loss_ctc_origin 31.685013 loss_ctc0 70.486008 lr 0.00070481 rank 0
2022-08-25 05:11:00,970 DEBUG TRAIN Batch 141/3300 loss 19.618229 loss_att 8.645119 loss_ctc 45.222149 loss_ctc_origin 30.179039 loss_ctc0 80.322739 lr 0.00070477 rank 0
2022-08-25 05:11:29,841 DEBUG TRAIN Batch 141/3400 loss 19.814848 loss_att 8.240387 loss_ctc 46.821922 loss_ctc_origin 30.636484 loss_ctc0 84.587944 lr 0.00070473 rank 0
2022-08-25 05:11:58,698 DEBUG TRAIN Batch 141/3500 loss 50.405380 loss_att 32.688438 loss_ctc 91.744904 loss_ctc_origin 57.071766 loss_ctc0 172.648865 lr 0.00070468 rank 0
2022-08-25 05:12:27,498 DEBUG TRAIN Batch 141/3600 loss 61.134346 loss_att 35.423412 loss_ctc 121.126526 loss_ctc_origin 71.206436 loss_ctc0 237.606720 lr 0.00070464 rank 0
2022-08-25 05:12:55,177 DEBUG TRAIN Batch 141/3700 loss 19.175278 loss_att 11.353103 loss_ctc 37.427021 loss_ctc_origin 25.641174 loss_ctc0 64.927330 lr 0.00070460 rank 0
2022-08-25 05:13:23,375 DEBUG TRAIN Batch 141/3800 loss 22.501911 loss_att 9.945254 loss_ctc 51.800774 loss_ctc_origin 37.131256 loss_ctc0 86.029648 lr 0.00070455 rank 0
2022-08-25 05:13:52,450 DEBUG TRAIN Batch 141/3900 loss 23.241154 loss_att 9.753940 loss_ctc 54.711323 loss_ctc_origin 37.127895 loss_ctc0 95.739319 lr 0.00070451 rank 0
2022-08-25 05:14:22,139 DEBUG TRAIN Batch 141/4000 loss 54.260460 loss_att 35.324711 loss_ctc 98.443871 loss_ctc_origin 61.057518 loss_ctc0 185.678696 lr 0.00070446 rank 0
2022-08-25 05:14:52,077 DEBUG TRAIN Batch 141/4100 loss 58.059704 loss_att 29.377638 loss_ctc 124.984520 loss_ctc_origin 62.580982 loss_ctc0 270.592773 lr 0.00070442 rank 0
2022-08-25 05:15:20,458 DEBUG TRAIN Batch 141/4200 loss 20.727713 loss_att 11.797499 loss_ctc 41.564877 loss_ctc_origin 30.486366 loss_ctc0 67.414734 lr 0.00070438 rank 0
2022-08-25 05:15:47,910 DEBUG TRAIN Batch 141/4300 loss 17.678394 loss_att 7.019216 loss_ctc 42.549805 loss_ctc_origin 28.455341 loss_ctc0 75.436874 lr 0.00070433 rank 0
2022-08-25 05:16:16,334 DEBUG TRAIN Batch 141/4400 loss 22.595953 loss_att 9.680126 loss_ctc 52.732883 loss_ctc_origin 35.576180 loss_ctc0 92.765190 lr 0.00070429 rank 0
2022-08-25 05:16:50,988 DEBUG TRAIN Batch 141/4500 loss 43.064800 loss_att 26.358570 loss_ctc 82.046005 loss_ctc_origin 49.740112 loss_ctc0 157.426422 lr 0.00070425 rank 0
2022-08-25 05:17:20,122 DEBUG TRAIN Batch 141/4600 loss 52.713722 loss_att 28.424793 loss_ctc 109.387886 loss_ctc_origin 57.068100 loss_ctc0 231.467377 lr 0.00070420 rank 0
2022-08-25 05:17:48,154 DEBUG TRAIN Batch 141/4700 loss 18.729090 loss_att 8.299192 loss_ctc 43.065514 loss_ctc_origin 32.477695 loss_ctc0 67.770416 lr 0.00070416 rank 0
2022-08-25 05:18:17,221 DEBUG TRAIN Batch 141/4800 loss 19.772659 loss_att 9.037182 loss_ctc 44.822102 loss_ctc_origin 31.617332 loss_ctc0 75.633232 lr 0.00070412 rank 0
2022-08-25 05:18:45,480 DEBUG TRAIN Batch 141/4900 loss 21.949171 loss_att 9.523502 loss_ctc 50.942398 loss_ctc_origin 31.915657 loss_ctc0 95.338127 lr 0.00070407 rank 0
2022-08-25 05:19:14,107 DEBUG TRAIN Batch 141/5000 loss 42.253487 loss_att 27.514444 loss_ctc 76.644585 loss_ctc_origin 43.126076 loss_ctc0 154.854431 lr 0.00070403 rank 0
2022-08-25 05:19:40,635 DEBUG TRAIN Batch 141/5100 loss 59.487556 loss_att 31.586176 loss_ctc 124.590767 loss_ctc_origin 65.208458 loss_ctc0 263.149475 lr 0.00070398 rank 0
2022-08-25 05:20:08,405 DEBUG TRAIN Batch 141/5200 loss 20.142706 loss_att 13.687323 loss_ctc 35.205269 loss_ctc_origin 25.393589 loss_ctc0 58.099186 lr 0.00070394 rank 0
2022-08-25 05:20:34,678 DEBUG TRAIN Batch 141/5300 loss 17.993473 loss_att 7.236572 loss_ctc 43.092903 loss_ctc_origin 29.638353 loss_ctc0 74.486847 lr 0.00070390 rank 0
2022-08-25 05:21:03,280 DEBUG TRAIN Batch 141/5400 loss 23.968861 loss_att 11.306584 loss_ctc 53.514168 loss_ctc_origin 36.102459 loss_ctc0 94.141487 lr 0.00070385 rank 0
2022-08-25 05:21:30,073 DEBUG TRAIN Batch 141/5500 loss 52.271988 loss_att 32.965187 loss_ctc 97.321198 loss_ctc_origin 54.578045 loss_ctc0 197.055206 lr 0.00070381 rank 0
2022-08-25 05:21:56,942 DEBUG TRAIN Batch 141/5600 loss 58.507053 loss_att 33.439484 loss_ctc 116.998047 loss_ctc_origin 63.725456 loss_ctc0 241.300751 lr 0.00070377 rank 0
2022-08-25 05:22:19,907 DEBUG CV Batch 141/0 loss 11.581123 loss_att 8.454162 loss_ctc 18.877365 loss_ctc_origin 12.409531 loss_ctc0 33.968979 history loss 10.899881 rank 0
2022-08-25 05:22:29,946 DEBUG CV Batch 141/100 loss 21.269604 loss_att 17.096872 loss_ctc 31.005974 loss_ctc_origin 21.219128 loss_ctc0 53.841949 history loss 26.748574 rank 0
2022-08-25 05:22:39,096 DEBUG CV Batch 141/200 loss 24.883072 loss_att 19.572132 loss_ctc 37.275261 loss_ctc_origin 26.665333 loss_ctc0 62.031754 history loss 28.047113 rank 0
2022-08-25 05:22:48,665 DEBUG CV Batch 141/300 loss 23.328054 loss_att 17.410446 loss_ctc 37.135807 loss_ctc_origin 21.971378 loss_ctc0 72.519470 history loss 27.025859 rank 0
2022-08-25 05:22:58,620 DEBUG CV Batch 141/400 loss 37.958092 loss_att 30.730434 loss_ctc 54.822632 loss_ctc_origin 37.548229 loss_ctc0 95.129578 history loss 25.345012 rank 0
2022-08-25 05:23:08,501 DEBUG CV Batch 141/500 loss 16.987988 loss_att 12.635206 loss_ctc 27.144474 loss_ctc_origin 20.486858 loss_ctc0 42.678909 history loss 24.988754 rank 0
2022-08-25 05:23:18,542 DEBUG CV Batch 141/600 loss 17.322849 loss_att 12.002039 loss_ctc 29.738068 loss_ctc_origin 19.345718 loss_ctc0 53.986885 history loss 24.814869 rank 0
2022-08-25 05:23:27,837 DEBUG CV Batch 141/700 loss 18.803829 loss_att 13.037415 loss_ctc 32.258797 loss_ctc_origin 18.757267 loss_ctc0 63.762371 history loss 24.461376 rank 0
2022-08-25 05:23:37,462 DEBUG CV Batch 141/800 loss 22.193623 loss_att 17.521547 loss_ctc 33.095131 loss_ctc_origin 17.761066 loss_ctc0 68.874619 history loss 24.411302 rank 0
2022-08-25 05:23:47,474 INFO Epoch 141 CV info cv_loss 24.492972606073963
2022-08-25 05:23:47,475 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/141.pt
2022-08-25 05:23:47,921 INFO Epoch 142 TRAIN info lr 0.0007037299420252534
2022-08-25 05:23:47,925 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 05:24:14,272 DEBUG TRAIN Batch 142/0 loss 50.386711 loss_att 32.710339 loss_ctc 91.631577 loss_ctc_origin 57.738102 loss_ctc0 170.716354 lr 0.00070373 rank 0
2022-08-25 05:24:42,703 DEBUG TRAIN Batch 142/100 loss 57.205452 loss_att 32.957893 loss_ctc 113.783081 loss_ctc_origin 68.360168 loss_ctc0 219.769897 lr 0.00070368 rank 0
2022-08-25 05:25:11,063 DEBUG TRAIN Batch 142/200 loss 19.994026 loss_att 11.318718 loss_ctc 40.236412 loss_ctc_origin 29.222191 loss_ctc0 65.936264 lr 0.00070364 rank 0
2022-08-25 05:25:40,248 DEBUG TRAIN Batch 142/300 loss 18.356670 loss_att 7.190080 loss_ctc 44.412048 loss_ctc_origin 29.023994 loss_ctc0 80.317505 lr 0.00070360 rank 0
2022-08-25 05:26:08,681 DEBUG TRAIN Batch 142/400 loss 23.147837 loss_att 8.601012 loss_ctc 57.090424 loss_ctc_origin 38.080051 loss_ctc0 101.447945 lr 0.00070355 rank 0
2022-08-25 05:26:37,828 DEBUG TRAIN Batch 142/500 loss 45.965443 loss_att 28.364502 loss_ctc 87.034302 loss_ctc_origin 55.255665 loss_ctc0 161.184448 lr 0.00070351 rank 0
2022-08-25 05:26:45,050 WARNING NaN or Inf found in input tensor.
2022-08-25 05:27:05,962 DEBUG TRAIN Batch 142/600 loss 56.253098 loss_att 28.765984 loss_ctc 120.389694 loss_ctc_origin 67.616318 loss_ctc0 243.527557 lr 0.00070347 rank 0
2022-08-25 05:27:35,163 DEBUG TRAIN Batch 142/700 loss 18.928745 loss_att 8.917624 loss_ctc 42.288025 loss_ctc_origin 31.584883 loss_ctc0 67.262032 lr 0.00070342 rank 0
2022-08-25 05:28:03,734 DEBUG TRAIN Batch 142/800 loss 18.856701 loss_att 6.898277 loss_ctc 46.759689 loss_ctc_origin 32.397797 loss_ctc0 80.270775 lr 0.00070338 rank 0
2022-08-25 05:28:20,246 WARNING NaN or Inf found in input tensor.
2022-08-25 05:28:32,027 DEBUG TRAIN Batch 142/900 loss 19.646061 loss_att 8.040409 loss_ctc 46.725910 loss_ctc_origin 29.206255 loss_ctc0 87.605103 lr 0.00070334 rank 0
2022-08-25 05:29:00,073 DEBUG TRAIN Batch 142/1000 loss 49.421181 loss_att 34.221046 loss_ctc 84.888153 loss_ctc_origin 53.223583 loss_ctc0 158.772141 lr 0.00070329 rank 0
2022-08-25 05:29:28,168 DEBUG TRAIN Batch 142/1100 loss 62.165039 loss_att 37.125359 loss_ctc 120.590958 loss_ctc_origin 71.599846 loss_ctc0 234.903564 lr 0.00070325 rank 0
2022-08-25 05:29:58,827 DEBUG TRAIN Batch 142/1200 loss 20.751894 loss_att 10.751680 loss_ctc 44.085724 loss_ctc_origin 32.980545 loss_ctc0 69.997803 lr 0.00070321 rank 0
2022-08-25 05:30:27,836 DEBUG TRAIN Batch 142/1300 loss 21.023731 loss_att 9.141696 loss_ctc 48.748474 loss_ctc_origin 32.221352 loss_ctc0 87.311768 lr 0.00070316 rank 0
2022-08-25 05:30:57,254 DEBUG TRAIN Batch 142/1400 loss 21.928511 loss_att 9.503757 loss_ctc 50.919601 loss_ctc_origin 31.766726 loss_ctc0 95.609650 lr 0.00070312 rank 0
2022-08-25 05:31:32,262 DEBUG TRAIN Batch 142/1500 loss 41.504990 loss_att 25.814320 loss_ctc 78.116547 loss_ctc_origin 51.092205 loss_ctc0 141.173340 lr 0.00070308 rank 0
2022-08-25 05:32:02,147 DEBUG TRAIN Batch 142/1600 loss 52.160210 loss_att 28.460087 loss_ctc 107.460503 loss_ctc_origin 59.715153 loss_ctc0 218.866318 lr 0.00070303 rank 0
2022-08-25 05:32:31,716 DEBUG TRAIN Batch 142/1700 loss 21.146988 loss_att 10.256992 loss_ctc 46.556976 loss_ctc_origin 34.454536 loss_ctc0 74.796005 lr 0.00070299 rank 0
2022-08-25 05:33:00,225 DEBUG TRAIN Batch 142/1800 loss 24.060282 loss_att 10.637669 loss_ctc 55.379715 loss_ctc_origin 41.760536 loss_ctc0 87.157806 lr 0.00070295 rank 0
2022-08-25 05:33:28,596 DEBUG TRAIN Batch 142/1900 loss 21.487755 loss_att 8.979191 loss_ctc 50.674400 loss_ctc_origin 33.200722 loss_ctc0 91.446320 lr 0.00070290 rank 0
2022-08-25 05:33:57,400 DEBUG TRAIN Batch 142/2000 loss 53.012600 loss_att 35.962936 loss_ctc 92.795143 loss_ctc_origin 65.705276 loss_ctc0 156.004822 lr 0.00070286 rank 0
2022-08-25 05:34:26,228 DEBUG TRAIN Batch 142/2100 loss 58.983757 loss_att 36.405464 loss_ctc 111.666428 loss_ctc_origin 63.255146 loss_ctc0 224.626068 lr 0.00070282 rank 0
2022-08-25 05:34:55,071 DEBUG TRAIN Batch 142/2200 loss 22.622540 loss_att 12.673088 loss_ctc 45.837921 loss_ctc_origin 32.944633 loss_ctc0 75.922264 lr 0.00070277 rank 0
2022-08-25 05:35:23,274 DEBUG TRAIN Batch 142/2300 loss 20.870808 loss_att 9.872507 loss_ctc 46.533508 loss_ctc_origin 32.355610 loss_ctc0 79.615280 lr 0.00070273 rank 0
2022-08-25 05:35:52,233 DEBUG TRAIN Batch 142/2400 loss 22.963728 loss_att 9.085664 loss_ctc 55.345879 loss_ctc_origin 37.316544 loss_ctc0 97.414322 lr 0.00070268 rank 0
2022-08-25 05:36:21,249 DEBUG TRAIN Batch 142/2500 loss 49.568253 loss_att 31.637613 loss_ctc 91.406403 loss_ctc_origin 59.347206 loss_ctc0 166.211166 lr 0.00070264 rank 0
2022-08-25 05:36:50,069 DEBUG TRAIN Batch 142/2600 loss 49.132046 loss_att 24.925682 loss_ctc 105.613556 loss_ctc_origin 54.803734 loss_ctc0 224.169815 lr 0.00070260 rank 0
2022-08-25 05:37:20,507 DEBUG TRAIN Batch 142/2700 loss 21.660484 loss_att 12.931044 loss_ctc 42.029182 loss_ctc_origin 32.829010 loss_ctc0 63.496243 lr 0.00070255 rank 0
2022-08-25 05:37:51,055 DEBUG TRAIN Batch 142/2800 loss 20.891447 loss_att 9.901269 loss_ctc 46.535194 loss_ctc_origin 32.963161 loss_ctc0 78.203278 lr 0.00070251 rank 0
2022-08-25 05:38:17,822 DEBUG TRAIN Batch 142/2900 loss 24.836082 loss_att 11.824554 loss_ctc 55.196312 loss_ctc_origin 35.232796 loss_ctc0 101.777847 lr 0.00070247 rank 0
2022-08-25 05:38:53,933 DEBUG TRAIN Batch 142/3000 loss 49.260109 loss_att 33.380699 loss_ctc 86.312065 loss_ctc_origin 57.046978 loss_ctc0 154.597260 lr 0.00070242 rank 0
2022-08-25 05:39:22,939 DEBUG TRAIN Batch 142/3100 loss 59.563873 loss_att 34.088600 loss_ctc 119.006172 loss_ctc_origin 69.624832 loss_ctc0 234.229294 lr 0.00070238 rank 0
2022-08-25 05:39:50,990 DEBUG TRAIN Batch 142/3200 loss 20.801195 loss_att 9.438314 loss_ctc 47.314583 loss_ctc_origin 35.700142 loss_ctc0 74.414948 lr 0.00070234 rank 0
2022-08-25 05:40:19,535 DEBUG TRAIN Batch 142/3300 loss 19.017323 loss_att 8.336810 loss_ctc 43.938515 loss_ctc_origin 26.863888 loss_ctc0 83.779297 lr 0.00070229 rank 0
2022-08-25 05:40:48,216 DEBUG TRAIN Batch 142/3400 loss 21.141270 loss_att 9.068561 loss_ctc 49.310921 loss_ctc_origin 31.552580 loss_ctc0 90.747047 lr 0.00070225 rank 0
2022-08-25 05:41:18,551 DEBUG TRAIN Batch 142/3500 loss 47.012825 loss_att 31.270287 loss_ctc 83.745407 loss_ctc_origin 54.803658 loss_ctc0 151.276169 lr 0.00070221 rank 0
2022-08-25 05:41:39,791 WARNING NaN or Inf found in input tensor.
2022-08-25 05:41:46,679 DEBUG TRAIN Batch 142/3600 loss 61.403000 loss_att 35.456165 loss_ctc 121.945602 loss_ctc_origin 70.797432 loss_ctc0 241.291321 lr 0.00070217 rank 0
2022-08-25 05:42:15,872 DEBUG TRAIN Batch 142/3700 loss 18.605576 loss_att 9.862765 loss_ctc 39.005470 loss_ctc_origin 26.869997 loss_ctc0 67.321571 lr 0.00070212 rank 0
2022-08-25 05:42:43,721 DEBUG TRAIN Batch 142/3800 loss 17.177523 loss_att 7.014836 loss_ctc 40.890457 loss_ctc_origin 26.846634 loss_ctc0 73.659378 lr 0.00070208 rank 0
2022-08-25 05:43:00,433 WARNING NaN or Inf found in input tensor.
2022-08-25 05:43:07,087 WARNING NaN or Inf found in input tensor.
2022-08-25 05:43:11,224 DEBUG TRAIN Batch 142/3900 loss 25.306486 loss_att 10.670630 loss_ctc 59.456818 loss_ctc_origin 41.953945 loss_ctc0 100.296844 lr 0.00070204 rank 0
2022-08-25 05:43:40,726 DEBUG TRAIN Batch 142/4000 loss 44.831444 loss_att 28.002014 loss_ctc 84.100113 loss_ctc_origin 53.047001 loss_ctc0 156.557373 lr 0.00070199 rank 0
2022-08-25 05:44:01,918 WARNING NaN or Inf found in input tensor.
2022-08-25 05:44:08,817 DEBUG TRAIN Batch 142/4100 loss 51.954208 loss_att 27.492931 loss_ctc 109.030518 loss_ctc_origin 56.582909 loss_ctc0 231.408279 lr 0.00070195 rank 0
2022-08-25 05:44:36,750 DEBUG TRAIN Batch 142/4200 loss 22.399036 loss_att 13.266859 loss_ctc 43.707451 loss_ctc_origin 33.581100 loss_ctc0 67.335602 lr 0.00070191 rank 0
2022-08-25 05:45:05,832 DEBUG TRAIN Batch 142/4300 loss 25.977432 loss_att 11.627513 loss_ctc 59.460571 loss_ctc_origin 46.892448 loss_ctc0 88.786179 lr 0.00070186 rank 0
2022-08-25 05:45:30,642 WARNING NaN or Inf found in input tensor.
2022-08-25 05:45:34,985 DEBUG TRAIN Batch 142/4400 loss 23.356911 loss_att 10.123158 loss_ctc 54.235664 loss_ctc_origin 37.158722 loss_ctc0 94.081871 lr 0.00070182 rank 0
2022-08-25 05:46:11,949 DEBUG TRAIN Batch 142/4500 loss 41.938126 loss_att 27.699371 loss_ctc 75.161880 loss_ctc_origin 43.248569 loss_ctc0 149.626282 lr 0.00070178 rank 0
2022-08-25 05:46:39,406 DEBUG TRAIN Batch 142/4600 loss 55.081223 loss_att 29.571352 loss_ctc 114.604248 loss_ctc_origin 64.596436 loss_ctc0 231.289154 lr 0.00070173 rank 0
2022-08-25 05:47:08,779 DEBUG TRAIN Batch 142/4700 loss 20.171730 loss_att 11.583893 loss_ctc 40.210014 loss_ctc_origin 30.407848 loss_ctc0 63.081726 lr 0.00070169 rank 0
2022-08-25 05:47:37,061 DEBUG TRAIN Batch 142/4800 loss 20.877071 loss_att 9.089982 loss_ctc 48.380280 loss_ctc_origin 33.809799 loss_ctc0 82.378059 lr 0.00070165 rank 0
2022-08-25 05:48:01,303 WARNING NaN or Inf found in input tensor.
2022-08-25 05:48:05,990 DEBUG TRAIN Batch 142/4900 loss 23.771355 loss_att 10.815434 loss_ctc 54.001835 loss_ctc_origin 35.940979 loss_ctc0 96.143829 lr 0.00070160 rank 0
2022-08-25 05:48:35,228 DEBUG TRAIN Batch 142/5000 loss 29.477570 loss_att 22.838741 loss_ctc 44.968166 loss_ctc_origin 44.740288 loss_ctc0 45.499886 lr 0.00070156 rank 0
2022-08-25 05:49:04,136 DEBUG TRAIN Batch 142/5100 loss 42.440090 loss_att 19.371729 loss_ctc 96.266258 loss_ctc_origin 45.793034 loss_ctc0 214.037109 lr 0.00070152 rank 0
2022-08-25 05:49:32,532 DEBUG TRAIN Batch 142/5200 loss 19.760302 loss_att 11.075636 loss_ctc 40.024521 loss_ctc_origin 29.187817 loss_ctc0 65.310158 lr 0.00070147 rank 0
2022-08-25 05:50:01,053 DEBUG TRAIN Batch 142/5300 loss 19.316225 loss_att 8.352456 loss_ctc 44.898354 loss_ctc_origin 30.552807 loss_ctc0 78.371300 lr 0.00070143 rank 0
2022-08-25 05:50:29,124 DEBUG TRAIN Batch 142/5400 loss 19.351173 loss_att 7.672872 loss_ctc 46.600540 loss_ctc_origin 29.958118 loss_ctc0 85.432854 lr 0.00070139 rank 0
2022-08-25 05:50:57,891 DEBUG TRAIN Batch 142/5500 loss 25.805222 loss_att 21.287796 loss_ctc 36.345882 loss_ctc_origin 32.285671 loss_ctc0 45.819710 lr 0.00070134 rank 0
2022-08-25 05:51:25,991 DEBUG TRAIN Batch 142/5600 loss 53.932064 loss_att 30.895758 loss_ctc 107.683441 loss_ctc_origin 62.177464 loss_ctc0 213.864044 lr 0.00070130 rank 0
2022-08-25 05:51:50,397 DEBUG CV Batch 142/0 loss 12.443340 loss_att 9.262735 loss_ctc 19.864750 loss_ctc_origin 13.466772 loss_ctc0 34.793365 history loss 11.711379 rank 0
2022-08-25 05:52:01,222 DEBUG CV Batch 142/100 loss 21.437759 loss_att 17.302685 loss_ctc 31.086269 loss_ctc_origin 21.285585 loss_ctc0 53.954529 history loss 26.536872 rank 0
2022-08-25 05:52:10,620 DEBUG CV Batch 142/200 loss 24.154669 loss_att 18.712002 loss_ctc 36.854225 loss_ctc_origin 26.050653 loss_ctc0 62.062561 history loss 27.777839 rank 0
2022-08-25 05:52:20,506 DEBUG CV Batch 142/300 loss 23.022276 loss_att 17.514208 loss_ctc 35.874435 loss_ctc_origin 20.468815 loss_ctc0 71.820877 history loss 26.746811 rank 0
2022-08-25 05:52:30,720 DEBUG CV Batch 142/400 loss 38.285221 loss_att 31.240070 loss_ctc 54.723900 loss_ctc_origin 37.688766 loss_ctc0 94.472549 history loss 25.111523 rank 0
2022-08-25 05:52:41,115 DEBUG CV Batch 142/500 loss 16.732769 loss_att 12.638254 loss_ctc 26.286636 loss_ctc_origin 19.437424 loss_ctc0 42.268127 history loss 24.778005 rank 0
2022-08-25 05:52:51,720 DEBUG CV Batch 142/600 loss 17.834763 loss_att 12.297907 loss_ctc 30.754091 loss_ctc_origin 20.634109 loss_ctc0 54.367378 history loss 24.632100 rank 0
2022-08-25 05:53:01,504 DEBUG CV Batch 142/700 loss 18.471640 loss_att 12.696857 loss_ctc 31.946129 loss_ctc_origin 18.188274 loss_ctc0 64.047791 history loss 24.275157 rank 0
2022-08-25 05:53:11,884 DEBUG CV Batch 142/800 loss 22.265127 loss_att 17.605373 loss_ctc 33.137886 loss_ctc_origin 17.738895 loss_ctc0 69.068863 history loss 24.231944 rank 0
2022-08-25 05:53:22,034 INFO Epoch 142 CV info cv_loss 24.323123134438106
2022-08-25 05:53:22,035 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/142.pt
2022-08-25 05:53:22,480 INFO Epoch 143 TRAIN info lr 0.0007012650309771462
2022-08-25 05:53:22,484 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 05:53:49,185 DEBUG TRAIN Batch 143/0 loss 40.202106 loss_att 25.937611 loss_ctc 73.485931 loss_ctc_origin 41.014008 loss_ctc0 149.253754 lr 0.00070126 rank 0
2022-08-25 05:54:17,580 DEBUG TRAIN Batch 143/100 loss 58.003952 loss_att 34.139893 loss_ctc 113.686760 loss_ctc_origin 70.440895 loss_ctc0 214.593781 lr 0.00070122 rank 0
2022-08-25 05:54:47,591 DEBUG TRAIN Batch 143/200 loss 18.217299 loss_att 9.226989 loss_ctc 39.194687 loss_ctc_origin 27.028072 loss_ctc0 67.583450 lr 0.00070118 rank 0
2022-08-25 05:55:17,025 DEBUG TRAIN Batch 143/300 loss 19.433926 loss_att 8.297806 loss_ctc 45.418201 loss_ctc_origin 30.926752 loss_ctc0 79.231583 lr 0.00070113 rank 0
2022-08-25 05:55:45,634 DEBUG TRAIN Batch 143/400 loss 21.678188 loss_att 9.154993 loss_ctc 50.898979 loss_ctc_origin 34.581856 loss_ctc0 88.972275 lr 0.00070109 rank 0
2022-08-25 05:56:13,953 DEBUG TRAIN Batch 143/500 loss 39.982155 loss_att 25.322535 loss_ctc 74.187927 loss_ctc_origin 42.397549 loss_ctc0 148.365479 lr 0.00070105 rank 0
2022-08-25 05:56:21,704 WARNING NaN or Inf found in input tensor.
2022-08-25 05:56:44,126 DEBUG TRAIN Batch 143/600 loss 53.610470 loss_att 28.731112 loss_ctc 111.662300 loss_ctc_origin 59.151951 loss_ctc0 234.186432 lr 0.00070100 rank 0
2022-08-25 05:57:11,456 WARNING NaN or Inf found in input tensor.
2022-08-25 05:57:13,044 DEBUG TRAIN Batch 143/700 loss 19.453699 loss_att 10.377802 loss_ctc 40.630791 loss_ctc_origin 30.447865 loss_ctc0 64.390953 lr 0.00070096 rank 0
2022-08-25 05:57:41,387 DEBUG TRAIN Batch 143/800 loss 17.066624 loss_att 7.718367 loss_ctc 38.879219 loss_ctc_origin 25.599129 loss_ctc0 69.866096 lr 0.00070092 rank 0
2022-08-25 05:58:09,899 DEBUG TRAIN Batch 143/900 loss 24.575832 loss_att 11.482198 loss_ctc 55.127644 loss_ctc_origin 36.875542 loss_ctc0 97.715874 lr 0.00070088 rank 0
2022-08-25 05:58:38,315 DEBUG TRAIN Batch 143/1000 loss 48.093353 loss_att 33.245083 loss_ctc 82.739311 loss_ctc_origin 51.708305 loss_ctc0 155.144989 lr 0.00070083 rank 0
2022-08-25 05:59:06,320 DEBUG TRAIN Batch 143/1100 loss 55.397484 loss_att 30.163742 loss_ctc 114.276222 loss_ctc_origin 63.715221 loss_ctc0 232.251877 lr 0.00070079 rank 0
2022-08-25 05:59:34,578 DEBUG TRAIN Batch 143/1200 loss 20.757629 loss_att 13.750943 loss_ctc 37.106564 loss_ctc_origin 25.961288 loss_ctc0 63.112206 lr 0.00070075 rank 0
2022-08-25 06:00:04,202 DEBUG TRAIN Batch 143/1300 loss 21.746422 loss_att 9.522403 loss_ctc 50.269127 loss_ctc_origin 37.883553 loss_ctc0 79.168808 lr 0.00070070 rank 0
2022-08-25 06:00:33,703 DEBUG TRAIN Batch 143/1400 loss 21.584513 loss_att 8.827141 loss_ctc 51.351715 loss_ctc_origin 30.372635 loss_ctc0 100.302902 lr 0.00070066 rank 0
2022-08-25 06:01:09,070 DEBUG TRAIN Batch 143/1500 loss 43.420067 loss_att 27.277107 loss_ctc 81.086960 loss_ctc_origin 51.007835 loss_ctc0 151.271576 lr 0.00070062 rank 0
2022-08-25 06:01:37,459 DEBUG TRAIN Batch 143/1600 loss 50.403633 loss_att 27.594196 loss_ctc 103.625648 loss_ctc_origin 55.550179 loss_ctc0 215.801727 lr 0.00070057 rank 0
2022-08-25 06:02:05,499 DEBUG TRAIN Batch 143/1700 loss 24.279274 loss_att 12.187225 loss_ctc 52.494049 loss_ctc_origin 43.662254 loss_ctc0 73.101578 lr 0.00070053 rank 0
2022-08-25 06:02:34,384 DEBUG TRAIN Batch 143/1800 loss 21.074722 loss_att 8.756129 loss_ctc 49.818108 loss_ctc_origin 35.362354 loss_ctc0 83.548195 lr 0.00070049 rank 0
2022-08-25 06:03:02,837 DEBUG TRAIN Batch 143/1900 loss 23.155699 loss_att 9.880131 loss_ctc 54.132023 loss_ctc_origin 35.941498 loss_ctc0 96.576576 lr 0.00070045 rank 0
2022-08-25 06:03:32,943 DEBUG TRAIN Batch 143/2000 loss 46.020847 loss_att 29.339783 loss_ctc 84.943329 loss_ctc_origin 54.275116 loss_ctc0 156.502502 lr 0.00070040 rank 0
2022-08-25 06:04:01,303 DEBUG TRAIN Batch 143/2100 loss 59.557190 loss_att 34.267464 loss_ctc 118.566551 loss_ctc_origin 73.259453 loss_ctc0 224.283112 lr 0.00070036 rank 0
2022-08-25 06:04:29,529 DEBUG TRAIN Batch 143/2200 loss 17.691118 loss_att 9.194890 loss_ctc 37.515648 loss_ctc_origin 26.475246 loss_ctc0 63.276581 lr 0.00070032 rank 0
2022-08-25 06:04:58,619 DEBUG TRAIN Batch 143/2300 loss 19.751225 loss_att 8.842400 loss_ctc 45.205147 loss_ctc_origin 29.905415 loss_ctc0 80.904526 lr 0.00070027 rank 0
2022-08-25 06:05:27,450 DEBUG TRAIN Batch 143/2400 loss 23.177599 loss_att 9.139030 loss_ctc 55.934254 loss_ctc_origin 36.082199 loss_ctc0 102.255707 lr 0.00070023 rank 0
2022-08-25 06:05:56,187 DEBUG TRAIN Batch 143/2500 loss 43.530785 loss_att 27.522898 loss_ctc 80.882515 loss_ctc_origin 49.571732 loss_ctc0 153.941010 lr 0.00070019 rank 0
2022-08-25 06:06:17,013 WARNING NaN or Inf found in input tensor.
2022-08-25 06:06:23,947 WARNING NaN or Inf found in input tensor.
2022-08-25 06:06:23,989 DEBUG TRAIN Batch 143/2600 loss nan loss_att 31.795837 loss_ctc nan loss_ctc_origin 61.000389 loss_ctc0 nan lr 0.00070015 rank 0
2022-08-25 06:06:53,368 DEBUG TRAIN Batch 143/2700 loss 16.332315 loss_att 8.959282 loss_ctc 33.536060 loss_ctc_origin 20.633173 loss_ctc0 63.642796 lr 0.00070010 rank 0
2022-08-25 06:07:22,691 DEBUG TRAIN Batch 143/2800 loss 16.530008 loss_att 7.053436 loss_ctc 38.642010 loss_ctc_origin 22.802319 loss_ctc0 75.601288 lr 0.00070006 rank 0
2022-08-25 06:07:45,600 WARNING NaN or Inf found in input tensor.
2022-08-25 06:07:49,860 DEBUG TRAIN Batch 143/2900 loss 20.418436 loss_att 7.934485 loss_ctc 49.547653 loss_ctc_origin 30.134874 loss_ctc0 94.844131 lr 0.00070002 rank 0
2022-08-25 06:08:26,488 DEBUG TRAIN Batch 143/3000 loss 47.750206 loss_att 29.827839 loss_ctc 89.569061 loss_ctc_origin 55.801281 loss_ctc0 168.360519 lr 0.00069997 rank 0
2022-08-25 06:08:55,794 DEBUG TRAIN Batch 143/3100 loss 56.434608 loss_att 30.787674 loss_ctc 116.277466 loss_ctc_origin 67.670860 loss_ctc0 229.692886 lr 0.00069993 rank 0
2022-08-25 06:09:22,476 WARNING NaN or Inf found in input tensor.
2022-08-25 06:09:24,115 DEBUG TRAIN Batch 143/3200 loss 19.128880 loss_att 9.874748 loss_ctc 40.721851 loss_ctc_origin 30.631601 loss_ctc0 64.265762 lr 0.00069989 rank 0
2022-08-25 06:09:53,037 DEBUG TRAIN Batch 143/3300 loss 21.393665 loss_att 9.786036 loss_ctc 48.478134 loss_ctc_origin 32.710258 loss_ctc0 85.269836 lr 0.00069985 rank 0
2022-08-25 06:10:16,747 WARNING NaN or Inf found in input tensor.
2022-08-25 06:10:21,106 DEBUG TRAIN Batch 143/3400 loss 21.896276 loss_att 8.929775 loss_ctc 52.151443 loss_ctc_origin 34.726433 loss_ctc0 92.809799 lr 0.00069980 rank 0
2022-08-25 06:10:49,627 DEBUG TRAIN Batch 143/3500 loss 48.020760 loss_att 32.988895 loss_ctc 83.095108 loss_ctc_origin 56.379013 loss_ctc0 145.432648 lr 0.00069976 rank 0
2022-08-25 06:11:19,283 DEBUG TRAIN Batch 143/3600 loss 52.776806 loss_att 29.699650 loss_ctc 106.623497 loss_ctc_origin 61.944847 loss_ctc0 210.873672 lr 0.00069972 rank 0
2022-08-25 06:11:47,055 DEBUG TRAIN Batch 143/3700 loss 22.972401 loss_att 14.509825 loss_ctc 42.718407 loss_ctc_origin 31.680004 loss_ctc0 68.474686 lr 0.00069967 rank 0
2022-08-25 06:12:17,068 DEBUG TRAIN Batch 143/3800 loss 20.852224 loss_att 8.373859 loss_ctc 49.968410 loss_ctc_origin 35.534531 loss_ctc0 83.647461 lr 0.00069963 rank 0
2022-08-25 06:12:45,651 DEBUG TRAIN Batch 143/3900 loss 22.053072 loss_att 9.775299 loss_ctc 50.701210 loss_ctc_origin 34.365295 loss_ctc0 88.818352 lr 0.00069959 rank 0
2022-08-25 06:13:15,543 DEBUG TRAIN Batch 143/4000 loss 41.585602 loss_att 26.247349 loss_ctc 77.374855 loss_ctc_origin 45.349899 loss_ctc0 152.099762 lr 0.00069955 rank 0
2022-08-25 06:13:44,235 DEBUG TRAIN Batch 143/4100 loss 53.286331 loss_att 31.407663 loss_ctc 104.336555 loss_ctc_origin 62.445553 loss_ctc0 202.082214 lr 0.00069950 rank 0
2022-08-25 06:14:12,641 DEBUG TRAIN Batch 143/4200 loss 18.581909 loss_att 9.839569 loss_ctc 38.980705 loss_ctc_origin 28.673237 loss_ctc0 63.031456 lr 0.00069946 rank 0
2022-08-25 06:14:39,830 DEBUG TRAIN Batch 143/4300 loss 19.405594 loss_att 7.698524 loss_ctc 46.722092 loss_ctc_origin 33.016968 loss_ctc0 78.700706 lr 0.00069942 rank 0
2022-08-25 06:15:08,694 DEBUG TRAIN Batch 143/4400 loss 23.095011 loss_att 9.945835 loss_ctc 53.776421 loss_ctc_origin 36.310600 loss_ctc0 94.529991 lr 0.00069937 rank 0
2022-08-25 06:15:44,266 DEBUG TRAIN Batch 143/4500 loss 47.833012 loss_att 32.213829 loss_ctc 84.277763 loss_ctc_origin 50.977211 loss_ctc0 161.979050 lr 0.00069933 rank 0
2022-08-25 06:16:12,788 DEBUG TRAIN Batch 143/4600 loss 57.723129 loss_att 32.498405 loss_ctc 116.580811 loss_ctc_origin 60.350010 loss_ctc0 247.785995 lr 0.00069929 rank 0
2022-08-25 06:16:39,669 WARNING NaN or Inf found in input tensor.
2022-08-25 06:16:41,212 DEBUG TRAIN Batch 143/4700 loss 17.544336 loss_att 9.327271 loss_ctc 36.717491 loss_ctc_origin 25.177582 loss_ctc0 63.643936 lr 0.00069925 rank 0
2022-08-25 06:17:09,498 DEBUG TRAIN Batch 143/4800 loss 19.044989 loss_att 7.359392 loss_ctc 46.311378 loss_ctc_origin 30.713137 loss_ctc0 82.707275 lr 0.00069920 rank 0
2022-08-25 06:17:38,356 DEBUG TRAIN Batch 143/4900 loss 20.278002 loss_att 8.447942 loss_ctc 47.881474 loss_ctc_origin 29.893150 loss_ctc0 89.854225 lr 0.00069916 rank 0
2022-08-25 06:18:07,130 DEBUG TRAIN Batch 143/5000 loss 54.040604 loss_att 36.411453 loss_ctc 95.175293 loss_ctc_origin 63.078110 loss_ctc0 170.068726 lr 0.00069912 rank 0
2022-08-25 06:18:35,025 DEBUG TRAIN Batch 143/5100 loss 54.139511 loss_att 29.059450 loss_ctc 112.659637 loss_ctc_origin 59.159233 loss_ctc0 237.493912 lr 0.00069908 rank 0
2022-08-25 06:19:03,189 DEBUG TRAIN Batch 143/5200 loss 18.235725 loss_att 9.537264 loss_ctc 38.532135 loss_ctc_origin 26.846180 loss_ctc0 65.799355 lr 0.00069903 rank 0
2022-08-25 06:19:31,000 DEBUG TRAIN Batch 143/5300 loss 16.262779 loss_att 6.821699 loss_ctc 38.291969 loss_ctc_origin 22.520128 loss_ctc0 75.092926 lr 0.00069899 rank 0
2022-08-25 06:20:00,692 DEBUG TRAIN Batch 143/5400 loss 23.634327 loss_att 9.836603 loss_ctc 55.829014 loss_ctc_origin 38.522114 loss_ctc0 96.211777 lr 0.00069895 rank 0
2022-08-25 06:20:29,177 DEBUG TRAIN Batch 143/5500 loss 50.129333 loss_att 34.933609 loss_ctc 85.586014 loss_ctc_origin 51.919418 loss_ctc0 164.141388 lr 0.00069890 rank 0
2022-08-25 06:20:58,153 DEBUG TRAIN Batch 143/5600 loss 62.147064 loss_att 39.962021 loss_ctc 113.912155 loss_ctc_origin 60.513401 loss_ctc0 238.509247 lr 0.00069886 rank 0
2022-08-25 06:21:21,765 DEBUG CV Batch 143/0 loss 11.831863 loss_att 8.324914 loss_ctc 20.014744 loss_ctc_origin 13.809296 loss_ctc0 34.494118 history loss 11.135871 rank 0
2022-08-25 06:21:32,294 DEBUG CV Batch 143/100 loss 21.486389 loss_att 17.412668 loss_ctc 30.991741 loss_ctc_origin 21.003700 loss_ctc0 54.297165 history loss 26.516936 rank 0
2022-08-25 06:21:41,704 DEBUG CV Batch 143/200 loss 24.545237 loss_att 18.823328 loss_ctc 37.896355 loss_ctc_origin 27.560493 loss_ctc0 62.013367 history loss 27.836530 rank 0
2022-08-25 06:21:51,038 DEBUG CV Batch 143/300 loss 22.448559 loss_att 16.352938 loss_ctc 36.671677 loss_ctc_origin 21.393560 loss_ctc0 72.320602 history loss 26.828838 rank 0
2022-08-25 06:22:01,142 DEBUG CV Batch 143/400 loss 38.934464 loss_att 31.136744 loss_ctc 57.129147 loss_ctc_origin 40.972893 loss_ctc0 94.827072 history loss 25.189892 rank 0
2022-08-25 06:22:11,446 DEBUG CV Batch 143/500 loss 16.661537 loss_att 12.635516 loss_ctc 26.055590 loss_ctc_origin 19.216457 loss_ctc0 42.013565 history loss 24.842351 rank 0
2022-08-25 06:22:21,919 DEBUG CV Batch 143/600 loss 17.317511 loss_att 12.023016 loss_ctc 29.671329 loss_ctc_origin 19.083496 loss_ctc0 54.376274 history loss 24.661044 rank 0
2022-08-25 06:22:32,812 DEBUG CV Batch 143/700 loss 18.284752 loss_att 12.342276 loss_ctc 32.150532 loss_ctc_origin 18.852303 loss_ctc0 63.179729 history loss 24.312278 rank 0
2022-08-25 06:22:41,742 DEBUG CV Batch 143/800 loss 22.123184 loss_att 17.451000 loss_ctc 33.024944 loss_ctc_origin 17.641315 loss_ctc0 68.920074 history loss 24.261595 rank 0
2022-08-25 06:22:51,116 INFO Epoch 143 CV info cv_loss 24.343710040866416
2022-08-25 06:22:51,116 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/143.pt
2022-08-25 06:22:51,644 INFO Epoch 144 TRAIN info lr 0.0006988258408703161
2022-08-25 06:22:51,648 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 06:23:18,350 DEBUG TRAIN Batch 144/0 loss 46.766731 loss_att 31.037987 loss_ctc 83.467133 loss_ctc_origin 48.300980 loss_ctc0 165.521500 lr 0.00069882 rank 0
2022-08-25 06:23:47,933 DEBUG TRAIN Batch 144/100 loss 56.727367 loss_att 33.417130 loss_ctc 111.117920 loss_ctc_origin 58.389542 loss_ctc0 234.150818 lr 0.00069878 rank 0
2022-08-25 06:24:17,308 DEBUG TRAIN Batch 144/200 loss 19.089069 loss_att 9.107738 loss_ctc 42.378841 loss_ctc_origin 30.415056 loss_ctc0 70.294342 lr 0.00069874 rank 0
2022-08-25 06:24:46,545 DEBUG TRAIN Batch 144/300 loss 20.620153 loss_att 9.608559 loss_ctc 46.313873 loss_ctc_origin 33.905899 loss_ctc0 75.265808 lr 0.00069870 rank 0
2022-08-25 06:25:15,163 DEBUG TRAIN Batch 144/400 loss 18.175161 loss_att 6.903070 loss_ctc 44.476704 loss_ctc_origin 25.421751 loss_ctc0 88.938255 lr 0.00069865 rank 0
2022-08-25 06:25:44,030 DEBUG TRAIN Batch 144/500 loss 58.429459 loss_att 41.339500 loss_ctc 98.306030 loss_ctc_origin 63.895611 loss_ctc0 178.596985 lr 0.00069861 rank 0
2022-08-25 06:26:12,531 DEBUG TRAIN Batch 144/600 loss 55.023716 loss_att 31.803911 loss_ctc 109.203262 loss_ctc_origin 64.139908 loss_ctc0 214.351089 lr 0.00069857 rank 0
2022-08-25 06:26:41,981 DEBUG TRAIN Batch 144/700 loss 18.635502 loss_att 11.501122 loss_ctc 35.282391 loss_ctc_origin 24.802526 loss_ctc0 59.735405 lr 0.00069853 rank 0
2022-08-25 06:26:47,302 WARNING NaN or Inf found in input tensor.
2022-08-25 06:27:10,258 DEBUG TRAIN Batch 144/800 loss 18.088379 loss_att 7.164040 loss_ctc 43.578499 loss_ctc_origin 27.576748 loss_ctc0 80.915924 lr 0.00069848 rank 0
2022-08-25 06:27:39,358 DEBUG TRAIN Batch 144/900 loss 20.974056 loss_att 8.845739 loss_ctc 49.273464 loss_ctc_origin 31.891237 loss_ctc0 89.831993 lr 0.00069844 rank 0
2022-08-25 06:28:07,758 DEBUG TRAIN Batch 144/1000 loss 49.447952 loss_att 32.339046 loss_ctc 89.368729 loss_ctc_origin 58.956429 loss_ctc0 160.330750 lr 0.00069840 rank 0
2022-08-25 06:28:36,201 DEBUG TRAIN Batch 144/1100 loss 56.405403 loss_att 31.733822 loss_ctc 113.972412 loss_ctc_origin 60.154331 loss_ctc0 239.547913 lr 0.00069836 rank 0
2022-08-25 06:29:05,623 DEBUG TRAIN Batch 144/1200 loss 18.374527 loss_att 10.202343 loss_ctc 37.442955 loss_ctc_origin 24.836628 loss_ctc0 66.857719 lr 0.00069831 rank 0
2022-08-25 06:29:35,034 DEBUG TRAIN Batch 144/1300 loss 20.315401 loss_att 9.490398 loss_ctc 45.573738 loss_ctc_origin 31.071960 loss_ctc0 79.411224 lr 0.00069827 rank 0
2022-08-25 06:30:03,181 DEBUG TRAIN Batch 144/1400 loss 23.091543 loss_att 10.038607 loss_ctc 53.548389 loss_ctc_origin 34.013474 loss_ctc0 99.129860 lr 0.00069823 rank 0
2022-08-25 06:30:38,307 DEBUG TRAIN Batch 144/1500 loss 48.387665 loss_att 30.533171 loss_ctc 90.048157 loss_ctc_origin 57.184841 loss_ctc0 166.729218 lr 0.00069819 rank 0
2022-08-25 06:31:06,580 DEBUG TRAIN Batch 144/1600 loss 50.108841 loss_att 24.525269 loss_ctc 109.803848 loss_ctc_origin 57.985466 loss_ctc0 230.713409 lr 0.00069814 rank 0
2022-08-25 06:31:35,539 DEBUG TRAIN Batch 144/1700 loss 18.427994 loss_att 10.020293 loss_ctc 38.045959 loss_ctc_origin 26.209270 loss_ctc0 65.664902 lr 0.00069810 rank 0
2022-08-25 06:32:04,319 DEBUG TRAIN Batch 144/1800 loss 16.551899 loss_att 6.279355 loss_ctc 40.521164 loss_ctc_origin 24.053787 loss_ctc0 78.945045 lr 0.00069806 rank 0
2022-08-25 06:32:32,820 DEBUG TRAIN Batch 144/1900 loss 18.242893 loss_att 7.207648 loss_ctc 43.991798 loss_ctc_origin 26.015377 loss_ctc0 85.936783 lr 0.00069802 rank 0
2022-08-25 06:33:02,253 DEBUG TRAIN Batch 144/2000 loss 54.986832 loss_att 36.176430 loss_ctc 98.877762 loss_ctc_origin 67.856461 loss_ctc0 171.260803 lr 0.00069797 rank 0
2022-08-25 06:33:10,183 WARNING NaN or Inf found in input tensor.
2022-08-25 06:33:30,941 DEBUG TRAIN Batch 144/2100 loss 56.859020 loss_att 33.039116 loss_ctc 112.438797 loss_ctc_origin 63.692535 loss_ctc0 226.180084 lr 0.00069793 rank 0
2022-08-25 06:33:59,961 DEBUG TRAIN Batch 144/2200 loss 21.910172 loss_att 11.019950 loss_ctc 47.320686 loss_ctc_origin 35.721451 loss_ctc0 74.385567 lr 0.00069789 rank 0
2022-08-25 06:34:28,188 DEBUG TRAIN Batch 144/2300 loss 21.593939 loss_att 10.199455 loss_ctc 48.181068 loss_ctc_origin 35.456543 loss_ctc0 77.871628 lr 0.00069785 rank 0
2022-08-25 06:34:56,920 DEBUG TRAIN Batch 144/2400 loss 22.479939 loss_att 9.225567 loss_ctc 53.406799 loss_ctc_origin 37.729519 loss_ctc0 89.987122 lr 0.00069780 rank 0
2022-08-25 06:35:26,276 DEBUG TRAIN Batch 144/2500 loss 45.132412 loss_att 28.990385 loss_ctc 82.797134 loss_ctc_origin 54.337555 loss_ctc0 149.202805 lr 0.00069776 rank 0
2022-08-25 06:35:54,570 DEBUG TRAIN Batch 144/2600 loss 60.860626 loss_att 33.624638 loss_ctc 124.411255 loss_ctc_origin 76.822189 loss_ctc0 235.452423 lr 0.00069772 rank 0
2022-08-25 06:36:23,768 DEBUG TRAIN Batch 144/2700 loss 20.357639 loss_att 11.484802 loss_ctc 41.060928 loss_ctc_origin 32.593033 loss_ctc0 60.819359 lr 0.00069768 rank 0
2022-08-25 06:36:53,049 DEBUG TRAIN Batch 144/2800 loss 18.249958 loss_att 7.680471 loss_ctc 42.912094 loss_ctc_origin 27.148230 loss_ctc0 79.694443 lr 0.00069763 rank 0
2022-08-25 06:37:22,237 DEBUG TRAIN Batch 144/2900 loss 19.540960 loss_att 6.896212 loss_ctc 49.045372 loss_ctc_origin 32.158802 loss_ctc0 88.447357 lr 0.00069759 rank 0
2022-08-25 06:37:56,537 DEBUG TRAIN Batch 144/3000 loss 41.393818 loss_att 26.230011 loss_ctc 76.776031 loss_ctc_origin 46.047562 loss_ctc0 148.475784 lr 0.00069755 rank 0
2022-08-25 06:38:25,023 DEBUG TRAIN Batch 144/3100 loss 58.711372 loss_att 31.277084 loss_ctc 122.724701 loss_ctc_origin 70.535141 loss_ctc0 244.500305 lr 0.00069751 rank 0
2022-08-25 06:38:38,270 WARNING NaN or Inf found in input tensor.
2022-08-25 06:38:53,911 DEBUG TRAIN Batch 144/3200 loss 18.928909 loss_att 10.849989 loss_ctc 37.779724 loss_ctc_origin 27.826508 loss_ctc0 61.003891 lr 0.00069746 rank 0
2022-08-25 06:38:59,165 WARNING NaN or Inf found in input tensor.
2022-08-25 06:39:21,466 DEBUG TRAIN Batch 144/3300 loss 19.248844 loss_att 8.154646 loss_ctc 45.135303 loss_ctc_origin 31.336906 loss_ctc0 77.331558 lr 0.00069742 rank 0
2022-08-25 06:39:49,352 DEBUG TRAIN Batch 144/3400 loss 22.128258 loss_att 9.062770 loss_ctc 52.614395 loss_ctc_origin 35.846287 loss_ctc0 91.739975 lr 0.00069738 rank 0
2022-08-25 06:40:18,104 DEBUG TRAIN Batch 144/3500 loss 53.124336 loss_att 36.564072 loss_ctc 91.764954 loss_ctc_origin 62.182274 loss_ctc0 160.791183 lr 0.00069734 rank 0
2022-08-25 06:40:46,583 DEBUG TRAIN Batch 144/3600 loss 62.991058 loss_att 35.749969 loss_ctc 126.553589 loss_ctc_origin 70.811218 loss_ctc0 256.619110 lr 0.00069729 rank 0
2022-08-25 06:41:15,970 DEBUG TRAIN Batch 144/3700 loss 21.101007 loss_att 11.106762 loss_ctc 44.420914 loss_ctc_origin 32.822132 loss_ctc0 71.484726 lr 0.00069725 rank 0
2022-08-25 06:41:43,076 DEBUG TRAIN Batch 144/3800 loss 19.174843 loss_att 7.431411 loss_ctc 46.576187 loss_ctc_origin 30.889011 loss_ctc0 83.179588 lr 0.00069721 rank 0
2022-08-25 06:42:10,992 DEBUG TRAIN Batch 144/3900 loss 23.276878 loss_att 9.760958 loss_ctc 54.814026 loss_ctc_origin 38.879986 loss_ctc0 91.993446 lr 0.00069717 rank 0
2022-08-25 06:42:40,607 DEBUG TRAIN Batch 144/4000 loss 50.195320 loss_att 35.440315 loss_ctc 84.623672 loss_ctc_origin 51.871010 loss_ctc0 161.046539 lr 0.00069712 rank 0
2022-08-25 06:43:08,124 DEBUG TRAIN Batch 144/4100 loss 59.113190 loss_att 34.164238 loss_ctc 117.327400 loss_ctc_origin 63.728191 loss_ctc0 242.392212 lr 0.00069708 rank 0
2022-08-25 06:43:35,749 DEBUG TRAIN Batch 144/4200 loss 18.661196 loss_att 9.638676 loss_ctc 39.713741 loss_ctc_origin 28.312973 loss_ctc0 66.315536 lr 0.00069704 rank 0
2022-08-25 06:44:05,958 DEBUG TRAIN Batch 144/4300 loss 21.380739 loss_att 9.871414 loss_ctc 48.235832 loss_ctc_origin 34.373558 loss_ctc0 80.581139 lr 0.00069700 rank 0
2022-08-25 06:44:33,433 DEBUG TRAIN Batch 144/4400 loss 23.131058 loss_att 10.850292 loss_ctc 51.786179 loss_ctc_origin 33.069237 loss_ctc0 95.459045 lr 0.00069695 rank 0
2022-08-25 06:45:09,427 DEBUG TRAIN Batch 144/4500 loss 54.823067 loss_att 38.313950 loss_ctc 93.344330 loss_ctc_origin 62.717209 loss_ctc0 164.807587 lr 0.00069691 rank 0
2022-08-25 06:45:17,394 WARNING NaN or Inf found in input tensor.
2022-08-25 06:45:37,625 DEBUG TRAIN Batch 144/4600 loss 62.836300 loss_att 36.820789 loss_ctc 123.539162 loss_ctc_origin 67.963638 loss_ctc0 253.215378 lr 0.00069687 rank 0
2022-08-25 06:46:06,490 DEBUG TRAIN Batch 144/4700 loss 20.762123 loss_att 11.044443 loss_ctc 43.436710 loss_ctc_origin 32.425545 loss_ctc0 69.129425 lr 0.00069683 rank 0
2022-08-25 06:46:35,839 DEBUG TRAIN Batch 144/4800 loss 19.352757 loss_att 7.763951 loss_ctc 46.393299 loss_ctc_origin 33.814934 loss_ctc0 75.742813 lr 0.00069679 rank 0
2022-08-25 06:47:04,791 DEBUG TRAIN Batch 144/4900 loss 24.280041 loss_att 11.134591 loss_ctc 54.952751 loss_ctc_origin 38.050816 loss_ctc0 94.390594 lr 0.00069674 rank 0
2022-08-25 06:47:34,006 DEBUG TRAIN Batch 144/5000 loss 39.591396 loss_att 23.435152 loss_ctc 77.289299 loss_ctc_origin 40.961456 loss_ctc0 162.054260 lr 0.00069670 rank 0
2022-08-25 06:48:02,092 DEBUG TRAIN Batch 144/5100 loss 55.409920 loss_att 28.522697 loss_ctc 118.146782 loss_ctc_origin 64.122902 loss_ctc0 244.202484 lr 0.00069666 rank 0
2022-08-25 06:48:21,025 WARNING NaN or Inf found in input tensor.
2022-08-25 06:48:29,276 WARNING NaN or Inf found in input tensor.
2022-08-25 06:48:30,923 DEBUG TRAIN Batch 144/5200 loss 22.174520 loss_att 11.248714 loss_ctc 47.668068 loss_ctc_origin 35.911358 loss_ctc0 75.100380 lr 0.00069662 rank 0
2022-08-25 06:49:01,109 DEBUG TRAIN Batch 144/5300 loss 19.513403 loss_att 7.706392 loss_ctc 47.063095 loss_ctc_origin 31.619652 loss_ctc0 83.097794 lr 0.00069657 rank 0
2022-08-25 06:49:27,220 DEBUG TRAIN Batch 144/5400 loss 20.530691 loss_att 8.529123 loss_ctc 48.534348 loss_ctc_origin 31.806767 loss_ctc0 87.565361 lr 0.00069653 rank 0
2022-08-25 06:49:56,460 DEBUG TRAIN Batch 144/5500 loss 45.067947 loss_att 28.187613 loss_ctc 84.455399 loss_ctc_origin 49.256813 loss_ctc0 166.585434 lr 0.00069649 rank 0
2022-08-25 06:50:24,060 DEBUG TRAIN Batch 144/5600 loss 57.448784 loss_att 30.639669 loss_ctc 120.003380 loss_ctc_origin 61.835751 loss_ctc0 255.727844 lr 0.00069645 rank 0
2022-08-25 06:50:46,176 DEBUG CV Batch 144/0 loss 13.439243 loss_att 10.213798 loss_ctc 20.965284 loss_ctc_origin 15.379164 loss_ctc0 33.999565 history loss 12.648700 rank 0
2022-08-25 06:50:56,498 DEBUG CV Batch 144/100 loss 21.970411 loss_att 17.969954 loss_ctc 31.304813 loss_ctc_origin 21.776278 loss_ctc0 53.538063 history loss 27.566316 rank 0
2022-08-25 06:51:05,777 DEBUG CV Batch 144/200 loss 25.936474 loss_att 20.067118 loss_ctc 39.631638 loss_ctc_origin 29.985144 loss_ctc0 62.140110 history loss 28.953889 rank 0
2022-08-25 06:51:15,724 DEBUG CV Batch 144/300 loss 23.977127 loss_att 18.338284 loss_ctc 37.134430 loss_ctc_origin 22.011444 loss_ctc0 72.421387 history loss 27.891314 rank 0
2022-08-25 06:51:26,053 DEBUG CV Batch 144/400 loss 38.809715 loss_att 31.942732 loss_ctc 54.832668 loss_ctc_origin 37.533855 loss_ctc0 95.196564 history loss 26.121041 rank 0
2022-08-25 06:51:35,062 DEBUG CV Batch 144/500 loss 16.345392 loss_att 12.740622 loss_ctc 24.756521 loss_ctc_origin 17.594204 loss_ctc0 41.468594 history loss 25.715597 rank 0
2022-08-25 06:51:44,883 DEBUG CV Batch 144/600 loss 17.751328 loss_att 12.344085 loss_ctc 30.368229 loss_ctc_origin 19.939840 loss_ctc0 54.701138 history loss 25.497530 rank 0
2022-08-25 06:51:54,876 DEBUG CV Batch 144/700 loss 18.667213 loss_att 12.968589 loss_ctc 31.964005 loss_ctc_origin 18.280855 loss_ctc0 63.891354 history loss 25.136394 rank 0
2022-08-25 06:52:05,059 DEBUG CV Batch 144/800 loss 23.555199 loss_att 18.912148 loss_ctc 34.388985 loss_ctc_origin 19.226400 loss_ctc0 69.768341 history loss 25.061773 rank 0
2022-08-25 06:52:15,086 INFO Epoch 144 CV info cv_loss 25.14188605845245
2022-08-25 06:52:15,086 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/144.pt
2022-08-25 06:52:15,557 INFO Epoch 145 TRAIN info lr 0.0006964119274712247
2022-08-25 06:52:15,561 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 06:52:42,688 DEBUG TRAIN Batch 145/0 loss 43.888130 loss_att 29.546450 loss_ctc 77.352051 loss_ctc_origin 39.907913 loss_ctc0 164.721680 lr 0.00069641 rank 0
2022-08-25 06:53:11,366 DEBUG TRAIN Batch 145/100 loss 58.730225 loss_att 30.122515 loss_ctc 125.481552 loss_ctc_origin 69.212555 loss_ctc0 256.775879 lr 0.00069637 rank 0
2022-08-25 06:53:38,912 DEBUG TRAIN Batch 145/200 loss 18.914303 loss_att 10.899729 loss_ctc 37.614975 loss_ctc_origin 25.786530 loss_ctc0 65.214676 lr 0.00069633 rank 0
2022-08-25 06:54:08,607 DEBUG TRAIN Batch 145/300 loss 23.023911 loss_att 10.011278 loss_ctc 53.386719 loss_ctc_origin 35.910919 loss_ctc0 94.163574 lr 0.00069628 rank 0
2022-08-25 06:54:37,648 DEBUG TRAIN Batch 145/400 loss 19.446915 loss_att 8.366762 loss_ctc 45.300606 loss_ctc_origin 26.725449 loss_ctc0 88.642632 lr 0.00069624 rank 0
2022-08-25 06:55:06,713 DEBUG TRAIN Batch 145/500 loss 51.530304 loss_att 35.238670 loss_ctc 89.544121 loss_ctc_origin 56.279675 loss_ctc0 167.161163 lr 0.00069620 rank 0
2022-08-25 06:55:35,286 DEBUG TRAIN Batch 145/600 loss 63.463608 loss_att 34.263000 loss_ctc 131.598358 loss_ctc_origin 75.428650 loss_ctc0 262.661011 lr 0.00069616 rank 0
2022-08-25 06:56:04,053 DEBUG TRAIN Batch 145/700 loss 18.305519 loss_att 9.177513 loss_ctc 39.604202 loss_ctc_origin 28.990484 loss_ctc0 64.369537 lr 0.00069611 rank 0
2022-08-25 06:56:32,868 DEBUG TRAIN Batch 145/800 loss 18.434795 loss_att 7.808308 loss_ctc 43.229935 loss_ctc_origin 29.219692 loss_ctc0 75.920502 lr 0.00069607 rank 0
2022-08-25 06:57:01,601 DEBUG TRAIN Batch 145/900 loss 21.542553 loss_att 8.633207 loss_ctc 51.664360 loss_ctc_origin 34.684772 loss_ctc0 91.283401 lr 0.00069603 rank 0
2022-08-25 06:57:30,841 DEBUG TRAIN Batch 145/1000 loss 47.922672 loss_att 29.480669 loss_ctc 90.954010 loss_ctc_origin 56.959885 loss_ctc0 170.273636 lr 0.00069599 rank 0
2022-08-25 06:57:59,246 DEBUG TRAIN Batch 145/1100 loss 60.589134 loss_att 33.414600 loss_ctc 123.996368 loss_ctc_origin 69.399261 loss_ctc0 251.389618 lr 0.00069595 rank 0
2022-08-25 06:58:28,423 DEBUG TRAIN Batch 145/1200 loss 16.426334 loss_att 8.918849 loss_ctc 33.943802 loss_ctc_origin 22.062901 loss_ctc0 61.665909 lr 0.00069590 rank 0
2022-08-25 06:58:40,940 WARNING NaN or Inf found in input tensor.
2022-08-25 06:58:57,201 DEBUG TRAIN Batch 145/1300 loss 19.369537 loss_att 7.644957 loss_ctc 46.726891 loss_ctc_origin 31.875969 loss_ctc0 81.379044 lr 0.00069586 rank 0
2022-08-25 06:59:25,122 DEBUG TRAIN Batch 145/1400 loss 21.124821 loss_att 8.886280 loss_ctc 49.681412 loss_ctc_origin 32.370869 loss_ctc0 90.072670 lr 0.00069582 rank 0
2022-08-25 07:00:01,286 DEBUG TRAIN Batch 145/1500 loss 49.563023 loss_att 33.301041 loss_ctc 87.507645 loss_ctc_origin 53.158558 loss_ctc0 167.655487 lr 0.00069578 rank 0
2022-08-25 07:00:30,114 DEBUG TRAIN Batch 145/1600 loss 64.425018 loss_att 36.961464 loss_ctc 128.506653 loss_ctc_origin 75.657196 loss_ctc0 251.822037 lr 0.00069574 rank 0
2022-08-25 07:00:58,209 DEBUG TRAIN Batch 145/1700 loss 17.112331 loss_att 9.450337 loss_ctc 34.990318 loss_ctc_origin 24.562420 loss_ctc0 59.322090 lr 0.00069569 rank 0
2022-08-25 07:01:26,685 DEBUG TRAIN Batch 145/1800 loss 22.668541 loss_att 9.935023 loss_ctc 52.380081 loss_ctc_origin 37.286247 loss_ctc0 87.599022 lr 0.00069565 rank 0
2022-08-25 07:01:56,185 DEBUG TRAIN Batch 145/1900 loss 22.067657 loss_att 8.972429 loss_ctc 52.623192 loss_ctc_origin 34.870258 loss_ctc0 94.046707 lr 0.00069561 rank 0
2022-08-25 07:02:24,459 DEBUG TRAIN Batch 145/2000 loss 49.883606 loss_att 32.753418 loss_ctc 89.854042 loss_ctc_origin 57.671837 loss_ctc0 164.945847 lr 0.00069557 rank 0
2022-08-25 07:02:53,622 DEBUG TRAIN Batch 145/2100 loss 58.743626 loss_att 33.669991 loss_ctc 117.248772 loss_ctc_origin 66.633095 loss_ctc0 235.352020 lr 0.00069553 rank 0
2022-08-25 07:03:21,446 DEBUG TRAIN Batch 145/2200 loss 18.545332 loss_att 9.377453 loss_ctc 39.937046 loss_ctc_origin 27.529890 loss_ctc0 68.887070 lr 0.00069548 rank 0
2022-08-25 07:03:49,727 DEBUG TRAIN Batch 145/2300 loss 15.049587 loss_att 5.741608 loss_ctc 36.768204 loss_ctc_origin 21.119770 loss_ctc0 73.281212 lr 0.00069544 rank 0
2022-08-25 07:04:07,668 WARNING NaN or Inf found in input tensor.
2022-08-25 07:04:14,539 WARNING NaN or Inf found in input tensor.
2022-08-25 07:04:18,962 DEBUG TRAIN Batch 145/2400 loss 21.974045 loss_att 9.282411 loss_ctc 51.587860 loss_ctc_origin 33.645428 loss_ctc0 93.453522 lr 0.00069540 rank 0
2022-08-25 07:04:48,339 DEBUG TRAIN Batch 145/2500 loss 41.224976 loss_att 26.147617 loss_ctc 76.405472 loss_ctc_origin 47.005280 loss_ctc0 145.005936 lr 0.00069536 rank 0
2022-08-25 07:05:09,617 WARNING NaN or Inf found in input tensor.
2022-08-25 07:05:16,472 DEBUG TRAIN Batch 145/2600 loss 50.013596 loss_att 27.356743 loss_ctc 102.879578 loss_ctc_origin 51.035210 loss_ctc0 223.849762 lr 0.00069532 rank 0
2022-08-25 07:05:45,844 DEBUG TRAIN Batch 145/2700 loss 20.294815 loss_att 10.422733 loss_ctc 43.329674 loss_ctc_origin 32.862858 loss_ctc0 67.752235 lr 0.00069527 rank 0
2022-08-25 07:06:14,299 DEBUG TRAIN Batch 145/2800 loss 20.720926 loss_att 7.723794 loss_ctc 51.047569 loss_ctc_origin 35.168884 loss_ctc0 88.097832 lr 0.00069523 rank 0
2022-08-25 07:06:42,550 DEBUG TRAIN Batch 145/2900 loss 21.419420 loss_att 9.139836 loss_ctc 50.071781 loss_ctc_origin 33.345024 loss_ctc0 89.100876 lr 0.00069519 rank 0
2022-08-25 07:07:18,546 DEBUG TRAIN Batch 145/3000 loss 55.819984 loss_att 39.217083 loss_ctc 94.560089 loss_ctc_origin 59.396477 loss_ctc0 176.608505 lr 0.00069515 rank 0
2022-08-25 07:07:47,773 DEBUG TRAIN Batch 145/3100 loss 57.631283 loss_att 31.645149 loss_ctc 118.265594 loss_ctc_origin 64.131027 loss_ctc0 244.579575 lr 0.00069511 rank 0
2022-08-25 07:08:16,494 DEBUG TRAIN Batch 145/3200 loss 19.629375 loss_att 9.616133 loss_ctc 42.993607 loss_ctc_origin 32.191448 loss_ctc0 68.198647 lr 0.00069506 rank 0
2022-08-25 07:08:46,178 DEBUG TRAIN Batch 145/3300 loss 17.985540 loss_att 7.818626 loss_ctc 41.708336 loss_ctc_origin 26.503723 loss_ctc0 77.185760 lr 0.00069502 rank 0
2022-08-25 07:09:10,484 WARNING NaN or Inf found in input tensor.
2022-08-25 07:09:14,961 DEBUG TRAIN Batch 145/3400 loss 18.482368 loss_att 7.204562 loss_ctc 44.797249 loss_ctc_origin 27.413227 loss_ctc0 85.359970 lr 0.00069498 rank 0
2022-08-25 07:09:44,606 DEBUG TRAIN Batch 145/3500 loss 53.812706 loss_att 37.882843 loss_ctc 90.982391 loss_ctc_origin 59.024464 loss_ctc0 165.550903 lr 0.00069494 rank 0
2022-08-25 07:10:06,591 WARNING NaN or Inf found in input tensor.
2022-08-25 07:10:13,245 DEBUG TRAIN Batch 145/3600 loss 59.358055 loss_att 34.302494 loss_ctc 117.821030 loss_ctc_origin 65.052811 loss_ctc0 240.946838 lr 0.00069490 rank 0
2022-08-25 07:10:41,188 WARNING NaN or Inf found in input tensor.
2022-08-25 07:10:42,625 DEBUG TRAIN Batch 145/3700 loss 22.505396 loss_att 12.243590 loss_ctc 46.449608 loss_ctc_origin 34.604889 loss_ctc0 74.087296 lr 0.00069485 rank 0
2022-08-25 07:11:11,651 DEBUG TRAIN Batch 145/3800 loss 18.306463 loss_att 8.257028 loss_ctc 41.755146 loss_ctc_origin 26.746181 loss_ctc0 76.776062 lr 0.00069481 rank 0
2022-08-25 07:11:39,936 DEBUG TRAIN Batch 145/3900 loss 24.109348 loss_att 10.499613 loss_ctc 55.865395 loss_ctc_origin 37.959007 loss_ctc0 97.646965 lr 0.00069477 rank 0
2022-08-25 07:12:09,666 DEBUG TRAIN Batch 145/4000 loss 53.367393 loss_att 36.974407 loss_ctc 91.617691 loss_ctc_origin 61.224026 loss_ctc0 162.536240 lr 0.00069473 rank 0
2022-08-25 07:12:38,313 DEBUG TRAIN Batch 145/4100 loss 55.007172 loss_att 31.969177 loss_ctc 108.762482 loss_ctc_origin 60.874969 loss_ctc0 220.500000 lr 0.00069469 rank 0
2022-08-25 07:13:07,009 DEBUG TRAIN Batch 145/4200 loss 20.732590 loss_att 11.086959 loss_ctc 43.239059 loss_ctc_origin 32.663086 loss_ctc0 67.916321 lr 0.00069464 rank 0
2022-08-25 07:13:19,216 WARNING NaN or Inf found in input tensor.
2022-08-25 07:13:36,381 DEBUG TRAIN Batch 145/4300 loss 19.264765 loss_att 8.595504 loss_ctc 44.159706 loss_ctc_origin 29.742493 loss_ctc0 77.799866 lr 0.00069460 rank 0
2022-08-25 07:14:03,770 DEBUG TRAIN Batch 145/4400 loss 24.589426 loss_att 9.730173 loss_ctc 59.261017 loss_ctc_origin 39.806816 loss_ctc0 104.654152 lr 0.00069456 rank 0
2022-08-25 07:14:41,134 DEBUG TRAIN Batch 145/4500 loss 41.792171 loss_att 26.089363 loss_ctc 78.432053 loss_ctc_origin 48.129757 loss_ctc0 149.137421 lr 0.00069452 rank 0
2022-08-25 07:14:49,417 WARNING NaN or Inf found in input tensor.
2022-08-25 07:15:09,586 DEBUG TRAIN Batch 145/4600 loss 53.428177 loss_att 30.248863 loss_ctc 107.513237 loss_ctc_origin 60.168568 loss_ctc0 217.984116 lr 0.00069448 rank 0
2022-08-25 07:15:38,806 DEBUG TRAIN Batch 145/4700 loss 22.498501 loss_att 12.218624 loss_ctc 46.484879 loss_ctc_origin 34.528469 loss_ctc0 74.383171 lr 0.00069443 rank 0
2022-08-25 07:16:06,741 DEBUG TRAIN Batch 145/4800 loss 22.482830 loss_att 9.737028 loss_ctc 52.223034 loss_ctc_origin 38.379265 loss_ctc0 84.525162 lr 0.00069439 rank 0
2022-08-25 07:16:30,710 WARNING NaN or Inf found in input tensor.
2022-08-25 07:16:35,140 DEBUG TRAIN Batch 145/4900 loss 21.860373 loss_att 8.331805 loss_ctc 53.427025 loss_ctc_origin 36.293427 loss_ctc0 93.405426 lr 0.00069435 rank 0
2022-08-25 07:17:04,831 DEBUG TRAIN Batch 145/5000 loss 45.864975 loss_att 30.909857 loss_ctc 80.760254 loss_ctc_origin 53.353889 loss_ctc0 144.708435 lr 0.00069431 rank 0
2022-08-25 07:17:32,758 DEBUG TRAIN Batch 145/5100 loss 55.111519 loss_att 33.842735 loss_ctc 104.738670 loss_ctc_origin 62.735321 loss_ctc0 202.746490 lr 0.00069427 rank 0
2022-08-25 07:18:02,946 DEBUG TRAIN Batch 145/5200 loss 19.536367 loss_att 11.208853 loss_ctc 38.967232 loss_ctc_origin 26.619501 loss_ctc0 67.778595 lr 0.00069423 rank 0
2022-08-25 07:18:31,819 DEBUG TRAIN Batch 145/5300 loss 22.831091 loss_att 10.114491 loss_ctc 52.503159 loss_ctc_origin 38.680767 loss_ctc0 84.755409 lr 0.00069418 rank 0
2022-08-25 07:18:59,936 DEBUG TRAIN Batch 145/5400 loss 21.298422 loss_att 9.023866 loss_ctc 49.939053 loss_ctc_origin 32.883595 loss_ctc0 89.735115 lr 0.00069414 rank 0
2022-08-25 07:19:28,428 DEBUG TRAIN Batch 145/5500 loss 48.666332 loss_att 32.182655 loss_ctc 87.128242 loss_ctc_origin 55.938763 loss_ctc0 159.903687 lr 0.00069410 rank 0
2022-08-25 07:19:58,885 DEBUG TRAIN Batch 145/5600 loss 58.074806 loss_att 33.446381 loss_ctc 115.541138 loss_ctc_origin 68.067154 loss_ctc0 226.313736 lr 0.00069406 rank 0
2022-08-25 07:20:25,521 DEBUG CV Batch 145/0 loss 12.419608 loss_att 9.109507 loss_ctc 20.143177 loss_ctc_origin 14.139217 loss_ctc0 34.152412 history loss 11.689043 rank 0
2022-08-25 07:20:36,721 DEBUG CV Batch 145/100 loss 21.780949 loss_att 17.754910 loss_ctc 31.175037 loss_ctc_origin 21.069096 loss_ctc0 54.755573 history loss 26.858659 rank 0
2022-08-25 07:20:46,798 DEBUG CV Batch 145/200 loss 24.688576 loss_att 19.341391 loss_ctc 37.165344 loss_ctc_origin 26.696966 loss_ctc0 61.591557 history loss 28.137336 rank 0
2022-08-25 07:20:57,399 DEBUG CV Batch 145/300 loss 22.489965 loss_att 16.928802 loss_ctc 35.466011 loss_ctc_origin 19.755905 loss_ctc0 72.122925 history loss 27.209526 rank 0
2022-08-25 07:21:08,339 DEBUG CV Batch 145/400 loss 39.102425 loss_att 32.066246 loss_ctc 55.520172 loss_ctc_origin 38.221012 loss_ctc0 95.884880 history loss 25.539894 rank 0
2022-08-25 07:21:19,089 DEBUG CV Batch 145/500 loss 17.137966 loss_att 13.067829 loss_ctc 26.634951 loss_ctc_origin 19.675497 loss_ctc0 42.873672 history loss 25.238800 rank 0
2022-08-25 07:21:29,685 DEBUG CV Batch 145/600 loss 17.574776 loss_att 11.937409 loss_ctc 30.728624 loss_ctc_origin 20.429058 loss_ctc0 54.760941 history loss 25.067623 rank 0
2022-08-25 07:21:39,787 DEBUG CV Batch 145/700 loss 18.343693 loss_att 12.323662 loss_ctc 32.390434 loss_ctc_origin 18.499443 loss_ctc0 64.802742 history loss 24.731400 rank 0
2022-08-25 07:21:50,310 DEBUG CV Batch 145/800 loss 23.332705 loss_att 18.764744 loss_ctc 33.991280 loss_ctc_origin 18.677387 loss_ctc0 69.723694 history loss 24.691826 rank 0
2022-08-25 07:22:00,655 INFO Epoch 145 CV info cv_loss 24.785601748702597
2022-08-25 07:22:00,656 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/145.pt
2022-08-25 07:22:01,151 INFO Epoch 146 TRAIN info lr 0.00069402285721413
2022-08-25 07:22:01,155 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 07:22:28,211 DEBUG TRAIN Batch 146/0 loss 43.766769 loss_att 27.572447 loss_ctc 81.553528 loss_ctc_origin 51.084389 loss_ctc0 152.648193 lr 0.00069402 rank 0
2022-08-25 07:22:55,746 DEBUG TRAIN Batch 146/100 loss 53.852455 loss_att 29.878359 loss_ctc 109.792007 loss_ctc_origin 59.052708 loss_ctc0 228.183716 lr 0.00069398 rank 0
2022-08-25 07:23:23,408 DEBUG TRAIN Batch 146/200 loss 16.894753 loss_att 9.698782 loss_ctc 33.685349 loss_ctc_origin 22.727278 loss_ctc0 59.254173 lr 0.00069394 rank 0
2022-08-25 07:23:36,115 WARNING NaN or Inf found in input tensor.
2022-08-25 07:23:51,406 DEBUG TRAIN Batch 146/300 loss 19.625860 loss_att 8.164852 loss_ctc 46.368214 loss_ctc_origin 33.324215 loss_ctc0 76.804207 lr 0.00069390 rank 0
2022-08-25 07:24:15,238 WARNING NaN or Inf found in input tensor.
2022-08-25 07:24:19,716 DEBUG TRAIN Batch 146/400 loss 21.515041 loss_att 8.740793 loss_ctc 51.321617 loss_ctc_origin 32.283360 loss_ctc0 95.744217 lr 0.00069385 rank 0
2022-08-25 07:24:48,998 DEBUG TRAIN Batch 146/500 loss 49.832886 loss_att 32.788090 loss_ctc 89.604080 loss_ctc_origin 60.207767 loss_ctc0 158.195465 lr 0.00069381 rank 0
2022-08-25 07:25:15,815 DEBUG TRAIN Batch 146/600 loss 47.426285 loss_att 26.551601 loss_ctc 96.133881 loss_ctc_origin 49.695251 loss_ctc0 204.490692 lr 0.00069377 rank 0
2022-08-25 07:25:44,230 DEBUG TRAIN Batch 146/700 loss 23.993986 loss_att 14.018429 loss_ctc 47.270287 loss_ctc_origin 37.712940 loss_ctc0 69.570770 lr 0.00069373 rank 0
2022-08-25 07:26:02,868 WARNING NaN or Inf found in input tensor.
2022-08-25 07:26:13,410 DEBUG TRAIN Batch 146/800 loss 17.858597 loss_att 7.635584 loss_ctc 41.712292 loss_ctc_origin 27.677956 loss_ctc0 74.459076 lr 0.00069369 rank 0
2022-08-25 07:26:41,991 DEBUG TRAIN Batch 146/900 loss 24.098646 loss_att 9.363038 loss_ctc 58.481728 loss_ctc_origin 39.921516 loss_ctc0 101.788879 lr 0.00069365 rank 0
2022-08-25 07:27:10,232 DEBUG TRAIN Batch 146/1000 loss 48.216667 loss_att 31.490694 loss_ctc 87.243927 loss_ctc_origin 64.360649 loss_ctc0 140.638245 lr 0.00069360 rank 0
2022-08-25 07:27:38,888 DEBUG TRAIN Batch 146/1100 loss 55.159027 loss_att 30.898724 loss_ctc 111.766403 loss_ctc_origin 64.532082 loss_ctc0 221.979828 lr 0.00069356 rank 0
2022-08-25 07:28:06,263 DEBUG TRAIN Batch 146/1200 loss 19.980232 loss_att 11.577725 loss_ctc 39.586086 loss_ctc_origin 30.201199 loss_ctc0 61.484158 lr 0.00069352 rank 0
2022-08-25 07:28:36,297 DEBUG TRAIN Batch 146/1300 loss 21.078199 loss_att 9.073889 loss_ctc 49.088257 loss_ctc_origin 37.037926 loss_ctc0 77.205688 lr 0.00069348 rank 0
2022-08-25 07:29:06,294 DEBUG TRAIN Batch 146/1400 loss 21.743912 loss_att 9.667280 loss_ctc 49.922718 loss_ctc_origin 31.596575 loss_ctc0 92.683716 lr 0.00069344 rank 0
2022-08-25 07:29:27,687 WARNING NaN or Inf found in input tensor.
2022-08-25 07:29:40,286 DEBUG TRAIN Batch 146/1500 loss 41.865242 loss_att 27.244997 loss_ctc 75.979141 loss_ctc_origin 46.528152 loss_ctc0 144.698120 lr 0.00069340 rank 0
2022-08-25 07:30:08,023 DEBUG TRAIN Batch 146/1600 loss 51.612968 loss_att 29.536491 loss_ctc 103.124741 loss_ctc_origin 57.689568 loss_ctc0 209.140137 lr 0.00069335 rank 0
2022-08-25 07:30:36,880 DEBUG TRAIN Batch 146/1700 loss 19.833050 loss_att 10.118739 loss_ctc 42.499771 loss_ctc_origin 31.903625 loss_ctc0 67.224113 lr 0.00069331 rank 0
2022-08-25 07:31:06,248 DEBUG TRAIN Batch 146/1800 loss 20.688438 loss_att 9.347710 loss_ctc 47.150139 loss_ctc_origin 35.103321 loss_ctc0 75.259384 lr 0.00069327 rank 0
2022-08-25 07:31:34,057 DEBUG TRAIN Batch 146/1900 loss 24.102203 loss_att 10.623239 loss_ctc 55.553116 loss_ctc_origin 37.703602 loss_ctc0 97.201973 lr 0.00069323 rank 0
2022-08-25 07:32:03,733 DEBUG TRAIN Batch 146/2000 loss 30.012642 loss_att 21.087536 loss_ctc 50.837887 loss_ctc_origin 36.908897 loss_ctc0 83.338860 lr 0.00069319 rank 0
2022-08-25 07:32:31,441 DEBUG TRAIN Batch 146/2100 loss 45.013042 loss_att 26.742428 loss_ctc 87.644470 loss_ctc_origin 47.510048 loss_ctc0 181.291443 lr 0.00069315 rank 0
2022-08-25 07:32:59,234 DEBUG TRAIN Batch 146/2200 loss 19.272682 loss_att 10.468156 loss_ctc 39.816574 loss_ctc_origin 27.661766 loss_ctc0 68.177788 lr 0.00069310 rank 0
2022-08-25 07:33:29,774 DEBUG TRAIN Batch 146/2300 loss 19.728741 loss_att 8.562581 loss_ctc 45.783112 loss_ctc_origin 33.621181 loss_ctc0 74.160957 lr 0.00069306 rank 0
2022-08-25 07:33:57,206 DEBUG TRAIN Batch 146/2400 loss 22.411421 loss_att 10.836271 loss_ctc 49.420105 loss_ctc_origin 32.300194 loss_ctc0 89.366554 lr 0.00069302 rank 0
2022-08-25 07:34:25,357 DEBUG TRAIN Batch 146/2500 loss 40.276665 loss_att 26.621246 loss_ctc 72.139297 loss_ctc_origin 45.020519 loss_ctc0 135.416443 lr 0.00069298 rank 0
2022-08-25 07:34:54,371 DEBUG TRAIN Batch 146/2600 loss 45.332020 loss_att 25.894899 loss_ctc 90.685303 loss_ctc_origin 48.216499 loss_ctc0 189.779175 lr 0.00069294 rank 0
2022-08-25 07:35:23,432 DEBUG TRAIN Batch 146/2700 loss 21.073742 loss_att 11.423775 loss_ctc 43.590332 loss_ctc_origin 33.919788 loss_ctc0 66.154938 lr 0.00069290 rank 0
2022-08-25 07:35:34,860 WARNING NaN or Inf found in input tensor.
2022-08-25 07:35:51,156 DEBUG TRAIN Batch 146/2800 loss 16.418730 loss_att 6.902320 loss_ctc 38.623684 loss_ctc_origin 24.660961 loss_ctc0 71.203369 lr 0.00069285 rank 0
2022-08-25 07:36:10,322 WARNING NaN or Inf found in input tensor.
2022-08-25 07:36:20,910 DEBUG TRAIN Batch 146/2900 loss 25.875977 loss_att 10.246316 loss_ctc 62.345184 loss_ctc_origin 44.722412 loss_ctc0 103.464989 lr 0.00069281 rank 0
2022-08-25 07:36:55,737 DEBUG TRAIN Batch 146/3000 loss 51.648392 loss_att 33.643826 loss_ctc 93.659042 loss_ctc_origin 51.778976 loss_ctc0 191.379181 lr 0.00069277 rank 0
2022-08-25 07:37:03,504 WARNING NaN or Inf found in input tensor.
2022-08-25 07:37:23,761 DEBUG TRAIN Batch 146/3100 loss 54.869675 loss_att 28.775230 loss_ctc 115.756714 loss_ctc_origin 57.043137 loss_ctc0 252.755066 lr 0.00069273 rank 0
2022-08-25 07:37:52,798 DEBUG TRAIN Batch 146/3200 loss 16.878035 loss_att 7.926423 loss_ctc 37.765125 loss_ctc_origin 24.794193 loss_ctc0 68.030632 lr 0.00069269 rank 0
2022-08-25 07:38:21,382 DEBUG TRAIN Batch 146/3300 loss 16.365065 loss_att 7.162289 loss_ctc 37.838207 loss_ctc_origin 22.813507 loss_ctc0 72.895844 lr 0.00069265 rank 0
2022-08-25 07:38:50,165 DEBUG TRAIN Batch 146/3400 loss 23.043507 loss_att 9.543850 loss_ctc 54.542702 loss_ctc_origin 36.461258 loss_ctc0 96.732727 lr 0.00069260 rank 0
2022-08-25 07:39:21,021 DEBUG TRAIN Batch 146/3500 loss 54.651459 loss_att 37.211262 loss_ctc 95.345261 loss_ctc_origin 54.860359 loss_ctc0 189.810028 lr 0.00069256 rank 0
2022-08-25 07:39:42,040 WARNING NaN or Inf found in input tensor.
2022-08-25 07:39:48,672 DEBUG TRAIN Batch 146/3600 loss 59.328201 loss_att 32.601093 loss_ctc 121.691452 loss_ctc_origin 68.656433 loss_ctc0 245.439819 lr 0.00069252 rank 0
2022-08-25 07:40:17,326 DEBUG TRAIN Batch 146/3700 loss 19.337790 loss_att 10.193827 loss_ctc 40.673702 loss_ctc_origin 27.846096 loss_ctc0 70.604782 lr 0.00069248 rank 0
2022-08-25 07:40:46,254 DEBUG TRAIN Batch 146/3800 loss 20.977535 loss_att 9.750370 loss_ctc 47.174255 loss_ctc_origin 33.967201 loss_ctc0 77.990715 lr 0.00069244 rank 0
2022-08-25 07:41:14,212 DEBUG TRAIN Batch 146/3900 loss 22.365416 loss_att 10.102587 loss_ctc 50.978680 loss_ctc_origin 30.699984 loss_ctc0 98.295631 lr 0.00069240 rank 0
2022-08-25 07:41:43,358 DEBUG TRAIN Batch 146/4000 loss 55.408314 loss_att 37.557213 loss_ctc 97.060883 loss_ctc_origin 61.683849 loss_ctc0 179.607269 lr 0.00069236 rank 0
2022-08-25 07:42:13,007 DEBUG TRAIN Batch 146/4100 loss 39.065559 loss_att 18.716429 loss_ctc 86.546860 loss_ctc_origin 45.189987 loss_ctc0 183.046234 lr 0.00069231 rank 0
2022-08-25 07:42:42,941 DEBUG TRAIN Batch 146/4200 loss 19.876146 loss_att 9.649877 loss_ctc 43.737442 loss_ctc_origin 31.010136 loss_ctc0 73.434494 lr 0.00069227 rank 0
2022-08-25 07:43:10,985 DEBUG TRAIN Batch 146/4300 loss 19.168594 loss_att 7.644757 loss_ctc 46.057549 loss_ctc_origin 30.685001 loss_ctc0 81.926819 lr 0.00069223 rank 0
2022-08-25 07:43:38,423 DEBUG TRAIN Batch 146/4400 loss 21.169371 loss_att 8.645276 loss_ctc 50.392258 loss_ctc_origin 32.275707 loss_ctc0 92.664215 lr 0.00069219 rank 0
2022-08-25 07:44:10,400 DEBUG TRAIN Batch 146/4500 loss 47.673538 loss_att 30.805033 loss_ctc 87.033386 loss_ctc_origin 48.845802 loss_ctc0 176.137726 lr 0.00069215 rank 0
2022-08-25 07:44:37,713 DEBUG TRAIN Batch 146/4600 loss 52.632786 loss_att 29.455448 loss_ctc 106.713234 loss_ctc_origin 53.219147 loss_ctc0 231.532761 lr 0.00069211 rank 0
2022-08-25 07:45:05,336 DEBUG TRAIN Batch 146/4700 loss 20.402380 loss_att 10.209208 loss_ctc 44.186447 loss_ctc_origin 32.848160 loss_ctc0 70.642441 lr 0.00069207 rank 0
2022-08-25 07:45:32,319 DEBUG TRAIN Batch 146/4800 loss 18.614649 loss_att 7.367939 loss_ctc 44.856968 loss_ctc_origin 30.809391 loss_ctc0 77.634644 lr 0.00069202 rank 0
2022-08-25 07:45:59,142 DEBUG TRAIN Batch 146/4900 loss 24.649757 loss_att 10.535737 loss_ctc 57.582474 loss_ctc_origin 38.328140 loss_ctc0 102.509254 lr 0.00069198 rank 0
2022-08-25 07:46:26,615 DEBUG TRAIN Batch 146/5000 loss 38.381321 loss_att 24.404629 loss_ctc 70.993599 loss_ctc_origin 41.848045 loss_ctc0 138.999878 lr 0.00069194 rank 0
2022-08-25 07:46:53,724 DEBUG TRAIN Batch 146/5100 loss 49.580154 loss_att 26.510630 loss_ctc 103.409042 loss_ctc_origin 52.398842 loss_ctc0 222.432831 lr 0.00069190 rank 0
2022-08-25 07:47:21,011 DEBUG TRAIN Batch 146/5200 loss 20.316385 loss_att 11.056275 loss_ctc 41.923306 loss_ctc_origin 29.200783 loss_ctc0 71.609192 lr 0.00069186 rank 0
2022-08-25 07:47:48,290 DEBUG TRAIN Batch 146/5300 loss 18.990990 loss_att 8.681663 loss_ctc 43.046082 loss_ctc_origin 27.091228 loss_ctc0 80.274063 lr 0.00069182 rank 0
2022-08-25 07:48:16,511 DEBUG TRAIN Batch 146/5400 loss 20.993881 loss_att 9.191338 loss_ctc 48.533146 loss_ctc_origin 35.138878 loss_ctc0 79.786438 lr 0.00069178 rank 0
2022-08-25 07:48:43,753 DEBUG TRAIN Batch 146/5500 loss 47.168213 loss_att 29.465801 loss_ctc 88.473839 loss_ctc_origin 51.371147 loss_ctc0 175.046783 lr 0.00069173 rank 0
2022-08-25 07:49:10,303 DEBUG TRAIN Batch 146/5600 loss 50.197060 loss_att 27.327602 loss_ctc 103.559120 loss_ctc_origin 52.601234 loss_ctc0 222.460846 lr 0.00069169 rank 0
2022-08-25 07:49:34,817 DEBUG CV Batch 146/0 loss 13.386009 loss_att 10.088958 loss_ctc 21.079128 loss_ctc_origin 15.809687 loss_ctc0 33.374493 history loss 12.598597 rank 0
2022-08-25 07:49:45,284 DEBUG CV Batch 146/100 loss 20.956451 loss_att 16.891703 loss_ctc 30.440861 loss_ctc_origin 20.171459 loss_ctc0 54.402802 history loss 27.079337 rank 0
2022-08-25 07:49:56,168 DEBUG CV Batch 146/200 loss 26.362961 loss_att 21.231373 loss_ctc 38.336662 loss_ctc_origin 28.248127 loss_ctc0 61.876575 history loss 28.368041 rank 0
2022-08-25 07:50:07,128 DEBUG CV Batch 146/300 loss 24.320030 loss_att 18.915323 loss_ctc 36.931007 loss_ctc_origin 21.601458 loss_ctc0 72.699951 history loss 27.376947 rank 0
2022-08-25 07:50:17,905 DEBUG CV Batch 146/400 loss 39.237953 loss_att 31.843658 loss_ctc 56.491302 loss_ctc_origin 39.590385 loss_ctc0 95.926773 history loss 25.728605 rank 0
2022-08-25 07:50:29,163 DEBUG CV Batch 146/500 loss 16.585159 loss_att 12.145955 loss_ctc 26.943302 loss_ctc_origin 20.142334 loss_ctc0 42.812229 history loss 25.430835 rank 0
2022-08-25 07:50:39,961 DEBUG CV Batch 146/600 loss 17.345375 loss_att 11.671646 loss_ctc 30.584072 loss_ctc_origin 19.055674 loss_ctc0 57.483665 history loss 25.303762 rank 0
2022-08-25 07:50:50,643 DEBUG CV Batch 146/700 loss 18.864651 loss_att 12.919037 loss_ctc 32.737747 loss_ctc_origin 19.367882 loss_ctc0 63.934093 history loss 24.922978 rank 0
2022-08-25 07:50:59,582 DEBUG CV Batch 146/800 loss 21.700394 loss_att 17.059101 loss_ctc 32.530075 loss_ctc_origin 17.040073 loss_ctc0 68.673416 history loss 24.859971 rank 0
2022-08-25 07:51:08,166 INFO Epoch 146 CV info cv_loss 24.932719221266215
2022-08-25 07:51:08,166 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/146.pt
2022-08-25 07:51:08,611 INFO Epoch 147 TRAIN info lr 0.0006916582068739605
2022-08-25 07:51:08,615 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 07:51:37,139 DEBUG TRAIN Batch 147/0 loss 49.829971 loss_att 33.731224 loss_ctc 87.393715 loss_ctc_origin 52.483521 loss_ctc0 168.850830 lr 0.00069166 rank 0
2022-08-25 07:52:06,795 DEBUG TRAIN Batch 147/100 loss 52.292778 loss_att 30.681416 loss_ctc 102.719299 loss_ctc_origin 60.440201 loss_ctc0 201.370529 lr 0.00069162 rank 0
2022-08-25 07:52:34,097 WARNING NaN or Inf found in input tensor.
2022-08-25 07:52:35,664 DEBUG TRAIN Batch 147/200 loss 20.292368 loss_att 10.375757 loss_ctc 43.431126 loss_ctc_origin 32.716789 loss_ctc0 68.431244 lr 0.00069157 rank 0
2022-08-25 07:53:03,504 DEBUG TRAIN Batch 147/300 loss 19.392326 loss_att 7.720219 loss_ctc 46.627239 loss_ctc_origin 33.963081 loss_ctc0 76.176941 lr 0.00069153 rank 0
2022-08-25 07:53:13,783 WARNING NaN or Inf found in input tensor.
2022-08-25 07:53:31,358 DEBUG TRAIN Batch 147/400 loss 22.580400 loss_att 9.517590 loss_ctc 53.060291 loss_ctc_origin 36.440193 loss_ctc0 91.840515 lr 0.00069149 rank 0
2022-08-25 07:53:59,868 DEBUG TRAIN Batch 147/500 loss 44.346771 loss_att 28.977722 loss_ctc 80.207886 loss_ctc_origin 45.649891 loss_ctc0 160.843201 lr 0.00069145 rank 0
2022-08-25 07:54:00,552 WARNING NaN or Inf found in input tensor.
2022-08-25 07:54:29,023 DEBUG TRAIN Batch 147/600 loss 53.302605 loss_att 31.036049 loss_ctc 105.257904 loss_ctc_origin 55.152542 loss_ctc0 222.170410 lr 0.00069141 rank 0
2022-08-25 07:54:56,813 DEBUG TRAIN Batch 147/700 loss 23.346365 loss_att 11.341077 loss_ctc 51.358700 loss_ctc_origin 39.492859 loss_ctc0 79.045662 lr 0.00069137 rank 0
2022-08-25 07:55:25,214 DEBUG TRAIN Batch 147/800 loss 19.202024 loss_att 8.561765 loss_ctc 44.029293 loss_ctc_origin 30.098221 loss_ctc0 76.535126 lr 0.00069133 rank 0
2022-08-25 07:55:55,002 DEBUG TRAIN Batch 147/900 loss 25.669495 loss_att 11.769361 loss_ctc 58.103130 loss_ctc_origin 40.971199 loss_ctc0 98.077637 lr 0.00069128 rank 0
2022-08-25 07:56:23,728 DEBUG TRAIN Batch 147/1000 loss 46.822063 loss_att 31.108982 loss_ctc 83.485916 loss_ctc_origin 49.920891 loss_ctc0 161.804291 lr 0.00069124 rank 0
2022-08-25 07:56:46,246 WARNING NaN or Inf found in input tensor.
2022-08-25 07:56:53,200 DEBUG TRAIN Batch 147/1100 loss 53.200680 loss_att 27.614594 loss_ctc 112.901543 loss_ctc_origin 62.535259 loss_ctc0 230.422867 lr 0.00069120 rank 0
2022-08-25 07:57:21,839 DEBUG TRAIN Batch 147/1200 loss 21.396557 loss_att 11.628917 loss_ctc 44.187717 loss_ctc_origin 32.393715 loss_ctc0 71.707054 lr 0.00069116 rank 0
2022-08-25 07:57:51,324 DEBUG TRAIN Batch 147/1300 loss 21.689274 loss_att 10.518345 loss_ctc 47.754776 loss_ctc_origin 34.190277 loss_ctc0 79.405273 lr 0.00069112 rank 0
2022-08-25 07:58:20,021 DEBUG TRAIN Batch 147/1400 loss 18.902082 loss_att 7.617919 loss_ctc 45.231796 loss_ctc_origin 26.625174 loss_ctc0 88.647240 lr 0.00069108 rank 0
2022-08-25 07:58:55,070 DEBUG TRAIN Batch 147/1500 loss 47.151245 loss_att 31.525988 loss_ctc 83.610168 loss_ctc_origin 52.886726 loss_ctc0 155.298187 lr 0.00069104 rank 0
2022-08-25 07:59:23,126 DEBUG TRAIN Batch 147/1600 loss 50.072365 loss_att 25.135983 loss_ctc 108.257248 loss_ctc_origin 59.091667 loss_ctc0 222.976929 lr 0.00069100 rank 0
2022-08-25 07:59:51,602 DEBUG TRAIN Batch 147/1700 loss 20.863100 loss_att 10.318344 loss_ctc 45.467529 loss_ctc_origin 34.240028 loss_ctc0 71.665039 lr 0.00069095 rank 0
2022-08-25 08:00:19,941 DEBUG TRAIN Batch 147/1800 loss 21.442705 loss_att 9.144902 loss_ctc 50.137577 loss_ctc_origin 36.413200 loss_ctc0 82.161118 lr 0.00069091 rank 0
2022-08-25 08:00:48,520 DEBUG TRAIN Batch 147/1900 loss 22.760509 loss_att 10.686756 loss_ctc 50.932598 loss_ctc_origin 33.406235 loss_ctc0 91.827446 lr 0.00069087 rank 0
2022-08-25 08:01:17,595 DEBUG TRAIN Batch 147/2000 loss 42.641525 loss_att 27.893581 loss_ctc 77.053391 loss_ctc_origin 45.356983 loss_ctc0 151.011673 lr 0.00069083 rank 0
2022-08-25 08:01:46,661 DEBUG TRAIN Batch 147/2100 loss 44.820713 loss_att 22.556297 loss_ctc 96.771011 loss_ctc_origin 46.324112 loss_ctc0 214.480438 lr 0.00069079 rank 0
2022-08-25 08:02:14,063 DEBUG TRAIN Batch 147/2200 loss 22.544289 loss_att 13.058117 loss_ctc 44.678688 loss_ctc_origin 34.998379 loss_ctc0 67.266068 lr 0.00069075 rank 0
2022-08-25 08:02:42,854 DEBUG TRAIN Batch 147/2300 loss 16.990364 loss_att 7.113088 loss_ctc 40.037342 loss_ctc_origin 25.192419 loss_ctc0 74.675491 lr 0.00069071 rank 0
2022-08-25 08:03:11,548 DEBUG TRAIN Batch 147/2400 loss 23.877439 loss_att 9.929092 loss_ctc 56.423576 loss_ctc_origin 37.534107 loss_ctc0 100.499008 lr 0.00069067 rank 0
2022-08-25 08:03:39,706 DEBUG TRAIN Batch 147/2500 loss 43.951233 loss_att 29.211067 loss_ctc 78.344955 loss_ctc_origin 45.637997 loss_ctc0 154.661194 lr 0.00069062 rank 0
2022-08-25 08:04:08,709 DEBUG TRAIN Batch 147/2600 loss 50.719666 loss_att 29.574694 loss_ctc 100.057930 loss_ctc_origin 49.623936 loss_ctc0 217.737244 lr 0.00069058 rank 0
2022-08-25 08:04:36,350 DEBUG TRAIN Batch 147/2700 loss 20.031399 loss_att 11.182089 loss_ctc 40.679783 loss_ctc_origin 29.302811 loss_ctc0 67.226051 lr 0.00069054 rank 0
2022-08-25 08:05:04,418 DEBUG TRAIN Batch 147/2800 loss 22.866192 loss_att 10.073649 loss_ctc 52.715454 loss_ctc_origin 37.271896 loss_ctc0 88.750420 lr 0.00069050 rank 0
2022-08-25 08:05:34,195 DEBUG TRAIN Batch 147/2900 loss 23.864777 loss_att 10.029450 loss_ctc 56.147202 loss_ctc_origin 38.956551 loss_ctc0 96.258728 lr 0.00069046 rank 0
2022-08-25 08:06:09,129 DEBUG TRAIN Batch 147/3000 loss 35.642693 loss_att 23.351780 loss_ctc 64.321495 loss_ctc_origin 36.657951 loss_ctc0 128.869751 lr 0.00069042 rank 0
2022-08-25 08:06:38,954 DEBUG TRAIN Batch 147/3100 loss 47.930542 loss_att 28.708376 loss_ctc 92.782257 loss_ctc_origin 49.737896 loss_ctc0 193.219070 lr 0.00069038 rank 0
2022-08-25 08:07:07,804 DEBUG TRAIN Batch 147/3200 loss 19.875654 loss_att 10.955004 loss_ctc 40.690506 loss_ctc_origin 29.658310 loss_ctc0 66.432297 lr 0.00069034 rank 0
2022-08-25 08:07:37,231 DEBUG TRAIN Batch 147/3300 loss 22.993246 loss_att 10.348882 loss_ctc 52.496761 loss_ctc_origin 37.828506 loss_ctc0 86.722687 lr 0.00069030 rank 0
2022-08-25 08:08:06,010 DEBUG TRAIN Batch 147/3400 loss 25.037312 loss_att 11.470924 loss_ctc 56.692207 loss_ctc_origin 38.949287 loss_ctc0 98.092346 lr 0.00069025 rank 0
2022-08-25 08:08:35,556 DEBUG TRAIN Batch 147/3500 loss 47.216110 loss_att 31.753571 loss_ctc 83.295364 loss_ctc_origin 51.941238 loss_ctc0 156.454971 lr 0.00069021 rank 0
2022-08-25 08:09:03,670 DEBUG TRAIN Batch 147/3600 loss 55.214073 loss_att 31.933258 loss_ctc 109.535973 loss_ctc_origin 61.694313 loss_ctc0 221.166504 lr 0.00069017 rank 0
2022-08-25 08:09:33,911 DEBUG TRAIN Batch 147/3700 loss 17.782330 loss_att 9.192572 loss_ctc 37.825096 loss_ctc_origin 26.177240 loss_ctc0 65.003433 lr 0.00069013 rank 0
2022-08-25 08:10:03,262 DEBUG TRAIN Batch 147/3800 loss 21.592453 loss_att 9.396276 loss_ctc 50.050194 loss_ctc_origin 35.170883 loss_ctc0 84.768585 lr 0.00069009 rank 0
2022-08-25 08:10:27,460 WARNING NaN or Inf found in input tensor.
2022-08-25 08:10:31,825 DEBUG TRAIN Batch 147/3900 loss 25.520458 loss_att 11.177523 loss_ctc 58.987305 loss_ctc_origin 41.052986 loss_ctc0 100.834045 lr 0.00069005 rank 0
2022-08-25 08:11:01,511 DEBUG TRAIN Batch 147/4000 loss 47.117134 loss_att 28.436817 loss_ctc 90.704536 loss_ctc_origin 49.794941 loss_ctc0 186.160263 lr 0.00069001 rank 0
2022-08-25 08:11:30,096 DEBUG TRAIN Batch 147/4100 loss 59.033623 loss_att 33.333599 loss_ctc 119.000336 loss_ctc_origin 65.930725 loss_ctc0 242.829407 lr 0.00068997 rank 0
2022-08-25 08:11:58,611 DEBUG TRAIN Batch 147/4200 loss 21.396145 loss_att 11.964796 loss_ctc 43.402626 loss_ctc_origin 31.974754 loss_ctc0 70.067657 lr 0.00068993 rank 0
2022-08-25 08:12:27,750 DEBUG TRAIN Batch 147/4300 loss 17.857594 loss_att 7.238257 loss_ctc 42.636047 loss_ctc_origin 28.149553 loss_ctc0 76.437866 lr 0.00068988 rank 0
2022-08-25 08:12:57,223 DEBUG TRAIN Batch 147/4400 loss 20.197191 loss_att 8.463991 loss_ctc 47.574654 loss_ctc_origin 29.614634 loss_ctc0 89.481369 lr 0.00068984 rank 0
2022-08-25 08:13:32,627 DEBUG TRAIN Batch 147/4500 loss 47.316422 loss_att 29.252468 loss_ctc 89.465637 loss_ctc_origin 53.608902 loss_ctc0 173.131332 lr 0.00068980 rank 0
2022-08-25 08:14:02,143 DEBUG TRAIN Batch 147/4600 loss 54.995949 loss_att 30.353781 loss_ctc 112.494339 loss_ctc_origin 61.408722 loss_ctc0 231.694122 lr 0.00068976 rank 0
2022-08-25 08:14:30,562 DEBUG TRAIN Batch 147/4700 loss 19.590603 loss_att 11.768805 loss_ctc 37.841461 loss_ctc_origin 25.736080 loss_ctc0 66.087357 lr 0.00068972 rank 0
2022-08-25 08:14:59,386 DEBUG TRAIN Batch 147/4800 loss 20.845789 loss_att 8.626869 loss_ctc 49.356598 loss_ctc_origin 33.208019 loss_ctc0 87.036621 lr 0.00068968 rank 0
2022-08-25 08:15:28,545 DEBUG TRAIN Batch 147/4900 loss 22.069202 loss_att 9.228207 loss_ctc 52.031525 loss_ctc_origin 32.989090 loss_ctc0 96.463860 lr 0.00068964 rank 0
2022-08-25 08:15:58,137 DEBUG TRAIN Batch 147/5000 loss 46.474510 loss_att 27.464466 loss_ctc 90.831268 loss_ctc_origin 54.269711 loss_ctc0 176.141571 lr 0.00068960 rank 0
2022-08-25 08:16:26,866 DEBUG TRAIN Batch 147/5100 loss 64.615051 loss_att 34.793240 loss_ctc 134.199280 loss_ctc_origin 83.315269 loss_ctc0 252.928650 lr 0.00068956 rank 0
2022-08-25 08:16:55,305 DEBUG TRAIN Batch 147/5200 loss 23.197554 loss_att 12.142475 loss_ctc 48.992737 loss_ctc_origin 38.595089 loss_ctc0 73.253906 lr 0.00068952 rank 0
2022-08-25 08:17:14,831 WARNING NaN or Inf found in input tensor.
2022-08-25 08:17:24,649 DEBUG TRAIN Batch 147/5300 loss 18.292789 loss_att 8.866482 loss_ctc 40.287506 loss_ctc_origin 27.707741 loss_ctc0 69.640282 lr 0.00068947 rank 0
2022-08-25 08:17:52,449 DEBUG TRAIN Batch 147/5400 loss 25.434347 loss_att 11.470956 loss_ctc 58.015591 loss_ctc_origin 39.444370 loss_ctc0 101.348434 lr 0.00068943 rank 0
2022-08-25 08:18:21,926 DEBUG TRAIN Batch 147/5500 loss 45.587341 loss_att 29.304619 loss_ctc 83.580353 loss_ctc_origin 47.820732 loss_ctc0 167.019455 lr 0.00068939 rank 0
2022-08-25 08:18:49,207 DEBUG TRAIN Batch 147/5600 loss 36.665489 loss_att 23.248072 loss_ctc 67.972794 loss_ctc_origin 42.651688 loss_ctc0 127.055367 lr 0.00068935 rank 0
2022-08-25 08:19:11,408 DEBUG CV Batch 147/0 loss 11.912053 loss_att 8.655951 loss_ctc 19.509624 loss_ctc_origin 13.297375 loss_ctc0 34.004875 history loss 11.211344 rank 0
2022-08-25 08:19:21,986 DEBUG CV Batch 147/100 loss 22.129238 loss_att 17.934805 loss_ctc 31.916250 loss_ctc_origin 22.252794 loss_ctc0 54.464310 history loss 27.377880 rank 0
2022-08-25 08:19:31,545 DEBUG CV Batch 147/200 loss 25.043335 loss_att 19.583820 loss_ctc 37.782196 loss_ctc_origin 27.260231 loss_ctc0 62.333454 history loss 28.727054 rank 0
2022-08-25 08:19:41,227 DEBUG CV Batch 147/300 loss 26.594973 loss_att 20.778143 loss_ctc 40.167576 loss_ctc_origin 26.132019 loss_ctc0 72.917206 history loss 27.832429 rank 0
2022-08-25 08:19:51,260 DEBUG CV Batch 147/400 loss 38.119110 loss_att 30.859285 loss_ctc 55.058693 loss_ctc_origin 37.498032 loss_ctc0 96.033577 history loss 26.159303 rank 0
2022-08-25 08:20:01,677 DEBUG CV Batch 147/500 loss 17.133373 loss_att 13.068109 loss_ctc 26.618988 loss_ctc_origin 19.758446 loss_ctc0 42.626923 history loss 25.808646 rank 0
2022-08-25 08:20:11,753 DEBUG CV Batch 147/600 loss 18.397621 loss_att 12.941303 loss_ctc 31.129032 loss_ctc_origin 20.916451 loss_ctc0 54.958389 history loss 25.631342 rank 0
2022-08-25 08:20:21,371 DEBUG CV Batch 147/700 loss 19.179693 loss_att 13.339802 loss_ctc 32.806107 loss_ctc_origin 19.776196 loss_ctc0 63.209229 history loss 25.278756 rank 0
2022-08-25 08:20:31,358 DEBUG CV Batch 147/800 loss 24.766394 loss_att 19.826088 loss_ctc 36.293774 loss_ctc_origin 21.745859 loss_ctc0 70.238907 history loss 25.220766 rank 0
2022-08-25 08:20:41,816 INFO Epoch 147 CV info cv_loss 25.277733745349963
2022-08-25 08:20:41,816 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/147.pt
2022-08-25 08:20:42,299 INFO Epoch 148 TRAIN info lr 0.0006893175632513685
2022-08-25 08:20:42,303 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 08:21:09,027 DEBUG TRAIN Batch 148/0 loss 42.486359 loss_att 26.609592 loss_ctc 79.532135 loss_ctc_origin 50.097637 loss_ctc0 148.212616 lr 0.00068932 rank 0
2022-08-25 08:21:36,877 DEBUG TRAIN Batch 148/100 loss 44.534939 loss_att 22.242199 loss_ctc 96.551331 loss_ctc_origin 46.494705 loss_ctc0 213.350128 lr 0.00068927 rank 0
2022-08-25 08:22:04,837 DEBUG TRAIN Batch 148/200 loss 20.151730 loss_att 10.431591 loss_ctc 42.832054 loss_ctc_origin 31.703098 loss_ctc0 68.799606 lr 0.00068923 rank 0
2022-08-25 08:22:34,242 DEBUG TRAIN Batch 148/300 loss 21.572495 loss_att 9.583305 loss_ctc 49.547268 loss_ctc_origin 35.631313 loss_ctc0 82.017822 lr 0.00068919 rank 0
2022-08-25 08:23:02,528 DEBUG TRAIN Batch 148/400 loss 22.205700 loss_att 8.665326 loss_ctc 53.799904 loss_ctc_origin 36.892654 loss_ctc0 93.250153 lr 0.00068915 rank 0
2022-08-25 08:23:30,755 DEBUG TRAIN Batch 148/500 loss 33.826908 loss_att 19.622929 loss_ctc 66.969528 loss_ctc_origin 37.187332 loss_ctc0 136.461334 lr 0.00068911 rank 0
2022-08-25 08:23:59,563 DEBUG TRAIN Batch 148/600 loss 49.990486 loss_att 27.441452 loss_ctc 102.604889 loss_ctc_origin 51.790802 loss_ctc0 221.171097 lr 0.00068907 rank 0
2022-08-25 08:24:27,668 DEBUG TRAIN Batch 148/700 loss 18.986801 loss_att 11.093901 loss_ctc 37.403568 loss_ctc_origin 27.137447 loss_ctc0 61.357853 lr 0.00068903 rank 0
2022-08-25 08:24:55,209 DEBUG TRAIN Batch 148/800 loss 18.657785 loss_att 8.742313 loss_ctc 41.793884 loss_ctc_origin 27.929298 loss_ctc0 74.144577 lr 0.00068899 rank 0
2022-08-25 08:25:23,899 DEBUG TRAIN Batch 148/900 loss 19.816057 loss_att 8.203424 loss_ctc 46.912201 loss_ctc_origin 26.654472 loss_ctc0 94.180222 lr 0.00068895 rank 0
2022-08-25 08:25:52,086 DEBUG TRAIN Batch 148/1000 loss 39.805611 loss_att 25.806635 loss_ctc 72.469879 loss_ctc_origin 43.820644 loss_ctc0 139.318085 lr 0.00068891 rank 0
2022-08-25 08:26:20,538 DEBUG TRAIN Batch 148/1100 loss 48.787994 loss_att 26.758200 loss_ctc 100.190842 loss_ctc_origin 50.282108 loss_ctc0 216.644562 lr 0.00068887 rank 0
2022-08-25 08:26:49,518 DEBUG TRAIN Batch 148/1200 loss 18.497665 loss_att 9.473978 loss_ctc 39.552933 loss_ctc_origin 28.471643 loss_ctc0 65.409279 lr 0.00068883 rank 0
2022-08-25 08:27:18,011 DEBUG TRAIN Batch 148/1300 loss 19.722088 loss_att 8.101144 loss_ctc 46.837624 loss_ctc_origin 34.655354 loss_ctc0 75.262924 lr 0.00068878 rank 0
2022-08-25 08:27:46,130 DEBUG TRAIN Batch 148/1400 loss 23.104294 loss_att 9.961876 loss_ctc 53.769936 loss_ctc_origin 35.637703 loss_ctc0 96.078468 lr 0.00068874 rank 0
2022-08-25 08:28:02,181 WARNING NaN or Inf found in input tensor.
2022-08-25 08:28:22,183 DEBUG TRAIN Batch 148/1500 loss 41.107880 loss_att 26.361469 loss_ctc 75.516174 loss_ctc_origin 46.166618 loss_ctc0 143.998474 lr 0.00068870 rank 0
2022-08-25 08:28:51,056 DEBUG TRAIN Batch 148/1600 loss 52.469593 loss_att 27.354572 loss_ctc 111.071304 loss_ctc_origin 63.965733 loss_ctc0 220.984314 lr 0.00068866 rank 0
2022-08-25 08:29:20,517 DEBUG TRAIN Batch 148/1700 loss 24.289104 loss_att 14.462082 loss_ctc 47.218819 loss_ctc_origin 37.944748 loss_ctc0 68.858307 lr 0.00068862 rank 0
2022-08-25 08:29:50,405 DEBUG TRAIN Batch 148/1800 loss 23.743460 loss_att 10.084641 loss_ctc 55.614037 loss_ctc_origin 41.207298 loss_ctc0 89.229752 lr 0.00068858 rank 0
2022-08-25 08:30:18,370 DEBUG TRAIN Batch 148/1900 loss 22.697718 loss_att 9.573778 loss_ctc 53.320244 loss_ctc_origin 34.116650 loss_ctc0 98.128632 lr 0.00068854 rank 0
2022-08-25 08:30:47,465 DEBUG TRAIN Batch 148/2000 loss 48.497246 loss_att 32.696892 loss_ctc 85.364738 loss_ctc_origin 52.300552 loss_ctc0 162.514496 lr 0.00068850 rank 0
2022-08-25 08:31:16,109 DEBUG TRAIN Batch 148/2100 loss 47.750984 loss_att 24.767818 loss_ctc 101.378372 loss_ctc_origin 50.651119 loss_ctc0 219.741974 lr 0.00068846 rank 0
2022-08-25 08:31:44,642 DEBUG TRAIN Batch 148/2200 loss 22.379673 loss_att 15.263483 loss_ctc 38.984119 loss_ctc_origin 30.767668 loss_ctc0 58.155838 lr 0.00068842 rank 0
2022-08-25 08:32:12,734 DEBUG TRAIN Batch 148/2300 loss 20.356956 loss_att 9.284307 loss_ctc 46.193138 loss_ctc_origin 31.624731 loss_ctc0 80.186081 lr 0.00068838 rank 0
2022-08-25 08:32:43,313 DEBUG TRAIN Batch 148/2400 loss 23.450277 loss_att 9.794200 loss_ctc 55.314457 loss_ctc_origin 38.297482 loss_ctc0 95.020729 lr 0.00068834 rank 0
2022-08-25 08:33:11,919 DEBUG TRAIN Batch 148/2500 loss 48.380821 loss_att 31.365162 loss_ctc 88.084023 loss_ctc_origin 56.950745 loss_ctc0 160.728333 lr 0.00068829 rank 0
2022-08-25 08:33:40,527 DEBUG TRAIN Batch 148/2600 loss 52.221313 loss_att 30.759581 loss_ctc 102.298691 loss_ctc_origin 49.672329 loss_ctc0 225.093536 lr 0.00068825 rank 0
2022-08-25 08:34:08,061 DEBUG TRAIN Batch 148/2700 loss 18.237078 loss_att 9.853434 loss_ctc 37.798912 loss_ctc_origin 26.115021 loss_ctc0 65.061325 lr 0.00068821 rank 0
2022-08-25 08:34:37,412 DEBUG TRAIN Batch 148/2800 loss 19.241163 loss_att 7.794736 loss_ctc 45.949493 loss_ctc_origin 32.378292 loss_ctc0 77.615631 lr 0.00068817 rank 0
2022-08-25 08:35:05,362 DEBUG TRAIN Batch 148/2900 loss 22.309765 loss_att 9.798157 loss_ctc 51.503517 loss_ctc_origin 34.328560 loss_ctc0 91.578415 lr 0.00068813 rank 0
2022-08-25 08:35:41,176 DEBUG TRAIN Batch 148/3000 loss 41.504860 loss_att 25.687424 loss_ctc 78.412216 loss_ctc_origin 47.465607 loss_ctc0 150.620972 lr 0.00068809 rank 0
2022-08-25 08:35:49,132 WARNING NaN or Inf found in input tensor.
2022-08-25 08:36:09,564 DEBUG TRAIN Batch 148/3100 loss 45.582394 loss_att 23.863867 loss_ctc 96.258957 loss_ctc_origin 50.004932 loss_ctc0 204.184998 lr 0.00068805 rank 0
2022-08-25 08:36:38,139 DEBUG TRAIN Batch 148/3200 loss 17.483299 loss_att 8.617702 loss_ctc 38.169689 loss_ctc_origin 25.086920 loss_ctc0 68.696144 lr 0.00068801 rank 0
2022-08-25 08:37:06,681 DEBUG TRAIN Batch 148/3300 loss 18.442850 loss_att 8.002813 loss_ctc 42.802933 loss_ctc_origin 29.935709 loss_ctc0 72.826462 lr 0.00068797 rank 0
2022-08-25 08:37:35,674 DEBUG TRAIN Batch 148/3400 loss 21.382744 loss_att 8.531357 loss_ctc 51.369308 loss_ctc_origin 34.291294 loss_ctc0 91.218002 lr 0.00068793 rank 0
2022-08-25 08:38:04,148 DEBUG TRAIN Batch 148/3500 loss 43.798874 loss_att 28.242947 loss_ctc 80.096039 loss_ctc_origin 49.722832 loss_ctc0 150.966858 lr 0.00068789 rank 0
2022-08-25 08:38:04,849 WARNING NaN or Inf found in input tensor.
2022-08-25 08:38:26,174 WARNING NaN or Inf found in input tensor.
2022-08-25 08:38:33,264 DEBUG TRAIN Batch 148/3600 loss 53.877571 loss_att 28.791580 loss_ctc 112.411545 loss_ctc_origin 62.196037 loss_ctc0 229.581070 lr 0.00068785 rank 0
2022-08-25 08:39:02,896 DEBUG TRAIN Batch 148/3700 loss 16.981300 loss_att 7.047957 loss_ctc 40.159103 loss_ctc_origin 26.943470 loss_ctc0 70.995583 lr 0.00068781 rank 0
2022-08-25 08:39:32,013 DEBUG TRAIN Batch 148/3800 loss 20.453724 loss_att 8.877245 loss_ctc 47.465504 loss_ctc_origin 34.396069 loss_ctc0 77.960854 lr 0.00068777 rank 0
2022-08-25 08:40:01,383 DEBUG TRAIN Batch 148/3900 loss 24.267982 loss_att 10.678914 loss_ctc 55.975807 loss_ctc_origin 38.766846 loss_ctc0 96.130058 lr 0.00068772 rank 0
2022-08-25 08:40:30,413 DEBUG TRAIN Batch 148/4000 loss 48.241364 loss_att 30.468910 loss_ctc 89.710419 loss_ctc_origin 53.876007 loss_ctc0 173.324036 lr 0.00068768 rank 0
2022-08-25 08:40:59,398 DEBUG TRAIN Batch 148/4100 loss 52.853722 loss_att 32.770294 loss_ctc 99.715042 loss_ctc_origin 64.706474 loss_ctc0 181.401703 lr 0.00068764 rank 0
2022-08-25 08:41:26,042 DEBUG TRAIN Batch 148/4200 loss 16.430008 loss_att 9.295424 loss_ctc 33.077366 loss_ctc_origin 23.101307 loss_ctc0 56.354836 lr 0.00068760 rank 0
2022-08-25 08:41:55,373 DEBUG TRAIN Batch 148/4300 loss 20.900845 loss_att 9.618709 loss_ctc 47.225830 loss_ctc_origin 31.434708 loss_ctc0 84.071785 lr 0.00068756 rank 0
2022-08-25 08:42:25,362 DEBUG TRAIN Batch 148/4400 loss 22.709419 loss_att 9.905363 loss_ctc 52.585548 loss_ctc_origin 35.130547 loss_ctc0 93.313873 lr 0.00068752 rank 0
2022-08-25 08:42:59,726 DEBUG TRAIN Batch 148/4500 loss 43.893990 loss_att 32.154938 loss_ctc 71.285110 loss_ctc_origin 47.224369 loss_ctc0 127.426849 lr 0.00068748 rank 0
2022-08-25 08:43:28,538 DEBUG TRAIN Batch 148/4600 loss 46.650833 loss_att 27.261898 loss_ctc 91.891678 loss_ctc_origin 48.707264 loss_ctc0 192.655319 lr 0.00068744 rank 0
2022-08-25 08:43:56,390 DEBUG TRAIN Batch 148/4700 loss 19.184132 loss_att 10.886803 loss_ctc 38.544563 loss_ctc_origin 26.576794 loss_ctc0 66.469353 lr 0.00068740 rank 0
2022-08-25 08:44:24,942 DEBUG TRAIN Batch 148/4800 loss 18.657793 loss_att 7.146729 loss_ctc 45.516945 loss_ctc_origin 31.160282 loss_ctc0 79.015823 lr 0.00068736 rank 0
2022-08-25 08:44:54,969 DEBUG TRAIN Batch 148/4900 loss 21.488056 loss_att 9.424011 loss_ctc 49.637489 loss_ctc_origin 33.810989 loss_ctc0 86.565979 lr 0.00068732 rank 0
2022-08-25 08:45:23,885 DEBUG TRAIN Batch 148/5000 loss 39.482162 loss_att 26.487946 loss_ctc 69.801994 loss_ctc_origin 45.308281 loss_ctc0 126.954002 lr 0.00068728 rank 0
2022-08-25 08:45:31,685 WARNING NaN or Inf found in input tensor.
2022-08-25 08:45:52,153 DEBUG TRAIN Batch 148/5100 loss 59.054657 loss_att 34.846748 loss_ctc 115.539780 loss_ctc_origin 65.477760 loss_ctc0 232.351166 lr 0.00068724 rank 0
2022-08-25 08:46:20,996 DEBUG TRAIN Batch 148/5200 loss 20.095915 loss_att 10.656663 loss_ctc 42.120834 loss_ctc_origin 31.052301 loss_ctc0 67.947403 lr 0.00068720 rank 0
2022-08-25 08:46:49,835 DEBUG TRAIN Batch 148/5300 loss 21.770897 loss_att 9.494911 loss_ctc 50.414864 loss_ctc_origin 37.024895 loss_ctc0 81.658119 lr 0.00068716 rank 0
2022-08-25 08:47:14,271 WARNING NaN or Inf found in input tensor.
2022-08-25 08:47:18,685 DEBUG TRAIN Batch 148/5400 loss 21.234688 loss_att 8.297545 loss_ctc 51.421349 loss_ctc_origin 33.344162 loss_ctc0 93.601440 lr 0.00068712 rank 0
2022-08-25 08:47:49,388 DEBUG TRAIN Batch 148/5500 loss 47.073879 loss_att 31.223595 loss_ctc 84.057877 loss_ctc_origin 58.748795 loss_ctc0 143.112396 lr 0.00068708 rank 0
2022-08-25 08:48:19,000 DEBUG TRAIN Batch 148/5600 loss 63.093155 loss_att 38.322571 loss_ctc 120.891182 loss_ctc_origin 69.695740 loss_ctc0 240.347198 lr 0.00068703 rank 0
2022-08-25 08:48:45,182 DEBUG CV Batch 148/0 loss 12.229488 loss_att 9.028182 loss_ctc 19.699203 loss_ctc_origin 13.460148 loss_ctc0 34.257004 history loss 11.510107 rank 0
2022-08-25 08:48:55,509 DEBUG CV Batch 148/100 loss 22.417274 loss_att 18.090672 loss_ctc 32.512684 loss_ctc_origin 23.052689 loss_ctc0 54.586006 history loss 27.086117 rank 0
2022-08-25 08:49:04,619 DEBUG CV Batch 148/200 loss 25.903008 loss_att 20.292482 loss_ctc 38.994236 loss_ctc_origin 28.791550 loss_ctc0 62.800499 history loss 28.597506 rank 0
2022-08-25 08:49:14,011 DEBUG CV Batch 148/300 loss 24.356136 loss_att 18.802364 loss_ctc 37.314941 loss_ctc_origin 22.100780 loss_ctc0 72.814651 history loss 27.736391 rank 0
2022-08-25 08:49:24,072 DEBUG CV Batch 148/400 loss 38.739773 loss_att 31.151587 loss_ctc 56.445541 loss_ctc_origin 39.469299 loss_ctc0 96.056770 history loss 25.986463 rank 0
2022-08-25 08:49:33,921 DEBUG CV Batch 148/500 loss 17.930729 loss_att 13.668322 loss_ctc 27.876343 loss_ctc_origin 21.760101 loss_ctc0 42.147575 history loss 25.642031 rank 0
2022-08-25 08:49:43,910 DEBUG CV Batch 148/600 loss 17.199266 loss_att 11.562975 loss_ctc 30.350613 loss_ctc_origin 19.976351 loss_ctc0 54.557228 history loss 25.453467 rank 0
2022-08-25 08:49:53,933 DEBUG CV Batch 148/700 loss 18.453413 loss_att 12.366217 loss_ctc 32.656872 loss_ctc_origin 19.080248 loss_ctc0 64.335655 history loss 25.105467 rank 0
2022-08-25 08:50:03,997 DEBUG CV Batch 148/800 loss 23.520336 loss_att 18.650434 loss_ctc 34.883438 loss_ctc_origin 19.966433 loss_ctc0 69.689789 history loss 25.059761 rank 0
2022-08-25 08:50:13,837 INFO Epoch 148 CV info cv_loss 25.162651423059355
2022-08-25 08:50:13,838 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/148.pt
2022-08-25 08:50:14,314 INFO Epoch 149 TRAIN info lr 0.0006870005228694269
2022-08-25 08:50:14,317 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 08:50:41,904 DEBUG TRAIN Batch 149/0 loss 48.748714 loss_att 31.823053 loss_ctc 88.241920 loss_ctc_origin 53.174824 loss_ctc0 170.065140 lr 0.00068700 rank 0
2022-08-25 08:51:10,652 DEBUG TRAIN Batch 149/100 loss 56.032188 loss_att 31.344870 loss_ctc 113.635933 loss_ctc_origin 67.377701 loss_ctc0 221.571808 lr 0.00068696 rank 0
2022-08-25 08:51:38,937 DEBUG TRAIN Batch 149/200 loss 18.507481 loss_att 7.755188 loss_ctc 43.596161 loss_ctc_origin 31.658260 loss_ctc0 71.451263 lr 0.00068692 rank 0
2022-08-25 08:52:07,055 DEBUG TRAIN Batch 149/300 loss 18.065622 loss_att 7.215365 loss_ctc 43.382889 loss_ctc_origin 29.455664 loss_ctc0 75.879745 lr 0.00068688 rank 0
2022-08-25 08:52:35,136 DEBUG TRAIN Batch 149/400 loss 23.128738 loss_att 9.224459 loss_ctc 55.572056 loss_ctc_origin 38.925003 loss_ctc0 94.415176 lr 0.00068684 rank 0
2022-08-25 08:53:05,295 DEBUG TRAIN Batch 149/500 loss 49.829971 loss_att 33.837982 loss_ctc 87.144608 loss_ctc_origin 54.954853 loss_ctc0 162.254028 lr 0.00068680 rank 0
2022-08-25 08:53:33,268 DEBUG TRAIN Batch 149/600 loss 54.145241 loss_att 29.223206 loss_ctc 112.296646 loss_ctc_origin 63.200657 loss_ctc0 226.853958 lr 0.00068676 rank 0
2022-08-25 08:54:01,679 DEBUG TRAIN Batch 149/700 loss 51.116028 loss_att 22.995651 loss_ctc 116.730240 loss_ctc_origin 61.242859 loss_ctc0 246.200790 lr 0.00068672 rank 0
2022-08-25 08:54:06,845 WARNING NaN or Inf found in input tensor.
2022-08-25 08:54:31,146 DEBUG TRAIN Batch 149/800 loss 20.330524 loss_att 8.411770 loss_ctc 48.140945 loss_ctc_origin 32.671925 loss_ctc0 84.235336 lr 0.00068667 rank 0
2022-08-25 08:54:59,525 DEBUG TRAIN Batch 149/900 loss 25.256350 loss_att 12.009885 loss_ctc 56.164764 loss_ctc_origin 39.959686 loss_ctc0 93.976601 lr 0.00068663 rank 0
2022-08-25 08:55:02,171 WARNING NaN or Inf found in input tensor.
2022-08-25 08:55:28,590 DEBUG TRAIN Batch 149/1000 loss 36.556843 loss_att 21.762238 loss_ctc 71.077583 loss_ctc_origin 39.044350 loss_ctc0 145.821777 lr 0.00068659 rank 0
2022-08-25 08:55:57,763 DEBUG TRAIN Batch 149/1100 loss 51.272259 loss_att 26.961004 loss_ctc 107.998512 loss_ctc_origin 55.836784 loss_ctc0 229.709198 lr 0.00068655 rank 0
2022-08-25 08:56:27,161 DEBUG TRAIN Batch 149/1200 loss 27.866962 loss_att 16.174179 loss_ctc 55.150124 loss_ctc_origin 48.723167 loss_ctc0 70.146362 lr 0.00068651 rank 0
2022-08-25 08:56:55,496 DEBUG TRAIN Batch 149/1300 loss 19.217459 loss_att 8.542120 loss_ctc 44.126579 loss_ctc_origin 31.144640 loss_ctc0 74.417763 lr 0.00068647 rank 0
2022-08-25 08:57:23,841 DEBUG TRAIN Batch 149/1400 loss 23.263157 loss_att 9.938667 loss_ctc 54.353630 loss_ctc_origin 35.835072 loss_ctc0 97.563599 lr 0.00068643 rank 0
2022-08-25 08:57:58,395 DEBUG TRAIN Batch 149/1500 loss 52.152237 loss_att 35.546391 loss_ctc 90.899216 loss_ctc_origin 62.604462 loss_ctc0 156.920288 lr 0.00068639 rank 0
2022-08-25 08:57:59,227 WARNING NaN or Inf found in input tensor.
2022-08-25 08:58:27,045 DEBUG TRAIN Batch 149/1600 loss 57.093941 loss_att 31.473381 loss_ctc 116.875244 loss_ctc_origin 67.636368 loss_ctc0 231.765945 lr 0.00068635 rank 0
2022-08-25 08:58:54,808 DEBUG TRAIN Batch 149/1700 loss 20.577560 loss_att 11.786995 loss_ctc 41.088882 loss_ctc_origin 29.210159 loss_ctc0 68.805893 lr 0.00068631 rank 0
2022-08-25 08:59:23,215 DEBUG TRAIN Batch 149/1800 loss 19.812017 loss_att 9.180758 loss_ctc 44.618286 loss_ctc_origin 31.349766 loss_ctc0 75.578163 lr 0.00068627 rank 0
2022-08-25 08:59:47,656 WARNING NaN or Inf found in input tensor.
2022-08-25 08:59:52,207 DEBUG TRAIN Batch 149/1900 loss 22.439098 loss_att 10.335052 loss_ctc 50.681873 loss_ctc_origin 32.549007 loss_ctc0 92.991890 lr 0.00068623 rank 0
2022-08-25 09:00:20,860 DEBUG TRAIN Batch 149/2000 loss 44.947773 loss_att 31.445145 loss_ctc 76.453903 loss_ctc_origin 47.896198 loss_ctc0 143.088547 lr 0.00068619 rank 0
2022-08-25 09:00:49,981 DEBUG TRAIN Batch 149/2100 loss 45.149345 loss_att 22.113102 loss_ctc 98.900574 loss_ctc_origin 51.826767 loss_ctc0 208.739441 lr 0.00068615 rank 0
2022-08-25 09:01:19,983 DEBUG TRAIN Batch 149/2200 loss 21.871948 loss_att 12.743442 loss_ctc 43.171791 loss_ctc_origin 33.443985 loss_ctc0 65.870003 lr 0.00068611 rank 0
2022-08-25 09:01:47,799 DEBUG TRAIN Batch 149/2300 loss 21.871817 loss_att 9.168612 loss_ctc 51.512627 loss_ctc_origin 36.809971 loss_ctc0 85.818817 lr 0.00068607 rank 0
2022-08-25 09:02:17,178 DEBUG TRAIN Batch 149/2400 loss 19.052097 loss_att 7.987996 loss_ctc 44.868332 loss_ctc_origin 27.724422 loss_ctc0 84.870789 lr 0.00068603 rank 0
2022-08-25 09:02:46,541 DEBUG TRAIN Batch 149/2500 loss 38.564148 loss_att 26.021498 loss_ctc 67.830330 loss_ctc_origin 38.785797 loss_ctc0 135.600906 lr 0.00068599 rank 0
2022-08-25 09:03:15,049 DEBUG TRAIN Batch 149/2600 loss 49.079773 loss_att 28.097939 loss_ctc 98.037392 loss_ctc_origin 52.862282 loss_ctc0 203.445969 lr 0.00068595 rank 0
2022-08-25 09:03:44,070 DEBUG TRAIN Batch 149/2700 loss 15.476409 loss_att 7.326008 loss_ctc 34.494011 loss_ctc_origin 22.512615 loss_ctc0 62.450600 lr 0.00068591 rank 0
2022-08-25 09:04:13,481 DEBUG TRAIN Batch 149/2800 loss 21.203125 loss_att 8.883984 loss_ctc 49.947784 loss_ctc_origin 36.321846 loss_ctc0 81.741638 lr 0.00068587 rank 0
2022-08-25 09:04:43,042 DEBUG TRAIN Batch 149/2900 loss 24.262943 loss_att 10.489727 loss_ctc 56.400448 loss_ctc_origin 39.740784 loss_ctc0 95.272995 lr 0.00068583 rank 0
2022-08-25 09:04:50,474 WARNING NaN or Inf found in input tensor.
2022-08-25 09:05:16,040 DEBUG TRAIN Batch 149/3000 loss 43.316170 loss_att 27.065231 loss_ctc 81.235031 loss_ctc_origin 46.189892 loss_ctc0 163.007034 lr 0.00068579 rank 0
2022-08-25 09:05:30,776 WARNING NaN or Inf found in input tensor.
2022-08-25 09:05:44,471 DEBUG TRAIN Batch 149/3100 loss 57.043186 loss_att 31.245634 loss_ctc 117.237473 loss_ctc_origin 58.710281 loss_ctc0 253.800903 lr 0.00068575 rank 0
2022-08-25 09:06:12,680 DEBUG TRAIN Batch 149/3200 loss 21.337902 loss_att 11.019732 loss_ctc 45.413635 loss_ctc_origin 34.335358 loss_ctc0 71.262955 lr 0.00068571 rank 0
2022-08-25 09:06:41,200 DEBUG TRAIN Batch 149/3300 loss 20.297546 loss_att 8.925407 loss_ctc 46.832539 loss_ctc_origin 31.669674 loss_ctc0 82.212555 lr 0.00068567 rank 0
2022-08-25 09:07:09,919 DEBUG TRAIN Batch 149/3400 loss 18.671560 loss_att 7.181866 loss_ctc 45.480843 loss_ctc_origin 25.614346 loss_ctc0 91.835999 lr 0.00068563 rank 0
2022-08-25 09:07:38,391 DEBUG TRAIN Batch 149/3500 loss 41.628220 loss_att 28.118723 loss_ctc 73.150375 loss_ctc_origin 41.185745 loss_ctc0 147.734497 lr 0.00068558 rank 0
2022-08-25 09:08:06,754 DEBUG TRAIN Batch 149/3600 loss 58.504765 loss_att 32.126759 loss_ctc 120.053436 loss_ctc_origin 61.245163 loss_ctc0 257.272736 lr 0.00068554 rank 0
2022-08-25 09:08:34,550 DEBUG TRAIN Batch 149/3700 loss 20.828098 loss_att 12.010541 loss_ctc 41.402397 loss_ctc_origin 31.682627 loss_ctc0 64.081863 lr 0.00068550 rank 0
2022-08-25 09:09:01,616 DEBUG TRAIN Batch 149/3800 loss 22.352074 loss_att 9.096314 loss_ctc 53.282181 loss_ctc_origin 42.137875 loss_ctc0 79.285561 lr 0.00068546 rank 0
2022-08-25 09:09:31,206 DEBUG TRAIN Batch 149/3900 loss 23.483498 loss_att 10.927541 loss_ctc 52.780724 loss_ctc_origin 36.310287 loss_ctc0 91.211739 lr 0.00068542 rank 0
2022-08-25 09:10:00,007 DEBUG TRAIN Batch 149/4000 loss 46.549431 loss_att 28.919056 loss_ctc 87.686966 loss_ctc_origin 50.267815 loss_ctc0 174.998322 lr 0.00068538 rank 0
2022-08-25 09:10:21,005 WARNING NaN or Inf found in input tensor.
2022-08-25 09:10:28,056 DEBUG TRAIN Batch 149/4100 loss 55.967316 loss_att 29.157722 loss_ctc 118.523018 loss_ctc_origin 63.733650 loss_ctc0 246.364868 lr 0.00068534 rank 0
2022-08-25 09:10:56,615 DEBUG TRAIN Batch 149/4200 loss 19.463120 loss_att 10.575758 loss_ctc 40.200298 loss_ctc_origin 29.097908 loss_ctc0 66.105873 lr 0.00068530 rank 0
2022-08-25 09:11:26,382 DEBUG TRAIN Batch 149/4300 loss 22.716780 loss_att 10.189373 loss_ctc 51.947395 loss_ctc_origin 37.865990 loss_ctc0 84.804001 lr 0.00068526 rank 0
2022-08-25 09:11:49,067 WARNING NaN or Inf found in input tensor.
2022-08-25 09:11:53,346 DEBUG TRAIN Batch 149/4400 loss 26.690254 loss_att 11.469194 loss_ctc 62.206055 loss_ctc_origin 44.403885 loss_ctc0 103.744446 lr 0.00068522 rank 0
2022-08-25 09:12:17,124 WARNING NaN or Inf found in input tensor.
2022-08-25 09:12:29,605 DEBUG TRAIN Batch 149/4500 loss 42.166557 loss_att 25.218639 loss_ctc 81.711700 loss_ctc_origin 45.978577 loss_ctc0 165.088989 lr 0.00068518 rank 0
2022-08-25 09:12:58,656 DEBUG TRAIN Batch 149/4600 loss 62.162369 loss_att 37.831303 loss_ctc 118.934853 loss_ctc_origin 65.135796 loss_ctc0 244.465973 lr 0.00068514 rank 0
2022-08-25 09:13:26,627 DEBUG TRAIN Batch 149/4700 loss 24.722717 loss_att 14.159152 loss_ctc 49.371033 loss_ctc_origin 39.888870 loss_ctc0 71.496071 lr 0.00068510 rank 0
2022-08-25 09:13:53,976 DEBUG TRAIN Batch 149/4800 loss 21.438637 loss_att 8.995028 loss_ctc 50.473721 loss_ctc_origin 36.046158 loss_ctc0 84.138031 lr 0.00068506 rank 0
2022-08-25 09:14:23,376 DEBUG TRAIN Batch 149/4900 loss 20.169020 loss_att 7.971165 loss_ctc 48.630676 loss_ctc_origin 29.946861 loss_ctc0 92.226242 lr 0.00068502 rank 0
2022-08-25 09:14:51,852 DEBUG TRAIN Batch 149/5000 loss 54.319881 loss_att 39.164093 loss_ctc 89.683380 loss_ctc_origin 58.458580 loss_ctc0 162.541229 lr 0.00068498 rank 0
2022-08-25 09:15:20,262 DEBUG TRAIN Batch 149/5100 loss 56.851692 loss_att 32.029388 loss_ctc 114.770386 loss_ctc_origin 58.303417 loss_ctc0 246.526627 lr 0.00068494 rank 0
2022-08-25 09:15:47,729 DEBUG TRAIN Batch 149/5200 loss 20.105179 loss_att 10.039738 loss_ctc 43.591209 loss_ctc_origin 32.445511 loss_ctc0 69.597839 lr 0.00068490 rank 0
2022-08-25 09:16:15,891 DEBUG TRAIN Batch 149/5300 loss 22.195770 loss_att 8.834578 loss_ctc 53.371887 loss_ctc_origin 38.991760 loss_ctc0 86.925507 lr 0.00068486 rank 0
2022-08-25 09:16:45,571 DEBUG TRAIN Batch 149/5400 loss 19.122311 loss_att 7.606589 loss_ctc 45.992325 loss_ctc_origin 26.037895 loss_ctc0 92.552658 lr 0.00068482 rank 0
2022-08-25 09:17:15,858 DEBUG TRAIN Batch 149/5500 loss 45.927753 loss_att 28.045582 loss_ctc 87.652817 loss_ctc_origin 51.131577 loss_ctc0 172.869049 lr 0.00068478 rank 0
2022-08-25 09:17:42,493 DEBUG TRAIN Batch 149/5600 loss 56.897522 loss_att 32.105019 loss_ctc 114.746689 loss_ctc_origin 64.892624 loss_ctc0 231.072845 lr 0.00068474 rank 0
2022-08-25 09:18:06,391 DEBUG CV Batch 149/0 loss 12.207205 loss_att 9.200193 loss_ctc 19.223564 loss_ctc_origin 13.087399 loss_ctc0 33.541283 history loss 11.489134 rank 0
2022-08-25 09:18:16,837 DEBUG CV Batch 149/100 loss 20.638306 loss_att 16.485725 loss_ctc 30.327656 loss_ctc_origin 20.472176 loss_ctc0 53.323776 history loss 26.217469 rank 0
2022-08-25 09:18:26,338 DEBUG CV Batch 149/200 loss 24.731972 loss_att 19.161493 loss_ctc 37.729752 loss_ctc_origin 27.368057 loss_ctc0 61.907036 history loss 27.575873 rank 0
2022-08-25 09:18:36,043 DEBUG CV Batch 149/300 loss 22.926682 loss_att 17.532520 loss_ctc 35.513054 loss_ctc_origin 19.876186 loss_ctc0 71.999077 history loss 26.765603 rank 0
2022-08-25 09:18:46,643 DEBUG CV Batch 149/400 loss 38.188301 loss_att 30.732567 loss_ctc 55.585022 loss_ctc_origin 38.489014 loss_ctc0 95.475716 history loss 25.153728 rank 0
2022-08-25 09:18:57,577 DEBUG CV Batch 149/500 loss 16.078087 loss_att 12.059071 loss_ctc 25.455795 loss_ctc_origin 18.301485 loss_ctc0 42.149181 history loss 24.823047 rank 0
2022-08-25 09:19:08,756 DEBUG CV Batch 149/600 loss 18.100204 loss_att 12.634109 loss_ctc 30.854427 loss_ctc_origin 20.816957 loss_ctc0 54.275185 history loss 24.643711 rank 0
2022-08-25 09:19:19,671 DEBUG CV Batch 149/700 loss 17.909576 loss_att 11.992887 loss_ctc 31.715185 loss_ctc_origin 18.133512 loss_ctc0 63.405750 history loss 24.295196 rank 0
2022-08-25 09:19:30,777 DEBUG CV Batch 149/800 loss 21.722383 loss_att 16.712643 loss_ctc 33.411777 loss_ctc_origin 18.303402 loss_ctc0 68.664650 history loss 24.260365 rank 0
2022-08-25 09:19:41,364 INFO Epoch 149 CV info cv_loss 24.3406386112829
2022-08-25 09:19:41,365 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/149.pt
2022-08-25 09:19:41,835 INFO Epoch 150 TRAIN info lr 0.0006847066916814675
2022-08-25 09:19:41,839 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 09:20:08,717 DEBUG TRAIN Batch 150/0 loss 41.216709 loss_att 26.098545 loss_ctc 76.492424 loss_ctc_origin 44.490509 loss_ctc0 151.163559 lr 0.00068471 rank 0
2022-08-25 09:20:37,533 DEBUG TRAIN Batch 150/100 loss 61.665730 loss_att 34.382462 loss_ctc 125.326691 loss_ctc_origin 70.705627 loss_ctc0 252.775818 lr 0.00068466 rank 0
2022-08-25 09:21:04,991 DEBUG TRAIN Batch 150/200 loss 17.116268 loss_att 7.950775 loss_ctc 38.502419 loss_ctc_origin 27.523304 loss_ctc0 64.120346 lr 0.00068462 rank 0
2022-08-25 09:21:34,063 DEBUG TRAIN Batch 150/300 loss 21.533558 loss_att 8.830647 loss_ctc 51.173683 loss_ctc_origin 35.968468 loss_ctc0 86.652512 lr 0.00068458 rank 0
2022-08-25 09:21:57,827 WARNING NaN or Inf found in input tensor.
2022-08-25 09:22:02,018 DEBUG TRAIN Batch 150/400 loss 21.689110 loss_att 8.593304 loss_ctc 52.245991 loss_ctc_origin 34.073532 loss_ctc0 94.648392 lr 0.00068454 rank 0
2022-08-25 09:22:31,194 DEBUG TRAIN Batch 150/500 loss 46.678268 loss_att 28.018242 loss_ctc 90.218338 loss_ctc_origin 52.461514 loss_ctc0 178.317581 lr 0.00068450 rank 0
2022-08-25 09:22:51,419 WARNING NaN or Inf found in input tensor.
2022-08-25 09:22:57,931 DEBUG TRAIN Batch 150/600 loss 56.488113 loss_att 32.370152 loss_ctc 112.763351 loss_ctc_origin 57.011665 loss_ctc0 242.850616 lr 0.00068446 rank 0
2022-08-25 09:23:26,748 DEBUG TRAIN Batch 150/700 loss 16.777287 loss_att 7.602412 loss_ctc 38.185329 loss_ctc_origin 25.934711 loss_ctc0 66.770103 lr 0.00068442 rank 0
2022-08-25 09:23:55,182 DEBUG TRAIN Batch 150/800 loss 19.279175 loss_att 7.832877 loss_ctc 45.987198 loss_ctc_origin 30.229752 loss_ctc0 82.754562 lr 0.00068438 rank 0
2022-08-25 09:24:24,954 DEBUG TRAIN Batch 150/900 loss 22.594585 loss_att 9.449047 loss_ctc 53.267506 loss_ctc_origin 35.191677 loss_ctc0 95.444435 lr 0.00068434 rank 0
2022-08-25 09:24:53,970 DEBUG TRAIN Batch 150/1000 loss 47.207909 loss_att 29.569538 loss_ctc 88.364105 loss_ctc_origin 54.792847 loss_ctc0 166.697052 lr 0.00068430 rank 0
2022-08-25 09:25:21,433 DEBUG TRAIN Batch 150/1100 loss 53.867653 loss_att 25.886951 loss_ctc 119.155960 loss_ctc_origin 58.071056 loss_ctc0 261.687408 lr 0.00068426 rank 0
2022-08-25 09:25:51,026 DEBUG TRAIN Batch 150/1200 loss 20.431334 loss_att 11.645737 loss_ctc 40.931057 loss_ctc_origin 30.058773 loss_ctc0 66.299713 lr 0.00068422 rank 0
2022-08-25 09:26:19,338 DEBUG TRAIN Batch 150/1300 loss 19.559984 loss_att 8.964887 loss_ctc 44.281876 loss_ctc_origin 30.362444 loss_ctc0 76.760544 lr 0.00068418 rank 0
2022-08-25 09:26:44,085 WARNING NaN or Inf found in input tensor.
2022-08-25 09:26:48,546 DEBUG TRAIN Batch 150/1400 loss 24.763729 loss_att 11.346782 loss_ctc 56.069939 loss_ctc_origin 39.307556 loss_ctc0 95.182159 lr 0.00068414 rank 0
2022-08-25 09:27:24,418 DEBUG TRAIN Batch 150/1500 loss 50.351585 loss_att 33.183510 loss_ctc 90.410431 loss_ctc_origin 60.920895 loss_ctc0 159.219330 lr 0.00068410 rank 0
2022-08-25 09:27:53,937 DEBUG TRAIN Batch 150/1600 loss 48.016922 loss_att 23.621763 loss_ctc 104.938950 loss_ctc_origin 52.159519 loss_ctc0 228.090973 lr 0.00068406 rank 0
2022-08-25 09:28:22,263 DEBUG TRAIN Batch 150/1700 loss 18.468388 loss_att 8.997245 loss_ctc 40.567719 loss_ctc_origin 28.960468 loss_ctc0 67.651306 lr 0.00068402 rank 0
2022-08-25 09:28:50,933 DEBUG TRAIN Batch 150/1800 loss 22.652676 loss_att 9.686817 loss_ctc 52.906345 loss_ctc_origin 39.766586 loss_ctc0 83.565781 lr 0.00068398 rank 0
2022-08-25 09:29:19,838 DEBUG TRAIN Batch 150/1900 loss 23.610655 loss_att 9.144558 loss_ctc 57.364883 loss_ctc_origin 39.754906 loss_ctc0 98.454834 lr 0.00068394 rank 0
2022-08-25 09:29:49,256 DEBUG TRAIN Batch 150/2000 loss 42.946243 loss_att 27.501789 loss_ctc 78.983299 loss_ctc_origin 50.417587 loss_ctc0 145.636627 lr 0.00068390 rank 0
2022-08-25 09:30:17,383 DEBUG TRAIN Batch 150/2100 loss 59.014763 loss_att 36.225109 loss_ctc 112.190628 loss_ctc_origin 60.870247 loss_ctc0 231.938156 lr 0.00068386 rank 0
2022-08-25 09:30:46,996 DEBUG TRAIN Batch 150/2200 loss 21.943119 loss_att 11.916491 loss_ctc 45.338585 loss_ctc_origin 34.636314 loss_ctc0 70.310555 lr 0.00068382 rank 0
2022-08-25 09:31:15,678 DEBUG TRAIN Batch 150/2300 loss 19.311905 loss_att 8.325434 loss_ctc 44.946999 loss_ctc_origin 30.632795 loss_ctc0 78.346809 lr 0.00068378 rank 0
2022-08-25 09:31:45,402 DEBUG TRAIN Batch 150/2400 loss 21.377905 loss_att 8.104954 loss_ctc 52.348122 loss_ctc_origin 31.099857 loss_ctc0 101.927406 lr 0.00068374 rank 0
2022-08-25 09:32:14,499 DEBUG TRAIN Batch 150/2500 loss 51.067204 loss_att 34.728088 loss_ctc 89.191803 loss_ctc_origin 57.594513 loss_ctc0 162.918808 lr 0.00068370 rank 0
2022-08-25 09:32:42,656 DEBUG TRAIN Batch 150/2600 loss 53.509293 loss_att 29.111326 loss_ctc 110.437889 loss_ctc_origin 58.090439 loss_ctc0 232.581940 lr 0.00068366 rank 0
2022-08-25 09:33:10,681 DEBUG TRAIN Batch 150/2700 loss 17.874271 loss_att 8.840637 loss_ctc 38.952751 loss_ctc_origin 28.196180 loss_ctc0 64.051407 lr 0.00068362 rank 0
2022-08-25 09:33:38,570 DEBUG TRAIN Batch 150/2800 loss 18.664949 loss_att 8.635849 loss_ctc 42.066185 loss_ctc_origin 27.907242 loss_ctc0 75.103714 lr 0.00068358 rank 0
2022-08-25 09:34:06,480 DEBUG TRAIN Batch 150/2900 loss 24.716511 loss_att 10.127991 loss_ctc 58.756386 loss_ctc_origin 41.653145 loss_ctc0 98.663940 lr 0.00068354 rank 0
2022-08-25 09:34:42,962 DEBUG TRAIN Batch 150/3000 loss 56.739006 loss_att 39.879890 loss_ctc 96.076935 loss_ctc_origin 69.711853 loss_ctc0 157.595459 lr 0.00068350 rank 0
2022-08-25 09:34:50,589 WARNING NaN or Inf found in input tensor.
2022-08-25 09:35:11,986 DEBUG TRAIN Batch 150/3100 loss 57.350082 loss_att 31.928776 loss_ctc 116.666458 loss_ctc_origin 64.861046 loss_ctc0 237.545746 lr 0.00068346 rank 0
2022-08-25 09:35:40,840 DEBUG TRAIN Batch 150/3200 loss 18.986549 loss_att 10.813477 loss_ctc 38.057049 loss_ctc_origin 27.170347 loss_ctc0 63.459347 lr 0.00068342 rank 0
2022-08-25 09:36:09,393 DEBUG TRAIN Batch 150/3300 loss 17.745308 loss_att 8.173933 loss_ctc 40.078514 loss_ctc_origin 25.383102 loss_ctc0 74.367798 lr 0.00068338 rank 0
2022-08-25 09:36:33,999 WARNING NaN or Inf found in input tensor.
2022-08-25 09:36:38,201 DEBUG TRAIN Batch 150/3400 loss 22.268513 loss_att 10.109866 loss_ctc 50.638687 loss_ctc_origin 35.063004 loss_ctc0 86.981941 lr 0.00068334 rank 0
2022-08-25 09:37:07,997 DEBUG TRAIN Batch 150/3500 loss 53.176155 loss_att 37.060875 loss_ctc 90.778473 loss_ctc_origin 59.975533 loss_ctc0 162.651978 lr 0.00068330 rank 0
2022-08-25 09:37:36,196 DEBUG TRAIN Batch 150/3600 loss 51.404289 loss_att 28.016624 loss_ctc 105.975494 loss_ctc_origin 52.857716 loss_ctc0 229.916946 lr 0.00068327 rank 0
2022-08-25 09:38:04,938 DEBUG TRAIN Batch 150/3700 loss 19.761086 loss_att 9.606092 loss_ctc 43.456070 loss_ctc_origin 32.000839 loss_ctc0 70.184937 lr 0.00068323 rank 0
2022-08-25 09:38:34,176 DEBUG TRAIN Batch 150/3800 loss 19.228159 loss_att 8.092323 loss_ctc 45.211773 loss_ctc_origin 30.392162 loss_ctc0 79.790863 lr 0.00068319 rank 0
2022-08-25 09:39:02,545 DEBUG TRAIN Batch 150/3900 loss 21.877605 loss_att 8.433310 loss_ctc 53.247627 loss_ctc_origin 35.297146 loss_ctc0 95.132072 lr 0.00068315 rank 0
2022-08-25 09:39:32,915 DEBUG TRAIN Batch 150/4000 loss 46.673927 loss_att 30.517992 loss_ctc 84.371109 loss_ctc_origin 51.355045 loss_ctc0 161.408569 lr 0.00068311 rank 0
2022-08-25 09:39:59,295 DEBUG TRAIN Batch 150/4100 loss 49.135326 loss_att 26.185925 loss_ctc 102.683929 loss_ctc_origin 47.318581 loss_ctc0 231.869720 lr 0.00068307 rank 0
2022-08-25 09:40:28,566 DEBUG TRAIN Batch 150/4200 loss 24.117153 loss_att 14.669775 loss_ctc 46.161034 loss_ctc_origin 37.548031 loss_ctc0 66.258034 lr 0.00068303 rank 0
2022-08-25 09:40:57,687 DEBUG TRAIN Batch 150/4300 loss 19.056078 loss_att 8.225052 loss_ctc 44.328468 loss_ctc_origin 30.667225 loss_ctc0 76.204697 lr 0.00068299 rank 0
2022-08-25 09:41:25,251 DEBUG TRAIN Batch 150/4400 loss 20.383959 loss_att 7.681136 loss_ctc 50.023876 loss_ctc_origin 33.656662 loss_ctc0 88.214035 lr 0.00068295 rank 0
2022-08-25 09:42:01,990 DEBUG TRAIN Batch 150/4500 loss 43.417053 loss_att 28.632454 loss_ctc 77.914444 loss_ctc_origin 53.518353 loss_ctc0 134.838654 lr 0.00068291 rank 0
2022-08-25 09:42:31,628 DEBUG TRAIN Batch 150/4600 loss 22.988838 loss_att 16.462774 loss_ctc 38.216316 loss_ctc_origin 30.720669 loss_ctc0 55.706169 lr 0.00068287 rank 0
2022-08-25 09:43:00,663 DEBUG TRAIN Batch 150/4700 loss 17.093300 loss_att 8.116958 loss_ctc 38.038094 loss_ctc_origin 25.300552 loss_ctc0 67.759026 lr 0.00068283 rank 0
2022-08-25 09:43:29,334 DEBUG TRAIN Batch 150/4800 loss 20.282429 loss_att 9.472242 loss_ctc 45.506191 loss_ctc_origin 30.243029 loss_ctc0 81.120232 lr 0.00068279 rank 0
2022-08-25 09:43:58,767 DEBUG TRAIN Batch 150/4900 loss 22.061848 loss_att 9.721376 loss_ctc 50.856277 loss_ctc_origin 33.089897 loss_ctc0 92.311165 lr 0.00068275 rank 0
2022-08-25 09:44:27,783 DEBUG TRAIN Batch 150/5000 loss 33.454330 loss_att 25.247295 loss_ctc 52.604080 loss_ctc_origin 41.042091 loss_ctc0 79.582047 lr 0.00068271 rank 0
2022-08-25 09:44:55,478 DEBUG TRAIN Batch 150/5100 loss 48.382008 loss_att 26.753862 loss_ctc 98.847679 loss_ctc_origin 57.882412 loss_ctc0 194.433289 lr 0.00068267 rank 0
2022-08-25 09:45:24,624 DEBUG TRAIN Batch 150/5200 loss 16.471596 loss_att 8.046556 loss_ctc 36.130020 loss_ctc_origin 23.946198 loss_ctc0 64.558937 lr 0.00068263 rank 0
2022-08-25 09:45:29,790 WARNING NaN or Inf found in input tensor.
2022-08-25 09:45:52,742 DEBUG TRAIN Batch 150/5300 loss 20.956341 loss_att 8.703224 loss_ctc 49.546944 loss_ctc_origin 35.117813 loss_ctc0 83.214920 lr 0.00068259 rank 0
2022-08-25 09:46:21,773 DEBUG TRAIN Batch 150/5400 loss 22.835682 loss_att 9.728749 loss_ctc 53.418518 loss_ctc_origin 33.815178 loss_ctc0 99.159653 lr 0.00068255 rank 0
2022-08-25 09:46:50,505 DEBUG TRAIN Batch 150/5500 loss 45.963837 loss_att 29.179665 loss_ctc 85.126907 loss_ctc_origin 50.591469 loss_ctc0 165.709595 lr 0.00068251 rank 0
2022-08-25 09:47:18,161 DEBUG TRAIN Batch 150/5600 loss 64.911308 loss_att 38.598072 loss_ctc 126.308861 loss_ctc_origin 71.723984 loss_ctc0 253.673569 lr 0.00068247 rank 0
2022-08-25 09:47:40,080 DEBUG CV Batch 150/0 loss 12.053586 loss_att 8.805817 loss_ctc 19.631714 loss_ctc_origin 13.411791 loss_ctc0 34.144871 history loss 11.344552 rank 0
2022-08-25 09:47:50,592 DEBUG CV Batch 150/100 loss 22.012905 loss_att 17.928947 loss_ctc 31.542137 loss_ctc_origin 22.358223 loss_ctc0 52.971268 history loss 26.418724 rank 0
2022-08-25 09:47:59,934 DEBUG CV Batch 150/200 loss 24.842743 loss_att 19.662724 loss_ctc 36.929451 loss_ctc_origin 26.788807 loss_ctc0 60.590942 history loss 27.774980 rank 0
2022-08-25 09:48:09,519 DEBUG CV Batch 150/300 loss 22.668512 loss_att 16.795036 loss_ctc 36.373291 loss_ctc_origin 21.280891 loss_ctc0 71.588898 history loss 26.854316 rank 0
2022-08-25 09:48:19,345 DEBUG CV Batch 150/400 loss 36.753540 loss_att 29.456959 loss_ctc 53.778900 loss_ctc_origin 36.603951 loss_ctc0 93.853775 history loss 25.189990 rank 0
2022-08-25 09:48:29,127 DEBUG CV Batch 150/500 loss 17.567690 loss_att 13.522276 loss_ctc 27.006989 loss_ctc_origin 20.474882 loss_ctc0 42.248566 history loss 24.840629 rank 0
2022-08-25 09:48:38,964 DEBUG CV Batch 150/600 loss 16.986328 loss_att 11.805498 loss_ctc 29.074928 loss_ctc_origin 18.349752 loss_ctc0 54.100334 history loss 24.634315 rank 0
2022-08-25 09:48:48,492 DEBUG CV Batch 150/700 loss 17.889584 loss_att 12.180464 loss_ctc 31.210865 loss_ctc_origin 17.620768 loss_ctc0 62.921089 history loss 24.287193 rank 0
2022-08-25 09:48:58,270 DEBUG CV Batch 150/800 loss 22.564423 loss_att 17.463505 loss_ctc 34.466564 loss_ctc_origin 19.639759 loss_ctc0 69.062439 history loss 24.243952 rank 0
2022-08-25 09:49:08,037 INFO Epoch 150 CV info cv_loss 24.322215520321322
2022-08-25 09:49:08,037 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/150.pt
2022-08-25 09:49:08,477 INFO Epoch 151 TRAIN info lr 0.0006824356847895768
2022-08-25 09:49:08,480 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 09:49:35,954 DEBUG TRAIN Batch 151/0 loss 48.351791 loss_att 31.491348 loss_ctc 87.692825 loss_ctc_origin 60.073898 loss_ctc0 152.136993 lr 0.00068243 rank 0
2022-08-25 09:50:05,439 DEBUG TRAIN Batch 151/100 loss 49.547459 loss_att 26.708464 loss_ctc 102.838440 loss_ctc_origin 52.085480 loss_ctc0 221.262009 lr 0.00068239 rank 0
2022-08-25 09:50:34,362 DEBUG TRAIN Batch 151/200 loss 21.893433 loss_att 13.078656 loss_ctc 42.461243 loss_ctc_origin 31.594057 loss_ctc0 67.818001 lr 0.00068235 rank 0
2022-08-25 09:51:02,493 DEBUG TRAIN Batch 151/300 loss 20.399179 loss_att 9.017357 loss_ctc 46.956764 loss_ctc_origin 31.764666 loss_ctc0 82.404984 lr 0.00068231 rank 0
2022-08-25 09:51:31,859 DEBUG TRAIN Batch 151/400 loss 20.883659 loss_att 8.124084 loss_ctc 50.655998 loss_ctc_origin 31.939341 loss_ctc0 94.328201 lr 0.00068228 rank 0
2022-08-25 09:52:00,745 DEBUG TRAIN Batch 151/500 loss 51.798588 loss_att 32.816986 loss_ctc 96.088989 loss_ctc_origin 59.633484 loss_ctc0 181.151810 lr 0.00068224 rank 0
2022-08-25 09:52:29,807 DEBUG TRAIN Batch 151/600 loss 52.738197 loss_att 26.456926 loss_ctc 114.061157 loss_ctc_origin 59.510601 loss_ctc0 241.345795 lr 0.00068220 rank 0
2022-08-25 09:52:48,637 WARNING NaN or Inf found in input tensor.
2022-08-25 09:52:58,153 DEBUG TRAIN Batch 151/700 loss 20.650898 loss_att 10.224715 loss_ctc 44.978657 loss_ctc_origin 33.584862 loss_ctc0 71.564178 lr 0.00068216 rank 0
2022-08-25 09:53:26,319 DEBUG TRAIN Batch 151/800 loss 17.654139 loss_att 7.876250 loss_ctc 40.469208 loss_ctc_origin 25.799826 loss_ctc0 74.697769 lr 0.00068212 rank 0
2022-08-25 09:53:56,355 DEBUG TRAIN Batch 151/900 loss 20.184130 loss_att 8.322521 loss_ctc 47.861214 loss_ctc_origin 28.465973 loss_ctc0 93.116783 lr 0.00068208 rank 0
2022-08-25 09:54:26,065 DEBUG TRAIN Batch 151/1000 loss 48.157867 loss_att 33.542797 loss_ctc 82.259705 loss_ctc_origin 56.636360 loss_ctc0 142.047516 lr 0.00068204 rank 0
2022-08-25 09:54:54,275 DEBUG TRAIN Batch 151/1100 loss 55.422657 loss_att 31.552778 loss_ctc 111.119034 loss_ctc_origin 70.661232 loss_ctc0 205.520554 lr 0.00068200 rank 0
2022-08-25 09:55:22,418 DEBUG TRAIN Batch 151/1200 loss 20.319576 loss_att 9.974625 loss_ctc 44.457794 loss_ctc_origin 33.084118 loss_ctc0 70.996376 lr 0.00068196 rank 0
2022-08-25 09:55:52,549 DEBUG TRAIN Batch 151/1300 loss 21.317249 loss_att 9.293624 loss_ctc 49.372375 loss_ctc_origin 35.710152 loss_ctc0 81.250893 lr 0.00068192 rank 0
2022-08-25 09:56:21,845 DEBUG TRAIN Batch 151/1400 loss 22.611010 loss_att 9.432926 loss_ctc 53.359871 loss_ctc_origin 35.652260 loss_ctc0 94.677628 lr 0.00068188 rank 0
2022-08-25 09:56:57,907 DEBUG TRAIN Batch 151/1500 loss 42.234737 loss_att 26.636635 loss_ctc 78.630310 loss_ctc_origin 45.556187 loss_ctc0 155.803253 lr 0.00068184 rank 0
2022-08-25 09:57:27,677 DEBUG TRAIN Batch 151/1600 loss 47.198738 loss_att 22.595970 loss_ctc 104.605194 loss_ctc_origin 57.583359 loss_ctc0 214.322800 lr 0.00068180 rank 0
2022-08-25 09:57:55,883 DEBUG TRAIN Batch 151/1700 loss 17.385654 loss_att 9.063967 loss_ctc 36.802925 loss_ctc_origin 24.061424 loss_ctc0 66.533096 lr 0.00068176 rank 0
2022-08-25 09:58:24,750 DEBUG TRAIN Batch 151/1800 loss 18.955656 loss_att 7.603659 loss_ctc 45.443649 loss_ctc_origin 32.485596 loss_ctc0 75.679115 lr 0.00068172 rank 0
2022-08-25 09:58:54,626 DEBUG TRAIN Batch 151/1900 loss 21.843361 loss_att 9.553060 loss_ctc 50.520725 loss_ctc_origin 33.902390 loss_ctc0 89.296837 lr 0.00068168 rank 0
2022-08-25 09:59:24,063 DEBUG TRAIN Batch 151/2000 loss 52.361656 loss_att 35.635612 loss_ctc 91.389084 loss_ctc_origin 55.953880 loss_ctc0 174.071213 lr 0.00068164 rank 0
2022-08-25 09:59:52,055 DEBUG TRAIN Batch 151/2100 loss 53.206001 loss_att 28.699825 loss_ctc 110.387070 loss_ctc_origin 57.438316 loss_ctc0 233.934128 lr 0.00068160 rank 0
2022-08-25 10:00:20,549 DEBUG TRAIN Batch 151/2200 loss 22.242868 loss_att 11.942398 loss_ctc 46.277298 loss_ctc_origin 34.275948 loss_ctc0 74.280457 lr 0.00068156 rank 0
2022-08-25 10:00:50,091 DEBUG TRAIN Batch 151/2300 loss 17.530575 loss_att 7.434914 loss_ctc 41.087112 loss_ctc_origin 26.745920 loss_ctc0 74.549896 lr 0.00068152 rank 0
2022-08-25 10:01:18,740 DEBUG TRAIN Batch 151/2400 loss 22.487743 loss_att 9.791330 loss_ctc 52.112709 loss_ctc_origin 34.304935 loss_ctc0 93.664169 lr 0.00068148 rank 0
2022-08-25 10:01:47,690 DEBUG TRAIN Batch 151/2500 loss 52.016998 loss_att 32.605331 loss_ctc 97.310883 loss_ctc_origin 61.508266 loss_ctc0 180.850296 lr 0.00068144 rank 0
2022-08-25 10:02:15,725 DEBUG TRAIN Batch 151/2600 loss 55.809830 loss_att 35.329632 loss_ctc 103.596954 loss_ctc_origin 61.128330 loss_ctc0 202.690399 lr 0.00068140 rank 0
2022-08-25 10:02:43,353 DEBUG TRAIN Batch 151/2700 loss 18.016088 loss_att 9.175101 loss_ctc 38.645058 loss_ctc_origin 27.428221 loss_ctc0 64.817665 lr 0.00068136 rank 0
2022-08-25 10:03:13,622 DEBUG TRAIN Batch 151/2800 loss 17.868814 loss_att 6.800165 loss_ctc 43.695663 loss_ctc_origin 29.623640 loss_ctc0 76.530380 lr 0.00068132 rank 0
2022-08-25 10:03:31,307 WARNING NaN or Inf found in input tensor.
2022-08-25 10:03:43,052 DEBUG TRAIN Batch 151/2900 loss 20.613207 loss_att 9.360023 loss_ctc 46.870632 loss_ctc_origin 28.054045 loss_ctc0 90.776001 lr 0.00068128 rank 0
2022-08-25 10:04:18,433 DEBUG TRAIN Batch 151/3000 loss 48.883801 loss_att 31.945183 loss_ctc 88.407242 loss_ctc_origin 48.246384 loss_ctc0 182.115906 lr 0.00068125 rank 0
2022-08-25 10:04:47,720 DEBUG TRAIN Batch 151/3100 loss 52.891090 loss_att 29.113400 loss_ctc 108.372360 loss_ctc_origin 59.804379 loss_ctc0 221.697662 lr 0.00068121 rank 0
2022-08-25 10:05:17,060 DEBUG TRAIN Batch 151/3200 loss 20.319244 loss_att 12.263107 loss_ctc 39.116898 loss_ctc_origin 28.455410 loss_ctc0 63.993706 lr 0.00068117 rank 0
2022-08-25 10:05:45,310 DEBUG TRAIN Batch 151/3300 loss 18.436321 loss_att 8.667143 loss_ctc 41.231071 loss_ctc_origin 27.085535 loss_ctc0 74.237320 lr 0.00068113 rank 0
2022-08-25 10:06:14,663 DEBUG TRAIN Batch 151/3400 loss 20.888895 loss_att 8.537447 loss_ctc 49.708939 loss_ctc_origin 31.085670 loss_ctc0 93.163223 lr 0.00068109 rank 0
2022-08-25 10:06:43,978 DEBUG TRAIN Batch 151/3500 loss 33.621437 loss_att 20.643200 loss_ctc 63.903984 loss_ctc_origin 37.658108 loss_ctc0 125.144356 lr 0.00068105 rank 0
2022-08-25 10:07:12,065 DEBUG TRAIN Batch 151/3600 loss 56.412758 loss_att 28.781616 loss_ctc 120.885406 loss_ctc_origin 66.259766 loss_ctc0 248.345215 lr 0.00068101 rank 0
2022-08-25 10:07:40,397 DEBUG TRAIN Batch 151/3700 loss 22.364607 loss_att 12.036214 loss_ctc 46.464191 loss_ctc_origin 33.958988 loss_ctc0 75.642998 lr 0.00068097 rank 0
2022-08-25 10:08:08,853 DEBUG TRAIN Batch 151/3800 loss 21.269516 loss_att 9.812441 loss_ctc 48.002686 loss_ctc_origin 34.829220 loss_ctc0 78.740768 lr 0.00068093 rank 0
2022-08-25 10:08:39,719 DEBUG TRAIN Batch 151/3900 loss 16.891369 loss_att 6.296395 loss_ctc 41.612976 loss_ctc_origin 23.402433 loss_ctc0 84.104248 lr 0.00068089 rank 0
2022-08-25 10:09:08,447 DEBUG TRAIN Batch 151/4000 loss 49.237755 loss_att 30.990696 loss_ctc 91.814224 loss_ctc_origin 57.981525 loss_ctc0 170.757187 lr 0.00068085 rank 0
2022-08-25 10:09:09,110 WARNING NaN or Inf found in input tensor.
2022-08-25 10:09:35,638 DEBUG TRAIN Batch 151/4100 loss 63.154442 loss_att 36.382843 loss_ctc 125.621506 loss_ctc_origin 69.815315 loss_ctc0 255.835938 lr 0.00068081 rank 0
2022-08-25 10:10:06,675 DEBUG TRAIN Batch 151/4200 loss 22.754503 loss_att 11.912522 loss_ctc 48.052460 loss_ctc_origin 35.783253 loss_ctc0 76.680603 lr 0.00068077 rank 0
2022-08-25 10:10:35,619 DEBUG TRAIN Batch 151/4300 loss 18.374788 loss_att 6.686434 loss_ctc 45.647617 loss_ctc_origin 32.673752 loss_ctc0 75.919968 lr 0.00068073 rank 0
2022-08-25 10:11:04,389 DEBUG TRAIN Batch 151/4400 loss 19.115763 loss_att 7.769111 loss_ctc 45.591278 loss_ctc_origin 27.990974 loss_ctc0 86.658661 lr 0.00068069 rank 0
2022-08-25 10:11:37,840 DEBUG TRAIN Batch 151/4500 loss 54.946693 loss_att 35.817356 loss_ctc 99.581818 loss_ctc_origin 67.105423 loss_ctc0 175.360046 lr 0.00068065 rank 0
2022-08-25 10:12:06,556 DEBUG TRAIN Batch 151/4600 loss 59.155540 loss_att 32.549622 loss_ctc 121.236023 loss_ctc_origin 63.425888 loss_ctc0 256.126343 lr 0.00068061 rank 0
2022-08-25 10:12:35,013 DEBUG TRAIN Batch 151/4700 loss 21.581116 loss_att 12.308054 loss_ctc 43.218254 loss_ctc_origin 34.293053 loss_ctc0 64.043716 lr 0.00068057 rank 0
2022-08-25 10:13:03,135 DEBUG TRAIN Batch 151/4800 loss 17.390736 loss_att 6.984765 loss_ctc 41.671333 loss_ctc_origin 28.364826 loss_ctc0 72.719856 lr 0.00068054 rank 0
2022-08-25 10:13:32,190 DEBUG TRAIN Batch 151/4900 loss 19.571051 loss_att 7.351708 loss_ctc 48.082848 loss_ctc_origin 28.619801 loss_ctc0 93.496628 lr 0.00068050 rank 0
2022-08-25 10:14:01,283 DEBUG TRAIN Batch 151/5000 loss 53.075634 loss_att 36.161530 loss_ctc 92.541878 loss_ctc_origin 56.863281 loss_ctc0 175.791931 lr 0.00068046 rank 0
2022-08-25 10:14:29,589 DEBUG TRAIN Batch 151/5100 loss 62.967384 loss_att 36.527351 loss_ctc 124.660797 loss_ctc_origin 63.255806 loss_ctc0 267.939087 lr 0.00068042 rank 0
2022-08-25 10:14:57,026 WARNING NaN or Inf found in input tensor.
2022-08-25 10:14:58,655 DEBUG TRAIN Batch 151/5200 loss 18.512934 loss_att 10.723039 loss_ctc 36.689354 loss_ctc_origin 23.756609 loss_ctc0 66.865768 lr 0.00068038 rank 0
2022-08-25 10:15:04,115 WARNING NaN or Inf found in input tensor.
2022-08-25 10:15:26,872 DEBUG TRAIN Batch 151/5300 loss 22.211763 loss_att 8.471014 loss_ctc 54.273506 loss_ctc_origin 40.449028 loss_ctc0 86.530617 lr 0.00068034 rank 0
2022-08-25 10:15:51,449 WARNING NaN or Inf found in input tensor.
2022-08-25 10:15:55,680 DEBUG TRAIN Batch 151/5400 loss 22.630297 loss_att 9.737006 loss_ctc 52.714642 loss_ctc_origin 34.271301 loss_ctc0 95.749100 lr 0.00068030 rank 0
2022-08-25 10:16:23,944 DEBUG TRAIN Batch 151/5500 loss 47.876629 loss_att 31.488247 loss_ctc 86.116180 loss_ctc_origin 49.566772 loss_ctc0 171.398132 lr 0.00068026 rank 0
2022-08-25 10:16:45,392 WARNING NaN or Inf found in input tensor.
2022-08-25 10:16:52,247 DEBUG TRAIN Batch 151/5600 loss 56.952789 loss_att 30.306810 loss_ctc 119.126740 loss_ctc_origin 59.232162 loss_ctc0 258.880737 lr 0.00068022 rank 0
2022-08-25 10:17:13,846 DEBUG CV Batch 151/0 loss 11.293081 loss_att 8.091934 loss_ctc 18.762424 loss_ctc_origin 12.470543 loss_ctc0 33.443478 history loss 10.628782 rank 0
2022-08-25 10:17:24,020 DEBUG CV Batch 151/100 loss 19.958048 loss_att 15.770896 loss_ctc 29.728067 loss_ctc_origin 19.603308 loss_ctc0 53.352509 history loss 26.081231 rank 0
2022-08-25 10:17:32,958 DEBUG CV Batch 151/200 loss 23.948521 loss_att 18.488205 loss_ctc 36.689262 loss_ctc_origin 26.273289 loss_ctc0 60.993195 history loss 27.490802 rank 0
2022-08-25 10:17:43,019 DEBUG CV Batch 151/300 loss 23.278706 loss_att 17.657007 loss_ctc 36.395996 loss_ctc_origin 21.030594 loss_ctc0 72.248596 history loss 26.590588 rank 0
2022-08-25 10:17:53,549 DEBUG CV Batch 151/400 loss 37.545986 loss_att 30.414755 loss_ctc 54.185524 loss_ctc_origin 36.841763 loss_ctc0 94.654297 history loss 24.996593 rank 0
2022-08-25 10:18:02,576 DEBUG CV Batch 151/500 loss 16.835197 loss_att 12.426836 loss_ctc 27.121372 loss_ctc_origin 20.458340 loss_ctc0 42.668442 history loss 24.696576 rank 0
2022-08-25 10:18:12,073 DEBUG CV Batch 151/600 loss 16.837391 loss_att 11.465464 loss_ctc 29.371883 loss_ctc_origin 19.096043 loss_ctc0 53.348846 history loss 24.521979 rank 0
2022-08-25 10:18:21,816 DEBUG CV Batch 151/700 loss 18.065800 loss_att 12.140983 loss_ctc 31.890369 loss_ctc_origin 18.312157 loss_ctc0 63.572868 history loss 24.183544 rank 0
2022-08-25 10:18:32,103 DEBUG CV Batch 151/800 loss 22.595787 loss_att 18.014397 loss_ctc 33.285698 loss_ctc_origin 18.167479 loss_ctc0 68.561546 history loss 24.152385 rank 0
2022-08-25 10:18:41,758 INFO Epoch 151 CV info cv_loss 24.25839901549573
2022-08-25 10:18:41,758 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/151.pt
2022-08-25 10:18:42,210 INFO Epoch 152 TRAIN info lr 0.0006801871261732969
2022-08-25 10:18:42,214 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 10:19:09,357 DEBUG TRAIN Batch 152/0 loss 48.447529 loss_att 30.949324 loss_ctc 89.276672 loss_ctc_origin 50.606182 loss_ctc0 179.507812 lr 0.00068019 rank 0
2022-08-25 10:19:38,788 DEBUG TRAIN Batch 152/100 loss 60.113159 loss_att 34.635826 loss_ctc 119.560272 loss_ctc_origin 67.151100 loss_ctc0 241.848328 lr 0.00068015 rank 0
2022-08-25 10:20:05,915 WARNING NaN or Inf found in input tensor.
2022-08-25 10:20:07,548 DEBUG TRAIN Batch 152/200 loss 21.071053 loss_att 12.076092 loss_ctc 42.059296 loss_ctc_origin 32.377228 loss_ctc0 64.650780 lr 0.00068011 rank 0
2022-08-25 10:20:36,070 DEBUG TRAIN Batch 152/300 loss 22.473324 loss_att 10.579386 loss_ctc 50.225842 loss_ctc_origin 34.562965 loss_ctc0 86.772552 lr 0.00068007 rank 0
2022-08-25 10:21:04,714 DEBUG TRAIN Batch 152/400 loss 27.221992 loss_att 12.062164 loss_ctc 62.594921 loss_ctc_origin 43.370346 loss_ctc0 107.452255 lr 0.00068003 rank 0
2022-08-25 10:21:34,228 DEBUG TRAIN Batch 152/500 loss 43.652115 loss_att 29.865498 loss_ctc 75.820885 loss_ctc_origin 43.129784 loss_ctc0 152.100128 lr 0.00067999 rank 0
2022-08-25 10:22:03,217 DEBUG TRAIN Batch 152/600 loss 50.612827 loss_att 23.876179 loss_ctc 112.998329 loss_ctc_origin 57.889175 loss_ctc0 241.586334 lr 0.00067995 rank 0
2022-08-25 10:22:32,562 DEBUG TRAIN Batch 152/700 loss 20.295406 loss_att 10.522667 loss_ctc 43.098465 loss_ctc_origin 32.673534 loss_ctc0 67.423302 lr 0.00067991 rank 0
2022-08-25 10:22:38,024 WARNING NaN or Inf found in input tensor.
2022-08-25 10:23:01,441 DEBUG TRAIN Batch 152/800 loss 19.711967 loss_att 8.552495 loss_ctc 45.750732 loss_ctc_origin 31.213087 loss_ctc0 79.671898 lr 0.00067987 rank 0
2022-08-25 10:23:30,170 DEBUG TRAIN Batch 152/900 loss 21.664593 loss_att 9.666985 loss_ctc 49.659012 loss_ctc_origin 31.894218 loss_ctc0 91.110199 lr 0.00067983 rank 0
2022-08-25 10:23:58,636 DEBUG TRAIN Batch 152/1000 loss 44.672943 loss_att 29.475473 loss_ctc 80.133705 loss_ctc_origin 49.644123 loss_ctc0 151.276062 lr 0.00067979 rank 0
2022-08-25 10:24:27,838 DEBUG TRAIN Batch 152/1100 loss 53.286797 loss_att 29.386061 loss_ctc 109.055183 loss_ctc_origin 58.395004 loss_ctc0 227.262268 lr 0.00067975 rank 0
2022-08-25 10:24:56,366 DEBUG TRAIN Batch 152/1200 loss 22.612995 loss_att 13.631104 loss_ctc 43.570740 loss_ctc_origin 33.802017 loss_ctc0 66.364418 lr 0.00067971 rank 0
2022-08-25 10:25:24,323 DEBUG TRAIN Batch 152/1300 loss 18.719139 loss_att 8.030968 loss_ctc 43.658199 loss_ctc_origin 29.066757 loss_ctc0 77.704895 lr 0.00067967 rank 0
2022-08-25 10:25:51,645 DEBUG TRAIN Batch 152/1400 loss 19.122921 loss_att 6.754299 loss_ctc 47.983036 loss_ctc_origin 30.770996 loss_ctc0 88.144455 lr 0.00067964 rank 0
2022-08-25 10:26:28,367 DEBUG TRAIN Batch 152/1500 loss 37.133469 loss_att 23.008450 loss_ctc 70.091835 loss_ctc_origin 38.030258 loss_ctc0 144.902176 lr 0.00067960 rank 0
2022-08-25 10:26:57,514 DEBUG TRAIN Batch 152/1600 loss 57.084393 loss_att 32.888401 loss_ctc 113.541702 loss_ctc_origin 61.558865 loss_ctc0 234.834961 lr 0.00067956 rank 0
2022-08-25 10:27:24,650 WARNING NaN or Inf found in input tensor.
2022-08-25 10:27:26,236 DEBUG TRAIN Batch 152/1700 loss 16.934145 loss_att 8.341311 loss_ctc 36.984093 loss_ctc_origin 23.346016 loss_ctc0 68.806267 lr 0.00067952 rank 0
2022-08-25 10:27:55,114 DEBUG TRAIN Batch 152/1800 loss 18.203959 loss_att 6.944505 loss_ctc 44.476013 loss_ctc_origin 28.891541 loss_ctc0 80.839790 lr 0.00067948 rank 0
2022-08-25 10:28:23,923 DEBUG TRAIN Batch 152/1900 loss 23.093872 loss_att 9.116274 loss_ctc 55.708267 loss_ctc_origin 37.628082 loss_ctc0 97.895355 lr 0.00067944 rank 0
2022-08-25 10:28:53,347 DEBUG TRAIN Batch 152/2000 loss 44.249428 loss_att 28.724264 loss_ctc 80.474808 loss_ctc_origin 51.165565 loss_ctc0 148.863037 lr 0.00067940 rank 0
2022-08-25 10:29:01,167 WARNING NaN or Inf found in input tensor.
2022-08-25 10:29:21,599 DEBUG TRAIN Batch 152/2100 loss 58.535637 loss_att 33.561481 loss_ctc 116.808662 loss_ctc_origin 63.892921 loss_ctc0 240.278717 lr 0.00067936 rank 0
2022-08-25 10:29:50,297 DEBUG TRAIN Batch 152/2200 loss 21.058565 loss_att 11.349707 loss_ctc 43.712566 loss_ctc_origin 31.930685 loss_ctc0 71.203621 lr 0.00067932 rank 0
2022-08-25 10:30:18,811 DEBUG TRAIN Batch 152/2300 loss 17.319796 loss_att 6.837494 loss_ctc 41.778500 loss_ctc_origin 26.164930 loss_ctc0 78.210159 lr 0.00067928 rank 0
2022-08-25 10:30:47,999 DEBUG TRAIN Batch 152/2400 loss 20.957195 loss_att 9.263597 loss_ctc 48.242260 loss_ctc_origin 30.699150 loss_ctc0 89.176178 lr 0.00067924 rank 0
2022-08-25 10:31:16,896 DEBUG TRAIN Batch 152/2500 loss 47.596596 loss_att 29.162212 loss_ctc 90.610161 loss_ctc_origin 52.472507 loss_ctc0 179.598007 lr 0.00067920 rank 0
2022-08-25 10:31:31,672 WARNING NaN or Inf found in input tensor.
2022-08-25 10:31:45,918 DEBUG TRAIN Batch 152/2600 loss 52.383701 loss_att 27.795967 loss_ctc 109.755074 loss_ctc_origin 60.324020 loss_ctc0 225.094193 lr 0.00067917 rank 0
2022-08-25 10:32:13,511 DEBUG TRAIN Batch 152/2700 loss 25.295141 loss_att 14.807460 loss_ctc 49.766396 loss_ctc_origin 40.117271 loss_ctc0 72.281021 lr 0.00067913 rank 0
2022-08-25 10:32:42,594 DEBUG TRAIN Batch 152/2800 loss 19.317951 loss_att 8.415365 loss_ctc 44.757317 loss_ctc_origin 31.843653 loss_ctc0 74.889191 lr 0.00067909 rank 0
2022-08-25 10:33:11,117 DEBUG TRAIN Batch 152/2900 loss 21.892202 loss_att 9.496120 loss_ctc 50.816391 loss_ctc_origin 32.214016 loss_ctc0 94.221924 lr 0.00067905 rank 0
2022-08-25 10:33:46,576 DEBUG TRAIN Batch 152/3000 loss 46.734772 loss_att 27.189013 loss_ctc 92.341545 loss_ctc_origin 56.394203 loss_ctc0 176.218674 lr 0.00067901 rank 0
2022-08-25 10:34:15,562 DEBUG TRAIN Batch 152/3100 loss 58.217468 loss_att 32.668087 loss_ctc 117.832687 loss_ctc_origin 62.953487 loss_ctc0 245.884125 lr 0.00067897 rank 0
2022-08-25 10:34:43,836 DEBUG TRAIN Batch 152/3200 loss 21.525349 loss_att 13.018370 loss_ctc 41.374962 loss_ctc_origin 31.045860 loss_ctc0 65.476196 lr 0.00067893 rank 0
2022-08-25 10:35:12,309 DEBUG TRAIN Batch 152/3300 loss 17.286274 loss_att 6.930389 loss_ctc 41.450005 loss_ctc_origin 24.084620 loss_ctc0 81.969238 lr 0.00067889 rank 0
2022-08-25 10:35:36,496 WARNING NaN or Inf found in input tensor.
2022-08-25 10:35:40,800 DEBUG TRAIN Batch 152/3400 loss 26.654823 loss_att 10.924330 loss_ctc 63.359306 loss_ctc_origin 47.729050 loss_ctc0 99.829895 lr 0.00067885 rank 0
2022-08-25 10:36:10,992 DEBUG TRAIN Batch 152/3500 loss 44.724884 loss_att 25.912163 loss_ctc 88.621223 loss_ctc_origin 55.413277 loss_ctc0 166.106430 lr 0.00067881 rank 0
2022-08-25 10:36:39,070 DEBUG TRAIN Batch 152/3600 loss 54.708862 loss_att 29.513508 loss_ctc 113.498024 loss_ctc_origin 66.181488 loss_ctc0 223.903275 lr 0.00067877 rank 0
2022-08-25 10:37:06,721 WARNING NaN or Inf found in input tensor.
2022-08-25 10:37:08,355 DEBUG TRAIN Batch 152/3700 loss 18.013908 loss_att 10.120049 loss_ctc 36.432911 loss_ctc_origin 26.713238 loss_ctc0 59.112144 lr 0.00067873 rank 0
2022-08-25 10:37:36,751 DEBUG TRAIN Batch 152/3800 loss 18.645781 loss_att 7.440090 loss_ctc 44.792389 loss_ctc_origin 29.732941 loss_ctc0 79.931091 lr 0.00067870 rank 0
2022-08-25 10:38:01,262 WARNING NaN or Inf found in input tensor.
2022-08-25 10:38:05,464 DEBUG TRAIN Batch 152/3900 loss 21.988831 loss_att 9.806459 loss_ctc 50.414360 loss_ctc_origin 32.583740 loss_ctc0 92.019127 lr 0.00067866 rank 0
2022-08-25 10:38:34,187 DEBUG TRAIN Batch 152/4000 loss 45.416122 loss_att 28.306450 loss_ctc 85.338684 loss_ctc_origin 55.421684 loss_ctc0 155.145020 lr 0.00067862 rank 0
2022-08-25 10:39:02,439 DEBUG TRAIN Batch 152/4100 loss 60.000801 loss_att 34.161118 loss_ctc 120.293381 loss_ctc_origin 62.106445 loss_ctc0 256.062897 lr 0.00067858 rank 0
2022-08-25 10:39:30,675 DEBUG TRAIN Batch 152/4200 loss 19.205954 loss_att 8.722660 loss_ctc 43.666969 loss_ctc_origin 30.943062 loss_ctc0 73.356079 lr 0.00067854 rank 0
2022-08-25 10:40:00,379 DEBUG TRAIN Batch 152/4300 loss 21.513090 loss_att 8.571221 loss_ctc 51.710781 loss_ctc_origin 37.175117 loss_ctc0 85.627327 lr 0.00067850 rank 0
2022-08-25 10:40:31,300 DEBUG TRAIN Batch 152/4400 loss 23.517260 loss_att 10.861548 loss_ctc 53.047253 loss_ctc_origin 35.959023 loss_ctc0 92.919785 lr 0.00067846 rank 0
2022-08-25 10:41:04,208 DEBUG TRAIN Batch 152/4500 loss 45.800751 loss_att 29.396893 loss_ctc 84.076424 loss_ctc_origin 51.827415 loss_ctc0 159.324112 lr 0.00067842 rank 0
2022-08-25 10:41:19,407 WARNING NaN or Inf found in input tensor.
2022-08-25 10:41:31,857 DEBUG TRAIN Batch 152/4600 loss 52.036118 loss_att 26.714928 loss_ctc 111.118881 loss_ctc_origin 62.104870 loss_ctc0 225.484894 lr 0.00067838 rank 0
2022-08-25 10:42:00,036 DEBUG TRAIN Batch 152/4700 loss 20.805206 loss_att 11.310238 loss_ctc 42.960129 loss_ctc_origin 31.476034 loss_ctc0 69.756348 lr 0.00067834 rank 0
2022-08-25 10:42:28,157 DEBUG TRAIN Batch 152/4800 loss 22.728067 loss_att 10.325897 loss_ctc 51.666466 loss_ctc_origin 38.370831 loss_ctc0 82.689606 lr 0.00067831 rank 0
2022-08-25 10:42:52,156 WARNING NaN or Inf found in input tensor.
2022-08-25 10:42:57,270 DEBUG TRAIN Batch 152/4900 loss 24.142792 loss_att 10.433321 loss_ctc 56.131550 loss_ctc_origin 37.611065 loss_ctc0 99.346008 lr 0.00067827 rank 0
2022-08-25 10:43:24,805 DEBUG TRAIN Batch 152/5000 loss 45.186401 loss_att 29.513361 loss_ctc 81.756821 loss_ctc_origin 52.462360 loss_ctc0 150.110565 lr 0.00067823 rank 0
2022-08-25 10:43:52,663 DEBUG TRAIN Batch 152/5100 loss 56.999443 loss_att 30.481310 loss_ctc 118.875076 loss_ctc_origin 59.865349 loss_ctc0 256.564453 lr 0.00067819 rank 0
2022-08-25 10:44:21,269 DEBUG TRAIN Batch 152/5200 loss 22.308167 loss_att 12.317486 loss_ctc 45.619755 loss_ctc_origin 37.748230 loss_ctc0 63.986641 lr 0.00067815 rank 0
2022-08-25 10:44:49,869 DEBUG TRAIN Batch 152/5300 loss 18.313807 loss_att 7.308596 loss_ctc 43.992630 loss_ctc_origin 28.958031 loss_ctc0 79.073364 lr 0.00067811 rank 0
2022-08-25 10:45:18,972 DEBUG TRAIN Batch 152/5400 loss 20.087809 loss_att 7.837512 loss_ctc 48.671833 loss_ctc_origin 29.020195 loss_ctc0 94.525650 lr 0.00067807 rank 0
2022-08-25 10:45:47,724 DEBUG TRAIN Batch 152/5500 loss 51.430809 loss_att 34.325764 loss_ctc 91.342575 loss_ctc_origin 61.320732 loss_ctc0 161.393524 lr 0.00067803 rank 0
2022-08-25 10:46:16,362 DEBUG TRAIN Batch 152/5600 loss 53.137329 loss_att 28.491001 loss_ctc 110.645416 loss_ctc_origin 63.858376 loss_ctc0 219.815155 lr 0.00067799 rank 0
2022-08-25 10:46:39,783 DEBUG CV Batch 152/0 loss 11.646572 loss_att 8.379665 loss_ctc 19.269356 loss_ctc_origin 12.894182 loss_ctc0 34.144756 history loss 10.961480 rank 0
2022-08-25 10:46:50,726 DEBUG CV Batch 152/100 loss 21.054855 loss_att 17.101994 loss_ctc 30.278202 loss_ctc_origin 20.294645 loss_ctc0 53.573166 history loss 26.385862 rank 0
2022-08-25 10:47:00,275 DEBUG CV Batch 152/200 loss 25.585512 loss_att 19.933636 loss_ctc 38.773224 loss_ctc_origin 29.116783 loss_ctc0 61.304924 history loss 27.665964 rank 0
2022-08-25 10:47:10,744 DEBUG CV Batch 152/300 loss 22.985495 loss_att 17.589813 loss_ctc 35.575417 loss_ctc_origin 19.898615 loss_ctc0 72.154617 history loss 26.762796 rank 0
2022-08-25 10:47:21,812 DEBUG CV Batch 152/400 loss 38.130878 loss_att 30.801031 loss_ctc 55.233849 loss_ctc_origin 38.285019 loss_ctc0 94.781113 history loss 25.133387 rank 0
2022-08-25 10:47:32,816 DEBUG CV Batch 152/500 loss 17.166674 loss_att 13.015207 loss_ctc 26.853428 loss_ctc_origin 20.001003 loss_ctc0 42.842422 history loss 24.809139 rank 0
2022-08-25 10:47:44,014 DEBUG CV Batch 152/600 loss 16.773884 loss_att 11.386288 loss_ctc 29.344940 loss_ctc_origin 18.842432 loss_ctc0 53.850792 history loss 24.631659 rank 0
2022-08-25 10:47:54,769 DEBUG CV Batch 152/700 loss 18.388996 loss_att 12.490707 loss_ctc 32.151665 loss_ctc_origin 18.530739 loss_ctc0 63.933823 history loss 24.292104 rank 0
2022-08-25 10:48:05,790 DEBUG CV Batch 152/800 loss 21.683111 loss_att 17.014009 loss_ctc 32.577682 loss_ctc_origin 16.670406 loss_ctc0 69.694664 history loss 24.244598 rank 0
2022-08-25 10:48:16,386 INFO Epoch 152 CV info cv_loss 24.339613819634863
2022-08-25 10:48:16,386 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/152.pt
2022-08-25 10:48:16,850 INFO Epoch 153 TRAIN info lr 0.0006779606484280923
2022-08-25 10:48:16,854 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 10:48:44,715 DEBUG TRAIN Batch 153/0 loss 44.370491 loss_att 26.424055 loss_ctc 86.245514 loss_ctc_origin 50.923576 loss_ctc0 168.663361 lr 0.00067796 rank 0
2022-08-25 10:48:45,467 WARNING NaN or Inf found in input tensor.
2022-08-25 10:49:13,668 DEBUG TRAIN Batch 153/100 loss 54.824654 loss_att 33.015709 loss_ctc 105.712181 loss_ctc_origin 57.223122 loss_ctc0 218.853317 lr 0.00067792 rank 0
2022-08-25 10:49:41,908 DEBUG TRAIN Batch 153/200 loss 16.759621 loss_att 8.223305 loss_ctc 36.677689 loss_ctc_origin 25.022043 loss_ctc0 63.874199 lr 0.00067788 rank 0
2022-08-25 10:50:11,287 DEBUG TRAIN Batch 153/300 loss 16.483438 loss_att 6.853415 loss_ctc 38.953495 loss_ctc_origin 26.514292 loss_ctc0 67.978302 lr 0.00067784 rank 0
2022-08-25 10:50:38,603 DEBUG TRAIN Batch 153/400 loss 19.567686 loss_att 7.765065 loss_ctc 47.107132 loss_ctc_origin 27.850796 loss_ctc0 92.038582 lr 0.00067780 rank 0
2022-08-25 10:51:08,038 DEBUG TRAIN Batch 153/500 loss 45.174587 loss_att 29.070602 loss_ctc 82.750549 loss_ctc_origin 51.457275 loss_ctc0 155.768188 lr 0.00067776 rank 0
2022-08-25 10:51:35,474 DEBUG TRAIN Batch 153/600 loss 49.218079 loss_att 25.450823 loss_ctc 104.675003 loss_ctc_origin 49.398911 loss_ctc0 233.652557 lr 0.00067773 rank 0
2022-08-25 10:52:04,172 DEBUG TRAIN Batch 153/700 loss 20.842747 loss_att 9.052493 loss_ctc 48.353340 loss_ctc_origin 36.168839 loss_ctc0 76.783844 lr 0.00067769 rank 0
2022-08-25 10:52:32,341 DEBUG TRAIN Batch 153/800 loss 18.294960 loss_att 8.075123 loss_ctc 42.141247 loss_ctc_origin 26.927372 loss_ctc0 77.640289 lr 0.00067765 rank 0
2022-08-25 10:53:01,341 DEBUG TRAIN Batch 153/900 loss 19.181534 loss_att 7.657985 loss_ctc 46.069817 loss_ctc_origin 27.301998 loss_ctc0 89.861389 lr 0.00067761 rank 0
2022-08-25 10:53:29,718 DEBUG TRAIN Batch 153/1000 loss 40.255405 loss_att 23.541763 loss_ctc 79.253899 loss_ctc_origin 46.276474 loss_ctc0 156.201218 lr 0.00067757 rank 0
2022-08-25 10:53:57,991 DEBUG TRAIN Batch 153/1100 loss 53.526314 loss_att 30.395884 loss_ctc 107.497307 loss_ctc_origin 54.465157 loss_ctc0 231.238968 lr 0.00067753 rank 0
2022-08-25 10:54:25,673 DEBUG TRAIN Batch 153/1200 loss 21.415829 loss_att 10.280226 loss_ctc 47.398903 loss_ctc_origin 36.679607 loss_ctc0 72.410599 lr 0.00067749 rank 0
2022-08-25 10:54:55,568 DEBUG TRAIN Batch 153/1300 loss 18.079159 loss_att 8.139153 loss_ctc 41.272503 loss_ctc_origin 26.523422 loss_ctc0 75.687027 lr 0.00067745 rank 0
2022-08-25 10:55:23,164 DEBUG TRAIN Batch 153/1400 loss 21.989607 loss_att 8.937490 loss_ctc 52.444542 loss_ctc_origin 32.937042 loss_ctc0 97.962044 lr 0.00067741 rank 0
2022-08-25 10:55:57,713 DEBUG TRAIN Batch 153/1500 loss 37.982586 loss_att 26.997496 loss_ctc 63.614464 loss_ctc_origin 37.774570 loss_ctc0 123.907547 lr 0.00067738 rank 0
2022-08-25 10:56:26,878 DEBUG TRAIN Batch 153/1600 loss 52.791336 loss_att 26.465078 loss_ctc 114.219269 loss_ctc_origin 61.274509 loss_ctc0 237.757050 lr 0.00067734 rank 0
2022-08-25 10:56:55,766 DEBUG TRAIN Batch 153/1700 loss 18.018423 loss_att 8.151841 loss_ctc 41.040447 loss_ctc_origin 29.522572 loss_ctc0 67.915489 lr 0.00067730 rank 0
2022-08-25 10:57:24,510 DEBUG TRAIN Batch 153/1800 loss 19.908466 loss_att 8.910480 loss_ctc 45.570435 loss_ctc_origin 29.989994 loss_ctc0 81.924789 lr 0.00067726 rank 0
2022-08-25 10:57:52,771 DEBUG TRAIN Batch 153/1900 loss 23.274155 loss_att 10.243410 loss_ctc 53.679222 loss_ctc_origin 36.128410 loss_ctc0 94.631119 lr 0.00067722 rank 0
2022-08-25 10:58:21,764 DEBUG TRAIN Batch 153/2000 loss 41.665565 loss_att 25.869259 loss_ctc 78.523621 loss_ctc_origin 46.653831 loss_ctc0 152.886475 lr 0.00067718 rank 0
2022-08-25 10:58:49,717 DEBUG TRAIN Batch 153/2100 loss 45.601025 loss_att 25.338757 loss_ctc 92.879646 loss_ctc_origin 49.334267 loss_ctc0 194.485535 lr 0.00067714 rank 0
2022-08-25 10:59:17,737 DEBUG TRAIN Batch 153/2200 loss 17.741903 loss_att 10.620613 loss_ctc 34.358246 loss_ctc_origin 24.608040 loss_ctc0 57.108719 lr 0.00067710 rank 0
2022-08-25 10:59:45,957 DEBUG TRAIN Batch 153/2300 loss 22.855869 loss_att 9.193152 loss_ctc 54.735542 loss_ctc_origin 39.049408 loss_ctc0 91.336525 lr 0.00067706 rank 0
2022-08-25 11:00:15,022 DEBUG TRAIN Batch 153/2400 loss 18.491409 loss_att 7.082548 loss_ctc 45.112083 loss_ctc_origin 27.524239 loss_ctc0 86.150391 lr 0.00067703 rank 0
2022-08-25 11:00:43,394 DEBUG TRAIN Batch 153/2500 loss 40.390694 loss_att 25.180380 loss_ctc 75.881424 loss_ctc_origin 44.333321 loss_ctc0 149.493652 lr 0.00067699 rank 0
2022-08-25 11:01:11,020 DEBUG TRAIN Batch 153/2600 loss 53.819057 loss_att 29.928726 loss_ctc 109.563156 loss_ctc_origin 64.864410 loss_ctc0 213.860245 lr 0.00067695 rank 0
2022-08-25 11:01:41,100 DEBUG TRAIN Batch 153/2700 loss 19.449860 loss_att 11.422200 loss_ctc 38.181061 loss_ctc_origin 26.772266 loss_ctc0 64.801590 lr 0.00067691 rank 0
2022-08-25 11:01:59,119 WARNING NaN or Inf found in input tensor.
2022-08-25 11:02:09,002 DEBUG TRAIN Batch 153/2800 loss 20.374540 loss_att 8.027334 loss_ctc 49.184685 loss_ctc_origin 36.077629 loss_ctc0 79.767822 lr 0.00067687 rank 0
2022-08-25 11:02:37,663 DEBUG TRAIN Batch 153/2900 loss 23.526665 loss_att 10.950942 loss_ctc 52.870018 loss_ctc_origin 35.454193 loss_ctc0 93.506950 lr 0.00067683 rank 0
2022-08-25 11:03:12,627 DEBUG TRAIN Batch 153/3000 loss 43.038681 loss_att 27.648748 loss_ctc 78.948517 loss_ctc_origin 52.991596 loss_ctc0 139.514679 lr 0.00067679 rank 0
2022-08-25 11:03:41,149 DEBUG TRAIN Batch 153/3100 loss 50.053341 loss_att 25.086704 loss_ctc 108.308830 loss_ctc_origin 55.182846 loss_ctc0 232.269455 lr 0.00067675 rank 0
2022-08-25 11:04:09,455 DEBUG TRAIN Batch 153/3200 loss 21.661560 loss_att 10.955989 loss_ctc 46.641224 loss_ctc_origin 35.074947 loss_ctc0 73.629196 lr 0.00067672 rank 0
2022-08-25 11:04:38,447 DEBUG TRAIN Batch 153/3300 loss 20.918280 loss_att 8.534103 loss_ctc 49.814690 loss_ctc_origin 36.595261 loss_ctc0 80.660027 lr 0.00067668 rank 0
2022-08-25 11:05:07,940 DEBUG TRAIN Batch 153/3400 loss 22.715786 loss_att 8.674014 loss_ctc 55.479919 loss_ctc_origin 36.000156 loss_ctc0 100.932701 lr 0.00067664 rank 0
2022-08-25 11:05:37,721 DEBUG TRAIN Batch 153/3500 loss 41.478844 loss_att 26.990959 loss_ctc 75.283905 loss_ctc_origin 45.664722 loss_ctc0 144.395325 lr 0.00067660 rank 0
2022-08-25 11:06:05,783 DEBUG TRAIN Batch 153/3600 loss 56.440430 loss_att 32.426674 loss_ctc 112.472527 loss_ctc_origin 68.241089 loss_ctc0 215.679199 lr 0.00067656 rank 0
2022-08-25 11:06:33,018 DEBUG TRAIN Batch 153/3700 loss 17.968012 loss_att 10.170919 loss_ctc 36.161228 loss_ctc_origin 26.106457 loss_ctc0 59.622360 lr 0.00067652 rank 0
2022-08-25 11:06:38,231 WARNING NaN or Inf found in input tensor.
2022-08-25 11:07:02,007 DEBUG TRAIN Batch 153/3800 loss 19.791138 loss_att 8.121606 loss_ctc 47.020046 loss_ctc_origin 30.921188 loss_ctc0 84.584045 lr 0.00067648 rank 0
2022-08-25 11:07:30,625 DEBUG TRAIN Batch 153/3900 loss 23.926441 loss_att 9.293948 loss_ctc 58.068924 loss_ctc_origin 42.701973 loss_ctc0 93.925148 lr 0.00067645 rank 0
2022-08-25 11:07:58,678 DEBUG TRAIN Batch 153/4000 loss 41.057533 loss_att 26.257566 loss_ctc 75.590782 loss_ctc_origin 47.798134 loss_ctc0 140.440292 lr 0.00067641 rank 0
2022-08-25 11:08:25,673 DEBUG TRAIN Batch 153/4100 loss 54.463104 loss_att 31.918482 loss_ctc 107.067215 loss_ctc_origin 60.031380 loss_ctc0 216.817490 lr 0.00067637 rank 0
2022-08-25 11:08:53,757 DEBUG TRAIN Batch 153/4200 loss 21.138947 loss_att 12.252906 loss_ctc 41.873043 loss_ctc_origin 30.885565 loss_ctc0 67.510490 lr 0.00067633 rank 0
2022-08-25 11:09:22,408 DEBUG TRAIN Batch 153/4300 loss 18.847685 loss_att 7.379923 loss_ctc 45.605793 loss_ctc_origin 32.274261 loss_ctc0 76.712700 lr 0.00067629 rank 0
2022-08-25 11:09:50,116 DEBUG TRAIN Batch 153/4400 loss 21.382673 loss_att 8.714657 loss_ctc 50.941376 loss_ctc_origin 32.019104 loss_ctc0 95.093338 lr 0.00067625 rank 0
2022-08-25 11:10:23,942 DEBUG TRAIN Batch 153/4500 loss 52.759396 loss_att 34.318634 loss_ctc 95.787842 loss_ctc_origin 62.839283 loss_ctc0 172.667786 lr 0.00067621 rank 0
2022-08-25 11:10:51,928 DEBUG TRAIN Batch 153/4600 loss 53.906197 loss_att 26.231434 loss_ctc 118.480637 loss_ctc_origin 60.536148 loss_ctc0 253.684448 lr 0.00067617 rank 0
2022-08-25 11:11:19,878 DEBUG TRAIN Batch 153/4700 loss 17.453354 loss_att 9.391886 loss_ctc 36.263443 loss_ctc_origin 24.865761 loss_ctc0 62.858025 lr 0.00067614 rank 0
2022-08-25 11:11:47,812 DEBUG TRAIN Batch 153/4800 loss 22.903675 loss_att 10.544706 loss_ctc 51.741264 loss_ctc_origin 37.378563 loss_ctc0 85.254227 lr 0.00067610 rank 0
2022-08-25 11:12:15,605 DEBUG TRAIN Batch 153/4900 loss 21.299299 loss_att 8.703278 loss_ctc 50.690018 loss_ctc_origin 31.691486 loss_ctc0 95.019920 lr 0.00067606 rank 0
2022-08-25 11:12:43,750 DEBUG TRAIN Batch 153/5000 loss 44.931488 loss_att 28.133190 loss_ctc 84.127502 loss_ctc_origin 52.540340 loss_ctc0 157.830872 lr 0.00067602 rank 0
2022-08-25 11:13:12,586 DEBUG TRAIN Batch 153/5100 loss 56.593102 loss_att 31.423222 loss_ctc 115.322815 loss_ctc_origin 64.855026 loss_ctc0 233.080963 lr 0.00067598 rank 0
2022-08-25 11:13:42,222 DEBUG TRAIN Batch 153/5200 loss 21.603718 loss_att 10.420998 loss_ctc 47.696732 loss_ctc_origin 38.035194 loss_ctc0 70.240326 lr 0.00067594 rank 0
2022-08-25 11:14:12,082 DEBUG TRAIN Batch 153/5300 loss 20.231077 loss_att 8.772503 loss_ctc 46.967751 loss_ctc_origin 34.254356 loss_ctc0 76.632347 lr 0.00067590 rank 0
2022-08-25 11:14:41,850 DEBUG TRAIN Batch 153/5400 loss 23.039066 loss_att 9.641304 loss_ctc 54.300507 loss_ctc_origin 35.281254 loss_ctc0 98.678757 lr 0.00067587 rank 0
2022-08-25 11:15:08,155 DEBUG TRAIN Batch 153/5500 loss 47.330490 loss_att 27.642368 loss_ctc 93.269440 loss_ctc_origin 56.335224 loss_ctc0 179.449280 lr 0.00067583 rank 0
2022-08-25 11:15:34,922 DEBUG TRAIN Batch 153/5600 loss 61.473198 loss_att 34.700191 loss_ctc 123.943535 loss_ctc_origin 67.445549 loss_ctc0 255.772171 lr 0.00067579 rank 0
2022-08-25 11:15:57,055 DEBUG CV Batch 153/0 loss 12.043068 loss_att 8.662472 loss_ctc 19.931126 loss_ctc_origin 13.493855 loss_ctc0 34.951424 history loss 11.334652 rank 0
2022-08-25 11:16:07,773 DEBUG CV Batch 153/100 loss 20.257307 loss_att 16.205593 loss_ctc 29.711306 loss_ctc_origin 19.489994 loss_ctc0 53.561028 history loss 26.352210 rank 0
2022-08-25 11:16:17,468 DEBUG CV Batch 153/200 loss 25.645081 loss_att 20.045155 loss_ctc 38.711578 loss_ctc_origin 28.472124 loss_ctc0 62.603645 history loss 27.644530 rank 0
2022-08-25 11:16:26,997 DEBUG CV Batch 153/300 loss 22.931087 loss_att 17.493275 loss_ctc 35.619316 loss_ctc_origin 20.257481 loss_ctc0 71.463593 history loss 26.729327 rank 0
2022-08-25 11:16:36,977 DEBUG CV Batch 153/400 loss 37.298470 loss_att 30.182961 loss_ctc 53.901325 loss_ctc_origin 36.330963 loss_ctc0 94.898834 history loss 25.077488 rank 0
2022-08-25 11:16:47,333 DEBUG CV Batch 153/500 loss 16.861570 loss_att 12.532461 loss_ctc 26.962826 loss_ctc_origin 20.188747 loss_ctc0 42.769005 history loss 24.726104 rank 0
2022-08-25 11:16:57,302 DEBUG CV Batch 153/600 loss 16.828476 loss_att 11.566244 loss_ctc 29.107019 loss_ctc_origin 18.370375 loss_ctc0 54.159187 history loss 24.516628 rank 0
2022-08-25 11:17:07,253 DEBUG CV Batch 153/700 loss 18.422771 loss_att 12.612164 loss_ctc 31.980854 loss_ctc_origin 18.376549 loss_ctc0 63.724232 history loss 24.181188 rank 0
2022-08-25 11:17:17,937 DEBUG CV Batch 153/800 loss 21.664637 loss_att 16.987177 loss_ctc 32.578709 loss_ctc_origin 17.248341 loss_ctc0 68.349564 history loss 24.136661 rank 0
2022-08-25 11:17:28,214 INFO Epoch 153 CV info cv_loss 24.250725006552962
2022-08-25 11:17:28,215 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/153.pt
2022-08-25 11:17:28,680 INFO Epoch 154 TRAIN info lr 0.0006757558925131763
2022-08-25 11:17:28,683 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 11:17:56,343 DEBUG TRAIN Batch 154/0 loss 51.029957 loss_att 31.007812 loss_ctc 97.748291 loss_ctc_origin 59.100716 loss_ctc0 187.925964 lr 0.00067575 rank 0
2022-08-25 11:18:25,337 DEBUG TRAIN Batch 154/100 loss 63.419178 loss_att 38.196754 loss_ctc 122.271492 loss_ctc_origin 68.588943 loss_ctc0 247.530762 lr 0.00067572 rank 0
2022-08-25 11:18:54,885 DEBUG TRAIN Batch 154/200 loss 20.584074 loss_att 12.908296 loss_ctc 38.494225 loss_ctc_origin 27.705610 loss_ctc0 63.667660 lr 0.00067568 rank 0
2022-08-25 11:19:22,765 DEBUG TRAIN Batch 154/300 loss 18.896505 loss_att 7.900482 loss_ctc 44.553890 loss_ctc_origin 30.081234 loss_ctc0 78.323418 lr 0.00067564 rank 0
2022-08-25 11:19:51,761 DEBUG TRAIN Batch 154/400 loss 22.693064 loss_att 8.857937 loss_ctc 54.975021 loss_ctc_origin 34.864891 loss_ctc0 101.898651 lr 0.00067560 rank 0
2022-08-25 11:20:20,883 DEBUG TRAIN Batch 154/500 loss 43.150803 loss_att 26.973463 loss_ctc 80.897934 loss_ctc_origin 52.347855 loss_ctc0 147.514801 lr 0.00067556 rank 0
2022-08-25 11:20:49,810 DEBUG TRAIN Batch 154/600 loss 59.359497 loss_att 33.294788 loss_ctc 120.177155 loss_ctc_origin 66.832397 loss_ctc0 244.648254 lr 0.00067552 rank 0
2022-08-25 11:21:18,822 DEBUG TRAIN Batch 154/700 loss 27.176460 loss_att 18.389660 loss_ctc 47.678993 loss_ctc_origin 39.073753 loss_ctc0 67.757889 lr 0.00067548 rank 0
2022-08-25 11:21:47,730 DEBUG TRAIN Batch 154/800 loss 18.073910 loss_att 8.094517 loss_ctc 41.359161 loss_ctc_origin 24.218479 loss_ctc0 81.354088 lr 0.00067545 rank 0
2022-08-25 11:22:14,989 DEBUG TRAIN Batch 154/900 loss 23.780489 loss_att 10.388817 loss_ctc 55.027725 loss_ctc_origin 35.591141 loss_ctc0 100.379761 lr 0.00067541 rank 0
2022-08-25 11:22:44,828 DEBUG TRAIN Batch 154/1000 loss 49.332172 loss_att 30.938896 loss_ctc 92.249817 loss_ctc_origin 59.606152 loss_ctc0 168.418381 lr 0.00067537 rank 0
2022-08-25 11:23:14,722 DEBUG TRAIN Batch 154/1100 loss 57.495064 loss_att 32.643097 loss_ctc 115.482979 loss_ctc_origin 65.917915 loss_ctc0 231.134781 lr 0.00067533 rank 0
2022-08-25 11:23:41,621 DEBUG TRAIN Batch 154/1200 loss 21.627340 loss_att 11.708414 loss_ctc 44.771500 loss_ctc_origin 35.175797 loss_ctc0 67.161469 lr 0.00067529 rank 0
2022-08-25 11:24:12,041 DEBUG TRAIN Batch 154/1300 loss 17.648657 loss_att 6.828599 loss_ctc 42.895454 loss_ctc_origin 28.468622 loss_ctc0 76.558060 lr 0.00067525 rank 0
2022-08-25 11:24:39,788 DEBUG TRAIN Batch 154/1400 loss 21.823112 loss_att 9.096056 loss_ctc 51.519577 loss_ctc_origin 35.265343 loss_ctc0 89.446121 lr 0.00067521 rank 0
2022-08-25 11:25:13,793 DEBUG TRAIN Batch 154/1500 loss 49.840599 loss_att 33.875488 loss_ctc 87.092514 loss_ctc_origin 57.092239 loss_ctc0 157.093170 lr 0.00067518 rank 0
2022-08-25 11:25:42,693 DEBUG TRAIN Batch 154/1600 loss 56.665333 loss_att 32.295544 loss_ctc 113.528168 loss_ctc_origin 62.116852 loss_ctc0 233.487900 lr 0.00067514 rank 0
2022-08-25 11:26:11,323 DEBUG TRAIN Batch 154/1700 loss 15.947189 loss_att 8.100885 loss_ctc 34.255230 loss_ctc_origin 22.936581 loss_ctc0 60.665409 lr 0.00067510 rank 0
2022-08-25 11:26:40,842 DEBUG TRAIN Batch 154/1800 loss 22.487627 loss_att 10.172339 loss_ctc 51.223297 loss_ctc_origin 36.181763 loss_ctc0 86.320198 lr 0.00067506 rank 0
2022-08-25 11:27:09,776 DEBUG TRAIN Batch 154/1900 loss 21.336002 loss_att 8.245823 loss_ctc 51.879753 loss_ctc_origin 33.118378 loss_ctc0 95.656303 lr 0.00067502 rank 0
2022-08-25 11:27:40,494 DEBUG TRAIN Batch 154/2000 loss 48.881424 loss_att 32.309311 loss_ctc 87.549683 loss_ctc_origin 52.765942 loss_ctc0 168.711746 lr 0.00067498 rank 0
2022-08-25 11:28:08,713 DEBUG TRAIN Batch 154/2100 loss 58.304050 loss_att 31.423771 loss_ctc 121.024696 loss_ctc_origin 63.746330 loss_ctc0 254.674210 lr 0.00067495 rank 0
2022-08-25 11:28:38,845 DEBUG TRAIN Batch 154/2200 loss 18.658045 loss_att 10.321927 loss_ctc 38.108986 loss_ctc_origin 25.427402 loss_ctc0 67.699356 lr 0.00067491 rank 0
2022-08-25 11:29:07,689 DEBUG TRAIN Batch 154/2300 loss 18.571087 loss_att 8.191046 loss_ctc 42.791180 loss_ctc_origin 28.889299 loss_ctc0 75.228897 lr 0.00067487 rank 0
2022-08-25 11:29:36,963 DEBUG TRAIN Batch 154/2400 loss 21.393703 loss_att 8.538082 loss_ctc 51.390152 loss_ctc_origin 32.557297 loss_ctc0 95.333481 lr 0.00067483 rank 0
2022-08-25 11:30:06,430 DEBUG TRAIN Batch 154/2500 loss 44.484421 loss_att 31.066586 loss_ctc 75.792709 loss_ctc_origin 51.039810 loss_ctc0 133.549484 lr 0.00067479 rank 0
2022-08-25 11:30:36,392 DEBUG TRAIN Batch 154/2600 loss 58.622559 loss_att 29.682476 loss_ctc 126.149414 loss_ctc_origin 67.607719 loss_ctc0 262.746704 lr 0.00067475 rank 0
2022-08-25 11:31:05,799 DEBUG TRAIN Batch 154/2700 loss 22.480408 loss_att 13.189308 loss_ctc 44.159637 loss_ctc_origin 35.648060 loss_ctc0 64.019974 lr 0.00067472 rank 0
2022-08-25 11:31:34,686 DEBUG TRAIN Batch 154/2800 loss 20.533781 loss_att 8.776293 loss_ctc 47.967918 loss_ctc_origin 33.349621 loss_ctc0 82.077286 lr 0.00067468 rank 0
2022-08-25 11:31:52,953 WARNING NaN or Inf found in input tensor.
2022-08-25 11:32:04,426 DEBUG TRAIN Batch 154/2900 loss 22.147305 loss_att 9.232567 loss_ctc 52.281693 loss_ctc_origin 35.467804 loss_ctc0 91.514099 lr 0.00067464 rank 0
2022-08-25 11:32:40,285 DEBUG TRAIN Batch 154/3000 loss 49.814274 loss_att 32.212494 loss_ctc 90.885086 loss_ctc_origin 52.827473 loss_ctc0 179.686188 lr 0.00067460 rank 0
2022-08-25 11:33:09,163 DEBUG TRAIN Batch 154/3100 loss 57.521580 loss_att 31.786892 loss_ctc 117.569183 loss_ctc_origin 56.113609 loss_ctc0 260.965515 lr 0.00067456 rank 0
2022-08-25 11:33:37,791 DEBUG TRAIN Batch 154/3200 loss 19.809456 loss_att 10.045662 loss_ctc 42.591644 loss_ctc_origin 30.023752 loss_ctc0 71.916718 lr 0.00067452 rank 0
2022-08-25 11:34:07,089 DEBUG TRAIN Batch 154/3300 loss 22.239716 loss_att 9.961843 loss_ctc 50.888084 loss_ctc_origin 37.480175 loss_ctc0 82.173203 lr 0.00067449 rank 0
2022-08-25 11:34:37,039 DEBUG TRAIN Batch 154/3400 loss 19.655561 loss_att 7.473475 loss_ctc 48.080429 loss_ctc_origin 28.837894 loss_ctc0 92.979675 lr 0.00067445 rank 0
2022-08-25 11:35:06,342 DEBUG TRAIN Batch 154/3500 loss 39.522747 loss_att 22.922962 loss_ctc 78.255577 loss_ctc_origin 42.550766 loss_ctc0 161.566803 lr 0.00067441 rank 0
2022-08-25 11:35:35,720 DEBUG TRAIN Batch 154/3600 loss 58.930027 loss_att 30.299709 loss_ctc 125.734100 loss_ctc_origin 66.497452 loss_ctc0 263.952942 lr 0.00067437 rank 0
2022-08-25 11:36:04,773 DEBUG TRAIN Batch 154/3700 loss 20.666290 loss_att 12.160269 loss_ctc 40.513672 loss_ctc_origin 28.937542 loss_ctc0 67.524643 lr 0.00067433 rank 0
2022-08-25 11:36:33,723 DEBUG TRAIN Batch 154/3800 loss 19.453796 loss_att 7.487761 loss_ctc 47.374542 loss_ctc_origin 33.318199 loss_ctc0 80.172668 lr 0.00067429 rank 0
2022-08-25 11:37:03,251 DEBUG TRAIN Batch 154/3900 loss 21.472319 loss_att 10.132102 loss_ctc 47.932823 loss_ctc_origin 29.401398 loss_ctc0 91.172821 lr 0.00067426 rank 0
2022-08-25 11:37:31,616 DEBUG TRAIN Batch 154/4000 loss 55.591393 loss_att 37.002441 loss_ctc 98.965607 loss_ctc_origin 55.947552 loss_ctc0 199.341049 lr 0.00067422 rank 0
2022-08-25 11:38:00,920 DEBUG TRAIN Batch 154/4100 loss 65.001099 loss_att 38.520206 loss_ctc 126.789841 loss_ctc_origin 70.176987 loss_ctc0 258.886475 lr 0.00067418 rank 0
2022-08-25 11:38:28,765 DEBUG TRAIN Batch 154/4200 loss 20.814396 loss_att 12.003222 loss_ctc 41.373802 loss_ctc_origin 32.359123 loss_ctc0 62.408043 lr 0.00067414 rank 0
2022-08-25 11:38:58,992 DEBUG TRAIN Batch 154/4300 loss 16.818451 loss_att 7.523160 loss_ctc 38.507462 loss_ctc_origin 24.253653 loss_ctc0 71.766342 lr 0.00067410 rank 0
2022-08-25 11:39:27,859 DEBUG TRAIN Batch 154/4400 loss 19.964266 loss_att 7.678634 loss_ctc 48.630741 loss_ctc_origin 31.672775 loss_ctc0 88.199326 lr 0.00067406 rank 0
2022-08-25 11:40:02,574 DEBUG TRAIN Batch 154/4500 loss 46.323784 loss_att 28.882025 loss_ctc 87.021225 loss_ctc_origin 49.855762 loss_ctc0 173.740631 lr 0.00067403 rank 0
2022-08-25 11:40:10,066 WARNING NaN or Inf found in input tensor.
2022-08-25 11:40:31,107 DEBUG TRAIN Batch 154/4600 loss 57.971855 loss_att 32.908939 loss_ctc 116.451988 loss_ctc_origin 62.632057 loss_ctc0 242.031830 lr 0.00067399 rank 0
2022-08-25 11:40:59,073 DEBUG TRAIN Batch 154/4700 loss 17.013477 loss_att 8.873716 loss_ctc 36.006256 loss_ctc_origin 25.128511 loss_ctc0 61.387661 lr 0.00067395 rank 0
2022-08-25 11:41:27,049 DEBUG TRAIN Batch 154/4800 loss 20.618210 loss_att 8.987452 loss_ctc 47.756645 loss_ctc_origin 31.345411 loss_ctc0 86.049515 lr 0.00067391 rank 0
2022-08-25 11:41:56,417 DEBUG TRAIN Batch 154/4900 loss 21.324881 loss_att 10.676369 loss_ctc 46.171406 loss_ctc_origin 27.979961 loss_ctc0 88.618111 lr 0.00067387 rank 0
2022-08-25 11:42:24,928 DEBUG TRAIN Batch 154/5000 loss 53.745201 loss_att 33.882797 loss_ctc 100.090805 loss_ctc_origin 63.467575 loss_ctc0 185.545013 lr 0.00067383 rank 0
2022-08-25 11:42:52,075 DEBUG TRAIN Batch 154/5100 loss 60.252007 loss_att 34.410309 loss_ctc 120.549301 loss_ctc_origin 64.984901 loss_ctc0 250.199554 lr 0.00067380 rank 0
2022-08-25 11:43:20,186 DEBUG TRAIN Batch 154/5200 loss 25.737659 loss_att 14.091187 loss_ctc 52.912758 loss_ctc_origin 43.625465 loss_ctc0 74.583099 lr 0.00067376 rank 0
2022-08-25 11:43:48,693 DEBUG TRAIN Batch 154/5300 loss 19.608074 loss_att 8.788195 loss_ctc 44.854462 loss_ctc_origin 30.914061 loss_ctc0 77.382065 lr 0.00067372 rank 0
2022-08-25 11:44:18,056 DEBUG TRAIN Batch 154/5400 loss 26.303246 loss_att 11.906456 loss_ctc 59.895752 loss_ctc_origin 40.629959 loss_ctc0 104.849274 lr 0.00067368 rank 0
2022-08-25 11:44:45,054 DEBUG TRAIN Batch 154/5500 loss 47.372124 loss_att 31.065498 loss_ctc 85.420914 loss_ctc_origin 50.942230 loss_ctc0 165.871185 lr 0.00067364 rank 0
2022-08-25 11:45:12,954 DEBUG TRAIN Batch 154/5600 loss 61.899956 loss_att 36.297142 loss_ctc 121.639847 loss_ctc_origin 62.694794 loss_ctc0 259.178284 lr 0.00067360 rank 0
2022-08-25 11:45:35,385 DEBUG CV Batch 154/0 loss 13.675303 loss_att 10.487021 loss_ctc 21.114624 loss_ctc_origin 15.110423 loss_ctc0 35.124428 history loss 12.870873 rank 0
2022-08-25 11:45:45,825 DEBUG CV Batch 154/100 loss 21.880461 loss_att 17.434492 loss_ctc 32.254387 loss_ctc_origin 22.816519 loss_ctc0 54.276073 history loss 28.325804 rank 0
2022-08-25 11:45:55,418 DEBUG CV Batch 154/200 loss 25.992895 loss_att 20.163319 loss_ctc 39.595242 loss_ctc_origin 29.617701 loss_ctc0 62.876171 history loss 29.866687 rank 0
2022-08-25 11:46:05,224 DEBUG CV Batch 154/300 loss 27.812447 loss_att 21.849428 loss_ctc 41.726158 loss_ctc_origin 27.656565 loss_ctc0 74.555206 history loss 28.903655 rank 0
2022-08-25 11:46:15,591 DEBUG CV Batch 154/400 loss 38.881657 loss_att 31.786934 loss_ctc 55.436012 loss_ctc_origin 38.287899 loss_ctc0 95.448273 history loss 27.156979 rank 0
2022-08-25 11:46:26,068 DEBUG CV Batch 154/500 loss 17.263033 loss_att 13.260441 loss_ctc 26.602413 loss_ctc_origin 19.789640 loss_ctc0 42.498886 history loss 26.808058 rank 0
2022-08-25 11:46:36,371 DEBUG CV Batch 154/600 loss 18.607038 loss_att 12.669691 loss_ctc 32.460846 loss_ctc_origin 22.134409 loss_ctc0 56.555859 history loss 26.679131 rank 0
2022-08-25 11:46:47,016 DEBUG CV Batch 154/700 loss 20.688976 loss_att 14.605827 loss_ctc 34.882992 loss_ctc_origin 21.779392 loss_ctc0 65.458054 history loss 26.347627 rank 0
2022-08-25 11:46:57,739 DEBUG CV Batch 154/800 loss 27.162870 loss_att 21.168018 loss_ctc 41.150856 loss_ctc_origin 27.714340 loss_ctc0 72.502731 history loss 26.272153 rank 0
2022-08-25 11:47:08,306 INFO Epoch 154 CV info cv_loss 26.39747503113828
2022-08-25 11:47:08,306 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/154.pt
2022-08-25 11:47:08,777 INFO Epoch 155 TRAIN info lr 0.0006735725075082957
2022-08-25 11:47:08,780 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 11:47:35,886 DEBUG TRAIN Batch 155/0 loss 51.518192 loss_att 34.899345 loss_ctc 90.295502 loss_ctc_origin 50.798721 loss_ctc0 182.454636 lr 0.00067357 rank 0
2022-08-25 11:47:43,987 WARNING NaN or Inf found in input tensor.
2022-08-25 11:48:04,336 DEBUG TRAIN Batch 155/100 loss 59.029068 loss_att 32.403606 loss_ctc 121.155136 loss_ctc_origin 64.175186 loss_ctc0 254.108337 lr 0.00067353 rank 0
2022-08-25 11:48:32,828 DEBUG TRAIN Batch 155/200 loss 19.617121 loss_att 9.521084 loss_ctc 43.174538 loss_ctc_origin 32.003616 loss_ctc0 69.240021 lr 0.00067349 rank 0
2022-08-25 11:49:01,520 DEBUG TRAIN Batch 155/300 loss 19.451996 loss_att 8.191922 loss_ctc 45.725502 loss_ctc_origin 30.836544 loss_ctc0 80.466400 lr 0.00067346 rank 0
2022-08-25 11:49:29,479 DEBUG TRAIN Batch 155/400 loss 26.872967 loss_att 12.624947 loss_ctc 60.118347 loss_ctc_origin 44.063446 loss_ctc0 97.579773 lr 0.00067342 rank 0
2022-08-25 11:49:59,269 DEBUG TRAIN Batch 155/500 loss 55.575386 loss_att 34.367882 loss_ctc 105.059563 loss_ctc_origin 64.501068 loss_ctc0 199.696045 lr 0.00067338 rank 0
2022-08-25 11:50:27,882 DEBUG TRAIN Batch 155/600 loss 53.172421 loss_att 26.636974 loss_ctc 115.088455 loss_ctc_origin 53.180832 loss_ctc0 259.539551 lr 0.00067334 rank 0
2022-08-25 11:50:56,879 DEBUG TRAIN Batch 155/700 loss 17.948936 loss_att 9.061564 loss_ctc 38.686134 loss_ctc_origin 26.313457 loss_ctc0 67.555702 lr 0.00067330 rank 0
2022-08-25 11:51:25,323 DEBUG TRAIN Batch 155/800 loss 21.447748 loss_att 8.674130 loss_ctc 51.252853 loss_ctc_origin 36.703957 loss_ctc0 85.200272 lr 0.00067327 rank 0
2022-08-25 11:51:53,958 DEBUG TRAIN Batch 155/900 loss 18.728848 loss_att 7.245711 loss_ctc 45.522835 loss_ctc_origin 28.062019 loss_ctc0 86.264740 lr 0.00067323 rank 0
2022-08-25 11:52:23,584 DEBUG TRAIN Batch 155/1000 loss 46.116508 loss_att 28.477640 loss_ctc 87.273872 loss_ctc_origin 54.375961 loss_ctc0 164.035660 lr 0.00067319 rank 0
2022-08-25 11:52:51,250 DEBUG TRAIN Batch 155/1100 loss 60.679062 loss_att 31.647535 loss_ctc 128.419281 loss_ctc_origin 75.518677 loss_ctc0 251.854004 lr 0.00067315 rank 0
2022-08-25 11:53:19,864 DEBUG TRAIN Batch 155/1200 loss 20.553623 loss_att 10.776424 loss_ctc 43.367081 loss_ctc_origin 32.414581 loss_ctc0 68.922905 lr 0.00067311 rank 0
2022-08-25 11:53:48,147 DEBUG TRAIN Batch 155/1300 loss 14.642012 loss_att 5.737774 loss_ctc 35.418564 loss_ctc_origin 20.881866 loss_ctc0 69.337517 lr 0.00067307 rank 0
2022-08-25 11:54:17,072 DEBUG TRAIN Batch 155/1400 loss 19.747873 loss_att 7.494374 loss_ctc 48.339371 loss_ctc_origin 30.478596 loss_ctc0 90.014511 lr 0.00067304 rank 0
2022-08-25 11:54:50,630 DEBUG TRAIN Batch 155/1500 loss 43.042259 loss_att 25.753307 loss_ctc 83.383148 loss_ctc_origin 45.915886 loss_ctc0 170.806732 lr 0.00067300 rank 0
2022-08-25 11:55:19,270 WARNING NaN or Inf found in input tensor.
2022-08-25 11:55:19,314 DEBUG TRAIN Batch 155/1600 loss nan loss_att 36.716751 loss_ctc nan loss_ctc_origin 62.467651 loss_ctc0 nan lr 0.00067296 rank 0
2022-08-25 11:55:47,504 DEBUG TRAIN Batch 155/1700 loss 23.376968 loss_att 14.010489 loss_ctc 45.232090 loss_ctc_origin 34.793613 loss_ctc0 69.588531 lr 0.00067292 rank 0
2022-08-25 11:56:16,508 DEBUG TRAIN Batch 155/1800 loss 20.026043 loss_att 7.484133 loss_ctc 49.290497 loss_ctc_origin 32.782887 loss_ctc0 87.808243 lr 0.00067288 rank 0
2022-08-25 11:56:45,547 DEBUG TRAIN Batch 155/1900 loss 22.612238 loss_att 8.438818 loss_ctc 55.683548 loss_ctc_origin 37.986649 loss_ctc0 96.976303 lr 0.00067285 rank 0
2022-08-25 11:57:14,747 DEBUG TRAIN Batch 155/2000 loss 46.089401 loss_att 30.164021 loss_ctc 83.248627 loss_ctc_origin 49.983654 loss_ctc0 160.866898 lr 0.00067281 rank 0
2022-08-25 11:57:43,407 DEBUG TRAIN Batch 155/2100 loss 57.346245 loss_att 34.002308 loss_ctc 111.815422 loss_ctc_origin 67.907104 loss_ctc0 214.268158 lr 0.00067277 rank 0
2022-08-25 11:58:10,744 WARNING NaN or Inf found in input tensor.
2022-08-25 11:58:12,556 DEBUG TRAIN Batch 155/2200 loss 22.044619 loss_att 11.046640 loss_ctc 47.706566 loss_ctc_origin 36.623421 loss_ctc0 73.567230 lr 0.00067273 rank 0
2022-08-25 11:58:40,803 DEBUG TRAIN Batch 155/2300 loss 23.224173 loss_att 10.662146 loss_ctc 52.535568 loss_ctc_origin 38.027786 loss_ctc0 86.387062 lr 0.00067269 rank 0
2022-08-25 11:59:09,903 DEBUG TRAIN Batch 155/2400 loss 21.342787 loss_att 9.923320 loss_ctc 47.988205 loss_ctc_origin 30.235126 loss_ctc0 89.412056 lr 0.00067266 rank 0
2022-08-25 11:59:39,577 DEBUG TRAIN Batch 155/2500 loss 36.743073 loss_att 22.454077 loss_ctc 70.084061 loss_ctc_origin 41.401421 loss_ctc0 137.010223 lr 0.00067262 rank 0
2022-08-25 12:00:07,198 DEBUG TRAIN Batch 155/2600 loss 60.181812 loss_att 36.479988 loss_ctc 115.486069 loss_ctc_origin 68.147095 loss_ctc0 225.943665 lr 0.00067258 rank 0
2022-08-25 12:00:34,837 WARNING NaN or Inf found in input tensor.
2022-08-25 12:00:36,404 DEBUG TRAIN Batch 155/2700 loss 17.570833 loss_att 8.190985 loss_ctc 39.457146 loss_ctc_origin 28.072994 loss_ctc0 66.020164 lr 0.00067254 rank 0
2022-08-25 12:01:04,755 DEBUG TRAIN Batch 155/2800 loss 17.378435 loss_att 6.949950 loss_ctc 41.711563 loss_ctc_origin 26.139231 loss_ctc0 78.046997 lr 0.00067250 rank 0
2022-08-25 12:01:33,889 DEBUG TRAIN Batch 155/2900 loss 19.212681 loss_att 7.537620 loss_ctc 46.454491 loss_ctc_origin 28.472771 loss_ctc0 88.411842 lr 0.00067247 rank 0
2022-08-25 12:02:09,878 DEBUG TRAIN Batch 155/3000 loss 46.771004 loss_att 32.154175 loss_ctc 80.876930 loss_ctc_origin 54.047287 loss_ctc0 143.479431 lr 0.00067243 rank 0
2022-08-25 12:02:38,881 DEBUG TRAIN Batch 155/3100 loss 49.857597 loss_att 25.991755 loss_ctc 105.544571 loss_ctc_origin 57.040195 loss_ctc0 218.721436 lr 0.00067239 rank 0
2022-08-25 12:03:08,306 DEBUG TRAIN Batch 155/3200 loss 23.641220 loss_att 14.310078 loss_ctc 45.413879 loss_ctc_origin 35.046295 loss_ctc0 69.604904 lr 0.00067235 rank 0
2022-08-25 12:03:38,039 DEBUG TRAIN Batch 155/3300 loss 19.467667 loss_att 8.952101 loss_ctc 44.003983 loss_ctc_origin 31.458744 loss_ctc0 73.276215 lr 0.00067231 rank 0
2022-08-25 12:04:07,424 DEBUG TRAIN Batch 155/3400 loss 23.666565 loss_att 10.543514 loss_ctc 54.287010 loss_ctc_origin 37.497368 loss_ctc0 93.462830 lr 0.00067228 rank 0
2022-08-25 12:04:36,283 DEBUG TRAIN Batch 155/3500 loss 52.684719 loss_att 33.986832 loss_ctc 96.313126 loss_ctc_origin 61.513180 loss_ctc0 177.512985 lr 0.00067224 rank 0
2022-08-25 12:04:36,982 WARNING NaN or Inf found in input tensor.
2022-08-25 12:05:03,845 DEBUG TRAIN Batch 155/3600 loss 49.912674 loss_att 25.906916 loss_ctc 105.926102 loss_ctc_origin 55.930779 loss_ctc0 222.581848 lr 0.00067220 rank 0
2022-08-25 12:05:33,627 DEBUG TRAIN Batch 155/3700 loss 20.340385 loss_att 12.063138 loss_ctc 39.653957 loss_ctc_origin 29.575462 loss_ctc0 63.170441 lr 0.00067216 rank 0
2022-08-25 12:06:02,891 DEBUG TRAIN Batch 155/3800 loss 22.490137 loss_att 9.715183 loss_ctc 52.298363 loss_ctc_origin 36.100830 loss_ctc0 90.092598 lr 0.00067212 rank 0
2022-08-25 12:06:33,356 DEBUG TRAIN Batch 155/3900 loss 24.788637 loss_att 9.759987 loss_ctc 59.855484 loss_ctc_origin 43.434830 loss_ctc0 98.170334 lr 0.00067209 rank 0
2022-08-25 12:07:02,583 DEBUG TRAIN Batch 155/4000 loss 51.525501 loss_att 33.361961 loss_ctc 93.907089 loss_ctc_origin 63.898174 loss_ctc0 163.927887 lr 0.00067205 rank 0
2022-08-25 12:07:31,505 DEBUG TRAIN Batch 155/4100 loss 50.573700 loss_att 26.691313 loss_ctc 106.299271 loss_ctc_origin 56.202854 loss_ctc0 223.190887 lr 0.00067201 rank 0
2022-08-25 12:07:58,723 DEBUG TRAIN Batch 155/4200 loss 19.155285 loss_att 9.509468 loss_ctc 41.662189 loss_ctc_origin 27.942406 loss_ctc0 73.675018 lr 0.00067197 rank 0
2022-08-25 12:08:11,659 WARNING NaN or Inf found in input tensor.
2022-08-25 12:08:28,570 DEBUG TRAIN Batch 155/4300 loss 18.956915 loss_att 8.436941 loss_ctc 43.503517 loss_ctc_origin 30.389336 loss_ctc0 74.103264 lr 0.00067193 rank 0
2022-08-25 12:08:57,586 DEBUG TRAIN Batch 155/4400 loss 23.528833 loss_att 10.302641 loss_ctc 54.389946 loss_ctc_origin 35.128654 loss_ctc0 99.332962 lr 0.00067190 rank 0
2022-08-25 12:09:32,389 DEBUG TRAIN Batch 155/4500 loss 45.914787 loss_att 29.188131 loss_ctc 84.943649 loss_ctc_origin 52.002819 loss_ctc0 161.805588 lr 0.00067186 rank 0
2022-08-25 12:10:00,732 DEBUG TRAIN Batch 155/4600 loss 58.235268 loss_att 36.179703 loss_ctc 109.698257 loss_ctc_origin 67.520103 loss_ctc0 208.113953 lr 0.00067182 rank 0
2022-08-25 12:10:28,342 DEBUG TRAIN Batch 155/4700 loss 19.724384 loss_att 11.321764 loss_ctc 39.330498 loss_ctc_origin 29.072266 loss_ctc0 63.266365 lr 0.00067178 rank 0
2022-08-25 12:10:57,001 DEBUG TRAIN Batch 155/4800 loss 20.755836 loss_att 8.887535 loss_ctc 48.448540 loss_ctc_origin 32.684128 loss_ctc0 85.232162 lr 0.00067174 rank 0
2022-08-25 12:11:24,865 DEBUG TRAIN Batch 155/4900 loss 21.359083 loss_att 9.183432 loss_ctc 49.768936 loss_ctc_origin 32.748848 loss_ctc0 89.482483 lr 0.00067171 rank 0
2022-08-25 12:11:53,914 DEBUG TRAIN Batch 155/5000 loss 49.304493 loss_att 34.302288 loss_ctc 84.309639 loss_ctc_origin 58.079704 loss_ctc0 145.512817 lr 0.00067167 rank 0
2022-08-25 12:12:21,742 DEBUG TRAIN Batch 155/5100 loss 58.713264 loss_att 34.834793 loss_ctc 114.429688 loss_ctc_origin 68.326233 loss_ctc0 222.004410 lr 0.00067163 rank 0
2022-08-25 12:12:50,247 DEBUG TRAIN Batch 155/5200 loss 21.638844 loss_att 11.857830 loss_ctc 44.461205 loss_ctc_origin 32.850777 loss_ctc0 71.552208 lr 0.00067159 rank 0
2022-08-25 12:13:19,309 DEBUG TRAIN Batch 155/5300 loss 18.401413 loss_att 7.244007 loss_ctc 44.435360 loss_ctc_origin 28.447483 loss_ctc0 81.740402 lr 0.00067156 rank 0
2022-08-25 12:13:48,413 DEBUG TRAIN Batch 155/5400 loss 19.708336 loss_att 7.877352 loss_ctc 47.313965 loss_ctc_origin 30.173855 loss_ctc0 87.307556 lr 0.00067152 rank 0
2022-08-25 12:14:16,168 DEBUG TRAIN Batch 155/5500 loss 40.186478 loss_att 24.210114 loss_ctc 77.464661 loss_ctc_origin 42.813148 loss_ctc0 158.318176 lr 0.00067148 rank 0
2022-08-25 12:14:44,383 DEBUG TRAIN Batch 155/5600 loss 53.715252 loss_att 32.567482 loss_ctc 103.060043 loss_ctc_origin 58.612442 loss_ctc0 206.771118 lr 0.00067144 rank 0
2022-08-25 12:15:06,217 DEBUG CV Batch 155/0 loss 12.526440 loss_att 8.994162 loss_ctc 20.768419 loss_ctc_origin 14.802189 loss_ctc0 34.689621 history loss 11.789590 rank 0
2022-08-25 12:15:16,926 DEBUG CV Batch 155/100 loss 22.169655 loss_att 18.090538 loss_ctc 31.687592 loss_ctc_origin 22.291170 loss_ctc0 53.612572 history loss 26.880041 rank 0
2022-08-25 12:15:26,647 DEBUG CV Batch 155/200 loss 24.221367 loss_att 18.905006 loss_ctc 36.626209 loss_ctc_origin 26.328529 loss_ctc0 60.654129 history loss 28.046744 rank 0
2022-08-25 12:15:37,268 DEBUG CV Batch 155/300 loss 24.146008 loss_att 18.840492 loss_ctc 36.525547 loss_ctc_origin 21.587147 loss_ctc0 71.381805 history loss 27.111930 rank 0
2022-08-25 12:15:48,275 DEBUG CV Batch 155/400 loss 37.593876 loss_att 30.125315 loss_ctc 55.020515 loss_ctc_origin 38.023117 loss_ctc0 94.681099 history loss 25.411733 rank 0
2022-08-25 12:15:59,347 DEBUG CV Batch 155/500 loss 16.228878 loss_att 12.140916 loss_ctc 25.767458 loss_ctc_origin 18.671795 loss_ctc0 42.324005 history loss 25.068185 rank 0
2022-08-25 12:16:10,262 DEBUG CV Batch 155/600 loss 16.670940 loss_att 11.352292 loss_ctc 29.081120 loss_ctc_origin 18.316151 loss_ctc0 54.199379 history loss 24.886418 rank 0
2022-08-25 12:16:20,730 DEBUG CV Batch 155/700 loss 18.973904 loss_att 13.247520 loss_ctc 32.335464 loss_ctc_origin 18.982449 loss_ctc0 63.492504 history loss 24.570592 rank 0
2022-08-25 12:16:31,981 DEBUG CV Batch 155/800 loss 21.802074 loss_att 16.877863 loss_ctc 33.291901 loss_ctc_origin 17.824766 loss_ctc0 69.381882 history loss 24.526556 rank 0
2022-08-25 12:16:42,328 INFO Epoch 155 CV info cv_loss 24.64728365139493
2022-08-25 12:16:42,328 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/155.pt
2022-08-25 12:16:42,870 INFO Epoch 156 TRAIN info lr 0.0006714101503791079
2022-08-25 12:16:42,874 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 12:17:10,160 DEBUG TRAIN Batch 156/0 loss 43.355968 loss_att 29.566509 loss_ctc 75.531372 loss_ctc_origin 46.607841 loss_ctc0 143.019608 lr 0.00067141 rank 0
2022-08-25 12:17:39,717 DEBUG TRAIN Batch 156/100 loss 57.532364 loss_att 32.997276 loss_ctc 114.780891 loss_ctc_origin 71.951675 loss_ctc0 214.715729 lr 0.00067137 rank 0
2022-08-25 12:17:48,113 WARNING NaN or Inf found in input tensor.
2022-08-25 12:18:07,990 DEBUG TRAIN Batch 156/200 loss 22.434631 loss_att 11.511232 loss_ctc 47.922562 loss_ctc_origin 37.469070 loss_ctc0 72.314041 lr 0.00067133 rank 0
2022-08-25 12:18:36,703 DEBUG TRAIN Batch 156/300 loss 19.773643 loss_att 7.676741 loss_ctc 47.999752 loss_ctc_origin 33.420296 loss_ctc0 82.018478 lr 0.00067130 rank 0
2022-08-25 12:19:05,592 DEBUG TRAIN Batch 156/400 loss 17.537415 loss_att 6.044348 loss_ctc 44.354568 loss_ctc_origin 26.507601 loss_ctc0 85.997482 lr 0.00067126 rank 0
2022-08-25 12:19:35,062 DEBUG TRAIN Batch 156/500 loss 44.174156 loss_att 29.118450 loss_ctc 79.304138 loss_ctc_origin 47.845947 loss_ctc0 152.706604 lr 0.00067122 rank 0
2022-08-25 12:19:43,521 WARNING NaN or Inf found in input tensor.
2022-08-25 12:20:03,999 DEBUG TRAIN Batch 156/600 loss 54.850784 loss_att 30.821568 loss_ctc 110.918961 loss_ctc_origin 66.367447 loss_ctc0 214.872498 lr 0.00067118 rank 0
2022-08-25 12:20:32,937 DEBUG TRAIN Batch 156/700 loss 19.798378 loss_att 9.613809 loss_ctc 43.562370 loss_ctc_origin 29.793983 loss_ctc0 75.688599 lr 0.00067114 rank 0
2022-08-25 12:21:01,236 DEBUG TRAIN Batch 156/800 loss 19.319134 loss_att 7.298379 loss_ctc 47.367558 loss_ctc_origin 32.689617 loss_ctc0 81.616081 lr 0.00067111 rank 0
2022-08-25 12:21:29,813 DEBUG TRAIN Batch 156/900 loss 22.541494 loss_att 9.506510 loss_ctc 52.956459 loss_ctc_origin 36.592945 loss_ctc0 91.137985 lr 0.00067107 rank 0
2022-08-25 12:21:58,754 DEBUG TRAIN Batch 156/1000 loss 49.603546 loss_att 31.765650 loss_ctc 91.225296 loss_ctc_origin 59.173088 loss_ctc0 166.013763 lr 0.00067103 rank 0
2022-08-25 12:22:26,439 DEBUG TRAIN Batch 156/1100 loss 54.450546 loss_att 28.750025 loss_ctc 114.418419 loss_ctc_origin 66.020866 loss_ctc0 227.346039 lr 0.00067099 rank 0
2022-08-25 12:22:55,150 DEBUG TRAIN Batch 156/1200 loss 21.114189 loss_att 11.121540 loss_ctc 44.430370 loss_ctc_origin 33.469910 loss_ctc0 70.004776 lr 0.00067096 rank 0
2022-08-25 12:23:07,258 WARNING NaN or Inf found in input tensor.
2022-08-25 12:23:24,552 DEBUG TRAIN Batch 156/1300 loss 23.270439 loss_att 9.140898 loss_ctc 56.239368 loss_ctc_origin 40.997932 loss_ctc0 91.802711 lr 0.00067092 rank 0
2022-08-25 12:23:52,738 DEBUG TRAIN Batch 156/1400 loss 25.159294 loss_att 10.904629 loss_ctc 58.420181 loss_ctc_origin 39.106892 loss_ctc0 103.484520 lr 0.00067088 rank 0
2022-08-25 12:24:27,756 DEBUG TRAIN Batch 156/1500 loss 48.523972 loss_att 33.803276 loss_ctc 82.872269 loss_ctc_origin 53.309689 loss_ctc0 151.851639 lr 0.00067084 rank 0
2022-08-25 12:24:56,723 DEBUG TRAIN Batch 156/1600 loss 58.834427 loss_att 34.502117 loss_ctc 115.609810 loss_ctc_origin 66.409424 loss_ctc0 230.410706 lr 0.00067080 rank 0
2022-08-25 12:25:24,500 DEBUG TRAIN Batch 156/1700 loss 20.323700 loss_att 11.564969 loss_ctc 40.760738 loss_ctc_origin 30.405910 loss_ctc0 64.921997 lr 0.00067077 rank 0
2022-08-25 12:25:53,310 DEBUG TRAIN Batch 156/1800 loss 18.051548 loss_att 7.803913 loss_ctc 41.962696 loss_ctc_origin 26.222134 loss_ctc0 78.690674 lr 0.00067073 rank 0
2022-08-25 12:26:23,313 DEBUG TRAIN Batch 156/1900 loss 20.244232 loss_att 8.040980 loss_ctc 48.718483 loss_ctc_origin 28.571487 loss_ctc0 95.728142 lr 0.00067069 rank 0
2022-08-25 12:26:52,920 DEBUG TRAIN Batch 156/2000 loss 54.245155 loss_att 34.421844 loss_ctc 100.499542 loss_ctc_origin 64.362442 loss_ctc0 184.819458 lr 0.00067065 rank 0
2022-08-25 12:27:00,782 WARNING NaN or Inf found in input tensor.
2022-08-25 12:27:14,257 WARNING NaN or Inf found in input tensor.
2022-08-25 12:27:21,322 DEBUG TRAIN Batch 156/2100 loss 60.208237 loss_att 39.310112 loss_ctc 108.970520 loss_ctc_origin 67.648384 loss_ctc0 205.388824 lr 0.00067062 rank 0
2022-08-25 12:27:47,527 WARNING NaN or Inf found in input tensor.
2022-08-25 12:27:49,004 DEBUG TRAIN Batch 156/2200 loss 22.041370 loss_att 13.004511 loss_ctc 43.127380 loss_ctc_origin 33.675690 loss_ctc0 65.181320 lr 0.00067058 rank 0
2022-08-25 12:28:17,690 DEBUG TRAIN Batch 156/2300 loss 19.835785 loss_att 8.485176 loss_ctc 46.320538 loss_ctc_origin 31.893696 loss_ctc0 79.983170 lr 0.00067054 rank 0
2022-08-25 12:28:43,240 WARNING NaN or Inf found in input tensor.
2022-08-25 12:28:47,765 DEBUG TRAIN Batch 156/2400 loss 19.500511 loss_att 7.630318 loss_ctc 47.197628 loss_ctc_origin 28.797993 loss_ctc0 90.130112 lr 0.00067050 rank 0
2022-08-25 12:29:16,042 DEBUG TRAIN Batch 156/2500 loss 29.744516 loss_att 18.056061 loss_ctc 57.017578 loss_ctc_origin 30.427855 loss_ctc0 119.060257 lr 0.00067046 rank 0
2022-08-25 12:29:44,653 DEBUG TRAIN Batch 156/2600 loss 54.974701 loss_att 27.700434 loss_ctc 118.614647 loss_ctc_origin 62.030205 loss_ctc0 250.645004 lr 0.00067043 rank 0
2022-08-25 12:30:12,934 DEBUG TRAIN Batch 156/2700 loss 18.657932 loss_att 10.045014 loss_ctc 38.754742 loss_ctc_origin 27.259140 loss_ctc0 65.577812 lr 0.00067039 rank 0
2022-08-25 12:30:42,894 DEBUG TRAIN Batch 156/2800 loss 21.254930 loss_att 9.239763 loss_ctc 49.290321 loss_ctc_origin 35.102867 loss_ctc0 82.394379 lr 0.00067035 rank 0
2022-08-25 12:30:59,776 WARNING NaN or Inf found in input tensor.
2022-08-25 12:31:11,720 DEBUG TRAIN Batch 156/2900 loss 20.238575 loss_att 8.678543 loss_ctc 47.211983 loss_ctc_origin 29.935587 loss_ctc0 87.523575 lr 0.00067031 rank 0
2022-08-25 12:31:46,383 DEBUG TRAIN Batch 156/3000 loss 44.964027 loss_att 27.538162 loss_ctc 85.624382 loss_ctc_origin 49.211681 loss_ctc0 170.587341 lr 0.00067028 rank 0
2022-08-25 12:32:15,219 DEBUG TRAIN Batch 156/3100 loss 63.027332 loss_att 38.910789 loss_ctc 119.299255 loss_ctc_origin 67.638344 loss_ctc0 239.841385 lr 0.00067024 rank 0
2022-08-25 12:32:42,198 WARNING NaN or Inf found in input tensor.
2022-08-25 12:32:43,791 DEBUG TRAIN Batch 156/3200 loss 20.600075 loss_att 11.277320 loss_ctc 42.353165 loss_ctc_origin 30.648813 loss_ctc0 69.663315 lr 0.00067020 rank 0
2022-08-25 12:33:13,245 DEBUG TRAIN Batch 156/3300 loss 18.952164 loss_att 7.681127 loss_ctc 45.251247 loss_ctc_origin 29.898304 loss_ctc0 81.074783 lr 0.00067016 rank 0
2022-08-25 12:33:42,116 DEBUG TRAIN Batch 156/3400 loss 22.859781 loss_att 9.709385 loss_ctc 53.544037 loss_ctc_origin 35.953358 loss_ctc0 94.588943 lr 0.00067013 rank 0
2022-08-25 12:34:11,010 DEBUG TRAIN Batch 156/3500 loss 51.654259 loss_att 33.487511 loss_ctc 94.043335 loss_ctc_origin 60.545670 loss_ctc0 172.204544 lr 0.00067009 rank 0
2022-08-25 12:34:38,735 DEBUG TRAIN Batch 156/3600 loss 60.910385 loss_att 36.179150 loss_ctc 118.616592 loss_ctc_origin 77.661621 loss_ctc0 214.178192 lr 0.00067005 rank 0
2022-08-25 12:35:07,292 DEBUG TRAIN Batch 156/3700 loss 23.619438 loss_att 12.960369 loss_ctc 48.490597 loss_ctc_origin 38.166672 loss_ctc0 72.579758 lr 0.00067001 rank 0
2022-08-25 12:35:12,627 WARNING NaN or Inf found in input tensor.
2022-08-25 12:35:35,024 DEBUG TRAIN Batch 156/3800 loss 19.093204 loss_att 7.313707 loss_ctc 46.578693 loss_ctc_origin 30.548058 loss_ctc0 83.983505 lr 0.00066998 rank 0
2022-08-25 12:36:04,207 DEBUG TRAIN Batch 156/3900 loss 22.445892 loss_att 9.814194 loss_ctc 51.919853 loss_ctc_origin 34.513569 loss_ctc0 92.534508 lr 0.00066994 rank 0
2022-08-25 12:36:33,417 DEBUG TRAIN Batch 156/4000 loss 45.268551 loss_att 30.735620 loss_ctc 79.178719 loss_ctc_origin 47.261864 loss_ctc0 153.651367 lr 0.00066990 rank 0
2022-08-25 12:37:00,891 DEBUG TRAIN Batch 156/4100 loss 61.156956 loss_att 38.854942 loss_ctc 113.194977 loss_ctc_origin 70.533585 loss_ctc0 212.738235 lr 0.00066986 rank 0
2022-08-25 12:37:30,369 DEBUG TRAIN Batch 156/4200 loss 17.387022 loss_att 8.564004 loss_ctc 37.974064 loss_ctc_origin 25.699169 loss_ctc0 66.615486 lr 0.00066983 rank 0
2022-08-25 12:37:42,824 WARNING NaN or Inf found in input tensor.
2022-08-25 12:38:00,081 DEBUG TRAIN Batch 156/4300 loss 20.440437 loss_att 8.769662 loss_ctc 47.672249 loss_ctc_origin 33.223461 loss_ctc0 81.386093 lr 0.00066979 rank 0
2022-08-25 12:38:27,781 DEBUG TRAIN Batch 156/4400 loss 20.793915 loss_att 8.758104 loss_ctc 48.877468 loss_ctc_origin 30.611713 loss_ctc0 91.497559 lr 0.00066975 rank 0
2022-08-25 12:39:03,008 DEBUG TRAIN Batch 156/4500 loss 35.422791 loss_att 21.145309 loss_ctc 68.736916 loss_ctc_origin 40.799301 loss_ctc0 133.924683 lr 0.00066971 rank 0
2022-08-25 12:39:31,074 DEBUG TRAIN Batch 156/4600 loss 54.996624 loss_att 31.898106 loss_ctc 108.893166 loss_ctc_origin 61.758247 loss_ctc0 218.874634 lr 0.00066968 rank 0
2022-08-25 12:39:59,495 DEBUG TRAIN Batch 156/4700 loss 23.898195 loss_att 13.254176 loss_ctc 48.734238 loss_ctc_origin 38.105675 loss_ctc0 73.534225 lr 0.00066964 rank 0
2022-08-25 12:40:27,633 DEBUG TRAIN Batch 156/4800 loss 22.256510 loss_att 9.453431 loss_ctc 52.130360 loss_ctc_origin 37.950024 loss_ctc0 85.217812 lr 0.00066960 rank 0
2022-08-25 12:40:56,199 DEBUG TRAIN Batch 156/4900 loss 23.818092 loss_att 9.718046 loss_ctc 56.718193 loss_ctc_origin 37.586388 loss_ctc0 101.359077 lr 0.00066956 rank 0
2022-08-25 12:41:23,885 DEBUG TRAIN Batch 156/5000 loss 41.464943 loss_att 28.028599 loss_ctc 72.816414 loss_ctc_origin 41.981758 loss_ctc0 144.763947 lr 0.00066952 rank 0
2022-08-25 12:41:51,491 DEBUG TRAIN Batch 156/5100 loss 52.067741 loss_att 28.107634 loss_ctc 107.974655 loss_ctc_origin 60.024376 loss_ctc0 219.858643 lr 0.00066949 rank 0
2022-08-25 12:42:19,116 WARNING NaN or Inf found in input tensor.
2022-08-25 12:42:20,653 DEBUG TRAIN Batch 156/5200 loss 17.853127 loss_att 9.148720 loss_ctc 38.163406 loss_ctc_origin 25.310719 loss_ctc0 68.153015 lr 0.00066945 rank 0
2022-08-25 12:42:48,759 DEBUG TRAIN Batch 156/5300 loss 19.673433 loss_att 8.894453 loss_ctc 44.824387 loss_ctc_origin 31.278393 loss_ctc0 76.431709 lr 0.00066941 rank 0
2022-08-25 12:42:51,577 WARNING NaN or Inf found in input tensor.
2022-08-25 12:43:18,469 DEBUG TRAIN Batch 156/5400 loss 22.489346 loss_att 10.208727 loss_ctc 51.144119 loss_ctc_origin 32.645302 loss_ctc0 94.308022 lr 0.00066937 rank 0
2022-08-25 12:43:48,042 DEBUG TRAIN Batch 156/5500 loss 43.154259 loss_att 29.474758 loss_ctc 75.073097 loss_ctc_origin 44.124863 loss_ctc0 147.285645 lr 0.00066934 rank 0
2022-08-25 12:44:09,413 WARNING NaN or Inf found in input tensor.
2022-08-25 12:44:16,229 DEBUG TRAIN Batch 156/5600 loss 53.301746 loss_att 30.820007 loss_ctc 105.759132 loss_ctc_origin 59.379841 loss_ctc0 213.977478 lr 0.00066930 rank 0
2022-08-25 12:44:39,467 DEBUG CV Batch 156/0 loss 12.314067 loss_att 9.069594 loss_ctc 19.884502 loss_ctc_origin 13.447266 loss_ctc0 34.904720 history loss 11.589710 rank 0
2022-08-25 12:44:50,794 DEBUG CV Batch 156/100 loss 20.414152 loss_att 16.167366 loss_ctc 30.323318 loss_ctc_origin 20.328030 loss_ctc0 53.645657 history loss 25.855122 rank 0
2022-08-25 12:45:00,671 DEBUG CV Batch 156/200 loss 24.643747 loss_att 19.038216 loss_ctc 37.723320 loss_ctc_origin 27.317621 loss_ctc0 62.003288 history loss 27.039051 rank 0
2022-08-25 12:45:10,795 DEBUG CV Batch 156/300 loss 22.682669 loss_att 17.173996 loss_ctc 35.536236 loss_ctc_origin 20.124441 loss_ctc0 71.497086 history loss 26.199292 rank 0
2022-08-25 12:45:21,641 DEBUG CV Batch 156/400 loss 37.530243 loss_att 30.112305 loss_ctc 54.838768 loss_ctc_origin 37.895313 loss_ctc0 94.373489 history loss 24.624963 rank 0
2022-08-25 12:45:32,510 DEBUG CV Batch 156/500 loss 15.820915 loss_att 12.051252 loss_ctc 24.616795 loss_ctc_origin 17.002962 loss_ctc0 42.382404 history loss 24.332696 rank 0
2022-08-25 12:45:43,174 DEBUG CV Batch 156/600 loss 17.012648 loss_att 11.674128 loss_ctc 29.469194 loss_ctc_origin 18.732744 loss_ctc0 54.520912 history loss 24.162669 rank 0
2022-08-25 12:45:53,570 DEBUG CV Batch 156/700 loss 17.526388 loss_att 11.908545 loss_ctc 30.634687 loss_ctc_origin 16.916632 loss_ctc0 62.643482 history loss 23.829341 rank 0
2022-08-25 12:46:04,565 DEBUG CV Batch 156/800 loss 21.337002 loss_att 16.527153 loss_ctc 32.559982 loss_ctc_origin 17.106182 loss_ctc0 68.618851 history loss 23.800967 rank 0
2022-08-25 12:46:15,479 INFO Epoch 156 CV info cv_loss 23.89932128284268
2022-08-25 12:46:15,480 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/156.pt
2022-08-25 12:46:15,977 INFO Epoch 157 TRAIN info lr 0.0006692684857507883
2022-08-25 12:46:15,981 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 12:46:43,463 DEBUG TRAIN Batch 157/0 loss 49.982124 loss_att 33.457695 loss_ctc 88.539124 loss_ctc_origin 53.549717 loss_ctc0 170.181061 lr 0.00066927 rank 0
2022-08-25 12:47:13,188 DEBUG TRAIN Batch 157/100 loss 45.868851 loss_att 23.583935 loss_ctc 97.866982 loss_ctc_origin 52.705391 loss_ctc0 203.244019 lr 0.00066923 rank 0
2022-08-25 12:47:41,870 DEBUG TRAIN Batch 157/200 loss 20.779533 loss_att 10.598423 loss_ctc 44.535458 loss_ctc_origin 33.725998 loss_ctc0 69.757530 lr 0.00066919 rank 0
2022-08-25 12:48:10,173 DEBUG TRAIN Batch 157/300 loss 19.002808 loss_att 8.633266 loss_ctc 43.198402 loss_ctc_origin 28.834707 loss_ctc0 76.713684 lr 0.00066915 rank 0
2022-08-25 12:48:38,871 DEBUG TRAIN Batch 157/400 loss 24.568031 loss_att 10.445992 loss_ctc 57.519455 loss_ctc_origin 39.669655 loss_ctc0 99.168976 lr 0.00066912 rank 0
2022-08-25 12:49:06,540 DEBUG TRAIN Batch 157/500 loss 41.456261 loss_att 27.607668 loss_ctc 73.769638 loss_ctc_origin 46.121834 loss_ctc0 138.281189 lr 0.00066908 rank 0
2022-08-25 12:49:35,006 DEBUG TRAIN Batch 157/600 loss 52.634556 loss_att 29.367268 loss_ctc 106.924896 loss_ctc_origin 60.771973 loss_ctc0 214.615067 lr 0.00066904 rank 0
2022-08-25 12:50:04,185 DEBUG TRAIN Batch 157/700 loss 17.941122 loss_att 9.877800 loss_ctc 36.755539 loss_ctc_origin 24.516626 loss_ctc0 65.313004 lr 0.00066900 rank 0
2022-08-25 12:50:31,377 DEBUG TRAIN Batch 157/800 loss 16.418068 loss_att 6.465765 loss_ctc 39.640106 loss_ctc_origin 24.703405 loss_ctc0 74.492416 lr 0.00066897 rank 0
2022-08-25 12:50:59,269 DEBUG TRAIN Batch 157/900 loss 19.520771 loss_att 7.643677 loss_ctc 47.233990 loss_ctc_origin 29.577188 loss_ctc0 88.433189 lr 0.00066893 rank 0
2022-08-25 12:51:27,458 DEBUG TRAIN Batch 157/1000 loss 43.979046 loss_att 28.741898 loss_ctc 79.532394 loss_ctc_origin 47.825378 loss_ctc0 153.515427 lr 0.00066889 rank 0
2022-08-25 12:51:55,945 DEBUG TRAIN Batch 157/1100 loss 51.545078 loss_att 30.779200 loss_ctc 99.998795 loss_ctc_origin 51.606850 loss_ctc0 212.913315 lr 0.00066886 rank 0
2022-08-25 12:52:23,624 DEBUG TRAIN Batch 157/1200 loss 18.621403 loss_att 11.535189 loss_ctc 35.155903 loss_ctc_origin 24.199469 loss_ctc0 60.720909 lr 0.00066882 rank 0
2022-08-25 12:52:53,246 DEBUG TRAIN Batch 157/1300 loss 20.140965 loss_att 8.950696 loss_ctc 46.251591 loss_ctc_origin 32.068443 loss_ctc0 79.345596 lr 0.00066878 rank 0
2022-08-25 12:53:22,126 DEBUG TRAIN Batch 157/1400 loss 19.871063 loss_att 8.149553 loss_ctc 47.221256 loss_ctc_origin 27.244091 loss_ctc0 93.834641 lr 0.00066874 rank 0
2022-08-25 12:53:58,341 DEBUG TRAIN Batch 157/1500 loss 44.467209 loss_att 31.617481 loss_ctc 74.449913 loss_ctc_origin 49.074276 loss_ctc0 133.659729 lr 0.00066871 rank 0
2022-08-25 12:54:26,520 DEBUG TRAIN Batch 157/1600 loss 48.991562 loss_att 26.160591 loss_ctc 102.263824 loss_ctc_origin 57.215218 loss_ctc0 207.377228 lr 0.00066867 rank 0
2022-08-25 12:54:55,729 DEBUG TRAIN Batch 157/1700 loss 19.504995 loss_att 10.316402 loss_ctc 40.945045 loss_ctc_origin 29.599987 loss_ctc0 67.416847 lr 0.00066863 rank 0
2022-08-25 12:55:24,567 DEBUG TRAIN Batch 157/1800 loss 19.634222 loss_att 8.535955 loss_ctc 45.530174 loss_ctc_origin 29.116041 loss_ctc0 83.829819 lr 0.00066859 rank 0
2022-08-25 12:55:53,471 DEBUG TRAIN Batch 157/1900 loss 21.681915 loss_att 8.707078 loss_ctc 51.956532 loss_ctc_origin 35.221771 loss_ctc0 91.004303 lr 0.00066856 rank 0
2022-08-25 12:56:22,995 DEBUG TRAIN Batch 157/2000 loss 44.491219 loss_att 30.517315 loss_ctc 77.096985 loss_ctc_origin 44.898788 loss_ctc0 152.226105 lr 0.00066852 rank 0
2022-08-25 12:56:51,779 DEBUG TRAIN Batch 157/2100 loss 48.798241 loss_att 27.280968 loss_ctc 99.005211 loss_ctc_origin 56.240097 loss_ctc0 198.790466 lr 0.00066848 rank 0
2022-08-25 12:56:58,764 WARNING NaN or Inf found in input tensor.
2022-08-25 12:57:20,172 DEBUG TRAIN Batch 157/2200 loss 20.679262 loss_att 11.415029 loss_ctc 42.295803 loss_ctc_origin 31.374033 loss_ctc0 67.779930 lr 0.00066844 rank 0
2022-08-25 12:57:49,660 DEBUG TRAIN Batch 157/2300 loss 16.949749 loss_att 7.446368 loss_ctc 39.124306 loss_ctc_origin 23.841389 loss_ctc0 74.784439 lr 0.00066841 rank 0
2022-08-25 12:58:18,900 DEBUG TRAIN Batch 157/2400 loss 20.865620 loss_att 8.072300 loss_ctc 50.716694 loss_ctc_origin 32.400909 loss_ctc0 93.453522 lr 0.00066837 rank 0
2022-08-25 12:58:48,594 DEBUG TRAIN Batch 157/2500 loss 39.768795 loss_att 25.471912 loss_ctc 73.128189 loss_ctc_origin 48.216297 loss_ctc0 131.255920 lr 0.00066833 rank 0
2022-08-25 12:59:02,312 WARNING NaN or Inf found in input tensor.
2022-08-25 12:59:09,797 WARNING NaN or Inf found in input tensor.
2022-08-25 12:59:16,715 DEBUG TRAIN Batch 157/2600 loss 46.592850 loss_att 26.500534 loss_ctc 93.474915 loss_ctc_origin 47.650833 loss_ctc0 200.397766 lr 0.00066829 rank 0
2022-08-25 12:59:45,050 DEBUG TRAIN Batch 157/2700 loss 20.304806 loss_att 10.850895 loss_ctc 42.363930 loss_ctc_origin 32.359108 loss_ctc0 65.708511 lr 0.00066826 rank 0
2022-08-25 13:00:13,676 DEBUG TRAIN Batch 157/2800 loss 19.365959 loss_att 8.397657 loss_ctc 44.958664 loss_ctc_origin 31.554531 loss_ctc0 76.234978 lr 0.00066822 rank 0
2022-08-25 13:00:41,580 DEBUG TRAIN Batch 157/2900 loss 25.026857 loss_att 10.628232 loss_ctc 58.623650 loss_ctc_origin 41.635063 loss_ctc0 98.263687 lr 0.00066818 rank 0
2022-08-25 13:01:19,322 DEBUG TRAIN Batch 157/3000 loss 38.299339 loss_att 22.518715 loss_ctc 75.120789 loss_ctc_origin 43.744076 loss_ctc0 148.333130 lr 0.00066815 rank 0
2022-08-25 13:01:48,164 DEBUG TRAIN Batch 157/3100 loss 47.607605 loss_att 25.916553 loss_ctc 98.220062 loss_ctc_origin 57.515404 loss_ctc0 193.197617 lr 0.00066811 rank 0
2022-08-25 13:02:17,042 DEBUG TRAIN Batch 157/3200 loss 20.989801 loss_att 11.153582 loss_ctc 43.940979 loss_ctc_origin 33.027733 loss_ctc0 69.405212 lr 0.00066807 rank 0
2022-08-25 13:02:46,195 DEBUG TRAIN Batch 157/3300 loss 16.586880 loss_att 7.048398 loss_ctc 38.843338 loss_ctc_origin 24.450708 loss_ctc0 72.426147 lr 0.00066803 rank 0
2022-08-25 13:03:15,596 DEBUG TRAIN Batch 157/3400 loss 20.510939 loss_att 7.827489 loss_ctc 50.105652 loss_ctc_origin 31.780903 loss_ctc0 92.863403 lr 0.00066800 rank 0
2022-08-25 13:03:43,908 DEBUG TRAIN Batch 157/3500 loss 39.660740 loss_att 25.890781 loss_ctc 71.790642 loss_ctc_origin 44.703094 loss_ctc0 134.994904 lr 0.00066796 rank 0
2022-08-25 13:04:12,634 DEBUG TRAIN Batch 157/3600 loss 47.792015 loss_att 26.063557 loss_ctc 98.491745 loss_ctc_origin 53.419212 loss_ctc0 203.660980 lr 0.00066792 rank 0
2022-08-25 13:04:40,675 DEBUG TRAIN Batch 157/3700 loss 21.134212 loss_att 12.375903 loss_ctc 41.570267 loss_ctc_origin 32.683079 loss_ctc0 62.307030 lr 0.00066788 rank 0
2022-08-25 13:05:09,750 DEBUG TRAIN Batch 157/3800 loss 18.108997 loss_att 7.228628 loss_ctc 43.496529 loss_ctc_origin 28.516058 loss_ctc0 78.450958 lr 0.00066785 rank 0
2022-08-25 13:05:38,166 DEBUG TRAIN Batch 157/3900 loss 20.864544 loss_att 8.195031 loss_ctc 50.426743 loss_ctc_origin 31.963318 loss_ctc0 93.508057 lr 0.00066781 rank 0
2022-08-25 13:06:01,343 WARNING NaN or Inf found in input tensor.
2022-08-25 13:06:07,203 DEBUG TRAIN Batch 157/4000 loss 38.488617 loss_att 26.719566 loss_ctc 65.949738 loss_ctc_origin 40.628632 loss_ctc0 125.032303 lr 0.00066777 rank 0
2022-08-25 13:06:34,330 DEBUG TRAIN Batch 157/4100 loss 45.730904 loss_att 23.615217 loss_ctc 97.334167 loss_ctc_origin 50.328888 loss_ctc0 207.013153 lr 0.00066774 rank 0
2022-08-25 13:07:02,779 DEBUG TRAIN Batch 157/4200 loss 18.377657 loss_att 9.361939 loss_ctc 39.414330 loss_ctc_origin 25.302620 loss_ctc0 72.341652 lr 0.00066770 rank 0
2022-08-25 13:07:31,583 DEBUG TRAIN Batch 157/4300 loss 20.187981 loss_att 8.496562 loss_ctc 47.467957 loss_ctc_origin 33.337891 loss_ctc0 80.438103 lr 0.00066766 rank 0
2022-08-25 13:08:01,117 DEBUG TRAIN Batch 157/4400 loss 18.328356 loss_att 7.701427 loss_ctc 43.124523 loss_ctc_origin 25.152168 loss_ctc0 85.060013 lr 0.00066762 rank 0
2022-08-25 13:08:36,890 DEBUG TRAIN Batch 157/4500 loss 43.297775 loss_att 27.472456 loss_ctc 80.223511 loss_ctc_origin 45.068733 loss_ctc0 162.251312 lr 0.00066759 rank 0
2022-08-25 13:08:44,817 WARNING NaN or Inf found in input tensor.
2022-08-25 13:09:06,408 DEBUG TRAIN Batch 157/4600 loss 52.489738 loss_att 29.704613 loss_ctc 105.655037 loss_ctc_origin 58.406036 loss_ctc0 215.902710 lr 0.00066755 rank 0
2022-08-25 13:09:35,466 DEBUG TRAIN Batch 157/4700 loss 18.524849 loss_att 8.494453 loss_ctc 41.929104 loss_ctc_origin 30.442003 loss_ctc0 68.732338 lr 0.00066751 rank 0
2022-08-25 13:10:04,313 DEBUG TRAIN Batch 157/4800 loss 15.895559 loss_att 6.856332 loss_ctc 36.987087 loss_ctc_origin 21.894356 loss_ctc0 72.203461 lr 0.00066748 rank 0
2022-08-25 13:10:32,846 DEBUG TRAIN Batch 157/4900 loss 21.366583 loss_att 8.311306 loss_ctc 51.828896 loss_ctc_origin 34.040672 loss_ctc0 93.334740 lr 0.00066744 rank 0
2022-08-25 13:11:02,825 DEBUG TRAIN Batch 157/5000 loss 42.120956 loss_att 28.265190 loss_ctc 74.451080 loss_ctc_origin 44.763168 loss_ctc0 143.722870 lr 0.00066740 rank 0
2022-08-25 13:11:31,315 DEBUG TRAIN Batch 157/5100 loss 53.745689 loss_att 30.446699 loss_ctc 108.109985 loss_ctc_origin 61.730766 loss_ctc0 216.328156 lr 0.00066736 rank 0
2022-08-25 13:11:59,844 DEBUG TRAIN Batch 157/5200 loss 22.795321 loss_att 12.166614 loss_ctc 47.595634 loss_ctc_origin 37.606842 loss_ctc0 70.902817 lr 0.00066733 rank 0
2022-08-25 13:12:28,202 DEBUG TRAIN Batch 157/5300 loss 20.641384 loss_att 8.761831 loss_ctc 48.360344 loss_ctc_origin 31.919172 loss_ctc0 86.723083 lr 0.00066729 rank 0
2022-08-25 13:12:53,825 WARNING NaN or Inf found in input tensor.
2022-08-25 13:12:58,598 DEBUG TRAIN Batch 157/5400 loss 22.024235 loss_att 8.853645 loss_ctc 52.755608 loss_ctc_origin 35.003597 loss_ctc0 94.176971 lr 0.00066725 rank 0
2022-08-25 13:13:26,946 DEBUG TRAIN Batch 157/5500 loss 32.171253 loss_att 19.854603 loss_ctc 60.910099 loss_ctc_origin 36.729454 loss_ctc0 117.331604 lr 0.00066722 rank 0
2022-08-25 13:13:41,186 WARNING NaN or Inf found in input tensor.
2022-08-25 13:13:55,323 DEBUG TRAIN Batch 157/5600 loss 51.351273 loss_att 27.384724 loss_ctc 107.273224 loss_ctc_origin 61.644611 loss_ctc0 213.739960 lr 0.00066718 rank 0
2022-08-25 13:14:18,693 DEBUG CV Batch 157/0 loss 12.382334 loss_att 9.174238 loss_ctc 19.867891 loss_ctc_origin 13.821497 loss_ctc0 33.976143 history loss 11.653961 rank 0
2022-08-25 13:14:29,054 DEBUG CV Batch 157/100 loss 21.310892 loss_att 17.522114 loss_ctc 30.151377 loss_ctc_origin 20.497566 loss_ctc0 52.676933 history loss 26.097705 rank 0
2022-08-25 13:14:38,266 DEBUG CV Batch 157/200 loss 25.191292 loss_att 19.659779 loss_ctc 38.098160 loss_ctc_origin 28.113243 loss_ctc0 61.396290 history loss 27.548602 rank 0
2022-08-25 13:14:48,299 DEBUG CV Batch 157/300 loss 23.769936 loss_att 18.424520 loss_ctc 36.242565 loss_ctc_origin 21.269470 loss_ctc0 71.179779 history loss 26.591372 rank 0
2022-08-25 13:14:58,327 DEBUG CV Batch 157/400 loss 37.447346 loss_att 29.875834 loss_ctc 55.114204 loss_ctc_origin 38.283840 loss_ctc0 94.385056 history loss 24.978160 rank 0
2022-08-25 13:15:08,378 DEBUG CV Batch 157/500 loss 16.261402 loss_att 12.153579 loss_ctc 25.846323 loss_ctc_origin 18.897007 loss_ctc0 42.061394 history loss 24.652464 rank 0
2022-08-25 13:15:18,572 DEBUG CV Batch 157/600 loss 17.135014 loss_att 12.051760 loss_ctc 28.995941 loss_ctc_origin 18.403027 loss_ctc0 53.712738 history loss 24.494343 rank 0
2022-08-25 13:15:28,245 DEBUG CV Batch 157/700 loss 18.275715 loss_att 12.565929 loss_ctc 31.598549 loss_ctc_origin 17.961159 loss_ctc0 63.419121 history loss 24.149920 rank 0
2022-08-25 13:15:38,448 DEBUG CV Batch 157/800 loss 21.576191 loss_att 16.981325 loss_ctc 32.297546 loss_ctc_origin 16.868427 loss_ctc0 68.298828 history loss 24.109827 rank 0
2022-08-25 13:15:48,459 INFO Epoch 157 CV info cv_loss 24.178368463048283
2022-08-25 13:15:48,459 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/157.pt
2022-08-25 13:15:48,913 INFO Epoch 158 TRAIN info lr 0.0006671471856895314
2022-08-25 13:15:48,917 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 13:16:16,262 DEBUG TRAIN Batch 158/0 loss 44.054070 loss_att 28.173275 loss_ctc 81.109253 loss_ctc_origin 49.848106 loss_ctc0 154.051910 lr 0.00066715 rank 0
2022-08-25 13:16:45,853 DEBUG TRAIN Batch 158/100 loss 49.090561 loss_att 25.909811 loss_ctc 103.178970 loss_ctc_origin 55.655075 loss_ctc0 214.068024 lr 0.00066711 rank 0
2022-08-25 13:17:14,819 DEBUG TRAIN Batch 158/200 loss 19.322735 loss_att 9.490613 loss_ctc 42.264351 loss_ctc_origin 32.885529 loss_ctc0 64.148270 lr 0.00066707 rank 0
2022-08-25 13:17:43,552 DEBUG TRAIN Batch 158/300 loss 17.473124 loss_att 7.496438 loss_ctc 40.752052 loss_ctc_origin 25.478832 loss_ctc0 76.389572 lr 0.00066703 rank 0
2022-08-25 13:18:12,003 DEBUG TRAIN Batch 158/400 loss 21.024174 loss_att 7.806149 loss_ctc 51.866226 loss_ctc_origin 31.603542 loss_ctc0 99.145828 lr 0.00066700 rank 0
2022-08-25 13:18:41,601 DEBUG TRAIN Batch 158/500 loss 42.670616 loss_att 28.814983 loss_ctc 75.000427 loss_ctc_origin 48.763916 loss_ctc0 136.218964 lr 0.00066696 rank 0
2022-08-25 13:18:42,382 WARNING NaN or Inf found in input tensor.
2022-08-25 13:18:50,781 WARNING NaN or Inf found in input tensor.
2022-08-25 13:19:03,055 WARNING NaN or Inf found in input tensor.
2022-08-25 13:19:10,008 DEBUG TRAIN Batch 158/600 loss 48.231781 loss_att 27.014252 loss_ctc 97.739357 loss_ctc_origin 51.793133 loss_ctc0 204.947205 lr 0.00066692 rank 0
2022-08-25 13:19:39,891 DEBUG TRAIN Batch 158/700 loss 21.257877 loss_att 12.442255 loss_ctc 41.827660 loss_ctc_origin 31.657619 loss_ctc0 65.557747 lr 0.00066689 rank 0
2022-08-25 13:20:07,532 DEBUG TRAIN Batch 158/800 loss 17.821987 loss_att 6.479454 loss_ctc 44.287895 loss_ctc_origin 29.256454 loss_ctc0 79.361259 lr 0.00066685 rank 0
2022-08-25 13:20:37,335 DEBUG TRAIN Batch 158/900 loss 22.688950 loss_att 10.040453 loss_ctc 52.202106 loss_ctc_origin 35.236580 loss_ctc0 91.788330 lr 0.00066681 rank 0
2022-08-25 13:21:07,730 DEBUG TRAIN Batch 158/1000 loss 42.938381 loss_att 28.717577 loss_ctc 76.120255 loss_ctc_origin 49.997169 loss_ctc0 137.074127 lr 0.00066677 rank 0
2022-08-25 13:21:35,930 DEBUG TRAIN Batch 158/1100 loss 54.124699 loss_att 32.905670 loss_ctc 103.635765 loss_ctc_origin 61.267532 loss_ctc0 202.494965 lr 0.00066674 rank 0
2022-08-25 13:22:04,843 DEBUG TRAIN Batch 158/1200 loss 17.695614 loss_att 9.852787 loss_ctc 35.995544 loss_ctc_origin 24.349594 loss_ctc0 63.169434 lr 0.00066670 rank 0
2022-08-25 13:22:34,675 DEBUG TRAIN Batch 158/1300 loss 20.247736 loss_att 8.355946 loss_ctc 47.995247 loss_ctc_origin 31.324524 loss_ctc0 86.893608 lr 0.00066666 rank 0
2022-08-25 13:23:03,961 DEBUG TRAIN Batch 158/1400 loss 20.490162 loss_att 7.881210 loss_ctc 49.911049 loss_ctc_origin 30.397335 loss_ctc0 95.443039 lr 0.00066663 rank 0
2022-08-25 13:23:38,652 DEBUG TRAIN Batch 158/1500 loss 42.411057 loss_att 23.299757 loss_ctc 87.004082 loss_ctc_origin 46.878845 loss_ctc0 180.629639 lr 0.00066659 rank 0
2022-08-25 13:24:07,294 DEBUG TRAIN Batch 158/1600 loss 48.971298 loss_att 26.720734 loss_ctc 100.889282 loss_ctc_origin 50.304115 loss_ctc0 218.921356 lr 0.00066655 rank 0
2022-08-25 13:24:36,285 DEBUG TRAIN Batch 158/1700 loss 23.176949 loss_att 13.326940 loss_ctc 46.160301 loss_ctc_origin 36.511894 loss_ctc0 68.673256 lr 0.00066652 rank 0
2022-08-25 13:25:05,532 DEBUG TRAIN Batch 158/1800 loss 22.478485 loss_att 10.960936 loss_ctc 49.352768 loss_ctc_origin 38.369705 loss_ctc0 74.979904 lr 0.00066648 rank 0
2022-08-25 13:25:15,890 WARNING NaN or Inf found in input tensor.
2022-08-25 13:25:34,143 DEBUG TRAIN Batch 158/1900 loss 21.877340 loss_att 8.270037 loss_ctc 53.627708 loss_ctc_origin 35.541443 loss_ctc0 95.828995 lr 0.00066644 rank 0
2022-08-25 13:26:03,202 DEBUG TRAIN Batch 158/2000 loss 41.043541 loss_att 26.681889 loss_ctc 74.554062 loss_ctc_origin 46.490921 loss_ctc0 140.034729 lr 0.00066640 rank 0
2022-08-25 13:26:32,388 DEBUG TRAIN Batch 158/2100 loss 56.407677 loss_att 32.137764 loss_ctc 113.037460 loss_ctc_origin 67.409462 loss_ctc0 219.502777 lr 0.00066637 rank 0
2022-08-25 13:27:01,654 DEBUG TRAIN Batch 158/2200 loss 19.436888 loss_att 10.949801 loss_ctc 39.240089 loss_ctc_origin 28.292944 loss_ctc0 64.783417 lr 0.00066633 rank 0
2022-08-25 13:27:29,391 DEBUG TRAIN Batch 158/2300 loss 18.610249 loss_att 7.500316 loss_ctc 44.533424 loss_ctc_origin 29.677114 loss_ctc0 79.198151 lr 0.00066629 rank 0
2022-08-25 13:27:58,526 DEBUG TRAIN Batch 158/2400 loss 24.154898 loss_att 11.899529 loss_ctc 52.750755 loss_ctc_origin 34.004360 loss_ctc0 96.492340 lr 0.00066626 rank 0
2022-08-25 13:28:27,997 DEBUG TRAIN Batch 158/2500 loss 42.329727 loss_att 27.928343 loss_ctc 75.932961 loss_ctc_origin 42.384300 loss_ctc0 154.213165 lr 0.00066622 rank 0
2022-08-25 13:28:56,349 DEBUG TRAIN Batch 158/2600 loss 51.410027 loss_att 28.085108 loss_ctc 105.834831 loss_ctc_origin 58.817032 loss_ctc0 215.543015 lr 0.00066618 rank 0
2022-08-25 13:29:25,242 DEBUG TRAIN Batch 158/2700 loss 21.653236 loss_att 11.741537 loss_ctc 44.780537 loss_ctc_origin 32.304848 loss_ctc0 73.890472 lr 0.00066615 rank 0
2022-08-25 13:29:53,848 DEBUG TRAIN Batch 158/2800 loss 20.721237 loss_att 9.370884 loss_ctc 47.205391 loss_ctc_origin 31.968143 loss_ctc0 82.758972 lr 0.00066611 rank 0
2022-08-25 13:30:18,297 WARNING NaN or Inf found in input tensor.
2022-08-25 13:30:22,791 DEBUG TRAIN Batch 158/2900 loss 22.100616 loss_att 9.514491 loss_ctc 51.468239 loss_ctc_origin 31.261297 loss_ctc0 98.617775 lr 0.00066607 rank 0
2022-08-25 13:30:57,522 DEBUG TRAIN Batch 158/3000 loss 48.798775 loss_att 34.752232 loss_ctc 81.574043 loss_ctc_origin 54.489094 loss_ctc0 144.772263 lr 0.00066603 rank 0
2022-08-25 13:31:25,591 DEBUG TRAIN Batch 158/3100 loss 59.339874 loss_att 36.361404 loss_ctc 112.956306 loss_ctc_origin 64.517136 loss_ctc0 225.981018 lr 0.00066600 rank 0
2022-08-25 13:31:53,920 DEBUG TRAIN Batch 158/3200 loss 18.898439 loss_att 9.434749 loss_ctc 40.980381 loss_ctc_origin 30.688335 loss_ctc0 64.995155 lr 0.00066596 rank 0
2022-08-25 13:32:23,017 DEBUG TRAIN Batch 158/3300 loss 20.512085 loss_att 9.509592 loss_ctc 46.184570 loss_ctc_origin 30.260828 loss_ctc0 83.339973 lr 0.00066592 rank 0
2022-08-25 13:32:52,042 DEBUG TRAIN Batch 158/3400 loss 21.804853 loss_att 9.497372 loss_ctc 50.522308 loss_ctc_origin 31.462673 loss_ctc0 94.994789 lr 0.00066589 rank 0
2022-08-25 13:33:20,420 DEBUG TRAIN Batch 158/3500 loss 44.909889 loss_att 27.393677 loss_ctc 85.781052 loss_ctc_origin 50.684174 loss_ctc0 167.673767 lr 0.00066585 rank 0
2022-08-25 13:33:47,917 DEBUG TRAIN Batch 158/3600 loss 56.544342 loss_att 31.118368 loss_ctc 115.871620 loss_ctc_origin 59.987923 loss_ctc0 246.266907 lr 0.00066581 rank 0
2022-08-25 13:34:15,749 DEBUG TRAIN Batch 158/3700 loss 20.499905 loss_att 9.215206 loss_ctc 46.830868 loss_ctc_origin 36.526272 loss_ctc0 70.874924 lr 0.00066578 rank 0
2022-08-25 13:34:44,741 DEBUG TRAIN Batch 158/3800 loss 19.843124 loss_att 8.347915 loss_ctc 46.665283 loss_ctc_origin 33.192558 loss_ctc0 78.101639 lr 0.00066574 rank 0
2022-08-25 13:35:13,683 DEBUG TRAIN Batch 158/3900 loss 20.613846 loss_att 8.426357 loss_ctc 49.051315 loss_ctc_origin 30.553446 loss_ctc0 92.213005 lr 0.00066570 rank 0
2022-08-25 13:35:42,825 DEBUG TRAIN Batch 158/4000 loss 40.404686 loss_att 26.149120 loss_ctc 73.667671 loss_ctc_origin 44.497185 loss_ctc0 141.732132 lr 0.00066567 rank 0
2022-08-25 13:36:11,634 DEBUG TRAIN Batch 158/4100 loss 53.183044 loss_att 26.785385 loss_ctc 114.777588 loss_ctc_origin 58.191811 loss_ctc0 246.811066 lr 0.00066563 rank 0
2022-08-25 13:36:41,030 DEBUG TRAIN Batch 158/4200 loss 17.941837 loss_att 9.205582 loss_ctc 38.326431 loss_ctc_origin 26.242058 loss_ctc0 66.523300 lr 0.00066559 rank 0
2022-08-25 13:37:08,668 DEBUG TRAIN Batch 158/4300 loss 18.336746 loss_att 7.567434 loss_ctc 43.465141 loss_ctc_origin 28.357510 loss_ctc0 78.716278 lr 0.00066556 rank 0
2022-08-25 13:37:19,214 WARNING NaN or Inf found in input tensor.
2022-08-25 13:37:37,026 DEBUG TRAIN Batch 158/4400 loss 24.997768 loss_att 10.982812 loss_ctc 57.699333 loss_ctc_origin 40.821156 loss_ctc0 97.081741 lr 0.00066552 rank 0
2022-08-25 13:38:12,596 DEBUG TRAIN Batch 158/4500 loss 49.821068 loss_att 34.527824 loss_ctc 85.505295 loss_ctc_origin 55.687698 loss_ctc0 155.079666 lr 0.00066548 rank 0
2022-08-25 13:38:41,731 DEBUG TRAIN Batch 158/4600 loss 54.116707 loss_att 30.414333 loss_ctc 109.422241 loss_ctc_origin 56.041901 loss_ctc0 233.976379 lr 0.00066544 rank 0
2022-08-25 13:39:11,216 DEBUG TRAIN Batch 158/4700 loss 17.455147 loss_att 7.243255 loss_ctc 41.282898 loss_ctc_origin 28.138628 loss_ctc0 71.952866 lr 0.00066541 rank 0
2022-08-25 13:39:39,162 DEBUG TRAIN Batch 158/4800 loss 24.982298 loss_att 11.259712 loss_ctc 57.001663 loss_ctc_origin 42.917511 loss_ctc0 89.864685 lr 0.00066537 rank 0
2022-08-25 13:40:08,910 DEBUG TRAIN Batch 158/4900 loss 20.276455 loss_att 8.671204 loss_ctc 47.355377 loss_ctc_origin 29.539730 loss_ctc0 88.925217 lr 0.00066533 rank 0
2022-08-25 13:40:37,798 DEBUG TRAIN Batch 158/5000 loss 38.996300 loss_att 24.143795 loss_ctc 73.652145 loss_ctc_origin 40.859894 loss_ctc0 150.167389 lr 0.00066530 rank 0
2022-08-25 13:41:06,529 DEBUG TRAIN Batch 158/5100 loss 52.352303 loss_att 29.484167 loss_ctc 105.711288 loss_ctc_origin 53.675690 loss_ctc0 227.127686 lr 0.00066526 rank 0
2022-08-25 13:41:35,172 DEBUG TRAIN Batch 158/5200 loss 17.974705 loss_att 8.666486 loss_ctc 39.693878 loss_ctc_origin 26.242697 loss_ctc0 71.079956 lr 0.00066522 rank 0
2022-08-25 13:42:03,695 DEBUG TRAIN Batch 158/5300 loss 19.970076 loss_att 8.772491 loss_ctc 46.097771 loss_ctc_origin 31.977505 loss_ctc0 79.045059 lr 0.00066519 rank 0
2022-08-25 13:42:32,469 DEBUG TRAIN Batch 158/5400 loss 22.681858 loss_att 9.757149 loss_ctc 52.839512 loss_ctc_origin 33.434540 loss_ctc0 98.117783 lr 0.00066515 rank 0
2022-08-25 13:43:01,870 DEBUG TRAIN Batch 158/5500 loss 42.742874 loss_att 27.566486 loss_ctc 78.154449 loss_ctc_origin 46.795898 loss_ctc0 151.324387 lr 0.00066511 rank 0
2022-08-25 13:43:29,594 DEBUG TRAIN Batch 158/5600 loss 56.237930 loss_att 31.734234 loss_ctc 113.413223 loss_ctc_origin 64.517365 loss_ctc0 227.503540 lr 0.00066508 rank 0
2022-08-25 13:43:51,709 DEBUG CV Batch 158/0 loss 12.593870 loss_att 9.446447 loss_ctc 19.937855 loss_ctc_origin 13.942339 loss_ctc0 33.927391 history loss 11.853054 rank 0
2022-08-25 13:44:01,816 DEBUG CV Batch 158/100 loss 20.693462 loss_att 16.723160 loss_ctc 29.957497 loss_ctc_origin 20.484690 loss_ctc0 52.060707 history loss 26.194718 rank 0
2022-08-25 13:44:10,956 DEBUG CV Batch 158/200 loss 23.743723 loss_att 18.530371 loss_ctc 35.908211 loss_ctc_origin 25.327866 loss_ctc0 60.595673 history loss 27.410763 rank 0
2022-08-25 13:44:20,744 DEBUG CV Batch 158/300 loss 22.607985 loss_att 17.147751 loss_ctc 35.348530 loss_ctc_origin 19.822697 loss_ctc0 71.575470 history loss 26.536938 rank 0
2022-08-25 13:44:30,676 DEBUG CV Batch 158/400 loss 36.938866 loss_att 29.299675 loss_ctc 54.763641 loss_ctc_origin 37.495056 loss_ctc0 95.057007 history loss 24.964193 rank 0
2022-08-25 13:44:40,576 DEBUG CV Batch 158/500 loss 15.787443 loss_att 11.711921 loss_ctc 25.296993 loss_ctc_origin 18.194523 loss_ctc0 41.869427 history loss 24.693970 rank 0
2022-08-25 13:44:51,374 DEBUG CV Batch 158/600 loss 17.578468 loss_att 12.306170 loss_ctc 29.880497 loss_ctc_origin 19.426163 loss_ctc0 54.273949 history loss 24.549039 rank 0
2022-08-25 13:45:01,066 DEBUG CV Batch 158/700 loss 17.929514 loss_att 12.196060 loss_ctc 31.307571 loss_ctc_origin 17.481312 loss_ctc0 63.568844 history loss 24.236169 rank 0
2022-08-25 13:45:10,246 DEBUG CV Batch 158/800 loss 21.989262 loss_att 17.302992 loss_ctc 32.923889 loss_ctc_origin 17.604839 loss_ctc0 68.668335 history loss 24.212154 rank 0
2022-08-25 13:45:21,098 INFO Epoch 158 CV info cv_loss 24.28927482742903
2022-08-25 13:45:21,099 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/158.pt
2022-08-25 13:45:21,577 INFO Epoch 159 TRAIN info lr 0.0006650459294916236
2022-08-25 13:45:21,581 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 13:45:49,402 DEBUG TRAIN Batch 159/0 loss 42.200035 loss_att 27.648180 loss_ctc 76.154358 loss_ctc_origin 51.024132 loss_ctc0 134.791550 lr 0.00066504 rank 0
2022-08-25 13:45:57,700 WARNING NaN or Inf found in input tensor.
2022-08-25 13:46:18,723 DEBUG TRAIN Batch 159/100 loss 51.732063 loss_att 27.819553 loss_ctc 107.527916 loss_ctc_origin 54.805027 loss_ctc0 230.547989 lr 0.00066501 rank 0
2022-08-25 13:46:48,443 DEBUG TRAIN Batch 159/200 loss 19.060844 loss_att 9.285558 loss_ctc 41.869843 loss_ctc_origin 28.665112 loss_ctc0 72.680878 lr 0.00066497 rank 0
2022-08-25 13:47:16,859 DEBUG TRAIN Batch 159/300 loss 20.642399 loss_att 9.011497 loss_ctc 47.781166 loss_ctc_origin 34.103256 loss_ctc0 79.696297 lr 0.00066493 rank 0
2022-08-25 13:47:45,818 DEBUG TRAIN Batch 159/400 loss 19.278692 loss_att 7.983170 loss_ctc 45.634911 loss_ctc_origin 28.213743 loss_ctc0 86.284302 lr 0.00066490 rank 0
2022-08-25 13:48:13,939 DEBUG TRAIN Batch 159/500 loss 44.117943 loss_att 29.319098 loss_ctc 78.648575 loss_ctc_origin 48.057014 loss_ctc0 150.028900 lr 0.00066486 rank 0
2022-08-25 13:48:43,151 DEBUG TRAIN Batch 159/600 loss 48.567230 loss_att 25.472887 loss_ctc 102.454025 loss_ctc_origin 53.368992 loss_ctc0 216.985733 lr 0.00066482 rank 0
2022-08-25 13:49:11,111 DEBUG TRAIN Batch 159/700 loss 19.038902 loss_att 9.506901 loss_ctc 41.280239 loss_ctc_origin 29.740585 loss_ctc0 68.206100 lr 0.00066479 rank 0
2022-08-25 13:49:39,006 DEBUG TRAIN Batch 159/800 loss 18.392265 loss_att 7.215718 loss_ctc 44.470879 loss_ctc_origin 28.841316 loss_ctc0 80.939850 lr 0.00066475 rank 0
2022-08-25 13:50:08,144 DEBUG TRAIN Batch 159/900 loss 22.995729 loss_att 8.765267 loss_ctc 56.200142 loss_ctc_origin 39.091915 loss_ctc0 96.119331 lr 0.00066471 rank 0
2022-08-25 13:50:36,234 DEBUG TRAIN Batch 159/1000 loss 38.947598 loss_att 25.066448 loss_ctc 71.336945 loss_ctc_origin 40.234177 loss_ctc0 143.910065 lr 0.00066468 rank 0
2022-08-25 13:51:03,688 DEBUG TRAIN Batch 159/1100 loss 49.761700 loss_att 26.925989 loss_ctc 103.045021 loss_ctc_origin 53.311649 loss_ctc0 219.089554 lr 0.00066464 rank 0
2022-08-25 13:51:33,214 DEBUG TRAIN Batch 159/1200 loss 19.763737 loss_att 9.650574 loss_ctc 43.361115 loss_ctc_origin 30.924341 loss_ctc0 72.380241 lr 0.00066460 rank 0
2022-08-25 13:51:43,737 WARNING NaN or Inf found in input tensor.
2022-08-25 13:52:00,732 DEBUG TRAIN Batch 159/1300 loss 17.363878 loss_att 6.893242 loss_ctc 41.795364 loss_ctc_origin 25.846657 loss_ctc0 79.009018 lr 0.00066457 rank 0
2022-08-25 13:52:24,278 WARNING NaN or Inf found in input tensor.
2022-08-25 13:52:28,739 DEBUG TRAIN Batch 159/1400 loss 21.309256 loss_att 8.784991 loss_ctc 50.532536 loss_ctc_origin 31.143444 loss_ctc0 95.773743 lr 0.00066453 rank 0
2022-08-25 13:53:03,191 DEBUG TRAIN Batch 159/1500 loss 44.594822 loss_att 29.838928 loss_ctc 79.025238 loss_ctc_origin 51.139553 loss_ctc0 144.091827 lr 0.00066449 rank 0
2022-08-25 13:53:31,835 DEBUG TRAIN Batch 159/1600 loss 51.514458 loss_att 29.803087 loss_ctc 102.174316 loss_ctc_origin 60.673050 loss_ctc0 199.010590 lr 0.00066446 rank 0
2022-08-25 13:54:01,117 DEBUG TRAIN Batch 159/1700 loss 20.419064 loss_att 10.748824 loss_ctc 42.982952 loss_ctc_origin 31.005955 loss_ctc0 70.929276 lr 0.00066442 rank 0
2022-08-25 13:54:30,819 DEBUG TRAIN Batch 159/1800 loss 17.894951 loss_att 7.135513 loss_ctc 43.000301 loss_ctc_origin 27.866619 loss_ctc0 78.312225 lr 0.00066438 rank 0
2022-08-25 13:54:59,112 DEBUG TRAIN Batch 159/1900 loss 18.024029 loss_att 7.382017 loss_ctc 42.855392 loss_ctc_origin 24.853016 loss_ctc0 84.860947 lr 0.00066435 rank 0
2022-08-25 13:55:28,321 DEBUG TRAIN Batch 159/2000 loss 43.192749 loss_att 29.558914 loss_ctc 75.005020 loss_ctc_origin 48.130325 loss_ctc0 137.712646 lr 0.00066431 rank 0
2022-08-25 13:55:56,213 DEBUG TRAIN Batch 159/2100 loss 49.998692 loss_att 27.524897 loss_ctc 102.437546 loss_ctc_origin 54.416714 loss_ctc0 214.486145 lr 0.00066427 rank 0
2022-08-25 13:56:24,909 DEBUG TRAIN Batch 159/2200 loss 22.776245 loss_att 13.693291 loss_ctc 43.969803 loss_ctc_origin 33.571495 loss_ctc0 68.232529 lr 0.00066424 rank 0
2022-08-25 13:56:54,302 DEBUG TRAIN Batch 159/2300 loss 17.810196 loss_att 7.793086 loss_ctc 41.183453 loss_ctc_origin 24.315472 loss_ctc0 80.542068 lr 0.00066420 rank 0
2022-08-25 13:57:23,585 DEBUG TRAIN Batch 159/2400 loss 18.157784 loss_att 7.352279 loss_ctc 43.370628 loss_ctc_origin 25.315960 loss_ctc0 85.498192 lr 0.00066416 rank 0
2022-08-25 13:57:52,811 DEBUG TRAIN Batch 159/2500 loss 42.074982 loss_att 28.089191 loss_ctc 74.708488 loss_ctc_origin 49.183559 loss_ctc0 134.266663 lr 0.00066413 rank 0
2022-08-25 13:58:21,494 DEBUG TRAIN Batch 159/2600 loss 43.032936 loss_att 24.090805 loss_ctc 87.231247 loss_ctc_origin 46.794643 loss_ctc0 181.583313 lr 0.00066409 rank 0
2022-08-25 13:58:51,014 DEBUG TRAIN Batch 159/2700 loss 17.854395 loss_att 9.451830 loss_ctc 37.460377 loss_ctc_origin 27.254728 loss_ctc0 61.273552 lr 0.00066405 rank 0
2022-08-25 13:59:02,479 WARNING NaN or Inf found in input tensor.
2022-08-25 13:59:19,468 DEBUG TRAIN Batch 159/2800 loss 17.361364 loss_att 7.279444 loss_ctc 40.885841 loss_ctc_origin 27.893801 loss_ctc0 71.200607 lr 0.00066402 rank 0
2022-08-25 13:59:36,431 WARNING NaN or Inf found in input tensor.
2022-08-25 13:59:48,448 DEBUG TRAIN Batch 159/2900 loss 18.764891 loss_att 7.648020 loss_ctc 44.704254 loss_ctc_origin 26.792675 loss_ctc0 86.497940 lr 0.00066398 rank 0
2022-08-25 14:00:24,416 DEBUG TRAIN Batch 159/3000 loss 52.288750 loss_att 35.308838 loss_ctc 91.908539 loss_ctc_origin 60.405849 loss_ctc0 165.414795 lr 0.00066394 rank 0
2022-08-25 14:00:53,267 DEBUG TRAIN Batch 159/3100 loss 56.502213 loss_att 31.970911 loss_ctc 113.741913 loss_ctc_origin 61.017189 loss_ctc0 236.766266 lr 0.00066391 rank 0
2022-08-25 14:01:21,550 DEBUG TRAIN Batch 159/3200 loss 18.547932 loss_att 9.665287 loss_ctc 39.274101 loss_ctc_origin 28.445732 loss_ctc0 64.540298 lr 0.00066387 rank 0
2022-08-25 14:01:50,423 DEBUG TRAIN Batch 159/3300 loss 17.154835 loss_att 6.802301 loss_ctc 41.310745 loss_ctc_origin 26.145359 loss_ctc0 76.696655 lr 0.00066383 rank 0
2022-08-25 14:02:19,133 DEBUG TRAIN Batch 159/3400 loss 17.528492 loss_att 7.202928 loss_ctc 41.621471 loss_ctc_origin 24.194189 loss_ctc0 82.285126 lr 0.00066380 rank 0
2022-08-25 14:02:48,309 DEBUG TRAIN Batch 159/3500 loss 44.257523 loss_att 31.874371 loss_ctc 73.151550 loss_ctc_origin 44.749104 loss_ctc0 139.423920 lr 0.00066376 rank 0
2022-08-25 14:03:17,036 DEBUG TRAIN Batch 159/3600 loss 50.929291 loss_att 28.564915 loss_ctc 103.112839 loss_ctc_origin 56.231678 loss_ctc0 212.502213 lr 0.00066372 rank 0
2022-08-25 14:03:45,293 DEBUG TRAIN Batch 159/3700 loss 17.607533 loss_att 9.936243 loss_ctc 35.507210 loss_ctc_origin 25.033524 loss_ctc0 59.945801 lr 0.00066369 rank 0
2022-08-25 14:04:14,065 DEBUG TRAIN Batch 159/3800 loss 19.133228 loss_att 8.898674 loss_ctc 43.013855 loss_ctc_origin 27.544558 loss_ctc0 79.108879 lr 0.00066365 rank 0
2022-08-25 14:04:43,217 DEBUG TRAIN Batch 159/3900 loss 21.116394 loss_att 8.545854 loss_ctc 50.447651 loss_ctc_origin 34.556194 loss_ctc0 87.527718 lr 0.00066362 rank 0
2022-08-25 14:05:13,024 DEBUG TRAIN Batch 159/4000 loss 47.359081 loss_att 32.523376 loss_ctc 81.975723 loss_ctc_origin 51.910294 loss_ctc0 152.128403 lr 0.00066358 rank 0
2022-08-25 14:05:40,628 DEBUG TRAIN Batch 159/4100 loss 51.598076 loss_att 28.497946 loss_ctc 105.498367 loss_ctc_origin 64.559952 loss_ctc0 201.021332 lr 0.00066354 rank 0
2022-08-25 14:06:10,556 DEBUG TRAIN Batch 159/4200 loss 21.792622 loss_att 12.287879 loss_ctc 43.970352 loss_ctc_origin 33.316040 loss_ctc0 68.830414 lr 0.00066351 rank 0
2022-08-25 14:06:39,392 DEBUG TRAIN Batch 159/4300 loss 16.374611 loss_att 6.912402 loss_ctc 38.453094 loss_ctc_origin 23.004723 loss_ctc0 74.499298 lr 0.00066347 rank 0
2022-08-25 14:07:09,662 DEBUG TRAIN Batch 159/4400 loss 19.944927 loss_att 8.213608 loss_ctc 47.318001 loss_ctc_origin 27.436646 loss_ctc0 93.707825 lr 0.00066343 rank 0
2022-08-25 14:07:45,231 DEBUG TRAIN Batch 159/4500 loss 45.948521 loss_att 30.940601 loss_ctc 80.966995 loss_ctc_origin 51.893494 loss_ctc0 148.805176 lr 0.00066340 rank 0
2022-08-25 14:07:53,122 WARNING NaN or Inf found in input tensor.
2022-08-25 14:08:14,026 DEBUG TRAIN Batch 159/4600 loss 49.913292 loss_att 26.275223 loss_ctc 105.068779 loss_ctc_origin 55.020580 loss_ctc0 221.847900 lr 0.00066336 rank 0
2022-08-25 14:08:42,701 DEBUG TRAIN Batch 159/4700 loss 17.817223 loss_att 9.118419 loss_ctc 38.114433 loss_ctc_origin 26.851917 loss_ctc0 64.393639 lr 0.00066332 rank 0
2022-08-25 14:09:11,381 DEBUG TRAIN Batch 159/4800 loss 19.511639 loss_att 8.712912 loss_ctc 44.708664 loss_ctc_origin 31.422886 loss_ctc0 75.708817 lr 0.00066329 rank 0
2022-08-25 14:09:40,580 DEBUG TRAIN Batch 159/4900 loss 27.581827 loss_att 12.342998 loss_ctc 63.139091 loss_ctc_origin 44.703064 loss_ctc0 106.156479 lr 0.00066325 rank 0
2022-08-25 14:10:09,363 DEBUG TRAIN Batch 159/5000 loss 45.001347 loss_att 31.487514 loss_ctc 76.533623 loss_ctc_origin 44.939323 loss_ctc0 150.253662 lr 0.00066321 rank 0
2022-08-25 14:10:37,360 DEBUG TRAIN Batch 159/5100 loss 55.442940 loss_att 32.281204 loss_ctc 109.486984 loss_ctc_origin 64.686447 loss_ctc0 214.021545 lr 0.00066318 rank 0
2022-08-25 14:11:06,789 DEBUG TRAIN Batch 159/5200 loss 14.940783 loss_att 8.108152 loss_ctc 30.883583 loss_ctc_origin 18.965008 loss_ctc0 58.693588 lr 0.00066314 rank 0
2022-08-25 14:11:12,301 WARNING NaN or Inf found in input tensor.
2022-08-25 14:11:34,768 DEBUG TRAIN Batch 159/5300 loss 17.360205 loss_att 7.289258 loss_ctc 40.859077 loss_ctc_origin 26.557011 loss_ctc0 74.230576 lr 0.00066310 rank 0
2022-08-25 14:12:04,169 DEBUG TRAIN Batch 159/5400 loss 20.544291 loss_att 8.591120 loss_ctc 48.435020 loss_ctc_origin 32.325321 loss_ctc0 86.024315 lr 0.00066307 rank 0
2022-08-25 14:12:32,139 DEBUG TRAIN Batch 159/5500 loss 48.916454 loss_att 35.211845 loss_ctc 80.893875 loss_ctc_origin 51.169144 loss_ctc0 150.251587 lr 0.00066303 rank 0
2022-08-25 14:13:01,075 DEBUG TRAIN Batch 159/5600 loss 49.346664 loss_att 26.203663 loss_ctc 103.347008 loss_ctc_origin 56.586487 loss_ctc0 212.454895 lr 0.00066300 rank 0
2022-08-25 14:13:24,794 DEBUG CV Batch 159/0 loss 11.921509 loss_att 8.777621 loss_ctc 19.257246 loss_ctc_origin 12.950518 loss_ctc0 33.972946 history loss 11.220244 rank 0
2022-08-25 14:13:35,873 DEBUG CV Batch 159/100 loss 20.230888 loss_att 16.316425 loss_ctc 29.364632 loss_ctc_origin 19.522827 loss_ctc0 52.328838 history loss 25.800414 rank 0
2022-08-25 14:13:45,639 DEBUG CV Batch 159/200 loss 24.225374 loss_att 18.384617 loss_ctc 37.853809 loss_ctc_origin 27.514639 loss_ctc0 61.978542 history loss 27.093994 rank 0
2022-08-25 14:13:55,891 DEBUG CV Batch 159/300 loss 23.286552 loss_att 17.745464 loss_ctc 36.215763 loss_ctc_origin 20.898617 loss_ctc0 71.955765 history loss 26.293911 rank 0
2022-08-25 14:14:06,537 DEBUG CV Batch 159/400 loss 37.719883 loss_att 30.322252 loss_ctc 54.981018 loss_ctc_origin 37.966053 loss_ctc0 94.682594 history loss 24.691475 rank 0
2022-08-25 14:14:17,432 DEBUG CV Batch 159/500 loss 15.886182 loss_att 11.637389 loss_ctc 25.800030 loss_ctc_origin 18.442385 loss_ctc0 42.967865 history loss 24.381244 rank 0
2022-08-25 14:14:28,055 DEBUG CV Batch 159/600 loss 16.907116 loss_att 11.796554 loss_ctc 28.831760 loss_ctc_origin 18.249277 loss_ctc0 53.524216 history loss 24.206003 rank 0
2022-08-25 14:14:38,481 DEBUG CV Batch 159/700 loss 17.640635 loss_att 11.889992 loss_ctc 31.058800 loss_ctc_origin 17.316479 loss_ctc0 63.124218 history loss 23.887690 rank 0
2022-08-25 14:14:49,083 DEBUG CV Batch 159/800 loss 21.898396 loss_att 17.116863 loss_ctc 33.055305 loss_ctc_origin 17.521629 loss_ctc0 69.300552 history loss 23.859892 rank 0
2022-08-25 14:14:59,451 INFO Epoch 159 CV info cv_loss 23.972759242299762
2022-08-25 14:14:59,452 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/159.pt
2022-08-25 14:14:59,924 INFO Epoch 160 TRAIN info lr 0.000662964403479775
2022-08-25 14:14:59,927 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 14:15:27,257 DEBUG TRAIN Batch 160/0 loss 45.963444 loss_att 30.454456 loss_ctc 82.151077 loss_ctc_origin 57.703491 loss_ctc0 139.195450 lr 0.00066296 rank 0
2022-08-25 14:15:56,422 DEBUG TRAIN Batch 160/100 loss 41.268181 loss_att 22.603413 loss_ctc 84.819305 loss_ctc_origin 46.373665 loss_ctc0 174.525787 lr 0.00066293 rank 0
2022-08-25 14:16:25,240 DEBUG TRAIN Batch 160/200 loss 21.724995 loss_att 10.987538 loss_ctc 46.779057 loss_ctc_origin 35.602901 loss_ctc0 72.856750 lr 0.00066289 rank 0
2022-08-25 14:16:53,847 DEBUG TRAIN Batch 160/300 loss 21.005159 loss_att 8.470232 loss_ctc 50.253323 loss_ctc_origin 36.601860 loss_ctc0 82.106735 lr 0.00066285 rank 0
2022-08-25 14:17:23,053 DEBUG TRAIN Batch 160/400 loss 24.103434 loss_att 9.905505 loss_ctc 57.231934 loss_ctc_origin 37.667168 loss_ctc0 102.883057 lr 0.00066282 rank 0
2022-08-25 14:17:52,182 DEBUG TRAIN Batch 160/500 loss 39.449318 loss_att 26.690037 loss_ctc 69.220970 loss_ctc_origin 45.599358 loss_ctc0 124.338066 lr 0.00066278 rank 0
2022-08-25 14:18:20,501 DEBUG TRAIN Batch 160/600 loss 40.120670 loss_att 26.652233 loss_ctc 71.547020 loss_ctc_origin 41.724476 loss_ctc0 141.132965 lr 0.00066274 rank 0
2022-08-25 14:18:48,060 DEBUG TRAIN Batch 160/700 loss 20.095104 loss_att 12.204136 loss_ctc 38.507359 loss_ctc_origin 26.755173 loss_ctc0 65.929123 lr 0.00066271 rank 0
2022-08-25 14:19:16,707 DEBUG TRAIN Batch 160/800 loss 18.986599 loss_att 8.331663 loss_ctc 43.848114 loss_ctc_origin 28.155407 loss_ctc0 80.464432 lr 0.00066267 rank 0
2022-08-25 14:19:46,840 DEBUG TRAIN Batch 160/900 loss 19.940811 loss_att 8.550146 loss_ctc 46.519028 loss_ctc_origin 30.006901 loss_ctc0 85.047333 lr 0.00066264 rank 0
2022-08-25 14:20:15,418 DEBUG TRAIN Batch 160/1000 loss 39.141838 loss_att 27.003330 loss_ctc 67.465027 loss_ctc_origin 45.889851 loss_ctc0 117.807091 lr 0.00066260 rank 0
2022-08-25 14:20:43,766 DEBUG TRAIN Batch 160/1100 loss 41.131218 loss_att 20.504398 loss_ctc 89.260468 loss_ctc_origin 50.134865 loss_ctc0 180.553528 lr 0.00066256 rank 0
2022-08-25 14:21:12,425 DEBUG TRAIN Batch 160/1200 loss 18.704906 loss_att 11.186043 loss_ctc 36.248917 loss_ctc_origin 25.519032 loss_ctc0 61.285313 lr 0.00066253 rank 0
2022-08-25 14:21:41,168 DEBUG TRAIN Batch 160/1300 loss 19.233843 loss_att 7.857922 loss_ctc 45.777657 loss_ctc_origin 31.714106 loss_ctc0 78.592606 lr 0.00066249 rank 0
2022-08-25 14:22:10,157 DEBUG TRAIN Batch 160/1400 loss 20.284159 loss_att 7.910470 loss_ctc 49.156097 loss_ctc_origin 32.966183 loss_ctc0 86.932564 lr 0.00066245 rank 0
2022-08-25 14:22:47,001 DEBUG TRAIN Batch 160/1500 loss 42.767876 loss_att 28.833534 loss_ctc 75.281342 loss_ctc_origin 47.973709 loss_ctc0 138.999130 lr 0.00066242 rank 0
2022-08-25 14:23:15,953 DEBUG TRAIN Batch 160/1600 loss 50.894947 loss_att 31.294968 loss_ctc 96.628227 loss_ctc_origin 62.163441 loss_ctc0 177.046051 lr 0.00066238 rank 0
2022-08-25 14:23:44,221 DEBUG TRAIN Batch 160/1700 loss 17.694815 loss_att 8.836977 loss_ctc 38.363098 loss_ctc_origin 26.156757 loss_ctc0 66.844559 lr 0.00066234 rank 0
2022-08-25 14:24:13,147 DEBUG TRAIN Batch 160/1800 loss 21.208481 loss_att 10.086825 loss_ctc 47.159008 loss_ctc_origin 33.284981 loss_ctc0 79.531738 lr 0.00066231 rank 0
2022-08-25 14:24:42,579 DEBUG TRAIN Batch 160/1900 loss 20.626781 loss_att 8.292318 loss_ctc 49.407196 loss_ctc_origin 32.319008 loss_ctc0 89.279640 lr 0.00066227 rank 0
2022-08-25 14:25:12,361 DEBUG TRAIN Batch 160/2000 loss 49.430939 loss_att 34.200218 loss_ctc 84.969284 loss_ctc_origin 58.513313 loss_ctc0 146.699890 lr 0.00066224 rank 0
2022-08-25 14:25:13,056 WARNING NaN or Inf found in input tensor.
2022-08-25 14:25:39,171 DEBUG TRAIN Batch 160/2100 loss 45.964100 loss_att 23.413399 loss_ctc 98.582397 loss_ctc_origin 51.036148 loss_ctc0 209.523621 lr 0.00066220 rank 0
2022-08-25 14:26:08,172 DEBUG TRAIN Batch 160/2200 loss 21.631105 loss_att 11.444622 loss_ctc 45.399567 loss_ctc_origin 34.941925 loss_ctc0 69.800735 lr 0.00066216 rank 0
2022-08-25 14:26:35,547 DEBUG TRAIN Batch 160/2300 loss 18.686789 loss_att 8.435691 loss_ctc 42.606014 loss_ctc_origin 29.235973 loss_ctc0 73.802773 lr 0.00066213 rank 0
2022-08-25 14:27:03,393 DEBUG TRAIN Batch 160/2400 loss 19.581097 loss_att 8.037119 loss_ctc 46.517044 loss_ctc_origin 30.281059 loss_ctc0 84.401001 lr 0.00066209 rank 0
2022-08-25 14:27:31,328 DEBUG TRAIN Batch 160/2500 loss 34.831326 loss_att 22.447241 loss_ctc 63.727524 loss_ctc_origin 39.072617 loss_ctc0 121.255630 lr 0.00066205 rank 0
2022-08-25 14:27:59,896 DEBUG TRAIN Batch 160/2600 loss 39.842785 loss_att 22.724518 loss_ctc 79.785400 loss_ctc_origin 39.027771 loss_ctc0 174.886520 lr 0.00066202 rank 0
2022-08-25 14:28:27,285 DEBUG TRAIN Batch 160/2700 loss 15.816934 loss_att 8.291654 loss_ctc 33.375919 loss_ctc_origin 21.515503 loss_ctc0 61.050224 lr 0.00066198 rank 0
2022-08-25 14:28:55,817 DEBUG TRAIN Batch 160/2800 loss 18.910721 loss_att 7.608722 loss_ctc 45.282051 loss_ctc_origin 29.856321 loss_ctc0 81.275421 lr 0.00066195 rank 0
2022-08-25 14:29:24,900 DEBUG TRAIN Batch 160/2900 loss 19.714851 loss_att 7.878687 loss_ctc 47.332569 loss_ctc_origin 30.680191 loss_ctc0 86.188118 lr 0.00066191 rank 0
2022-08-25 14:29:59,645 DEBUG TRAIN Batch 160/3000 loss 49.126526 loss_att 31.409805 loss_ctc 90.465530 loss_ctc_origin 59.832699 loss_ctc0 161.942123 lr 0.00066187 rank 0
2022-08-25 14:30:07,604 WARNING NaN or Inf found in input tensor.
2022-08-25 14:30:29,524 DEBUG TRAIN Batch 160/3100 loss 60.089211 loss_att 34.327663 loss_ctc 120.199478 loss_ctc_origin 66.668106 loss_ctc0 245.106018 lr 0.00066184 rank 0
2022-08-25 14:30:58,245 DEBUG TRAIN Batch 160/3200 loss 18.983582 loss_att 9.886238 loss_ctc 40.210716 loss_ctc_origin 31.289171 loss_ctc0 61.027653 lr 0.00066180 rank 0
2022-08-25 14:31:27,211 DEBUG TRAIN Batch 160/3300 loss 21.496220 loss_att 9.087754 loss_ctc 50.449303 loss_ctc_origin 37.765091 loss_ctc0 80.045792 lr 0.00066176 rank 0
2022-08-25 14:31:57,090 DEBUG TRAIN Batch 160/3400 loss 22.406178 loss_att 9.079233 loss_ctc 53.502380 loss_ctc_origin 34.373714 loss_ctc0 98.135933 lr 0.00066173 rank 0
2022-08-25 14:32:26,490 DEBUG TRAIN Batch 160/3500 loss 45.657364 loss_att 28.603062 loss_ctc 85.450737 loss_ctc_origin 53.309113 loss_ctc0 160.447845 lr 0.00066169 rank 0
2022-08-25 14:32:55,907 DEBUG TRAIN Batch 160/3600 loss 53.780952 loss_att 29.228556 loss_ctc 111.069878 loss_ctc_origin 60.591202 loss_ctc0 228.853455 lr 0.00066166 rank 0
2022-08-25 14:33:22,152 WARNING NaN or Inf found in input tensor.
2022-08-25 14:33:23,775 DEBUG TRAIN Batch 160/3700 loss 18.477737 loss_att 9.985974 loss_ctc 38.291847 loss_ctc_origin 26.995434 loss_ctc0 64.650146 lr 0.00066162 rank 0
2022-08-25 14:33:53,534 DEBUG TRAIN Batch 160/3800 loss 16.015007 loss_att 6.767052 loss_ctc 37.593571 loss_ctc_origin 22.713703 loss_ctc0 72.313263 lr 0.00066158 rank 0
2022-08-25 14:34:21,675 DEBUG TRAIN Batch 160/3900 loss 18.884331 loss_att 6.949670 loss_ctc 46.731873 loss_ctc_origin 30.251373 loss_ctc0 85.186371 lr 0.00066155 rank 0
2022-08-25 14:34:51,522 DEBUG TRAIN Batch 160/4000 loss 42.164017 loss_att 28.470039 loss_ctc 74.116623 loss_ctc_origin 46.883842 loss_ctc0 137.659790 lr 0.00066151 rank 0
2022-08-25 14:35:19,752 DEBUG TRAIN Batch 160/4100 loss 53.997364 loss_att 32.533543 loss_ctc 104.079613 loss_ctc_origin 59.899986 loss_ctc0 207.165405 lr 0.00066147 rank 0
2022-08-25 14:35:47,575 DEBUG TRAIN Batch 160/4200 loss 16.219250 loss_att 7.997251 loss_ctc 35.403915 loss_ctc_origin 21.774246 loss_ctc0 67.206467 lr 0.00066144 rank 0
2022-08-25 14:35:59,217 WARNING NaN or Inf found in input tensor.
2022-08-25 14:36:16,512 DEBUG TRAIN Batch 160/4300 loss 17.019398 loss_att 7.346416 loss_ctc 39.589687 loss_ctc_origin 21.998600 loss_ctc0 80.635551 lr 0.00066140 rank 0
2022-08-25 14:36:40,332 WARNING NaN or Inf found in input tensor.
2022-08-25 14:36:44,803 DEBUG TRAIN Batch 160/4400 loss 20.100788 loss_att 7.368608 loss_ctc 49.809208 loss_ctc_origin 31.932274 loss_ctc0 91.522057 lr 0.00066137 rank 0
2022-08-25 14:37:20,770 DEBUG TRAIN Batch 160/4500 loss 45.062904 loss_att 29.826256 loss_ctc 80.615089 loss_ctc_origin 54.343449 loss_ctc0 141.915588 lr 0.00066133 rank 0
2022-08-25 14:37:49,541 DEBUG TRAIN Batch 160/4600 loss 61.671738 loss_att 36.769394 loss_ctc 119.777206 loss_ctc_origin 76.106583 loss_ctc0 221.675339 lr 0.00066129 rank 0
2022-08-25 14:38:17,509 DEBUG TRAIN Batch 160/4700 loss 20.231991 loss_att 12.325048 loss_ctc 38.681522 loss_ctc_origin 26.124567 loss_ctc0 67.981079 lr 0.00066126 rank 0
2022-08-25 14:38:46,929 DEBUG TRAIN Batch 160/4800 loss 20.602161 loss_att 8.727929 loss_ctc 48.308701 loss_ctc_origin 35.213425 loss_ctc0 78.864349 lr 0.00066122 rank 0
2022-08-25 14:39:15,351 DEBUG TRAIN Batch 160/4900 loss 20.446465 loss_att 8.282906 loss_ctc 48.828102 loss_ctc_origin 32.035423 loss_ctc0 88.011017 lr 0.00066119 rank 0
2022-08-25 14:39:18,066 WARNING NaN or Inf found in input tensor.
2022-08-25 14:39:44,265 DEBUG TRAIN Batch 160/5000 loss 44.539375 loss_att 27.927786 loss_ctc 83.299751 loss_ctc_origin 54.476013 loss_ctc0 150.555130 lr 0.00066115 rank 0
2022-08-25 14:40:13,067 DEBUG TRAIN Batch 160/5100 loss 49.779137 loss_att 26.910007 loss_ctc 103.140427 loss_ctc_origin 60.798790 loss_ctc0 201.937592 lr 0.00066111 rank 0
2022-08-25 14:40:42,141 DEBUG TRAIN Batch 160/5200 loss 17.555300 loss_att 9.757931 loss_ctc 35.749161 loss_ctc_origin 24.033772 loss_ctc0 63.085064 lr 0.00066108 rank 0
2022-08-25 14:41:11,631 DEBUG TRAIN Batch 160/5300 loss 20.459587 loss_att 8.712233 loss_ctc 47.870079 loss_ctc_origin 31.608068 loss_ctc0 85.814774 lr 0.00066104 rank 0
2022-08-25 14:41:41,142 DEBUG TRAIN Batch 160/5400 loss 22.455111 loss_att 8.433895 loss_ctc 55.171280 loss_ctc_origin 39.008652 loss_ctc0 92.884071 lr 0.00066100 rank 0
2022-08-25 14:42:10,180 DEBUG TRAIN Batch 160/5500 loss 37.500523 loss_att 25.472553 loss_ctc 65.565781 loss_ctc_origin 39.823326 loss_ctc0 125.631500 lr 0.00066097 rank 0
2022-08-25 14:42:37,549 DEBUG TRAIN Batch 160/5600 loss 44.299267 loss_att 22.593369 loss_ctc 94.946358 loss_ctc_origin 50.509811 loss_ctc0 198.631622 lr 0.00066093 rank 0
2022-08-25 14:43:01,070 DEBUG CV Batch 160/0 loss 12.726251 loss_att 9.602733 loss_ctc 20.014458 loss_ctc_origin 14.070069 loss_ctc0 33.884697 history loss 11.977648 rank 0
2022-08-25 14:43:11,606 DEBUG CV Batch 160/100 loss 20.683487 loss_att 16.778069 loss_ctc 29.796131 loss_ctc_origin 19.973099 loss_ctc0 52.716541 history loss 26.039860 rank 0
2022-08-25 14:43:20,783 DEBUG CV Batch 160/200 loss 25.194679 loss_att 19.533623 loss_ctc 38.403809 loss_ctc_origin 28.487488 loss_ctc0 61.541893 history loss 27.293367 rank 0
2022-08-25 14:43:30,347 DEBUG CV Batch 160/300 loss 23.495432 loss_att 17.827450 loss_ctc 36.720722 loss_ctc_origin 21.800501 loss_ctc0 71.534576 history loss 26.377608 rank 0
2022-08-25 14:43:40,288 DEBUG CV Batch 160/400 loss 37.075371 loss_att 29.844589 loss_ctc 53.947201 loss_ctc_origin 36.674061 loss_ctc0 94.251190 history loss 24.772581 rank 0
2022-08-25 14:43:50,434 DEBUG CV Batch 160/500 loss 16.107990 loss_att 12.154602 loss_ctc 25.332561 loss_ctc_origin 18.220377 loss_ctc0 41.927658 history loss 24.441518 rank 0
2022-08-25 14:44:00,398 DEBUG CV Batch 160/600 loss 17.269871 loss_att 12.008780 loss_ctc 29.545750 loss_ctc_origin 19.183207 loss_ctc0 53.725010 history loss 24.250380 rank 0
2022-08-25 14:44:10,127 DEBUG CV Batch 160/700 loss 17.779961 loss_att 11.954943 loss_ctc 31.371668 loss_ctc_origin 17.675062 loss_ctc0 63.330414 history loss 23.926892 rank 0
2022-08-25 14:44:20,036 DEBUG CV Batch 160/800 loss 22.344856 loss_att 17.613205 loss_ctc 33.385372 loss_ctc_origin 17.896549 loss_ctc0 69.525955 history loss 23.892257 rank 0
2022-08-25 14:44:29,965 INFO Epoch 160 CV info cv_loss 23.991712464618608
2022-08-25 14:44:29,965 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/160.pt
2022-08-25 14:44:30,427 INFO Epoch 161 TRAIN info lr 0.0006609023008064232
2022-08-25 14:44:30,430 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 14:44:56,842 DEBUG TRAIN Batch 161/0 loss 40.454109 loss_att 28.430042 loss_ctc 68.510254 loss_ctc_origin 43.313385 loss_ctc0 127.302948 lr 0.00066090 rank 0
2022-08-25 14:45:25,032 DEBUG TRAIN Batch 161/100 loss 59.921364 loss_att 34.221832 loss_ctc 119.886940 loss_ctc_origin 69.184822 loss_ctc0 238.191879 lr 0.00066086 rank 0
2022-08-25 14:45:53,506 DEBUG TRAIN Batch 161/200 loss 19.696861 loss_att 9.635092 loss_ctc 43.174324 loss_ctc_origin 30.272175 loss_ctc0 73.279335 lr 0.00066083 rank 0
2022-08-25 14:46:21,276 DEBUG TRAIN Batch 161/300 loss 19.300030 loss_att 7.974809 loss_ctc 45.725544 loss_ctc_origin 29.695585 loss_ctc0 83.128777 lr 0.00066079 rank 0
2022-08-25 14:46:50,115 DEBUG TRAIN Batch 161/400 loss 19.486963 loss_att 7.938179 loss_ctc 46.434124 loss_ctc_origin 27.168541 loss_ctc0 91.387146 lr 0.00066076 rank 0
2022-08-25 14:47:18,621 DEBUG TRAIN Batch 161/500 loss 42.842934 loss_att 29.110804 loss_ctc 74.884567 loss_ctc_origin 50.570190 loss_ctc0 131.618103 lr 0.00066072 rank 0
2022-08-25 14:47:46,541 DEBUG TRAIN Batch 161/600 loss 55.904911 loss_att 33.524754 loss_ctc 108.125275 loss_ctc_origin 66.986694 loss_ctc0 204.115295 lr 0.00066068 rank 0
2022-08-25 14:48:13,651 DEBUG TRAIN Batch 161/700 loss 18.095938 loss_att 10.032847 loss_ctc 36.909813 loss_ctc_origin 23.825024 loss_ctc0 67.440979 lr 0.00066065 rank 0
2022-08-25 14:48:41,771 DEBUG TRAIN Batch 161/800 loss 20.751099 loss_att 8.733453 loss_ctc 48.792267 loss_ctc_origin 34.725151 loss_ctc0 81.615532 lr 0.00066061 rank 0
2022-08-25 14:49:10,646 DEBUG TRAIN Batch 161/900 loss 19.997145 loss_att 7.972846 loss_ctc 48.053841 loss_ctc_origin 29.402987 loss_ctc0 91.572495 lr 0.00066058 rank 0
2022-08-25 14:49:39,918 DEBUG TRAIN Batch 161/1000 loss 57.280037 loss_att 41.053993 loss_ctc 95.140808 loss_ctc_origin 74.390411 loss_ctc0 143.558380 lr 0.00066054 rank 0
2022-08-25 14:49:40,597 WARNING NaN or Inf found in input tensor.
2022-08-25 14:49:53,741 WARNING NaN or Inf found in input tensor.
2022-08-25 14:50:08,056 DEBUG TRAIN Batch 161/1100 loss 61.328411 loss_att 34.398319 loss_ctc 124.165283 loss_ctc_origin 81.830612 loss_ctc0 222.946167 lr 0.00066050 rank 0
2022-08-25 14:50:37,308 DEBUG TRAIN Batch 161/1200 loss 14.725660 loss_att 6.614809 loss_ctc 33.650978 loss_ctc_origin 20.982983 loss_ctc0 63.209633 lr 0.00066047 rank 0
2022-08-25 14:51:06,718 DEBUG TRAIN Batch 161/1300 loss 20.457127 loss_att 8.520785 loss_ctc 48.308590 loss_ctc_origin 33.490124 loss_ctc0 82.885010 lr 0.00066043 rank 0
2022-08-25 14:51:30,787 WARNING NaN or Inf found in input tensor.
2022-08-25 14:51:35,162 DEBUG TRAIN Batch 161/1400 loss 19.969236 loss_att 8.420053 loss_ctc 46.917328 loss_ctc_origin 28.614187 loss_ctc0 89.624649 lr 0.00066040 rank 0
2022-08-25 14:52:11,237 DEBUG TRAIN Batch 161/1500 loss 44.010902 loss_att 30.647194 loss_ctc 75.192886 loss_ctc_origin 47.863499 loss_ctc0 138.961456 lr 0.00066036 rank 0
2022-08-25 14:52:39,483 DEBUG TRAIN Batch 161/1600 loss 48.663208 loss_att 26.078327 loss_ctc 101.361259 loss_ctc_origin 51.750980 loss_ctc0 217.118561 lr 0.00066032 rank 0
2022-08-25 14:53:08,083 DEBUG TRAIN Batch 161/1700 loss 20.035847 loss_att 10.981023 loss_ctc 41.163765 loss_ctc_origin 30.825256 loss_ctc0 65.286957 lr 0.00066029 rank 0
2022-08-25 14:53:13,660 WARNING NaN or Inf found in input tensor.
2022-08-25 14:53:36,125 DEBUG TRAIN Batch 161/1800 loss 15.784723 loss_att 6.232713 loss_ctc 38.072742 loss_ctc_origin 22.917959 loss_ctc0 73.433899 lr 0.00066025 rank 0
2022-08-25 14:53:47,124 WARNING NaN or Inf found in input tensor.
2022-08-25 14:54:05,289 DEBUG TRAIN Batch 161/1900 loss 22.267773 loss_att 8.490804 loss_ctc 54.414032 loss_ctc_origin 36.228054 loss_ctc0 96.847969 lr 0.00066022 rank 0
2022-08-25 14:54:35,359 DEBUG TRAIN Batch 161/2000 loss 40.632710 loss_att 25.566555 loss_ctc 75.787071 loss_ctc_origin 45.334869 loss_ctc0 146.842209 lr 0.00066018 rank 0
2022-08-25 14:55:03,746 DEBUG TRAIN Batch 161/2100 loss 43.678665 loss_att 21.505894 loss_ctc 95.415131 loss_ctc_origin 47.710793 loss_ctc0 206.725250 lr 0.00066014 rank 0
2022-08-25 14:55:32,235 DEBUG TRAIN Batch 161/2200 loss 21.797192 loss_att 10.803135 loss_ctc 47.449989 loss_ctc_origin 36.203709 loss_ctc0 73.691315 lr 0.00066011 rank 0
2022-08-25 14:56:01,337 DEBUG TRAIN Batch 161/2300 loss 16.346125 loss_att 6.074815 loss_ctc 40.312515 loss_ctc_origin 24.149326 loss_ctc0 78.026619 lr 0.00066007 rank 0
2022-08-25 14:56:30,523 DEBUG TRAIN Batch 161/2400 loss 20.741434 loss_att 7.803719 loss_ctc 50.929436 loss_ctc_origin 31.340622 loss_ctc0 96.636658 lr 0.00066004 rank 0
2022-08-25 14:56:58,629 DEBUG TRAIN Batch 161/2500 loss 40.001690 loss_att 26.060364 loss_ctc 72.531448 loss_ctc_origin 44.349281 loss_ctc0 138.289825 lr 0.00066000 rank 0
2022-08-25 14:57:12,696 WARNING NaN or Inf found in input tensor.
2022-08-25 14:57:27,574 DEBUG TRAIN Batch 161/2600 loss 45.707855 loss_att 24.123341 loss_ctc 96.071716 loss_ctc_origin 50.307785 loss_ctc0 202.854202 lr 0.00065996 rank 0
2022-08-25 14:57:56,325 DEBUG TRAIN Batch 161/2700 loss 17.739946 loss_att 10.234433 loss_ctc 35.252808 loss_ctc_origin 24.702820 loss_ctc0 59.869453 lr 0.00065993 rank 0
2022-08-25 14:58:24,739 DEBUG TRAIN Batch 161/2800 loss 16.822563 loss_att 5.967295 loss_ctc 42.151520 loss_ctc_origin 26.375261 loss_ctc0 78.962784 lr 0.00065989 rank 0
2022-08-25 14:58:49,258 WARNING NaN or Inf found in input tensor.
2022-08-25 14:58:53,520 DEBUG TRAIN Batch 161/2900 loss 20.490002 loss_att 7.560849 loss_ctc 50.658024 loss_ctc_origin 30.743790 loss_ctc0 97.124565 lr 0.00065986 rank 0
2022-08-25 14:59:28,789 DEBUG TRAIN Batch 161/3000 loss 41.021641 loss_att 25.949615 loss_ctc 76.189697 loss_ctc_origin 48.610844 loss_ctc0 140.540344 lr 0.00065982 rank 0
2022-08-25 14:59:57,739 DEBUG TRAIN Batch 161/3100 loss 42.649841 loss_att 20.094837 loss_ctc 95.278183 loss_ctc_origin 45.758575 loss_ctc0 210.823944 lr 0.00065979 rank 0
2022-08-25 15:00:26,145 DEBUG TRAIN Batch 161/3200 loss 20.501856 loss_att 11.662060 loss_ctc 41.128044 loss_ctc_origin 29.731632 loss_ctc0 67.719666 lr 0.00065975 rank 0
2022-08-25 15:00:55,109 DEBUG TRAIN Batch 161/3300 loss 16.426357 loss_att 6.742161 loss_ctc 39.022812 loss_ctc_origin 24.434586 loss_ctc0 73.062004 lr 0.00065971 rank 0
2022-08-25 15:01:25,129 DEBUG TRAIN Batch 161/3400 loss 22.310339 loss_att 9.124030 loss_ctc 53.078392 loss_ctc_origin 35.175140 loss_ctc0 94.852646 lr 0.00065968 rank 0
2022-08-25 15:01:53,969 DEBUG TRAIN Batch 161/3500 loss 41.558495 loss_att 26.266205 loss_ctc 77.240509 loss_ctc_origin 50.778946 loss_ctc0 138.984161 lr 0.00065964 rank 0
2022-08-25 15:02:22,446 DEBUG TRAIN Batch 161/3600 loss 52.958206 loss_att 29.587841 loss_ctc 107.489044 loss_ctc_origin 62.413071 loss_ctc0 212.666321 lr 0.00065961 rank 0
2022-08-25 15:02:50,209 DEBUG TRAIN Batch 161/3700 loss 22.476511 loss_att 11.580071 loss_ctc 47.901535 loss_ctc_origin 36.734756 loss_ctc0 73.957344 lr 0.00065957 rank 0
2022-08-25 15:03:18,335 DEBUG TRAIN Batch 161/3800 loss 21.613985 loss_att 8.797777 loss_ctc 51.518467 loss_ctc_origin 35.869705 loss_ctc0 88.032242 lr 0.00065953 rank 0
2022-08-25 15:03:46,748 DEBUG TRAIN Batch 161/3900 loss 24.831497 loss_att 9.899184 loss_ctc 59.673553 loss_ctc_origin 38.548759 loss_ctc0 108.964737 lr 0.00065950 rank 0
2022-08-25 15:04:15,162 DEBUG TRAIN Batch 161/4000 loss 38.984173 loss_att 24.079205 loss_ctc 73.762436 loss_ctc_origin 49.211990 loss_ctc0 131.046829 lr 0.00065946 rank 0
2022-08-25 15:04:43,655 DEBUG TRAIN Batch 161/4100 loss 46.530617 loss_att 23.231058 loss_ctc 100.896255 loss_ctc_origin 53.116386 loss_ctc0 212.382614 lr 0.00065943 rank 0
2022-08-25 15:05:10,336 WARNING NaN or Inf found in input tensor.
2022-08-25 15:05:11,952 DEBUG TRAIN Batch 161/4200 loss 17.723230 loss_att 8.127090 loss_ctc 40.114227 loss_ctc_origin 28.065601 loss_ctc0 68.227692 lr 0.00065939 rank 0
2022-08-25 15:05:40,102 DEBUG TRAIN Batch 161/4300 loss 19.242407 loss_att 8.041229 loss_ctc 45.378487 loss_ctc_origin 31.034332 loss_ctc0 78.848175 lr 0.00065935 rank 0
2022-08-25 15:06:08,838 DEBUG TRAIN Batch 161/4400 loss 17.917698 loss_att 7.247956 loss_ctc 42.813759 loss_ctc_origin 25.080330 loss_ctc0 84.191765 lr 0.00065932 rank 0
2022-08-25 15:06:44,210 DEBUG TRAIN Batch 161/4500 loss 42.604012 loss_att 27.374865 loss_ctc 78.138680 loss_ctc_origin 45.931915 loss_ctc0 153.287796 lr 0.00065928 rank 0
2022-08-25 15:07:13,268 DEBUG TRAIN Batch 161/4600 loss 50.033688 loss_att 27.702904 loss_ctc 102.138847 loss_ctc_origin 57.170883 loss_ctc0 207.064087 lr 0.00065925 rank 0
2022-08-25 15:07:41,876 DEBUG TRAIN Batch 161/4700 loss 20.419031 loss_att 10.752966 loss_ctc 42.973183 loss_ctc_origin 32.899353 loss_ctc0 66.478790 lr 0.00065921 rank 0
2022-08-25 15:08:09,954 DEBUG TRAIN Batch 161/4800 loss 20.233479 loss_att 7.483970 loss_ctc 49.982330 loss_ctc_origin 36.194016 loss_ctc0 82.155060 lr 0.00065918 rank 0
2022-08-25 15:08:38,749 DEBUG TRAIN Batch 161/4900 loss 25.098454 loss_att 10.363402 loss_ctc 59.480236 loss_ctc_origin 42.305420 loss_ctc0 99.554802 lr 0.00065914 rank 0
2022-08-25 15:09:08,666 DEBUG TRAIN Batch 161/5000 loss 43.710953 loss_att 27.433722 loss_ctc 81.691147 loss_ctc_origin 50.878551 loss_ctc0 153.587189 lr 0.00065910 rank 0
2022-08-25 15:09:09,361 WARNING NaN or Inf found in input tensor.
2022-08-25 15:09:37,254 DEBUG TRAIN Batch 161/5100 loss 51.567932 loss_att 25.962383 loss_ctc 111.314209 loss_ctc_origin 54.538986 loss_ctc0 243.789703 lr 0.00065907 rank 0
2022-08-25 15:10:05,083 WARNING NaN or Inf found in input tensor.
2022-08-25 15:10:06,664 DEBUG TRAIN Batch 161/5200 loss 19.294216 loss_att 10.309695 loss_ctc 40.258095 loss_ctc_origin 28.802578 loss_ctc0 66.987640 lr 0.00065903 rank 0
2022-08-25 15:10:35,781 DEBUG TRAIN Batch 161/5300 loss 20.011183 loss_att 7.831610 loss_ctc 48.430183 loss_ctc_origin 32.835812 loss_ctc0 84.817055 lr 0.00065900 rank 0
2022-08-25 15:11:04,705 DEBUG TRAIN Batch 161/5400 loss 23.954247 loss_att 10.440548 loss_ctc 55.486206 loss_ctc_origin 39.954685 loss_ctc0 91.726425 lr 0.00065896 rank 0
2022-08-25 15:11:33,856 DEBUG TRAIN Batch 161/5500 loss 39.688690 loss_att 22.309505 loss_ctc 80.240112 loss_ctc_origin 49.713711 loss_ctc0 151.468384 lr 0.00065893 rank 0
2022-08-25 15:12:02,841 DEBUG TRAIN Batch 161/5600 loss 53.476608 loss_att 31.440834 loss_ctc 104.893417 loss_ctc_origin 59.875923 loss_ctc0 209.934235 lr 0.00065889 rank 0
2022-08-25 15:12:26,050 DEBUG CV Batch 161/0 loss 11.553648 loss_att 8.777403 loss_ctc 18.031553 loss_ctc_origin 11.395093 loss_ctc0 33.516624 history loss 10.874022 rank 0
2022-08-25 15:12:37,042 DEBUG CV Batch 161/100 loss 19.296507 loss_att 15.468579 loss_ctc 28.228336 loss_ctc_origin 17.546972 loss_ctc0 53.151512 history loss 25.799702 rank 0
2022-08-25 15:12:46,848 DEBUG CV Batch 161/200 loss 24.323692 loss_att 18.533672 loss_ctc 37.833733 loss_ctc_origin 27.174946 loss_ctc0 62.704239 history loss 27.171271 rank 0
2022-08-25 15:12:57,101 DEBUG CV Batch 161/300 loss 22.660652 loss_att 16.990034 loss_ctc 35.892090 loss_ctc_origin 20.293785 loss_ctc0 72.288132 history loss 26.230136 rank 0
2022-08-25 15:13:07,903 DEBUG CV Batch 161/400 loss 37.341965 loss_att 30.302011 loss_ctc 53.768524 loss_ctc_origin 36.152733 loss_ctc0 94.872025 history loss 24.656599 rank 0
2022-08-25 15:13:19,176 DEBUG CV Batch 161/500 loss 15.827656 loss_att 11.667391 loss_ctc 25.534939 loss_ctc_origin 18.328201 loss_ctc0 42.350655 history loss 24.360401 rank 0
2022-08-25 15:13:29,965 DEBUG CV Batch 161/600 loss 16.825489 loss_att 11.377182 loss_ctc 29.538200 loss_ctc_origin 19.018322 loss_ctc0 54.084576 history loss 24.209110 rank 0
2022-08-25 15:13:40,276 DEBUG CV Batch 161/700 loss 17.844782 loss_att 11.966808 loss_ctc 31.560055 loss_ctc_origin 18.028685 loss_ctc0 63.133251 history loss 23.890546 rank 0
2022-08-25 15:13:50,804 DEBUG CV Batch 161/800 loss 21.965271 loss_att 17.200409 loss_ctc 33.083286 loss_ctc_origin 17.723301 loss_ctc0 68.923256 history loss 23.852275 rank 0
2022-08-25 15:14:01,209 INFO Epoch 161 CV info cv_loss 23.952588817633444
2022-08-25 15:14:01,210 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/161.pt
2022-08-25 15:14:01,658 INFO Epoch 162 TRAIN info lr 0.0006588593212637223
2022-08-25 15:14:01,661 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 15:14:28,037 DEBUG TRAIN Batch 162/0 loss 39.493034 loss_att 25.066483 loss_ctc 73.154991 loss_ctc_origin 45.590851 loss_ctc0 137.471313 lr 0.00065886 rank 0
2022-08-25 15:14:56,119 DEBUG TRAIN Batch 162/100 loss 52.826645 loss_att 30.280922 loss_ctc 105.433334 loss_ctc_origin 60.635399 loss_ctc0 209.961853 lr 0.00065882 rank 0
2022-08-25 15:15:24,616 DEBUG TRAIN Batch 162/200 loss 20.091124 loss_att 10.649902 loss_ctc 42.120640 loss_ctc_origin 30.794737 loss_ctc0 68.547745 lr 0.00065879 rank 0
2022-08-25 15:15:52,766 DEBUG TRAIN Batch 162/300 loss 18.645491 loss_att 7.713147 loss_ctc 44.154289 loss_ctc_origin 30.834621 loss_ctc0 75.233521 lr 0.00065875 rank 0
2022-08-25 15:16:21,258 DEBUG TRAIN Batch 162/400 loss 19.786961 loss_att 7.621458 loss_ctc 48.173138 loss_ctc_origin 28.919508 loss_ctc0 93.098267 lr 0.00065871 rank 0
2022-08-25 15:16:50,265 DEBUG TRAIN Batch 162/500 loss 52.184322 loss_att 36.434006 loss_ctc 88.935059 loss_ctc_origin 63.951195 loss_ctc0 147.230743 lr 0.00065868 rank 0
2022-08-25 15:17:17,961 DEBUG TRAIN Batch 162/600 loss 57.454704 loss_att 33.373550 loss_ctc 113.644058 loss_ctc_origin 66.370300 loss_ctc0 223.949478 lr 0.00065864 rank 0
2022-08-25 15:17:45,755 DEBUG TRAIN Batch 162/700 loss 22.711092 loss_att 12.159164 loss_ctc 47.332256 loss_ctc_origin 35.893784 loss_ctc0 74.022026 lr 0.00065861 rank 0
2022-08-25 15:18:14,687 DEBUG TRAIN Batch 162/800 loss 20.586693 loss_att 8.976450 loss_ctc 47.677261 loss_ctc_origin 31.385994 loss_ctc0 85.690208 lr 0.00065857 rank 0
2022-08-25 15:18:43,538 DEBUG TRAIN Batch 162/900 loss 19.733463 loss_att 7.838844 loss_ctc 47.487572 loss_ctc_origin 28.983139 loss_ctc0 90.664581 lr 0.00065854 rank 0
2022-08-25 15:19:12,265 DEBUG TRAIN Batch 162/1000 loss 43.085464 loss_att 27.963497 loss_ctc 78.370056 loss_ctc_origin 49.851131 loss_ctc0 144.914230 lr 0.00065850 rank 0
2022-08-25 15:19:41,161 DEBUG TRAIN Batch 162/1100 loss 48.243584 loss_att 26.113770 loss_ctc 99.879807 loss_ctc_origin 50.162689 loss_ctc0 215.886429 lr 0.00065846 rank 0
2022-08-25 15:20:10,538 DEBUG TRAIN Batch 162/1200 loss 19.264471 loss_att 9.830461 loss_ctc 41.277161 loss_ctc_origin 28.718925 loss_ctc0 70.579712 lr 0.00065843 rank 0
2022-08-25 15:20:38,807 DEBUG TRAIN Batch 162/1300 loss 20.127146 loss_att 8.082844 loss_ctc 48.230515 loss_ctc_origin 36.021210 loss_ctc0 76.718887 lr 0.00065839 rank 0
2022-08-25 15:21:07,665 DEBUG TRAIN Batch 162/1400 loss 22.300043 loss_att 10.673208 loss_ctc 49.429321 loss_ctc_origin 31.378502 loss_ctc0 91.547897 lr 0.00065836 rank 0
2022-08-25 15:21:43,173 DEBUG TRAIN Batch 162/1500 loss 46.601044 loss_att 32.218063 loss_ctc 80.161331 loss_ctc_origin 51.716000 loss_ctc0 146.533783 lr 0.00065832 rank 0
2022-08-25 15:21:58,414 WARNING NaN or Inf found in input tensor.
2022-08-25 15:22:12,673 DEBUG TRAIN Batch 162/1600 loss 52.380180 loss_att 29.743160 loss_ctc 105.199890 loss_ctc_origin 57.942307 loss_ctc0 215.467575 lr 0.00065829 rank 0
2022-08-25 15:22:42,483 DEBUG TRAIN Batch 162/1700 loss 17.481609 loss_att 8.212453 loss_ctc 39.109642 loss_ctc_origin 28.726223 loss_ctc0 63.337608 lr 0.00065825 rank 0
2022-08-25 15:23:10,734 DEBUG TRAIN Batch 162/1800 loss 20.780043 loss_att 9.443821 loss_ctc 47.231224 loss_ctc_origin 33.993999 loss_ctc0 78.118088 lr 0.00065822 rank 0
2022-08-25 15:23:38,751 DEBUG TRAIN Batch 162/1900 loss 21.861744 loss_att 9.224684 loss_ctc 51.348213 loss_ctc_origin 32.478863 loss_ctc0 95.376694 lr 0.00065818 rank 0
2022-08-25 15:24:07,147 DEBUG TRAIN Batch 162/2000 loss 42.799004 loss_att 28.639366 loss_ctc 75.838158 loss_ctc_origin 46.185844 loss_ctc0 145.026886 lr 0.00065814 rank 0
2022-08-25 15:24:27,424 WARNING NaN or Inf found in input tensor.
2022-08-25 15:24:34,453 DEBUG TRAIN Batch 162/2100 loss 47.707195 loss_att 25.188261 loss_ctc 100.251373 loss_ctc_origin 52.575424 loss_ctc0 211.495270 lr 0.00065811 rank 0
2022-08-25 15:25:02,229 DEBUG TRAIN Batch 162/2200 loss 15.840359 loss_att 7.872297 loss_ctc 34.432503 loss_ctc_origin 22.313963 loss_ctc0 62.709095 lr 0.00065807 rank 0
2022-08-25 15:25:30,921 DEBUG TRAIN Batch 162/2300 loss 19.249947 loss_att 8.759424 loss_ctc 43.727829 loss_ctc_origin 30.572933 loss_ctc0 74.422592 lr 0.00065804 rank 0
2022-08-25 15:25:48,109 WARNING NaN or Inf found in input tensor.
2022-08-25 15:25:59,623 DEBUG TRAIN Batch 162/2400 loss 20.303614 loss_att 7.989842 loss_ctc 49.035744 loss_ctc_origin 30.917393 loss_ctc0 91.311905 lr 0.00065800 rank 0
2022-08-25 15:26:21,148 WARNING NaN or Inf found in input tensor.
2022-08-25 15:26:28,137 DEBUG TRAIN Batch 162/2500 loss 45.370853 loss_att 29.685535 loss_ctc 81.969925 loss_ctc_origin 53.605160 loss_ctc0 148.154373 lr 0.00065797 rank 0
2022-08-25 15:26:57,333 DEBUG TRAIN Batch 162/2600 loss 49.320900 loss_att 30.196081 loss_ctc 93.945480 loss_ctc_origin 55.238403 loss_ctc0 184.261993 lr 0.00065793 rank 0
2022-08-25 15:27:24,959 DEBUG TRAIN Batch 162/2700 loss 17.620094 loss_att 9.436382 loss_ctc 36.715420 loss_ctc_origin 25.635189 loss_ctc0 62.569290 lr 0.00065789 rank 0
2022-08-25 15:27:36,052 WARNING NaN or Inf found in input tensor.
2022-08-25 15:27:52,984 DEBUG TRAIN Batch 162/2800 loss 22.291592 loss_att 9.138595 loss_ctc 52.981918 loss_ctc_origin 39.495003 loss_ctc0 84.451385 lr 0.00065786 rank 0
2022-08-25 15:28:22,131 DEBUG TRAIN Batch 162/2900 loss 19.745646 loss_att 7.636440 loss_ctc 48.000454 loss_ctc_origin 30.043997 loss_ctc0 89.898849 lr 0.00065782 rank 0
2022-08-25 15:28:58,018 DEBUG TRAIN Batch 162/3000 loss 38.549282 loss_att 23.174696 loss_ctc 74.423317 loss_ctc_origin 46.181728 loss_ctc0 140.320358 lr 0.00065779 rank 0
2022-08-25 15:29:26,799 DEBUG TRAIN Batch 162/3100 loss 46.808231 loss_att 23.326752 loss_ctc 101.598351 loss_ctc_origin 55.920685 loss_ctc0 208.179565 lr 0.00065775 rank 0
2022-08-25 15:29:55,528 DEBUG TRAIN Batch 162/3200 loss 19.437103 loss_att 9.412553 loss_ctc 42.827721 loss_ctc_origin 32.930923 loss_ctc0 65.920242 lr 0.00065772 rank 0
2022-08-25 15:30:24,882 DEBUG TRAIN Batch 162/3300 loss 19.718424 loss_att 9.315076 loss_ctc 43.992901 loss_ctc_origin 29.532558 loss_ctc0 77.733696 lr 0.00065768 rank 0
2022-08-25 15:30:54,279 DEBUG TRAIN Batch 162/3400 loss 20.935459 loss_att 9.067293 loss_ctc 48.627846 loss_ctc_origin 30.840244 loss_ctc0 90.132248 lr 0.00065765 rank 0
2022-08-25 15:31:23,574 DEBUG TRAIN Batch 162/3500 loss 45.819649 loss_att 29.068958 loss_ctc 84.904587 loss_ctc_origin 56.190659 loss_ctc0 151.903748 lr 0.00065761 rank 0
2022-08-25 15:31:52,202 DEBUG TRAIN Batch 162/3600 loss 50.240570 loss_att 29.783600 loss_ctc 97.973503 loss_ctc_origin 54.344257 loss_ctc0 199.775070 lr 0.00065757 rank 0
2022-08-25 15:32:20,215 DEBUG TRAIN Batch 162/3700 loss 20.177307 loss_att 9.315577 loss_ctc 45.521339 loss_ctc_origin 34.054375 loss_ctc0 72.277580 lr 0.00065754 rank 0
2022-08-25 15:32:49,566 DEBUG TRAIN Batch 162/3800 loss 17.762093 loss_att 7.917248 loss_ctc 40.733398 loss_ctc_origin 27.279663 loss_ctc0 72.125443 lr 0.00065750 rank 0
2022-08-25 15:33:18,123 DEBUG TRAIN Batch 162/3900 loss 21.470339 loss_att 9.101513 loss_ctc 50.330933 loss_ctc_origin 34.746803 loss_ctc0 86.693893 lr 0.00065747 rank 0
2022-08-25 15:33:46,913 DEBUG TRAIN Batch 162/4000 loss 42.940697 loss_att 26.061745 loss_ctc 82.324921 loss_ctc_origin 49.795700 loss_ctc0 158.226440 lr 0.00065743 rank 0
2022-08-25 15:34:15,534 DEBUG TRAIN Batch 162/4100 loss 53.712212 loss_att 29.267412 loss_ctc 110.750084 loss_ctc_origin 62.481342 loss_ctc0 223.377136 lr 0.00065740 rank 0
2022-08-25 15:34:43,365 DEBUG TRAIN Batch 162/4200 loss 20.939220 loss_att 9.953833 loss_ctc 46.571789 loss_ctc_origin 35.990940 loss_ctc0 71.260437 lr 0.00065736 rank 0
2022-08-25 15:35:12,107 DEBUG TRAIN Batch 162/4300 loss 20.484472 loss_att 8.917768 loss_ctc 47.473446 loss_ctc_origin 32.870602 loss_ctc0 81.546745 lr 0.00065733 rank 0
2022-08-25 15:35:42,412 DEBUG TRAIN Batch 162/4400 loss 22.508701 loss_att 9.657025 loss_ctc 52.495945 loss_ctc_origin 34.057434 loss_ctc0 95.519135 lr 0.00065729 rank 0
2022-08-25 15:35:51,263 WARNING NaN or Inf found in input tensor.
2022-08-25 15:36:17,687 DEBUG TRAIN Batch 162/4500 loss 51.056290 loss_att 34.170605 loss_ctc 90.456215 loss_ctc_origin 61.918510 loss_ctc0 157.044189 lr 0.00065725 rank 0
2022-08-25 15:36:46,277 DEBUG TRAIN Batch 162/4600 loss 49.320312 loss_att 28.321175 loss_ctc 98.318298 loss_ctc_origin 57.705322 loss_ctc0 193.081909 lr 0.00065722 rank 0
2022-08-25 15:37:14,961 DEBUG TRAIN Batch 162/4700 loss 18.898390 loss_att 10.411016 loss_ctc 38.702259 loss_ctc_origin 27.771601 loss_ctc0 64.207123 lr 0.00065718 rank 0
2022-08-25 15:37:44,298 DEBUG TRAIN Batch 162/4800 loss 17.485184 loss_att 6.566901 loss_ctc 42.961174 loss_ctc_origin 27.785149 loss_ctc0 78.371895 lr 0.00065715 rank 0
2022-08-25 15:38:13,405 DEBUG TRAIN Batch 162/4900 loss 21.287706 loss_att 8.107231 loss_ctc 52.042145 loss_ctc_origin 32.799858 loss_ctc0 96.940804 lr 0.00065711 rank 0
2022-08-25 15:38:42,408 DEBUG TRAIN Batch 162/5000 loss 32.131119 loss_att 19.999222 loss_ctc 60.438881 loss_ctc_origin 34.364975 loss_ctc0 121.278000 lr 0.00065708 rank 0
2022-08-25 15:39:10,545 DEBUG TRAIN Batch 162/5100 loss 52.889305 loss_att 30.005903 loss_ctc 106.283913 loss_ctc_origin 59.350380 loss_ctc0 215.795486 lr 0.00065704 rank 0
2022-08-25 15:39:38,159 DEBUG TRAIN Batch 162/5200 loss 19.857399 loss_att 11.161395 loss_ctc 40.148075 loss_ctc_origin 29.072014 loss_ctc0 65.992218 lr 0.00065701 rank 0
2022-08-25 15:40:06,617 DEBUG TRAIN Batch 162/5300 loss 17.093670 loss_att 6.685645 loss_ctc 41.379059 loss_ctc_origin 26.998535 loss_ctc0 74.933624 lr 0.00065697 rank 0
2022-08-25 15:40:36,554 DEBUG TRAIN Batch 162/5400 loss 20.327721 loss_att 7.536969 loss_ctc 50.172806 loss_ctc_origin 32.454811 loss_ctc0 91.514786 lr 0.00065694 rank 0
2022-08-25 15:41:04,760 DEBUG TRAIN Batch 162/5500 loss 50.401573 loss_att 33.724586 loss_ctc 89.314545 loss_ctc_origin 60.044147 loss_ctc0 157.612137 lr 0.00065690 rank 0
2022-08-25 15:41:33,586 DEBUG TRAIN Batch 162/5600 loss 53.163246 loss_att 30.159355 loss_ctc 106.838989 loss_ctc_origin 60.998867 loss_ctc0 213.799255 lr 0.00065686 rank 0
2022-08-25 15:41:56,486 DEBUG CV Batch 162/0 loss 11.892956 loss_att 8.710085 loss_ctc 19.319653 loss_ctc_origin 13.074190 loss_ctc0 33.892395 history loss 11.193370 rank 0
2022-08-25 15:42:07,508 DEBUG CV Batch 162/100 loss 19.725914 loss_att 15.475216 loss_ctc 29.644207 loss_ctc_origin 19.692871 loss_ctc0 52.863987 history loss 26.120009 rank 0
2022-08-25 15:42:16,801 DEBUG CV Batch 162/200 loss 24.377029 loss_att 18.711834 loss_ctc 37.595821 loss_ctc_origin 27.386501 loss_ctc0 61.417564 history loss 27.249466 rank 0
2022-08-25 15:42:27,001 DEBUG CV Batch 162/300 loss 23.057005 loss_att 17.514210 loss_ctc 35.990192 loss_ctc_origin 20.760416 loss_ctc0 71.526337 history loss 26.347186 rank 0
2022-08-25 15:42:38,237 DEBUG CV Batch 162/400 loss 36.831226 loss_att 29.909550 loss_ctc 52.981812 loss_ctc_origin 35.200657 loss_ctc0 94.471176 history loss 24.729853 rank 0
2022-08-25 15:42:49,826 DEBUG CV Batch 162/500 loss 16.230663 loss_att 11.843916 loss_ctc 26.466406 loss_ctc_origin 19.825232 loss_ctc0 41.962479 history loss 24.405897 rank 0
2022-08-25 15:43:00,583 DEBUG CV Batch 162/600 loss 16.971455 loss_att 11.814218 loss_ctc 29.005009 loss_ctc_origin 18.530102 loss_ctc0 53.446457 history loss 24.220800 rank 0
2022-08-25 15:43:11,151 DEBUG CV Batch 162/700 loss 18.217163 loss_att 12.504650 loss_ctc 31.546364 loss_ctc_origin 18.071478 loss_ctc0 62.987766 history loss 23.899879 rank 0
2022-08-25 15:43:22,219 DEBUG CV Batch 162/800 loss 21.596100 loss_att 16.872889 loss_ctc 32.616928 loss_ctc_origin 17.216871 loss_ctc0 68.550385 history loss 23.863147 rank 0
2022-08-25 15:43:32,873 INFO Epoch 162 CV info cv_loss 23.958399186540717
2022-08-25 15:43:32,873 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/162.pt
2022-08-25 15:43:33,383 INFO Epoch 163 TRAIN info lr 0.0006568351710999559
2022-08-25 15:43:33,387 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 15:44:00,408 DEBUG TRAIN Batch 163/0 loss 47.800468 loss_att 33.002674 loss_ctc 82.328659 loss_ctc_origin 52.138191 loss_ctc0 152.773087 lr 0.00065683 rank 0
2022-08-25 15:44:29,341 DEBUG TRAIN Batch 163/100 loss 66.373520 loss_att 42.595062 loss_ctc 121.856583 loss_ctc_origin 79.922089 loss_ctc0 219.703735 lr 0.00065680 rank 0
2022-08-25 15:44:59,368 DEBUG TRAIN Batch 163/200 loss 18.345585 loss_att 9.325324 loss_ctc 39.392860 loss_ctc_origin 26.994928 loss_ctc0 68.321373 lr 0.00065676 rank 0
2022-08-25 15:45:28,970 DEBUG TRAIN Batch 163/300 loss 19.243793 loss_att 7.965408 loss_ctc 45.560020 loss_ctc_origin 30.606609 loss_ctc0 80.451309 lr 0.00065673 rank 0
2022-08-25 15:45:57,688 DEBUG TRAIN Batch 163/400 loss 20.243786 loss_att 7.990873 loss_ctc 48.833916 loss_ctc_origin 31.306267 loss_ctc0 89.731750 lr 0.00065669 rank 0
2022-08-25 15:46:27,646 DEBUG TRAIN Batch 163/500 loss 49.594360 loss_att 31.523708 loss_ctc 91.759216 loss_ctc_origin 54.766121 loss_ctc0 178.076431 lr 0.00065666 rank 0
2022-08-25 15:46:55,683 DEBUG TRAIN Batch 163/600 loss 53.072739 loss_att 30.631786 loss_ctc 105.434967 loss_ctc_origin 61.189053 loss_ctc0 208.675415 lr 0.00065662 rank 0
2022-08-25 15:47:24,732 DEBUG TRAIN Batch 163/700 loss 18.614698 loss_att 9.848691 loss_ctc 39.068718 loss_ctc_origin 27.090828 loss_ctc0 67.017120 lr 0.00065659 rank 0
2022-08-25 15:47:52,743 DEBUG TRAIN Batch 163/800 loss 20.471836 loss_att 8.438068 loss_ctc 48.550629 loss_ctc_origin 35.522457 loss_ctc0 78.949699 lr 0.00065655 rank 0
2022-08-25 15:48:21,793 DEBUG TRAIN Batch 163/900 loss 21.232294 loss_att 8.243048 loss_ctc 51.540535 loss_ctc_origin 33.591377 loss_ctc0 93.421906 lr 0.00065652 rank 0
2022-08-25 15:48:51,124 DEBUG TRAIN Batch 163/1000 loss 47.528015 loss_att 28.221453 loss_ctc 92.576660 loss_ctc_origin 53.344135 loss_ctc0 184.119232 lr 0.00065648 rank 0
2022-08-25 15:49:06,301 WARNING NaN or Inf found in input tensor.
2022-08-25 15:49:07,071 WARNING NaN or Inf found in input tensor.
2022-08-25 15:49:20,452 DEBUG TRAIN Batch 163/1100 loss 54.397232 loss_att 29.860527 loss_ctc 111.649551 loss_ctc_origin 58.640968 loss_ctc0 235.336243 lr 0.00065644 rank 0
2022-08-25 15:49:49,726 DEBUG TRAIN Batch 163/1200 loss 17.879185 loss_att 8.620567 loss_ctc 39.482628 loss_ctc_origin 25.928032 loss_ctc0 71.110016 lr 0.00065641 rank 0
2022-08-25 15:50:18,966 DEBUG TRAIN Batch 163/1300 loss 20.531635 loss_att 8.008019 loss_ctc 49.753403 loss_ctc_origin 35.207249 loss_ctc0 83.694420 lr 0.00065637 rank 0
2022-08-25 15:50:48,279 DEBUG TRAIN Batch 163/1400 loss 21.003555 loss_att 9.017817 loss_ctc 48.970276 loss_ctc_origin 29.919874 loss_ctc0 93.421211 lr 0.00065634 rank 0
2022-08-25 15:51:23,476 DEBUG TRAIN Batch 163/1500 loss 45.252636 loss_att 29.626663 loss_ctc 81.713234 loss_ctc_origin 51.204597 loss_ctc0 152.900055 lr 0.00065630 rank 0
2022-08-25 15:51:31,468 WARNING NaN or Inf found in input tensor.
2022-08-25 15:51:52,356 DEBUG TRAIN Batch 163/1600 loss 55.535957 loss_att 30.536110 loss_ctc 113.868927 loss_ctc_origin 64.485497 loss_ctc0 229.096924 lr 0.00065627 rank 0
2022-08-25 15:52:20,374 DEBUG TRAIN Batch 163/1700 loss 18.069784 loss_att 8.000067 loss_ctc 41.565792 loss_ctc_origin 29.316412 loss_ctc0 70.147675 lr 0.00065623 rank 0
2022-08-25 15:52:48,851 DEBUG TRAIN Batch 163/1800 loss 19.260227 loss_att 7.766577 loss_ctc 46.078743 loss_ctc_origin 29.936668 loss_ctc0 83.743576 lr 0.00065620 rank 0
2022-08-25 15:53:17,459 DEBUG TRAIN Batch 163/1900 loss 22.548893 loss_att 9.341440 loss_ctc 53.366280 loss_ctc_origin 35.003376 loss_ctc0 96.213058 lr 0.00065616 rank 0
2022-08-25 15:53:46,952 DEBUG TRAIN Batch 163/2000 loss 37.165588 loss_att 21.681986 loss_ctc 73.293991 loss_ctc_origin 37.521187 loss_ctc0 156.763855 lr 0.00065613 rank 0
2022-08-25 15:54:15,684 DEBUG TRAIN Batch 163/2100 loss 50.770180 loss_att 27.873363 loss_ctc 104.196075 loss_ctc_origin 53.963440 loss_ctc0 221.405563 lr 0.00065609 rank 0
2022-08-25 15:54:44,877 DEBUG TRAIN Batch 163/2200 loss 20.974472 loss_att 11.333662 loss_ctc 43.469696 loss_ctc_origin 30.686821 loss_ctc0 73.296402 lr 0.00065606 rank 0
2022-08-25 15:55:14,182 DEBUG TRAIN Batch 163/2300 loss 15.734447 loss_att 7.149459 loss_ctc 35.766083 loss_ctc_origin 21.342030 loss_ctc0 69.422203 lr 0.00065602 rank 0
2022-08-25 15:55:42,768 DEBUG TRAIN Batch 163/2400 loss 21.556551 loss_att 8.397831 loss_ctc 52.260231 loss_ctc_origin 32.337971 loss_ctc0 98.745506 lr 0.00065599 rank 0
2022-08-25 15:56:11,287 WARNING NaN or Inf found in input tensor.
2022-08-25 15:56:11,330 DEBUG TRAIN Batch 163/2500 loss inf loss_att 29.689646 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00065595 rank 0
2022-08-25 15:56:39,467 DEBUG TRAIN Batch 163/2600 loss 47.540504 loss_att 24.533865 loss_ctc 101.222656 loss_ctc_origin 52.163776 loss_ctc0 215.693359 lr 0.00065591 rank 0
2022-08-25 15:57:07,847 DEBUG TRAIN Batch 163/2700 loss 19.788715 loss_att 11.493450 loss_ctc 39.144333 loss_ctc_origin 28.598278 loss_ctc0 63.751781 lr 0.00065588 rank 0
2022-08-25 15:57:36,809 DEBUG TRAIN Batch 163/2800 loss 17.714624 loss_att 6.797377 loss_ctc 43.188202 loss_ctc_origin 28.308548 loss_ctc0 77.907394 lr 0.00065584 rank 0
2022-08-25 15:58:06,312 DEBUG TRAIN Batch 163/2900 loss 20.550968 loss_att 8.455544 loss_ctc 48.773621 loss_ctc_origin 28.489765 loss_ctc0 96.102615 lr 0.00065581 rank 0
2022-08-25 15:58:42,128 DEBUG TRAIN Batch 163/3000 loss 42.991081 loss_att 29.795639 loss_ctc 73.780441 loss_ctc_origin 44.593056 loss_ctc0 141.884323 lr 0.00065577 rank 0
2022-08-25 15:59:12,210 DEBUG TRAIN Batch 163/3100 loss 46.346542 loss_att 23.574963 loss_ctc 99.480232 loss_ctc_origin 51.375145 loss_ctc0 211.725433 lr 0.00065574 rank 0
2022-08-25 15:59:40,845 DEBUG TRAIN Batch 163/3200 loss 18.410158 loss_att 9.369057 loss_ctc 39.506058 loss_ctc_origin 27.956150 loss_ctc0 66.455841 lr 0.00065570 rank 0
2022-08-25 16:00:10,210 DEBUG TRAIN Batch 163/3300 loss 17.681557 loss_att 6.732984 loss_ctc 43.228226 loss_ctc_origin 27.068781 loss_ctc0 80.933601 lr 0.00065567 rank 0
2022-08-25 16:00:35,346 WARNING NaN or Inf found in input tensor.
2022-08-25 16:00:39,871 DEBUG TRAIN Batch 163/3400 loss 22.610481 loss_att 8.584590 loss_ctc 55.337563 loss_ctc_origin 37.686264 loss_ctc0 96.523918 lr 0.00065563 rank 0
2022-08-25 16:01:08,714 DEBUG TRAIN Batch 163/3500 loss 46.494926 loss_att 30.581198 loss_ctc 83.626953 loss_ctc_origin 53.808807 loss_ctc0 153.202621 lr 0.00065560 rank 0
2022-08-25 16:01:36,924 DEBUG TRAIN Batch 163/3600 loss 48.821186 loss_att 23.183426 loss_ctc 108.642624 loss_ctc_origin 51.112850 loss_ctc0 242.878769 lr 0.00065556 rank 0
2022-08-25 16:02:04,662 DEBUG TRAIN Batch 163/3700 loss 24.092043 loss_att 14.921931 loss_ctc 45.488968 loss_ctc_origin 35.461868 loss_ctc0 68.885536 lr 0.00065553 rank 0
2022-08-25 16:02:33,513 DEBUG TRAIN Batch 163/3800 loss 18.980553 loss_att 7.623315 loss_ctc 45.480774 loss_ctc_origin 30.971962 loss_ctc0 79.334671 lr 0.00065549 rank 0
2022-08-25 16:03:03,064 DEBUG TRAIN Batch 163/3900 loss 19.628147 loss_att 7.976213 loss_ctc 46.815994 loss_ctc_origin 29.834646 loss_ctc0 86.439133 lr 0.00065546 rank 0
2022-08-25 16:03:32,194 DEBUG TRAIN Batch 163/4000 loss 40.881050 loss_att 25.826759 loss_ctc 76.007721 loss_ctc_origin 46.381927 loss_ctc0 145.134552 lr 0.00065542 rank 0
2022-08-25 16:04:01,079 DEBUG TRAIN Batch 163/4100 loss 52.457977 loss_att 25.779264 loss_ctc 114.708298 loss_ctc_origin 62.792259 loss_ctc0 235.845718 lr 0.00065539 rank 0
2022-08-25 16:04:29,562 DEBUG TRAIN Batch 163/4200 loss 22.257364 loss_att 12.935318 loss_ctc 44.008804 loss_ctc_origin 34.049660 loss_ctc0 67.246811 lr 0.00065535 rank 0
2022-08-25 16:04:57,881 DEBUG TRAIN Batch 163/4300 loss 17.484888 loss_att 7.572495 loss_ctc 40.613804 loss_ctc_origin 27.654266 loss_ctc0 70.852722 lr 0.00065532 rank 0
2022-08-25 16:05:23,285 WARNING NaN or Inf found in input tensor.
2022-08-25 16:05:27,687 DEBUG TRAIN Batch 163/4400 loss 19.930313 loss_att 7.916511 loss_ctc 47.962521 loss_ctc_origin 28.552219 loss_ctc0 93.253220 lr 0.00065528 rank 0
2022-08-25 16:06:02,492 DEBUG TRAIN Batch 163/4500 loss 42.373150 loss_att 26.117577 loss_ctc 80.302818 loss_ctc_origin 48.495289 loss_ctc0 154.520386 lr 0.00065525 rank 0
2022-08-25 16:06:31,261 DEBUG TRAIN Batch 163/4600 loss 55.316856 loss_att 32.687546 loss_ctc 108.118576 loss_ctc_origin 58.518852 loss_ctc0 223.851257 lr 0.00065521 rank 0
2022-08-25 16:07:00,546 DEBUG TRAIN Batch 163/4700 loss 16.547829 loss_att 8.499134 loss_ctc 35.328117 loss_ctc_origin 23.211143 loss_ctc0 63.601055 lr 0.00065518 rank 0
2022-08-25 16:07:28,852 DEBUG TRAIN Batch 163/4800 loss 16.927109 loss_att 7.143810 loss_ctc 39.754803 loss_ctc_origin 25.317476 loss_ctc0 73.441895 lr 0.00065514 rank 0
2022-08-25 16:07:58,132 DEBUG TRAIN Batch 163/4900 loss 21.442940 loss_att 9.240713 loss_ctc 49.914799 loss_ctc_origin 30.530205 loss_ctc0 95.145515 lr 0.00065510 rank 0
2022-08-25 16:08:28,060 DEBUG TRAIN Batch 163/5000 loss 42.204788 loss_att 24.996826 loss_ctc 82.356705 loss_ctc_origin 45.175095 loss_ctc0 169.113770 lr 0.00065507 rank 0
2022-08-25 16:08:56,526 DEBUG TRAIN Batch 163/5100 loss 46.331451 loss_att 23.242744 loss_ctc 100.205093 loss_ctc_origin 51.096958 loss_ctc0 214.790726 lr 0.00065503 rank 0
2022-08-25 16:09:25,182 DEBUG TRAIN Batch 163/5200 loss 21.418526 loss_att 13.189976 loss_ctc 40.618477 loss_ctc_origin 29.657101 loss_ctc0 66.195030 lr 0.00065500 rank 0
2022-08-25 16:09:53,932 DEBUG TRAIN Batch 163/5300 loss 19.304373 loss_att 8.399685 loss_ctc 44.748642 loss_ctc_origin 29.014584 loss_ctc0 81.461441 lr 0.00065496 rank 0
2022-08-25 16:10:23,259 DEBUG TRAIN Batch 163/5400 loss 22.006926 loss_att 9.850202 loss_ctc 50.372612 loss_ctc_origin 31.047092 loss_ctc0 95.465500 lr 0.00065493 rank 0
2022-08-25 16:10:52,201 DEBUG TRAIN Batch 163/5500 loss 41.333138 loss_att 25.796818 loss_ctc 77.584541 loss_ctc_origin 45.030178 loss_ctc0 153.544724 lr 0.00065489 rank 0
2022-08-25 16:11:21,193 DEBUG TRAIN Batch 163/5600 loss 57.244026 loss_att 31.113283 loss_ctc 118.215744 loss_ctc_origin 66.782745 loss_ctc0 238.226074 lr 0.00065486 rank 0
2022-08-25 16:11:44,086 DEBUG CV Batch 163/0 loss 12.073403 loss_att 8.822572 loss_ctc 19.658676 loss_ctc_origin 13.619693 loss_ctc0 33.749634 history loss 11.363203 rank 0
2022-08-25 16:11:54,940 DEBUG CV Batch 163/100 loss 20.337296 loss_att 16.224236 loss_ctc 29.934429 loss_ctc_origin 20.244610 loss_ctc0 52.544006 history loss 26.145374 rank 0
2022-08-25 16:12:04,813 DEBUG CV Batch 163/200 loss 26.150278 loss_att 20.272100 loss_ctc 39.866028 loss_ctc_origin 30.222002 loss_ctc0 62.368748 history loss 27.503946 rank 0
2022-08-25 16:12:14,759 DEBUG CV Batch 163/300 loss 23.243202 loss_att 17.846214 loss_ctc 35.836174 loss_ctc_origin 20.411150 loss_ctc0 71.827896 history loss 26.588283 rank 0
2022-08-25 16:12:25,456 DEBUG CV Batch 163/400 loss 37.586952 loss_att 30.851654 loss_ctc 53.302654 loss_ctc_origin 35.473503 loss_ctc0 94.904007 history loss 24.961156 rank 0
2022-08-25 16:12:36,492 DEBUG CV Batch 163/500 loss 16.012484 loss_att 12.067183 loss_ctc 25.218189 loss_ctc_origin 17.981625 loss_ctc0 42.103500 history loss 24.629460 rank 0
2022-08-25 16:12:47,101 DEBUG CV Batch 163/600 loss 16.855062 loss_att 11.875650 loss_ctc 28.473690 loss_ctc_origin 17.823147 loss_ctc0 53.324951 history loss 24.432098 rank 0
2022-08-25 16:12:57,191 DEBUG CV Batch 163/700 loss 18.584026 loss_att 12.840136 loss_ctc 31.986443 loss_ctc_origin 18.660786 loss_ctc0 63.079643 history loss 24.089389 rank 0
2022-08-25 16:13:07,558 DEBUG CV Batch 163/800 loss 21.967825 loss_att 17.480255 loss_ctc 32.438820 loss_ctc_origin 17.185539 loss_ctc0 68.029800 history loss 24.037862 rank 0
2022-08-25 16:13:18,078 INFO Epoch 163 CV info cv_loss 24.14191030455857
2022-08-25 16:13:18,078 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/163.pt
2022-08-25 16:13:18,529 INFO Epoch 164 TRAIN info lr 0.000654829562842114
2022-08-25 16:13:18,532 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 16:13:44,922 DEBUG TRAIN Batch 164/0 loss 41.905609 loss_att 25.061569 loss_ctc 81.208366 loss_ctc_origin 42.546543 loss_ctc0 171.419281 lr 0.00065483 rank 0
2022-08-25 16:14:14,061 DEBUG TRAIN Batch 164/100 loss 53.989792 loss_att 28.532486 loss_ctc 113.390167 loss_ctc_origin 59.222672 loss_ctc0 239.780975 lr 0.00065479 rank 0
2022-08-25 16:14:42,529 DEBUG TRAIN Batch 164/200 loss 18.676983 loss_att 8.595688 loss_ctc 42.200005 loss_ctc_origin 30.723547 loss_ctc0 68.978394 lr 0.00065476 rank 0
2022-08-25 16:15:10,887 DEBUG TRAIN Batch 164/300 loss 15.917959 loss_att 6.550219 loss_ctc 37.776016 loss_ctc_origin 23.119852 loss_ctc0 71.973724 lr 0.00065472 rank 0
2022-08-25 16:15:38,593 DEBUG TRAIN Batch 164/400 loss 20.671522 loss_att 8.105098 loss_ctc 49.993176 loss_ctc_origin 30.828079 loss_ctc0 94.711731 lr 0.00065469 rank 0
2022-08-25 16:16:08,045 DEBUG TRAIN Batch 164/500 loss 42.096588 loss_att 25.810936 loss_ctc 80.096443 loss_ctc_origin 47.520458 loss_ctc0 156.107071 lr 0.00065465 rank 0
2022-08-25 16:16:36,401 DEBUG TRAIN Batch 164/600 loss 56.620625 loss_att 30.926971 loss_ctc 116.572472 loss_ctc_origin 62.989784 loss_ctc0 241.598724 lr 0.00065462 rank 0
2022-08-25 16:17:05,786 DEBUG TRAIN Batch 164/700 loss 18.515985 loss_att 7.574588 loss_ctc 44.045910 loss_ctc_origin 32.703354 loss_ctc0 70.511871 lr 0.00065458 rank 0
2022-08-25 16:17:34,168 DEBUG TRAIN Batch 164/800 loss 18.408766 loss_att 7.138754 loss_ctc 44.705460 loss_ctc_origin 30.295359 loss_ctc0 78.329033 lr 0.00065455 rank 0
2022-08-25 16:18:03,031 DEBUG TRAIN Batch 164/900 loss 20.601061 loss_att 8.504479 loss_ctc 48.826416 loss_ctc_origin 30.223484 loss_ctc0 92.233261 lr 0.00065451 rank 0
2022-08-25 16:18:32,137 DEBUG TRAIN Batch 164/1000 loss 40.561069 loss_att 23.811836 loss_ctc 79.642609 loss_ctc_origin 49.631561 loss_ctc0 149.668365 lr 0.00065448 rank 0
2022-08-25 16:19:01,182 DEBUG TRAIN Batch 164/1100 loss 51.030029 loss_att 27.717381 loss_ctc 105.426208 loss_ctc_origin 51.487747 loss_ctc0 231.282593 lr 0.00065444 rank 0
2022-08-25 16:19:28,652 DEBUG TRAIN Batch 164/1200 loss 19.598244 loss_att 10.933838 loss_ctc 39.815189 loss_ctc_origin 26.989613 loss_ctc0 69.741531 lr 0.00065441 rank 0
2022-08-25 16:19:57,059 DEBUG TRAIN Batch 164/1300 loss 17.465891 loss_att 7.294217 loss_ctc 41.199795 loss_ctc_origin 25.603903 loss_ctc0 77.590210 lr 0.00065437 rank 0
2022-08-25 16:20:25,565 DEBUG TRAIN Batch 164/1400 loss 20.772049 loss_att 8.979649 loss_ctc 48.287647 loss_ctc_origin 29.756397 loss_ctc0 91.527229 lr 0.00065434 rank 0
2022-08-25 16:21:00,538 DEBUG TRAIN Batch 164/1500 loss 49.924065 loss_att 33.352913 loss_ctc 88.590080 loss_ctc_origin 55.627029 loss_ctc0 165.503860 lr 0.00065430 rank 0
2022-08-25 16:21:28,681 DEBUG TRAIN Batch 164/1600 loss 55.460289 loss_att 29.411842 loss_ctc 116.239990 loss_ctc_origin 67.136978 loss_ctc0 230.813660 lr 0.00065427 rank 0
2022-08-25 16:21:56,389 DEBUG TRAIN Batch 164/1700 loss 20.076435 loss_att 11.112696 loss_ctc 40.991829 loss_ctc_origin 30.188999 loss_ctc0 66.198433 lr 0.00065423 rank 0
2022-08-25 16:22:24,425 DEBUG TRAIN Batch 164/1800 loss 20.659111 loss_att 8.811007 loss_ctc 48.304688 loss_ctc_origin 34.063423 loss_ctc0 81.534302 lr 0.00065420 rank 0
2022-08-25 16:22:53,370 DEBUG TRAIN Batch 164/1900 loss 22.815554 loss_att 9.260201 loss_ctc 54.444702 loss_ctc_origin 35.383118 loss_ctc0 98.921722 lr 0.00065416 rank 0
2022-08-25 16:23:20,849 DEBUG TRAIN Batch 164/2000 loss 46.790882 loss_att 31.016270 loss_ctc 83.598312 loss_ctc_origin 52.977020 loss_ctc0 155.048004 lr 0.00065413 rank 0
2022-08-25 16:23:48,141 DEBUG TRAIN Batch 164/2100 loss 51.234589 loss_att 26.329082 loss_ctc 109.347427 loss_ctc_origin 50.969666 loss_ctc0 245.562210 lr 0.00065409 rank 0
2022-08-25 16:24:14,596 DEBUG TRAIN Batch 164/2200 loss 16.655886 loss_att 9.317110 loss_ctc 33.779694 loss_ctc_origin 22.896711 loss_ctc0 59.173309 lr 0.00065406 rank 0
2022-08-25 16:24:40,706 DEBUG TRAIN Batch 164/2300 loss 19.399906 loss_att 7.987529 loss_ctc 46.028782 loss_ctc_origin 28.953896 loss_ctc0 85.870178 lr 0.00065402 rank 0
2022-08-25 16:25:07,784 DEBUG TRAIN Batch 164/2400 loss 23.384052 loss_att 9.410046 loss_ctc 55.990067 loss_ctc_origin 35.115677 loss_ctc0 104.696976 lr 0.00065399 rank 0
2022-08-25 16:25:36,013 DEBUG TRAIN Batch 164/2500 loss 37.902554 loss_att 25.612122 loss_ctc 66.580231 loss_ctc_origin 37.127556 loss_ctc0 135.303146 lr 0.00065395 rank 0
2022-08-25 16:26:02,438 DEBUG TRAIN Batch 164/2600 loss 49.726128 loss_att 26.363632 loss_ctc 104.238617 loss_ctc_origin 56.246956 loss_ctc0 216.219162 lr 0.00065392 rank 0
2022-08-25 16:26:27,940 WARNING NaN or Inf found in input tensor.
2022-08-25 16:26:29,620 DEBUG TRAIN Batch 164/2700 loss 19.104334 loss_att 9.621870 loss_ctc 41.230083 loss_ctc_origin 30.508051 loss_ctc0 66.248161 lr 0.00065388 rank 0
2022-08-25 16:26:57,351 DEBUG TRAIN Batch 164/2800 loss 19.452074 loss_att 8.880426 loss_ctc 44.119247 loss_ctc_origin 28.437931 loss_ctc0 80.708984 lr 0.00065385 rank 0
2022-08-25 16:27:25,855 DEBUG TRAIN Batch 164/2900 loss 20.890881 loss_att 7.646963 loss_ctc 51.793354 loss_ctc_origin 31.259619 loss_ctc0 99.705399 lr 0.00065381 rank 0
2022-08-25 16:27:57,550 WARNING NaN or Inf found in input tensor.
2022-08-25 16:27:57,615 DEBUG TRAIN Batch 164/3000 loss inf loss_att 27.546347 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00065378 rank 0
2022-08-25 16:28:25,619 DEBUG TRAIN Batch 164/3100 loss 50.179596 loss_att 26.689100 loss_ctc 104.990761 loss_ctc_origin 53.860168 loss_ctc0 224.295471 lr 0.00065374 rank 0
2022-08-25 16:28:52,976 DEBUG TRAIN Batch 164/3200 loss 19.194464 loss_att 9.765464 loss_ctc 41.195465 loss_ctc_origin 28.412479 loss_ctc0 71.022438 lr 0.00065371 rank 0
2022-08-25 16:29:20,673 DEBUG TRAIN Batch 164/3300 loss 13.449707 loss_att 6.109194 loss_ctc 30.577568 loss_ctc_origin 17.048096 loss_ctc0 62.146332 lr 0.00065367 rank 0
2022-08-25 16:29:49,369 DEBUG TRAIN Batch 164/3400 loss 22.395012 loss_att 9.703526 loss_ctc 52.008476 loss_ctc_origin 33.433773 loss_ctc0 95.349449 lr 0.00065364 rank 0
2022-08-25 16:30:17,220 DEBUG TRAIN Batch 164/3500 loss 44.281189 loss_att 28.118122 loss_ctc 81.995010 loss_ctc_origin 49.409866 loss_ctc0 158.027008 lr 0.00065360 rank 0
2022-08-25 16:30:44,217 DEBUG TRAIN Batch 164/3600 loss 46.870766 loss_att 23.608452 loss_ctc 101.149490 loss_ctc_origin 48.184570 loss_ctc0 224.734314 lr 0.00065357 rank 0
2022-08-25 16:31:12,466 DEBUG TRAIN Batch 164/3700 loss 17.223396 loss_att 7.043918 loss_ctc 40.975513 loss_ctc_origin 28.177765 loss_ctc0 70.836922 lr 0.00065353 rank 0
2022-08-25 16:31:39,122 DEBUG TRAIN Batch 164/3800 loss 17.816849 loss_att 8.120668 loss_ctc 40.441269 loss_ctc_origin 28.009232 loss_ctc0 69.449356 lr 0.00065350 rank 0
2022-08-25 16:32:06,634 DEBUG TRAIN Batch 164/3900 loss 20.049261 loss_att 8.430937 loss_ctc 47.158684 loss_ctc_origin 30.247261 loss_ctc0 86.618668 lr 0.00065346 rank 0
2022-08-25 16:32:35,307 DEBUG TRAIN Batch 164/4000 loss 49.419830 loss_att 34.763569 loss_ctc 83.617767 loss_ctc_origin 53.380547 loss_ctc0 154.171265 lr 0.00065343 rank 0
2022-08-25 16:33:01,841 DEBUG TRAIN Batch 164/4100 loss 57.258469 loss_att 30.884260 loss_ctc 118.798294 loss_ctc_origin 65.644455 loss_ctc0 242.823914 lr 0.00065339 rank 0
2022-08-25 16:33:30,003 DEBUG TRAIN Batch 164/4200 loss 18.709435 loss_att 11.470378 loss_ctc 35.600563 loss_ctc_origin 24.712585 loss_ctc0 61.005836 lr 0.00065336 rank 0
2022-08-25 16:33:40,993 WARNING NaN or Inf found in input tensor.
2022-08-25 16:33:57,958 DEBUG TRAIN Batch 164/4300 loss 19.633398 loss_att 7.963477 loss_ctc 46.863213 loss_ctc_origin 31.108128 loss_ctc0 83.625076 lr 0.00065332 rank 0
2022-08-25 16:34:21,104 WARNING NaN or Inf found in input tensor.
2022-08-25 16:34:25,792 DEBUG TRAIN Batch 164/4400 loss 21.187202 loss_att 8.844873 loss_ctc 49.985970 loss_ctc_origin 31.255657 loss_ctc0 93.690033 lr 0.00065329 rank 0
2022-08-25 16:34:58,504 DEBUG TRAIN Batch 164/4500 loss 44.726570 loss_att 27.390182 loss_ctc 85.178131 loss_ctc_origin 48.806786 loss_ctc0 170.044601 lr 0.00065325 rank 0
2022-08-25 16:35:25,451 DEBUG TRAIN Batch 164/4600 loss 54.767990 loss_att 30.327505 loss_ctc 111.795792 loss_ctc_origin 61.273502 loss_ctc0 229.681122 lr 0.00065322 rank 0
2022-08-25 16:35:51,954 DEBUG TRAIN Batch 164/4700 loss 21.634228 loss_att 13.354650 loss_ctc 40.953239 loss_ctc_origin 30.083820 loss_ctc0 66.315216 lr 0.00065318 rank 0
2022-08-25 16:36:19,493 DEBUG TRAIN Batch 164/4800 loss 22.965588 loss_att 10.567955 loss_ctc 51.893398 loss_ctc_origin 36.611511 loss_ctc0 87.551132 lr 0.00065315 rank 0
2022-08-25 16:36:47,079 DEBUG TRAIN Batch 164/4900 loss 17.779041 loss_att 6.100262 loss_ctc 45.029526 loss_ctc_origin 25.928528 loss_ctc0 89.598511 lr 0.00065312 rank 0
2022-08-25 16:37:15,206 DEBUG TRAIN Batch 164/5000 loss 48.058044 loss_att 28.156223 loss_ctc 94.495621 loss_ctc_origin 61.941216 loss_ctc0 170.455902 lr 0.00065308 rank 0
2022-08-25 16:37:42,361 DEBUG TRAIN Batch 164/5100 loss 51.543056 loss_att 26.547781 loss_ctc 109.865356 loss_ctc_origin 59.175125 loss_ctc0 228.142532 lr 0.00065305 rank 0
2022-08-25 16:38:09,885 DEBUG TRAIN Batch 164/5200 loss 23.231503 loss_att 12.176176 loss_ctc 49.027260 loss_ctc_origin 37.543839 loss_ctc0 75.821915 lr 0.00065301 rank 0
2022-08-25 16:38:37,753 DEBUG TRAIN Batch 164/5300 loss 19.635946 loss_att 9.303972 loss_ctc 43.743881 loss_ctc_origin 27.882830 loss_ctc0 80.752998 lr 0.00065298 rank 0
2022-08-25 16:39:05,110 DEBUG TRAIN Batch 164/5400 loss 20.312729 loss_att 8.868932 loss_ctc 47.014919 loss_ctc_origin 30.851107 loss_ctc0 84.730484 lr 0.00065294 rank 0
2022-08-25 16:39:32,102 DEBUG TRAIN Batch 164/5500 loss 41.140121 loss_att 27.101505 loss_ctc 73.896889 loss_ctc_origin 45.694702 loss_ctc0 139.701996 lr 0.00065291 rank 0
2022-08-25 16:39:58,904 DEBUG TRAIN Batch 164/5600 loss 49.075874 loss_att 25.467705 loss_ctc 104.161598 loss_ctc_origin 54.564800 loss_ctc0 219.887451 lr 0.00065287 rank 0
2022-08-25 16:40:21,658 DEBUG CV Batch 164/0 loss 11.965361 loss_att 9.107328 loss_ctc 18.634102 loss_ctc_origin 12.321458 loss_ctc0 33.363605 history loss 11.261516 rank 0
2022-08-25 16:40:32,619 DEBUG CV Batch 164/100 loss 20.532070 loss_att 16.338209 loss_ctc 30.317745 loss_ctc_origin 20.716045 loss_ctc0 52.721710 history loss 26.184070 rank 0
2022-08-25 16:40:42,720 DEBUG CV Batch 164/200 loss 25.408218 loss_att 19.651146 loss_ctc 38.841385 loss_ctc_origin 28.863400 loss_ctc0 62.123341 history loss 27.608428 rank 0
2022-08-25 16:40:53,266 DEBUG CV Batch 164/300 loss 23.149002 loss_att 17.489182 loss_ctc 36.355247 loss_ctc_origin 21.009577 loss_ctc0 72.161804 history loss 26.650442 rank 0
2022-08-25 16:41:04,238 DEBUG CV Batch 164/400 loss 37.240772 loss_att 30.416454 loss_ctc 53.164185 loss_ctc_origin 35.707695 loss_ctc0 93.895996 history loss 24.975871 rank 0
2022-08-25 16:41:15,092 DEBUG CV Batch 164/500 loss 15.695723 loss_att 11.785830 loss_ctc 24.818806 loss_ctc_origin 17.320566 loss_ctc0 42.314697 history loss 24.642348 rank 0
2022-08-25 16:41:25,471 DEBUG CV Batch 164/600 loss 16.845898 loss_att 11.722883 loss_ctc 28.799599 loss_ctc_origin 18.123779 loss_ctc0 53.709839 history loss 24.398067 rank 0
2022-08-25 16:41:35,296 DEBUG CV Batch 164/700 loss 18.044041 loss_att 12.144202 loss_ctc 31.810328 loss_ctc_origin 18.511028 loss_ctc0 62.842026 history loss 24.074759 rank 0
2022-08-25 16:41:45,766 DEBUG CV Batch 164/800 loss 21.787277 loss_att 17.196484 loss_ctc 32.499126 loss_ctc_origin 17.068050 loss_ctc0 68.504974 history loss 24.056398 rank 0
2022-08-25 16:41:55,917 INFO Epoch 164 CV info cv_loss 24.16909662341093
2022-08-25 16:41:55,917 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/164.pt
2022-08-25 16:41:56,352 INFO Epoch 165 TRAIN info lr 0.0006528422151243956
2022-08-25 16:41:56,355 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 16:42:24,075 DEBUG TRAIN Batch 165/0 loss 51.773746 loss_att 36.473228 loss_ctc 87.474953 loss_ctc_origin 59.747818 loss_ctc0 152.171600 lr 0.00065284 rank 0
2022-08-25 16:42:52,206 DEBUG TRAIN Batch 165/100 loss 52.931084 loss_att 28.362774 loss_ctc 110.257141 loss_ctc_origin 64.884094 loss_ctc0 216.127594 lr 0.00065281 rank 0
2022-08-25 16:43:20,038 DEBUG TRAIN Batch 165/200 loss 16.064947 loss_att 7.427497 loss_ctc 36.218994 loss_ctc_origin 24.378521 loss_ctc0 63.846767 lr 0.00065277 rank 0
2022-08-25 16:43:48,797 DEBUG TRAIN Batch 165/300 loss 17.186337 loss_att 7.584594 loss_ctc 39.590401 loss_ctc_origin 24.916695 loss_ctc0 73.829041 lr 0.00065274 rank 0
2022-08-25 16:44:18,630 DEBUG TRAIN Batch 165/400 loss 21.242331 loss_att 8.393387 loss_ctc 51.223198 loss_ctc_origin 33.991943 loss_ctc0 91.429451 lr 0.00065270 rank 0
2022-08-25 16:44:46,648 DEBUG TRAIN Batch 165/500 loss 44.067719 loss_att 29.993715 loss_ctc 76.907051 loss_ctc_origin 49.652153 loss_ctc0 140.501801 lr 0.00065267 rank 0
2022-08-25 16:45:15,258 DEBUG TRAIN Batch 165/600 loss 44.213474 loss_att 24.783297 loss_ctc 89.550552 loss_ctc_origin 48.040424 loss_ctc0 186.407532 lr 0.00065263 rank 0
2022-08-25 16:45:44,120 DEBUG TRAIN Batch 165/700 loss 19.370731 loss_att 9.648917 loss_ctc 42.054962 loss_ctc_origin 30.455940 loss_ctc0 69.119347 lr 0.00065260 rank 0
2022-08-25 16:46:12,103 DEBUG TRAIN Batch 165/800 loss 18.198357 loss_att 7.392162 loss_ctc 43.412811 loss_ctc_origin 29.299814 loss_ctc0 76.343124 lr 0.00065256 rank 0
2022-08-25 16:46:40,208 DEBUG TRAIN Batch 165/900 loss 22.122135 loss_att 8.503051 loss_ctc 53.899998 loss_ctc_origin 34.733349 loss_ctc0 98.622177 lr 0.00065253 rank 0
2022-08-25 16:47:08,255 DEBUG TRAIN Batch 165/1000 loss 41.886242 loss_att 28.567524 loss_ctc 72.963249 loss_ctc_origin 51.052975 loss_ctc0 124.087219 lr 0.00065249 rank 0
2022-08-25 16:47:30,096 WARNING NaN or Inf found in input tensor.
2022-08-25 16:47:36,932 DEBUG TRAIN Batch 165/1100 loss 49.172260 loss_att 28.538773 loss_ctc 97.317062 loss_ctc_origin 57.683029 loss_ctc0 189.796478 lr 0.00065246 rank 0
2022-08-25 16:48:05,350 DEBUG TRAIN Batch 165/1200 loss 20.986115 loss_att 10.448513 loss_ctc 45.573853 loss_ctc_origin 33.833202 loss_ctc0 72.968697 lr 0.00065242 rank 0
2022-08-25 16:48:34,687 DEBUG TRAIN Batch 165/1300 loss 16.864008 loss_att 6.654898 loss_ctc 40.685265 loss_ctc_origin 28.236147 loss_ctc0 69.733200 lr 0.00065239 rank 0
2022-08-25 16:49:03,247 DEBUG TRAIN Batch 165/1400 loss 19.329727 loss_att 8.093130 loss_ctc 45.548454 loss_ctc_origin 28.081863 loss_ctc0 86.303833 lr 0.00065235 rank 0
2022-08-25 16:49:39,669 DEBUG TRAIN Batch 165/1500 loss 46.215771 loss_att 31.209993 loss_ctc 81.229248 loss_ctc_origin 47.226341 loss_ctc0 160.569366 lr 0.00065232 rank 0
2022-08-25 16:50:08,233 DEBUG TRAIN Batch 165/1600 loss 46.458832 loss_att 25.765362 loss_ctc 94.743584 loss_ctc_origin 49.459076 loss_ctc0 200.407425 lr 0.00065229 rank 0
2022-08-25 16:50:36,489 DEBUG TRAIN Batch 165/1700 loss 21.255665 loss_att 11.996534 loss_ctc 42.860302 loss_ctc_origin 32.163670 loss_ctc0 67.819107 lr 0.00065225 rank 0
2022-08-25 16:51:05,106 DEBUG TRAIN Batch 165/1800 loss 18.097891 loss_att 7.630228 loss_ctc 42.522438 loss_ctc_origin 28.159374 loss_ctc0 76.036263 lr 0.00065222 rank 0
2022-08-25 16:51:34,558 DEBUG TRAIN Batch 165/1900 loss 21.537926 loss_att 8.599692 loss_ctc 51.727139 loss_ctc_origin 31.157455 loss_ctc0 99.723061 lr 0.00065218 rank 0
2022-08-25 16:52:03,544 DEBUG TRAIN Batch 165/2000 loss 36.269753 loss_att 23.809731 loss_ctc 65.343140 loss_ctc_origin 41.765476 loss_ctc0 120.357674 lr 0.00065215 rank 0
2022-08-25 16:52:32,088 DEBUG TRAIN Batch 165/2100 loss 39.230682 loss_att 19.744501 loss_ctc 84.698441 loss_ctc_origin 38.005753 loss_ctc0 193.648041 lr 0.00065211 rank 0
2022-08-25 16:53:00,239 DEBUG TRAIN Batch 165/2200 loss 17.778208 loss_att 9.306267 loss_ctc 37.546066 loss_ctc_origin 25.880878 loss_ctc0 64.764832 lr 0.00065208 rank 0
2022-08-25 16:53:29,299 DEBUG TRAIN Batch 165/2300 loss 19.675962 loss_att 8.388759 loss_ctc 46.012772 loss_ctc_origin 30.602108 loss_ctc0 81.970985 lr 0.00065204 rank 0
2022-08-25 16:53:56,996 DEBUG TRAIN Batch 165/2400 loss 25.186695 loss_att 11.026623 loss_ctc 58.226860 loss_ctc_origin 41.034279 loss_ctc0 98.342873 lr 0.00065201 rank 0
2022-08-25 16:54:25,996 DEBUG TRAIN Batch 165/2500 loss 49.464180 loss_att 32.254604 loss_ctc 89.619850 loss_ctc_origin 56.189919 loss_ctc0 167.623016 lr 0.00065197 rank 0
2022-08-25 16:54:54,549 DEBUG TRAIN Batch 165/2600 loss 55.164383 loss_att 28.997326 loss_ctc 116.220856 loss_ctc_origin 63.763287 loss_ctc0 238.621841 lr 0.00065194 rank 0
2022-08-25 16:55:23,541 DEBUG TRAIN Batch 165/2700 loss 20.961700 loss_att 11.818722 loss_ctc 42.295319 loss_ctc_origin 30.357967 loss_ctc0 70.149139 lr 0.00065190 rank 0
2022-08-25 16:55:53,348 DEBUG TRAIN Batch 165/2800 loss 19.232565 loss_att 7.623581 loss_ctc 46.320190 loss_ctc_origin 30.867355 loss_ctc0 82.376801 lr 0.00065187 rank 0
2022-08-25 16:56:21,185 DEBUG TRAIN Batch 165/2900 loss 20.042673 loss_att 7.802671 loss_ctc 48.602676 loss_ctc_origin 31.901505 loss_ctc0 87.572083 lr 0.00065183 rank 0
2022-08-25 16:56:29,985 WARNING NaN or Inf found in input tensor.
2022-08-25 16:56:55,913 DEBUG TRAIN Batch 165/3000 loss 46.739189 loss_att 31.821377 loss_ctc 81.547409 loss_ctc_origin 52.939835 loss_ctc0 148.298401 lr 0.00065180 rank 0
2022-08-25 16:57:24,699 DEBUG TRAIN Batch 165/3100 loss 57.135967 loss_att 31.886541 loss_ctc 116.051292 loss_ctc_origin 65.847527 loss_ctc0 233.193405 lr 0.00065177 rank 0
2022-08-25 16:57:53,220 DEBUG TRAIN Batch 165/3200 loss 20.397972 loss_att 9.789476 loss_ctc 45.151123 loss_ctc_origin 32.450623 loss_ctc0 74.785629 lr 0.00065173 rank 0
2022-08-25 16:58:20,749 DEBUG TRAIN Batch 165/3300 loss 17.001045 loss_att 6.478556 loss_ctc 41.553516 loss_ctc_origin 26.548737 loss_ctc0 76.564667 lr 0.00065170 rank 0
2022-08-25 16:58:49,118 DEBUG TRAIN Batch 165/3400 loss 22.494349 loss_att 9.090366 loss_ctc 53.770306 loss_ctc_origin 37.341240 loss_ctc0 92.104790 lr 0.00065166 rank 0
2022-08-25 16:58:58,268 WARNING NaN or Inf found in input tensor.
2022-08-25 16:58:58,982 WARNING NaN or Inf found in input tensor.
2022-08-25 16:59:17,848 DEBUG TRAIN Batch 165/3500 loss 52.754349 loss_att 36.120365 loss_ctc 91.566971 loss_ctc_origin 62.373814 loss_ctc0 159.684326 lr 0.00065163 rank 0
2022-08-25 16:59:46,288 DEBUG TRAIN Batch 165/3600 loss 54.529465 loss_att 30.376982 loss_ctc 110.885254 loss_ctc_origin 60.932926 loss_ctc0 227.440674 lr 0.00065159 rank 0
2022-08-25 17:00:14,563 DEBUG TRAIN Batch 165/3700 loss 19.006403 loss_att 10.299849 loss_ctc 39.321697 loss_ctc_origin 28.659931 loss_ctc0 64.199150 lr 0.00065156 rank 0
2022-08-25 17:00:43,627 DEBUG TRAIN Batch 165/3800 loss 17.863527 loss_att 7.826679 loss_ctc 41.282837 loss_ctc_origin 27.115627 loss_ctc0 74.339668 lr 0.00065152 rank 0
2022-08-25 17:01:12,145 DEBUG TRAIN Batch 165/3900 loss 20.379416 loss_att 8.694180 loss_ctc 47.644966 loss_ctc_origin 29.255890 loss_ctc0 90.552811 lr 0.00065149 rank 0
2022-08-25 17:01:41,567 DEBUG TRAIN Batch 165/4000 loss 48.994217 loss_att 31.283783 loss_ctc 90.318558 loss_ctc_origin 57.622032 loss_ctc0 166.610428 lr 0.00065145 rank 0
2022-08-25 17:01:42,264 WARNING NaN or Inf found in input tensor.
2022-08-25 17:02:10,260 DEBUG TRAIN Batch 165/4100 loss 47.939461 loss_att 25.690983 loss_ctc 99.852577 loss_ctc_origin 52.435226 loss_ctc0 210.493057 lr 0.00065142 rank 0
2022-08-25 17:02:38,514 DEBUG TRAIN Batch 165/4200 loss 18.779856 loss_att 9.642778 loss_ctc 40.099701 loss_ctc_origin 28.624508 loss_ctc0 66.875153 lr 0.00065138 rank 0
2022-08-25 17:03:06,815 DEBUG TRAIN Batch 165/4300 loss 15.543184 loss_att 6.092543 loss_ctc 37.594681 loss_ctc_origin 21.518057 loss_ctc0 75.106812 lr 0.00065135 rank 0
2022-08-25 17:03:34,957 DEBUG TRAIN Batch 165/4400 loss 23.872030 loss_att 9.895835 loss_ctc 56.483150 loss_ctc_origin 37.095413 loss_ctc0 101.721199 lr 0.00065132 rank 0
2022-08-25 17:03:44,210 WARNING NaN or Inf found in input tensor.
2022-08-25 17:04:10,686 DEBUG TRAIN Batch 165/4500 loss 41.697372 loss_att 26.712545 loss_ctc 76.661972 loss_ctc_origin 47.096851 loss_ctc0 145.647263 lr 0.00065128 rank 0
2022-08-25 17:04:40,447 DEBUG TRAIN Batch 165/4600 loss 50.512268 loss_att 26.786911 loss_ctc 105.871429 loss_ctc_origin 55.846649 loss_ctc0 222.595886 lr 0.00065125 rank 0
2022-08-25 17:05:09,448 DEBUG TRAIN Batch 165/4700 loss 19.841328 loss_att 11.041028 loss_ctc 40.375355 loss_ctc_origin 28.349205 loss_ctc0 68.436371 lr 0.00065121 rank 0
2022-08-25 17:05:15,054 WARNING NaN or Inf found in input tensor.
2022-08-25 17:05:37,434 DEBUG TRAIN Batch 165/4800 loss 20.122869 loss_att 8.489645 loss_ctc 47.267059 loss_ctc_origin 32.991982 loss_ctc0 80.575569 lr 0.00065118 rank 0
2022-08-25 17:06:06,379 DEBUG TRAIN Batch 165/4900 loss 21.700983 loss_att 9.357816 loss_ctc 50.501705 loss_ctc_origin 31.394554 loss_ctc0 95.085060 lr 0.00065114 rank 0
2022-08-25 17:06:36,208 DEBUG TRAIN Batch 165/5000 loss 49.885284 loss_att 32.098507 loss_ctc 91.387756 loss_ctc_origin 59.848457 loss_ctc0 164.979446 lr 0.00065111 rank 0
2022-08-25 17:07:04,234 DEBUG TRAIN Batch 165/5100 loss 53.268669 loss_att 30.761351 loss_ctc 105.785744 loss_ctc_origin 56.165653 loss_ctc0 221.565948 lr 0.00065107 rank 0
2022-08-25 17:07:33,822 DEBUG TRAIN Batch 165/5200 loss 20.442982 loss_att 11.170319 loss_ctc 42.079193 loss_ctc_origin 29.483095 loss_ctc0 71.470078 lr 0.00065104 rank 0
2022-08-25 17:08:02,276 DEBUG TRAIN Batch 165/5300 loss 18.245247 loss_att 7.948253 loss_ctc 42.271561 loss_ctc_origin 26.846462 loss_ctc0 78.263458 lr 0.00065101 rank 0
2022-08-25 17:08:31,588 DEBUG TRAIN Batch 165/5400 loss 19.552109 loss_att 7.731133 loss_ctc 47.134384 loss_ctc_origin 27.901360 loss_ctc0 92.011436 lr 0.00065097 rank 0
2022-08-25 17:09:01,733 DEBUG TRAIN Batch 165/5500 loss 48.337265 loss_att 32.600220 loss_ctc 85.057037 loss_ctc_origin 54.366383 loss_ctc0 156.668549 lr 0.00065094 rank 0
2022-08-25 17:09:30,351 DEBUG TRAIN Batch 165/5600 loss 49.606369 loss_att 27.906172 loss_ctc 100.240158 loss_ctc_origin 58.295258 loss_ctc0 198.111603 lr 0.00065090 rank 0
2022-08-25 17:09:44,067 WARNING NaN or Inf found in input tensor.
2022-08-25 17:09:53,908 DEBUG CV Batch 165/0 loss 11.728586 loss_att 8.687754 loss_ctc 18.823862 loss_ctc_origin 12.319688 loss_ctc0 34.000267 history loss 11.038669 rank 0
2022-08-25 17:10:04,690 DEBUG CV Batch 165/100 loss 19.770126 loss_att 15.537413 loss_ctc 29.646461 loss_ctc_origin 19.536121 loss_ctc0 53.237251 history loss 25.942229 rank 0
2022-08-25 17:10:14,371 DEBUG CV Batch 165/200 loss 25.854519 loss_att 20.238827 loss_ctc 38.957802 loss_ctc_origin 28.935619 loss_ctc0 62.342888 history loss 27.308346 rank 0
2022-08-25 17:10:23,994 DEBUG CV Batch 165/300 loss 22.444527 loss_att 17.000723 loss_ctc 35.146732 loss_ctc_origin 19.607319 loss_ctc0 71.405365 history loss 26.452520 rank 0
2022-08-25 17:10:34,248 DEBUG CV Batch 165/400 loss 37.038235 loss_att 29.954094 loss_ctc 53.567894 loss_ctc_origin 35.632629 loss_ctc0 95.416832 history loss 24.818199 rank 0
2022-08-25 17:10:45,009 DEBUG CV Batch 165/500 loss 16.230112 loss_att 12.636896 loss_ctc 24.614285 loss_ctc_origin 17.322588 loss_ctc0 41.628239 history loss 24.473685 rank 0
2022-08-25 17:10:55,469 DEBUG CV Batch 165/600 loss 16.917210 loss_att 11.770746 loss_ctc 28.925625 loss_ctc_origin 17.942081 loss_ctc0 54.553890 history loss 24.287649 rank 0
2022-08-25 17:11:05,611 DEBUG CV Batch 165/700 loss 18.805145 loss_att 12.788314 loss_ctc 32.844414 loss_ctc_origin 19.290684 loss_ctc0 64.469788 history loss 23.973547 rank 0
2022-08-25 17:11:16,241 DEBUG CV Batch 165/800 loss 21.351141 loss_att 16.864567 loss_ctc 31.819813 loss_ctc_origin 15.657559 loss_ctc0 69.531731 history loss 23.933597 rank 0
2022-08-25 17:11:26,677 INFO Epoch 165 CV info cv_loss 24.017395846532697
2022-08-25 17:11:26,677 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/165.pt
2022-08-25 17:11:27,170 INFO Epoch 166 TRAIN info lr 0.0006508728525223992
2022-08-25 17:11:27,174 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 17:11:53,958 DEBUG TRAIN Batch 166/0 loss 47.854282 loss_att 32.975616 loss_ctc 82.571167 loss_ctc_origin 53.219032 loss_ctc0 151.059464 lr 0.00065087 rank 0
2022-08-25 17:12:22,083 DEBUG TRAIN Batch 166/100 loss 46.520531 loss_att 25.428442 loss_ctc 95.735397 loss_ctc_origin 45.689644 loss_ctc0 212.508820 lr 0.00065084 rank 0
2022-08-25 17:12:51,381 DEBUG TRAIN Batch 166/200 loss 17.443932 loss_att 8.016991 loss_ctc 39.440125 loss_ctc_origin 28.193174 loss_ctc0 65.682999 lr 0.00065080 rank 0
2022-08-25 17:13:20,522 DEBUG TRAIN Batch 166/300 loss 20.548040 loss_att 9.132590 loss_ctc 47.184090 loss_ctc_origin 32.750698 loss_ctc0 80.862000 lr 0.00065077 rank 0
2022-08-25 17:13:49,444 DEBUG TRAIN Batch 166/400 loss 20.754089 loss_att 7.473643 loss_ctc 51.741791 loss_ctc_origin 32.524696 loss_ctc0 96.581673 lr 0.00065073 rank 0
2022-08-25 17:14:18,168 DEBUG TRAIN Batch 166/500 loss 45.602036 loss_att 28.399054 loss_ctc 85.742325 loss_ctc_origin 53.986511 loss_ctc0 159.839203 lr 0.00065070 rank 0
2022-08-25 17:14:47,044 DEBUG TRAIN Batch 166/600 loss 51.373116 loss_att 28.212696 loss_ctc 105.414093 loss_ctc_origin 60.217720 loss_ctc0 210.872299 lr 0.00065066 rank 0
2022-08-25 17:15:15,089 DEBUG TRAIN Batch 166/700 loss 19.517405 loss_att 10.368866 loss_ctc 40.863991 loss_ctc_origin 32.196472 loss_ctc0 61.088192 lr 0.00065063 rank 0
2022-08-25 17:15:39,009 WARNING NaN or Inf found in input tensor.
2022-08-25 17:15:42,371 DEBUG TRAIN Batch 166/800 loss 21.246220 loss_att 9.678843 loss_ctc 48.236767 loss_ctc_origin 35.386696 loss_ctc0 78.220261 lr 0.00065060 rank 0
2022-08-25 17:16:10,418 DEBUG TRAIN Batch 166/900 loss 19.928728 loss_att 7.769730 loss_ctc 48.299721 loss_ctc_origin 30.041418 loss_ctc0 90.902435 lr 0.00065056 rank 0
2022-08-25 17:16:38,627 DEBUG TRAIN Batch 166/1000 loss 49.224224 loss_att 31.875500 loss_ctc 89.704582 loss_ctc_origin 53.327881 loss_ctc0 174.583542 lr 0.00065053 rank 0
2022-08-25 17:17:06,499 DEBUG TRAIN Batch 166/1100 loss 56.556969 loss_att 31.396242 loss_ctc 115.265335 loss_ctc_origin 65.136711 loss_ctc0 232.232117 lr 0.00065049 rank 0
2022-08-25 17:17:35,328 DEBUG TRAIN Batch 166/1200 loss 18.197678 loss_att 9.213631 loss_ctc 39.160450 loss_ctc_origin 28.355906 loss_ctc0 64.371048 lr 0.00065046 rank 0
2022-08-25 17:18:03,019 DEBUG TRAIN Batch 166/1300 loss 19.124435 loss_att 8.161882 loss_ctc 44.703728 loss_ctc_origin 30.868906 loss_ctc0 76.984978 lr 0.00065042 rank 0
2022-08-25 17:18:20,799 WARNING NaN or Inf found in input tensor.
2022-08-25 17:18:32,356 DEBUG TRAIN Batch 166/1400 loss 25.686592 loss_att 10.323918 loss_ctc 61.532833 loss_ctc_origin 42.390686 loss_ctc0 106.197845 lr 0.00065039 rank 0
2022-08-25 17:19:06,622 DEBUG TRAIN Batch 166/1500 loss 48.582886 loss_att 30.267870 loss_ctc 91.317917 loss_ctc_origin 56.270584 loss_ctc0 173.095016 lr 0.00065036 rank 0
2022-08-25 17:19:34,952 DEBUG TRAIN Batch 166/1600 loss 52.473801 loss_att 27.285934 loss_ctc 111.245483 loss_ctc_origin 56.634338 loss_ctc0 238.671478 lr 0.00065032 rank 0
2022-08-25 17:20:03,185 DEBUG TRAIN Batch 166/1700 loss 16.849560 loss_att 7.988462 loss_ctc 37.525452 loss_ctc_origin 26.850832 loss_ctc0 62.432888 lr 0.00065029 rank 0
2022-08-25 17:20:31,181 DEBUG TRAIN Batch 166/1800 loss 18.807077 loss_att 6.734852 loss_ctc 46.975601 loss_ctc_origin 32.821098 loss_ctc0 80.002777 lr 0.00065025 rank 0
2022-08-25 17:20:59,049 DEBUG TRAIN Batch 166/1900 loss 23.229618 loss_att 9.053970 loss_ctc 56.306129 loss_ctc_origin 37.436020 loss_ctc0 100.336380 lr 0.00065022 rank 0
2022-08-25 17:21:27,028 DEBUG TRAIN Batch 166/2000 loss 39.204269 loss_att 25.266884 loss_ctc 71.724838 loss_ctc_origin 45.049961 loss_ctc0 133.966217 lr 0.00065018 rank 0
2022-08-25 17:21:55,165 DEBUG TRAIN Batch 166/2100 loss 35.136700 loss_att 17.811829 loss_ctc 75.561401 loss_ctc_origin 40.926929 loss_ctc0 156.375183 lr 0.00065015 rank 0
2022-08-25 17:22:22,715 DEBUG TRAIN Batch 166/2200 loss 17.851543 loss_att 10.414682 loss_ctc 35.204216 loss_ctc_origin 24.241241 loss_ctc0 60.784492 lr 0.00065011 rank 0
2022-08-25 17:22:50,751 DEBUG TRAIN Batch 166/2300 loss 19.178864 loss_att 7.437458 loss_ctc 46.575474 loss_ctc_origin 30.619545 loss_ctc0 83.805969 lr 0.00065008 rank 0
2022-08-25 17:23:18,989 DEBUG TRAIN Batch 166/2400 loss 19.594103 loss_att 8.191264 loss_ctc 46.200726 loss_ctc_origin 26.867199 loss_ctc0 91.312286 lr 0.00065005 rank 0
2022-08-25 17:23:47,549 DEBUG TRAIN Batch 166/2500 loss 44.486031 loss_att 28.455688 loss_ctc 81.890167 loss_ctc_origin 50.977486 loss_ctc0 154.019745 lr 0.00065001 rank 0
2022-08-25 17:24:14,976 DEBUG TRAIN Batch 166/2600 loss 51.893658 loss_att 30.480850 loss_ctc 101.856873 loss_ctc_origin 61.946266 loss_ctc0 194.981628 lr 0.00064998 rank 0
2022-08-25 17:24:42,314 DEBUG TRAIN Batch 166/2700 loss 20.064571 loss_att 12.753812 loss_ctc 37.123009 loss_ctc_origin 26.304090 loss_ctc0 62.367157 lr 0.00064994 rank 0
2022-08-25 17:25:10,258 DEBUG TRAIN Batch 166/2800 loss 22.356392 loss_att 10.076834 loss_ctc 51.008698 loss_ctc_origin 36.414856 loss_ctc0 85.060989 lr 0.00064991 rank 0
2022-08-25 17:25:38,494 DEBUG TRAIN Batch 166/2900 loss 17.211926 loss_att 6.110185 loss_ctc 43.115982 loss_ctc_origin 24.670414 loss_ctc0 86.155640 lr 0.00064987 rank 0
2022-08-25 17:26:12,543 DEBUG TRAIN Batch 166/3000 loss 42.655075 loss_att 25.616360 loss_ctc 82.412079 loss_ctc_origin 54.154388 loss_ctc0 148.346680 lr 0.00064984 rank 0
2022-08-25 17:26:40,994 DEBUG TRAIN Batch 166/3100 loss 50.066383 loss_att 27.932545 loss_ctc 101.712006 loss_ctc_origin 56.128525 loss_ctc0 208.073471 lr 0.00064981 rank 0
2022-08-25 17:27:07,353 WARNING NaN or Inf found in input tensor.
2022-08-25 17:27:08,931 DEBUG TRAIN Batch 166/3200 loss 17.943947 loss_att 9.458404 loss_ctc 37.743546 loss_ctc_origin 27.281748 loss_ctc0 62.154396 lr 0.00064977 rank 0
2022-08-25 17:27:37,218 DEBUG TRAIN Batch 166/3300 loss 17.084974 loss_att 7.096820 loss_ctc 40.390663 loss_ctc_origin 24.491982 loss_ctc0 77.487579 lr 0.00064974 rank 0
2022-08-25 17:28:04,694 DEBUG TRAIN Batch 166/3400 loss 20.762337 loss_att 7.218416 loss_ctc 52.364822 loss_ctc_origin 32.257435 loss_ctc0 99.282059 lr 0.00064970 rank 0
2022-08-25 17:28:33,144 DEBUG TRAIN Batch 166/3500 loss 46.868454 loss_att 29.308636 loss_ctc 87.841354 loss_ctc_origin 56.524494 loss_ctc0 160.914032 lr 0.00064967 rank 0
2022-08-25 17:28:40,681 WARNING NaN or Inf found in input tensor.
2022-08-25 17:29:02,403 DEBUG TRAIN Batch 166/3600 loss 48.440662 loss_att 25.830854 loss_ctc 101.196877 loss_ctc_origin 49.391228 loss_ctc0 222.076721 lr 0.00064963 rank 0
2022-08-25 17:29:28,981 WARNING NaN or Inf found in input tensor.
2022-08-25 17:29:30,571 DEBUG TRAIN Batch 166/3700 loss 21.126823 loss_att 10.168106 loss_ctc 46.697159 loss_ctc_origin 37.193859 loss_ctc0 68.871521 lr 0.00064960 rank 0
2022-08-25 17:29:59,426 DEBUG TRAIN Batch 166/3800 loss 16.818035 loss_att 7.102151 loss_ctc 39.488426 loss_ctc_origin 23.833603 loss_ctc0 76.016342 lr 0.00064957 rank 0
2022-08-25 17:30:29,233 DEBUG TRAIN Batch 166/3900 loss 17.502834 loss_att 6.683347 loss_ctc 42.748306 loss_ctc_origin 24.611473 loss_ctc0 85.067589 lr 0.00064953 rank 0
2022-08-25 17:30:58,115 DEBUG TRAIN Batch 166/4000 loss 40.876083 loss_att 27.299536 loss_ctc 72.554703 loss_ctc_origin 43.290009 loss_ctc0 140.838974 lr 0.00064950 rank 0
2022-08-25 17:31:10,914 WARNING NaN or Inf found in input tensor.
2022-08-25 17:31:25,152 DEBUG TRAIN Batch 166/4100 loss 50.976917 loss_att 27.930466 loss_ctc 104.751968 loss_ctc_origin 61.083282 loss_ctc0 206.645569 lr 0.00064946 rank 0
2022-08-25 17:31:53,017 DEBUG TRAIN Batch 166/4200 loss 20.701260 loss_att 10.879688 loss_ctc 43.618259 loss_ctc_origin 31.869469 loss_ctc0 71.032104 lr 0.00064943 rank 0
2022-08-25 17:32:21,511 DEBUG TRAIN Batch 166/4300 loss 17.514744 loss_att 7.144450 loss_ctc 41.712097 loss_ctc_origin 25.620815 loss_ctc0 79.258423 lr 0.00064939 rank 0
2022-08-25 17:32:38,991 WARNING NaN or Inf found in input tensor.
2022-08-25 17:32:50,324 DEBUG TRAIN Batch 166/4400 loss 20.867085 loss_att 8.705854 loss_ctc 49.243282 loss_ctc_origin 30.821083 loss_ctc0 92.228409 lr 0.00064936 rank 0
2022-08-25 17:33:23,876 DEBUG TRAIN Batch 166/4500 loss 43.550751 loss_att 28.845299 loss_ctc 77.863464 loss_ctc_origin 50.788448 loss_ctc0 141.038483 lr 0.00064933 rank 0
2022-08-25 17:33:52,534 DEBUG TRAIN Batch 166/4600 loss 45.276672 loss_att 23.976324 loss_ctc 94.977478 loss_ctc_origin 48.133808 loss_ctc0 204.279388 lr 0.00064929 rank 0
2022-08-25 17:34:19,840 DEBUG TRAIN Batch 166/4700 loss 18.613150 loss_att 9.193539 loss_ctc 40.592239 loss_ctc_origin 31.271914 loss_ctc0 62.339657 lr 0.00064926 rank 0
2022-08-25 17:34:48,731 DEBUG TRAIN Batch 166/4800 loss 20.723602 loss_att 9.292315 loss_ctc 47.396606 loss_ctc_origin 32.514107 loss_ctc0 82.122437 lr 0.00064922 rank 0
2022-08-25 17:34:59,097 WARNING NaN or Inf found in input tensor.
2022-08-25 17:35:18,224 DEBUG TRAIN Batch 166/4900 loss 23.236555 loss_att 10.065367 loss_ctc 53.969322 loss_ctc_origin 36.699696 loss_ctc0 94.265106 lr 0.00064919 rank 0
2022-08-25 17:35:47,126 DEBUG TRAIN Batch 166/5000 loss 44.119823 loss_att 31.735012 loss_ctc 73.017715 loss_ctc_origin 50.633400 loss_ctc0 125.247787 lr 0.00064915 rank 0
2022-08-25 17:36:15,294 DEBUG TRAIN Batch 166/5100 loss 53.210747 loss_att 28.946526 loss_ctc 109.827271 loss_ctc_origin 56.748901 loss_ctc0 233.676788 lr 0.00064912 rank 0
2022-08-25 17:36:43,230 DEBUG TRAIN Batch 166/5200 loss 18.288742 loss_att 10.057049 loss_ctc 37.496025 loss_ctc_origin 25.456955 loss_ctc0 65.587189 lr 0.00064909 rank 0
2022-08-25 17:37:11,911 DEBUG TRAIN Batch 166/5300 loss 19.274679 loss_att 8.255577 loss_ctc 44.985916 loss_ctc_origin 29.855631 loss_ctc0 80.289917 lr 0.00064905 rank 0
2022-08-25 17:37:36,327 WARNING NaN or Inf found in input tensor.
2022-08-25 17:37:40,805 DEBUG TRAIN Batch 166/5400 loss 19.692627 loss_att 8.258721 loss_ctc 46.371735 loss_ctc_origin 27.325829 loss_ctc0 90.812172 lr 0.00064902 rank 0
2022-08-25 17:38:09,246 DEBUG TRAIN Batch 166/5500 loss 46.399300 loss_att 30.245163 loss_ctc 84.092285 loss_ctc_origin 53.141964 loss_ctc0 156.309677 lr 0.00064898 rank 0
2022-08-25 17:38:36,840 DEBUG TRAIN Batch 166/5600 loss 54.582115 loss_att 27.017319 loss_ctc 118.899963 loss_ctc_origin 64.766144 loss_ctc0 245.212204 lr 0.00064895 rank 0
2022-08-25 17:38:59,791 DEBUG CV Batch 166/0 loss 12.245745 loss_att 9.223237 loss_ctc 19.298262 loss_ctc_origin 13.055088 loss_ctc0 33.865665 history loss 11.525407 rank 0
2022-08-25 17:39:10,400 DEBUG CV Batch 166/100 loss 20.046165 loss_att 15.846231 loss_ctc 29.846016 loss_ctc_origin 19.790937 loss_ctc0 53.307861 history loss 25.864581 rank 0
2022-08-25 17:39:20,087 DEBUG CV Batch 166/200 loss 26.028290 loss_att 20.364677 loss_ctc 39.243382 loss_ctc_origin 29.155968 loss_ctc0 62.780674 history loss 27.162509 rank 0
2022-08-25 17:39:30,059 DEBUG CV Batch 166/300 loss 22.132622 loss_att 16.654112 loss_ctc 34.915810 loss_ctc_origin 19.215351 loss_ctc0 71.550217 history loss 26.337801 rank 0
2022-08-25 17:39:40,685 DEBUG CV Batch 166/400 loss 37.449554 loss_att 30.298189 loss_ctc 54.136074 loss_ctc_origin 36.847462 loss_ctc0 94.476166 history loss 24.796134 rank 0
2022-08-25 17:39:51,332 DEBUG CV Batch 166/500 loss 15.539363 loss_att 11.683101 loss_ctc 24.537308 loss_ctc_origin 17.220612 loss_ctc0 41.609592 history loss 24.501846 rank 0
2022-08-25 17:40:01,920 DEBUG CV Batch 166/600 loss 16.993088 loss_att 11.567845 loss_ctc 29.651989 loss_ctc_origin 19.178751 loss_ctc0 54.089546 history loss 24.323802 rank 0
2022-08-25 17:40:11,847 DEBUG CV Batch 166/700 loss 18.515478 loss_att 12.751206 loss_ctc 31.965446 loss_ctc_origin 18.479902 loss_ctc0 63.431717 history loss 24.012483 rank 0
2022-08-25 17:40:22,186 DEBUG CV Batch 166/800 loss 21.401913 loss_att 16.787582 loss_ctc 32.168682 loss_ctc_origin 16.650951 loss_ctc0 68.376724 history loss 23.969820 rank 0
2022-08-25 17:40:32,539 INFO Epoch 166 CV info cv_loss 24.063720528458887
2022-08-25 17:40:32,540 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/166.pt
2022-08-25 17:40:32,991 INFO Epoch 167 TRAIN info lr 0.0006489212053927852
2022-08-25 17:40:32,994 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 17:40:59,562 DEBUG TRAIN Batch 167/0 loss 51.847214 loss_att 35.906963 loss_ctc 89.041130 loss_ctc_origin 60.189331 loss_ctc0 156.362000 lr 0.00064892 rank 0
2022-08-25 17:41:14,590 WARNING NaN or Inf found in input tensor.
2022-08-25 17:41:27,751 DEBUG TRAIN Batch 167/100 loss 53.401123 loss_att 30.163321 loss_ctc 107.622650 loss_ctc_origin 59.866848 loss_ctc0 219.052856 lr 0.00064889 rank 0
2022-08-25 17:41:56,749 DEBUG TRAIN Batch 167/200 loss 18.042854 loss_att 9.146958 loss_ctc 38.799946 loss_ctc_origin 26.562832 loss_ctc0 67.353210 lr 0.00064885 rank 0
2022-08-25 17:42:26,091 DEBUG TRAIN Batch 167/300 loss 19.204962 loss_att 7.054985 loss_ctc 47.554909 loss_ctc_origin 31.303263 loss_ctc0 85.475418 lr 0.00064882 rank 0
2022-08-25 17:42:55,312 DEBUG TRAIN Batch 167/400 loss 20.969732 loss_att 8.299590 loss_ctc 50.533398 loss_ctc_origin 31.820091 loss_ctc0 94.197777 lr 0.00064878 rank 0
2022-08-25 17:43:23,657 DEBUG TRAIN Batch 167/500 loss 38.920956 loss_att 25.595238 loss_ctc 70.014297 loss_ctc_origin 45.115875 loss_ctc0 128.110596 lr 0.00064875 rank 0
2022-08-25 17:43:31,472 WARNING NaN or Inf found in input tensor.
2022-08-25 17:43:44,356 WARNING NaN or Inf found in input tensor.
2022-08-25 17:43:51,496 DEBUG TRAIN Batch 167/600 loss 54.560356 loss_att 30.751511 loss_ctc 110.114334 loss_ctc_origin 66.545944 loss_ctc0 211.773911 lr 0.00064871 rank 0
2022-08-25 17:44:20,419 DEBUG TRAIN Batch 167/700 loss 16.167204 loss_att 8.051785 loss_ctc 35.103180 loss_ctc_origin 23.289467 loss_ctc0 62.668518 lr 0.00064868 rank 0
2022-08-25 17:44:49,158 DEBUG TRAIN Batch 167/800 loss 20.819937 loss_att 8.575983 loss_ctc 49.389160 loss_ctc_origin 35.971092 loss_ctc0 80.697983 lr 0.00064865 rank 0
2022-08-25 17:45:17,794 DEBUG TRAIN Batch 167/900 loss 17.892368 loss_att 7.110863 loss_ctc 43.049213 loss_ctc_origin 25.547150 loss_ctc0 83.887360 lr 0.00064861 rank 0
2022-08-25 17:45:45,867 DEBUG TRAIN Batch 167/1000 loss 45.172569 loss_att 28.055403 loss_ctc 85.112625 loss_ctc_origin 53.813156 loss_ctc0 158.144714 lr 0.00064858 rank 0
2022-08-25 17:46:13,317 WARNING NaN or Inf found in input tensor.
2022-08-25 17:46:13,359 DEBUG TRAIN Batch 167/1100 loss nan loss_att 32.316261 loss_ctc nan loss_ctc_origin 71.848412 loss_ctc0 nan lr 0.00064854 rank 0
2022-08-25 17:46:39,140 WARNING NaN or Inf found in input tensor.
2022-08-25 17:46:40,631 DEBUG TRAIN Batch 167/1200 loss 22.361099 loss_att 12.990794 loss_ctc 44.225147 loss_ctc_origin 33.735085 loss_ctc0 68.701958 lr 0.00064851 rank 0
2022-08-25 17:46:53,435 WARNING NaN or Inf found in input tensor.
2022-08-25 17:47:09,914 DEBUG TRAIN Batch 167/1300 loss 20.037701 loss_att 9.198566 loss_ctc 45.329010 loss_ctc_origin 30.378967 loss_ctc0 80.212448 lr 0.00064848 rank 0
2022-08-25 17:47:38,735 DEBUG TRAIN Batch 167/1400 loss 21.136448 loss_att 8.445433 loss_ctc 50.748817 loss_ctc_origin 34.268974 loss_ctc0 89.201782 lr 0.00064844 rank 0
2022-08-25 17:48:12,360 DEBUG TRAIN Batch 167/1500 loss 45.113525 loss_att 32.205666 loss_ctc 75.231857 loss_ctc_origin 51.924297 loss_ctc0 129.616150 lr 0.00064841 rank 0
2022-08-25 17:48:40,779 DEBUG TRAIN Batch 167/1600 loss 47.913597 loss_att 27.080215 loss_ctc 96.524826 loss_ctc_origin 57.813744 loss_ctc0 186.850662 lr 0.00064837 rank 0
2022-08-25 17:49:07,841 WARNING NaN or Inf found in input tensor.
2022-08-25 17:49:09,520 DEBUG TRAIN Batch 167/1700 loss 20.324482 loss_att 11.677153 loss_ctc 40.501579 loss_ctc_origin 29.995346 loss_ctc0 65.016113 lr 0.00064834 rank 0
2022-08-25 17:49:37,897 DEBUG TRAIN Batch 167/1800 loss 16.489605 loss_att 6.768676 loss_ctc 39.171772 loss_ctc_origin 24.444889 loss_ctc0 73.534500 lr 0.00064831 rank 0
2022-08-25 17:49:48,711 WARNING NaN or Inf found in input tensor.
2022-08-25 17:50:02,279 WARNING NaN or Inf found in input tensor.
2022-08-25 17:50:06,827 DEBUG TRAIN Batch 167/1900 loss 19.026381 loss_att 7.588058 loss_ctc 45.715797 loss_ctc_origin 27.957232 loss_ctc0 87.152451 lr 0.00064827 rank 0
2022-08-25 17:50:36,400 DEBUG TRAIN Batch 167/2000 loss 43.926159 loss_att 27.358257 loss_ctc 82.584595 loss_ctc_origin 52.997932 loss_ctc0 151.620117 lr 0.00064824 rank 0
2022-08-25 17:50:44,187 WARNING NaN or Inf found in input tensor.
2022-08-25 17:51:04,687 DEBUG TRAIN Batch 167/2100 loss 46.721272 loss_att 24.631632 loss_ctc 98.263763 loss_ctc_origin 50.548985 loss_ctc0 209.598236 lr 0.00064820 rank 0
2022-08-25 17:51:33,405 DEBUG TRAIN Batch 167/2200 loss 14.439997 loss_att 7.444107 loss_ctc 30.763741 loss_ctc_origin 17.586584 loss_ctc0 61.510437 lr 0.00064817 rank 0
2022-08-25 17:52:02,691 DEBUG TRAIN Batch 167/2300 loss 20.819780 loss_att 7.766153 loss_ctc 51.278244 loss_ctc_origin 37.442055 loss_ctc0 83.562675 lr 0.00064814 rank 0
2022-08-25 17:52:31,340 DEBUG TRAIN Batch 167/2400 loss 20.835716 loss_att 8.222384 loss_ctc 50.266823 loss_ctc_origin 32.810696 loss_ctc0 90.997772 lr 0.00064810 rank 0
2022-08-25 17:53:00,021 DEBUG TRAIN Batch 167/2500 loss 41.738373 loss_att 27.168497 loss_ctc 75.734749 loss_ctc_origin 47.352020 loss_ctc0 141.961121 lr 0.00064807 rank 0
2022-08-25 17:53:28,164 DEBUG TRAIN Batch 167/2600 loss 50.663223 loss_att 25.834322 loss_ctc 108.597321 loss_ctc_origin 58.839653 loss_ctc0 224.698517 lr 0.00064803 rank 0
2022-08-25 17:53:47,002 WARNING NaN or Inf found in input tensor.
2022-08-25 17:53:53,876 WARNING NaN or Inf found in input tensor.
2022-08-25 17:53:55,459 DEBUG TRAIN Batch 167/2700 loss 16.992172 loss_att 8.360586 loss_ctc 37.132534 loss_ctc_origin 26.599846 loss_ctc0 61.708801 lr 0.00064800 rank 0
2022-08-25 17:54:24,454 DEBUG TRAIN Batch 167/2800 loss 16.963438 loss_att 7.363873 loss_ctc 39.362419 loss_ctc_origin 27.841869 loss_ctc0 66.243698 lr 0.00064797 rank 0
2022-08-25 17:54:52,123 DEBUG TRAIN Batch 167/2900 loss 20.633038 loss_att 8.449210 loss_ctc 49.061966 loss_ctc_origin 29.312006 loss_ctc0 95.145203 lr 0.00064793 rank 0
2022-08-25 17:55:26,270 DEBUG TRAIN Batch 167/3000 loss 43.803925 loss_att 29.376989 loss_ctc 77.466774 loss_ctc_origin 49.872803 loss_ctc0 141.852707 lr 0.00064790 rank 0
2022-08-25 17:55:55,404 DEBUG TRAIN Batch 167/3100 loss 50.151512 loss_att 29.425816 loss_ctc 98.511475 loss_ctc_origin 56.746620 loss_ctc0 195.962799 lr 0.00064786 rank 0
2022-08-25 17:56:23,972 DEBUG TRAIN Batch 167/3200 loss 17.513639 loss_att 9.378147 loss_ctc 36.496452 loss_ctc_origin 21.843122 loss_ctc0 70.687546 lr 0.00064783 rank 0
2022-08-25 17:56:52,436 DEBUG TRAIN Batch 167/3300 loss 17.250881 loss_att 7.598971 loss_ctc 39.772003 loss_ctc_origin 25.572483 loss_ctc0 72.904221 lr 0.00064780 rank 0
2022-08-25 17:57:20,929 DEBUG TRAIN Batch 167/3400 loss 20.962669 loss_att 8.941866 loss_ctc 49.011208 loss_ctc_origin 30.636349 loss_ctc0 91.885872 lr 0.00064776 rank 0
2022-08-25 17:57:49,769 DEBUG TRAIN Batch 167/3500 loss 48.981209 loss_att 31.999725 loss_ctc 88.604660 loss_ctc_origin 58.297287 loss_ctc0 159.321869 lr 0.00064773 rank 0
2022-08-25 17:58:18,758 DEBUG TRAIN Batch 167/3600 loss 59.197678 loss_att 37.465485 loss_ctc 109.906128 loss_ctc_origin 69.278442 loss_ctc0 204.704071 lr 0.00064769 rank 0
2022-08-25 17:58:45,860 WARNING NaN or Inf found in input tensor.
2022-08-25 17:58:47,462 DEBUG TRAIN Batch 167/3700 loss 17.409285 loss_att 8.321302 loss_ctc 38.614578 loss_ctc_origin 26.570915 loss_ctc0 66.716461 lr 0.00064766 rank 0
2022-08-25 17:59:15,964 DEBUG TRAIN Batch 167/3800 loss 22.337845 loss_att 8.689701 loss_ctc 54.183510 loss_ctc_origin 39.628471 loss_ctc0 88.145264 lr 0.00064763 rank 0
2022-08-25 17:59:40,651 WARNING NaN or Inf found in input tensor.
2022-08-25 17:59:45,032 DEBUG TRAIN Batch 167/3900 loss 20.971155 loss_att 7.888360 loss_ctc 51.497673 loss_ctc_origin 30.341087 loss_ctc0 100.863037 lr 0.00064759 rank 0
2022-08-25 18:00:14,251 DEBUG TRAIN Batch 167/4000 loss 43.160065 loss_att 29.688396 loss_ctc 74.593964 loss_ctc_origin 48.499489 loss_ctc0 135.481064 lr 0.00064756 rank 0
2022-08-25 18:00:42,074 DEBUG TRAIN Batch 167/4100 loss 51.431763 loss_att 28.220821 loss_ctc 105.590630 loss_ctc_origin 49.958477 loss_ctc0 235.398987 lr 0.00064752 rank 0
2022-08-25 18:01:10,604 DEBUG TRAIN Batch 167/4200 loss 17.066536 loss_att 9.530928 loss_ctc 34.649620 loss_ctc_origin 23.266579 loss_ctc0 61.210056 lr 0.00064749 rank 0
2022-08-25 18:01:39,825 DEBUG TRAIN Batch 167/4300 loss 18.609701 loss_att 8.061264 loss_ctc 43.222721 loss_ctc_origin 29.439478 loss_ctc0 75.383621 lr 0.00064746 rank 0
2022-08-25 18:02:08,796 DEBUG TRAIN Batch 167/4400 loss 20.694942 loss_att 8.157605 loss_ctc 49.948730 loss_ctc_origin 29.499269 loss_ctc0 97.664139 lr 0.00064742 rank 0
2022-08-25 18:02:44,048 DEBUG TRAIN Batch 167/4500 loss 41.927505 loss_att 27.221472 loss_ctc 76.241577 loss_ctc_origin 48.150585 loss_ctc0 141.787201 lr 0.00064739 rank 0
2022-08-25 18:03:12,320 DEBUG TRAIN Batch 167/4600 loss 53.401505 loss_att 30.885281 loss_ctc 105.939362 loss_ctc_origin 66.591476 loss_ctc0 197.751099 lr 0.00064735 rank 0
2022-08-25 18:03:39,739 DEBUG TRAIN Batch 167/4700 loss 18.892775 loss_att 10.014347 loss_ctc 39.609108 loss_ctc_origin 28.555939 loss_ctc0 65.399841 lr 0.00064732 rank 0
2022-08-25 18:04:07,587 DEBUG TRAIN Batch 167/4800 loss 18.847805 loss_att 7.640869 loss_ctc 44.997322 loss_ctc_origin 31.737501 loss_ctc0 75.936905 lr 0.00064729 rank 0
2022-08-25 18:04:31,822 WARNING NaN or Inf found in input tensor.
2022-08-25 18:04:36,244 DEBUG TRAIN Batch 167/4900 loss 21.716694 loss_att 8.536235 loss_ctc 52.471096 loss_ctc_origin 34.178810 loss_ctc0 95.153091 lr 0.00064725 rank 0
2022-08-25 18:05:04,765 DEBUG TRAIN Batch 167/5000 loss 43.473381 loss_att 28.868139 loss_ctc 77.552277 loss_ctc_origin 50.323742 loss_ctc0 141.085510 lr 0.00064722 rank 0
2022-08-25 18:05:33,542 DEBUG TRAIN Batch 167/5100 loss 56.741203 loss_att 33.006748 loss_ctc 112.121597 loss_ctc_origin 65.698158 loss_ctc0 220.442963 lr 0.00064718 rank 0
2022-08-25 18:06:01,929 DEBUG TRAIN Batch 167/5200 loss 21.960302 loss_att 11.290677 loss_ctc 46.856094 loss_ctc_origin 37.808414 loss_ctc0 67.967346 lr 0.00064715 rank 0
2022-08-25 18:06:30,730 DEBUG TRAIN Batch 167/5300 loss 17.654606 loss_att 6.849716 loss_ctc 42.866016 loss_ctc_origin 26.297829 loss_ctc0 81.525116 lr 0.00064712 rank 0
2022-08-25 18:06:59,033 DEBUG TRAIN Batch 167/5400 loss 18.823137 loss_att 7.182240 loss_ctc 45.985229 loss_ctc_origin 29.304008 loss_ctc0 84.908066 lr 0.00064708 rank 0
2022-08-25 18:07:27,250 DEBUG TRAIN Batch 167/5500 loss 50.742924 loss_att 33.972824 loss_ctc 89.873154 loss_ctc_origin 63.223125 loss_ctc0 152.056564 lr 0.00064705 rank 0
2022-08-25 18:07:55,436 DEBUG TRAIN Batch 167/5600 loss 56.618019 loss_att 33.952400 loss_ctc 109.504448 loss_ctc_origin 60.368576 loss_ctc0 224.154816 lr 0.00064702 rank 0
2022-08-25 18:08:18,515 DEBUG CV Batch 167/0 loss 11.687791 loss_att 8.557379 loss_ctc 18.992085 loss_ctc_origin 12.864691 loss_ctc0 33.289337 history loss 11.000274 rank 0
2022-08-25 18:08:29,398 DEBUG CV Batch 167/100 loss 20.171825 loss_att 16.035967 loss_ctc 29.822163 loss_ctc_origin 19.661564 loss_ctc0 53.530224 history loss 25.617626 rank 0
2022-08-25 18:08:39,580 DEBUG CV Batch 167/200 loss 23.748405 loss_att 18.405619 loss_ctc 36.214905 loss_ctc_origin 25.301491 loss_ctc0 61.679531 history loss 27.042815 rank 0
2022-08-25 18:08:49,949 DEBUG CV Batch 167/300 loss 22.507298 loss_att 16.948408 loss_ctc 35.478035 loss_ctc_origin 20.203316 loss_ctc0 71.119049 history loss 26.061393 rank 0
2022-08-25 18:09:00,944 DEBUG CV Batch 167/400 loss 36.705948 loss_att 29.555954 loss_ctc 53.389267 loss_ctc_origin 35.937309 loss_ctc0 94.110504 history loss 24.495253 rank 0
2022-08-25 18:09:11,967 DEBUG CV Batch 167/500 loss 15.217445 loss_att 11.074396 loss_ctc 24.884562 loss_ctc_origin 17.473450 loss_ctc0 42.177155 history loss 24.190062 rank 0
2022-08-25 18:09:22,782 DEBUG CV Batch 167/600 loss 16.656914 loss_att 11.505661 loss_ctc 28.676498 loss_ctc_origin 17.955376 loss_ctc0 53.692444 history loss 23.994790 rank 0
2022-08-25 18:09:33,247 DEBUG CV Batch 167/700 loss 17.724270 loss_att 12.088858 loss_ctc 30.873566 loss_ctc_origin 16.920073 loss_ctc0 63.431709 history loss 23.682495 rank 0
2022-08-25 18:09:43,815 DEBUG CV Batch 167/800 loss 21.735153 loss_att 17.325037 loss_ctc 32.025421 loss_ctc_origin 16.361378 loss_ctc0 68.574860 history loss 23.641072 rank 0
2022-08-25 18:09:53,835 INFO Epoch 167 CV info cv_loss 23.732830425429395
2022-08-25 18:09:53,835 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/167.pt
2022-08-25 18:09:54,279 INFO Epoch 168 TRAIN info lr 0.0006469870097181933
2022-08-25 18:09:54,283 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 18:10:20,620 DEBUG TRAIN Batch 168/0 loss 46.924881 loss_att 30.645645 loss_ctc 84.909760 loss_ctc_origin 58.117203 loss_ctc0 147.425720 lr 0.00064699 rank 0
2022-08-25 18:10:49,004 DEBUG TRAIN Batch 168/100 loss 49.189766 loss_att 28.060036 loss_ctc 98.492462 loss_ctc_origin 54.341129 loss_ctc0 201.512222 lr 0.00064695 rank 0
2022-08-25 18:11:16,848 DEBUG TRAIN Batch 168/200 loss 20.316088 loss_att 10.810007 loss_ctc 42.496941 loss_ctc_origin 32.074883 loss_ctc0 66.815079 lr 0.00064692 rank 0
2022-08-25 18:11:45,520 DEBUG TRAIN Batch 168/300 loss 15.885657 loss_att 5.282656 loss_ctc 40.625992 loss_ctc_origin 23.590620 loss_ctc0 80.375198 lr 0.00064688 rank 0
2022-08-25 18:12:13,619 DEBUG TRAIN Batch 168/400 loss 24.254726 loss_att 10.891243 loss_ctc 55.436184 loss_ctc_origin 35.635761 loss_ctc0 101.637169 lr 0.00064685 rank 0
2022-08-25 18:12:41,718 DEBUG TRAIN Batch 168/500 loss 43.801216 loss_att 26.812004 loss_ctc 83.442703 loss_ctc_origin 51.430874 loss_ctc0 158.136978 lr 0.00064682 rank 0
2022-08-25 18:13:10,511 DEBUG TRAIN Batch 168/600 loss 54.707840 loss_att 28.366659 loss_ctc 116.170593 loss_ctc_origin 61.544685 loss_ctc0 243.631042 lr 0.00064678 rank 0
2022-08-25 18:13:39,180 DEBUG TRAIN Batch 168/700 loss 21.208479 loss_att 10.448553 loss_ctc 46.314972 loss_ctc_origin 34.037182 loss_ctc0 74.963150 lr 0.00064675 rank 0
2022-08-25 18:14:07,575 DEBUG TRAIN Batch 168/800 loss 21.826029 loss_att 8.510355 loss_ctc 52.895935 loss_ctc_origin 38.613251 loss_ctc0 86.222198 lr 0.00064672 rank 0
2022-08-25 18:14:36,108 DEBUG TRAIN Batch 168/900 loss 24.000053 loss_att 10.060066 loss_ctc 56.526688 loss_ctc_origin 39.862812 loss_ctc0 95.409050 lr 0.00064668 rank 0
2022-08-25 18:15:05,017 DEBUG TRAIN Batch 168/1000 loss 43.726486 loss_att 29.558514 loss_ctc 76.785080 loss_ctc_origin 49.139328 loss_ctc0 141.291824 lr 0.00064665 rank 0
2022-08-25 18:15:33,023 DEBUG TRAIN Batch 168/1100 loss 54.793549 loss_att 32.637821 loss_ctc 106.490242 loss_ctc_origin 64.535439 loss_ctc0 204.384781 lr 0.00064661 rank 0
2022-08-25 18:16:01,293 DEBUG TRAIN Batch 168/1200 loss 18.295492 loss_att 9.043166 loss_ctc 39.884251 loss_ctc_origin 29.849731 loss_ctc0 63.298126 lr 0.00064658 rank 0
2022-08-25 18:16:30,417 DEBUG TRAIN Batch 168/1300 loss 19.888786 loss_att 8.311163 loss_ctc 46.903236 loss_ctc_origin 32.733307 loss_ctc0 79.966400 lr 0.00064655 rank 0
2022-08-25 18:16:58,809 DEBUG TRAIN Batch 168/1400 loss 19.157879 loss_att 7.888130 loss_ctc 45.453957 loss_ctc_origin 27.151493 loss_ctc0 88.159698 lr 0.00064651 rank 0
2022-08-25 18:17:35,681 WARNING NaN or Inf found in input tensor.
2022-08-25 18:17:35,748 DEBUG TRAIN Batch 168/1500 loss inf loss_att 35.878342 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00064648 rank 0
2022-08-25 18:18:04,724 DEBUG TRAIN Batch 168/1600 loss 50.229210 loss_att 29.032301 loss_ctc 99.688660 loss_ctc_origin 51.255119 loss_ctc0 212.700256 lr 0.00064644 rank 0
2022-08-25 18:18:33,117 DEBUG TRAIN Batch 168/1700 loss 18.945786 loss_att 10.954976 loss_ctc 37.591003 loss_ctc_origin 25.281971 loss_ctc0 66.312080 lr 0.00064641 rank 0
2022-08-25 18:19:02,072 DEBUG TRAIN Batch 168/1800 loss 16.310663 loss_att 6.322959 loss_ctc 39.615307 loss_ctc_origin 24.371256 loss_ctc0 75.184753 lr 0.00064638 rank 0
2022-08-25 18:19:31,342 DEBUG TRAIN Batch 168/1900 loss 20.947258 loss_att 8.242291 loss_ctc 50.592178 loss_ctc_origin 30.984793 loss_ctc0 96.342743 lr 0.00064634 rank 0
2022-08-25 18:19:59,610 DEBUG TRAIN Batch 168/2000 loss 37.518600 loss_att 24.327713 loss_ctc 68.297348 loss_ctc_origin 42.525204 loss_ctc0 128.432343 lr 0.00064631 rank 0
2022-08-25 18:20:28,241 DEBUG TRAIN Batch 168/2100 loss 45.169399 loss_att 25.981579 loss_ctc 89.940979 loss_ctc_origin 55.051899 loss_ctc0 171.348831 lr 0.00064628 rank 0
2022-08-25 18:20:56,261 DEBUG TRAIN Batch 168/2200 loss 15.713736 loss_att 7.264922 loss_ctc 35.427631 loss_ctc_origin 24.376991 loss_ctc0 61.212456 lr 0.00064624 rank 0
2022-08-25 18:21:01,768 WARNING NaN or Inf found in input tensor.
2022-08-25 18:21:14,836 WARNING NaN or Inf found in input tensor.
2022-08-25 18:21:24,835 DEBUG TRAIN Batch 168/2300 loss 17.110905 loss_att 7.068097 loss_ctc 40.544121 loss_ctc_origin 25.805676 loss_ctc0 74.933830 lr 0.00064621 rank 0
2022-08-25 18:21:48,011 WARNING NaN or Inf found in input tensor.
2022-08-25 18:21:53,047 DEBUG TRAIN Batch 168/2400 loss 15.815659 loss_att 5.742513 loss_ctc 39.319664 loss_ctc_origin 19.752882 loss_ctc0 84.975494 lr 0.00064617 rank 0
2022-08-25 18:22:21,138 DEBUG TRAIN Batch 168/2500 loss 45.937836 loss_att 30.837244 loss_ctc 81.172546 loss_ctc_origin 57.735752 loss_ctc0 135.858398 lr 0.00064614 rank 0
2022-08-25 18:22:49,600 DEBUG TRAIN Batch 168/2600 loss 44.597042 loss_att 22.708799 loss_ctc 95.669601 loss_ctc_origin 49.587158 loss_ctc0 203.195282 lr 0.00064611 rank 0
2022-08-25 18:23:17,194 DEBUG TRAIN Batch 168/2700 loss 19.087009 loss_att 9.673575 loss_ctc 41.051689 loss_ctc_origin 28.470421 loss_ctc0 70.407974 lr 0.00064607 rank 0
2022-08-25 18:23:46,320 DEBUG TRAIN Batch 168/2800 loss 17.984467 loss_att 6.475192 loss_ctc 44.839439 loss_ctc_origin 31.126381 loss_ctc0 76.836578 lr 0.00064604 rank 0
2022-08-25 18:24:09,947 WARNING NaN or Inf found in input tensor.
2022-08-25 18:24:14,286 DEBUG TRAIN Batch 168/2900 loss 21.611645 loss_att 8.616287 loss_ctc 51.934143 loss_ctc_origin 34.726051 loss_ctc0 92.086365 lr 0.00064601 rank 0
2022-08-25 18:24:48,747 DEBUG TRAIN Batch 168/3000 loss 33.176117 loss_att 21.954243 loss_ctc 59.360489 loss_ctc_origin 37.464684 loss_ctc0 110.450684 lr 0.00064597 rank 0
2022-08-25 18:25:16,342 DEBUG TRAIN Batch 168/3100 loss 56.907326 loss_att 30.846687 loss_ctc 117.715485 loss_ctc_origin 74.598625 loss_ctc0 218.321472 lr 0.00064594 rank 0
2022-08-25 18:25:44,611 DEBUG TRAIN Batch 168/3200 loss 16.941381 loss_att 8.609409 loss_ctc 36.382648 loss_ctc_origin 23.702328 loss_ctc0 65.970062 lr 0.00064591 rank 0
2022-08-25 18:26:13,276 DEBUG TRAIN Batch 168/3300 loss 16.003468 loss_att 5.851434 loss_ctc 39.691544 loss_ctc_origin 24.027006 loss_ctc0 76.242134 lr 0.00064587 rank 0
2022-08-25 18:26:42,469 DEBUG TRAIN Batch 168/3400 loss 19.287754 loss_att 8.017660 loss_ctc 45.584641 loss_ctc_origin 26.519917 loss_ctc0 90.069000 lr 0.00064584 rank 0
2022-08-25 18:27:10,946 DEBUG TRAIN Batch 168/3500 loss 46.831116 loss_att 31.770792 loss_ctc 81.971878 loss_ctc_origin 52.784622 loss_ctc0 150.075470 lr 0.00064580 rank 0
2022-08-25 18:27:38,297 DEBUG TRAIN Batch 168/3600 loss 47.931786 loss_att 25.582399 loss_ctc 100.080360 loss_ctc_origin 53.262161 loss_ctc0 209.322815 lr 0.00064577 rank 0
2022-08-25 18:28:06,723 DEBUG TRAIN Batch 168/3700 loss 19.513237 loss_att 9.915575 loss_ctc 41.907784 loss_ctc_origin 29.639011 loss_ctc0 70.534927 lr 0.00064574 rank 0
2022-08-25 18:28:32,210 WARNING NaN or Inf found in input tensor.
2022-08-25 18:28:35,556 DEBUG TRAIN Batch 168/3800 loss 18.772034 loss_att 7.585789 loss_ctc 44.873268 loss_ctc_origin 29.474878 loss_ctc0 80.802849 lr 0.00064570 rank 0
2022-08-25 18:29:04,673 DEBUG TRAIN Batch 168/3900 loss 22.615160 loss_att 9.502184 loss_ctc 53.212105 loss_ctc_origin 35.274498 loss_ctc0 95.066521 lr 0.00064567 rank 0
2022-08-25 18:29:32,825 DEBUG TRAIN Batch 168/4000 loss 44.595200 loss_att 26.700211 loss_ctc 86.350174 loss_ctc_origin 55.013306 loss_ctc0 159.469528 lr 0.00064564 rank 0
2022-08-25 18:30:00,966 DEBUG TRAIN Batch 168/4100 loss 59.751656 loss_att 35.015850 loss_ctc 117.468536 loss_ctc_origin 70.786240 loss_ctc0 226.393906 lr 0.00064560 rank 0
2022-08-25 18:30:30,137 DEBUG TRAIN Batch 168/4200 loss 23.298641 loss_att 13.167412 loss_ctc 46.938171 loss_ctc_origin 34.858349 loss_ctc0 75.124413 lr 0.00064557 rank 0
2022-08-25 18:30:57,645 DEBUG TRAIN Batch 168/4300 loss 18.601126 loss_att 8.011936 loss_ctc 43.309231 loss_ctc_origin 28.190876 loss_ctc0 78.585396 lr 0.00064553 rank 0
2022-08-25 18:31:25,866 DEBUG TRAIN Batch 168/4400 loss 23.467827 loss_att 10.455392 loss_ctc 53.830173 loss_ctc_origin 35.507301 loss_ctc0 96.583542 lr 0.00064550 rank 0
2022-08-25 18:32:00,625 DEBUG TRAIN Batch 168/4500 loss 31.278549 loss_att 18.587463 loss_ctc 60.891083 loss_ctc_origin 31.268471 loss_ctc0 130.010498 lr 0.00064547 rank 0
2022-08-25 18:32:28,889 DEBUG TRAIN Batch 168/4600 loss 45.857956 loss_att 24.745960 loss_ctc 95.119278 loss_ctc_origin 50.736382 loss_ctc0 198.679382 lr 0.00064543 rank 0
2022-08-25 18:32:57,336 DEBUG TRAIN Batch 168/4700 loss 21.677402 loss_att 11.430386 loss_ctc 45.587112 loss_ctc_origin 35.610371 loss_ctc0 68.866180 lr 0.00064540 rank 0
2022-08-25 18:33:25,604 DEBUG TRAIN Batch 168/4800 loss 18.159403 loss_att 7.499801 loss_ctc 43.031807 loss_ctc_origin 28.502214 loss_ctc0 76.934196 lr 0.00064537 rank 0
2022-08-25 18:33:54,648 DEBUG TRAIN Batch 168/4900 loss 15.441776 loss_att 5.760291 loss_ctc 38.031906 loss_ctc_origin 17.986956 loss_ctc0 84.803459 lr 0.00064533 rank 0
2022-08-25 18:34:23,567 DEBUG TRAIN Batch 168/5000 loss 51.815060 loss_att 35.752464 loss_ctc 89.294449 loss_ctc_origin 62.986618 loss_ctc0 150.679382 lr 0.00064530 rank 0
2022-08-25 18:34:51,734 DEBUG TRAIN Batch 168/5100 loss 55.126213 loss_att 31.985149 loss_ctc 109.122025 loss_ctc_origin 59.928902 loss_ctc0 223.905991 lr 0.00064527 rank 0
2022-08-25 18:35:19,609 DEBUG TRAIN Batch 168/5200 loss 17.837845 loss_att 9.864110 loss_ctc 36.443226 loss_ctc_origin 24.753281 loss_ctc0 63.719769 lr 0.00064523 rank 0
2022-08-25 18:35:24,844 WARNING NaN or Inf found in input tensor.
2022-08-25 18:35:48,314 DEBUG TRAIN Batch 168/5300 loss 19.284185 loss_att 7.658886 loss_ctc 46.409882 loss_ctc_origin 30.460531 loss_ctc0 83.625031 lr 0.00064520 rank 0
2022-08-25 18:36:17,303 DEBUG TRAIN Batch 168/5400 loss 22.862402 loss_att 9.428537 loss_ctc 54.208084 loss_ctc_origin 36.189625 loss_ctc0 96.251144 lr 0.00064517 rank 0
2022-08-25 18:36:44,735 DEBUG TRAIN Batch 168/5500 loss 44.809334 loss_att 28.854813 loss_ctc 82.036545 loss_ctc_origin 47.070370 loss_ctc0 163.624298 lr 0.00064513 rank 0
2022-08-25 18:37:13,499 DEBUG TRAIN Batch 168/5600 loss 48.878044 loss_att 28.952669 loss_ctc 95.370590 loss_ctc_origin 52.000740 loss_ctc0 196.566895 lr 0.00064510 rank 0
2022-08-25 18:37:37,406 DEBUG CV Batch 168/0 loss 12.113092 loss_att 8.847614 loss_ctc 19.732540 loss_ctc_origin 13.657506 loss_ctc0 33.907616 history loss 11.400558 rank 0
2022-08-25 18:37:48,169 DEBUG CV Batch 168/100 loss 20.465328 loss_att 16.543043 loss_ctc 29.617329 loss_ctc_origin 19.546761 loss_ctc0 53.115314 history loss 25.823907 rank 0
2022-08-25 18:37:57,733 DEBUG CV Batch 168/200 loss 24.786169 loss_att 19.360210 loss_ctc 37.446739 loss_ctc_origin 26.876545 loss_ctc0 62.110516 history loss 27.307952 rank 0
2022-08-25 18:38:07,812 DEBUG CV Batch 168/300 loss 22.707314 loss_att 17.445734 loss_ctc 34.984329 loss_ctc_origin 19.367636 loss_ctc0 71.423279 history loss 26.447030 rank 0
2022-08-25 18:38:18,258 DEBUG CV Batch 168/400 loss 37.240990 loss_att 30.328127 loss_ctc 53.371010 loss_ctc_origin 35.697479 loss_ctc0 94.609253 history loss 24.806398 rank 0
2022-08-25 18:38:28,601 DEBUG CV Batch 168/500 loss 15.311830 loss_att 11.196060 loss_ctc 24.915291 loss_ctc_origin 17.628767 loss_ctc0 41.917183 history loss 24.470869 rank 0
2022-08-25 18:38:38,869 DEBUG CV Batch 168/600 loss 17.614725 loss_att 12.575480 loss_ctc 29.372961 loss_ctc_origin 18.827469 loss_ctc0 53.979111 history loss 24.284191 rank 0
2022-08-25 18:38:48,436 DEBUG CV Batch 168/700 loss 19.315874 loss_att 13.546852 loss_ctc 32.776924 loss_ctc_origin 19.518757 loss_ctc0 63.712643 history loss 23.970846 rank 0
2022-08-25 18:38:58,535 DEBUG CV Batch 168/800 loss 21.455481 loss_att 16.984406 loss_ctc 31.887989 loss_ctc_origin 16.251497 loss_ctc0 68.373131 history loss 23.936593 rank 0
2022-08-25 18:39:08,906 INFO Epoch 168 CV info cv_loss 24.031545952558435
2022-08-25 18:39:08,906 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/168.pt
2022-08-25 18:39:09,348 INFO Epoch 169 TRAIN info lr 0.0006450700069572149
2022-08-25 18:39:09,352 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 18:39:34,571 DEBUG TRAIN Batch 169/0 loss 44.593571 loss_att 26.268269 loss_ctc 87.352608 loss_ctc_origin 57.563297 loss_ctc0 156.860992 lr 0.00064507 rank 0
2022-08-25 18:40:02,516 DEBUG TRAIN Batch 169/100 loss 52.068352 loss_att 29.769047 loss_ctc 104.100060 loss_ctc_origin 59.926487 loss_ctc0 207.171722 lr 0.00064504 rank 0
2022-08-25 18:40:30,302 DEBUG TRAIN Batch 169/200 loss 21.160963 loss_att 10.173818 loss_ctc 46.797634 loss_ctc_origin 35.181103 loss_ctc0 73.902870 lr 0.00064500 rank 0
2022-08-25 18:40:41,722 WARNING NaN or Inf found in input tensor.
2022-08-25 18:40:58,129 DEBUG TRAIN Batch 169/300 loss 20.020786 loss_att 7.844368 loss_ctc 48.432426 loss_ctc_origin 34.360626 loss_ctc0 81.266624 lr 0.00064497 rank 0
2022-08-25 18:41:26,790 DEBUG TRAIN Batch 169/400 loss 21.905054 loss_att 9.315335 loss_ctc 51.281063 loss_ctc_origin 31.808002 loss_ctc0 96.718201 lr 0.00064493 rank 0
2022-08-25 18:41:55,285 DEBUG TRAIN Batch 169/500 loss 44.988335 loss_att 30.126049 loss_ctc 79.666992 loss_ctc_origin 55.475800 loss_ctc0 136.113098 lr 0.00064490 rank 0
2022-08-25 18:42:23,072 DEBUG TRAIN Batch 169/600 loss 44.786232 loss_att 22.398909 loss_ctc 97.023315 loss_ctc_origin 49.449944 loss_ctc0 208.027847 lr 0.00064487 rank 0
2022-08-25 18:42:49,441 WARNING NaN or Inf found in input tensor.
2022-08-25 18:42:50,962 DEBUG TRAIN Batch 169/700 loss 14.820469 loss_att 6.784965 loss_ctc 33.569981 loss_ctc_origin 21.487701 loss_ctc0 61.761959 lr 0.00064483 rank 0
2022-08-25 18:43:19,993 DEBUG TRAIN Batch 169/800 loss 19.538450 loss_att 8.410951 loss_ctc 45.502617 loss_ctc_origin 31.281738 loss_ctc0 78.684662 lr 0.00064480 rank 0
2022-08-25 18:43:43,489 WARNING NaN or Inf found in input tensor.
2022-08-25 18:43:47,765 DEBUG TRAIN Batch 169/900 loss 19.110146 loss_att 8.179140 loss_ctc 44.615822 loss_ctc_origin 25.527454 loss_ctc0 89.155350 lr 0.00064477 rank 0
2022-08-25 18:44:16,539 DEBUG TRAIN Batch 169/1000 loss 39.711601 loss_att 25.233234 loss_ctc 73.494461 loss_ctc_origin 49.327534 loss_ctc0 129.883942 lr 0.00064473 rank 0
2022-08-25 18:44:43,622 DEBUG TRAIN Batch 169/1100 loss 39.469646 loss_att 21.008511 loss_ctc 82.545624 loss_ctc_origin 37.611145 loss_ctc0 187.392731 lr 0.00064470 rank 0
2022-08-25 18:45:11,946 DEBUG TRAIN Batch 169/1200 loss 18.173416 loss_att 9.678326 loss_ctc 37.995296 loss_ctc_origin 27.222980 loss_ctc0 63.130699 lr 0.00064467 rank 0
2022-08-25 18:45:40,786 DEBUG TRAIN Batch 169/1300 loss 19.239698 loss_att 7.566833 loss_ctc 46.476383 loss_ctc_origin 30.021399 loss_ctc0 84.871346 lr 0.00064463 rank 0
2022-08-25 18:46:08,457 DEBUG TRAIN Batch 169/1400 loss 18.819542 loss_att 6.454059 loss_ctc 47.672333 loss_ctc_origin 30.920095 loss_ctc0 86.760895 lr 0.00064460 rank 0
2022-08-25 18:46:43,614 DEBUG TRAIN Batch 169/1500 loss 43.052887 loss_att 26.965668 loss_ctc 80.589729 loss_ctc_origin 48.349304 loss_ctc0 155.817383 lr 0.00064457 rank 0
2022-08-25 18:46:44,513 WARNING NaN or Inf found in input tensor.
2022-08-25 18:47:12,886 DEBUG TRAIN Batch 169/1600 loss 50.577629 loss_att 28.460867 loss_ctc 102.183395 loss_ctc_origin 59.800591 loss_ctc0 201.076599 lr 0.00064453 rank 0
2022-08-25 18:47:40,984 DEBUG TRAIN Batch 169/1700 loss 21.038992 loss_att 12.114483 loss_ctc 41.862846 loss_ctc_origin 31.306639 loss_ctc0 66.494003 lr 0.00064450 rank 0
2022-08-25 18:48:09,740 DEBUG TRAIN Batch 169/1800 loss 21.792818 loss_att 9.729361 loss_ctc 49.940887 loss_ctc_origin 36.547604 loss_ctc0 81.191887 lr 0.00064447 rank 0
2022-08-25 18:48:37,667 DEBUG TRAIN Batch 169/1900 loss 20.897209 loss_att 7.674795 loss_ctc 51.749512 loss_ctc_origin 35.573307 loss_ctc0 89.493996 lr 0.00064443 rank 0
2022-08-25 18:49:06,562 DEBUG TRAIN Batch 169/2000 loss 40.180305 loss_att 26.978922 loss_ctc 70.983528 loss_ctc_origin 41.438416 loss_ctc0 139.922119 lr 0.00064440 rank 0
2022-08-25 18:49:35,120 DEBUG TRAIN Batch 169/2100 loss 49.545155 loss_att 31.326900 loss_ctc 92.054413 loss_ctc_origin 53.966385 loss_ctc0 180.926453 lr 0.00064437 rank 0
2022-08-25 18:50:02,764 DEBUG TRAIN Batch 169/2200 loss 18.263128 loss_att 9.619809 loss_ctc 38.430870 loss_ctc_origin 26.889387 loss_ctc0 65.360992 lr 0.00064433 rank 0
2022-08-25 18:50:30,954 DEBUG TRAIN Batch 169/2300 loss 21.604704 loss_att 10.278131 loss_ctc 48.033371 loss_ctc_origin 34.214241 loss_ctc0 80.278008 lr 0.00064430 rank 0
2022-08-25 18:50:59,416 DEBUG TRAIN Batch 169/2400 loss 17.330795 loss_att 6.448958 loss_ctc 42.721748 loss_ctc_origin 23.861956 loss_ctc0 86.727921 lr 0.00064426 rank 0
2022-08-25 18:51:26,918 DEBUG TRAIN Batch 169/2500 loss 49.582241 loss_att 31.173363 loss_ctc 92.536285 loss_ctc_origin 54.249756 loss_ctc0 181.871536 lr 0.00064423 rank 0
2022-08-25 18:51:40,297 WARNING NaN or Inf found in input tensor.
2022-08-25 18:51:54,435 DEBUG TRAIN Batch 169/2600 loss 52.989975 loss_att 28.480736 loss_ctc 110.178207 loss_ctc_origin 60.870766 loss_ctc0 225.228897 lr 0.00064420 rank 0
2022-08-25 18:52:22,354 DEBUG TRAIN Batch 169/2700 loss 18.638786 loss_att 9.352609 loss_ctc 40.306530 loss_ctc_origin 29.650879 loss_ctc0 65.169716 lr 0.00064416 rank 0
2022-08-25 18:52:51,021 DEBUG TRAIN Batch 169/2800 loss 19.141056 loss_att 8.931232 loss_ctc 42.963974 loss_ctc_origin 29.481901 loss_ctc0 74.422134 lr 0.00064413 rank 0
2022-08-25 18:53:19,927 DEBUG TRAIN Batch 169/2900 loss 20.670567 loss_att 7.805935 loss_ctc 50.688038 loss_ctc_origin 31.312019 loss_ctc0 95.898743 lr 0.00064410 rank 0
2022-08-25 18:53:54,388 DEBUG TRAIN Batch 169/3000 loss 42.517570 loss_att 25.138195 loss_ctc 83.069443 loss_ctc_origin 50.937244 loss_ctc0 158.044556 lr 0.00064406 rank 0
2022-08-25 18:54:23,063 DEBUG TRAIN Batch 169/3100 loss 49.074184 loss_att 26.181828 loss_ctc 102.489685 loss_ctc_origin 53.977043 loss_ctc0 215.685852 lr 0.00064403 rank 0
2022-08-25 18:54:51,907 DEBUG TRAIN Batch 169/3200 loss 20.941614 loss_att 10.919718 loss_ctc 44.326038 loss_ctc_origin 32.722889 loss_ctc0 71.400055 lr 0.00064400 rank 0
2022-08-25 18:55:20,201 DEBUG TRAIN Batch 169/3300 loss 19.195030 loss_att 8.685936 loss_ctc 43.716251 loss_ctc_origin 29.472223 loss_ctc0 76.952316 lr 0.00064396 rank 0
2022-08-25 18:55:48,514 DEBUG TRAIN Batch 169/3400 loss 19.729370 loss_att 8.473971 loss_ctc 45.991966 loss_ctc_origin 28.676056 loss_ctc0 86.395752 lr 0.00064393 rank 0
2022-08-25 18:56:17,436 DEBUG TRAIN Batch 169/3500 loss 45.036942 loss_att 27.968641 loss_ctc 84.862976 loss_ctc_origin 48.658566 loss_ctc0 169.339920 lr 0.00064390 rank 0
2022-08-25 18:56:46,363 DEBUG TRAIN Batch 169/3600 loss 51.921852 loss_att 28.117481 loss_ctc 107.465385 loss_ctc_origin 58.009026 loss_ctc0 222.863556 lr 0.00064386 rank 0
2022-08-25 18:57:15,214 DEBUG TRAIN Batch 169/3700 loss 18.640467 loss_att 8.896752 loss_ctc 41.375801 loss_ctc_origin 27.651039 loss_ctc0 73.400253 lr 0.00064383 rank 0
2022-08-25 18:57:43,704 DEBUG TRAIN Batch 169/3800 loss 18.677784 loss_att 7.660607 loss_ctc 44.384529 loss_ctc_origin 31.895317 loss_ctc0 73.526016 lr 0.00064380 rank 0
2022-08-25 18:58:13,523 DEBUG TRAIN Batch 169/3900 loss 16.987648 loss_att 6.551027 loss_ctc 41.339760 loss_ctc_origin 21.736397 loss_ctc0 87.080933 lr 0.00064376 rank 0
2022-08-25 18:58:42,381 DEBUG TRAIN Batch 169/4000 loss 42.136635 loss_att 26.692831 loss_ctc 78.172165 loss_ctc_origin 47.631088 loss_ctc0 149.434677 lr 0.00064373 rank 0
2022-08-25 18:59:10,667 DEBUG TRAIN Batch 169/4100 loss 50.446213 loss_att 28.217373 loss_ctc 102.313507 loss_ctc_origin 48.025318 loss_ctc0 228.985931 lr 0.00064370 rank 0
2022-08-25 18:59:38,841 DEBUG TRAIN Batch 169/4200 loss 18.648874 loss_att 10.314796 loss_ctc 38.095055 loss_ctc_origin 24.692829 loss_ctc0 69.366905 lr 0.00064366 rank 0
2022-08-25 19:00:08,366 DEBUG TRAIN Batch 169/4300 loss 19.822451 loss_att 9.248302 loss_ctc 44.495461 loss_ctc_origin 31.477917 loss_ctc0 74.869720 lr 0.00064363 rank 0
2022-08-25 19:00:36,468 DEBUG TRAIN Batch 169/4400 loss 20.662739 loss_att 8.166040 loss_ctc 49.821701 loss_ctc_origin 33.066673 loss_ctc0 88.916763 lr 0.00064360 rank 0
2022-08-25 19:01:10,746 DEBUG TRAIN Batch 169/4500 loss 52.373676 loss_att 32.305607 loss_ctc 99.199173 loss_ctc_origin 62.974598 loss_ctc0 183.723190 lr 0.00064356 rank 0
2022-08-25 19:01:39,500 DEBUG TRAIN Batch 169/4600 loss 52.072502 loss_att 25.031788 loss_ctc 115.167503 loss_ctc_origin 57.010315 loss_ctc0 250.867599 lr 0.00064353 rank 0
2022-08-25 19:02:07,046 DEBUG TRAIN Batch 169/4700 loss 21.087259 loss_att 11.912355 loss_ctc 42.495365 loss_ctc_origin 31.091618 loss_ctc0 69.104111 lr 0.00064350 rank 0
2022-08-25 19:02:35,597 DEBUG TRAIN Batch 169/4800 loss 24.413992 loss_att 11.398621 loss_ctc 54.783192 loss_ctc_origin 41.971550 loss_ctc0 84.677017 lr 0.00064346 rank 0
2022-08-25 19:03:03,285 DEBUG TRAIN Batch 169/4900 loss 21.669106 loss_att 9.288340 loss_ctc 50.557556 loss_ctc_origin 32.187664 loss_ctc0 93.420631 lr 0.00064343 rank 0
2022-08-25 19:03:31,191 DEBUG TRAIN Batch 169/5000 loss 52.111511 loss_att 34.549793 loss_ctc 93.088844 loss_ctc_origin 59.580360 loss_ctc0 171.275299 lr 0.00064340 rank 0
2022-08-25 19:03:59,135 DEBUG TRAIN Batch 169/5100 loss 64.287132 loss_att 36.225002 loss_ctc 129.765427 loss_ctc_origin 76.980324 loss_ctc0 252.930679 lr 0.00064336 rank 0
2022-08-25 19:04:26,232 DEBUG TRAIN Batch 169/5200 loss 17.262243 loss_att 9.774946 loss_ctc 34.732605 loss_ctc_origin 24.972769 loss_ctc0 57.505562 lr 0.00064333 rank 0
2022-08-25 19:04:53,409 DEBUG TRAIN Batch 169/5300 loss 17.408871 loss_att 6.922187 loss_ctc 41.877796 loss_ctc_origin 27.904049 loss_ctc0 74.483208 lr 0.00064330 rank 0
2022-08-25 19:05:16,847 WARNING NaN or Inf found in input tensor.
2022-08-25 19:05:21,292 DEBUG TRAIN Batch 169/5400 loss 22.686890 loss_att 9.046659 loss_ctc 54.514091 loss_ctc_origin 35.449409 loss_ctc0 98.998337 lr 0.00064326 rank 0
2022-08-25 19:05:49,223 DEBUG TRAIN Batch 169/5500 loss 42.606781 loss_att 25.250587 loss_ctc 83.104553 loss_ctc_origin 51.923134 loss_ctc0 155.861206 lr 0.00064323 rank 0
2022-08-25 19:06:17,113 DEBUG TRAIN Batch 169/5600 loss 62.504242 loss_att 37.254539 loss_ctc 121.420212 loss_ctc_origin 69.285568 loss_ctc0 243.067703 lr 0.00064320 rank 0
2022-08-25 19:06:40,688 DEBUG CV Batch 169/0 loss 12.082848 loss_att 8.931836 loss_ctc 19.435209 loss_ctc_origin 13.237892 loss_ctc0 33.895615 history loss 11.372092 rank 0
2022-08-25 19:06:51,154 DEBUG CV Batch 169/100 loss 20.628712 loss_att 16.115673 loss_ctc 31.159140 loss_ctc_origin 22.072681 loss_ctc0 52.360874 history loss 25.606617 rank 0
2022-08-25 19:07:00,837 DEBUG CV Batch 169/200 loss 24.757666 loss_att 18.984447 loss_ctc 38.228508 loss_ctc_origin 27.875164 loss_ctc0 62.386303 history loss 26.964425 rank 0
2022-08-25 19:07:10,950 DEBUG CV Batch 169/300 loss 22.605007 loss_att 16.944366 loss_ctc 35.813168 loss_ctc_origin 20.533527 loss_ctc0 71.465660 history loss 26.148198 rank 0
2022-08-25 19:07:21,659 DEBUG CV Batch 169/400 loss 37.725807 loss_att 30.493715 loss_ctc 54.600697 loss_ctc_origin 37.373856 loss_ctc0 94.796654 history loss 24.533045 rank 0
2022-08-25 19:07:32,612 DEBUG CV Batch 169/500 loss 15.943563 loss_att 11.309255 loss_ctc 26.756950 loss_ctc_origin 20.208832 loss_ctc0 42.035896 history loss 24.235839 rank 0
2022-08-25 19:07:43,269 DEBUG CV Batch 169/600 loss 17.333813 loss_att 12.579706 loss_ctc 28.426725 loss_ctc_origin 17.487747 loss_ctc0 53.951004 history loss 24.076730 rank 0
2022-08-25 19:07:53,357 DEBUG CV Batch 169/700 loss 18.029636 loss_att 12.267263 loss_ctc 31.475170 loss_ctc_origin 17.834520 loss_ctc0 63.303352 history loss 23.751237 rank 0
2022-08-25 19:08:03,971 DEBUG CV Batch 169/800 loss 21.398933 loss_att 16.589340 loss_ctc 32.621319 loss_ctc_origin 17.262316 loss_ctc0 68.458984 history loss 23.718716 rank 0
2022-08-25 19:08:14,241 INFO Epoch 169 CV info cv_loss 23.805759380141147
2022-08-25 19:08:14,241 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/169.pt
2022-08-25 19:08:14,706 INFO Epoch 170 TRAIN info lr 0.0006431699438992275
2022-08-25 19:08:14,710 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 19:08:42,354 DEBUG TRAIN Batch 170/0 loss 52.989067 loss_att 35.151871 loss_ctc 94.609192 loss_ctc_origin 60.885563 loss_ctc0 173.297653 lr 0.00064317 rank 0
2022-08-25 19:09:11,471 DEBUG TRAIN Batch 170/100 loss 63.950077 loss_att 39.750061 loss_ctc 120.416779 loss_ctc_origin 74.225174 loss_ctc0 228.197174 lr 0.00064314 rank 0
2022-08-25 19:09:39,800 DEBUG TRAIN Batch 170/200 loss 20.776352 loss_att 11.227157 loss_ctc 43.057808 loss_ctc_origin 35.029339 loss_ctc0 61.790901 lr 0.00064310 rank 0
2022-08-25 19:10:09,011 DEBUG TRAIN Batch 170/300 loss 18.703548 loss_att 6.873383 loss_ctc 46.307270 loss_ctc_origin 29.193743 loss_ctc0 86.238831 lr 0.00064307 rank 0
2022-08-25 19:10:36,992 DEBUG TRAIN Batch 170/400 loss 20.272573 loss_att 8.120428 loss_ctc 48.627579 loss_ctc_origin 30.673258 loss_ctc0 90.520996 lr 0.00064304 rank 0
2022-08-25 19:11:05,831 DEBUG TRAIN Batch 170/500 loss 49.534187 loss_att 32.293247 loss_ctc 89.763054 loss_ctc_origin 58.634502 loss_ctc0 162.396332 lr 0.00064300 rank 0
2022-08-25 19:11:33,812 DEBUG TRAIN Batch 170/600 loss 55.237793 loss_att 31.583818 loss_ctc 110.430397 loss_ctc_origin 63.142822 loss_ctc0 220.768066 lr 0.00064297 rank 0
2022-08-25 19:12:01,819 DEBUG TRAIN Batch 170/700 loss 21.668394 loss_att 12.373970 loss_ctc 43.355385 loss_ctc_origin 32.679817 loss_ctc0 68.265045 lr 0.00064294 rank 0
2022-08-25 19:12:07,079 WARNING NaN or Inf found in input tensor.
2022-08-25 19:12:30,965 DEBUG TRAIN Batch 170/800 loss 19.051264 loss_att 7.842713 loss_ctc 45.204544 loss_ctc_origin 30.053089 loss_ctc0 80.557938 lr 0.00064290 rank 0
2022-08-25 19:13:00,444 DEBUG TRAIN Batch 170/900 loss 20.150242 loss_att 9.502216 loss_ctc 44.995636 loss_ctc_origin 26.209614 loss_ctc0 88.829689 lr 0.00064287 rank 0
2022-08-25 19:13:28,943 DEBUG TRAIN Batch 170/1000 loss 45.166241 loss_att 30.867468 loss_ctc 78.530045 loss_ctc_origin 48.081196 loss_ctc0 149.577362 lr 0.00064284 rank 0
2022-08-25 19:13:56,476 DEBUG TRAIN Batch 170/1100 loss 56.646591 loss_att 31.889507 loss_ctc 114.413116 loss_ctc_origin 64.750626 loss_ctc0 230.292236 lr 0.00064280 rank 0
2022-08-25 19:14:25,104 DEBUG TRAIN Batch 170/1200 loss 18.257149 loss_att 9.731046 loss_ctc 38.151390 loss_ctc_origin 28.284468 loss_ctc0 61.174210 lr 0.00064277 rank 0
2022-08-25 19:14:52,117 DEBUG TRAIN Batch 170/1300 loss 17.322502 loss_att 7.528461 loss_ctc 40.175262 loss_ctc_origin 27.145191 loss_ctc0 70.578766 lr 0.00064274 rank 0
2022-08-25 19:15:21,793 DEBUG TRAIN Batch 170/1400 loss 20.757860 loss_att 8.213616 loss_ctc 50.027763 loss_ctc_origin 32.322365 loss_ctc0 91.340363 lr 0.00064270 rank 0
2022-08-25 19:15:56,829 DEBUG TRAIN Batch 170/1500 loss 46.113670 loss_att 27.614182 loss_ctc 89.279144 loss_ctc_origin 54.885273 loss_ctc0 169.531525 lr 0.00064267 rank 0
2022-08-25 19:16:25,674 DEBUG TRAIN Batch 170/1600 loss 58.181862 loss_att 35.374004 loss_ctc 111.400192 loss_ctc_origin 64.265198 loss_ctc0 221.381836 lr 0.00064264 rank 0
2022-08-25 19:16:52,230 WARNING NaN or Inf found in input tensor.
2022-08-25 19:16:53,879 DEBUG TRAIN Batch 170/1700 loss 17.554951 loss_att 9.225845 loss_ctc 36.989525 loss_ctc_origin 25.067076 loss_ctc0 64.808563 lr 0.00064260 rank 0
2022-08-25 19:17:22,169 DEBUG TRAIN Batch 170/1800 loss 23.838768 loss_att 10.693735 loss_ctc 54.510506 loss_ctc_origin 40.592663 loss_ctc0 86.985466 lr 0.00064257 rank 0
2022-08-25 19:17:51,613 DEBUG TRAIN Batch 170/1900 loss 22.177000 loss_att 9.077391 loss_ctc 52.742752 loss_ctc_origin 34.911682 loss_ctc0 94.348572 lr 0.00064254 rank 0
2022-08-25 19:18:21,405 DEBUG TRAIN Batch 170/2000 loss 39.623192 loss_att 24.220497 loss_ctc 75.562813 loss_ctc_origin 42.713539 loss_ctc0 152.211105 lr 0.00064250 rank 0
2022-08-25 19:18:49,804 DEBUG TRAIN Batch 170/2100 loss 55.340694 loss_att 28.381823 loss_ctc 118.244720 loss_ctc_origin 67.061371 loss_ctc0 237.672516 lr 0.00064247 rank 0
2022-08-25 19:19:18,672 DEBUG TRAIN Batch 170/2200 loss 17.731380 loss_att 8.663632 loss_ctc 38.889458 loss_ctc_origin 26.962532 loss_ctc0 66.718948 lr 0.00064244 rank 0
2022-08-25 19:19:47,355 DEBUG TRAIN Batch 170/2300 loss 18.853067 loss_att 8.011239 loss_ctc 44.150665 loss_ctc_origin 28.227234 loss_ctc0 81.305344 lr 0.00064241 rank 0
2022-08-25 19:20:16,036 DEBUG TRAIN Batch 170/2400 loss 19.591433 loss_att 7.288409 loss_ctc 48.298489 loss_ctc_origin 27.609928 loss_ctc0 96.571793 lr 0.00064237 rank 0
2022-08-25 19:20:44,865 DEBUG TRAIN Batch 170/2500 loss 45.207966 loss_att 30.879925 loss_ctc 78.640060 loss_ctc_origin 49.922432 loss_ctc0 145.647842 lr 0.00064234 rank 0
2022-08-25 19:21:13,150 DEBUG TRAIN Batch 170/2600 loss 52.313622 loss_att 30.002972 loss_ctc 104.371811 loss_ctc_origin 54.595840 loss_ctc0 220.515747 lr 0.00064231 rank 0
2022-08-25 19:21:41,147 DEBUG TRAIN Batch 170/2700 loss 19.959681 loss_att 11.333892 loss_ctc 40.086517 loss_ctc_origin 28.430408 loss_ctc0 67.284103 lr 0.00064227 rank 0
2022-08-25 19:22:09,870 DEBUG TRAIN Batch 170/2800 loss 17.526867 loss_att 6.986137 loss_ctc 42.121902 loss_ctc_origin 27.858181 loss_ctc0 75.403915 lr 0.00064224 rank 0
2022-08-25 19:22:27,918 WARNING NaN or Inf found in input tensor.
2022-08-25 19:22:39,618 DEBUG TRAIN Batch 170/2900 loss 24.916224 loss_att 10.674452 loss_ctc 58.147018 loss_ctc_origin 39.435852 loss_ctc0 101.806396 lr 0.00064221 rank 0
2022-08-25 19:23:15,472 DEBUG TRAIN Batch 170/3000 loss 40.232498 loss_att 25.647442 loss_ctc 74.264297 loss_ctc_origin 44.880283 loss_ctc0 142.826996 lr 0.00064217 rank 0
2022-08-25 19:23:44,233 DEBUG TRAIN Batch 170/3100 loss 46.966446 loss_att 25.426256 loss_ctc 97.226883 loss_ctc_origin 49.403587 loss_ctc0 208.814545 lr 0.00064214 rank 0
2022-08-25 19:24:12,728 DEBUG TRAIN Batch 170/3200 loss 17.087284 loss_att 7.671420 loss_ctc 39.057632 loss_ctc_origin 27.634823 loss_ctc0 65.710861 lr 0.00064211 rank 0
2022-08-25 19:24:41,137 DEBUG TRAIN Batch 170/3300 loss 17.740261 loss_att 7.224160 loss_ctc 42.277828 loss_ctc_origin 27.536942 loss_ctc0 76.673233 lr 0.00064207 rank 0
2022-08-25 19:25:09,729 DEBUG TRAIN Batch 170/3400 loss 20.928846 loss_att 8.367521 loss_ctc 50.238602 loss_ctc_origin 33.718914 loss_ctc0 88.784546 lr 0.00064204 rank 0
2022-08-25 19:25:40,015 DEBUG TRAIN Batch 170/3500 loss 46.149551 loss_att 30.425196 loss_ctc 82.839714 loss_ctc_origin 50.621582 loss_ctc0 158.015350 lr 0.00064201 rank 0
2022-08-25 19:26:08,644 DEBUG TRAIN Batch 170/3600 loss 50.965576 loss_att 28.190853 loss_ctc 104.106598 loss_ctc_origin 53.397476 loss_ctc0 222.427902 lr 0.00064197 rank 0
2022-08-25 19:26:37,050 DEBUG TRAIN Batch 170/3700 loss 18.129744 loss_att 10.669649 loss_ctc 35.536629 loss_ctc_origin 25.920141 loss_ctc0 57.975090 lr 0.00064194 rank 0
2022-08-25 19:26:42,576 WARNING NaN or Inf found in input tensor.
2022-08-25 19:26:55,639 WARNING NaN or Inf found in input tensor.
2022-08-25 19:27:04,987 DEBUG TRAIN Batch 170/3800 loss 17.838490 loss_att 8.245272 loss_ctc 40.222664 loss_ctc_origin 27.323769 loss_ctc0 70.320084 lr 0.00064191 rank 0
2022-08-25 19:27:29,491 WARNING NaN or Inf found in input tensor.
2022-08-25 19:27:33,721 DEBUG TRAIN Batch 170/3900 loss 22.733450 loss_att 10.075459 loss_ctc 52.268761 loss_ctc_origin 35.328850 loss_ctc0 91.795227 lr 0.00064188 rank 0
2022-08-25 19:28:02,031 DEBUG TRAIN Batch 170/4000 loss 52.923126 loss_att 36.138054 loss_ctc 92.088303 loss_ctc_origin 62.406338 loss_ctc0 161.346222 lr 0.00064184 rank 0
2022-08-25 19:28:16,391 WARNING NaN or Inf found in input tensor.
2022-08-25 19:28:30,783 DEBUG TRAIN Batch 170/4100 loss 57.237080 loss_att 34.187302 loss_ctc 111.019890 loss_ctc_origin 62.411804 loss_ctc0 224.438751 lr 0.00064181 rank 0
2022-08-25 19:28:58,250 DEBUG TRAIN Batch 170/4200 loss 22.058113 loss_att 11.685886 loss_ctc 46.259972 loss_ctc_origin 36.294678 loss_ctc0 69.512314 lr 0.00064178 rank 0
2022-08-25 19:29:27,621 DEBUG TRAIN Batch 170/4300 loss 19.085691 loss_att 7.192629 loss_ctc 46.836166 loss_ctc_origin 30.814564 loss_ctc0 84.219894 lr 0.00064174 rank 0
2022-08-25 19:29:57,557 DEBUG TRAIN Batch 170/4400 loss 22.753689 loss_att 8.897412 loss_ctc 55.085003 loss_ctc_origin 39.553497 loss_ctc0 91.325180 lr 0.00064171 rank 0
2022-08-25 19:30:32,912 DEBUG TRAIN Batch 170/4500 loss 49.713188 loss_att 32.573235 loss_ctc 89.706406 loss_ctc_origin 54.035835 loss_ctc0 172.937744 lr 0.00064168 rank 0
2022-08-25 19:31:01,171 DEBUG TRAIN Batch 170/4600 loss 46.334381 loss_att 25.345333 loss_ctc 95.308815 loss_ctc_origin 47.162712 loss_ctc0 207.649719 lr 0.00064164 rank 0
2022-08-25 19:31:30,064 DEBUG TRAIN Batch 170/4700 loss 22.098614 loss_att 12.285151 loss_ctc 44.996696 loss_ctc_origin 33.574909 loss_ctc0 71.647530 lr 0.00064161 rank 0
2022-08-25 19:31:59,420 DEBUG TRAIN Batch 170/4800 loss 16.345829 loss_att 6.030392 loss_ctc 40.415184 loss_ctc_origin 25.571575 loss_ctc0 75.050262 lr 0.00064158 rank 0
2022-08-25 19:32:28,767 DEBUG TRAIN Batch 170/4900 loss 20.570412 loss_att 8.073944 loss_ctc 49.728832 loss_ctc_origin 31.140371 loss_ctc0 93.101906 lr 0.00064155 rank 0
2022-08-25 19:32:57,353 DEBUG TRAIN Batch 170/5000 loss 43.145206 loss_att 27.148788 loss_ctc 80.470177 loss_ctc_origin 53.165077 loss_ctc0 144.182068 lr 0.00064151 rank 0
2022-08-25 19:33:26,891 DEBUG TRAIN Batch 170/5100 loss 53.618793 loss_att 28.483652 loss_ctc 112.267456 loss_ctc_origin 64.413162 loss_ctc0 223.927460 lr 0.00064148 rank 0
2022-08-25 19:33:56,467 DEBUG TRAIN Batch 170/5200 loss 17.473862 loss_att 8.811556 loss_ctc 37.685905 loss_ctc_origin 25.496555 loss_ctc0 66.127731 lr 0.00064145 rank 0
2022-08-25 19:34:25,427 DEBUG TRAIN Batch 170/5300 loss 21.154985 loss_att 8.504309 loss_ctc 50.673233 loss_ctc_origin 34.872307 loss_ctc0 87.542053 lr 0.00064141 rank 0
2022-08-25 19:34:55,281 DEBUG TRAIN Batch 170/5400 loss 20.562595 loss_att 8.312831 loss_ctc 49.145374 loss_ctc_origin 30.777542 loss_ctc0 92.003647 lr 0.00064138 rank 0
2022-08-25 19:35:22,967 DEBUG TRAIN Batch 170/5500 loss 44.730770 loss_att 27.896744 loss_ctc 84.010162 loss_ctc_origin 51.008057 loss_ctc0 161.015076 lr 0.00064135 rank 0
2022-08-25 19:35:36,814 WARNING NaN or Inf found in input tensor.
2022-08-25 19:35:50,905 DEBUG TRAIN Batch 170/5600 loss 45.568405 loss_att 23.912813 loss_ctc 96.098106 loss_ctc_origin 49.534958 loss_ctc0 204.745453 lr 0.00064131 rank 0
2022-08-25 19:36:14,102 DEBUG CV Batch 170/0 loss 11.751780 loss_att 8.508048 loss_ctc 19.320488 loss_ctc_origin 13.137985 loss_ctc0 33.746330 history loss 11.060498 rank 0
2022-08-25 19:36:25,389 DEBUG CV Batch 170/100 loss 20.777933 loss_att 16.490303 loss_ctc 30.782402 loss_ctc_origin 21.224327 loss_ctc0 53.084579 history loss 25.918435 rank 0
2022-08-25 19:36:35,048 DEBUG CV Batch 170/200 loss 24.557903 loss_att 19.213238 loss_ctc 37.028786 loss_ctc_origin 26.514309 loss_ctc0 61.562557 history loss 27.213648 rank 0
2022-08-25 19:36:45,372 DEBUG CV Batch 170/300 loss 23.330708 loss_att 17.798271 loss_ctc 36.239723 loss_ctc_origin 21.369175 loss_ctc0 70.937668 history loss 26.376488 rank 0
2022-08-25 19:36:56,361 DEBUG CV Batch 170/400 loss 37.008133 loss_att 29.773746 loss_ctc 53.888363 loss_ctc_origin 36.352776 loss_ctc0 94.804726 history loss 24.767418 rank 0
2022-08-25 19:37:06,474 DEBUG CV Batch 170/500 loss 16.143005 loss_att 12.029081 loss_ctc 25.742165 loss_ctc_origin 18.694822 loss_ctc0 42.185959 history loss 24.451324 rank 0
2022-08-25 19:37:17,170 DEBUG CV Batch 170/600 loss 16.991096 loss_att 11.941143 loss_ctc 28.774323 loss_ctc_origin 18.138227 loss_ctc0 53.591873 history loss 24.281465 rank 0
2022-08-25 19:37:27,312 DEBUG CV Batch 170/700 loss 18.003635 loss_att 12.445572 loss_ctc 30.972454 loss_ctc_origin 17.511341 loss_ctc0 62.381718 history loss 23.943847 rank 0
2022-08-25 19:37:38,017 DEBUG CV Batch 170/800 loss 20.710155 loss_att 15.970278 loss_ctc 31.769865 loss_ctc_origin 16.287491 loss_ctc0 67.895401 history loss 23.900948 rank 0
2022-08-25 19:37:48,461 INFO Epoch 170 CV info cv_loss 23.9792520753785
2022-08-25 19:37:48,462 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/170.pt
2022-08-25 19:37:48,976 INFO Epoch 171 TRAIN info lr 0.0006412865725239041
2022-08-25 19:37:48,980 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 19:38:16,994 DEBUG TRAIN Batch 171/0 loss 36.621330 loss_att 23.249893 loss_ctc 67.821350 loss_ctc_origin 42.525806 loss_ctc0 126.844292 lr 0.00064129 rank 0
2022-08-25 19:38:45,569 DEBUG TRAIN Batch 171/100 loss 41.832462 loss_att 23.408859 loss_ctc 84.820862 loss_ctc_origin 45.685692 loss_ctc0 176.136246 lr 0.00064125 rank 0
2022-08-25 19:39:14,889 DEBUG TRAIN Batch 171/200 loss 19.721869 loss_att 9.530448 loss_ctc 43.501850 loss_ctc_origin 31.089245 loss_ctc0 72.464600 lr 0.00064122 rank 0
2022-08-25 19:39:43,381 DEBUG TRAIN Batch 171/300 loss 17.987333 loss_att 7.802190 loss_ctc 41.752666 loss_ctc_origin 28.908310 loss_ctc0 71.722832 lr 0.00064119 rank 0
2022-08-25 19:40:12,175 DEBUG TRAIN Batch 171/400 loss 22.026569 loss_att 8.677591 loss_ctc 53.174187 loss_ctc_origin 33.992088 loss_ctc0 97.932404 lr 0.00064115 rank 0
2022-08-25 19:40:42,291 DEBUG TRAIN Batch 171/500 loss 41.235229 loss_att 29.370209 loss_ctc 68.920288 loss_ctc_origin 41.150223 loss_ctc0 133.717117 lr 0.00064112 rank 0
2022-08-25 19:41:04,306 WARNING NaN or Inf found in input tensor.
2022-08-25 19:41:11,660 DEBUG TRAIN Batch 171/600 loss 47.269363 loss_att 24.191423 loss_ctc 101.117889 loss_ctc_origin 56.604492 loss_ctc0 204.982498 lr 0.00064109 rank 0
2022-08-25 19:41:40,189 DEBUG TRAIN Batch 171/700 loss 17.943790 loss_att 9.006715 loss_ctc 38.796967 loss_ctc_origin 29.635221 loss_ctc0 60.174366 lr 0.00064105 rank 0
2022-08-25 19:42:09,278 DEBUG TRAIN Batch 171/800 loss 18.129738 loss_att 8.155985 loss_ctc 41.401825 loss_ctc_origin 27.566900 loss_ctc0 73.683311 lr 0.00064102 rank 0
2022-08-25 19:42:37,825 DEBUG TRAIN Batch 171/900 loss 20.862793 loss_att 8.219040 loss_ctc 50.364883 loss_ctc_origin 31.603222 loss_ctc0 94.142097 lr 0.00064099 rank 0
2022-08-25 19:43:06,752 DEBUG TRAIN Batch 171/1000 loss 39.850433 loss_att 25.578667 loss_ctc 73.151230 loss_ctc_origin 40.907413 loss_ctc0 148.386795 lr 0.00064096 rank 0
2022-08-25 19:43:34,876 DEBUG TRAIN Batch 171/1100 loss 46.387680 loss_att 25.482014 loss_ctc 95.167572 loss_ctc_origin 54.512054 loss_ctc0 190.030457 lr 0.00064092 rank 0
2022-08-25 19:44:01,880 DEBUG TRAIN Batch 171/1200 loss 18.223690 loss_att 10.141340 loss_ctc 37.082504 loss_ctc_origin 24.630104 loss_ctc0 66.138115 lr 0.00064089 rank 0
2022-08-25 19:44:29,356 DEBUG TRAIN Batch 171/1300 loss 21.143841 loss_att 8.211191 loss_ctc 51.320023 loss_ctc_origin 38.002666 loss_ctc0 82.393852 lr 0.00064086 rank 0
2022-08-25 19:44:57,321 DEBUG TRAIN Batch 171/1400 loss 21.057161 loss_att 7.720882 loss_ctc 52.175140 loss_ctc_origin 31.973873 loss_ctc0 99.311440 lr 0.00064082 rank 0
2022-08-25 19:45:33,581 DEBUG TRAIN Batch 171/1500 loss 41.927399 loss_att 27.693056 loss_ctc 75.140862 loss_ctc_origin 47.183258 loss_ctc0 140.375275 lr 0.00064079 rank 0
2022-08-25 19:46:01,719 DEBUG TRAIN Batch 171/1600 loss 52.813423 loss_att 28.377632 loss_ctc 109.830261 loss_ctc_origin 61.309765 loss_ctc0 223.044754 lr 0.00064076 rank 0
2022-08-25 19:46:30,587 DEBUG TRAIN Batch 171/1700 loss 19.916218 loss_att 11.103452 loss_ctc 40.479340 loss_ctc_origin 30.799900 loss_ctc0 63.064705 lr 0.00064073 rank 0
2022-08-25 19:46:58,869 DEBUG TRAIN Batch 171/1800 loss 19.210423 loss_att 7.962516 loss_ctc 45.455536 loss_ctc_origin 29.301392 loss_ctc0 83.148544 lr 0.00064069 rank 0
2022-08-25 19:47:27,071 DEBUG TRAIN Batch 171/1900 loss 22.213520 loss_att 7.939635 loss_ctc 55.519249 loss_ctc_origin 35.351208 loss_ctc0 102.578003 lr 0.00064066 rank 0
2022-08-25 19:47:29,776 WARNING NaN or Inf found in input tensor.
2022-08-25 19:47:56,812 DEBUG TRAIN Batch 171/2000 loss 35.448341 loss_att 22.944468 loss_ctc 64.624054 loss_ctc_origin 38.085949 loss_ctc0 126.546310 lr 0.00064063 rank 0
2022-08-25 19:48:24,540 DEBUG TRAIN Batch 171/2100 loss 42.219925 loss_att 25.231043 loss_ctc 81.860641 loss_ctc_origin 42.664742 loss_ctc0 173.317719 lr 0.00064059 rank 0
2022-08-25 19:48:55,283 DEBUG TRAIN Batch 171/2200 loss 15.905558 loss_att 7.401786 loss_ctc 35.747688 loss_ctc_origin 21.673523 loss_ctc0 68.587410 lr 0.00064056 rank 0
2022-08-25 19:49:23,865 DEBUG TRAIN Batch 171/2300 loss 16.665558 loss_att 6.662316 loss_ctc 40.006454 loss_ctc_origin 25.400841 loss_ctc0 74.086227 lr 0.00064053 rank 0
2022-08-25 19:49:51,367 DEBUG TRAIN Batch 171/2400 loss 22.136080 loss_att 8.191904 loss_ctc 54.672489 loss_ctc_origin 37.999313 loss_ctc0 93.576561 lr 0.00064050 rank 0
2022-08-25 19:50:20,719 DEBUG TRAIN Batch 171/2500 loss 40.872597 loss_att 27.443327 loss_ctc 72.207565 loss_ctc_origin 45.824280 loss_ctc0 133.768570 lr 0.00064046 rank 0
2022-08-25 19:50:49,206 DEBUG TRAIN Batch 171/2600 loss 41.761826 loss_att 21.351707 loss_ctc 89.385437 loss_ctc_origin 44.717712 loss_ctc0 193.610138 lr 0.00064043 rank 0
2022-08-25 19:51:17,310 DEBUG TRAIN Batch 171/2700 loss 18.593899 loss_att 10.365488 loss_ctc 37.793522 loss_ctc_origin 25.930361 loss_ctc0 65.474228 lr 0.00064040 rank 0
2022-08-25 19:51:45,619 DEBUG TRAIN Batch 171/2800 loss 19.355556 loss_att 8.631693 loss_ctc 44.377899 loss_ctc_origin 29.693375 loss_ctc0 78.641785 lr 0.00064036 rank 0
2022-08-25 19:52:15,108 DEBUG TRAIN Batch 171/2900 loss 17.967354 loss_att 7.294866 loss_ctc 42.869827 loss_ctc_origin 26.835712 loss_ctc0 80.282761 lr 0.00064033 rank 0
2022-08-25 19:52:50,952 DEBUG TRAIN Batch 171/3000 loss 44.056305 loss_att 28.825817 loss_ctc 79.594101 loss_ctc_origin 47.075180 loss_ctc0 155.471588 lr 0.00064030 rank 0
2022-08-25 19:53:19,930 DEBUG TRAIN Batch 171/3100 loss 53.930687 loss_att 30.966454 loss_ctc 107.513893 loss_ctc_origin 63.964012 loss_ctc0 209.130280 lr 0.00064027 rank 0
2022-08-25 19:53:48,022 DEBUG TRAIN Batch 171/3200 loss 20.254766 loss_att 10.206120 loss_ctc 43.701607 loss_ctc_origin 31.771036 loss_ctc0 71.539597 lr 0.00064023 rank 0
2022-08-25 19:54:16,634 DEBUG TRAIN Batch 171/3300 loss 18.952297 loss_att 7.882170 loss_ctc 44.782593 loss_ctc_origin 28.501717 loss_ctc0 82.771301 lr 0.00064020 rank 0
2022-08-25 19:54:44,991 DEBUG TRAIN Batch 171/3400 loss 21.461113 loss_att 8.786234 loss_ctc 51.035828 loss_ctc_origin 34.128918 loss_ctc0 90.485275 lr 0.00064017 rank 0
2022-08-25 19:55:14,217 DEBUG TRAIN Batch 171/3500 loss 40.550545 loss_att 25.122143 loss_ctc 76.550148 loss_ctc_origin 45.980499 loss_ctc0 147.879333 lr 0.00064013 rank 0
2022-08-25 19:55:21,922 WARNING NaN or Inf found in input tensor.
2022-08-25 19:55:41,647 DEBUG TRAIN Batch 171/3600 loss 49.805008 loss_att 26.033882 loss_ctc 105.270966 loss_ctc_origin 47.594368 loss_ctc0 239.849701 lr 0.00064010 rank 0
2022-08-25 19:56:10,414 DEBUG TRAIN Batch 171/3700 loss 21.952545 loss_att 9.661116 loss_ctc 50.632549 loss_ctc_origin 38.638771 loss_ctc0 78.618027 lr 0.00064007 rank 0
2022-08-25 19:56:39,168 DEBUG TRAIN Batch 171/3800 loss 17.176096 loss_att 7.404384 loss_ctc 39.976757 loss_ctc_origin 26.489782 loss_ctc0 71.446365 lr 0.00064004 rank 0
2022-08-25 19:57:02,347 WARNING NaN or Inf found in input tensor.
2022-08-25 19:57:06,979 DEBUG TRAIN Batch 171/3900 loss 21.863506 loss_att 9.923874 loss_ctc 49.722649 loss_ctc_origin 31.711176 loss_ctc0 91.749420 lr 0.00064000 rank 0
2022-08-25 19:57:36,362 DEBUG TRAIN Batch 171/4000 loss 54.088757 loss_att 38.403828 loss_ctc 90.686920 loss_ctc_origin 58.145927 loss_ctc0 166.615891 lr 0.00063997 rank 0
2022-08-25 19:58:04,249 DEBUG TRAIN Batch 171/4100 loss 56.797829 loss_att 30.087486 loss_ctc 119.121964 loss_ctc_origin 61.589050 loss_ctc0 253.365417 lr 0.00063994 rank 0
2022-08-25 19:58:32,408 DEBUG TRAIN Batch 171/4200 loss 18.175266 loss_att 9.517445 loss_ctc 38.376850 loss_ctc_origin 26.576302 loss_ctc0 65.911461 lr 0.00063991 rank 0
2022-08-25 19:59:00,373 DEBUG TRAIN Batch 171/4300 loss 20.379723 loss_att 8.501877 loss_ctc 48.094696 loss_ctc_origin 32.786320 loss_ctc0 83.814240 lr 0.00063987 rank 0
2022-08-25 19:59:27,303 DEBUG TRAIN Batch 171/4400 loss 21.121300 loss_att 8.707212 loss_ctc 50.087502 loss_ctc_origin 33.762360 loss_ctc0 88.179489 lr 0.00063984 rank 0
2022-08-25 20:00:02,075 DEBUG TRAIN Batch 171/4500 loss 43.897713 loss_att 24.529110 loss_ctc 89.091125 loss_ctc_origin 52.309395 loss_ctc0 174.915146 lr 0.00063981 rank 0
2022-08-25 20:00:18,124 WARNING NaN or Inf found in input tensor.
2022-08-25 20:00:30,394 DEBUG TRAIN Batch 171/4600 loss 53.216316 loss_att 27.357574 loss_ctc 113.553375 loss_ctc_origin 64.134674 loss_ctc0 228.863663 lr 0.00063977 rank 0
2022-08-25 20:00:58,837 DEBUG TRAIN Batch 171/4700 loss 18.999683 loss_att 10.389959 loss_ctc 39.089039 loss_ctc_origin 28.030823 loss_ctc0 64.891541 lr 0.00063974 rank 0
2022-08-25 20:01:27,581 DEBUG TRAIN Batch 171/4800 loss 21.319923 loss_att 8.444044 loss_ctc 51.363640 loss_ctc_origin 36.670815 loss_ctc0 85.646896 lr 0.00063971 rank 0
2022-08-25 20:01:51,392 WARNING NaN or Inf found in input tensor.
2022-08-25 20:01:56,029 DEBUG TRAIN Batch 171/4900 loss 21.534077 loss_att 8.158094 loss_ctc 52.744698 loss_ctc_origin 34.651443 loss_ctc0 94.962296 lr 0.00063968 rank 0
2022-08-25 20:02:25,373 DEBUG TRAIN Batch 171/5000 loss 48.463753 loss_att 30.250021 loss_ctc 90.962448 loss_ctc_origin 55.888290 loss_ctc0 172.802155 lr 0.00063964 rank 0
2022-08-25 20:02:53,147 DEBUG TRAIN Batch 171/5100 loss 50.935398 loss_att 25.277781 loss_ctc 110.803162 loss_ctc_origin 59.673836 loss_ctc0 230.104919 lr 0.00063961 rank 0
2022-08-25 20:03:20,917 DEBUG TRAIN Batch 171/5200 loss 18.457680 loss_att 9.153735 loss_ctc 40.166885 loss_ctc_origin 29.079180 loss_ctc0 66.038193 lr 0.00063958 rank 0
2022-08-25 20:03:48,434 DEBUG TRAIN Batch 171/5300 loss 23.809134 loss_att 10.223564 loss_ctc 55.508793 loss_ctc_origin 42.546577 loss_ctc0 85.753960 lr 0.00063955 rank 0
2022-08-25 20:04:12,729 WARNING NaN or Inf found in input tensor.
2022-08-25 20:04:17,205 DEBUG TRAIN Batch 171/5400 loss 20.744781 loss_att 8.703144 loss_ctc 48.841934 loss_ctc_origin 34.358246 loss_ctc0 82.637207 lr 0.00063951 rank 0
2022-08-25 20:04:45,977 DEBUG TRAIN Batch 171/5500 loss 49.004700 loss_att 31.693977 loss_ctc 89.396378 loss_ctc_origin 57.389942 loss_ctc0 164.078064 lr 0.00063948 rank 0
2022-08-25 20:05:15,035 DEBUG TRAIN Batch 171/5600 loss 53.143288 loss_att 27.930836 loss_ctc 111.972336 loss_ctc_origin 61.228180 loss_ctc0 230.375366 lr 0.00063945 rank 0
2022-08-25 20:05:38,214 DEBUG CV Batch 171/0 loss 11.937356 loss_att 9.231171 loss_ctc 18.251789 loss_ctc_origin 11.782177 loss_ctc0 33.347549 history loss 11.235159 rank 0
2022-08-25 20:05:49,241 DEBUG CV Batch 171/100 loss 20.887289 loss_att 16.444466 loss_ctc 31.253876 loss_ctc_origin 21.920290 loss_ctc0 53.032242 history loss 26.232120 rank 0
2022-08-25 20:05:59,234 DEBUG CV Batch 171/200 loss 24.193192 loss_att 18.382774 loss_ctc 37.750828 loss_ctc_origin 27.438469 loss_ctc0 61.812996 history loss 27.562809 rank 0
2022-08-25 20:06:09,648 DEBUG CV Batch 171/300 loss 21.995739 loss_att 16.666599 loss_ctc 34.430393 loss_ctc_origin 18.471497 loss_ctc0 71.667816 history loss 26.618679 rank 0
2022-08-25 20:06:20,721 DEBUG CV Batch 171/400 loss 37.817047 loss_att 30.659798 loss_ctc 54.517296 loss_ctc_origin 37.446362 loss_ctc0 94.349472 history loss 24.946682 rank 0
2022-08-25 20:06:31,871 DEBUG CV Batch 171/500 loss 16.697670 loss_att 12.696379 loss_ctc 26.034014 loss_ctc_origin 18.948523 loss_ctc0 42.566826 history loss 24.634278 rank 0
2022-08-25 20:06:43,103 DEBUG CV Batch 171/600 loss 17.110359 loss_att 11.794716 loss_ctc 29.513523 loss_ctc_origin 19.210136 loss_ctc0 53.554756 history loss 24.436193 rank 0
2022-08-25 20:06:52,933 DEBUG CV Batch 171/700 loss 18.754410 loss_att 13.080239 loss_ctc 31.994141 loss_ctc_origin 18.529732 loss_ctc0 63.411095 history loss 24.095045 rank 0
2022-08-25 20:07:03,349 DEBUG CV Batch 171/800 loss 22.233494 loss_att 17.703857 loss_ctc 32.802647 loss_ctc_origin 17.544285 loss_ctc0 68.405495 history loss 24.046425 rank 0
2022-08-25 20:07:13,722 INFO Epoch 171 CV info cv_loss 24.131795133791858
2022-08-25 20:07:13,722 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/171.pt
2022-08-25 20:07:14,246 INFO Epoch 172 TRAIN info lr 0.0006394196498652211
2022-08-25 20:07:14,249 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 20:07:41,962 DEBUG TRAIN Batch 172/0 loss 52.769684 loss_att 35.409477 loss_ctc 93.276825 loss_ctc_origin 57.966888 loss_ctc0 175.666656 lr 0.00063942 rank 0
2022-08-25 20:07:50,132 WARNING NaN or Inf found in input tensor.
2022-08-25 20:08:11,393 DEBUG TRAIN Batch 172/100 loss 48.380821 loss_att 24.777935 loss_ctc 103.454208 loss_ctc_origin 52.875130 loss_ctc0 221.472046 lr 0.00063939 rank 0
2022-08-25 20:08:40,469 DEBUG TRAIN Batch 172/200 loss 15.625650 loss_att 7.043361 loss_ctc 35.650993 loss_ctc_origin 22.560453 loss_ctc0 66.195580 lr 0.00063935 rank 0
2022-08-25 20:09:08,208 DEBUG TRAIN Batch 172/300 loss 19.931564 loss_att 7.519813 loss_ctc 48.892315 loss_ctc_origin 34.136162 loss_ctc0 83.323334 lr 0.00063932 rank 0
2022-08-25 20:09:36,678 DEBUG TRAIN Batch 172/400 loss 19.915775 loss_att 8.446808 loss_ctc 46.676701 loss_ctc_origin 29.268988 loss_ctc0 87.294693 lr 0.00063929 rank 0
2022-08-25 20:10:05,559 DEBUG TRAIN Batch 172/500 loss 47.468906 loss_att 31.190626 loss_ctc 85.451553 loss_ctc_origin 52.946453 loss_ctc0 161.296799 lr 0.00063926 rank 0
2022-08-25 20:10:34,637 DEBUG TRAIN Batch 172/600 loss 59.011864 loss_att 37.030319 loss_ctc 110.302132 loss_ctc_origin 63.399929 loss_ctc0 219.740585 lr 0.00063922 rank 0
2022-08-25 20:11:03,414 DEBUG TRAIN Batch 172/700 loss 20.562729 loss_att 11.824255 loss_ctc 40.952499 loss_ctc_origin 30.982567 loss_ctc0 64.215683 lr 0.00063919 rank 0
2022-08-25 20:11:32,727 DEBUG TRAIN Batch 172/800 loss 20.467894 loss_att 8.057825 loss_ctc 49.424717 loss_ctc_origin 33.319931 loss_ctc0 87.002548 lr 0.00063916 rank 0
2022-08-25 20:12:00,956 DEBUG TRAIN Batch 172/900 loss 21.078489 loss_att 8.243148 loss_ctc 51.027618 loss_ctc_origin 32.267143 loss_ctc0 94.802063 lr 0.00063912 rank 0
2022-08-25 20:12:29,480 DEBUG TRAIN Batch 172/1000 loss 46.397659 loss_att 29.891161 loss_ctc 84.912819 loss_ctc_origin 49.065674 loss_ctc0 168.556152 lr 0.00063909 rank 0
2022-08-25 20:12:57,678 DEBUG TRAIN Batch 172/1100 loss 51.012295 loss_att 29.218494 loss_ctc 101.864494 loss_ctc_origin 58.677559 loss_ctc0 202.634003 lr 0.00063906 rank 0
2022-08-25 20:13:24,390 DEBUG TRAIN Batch 172/1200 loss 21.500244 loss_att 10.731474 loss_ctc 46.627369 loss_ctc_origin 36.112465 loss_ctc0 71.162148 lr 0.00063903 rank 0
2022-08-25 20:13:54,331 DEBUG TRAIN Batch 172/1300 loss 18.296322 loss_att 8.031191 loss_ctc 42.248291 loss_ctc_origin 29.693342 loss_ctc0 71.543167 lr 0.00063899 rank 0
2022-08-25 20:14:22,693 DEBUG TRAIN Batch 172/1400 loss 20.850494 loss_att 8.318379 loss_ctc 50.092091 loss_ctc_origin 30.833202 loss_ctc0 95.029495 lr 0.00063896 rank 0
2022-08-25 20:14:57,039 DEBUG TRAIN Batch 172/1500 loss 35.858589 loss_att 21.673531 loss_ctc 68.957054 loss_ctc_origin 38.657715 loss_ctc0 139.655518 lr 0.00063893 rank 0
2022-08-25 20:15:05,060 WARNING NaN or Inf found in input tensor.
2022-08-25 20:15:26,358 DEBUG TRAIN Batch 172/1600 loss 54.163689 loss_att 30.106516 loss_ctc 110.297081 loss_ctc_origin 59.408546 loss_ctc0 229.036987 lr 0.00063890 rank 0
2022-08-25 20:15:54,292 DEBUG TRAIN Batch 172/1700 loss 22.463215 loss_att 12.829563 loss_ctc 44.941730 loss_ctc_origin 34.764347 loss_ctc0 68.688957 lr 0.00063886 rank 0
2022-08-25 20:16:22,754 DEBUG TRAIN Batch 172/1800 loss 19.129456 loss_att 7.897323 loss_ctc 45.337769 loss_ctc_origin 30.298908 loss_ctc0 80.428436 lr 0.00063883 rank 0
2022-08-25 20:16:51,572 DEBUG TRAIN Batch 172/1900 loss 22.637993 loss_att 9.428004 loss_ctc 53.461296 loss_ctc_origin 36.731117 loss_ctc0 92.498383 lr 0.00063880 rank 0
2022-08-25 20:17:19,778 DEBUG TRAIN Batch 172/2000 loss 44.788521 loss_att 29.248617 loss_ctc 81.048302 loss_ctc_origin 53.350285 loss_ctc0 145.677002 lr 0.00063877 rank 0
2022-08-25 20:17:48,033 DEBUG TRAIN Batch 172/2100 loss 46.879997 loss_att 25.969652 loss_ctc 95.670807 loss_ctc_origin 56.565094 loss_ctc0 186.917450 lr 0.00063873 rank 0
2022-08-25 20:18:15,962 DEBUG TRAIN Batch 172/2200 loss 23.106722 loss_att 13.391301 loss_ctc 45.776035 loss_ctc_origin 34.960480 loss_ctc0 71.012329 lr 0.00063870 rank 0
2022-08-25 20:18:44,812 DEBUG TRAIN Batch 172/2300 loss 19.097836 loss_att 8.320930 loss_ctc 44.243950 loss_ctc_origin 29.575390 loss_ctc0 78.470596 lr 0.00063867 rank 0
2022-08-25 20:19:08,348 WARNING NaN or Inf found in input tensor.
2022-08-25 20:19:12,535 DEBUG TRAIN Batch 172/2400 loss 21.367659 loss_att 9.220821 loss_ctc 49.710274 loss_ctc_origin 30.410486 loss_ctc0 94.743111 lr 0.00063864 rank 0
2022-08-25 20:19:15,072 WARNING NaN or Inf found in input tensor.
2022-08-25 20:19:41,748 DEBUG TRAIN Batch 172/2500 loss 48.525139 loss_att 31.298204 loss_ctc 88.721313 loss_ctc_origin 52.474487 loss_ctc0 173.297241 lr 0.00063860 rank 0
2022-08-25 20:20:10,787 DEBUG TRAIN Batch 172/2600 loss 50.546444 loss_att 27.199276 loss_ctc 105.023163 loss_ctc_origin 61.015594 loss_ctc0 207.707489 lr 0.00063857 rank 0
2022-08-25 20:20:38,885 DEBUG TRAIN Batch 172/2700 loss 16.251547 loss_att 9.097769 loss_ctc 32.943691 loss_ctc_origin 21.412712 loss_ctc0 59.849308 lr 0.00063854 rank 0
2022-08-25 20:21:07,438 DEBUG TRAIN Batch 172/2800 loss 18.969799 loss_att 8.659307 loss_ctc 43.027611 loss_ctc_origin 27.845715 loss_ctc0 78.452026 lr 0.00063851 rank 0
2022-08-25 20:21:40,046 DEBUG TRAIN Batch 172/2900 loss 19.522745 loss_att 8.099624 loss_ctc 46.176693 loss_ctc_origin 27.913368 loss_ctc0 88.791115 lr 0.00063847 rank 0
2022-08-25 20:22:09,773 DEBUG TRAIN Batch 172/3000 loss 41.501732 loss_att 27.832808 loss_ctc 73.395889 loss_ctc_origin 45.620754 loss_ctc0 138.204529 lr 0.00063844 rank 0
2022-08-25 20:22:38,261 DEBUG TRAIN Batch 172/3100 loss 48.809074 loss_att 25.130989 loss_ctc 104.057945 loss_ctc_origin 52.096012 loss_ctc0 225.302444 lr 0.00063841 rank 0
2022-08-25 20:23:06,370 DEBUG TRAIN Batch 172/3200 loss 21.247925 loss_att 11.585304 loss_ctc 43.794037 loss_ctc_origin 33.320808 loss_ctc0 68.231567 lr 0.00063838 rank 0
2022-08-25 20:23:35,845 DEBUG TRAIN Batch 172/3300 loss 18.265034 loss_att 7.158851 loss_ctc 44.179462 loss_ctc_origin 28.052086 loss_ctc0 81.810005 lr 0.00063834 rank 0
2022-08-25 20:24:03,664 DEBUG TRAIN Batch 172/3400 loss 22.195229 loss_att 9.241831 loss_ctc 52.419819 loss_ctc_origin 34.726639 loss_ctc0 93.703903 lr 0.00063831 rank 0
2022-08-25 20:24:32,682 DEBUG TRAIN Batch 172/3500 loss 40.097710 loss_att 24.439247 loss_ctc 76.634125 loss_ctc_origin 47.598633 loss_ctc0 144.383606 lr 0.00063828 rank 0
2022-08-25 20:25:01,022 DEBUG TRAIN Batch 172/3600 loss 42.836437 loss_att 23.213486 loss_ctc 88.623322 loss_ctc_origin 42.564621 loss_ctc0 196.093597 lr 0.00063825 rank 0
2022-08-25 20:25:29,203 DEBUG TRAIN Batch 172/3700 loss 17.017262 loss_att 9.299120 loss_ctc 35.026260 loss_ctc_origin 23.248978 loss_ctc0 62.506592 lr 0.00063821 rank 0
2022-08-25 20:25:58,207 DEBUG TRAIN Batch 172/3800 loss 19.665737 loss_att 8.566765 loss_ctc 45.563339 loss_ctc_origin 30.113852 loss_ctc0 81.612129 lr 0.00063818 rank 0
2022-08-25 20:26:26,289 DEBUG TRAIN Batch 172/3900 loss 20.699709 loss_att 8.675522 loss_ctc 48.756142 loss_ctc_origin 30.292692 loss_ctc0 91.837524 lr 0.00063815 rank 0
2022-08-25 20:26:54,259 DEBUG TRAIN Batch 172/4000 loss 40.349430 loss_att 24.210052 loss_ctc 78.007973 loss_ctc_origin 47.690918 loss_ctc0 148.747772 lr 0.00063812 rank 0
2022-08-25 20:27:07,093 WARNING NaN or Inf found in input tensor.
2022-08-25 20:27:21,000 DEBUG TRAIN Batch 172/4100 loss 58.045567 loss_att 35.287960 loss_ctc 111.146645 loss_ctc_origin 66.687668 loss_ctc0 214.884262 lr 0.00063808 rank 0
2022-08-25 20:27:49,448 DEBUG TRAIN Batch 172/4200 loss 16.608404 loss_att 8.870079 loss_ctc 34.664494 loss_ctc_origin 23.185251 loss_ctc0 61.449390 lr 0.00063805 rank 0
2022-08-25 20:28:16,368 DEBUG TRAIN Batch 172/4300 loss 19.002251 loss_att 6.940302 loss_ctc 47.146797 loss_ctc_origin 30.762661 loss_ctc0 85.376442 lr 0.00063802 rank 0
2022-08-25 20:28:45,117 DEBUG TRAIN Batch 172/4400 loss 22.377909 loss_att 8.654263 loss_ctc 54.399750 loss_ctc_origin 38.348072 loss_ctc0 91.853668 lr 0.00063799 rank 0
2022-08-25 20:29:21,125 DEBUG TRAIN Batch 172/4500 loss 45.229195 loss_att 30.427195 loss_ctc 79.767189 loss_ctc_origin 54.792950 loss_ctc0 138.040405 lr 0.00063795 rank 0
2022-08-25 20:29:49,633 DEBUG TRAIN Batch 172/4600 loss 60.209770 loss_att 37.697731 loss_ctc 112.737854 loss_ctc_origin 69.379662 loss_ctc0 213.906952 lr 0.00063792 rank 0
2022-08-25 20:30:17,195 WARNING NaN or Inf found in input tensor.
2022-08-25 20:30:18,815 DEBUG TRAIN Batch 172/4700 loss 24.508932 loss_att 13.182103 loss_ctc 50.938198 loss_ctc_origin 40.088627 loss_ctc0 76.253860 lr 0.00063789 rank 0
2022-08-25 20:30:47,753 DEBUG TRAIN Batch 172/4800 loss 17.535149 loss_att 7.130007 loss_ctc 41.813812 loss_ctc_origin 26.750599 loss_ctc0 76.961319 lr 0.00063786 rank 0
2022-08-25 20:31:15,534 DEBUG TRAIN Batch 172/4900 loss 22.141445 loss_att 9.235074 loss_ctc 52.256310 loss_ctc_origin 31.753616 loss_ctc0 100.095932 lr 0.00063782 rank 0
2022-08-25 20:31:45,800 DEBUG TRAIN Batch 172/5000 loss 51.515266 loss_att 38.510063 loss_ctc 81.860733 loss_ctc_origin 58.695930 loss_ctc0 135.911926 lr 0.00063779 rank 0
2022-08-25 20:32:14,912 DEBUG TRAIN Batch 172/5100 loss 55.411247 loss_att 32.567818 loss_ctc 108.712570 loss_ctc_origin 69.339226 loss_ctc0 200.583710 lr 0.00063776 rank 0
2022-08-25 20:32:42,850 DEBUG TRAIN Batch 172/5200 loss 19.032360 loss_att 8.133751 loss_ctc 44.462448 loss_ctc_origin 34.958878 loss_ctc0 66.637436 lr 0.00063773 rank 0
2022-08-25 20:33:11,921 DEBUG TRAIN Batch 172/5300 loss 18.858215 loss_att 7.302064 loss_ctc 45.822563 loss_ctc_origin 31.089096 loss_ctc0 80.200645 lr 0.00063769 rank 0
2022-08-25 20:33:41,018 DEBUG TRAIN Batch 172/5400 loss 18.076067 loss_att 7.197588 loss_ctc 43.459183 loss_ctc_origin 24.935184 loss_ctc0 86.681839 lr 0.00063766 rank 0
2022-08-25 20:34:09,829 DEBUG TRAIN Batch 172/5500 loss 51.734627 loss_att 36.691448 loss_ctc 86.835381 loss_ctc_origin 60.055485 loss_ctc0 149.321808 lr 0.00063763 rank 0
2022-08-25 20:34:38,167 DEBUG TRAIN Batch 172/5600 loss 50.995895 loss_att 26.235027 loss_ctc 108.771255 loss_ctc_origin 57.315018 loss_ctc0 228.835800 lr 0.00063760 rank 0
2022-08-25 20:35:00,132 DEBUG CV Batch 172/0 loss 12.113220 loss_att 9.205751 loss_ctc 18.897312 loss_ctc_origin 12.362494 loss_ctc0 34.145222 history loss 11.400678 rank 0
2022-08-25 20:35:11,060 DEBUG CV Batch 172/100 loss 21.517313 loss_att 17.131153 loss_ctc 31.751686 loss_ctc_origin 22.277529 loss_ctc0 53.858055 history loss 26.850223 rank 0
2022-08-25 20:35:20,895 DEBUG CV Batch 172/200 loss 24.455505 loss_att 18.823360 loss_ctc 37.597176 loss_ctc_origin 27.436789 loss_ctc0 61.304745 history loss 28.499192 rank 0
2022-08-25 20:35:31,219 DEBUG CV Batch 172/300 loss 22.726919 loss_att 16.926567 loss_ctc 36.261074 loss_ctc_origin 21.222836 loss_ctc0 71.350296 history loss 27.457969 rank 0
2022-08-25 20:35:41,962 DEBUG CV Batch 172/400 loss 38.364391 loss_att 31.378746 loss_ctc 54.664230 loss_ctc_origin 37.379234 loss_ctc0 94.995880 history loss 25.693731 rank 0
2022-08-25 20:35:52,970 DEBUG CV Batch 172/500 loss 16.057283 loss_att 12.115917 loss_ctc 25.253801 loss_ctc_origin 18.150394 loss_ctc0 41.828419 history loss 25.364552 rank 0
2022-08-25 20:36:03,842 DEBUG CV Batch 172/600 loss 17.328297 loss_att 12.063305 loss_ctc 29.613281 loss_ctc_origin 19.148720 loss_ctc0 54.030586 history loss 25.124167 rank 0
2022-08-25 20:36:14,056 DEBUG CV Batch 172/700 loss 18.787899 loss_att 13.027607 loss_ctc 32.228580 loss_ctc_origin 18.749481 loss_ctc0 63.679810 history loss 24.760352 rank 0
2022-08-25 20:36:25,012 DEBUG CV Batch 172/800 loss 22.238045 loss_att 17.516207 loss_ctc 33.255665 loss_ctc_origin 17.939957 loss_ctc0 68.992317 history loss 24.713525 rank 0
2022-08-25 20:36:35,251 INFO Epoch 172 CV info cv_loss 24.79439893583946
2022-08-25 20:36:35,252 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/172.pt
2022-08-25 20:36:35,749 INFO Epoch 173 TRAIN info lr 0.0006375689378797979
2022-08-25 20:36:35,753 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 20:37:02,538 DEBUG TRAIN Batch 173/0 loss 49.189625 loss_att 34.377716 loss_ctc 83.750740 loss_ctc_origin 59.731071 loss_ctc0 139.796631 lr 0.00063757 rank 0
2022-08-25 20:37:31,071 DEBUG TRAIN Batch 173/100 loss 57.727043 loss_att 35.170410 loss_ctc 110.359184 loss_ctc_origin 66.558792 loss_ctc0 212.560104 lr 0.00063754 rank 0
2022-08-25 20:38:00,783 DEBUG TRAIN Batch 173/200 loss 19.785149 loss_att 10.988721 loss_ctc 40.310150 loss_ctc_origin 28.847708 loss_ctc0 67.055855 lr 0.00063750 rank 0
2022-08-25 20:38:29,763 DEBUG TRAIN Batch 173/300 loss 18.037008 loss_att 8.347811 loss_ctc 40.645138 loss_ctc_origin 25.227150 loss_ctc0 76.620445 lr 0.00063747 rank 0
2022-08-25 20:38:58,781 DEBUG TRAIN Batch 173/400 loss 20.656336 loss_att 8.488897 loss_ctc 49.047028 loss_ctc_origin 30.438267 loss_ctc0 92.467468 lr 0.00063744 rank 0
2022-08-25 20:39:28,524 DEBUG TRAIN Batch 173/500 loss 44.222359 loss_att 31.971178 loss_ctc 72.808449 loss_ctc_origin 43.685001 loss_ctc0 140.763153 lr 0.00063741 rank 0
2022-08-25 20:39:57,732 DEBUG TRAIN Batch 173/600 loss 54.088768 loss_att 33.325195 loss_ctc 102.537094 loss_ctc_origin 61.161575 loss_ctc0 199.079956 lr 0.00063737 rank 0
2022-08-25 20:40:26,348 DEBUG TRAIN Batch 173/700 loss 18.722994 loss_att 10.326498 loss_ctc 38.314819 loss_ctc_origin 26.106331 loss_ctc0 66.801285 lr 0.00063734 rank 0
2022-08-25 20:40:55,619 DEBUG TRAIN Batch 173/800 loss 19.443321 loss_att 8.674164 loss_ctc 44.571350 loss_ctc_origin 31.703556 loss_ctc0 74.596191 lr 0.00063731 rank 0
2022-08-25 20:41:19,662 WARNING NaN or Inf found in input tensor.
2022-08-25 20:41:24,051 DEBUG TRAIN Batch 173/900 loss 23.102951 loss_att 9.416459 loss_ctc 55.038101 loss_ctc_origin 37.053230 loss_ctc0 97.002792 lr 0.00063728 rank 0
2022-08-25 20:41:54,025 DEBUG TRAIN Batch 173/1000 loss 44.852226 loss_att 26.973154 loss_ctc 86.570053 loss_ctc_origin 55.130379 loss_ctc0 159.929291 lr 0.00063724 rank 0
2022-08-25 20:42:22,626 DEBUG TRAIN Batch 173/1100 loss 56.790581 loss_att 36.502403 loss_ctc 104.129662 loss_ctc_origin 62.378777 loss_ctc0 201.548386 lr 0.00063721 rank 0
2022-08-25 20:42:50,495 DEBUG TRAIN Batch 173/1200 loss 19.612747 loss_att 10.753838 loss_ctc 40.283531 loss_ctc_origin 29.425056 loss_ctc0 65.619965 lr 0.00063718 rank 0
2022-08-25 20:43:19,126 DEBUG TRAIN Batch 173/1300 loss 17.090530 loss_att 7.445353 loss_ctc 39.595947 loss_ctc_origin 25.183830 loss_ctc0 73.224213 lr 0.00063715 rank 0
2022-08-25 20:43:48,297 DEBUG TRAIN Batch 173/1400 loss 22.550346 loss_att 9.526689 loss_ctc 52.938881 loss_ctc_origin 36.618603 loss_ctc0 91.019531 lr 0.00063711 rank 0
2022-08-25 20:44:24,251 DEBUG TRAIN Batch 173/1500 loss 54.306038 loss_att 38.082405 loss_ctc 92.161186 loss_ctc_origin 66.793961 loss_ctc0 151.351379 lr 0.00063708 rank 0
2022-08-25 20:44:52,847 DEBUG TRAIN Batch 173/1600 loss 47.631298 loss_att 27.576153 loss_ctc 94.426636 loss_ctc_origin 52.860352 loss_ctc0 191.414612 lr 0.00063705 rank 0
2022-08-25 20:45:21,056 DEBUG TRAIN Batch 173/1700 loss 20.537128 loss_att 9.786955 loss_ctc 45.620865 loss_ctc_origin 36.650467 loss_ctc0 66.551788 lr 0.00063702 rank 0
2022-08-25 20:45:49,349 DEBUG TRAIN Batch 173/1800 loss 19.737526 loss_att 8.884325 loss_ctc 45.061661 loss_ctc_origin 31.574196 loss_ctc0 76.532410 lr 0.00063699 rank 0
2022-08-25 20:46:13,797 WARNING NaN or Inf found in input tensor.
2022-08-25 20:46:18,268 DEBUG TRAIN Batch 173/1900 loss 20.258469 loss_att 7.557211 loss_ctc 49.894737 loss_ctc_origin 30.755064 loss_ctc0 94.553970 lr 0.00063695 rank 0
2022-08-25 20:46:47,131 DEBUG TRAIN Batch 173/2000 loss 35.922180 loss_att 23.208345 loss_ctc 65.587799 loss_ctc_origin 38.320126 loss_ctc0 129.212357 lr 0.00063692 rank 0
2022-08-25 20:47:14,711 DEBUG TRAIN Batch 173/2100 loss 52.737488 loss_att 29.709936 loss_ctc 106.468430 loss_ctc_origin 64.935471 loss_ctc0 203.378662 lr 0.00063689 rank 0
2022-08-25 20:47:43,260 DEBUG TRAIN Batch 173/2200 loss 17.627773 loss_att 9.041680 loss_ctc 37.661987 loss_ctc_origin 26.692070 loss_ctc0 63.258469 lr 0.00063686 rank 0
2022-08-25 20:48:11,869 DEBUG TRAIN Batch 173/2300 loss 17.288797 loss_att 7.224448 loss_ctc 40.772278 loss_ctc_origin 26.203112 loss_ctc0 74.766998 lr 0.00063682 rank 0
2022-08-25 20:48:30,108 WARNING NaN or Inf found in input tensor.
2022-08-25 20:48:41,581 DEBUG TRAIN Batch 173/2400 loss 20.924801 loss_att 8.391344 loss_ctc 50.169533 loss_ctc_origin 31.581247 loss_ctc0 93.542206 lr 0.00063679 rank 0
2022-08-25 20:48:44,275 WARNING NaN or Inf found in input tensor.
2022-08-25 20:49:10,655 DEBUG TRAIN Batch 173/2500 loss 45.015320 loss_att 27.991323 loss_ctc 84.737968 loss_ctc_origin 53.260918 loss_ctc0 158.184418 lr 0.00063676 rank 0
2022-08-25 20:49:39,393 DEBUG TRAIN Batch 173/2600 loss 52.083893 loss_att 29.218067 loss_ctc 105.437492 loss_ctc_origin 58.569237 loss_ctc0 214.796753 lr 0.00063673 rank 0
2022-08-25 20:50:07,841 DEBUG TRAIN Batch 173/2700 loss 23.769413 loss_att 15.082852 loss_ctc 44.038055 loss_ctc_origin 35.009007 loss_ctc0 65.105827 lr 0.00063669 rank 0
2022-08-25 20:50:37,171 DEBUG TRAIN Batch 173/2800 loss 22.360107 loss_att 9.039657 loss_ctc 53.441162 loss_ctc_origin 39.698463 loss_ctc0 85.507462 lr 0.00063666 rank 0
2022-08-25 20:51:06,209 DEBUG TRAIN Batch 173/2900 loss 24.748928 loss_att 10.604335 loss_ctc 57.752975 loss_ctc_origin 38.054943 loss_ctc0 103.715050 lr 0.00063663 rank 0
2022-08-25 20:51:41,205 WARNING NaN or Inf found in input tensor.
2022-08-25 20:51:41,265 DEBUG TRAIN Batch 173/3000 loss inf loss_att 32.628380 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00063660 rank 0
2022-08-25 20:52:11,014 DEBUG TRAIN Batch 173/3100 loss 43.356789 loss_att 22.677191 loss_ctc 91.609177 loss_ctc_origin 49.220928 loss_ctc0 190.515091 lr 0.00063657 rank 0
2022-08-25 20:52:40,037 DEBUG TRAIN Batch 173/3200 loss 23.500076 loss_att 14.727820 loss_ctc 43.968674 loss_ctc_origin 35.386696 loss_ctc0 63.993290 lr 0.00063653 rank 0
2022-08-25 20:52:45,629 WARNING NaN or Inf found in input tensor.
2022-08-25 20:53:08,475 DEBUG TRAIN Batch 173/3300 loss 16.350353 loss_att 7.016808 loss_ctc 38.128628 loss_ctc_origin 24.103151 loss_ctc0 70.854736 lr 0.00063650 rank 0
2022-08-25 20:53:36,900 DEBUG TRAIN Batch 173/3400 loss 21.701212 loss_att 8.407673 loss_ctc 52.719471 loss_ctc_origin 33.968639 loss_ctc0 96.471405 lr 0.00063647 rank 0
2022-08-25 20:54:06,556 DEBUG TRAIN Batch 173/3500 loss 41.584587 loss_att 29.799339 loss_ctc 69.083496 loss_ctc_origin 45.880394 loss_ctc0 123.224052 lr 0.00063644 rank 0
2022-08-25 20:54:34,902 DEBUG TRAIN Batch 173/3600 loss 42.705002 loss_att 22.687912 loss_ctc 89.411545 loss_ctc_origin 46.357918 loss_ctc0 189.869995 lr 0.00063640 rank 0
2022-08-25 20:55:03,516 DEBUG TRAIN Batch 173/3700 loss 21.892179 loss_att 11.101696 loss_ctc 47.069973 loss_ctc_origin 37.924011 loss_ctc0 68.410545 lr 0.00063637 rank 0
2022-08-25 20:55:31,600 DEBUG TRAIN Batch 173/3800 loss 16.982477 loss_att 7.087314 loss_ctc 40.071190 loss_ctc_origin 26.369543 loss_ctc0 72.041702 lr 0.00063634 rank 0
2022-08-25 20:56:00,838 DEBUG TRAIN Batch 173/3900 loss 21.751940 loss_att 8.607571 loss_ctc 52.422131 loss_ctc_origin 34.615685 loss_ctc0 93.970505 lr 0.00063631 rank 0
2022-08-25 20:56:30,714 DEBUG TRAIN Batch 173/4000 loss 31.277466 loss_att 19.578892 loss_ctc 58.574142 loss_ctc_origin 33.502037 loss_ctc0 117.075729 lr 0.00063628 rank 0
2022-08-25 20:56:58,464 DEBUG TRAIN Batch 173/4100 loss 44.261391 loss_att 25.411739 loss_ctc 88.243904 loss_ctc_origin 44.853470 loss_ctc0 189.488251 lr 0.00063624 rank 0
2022-08-25 20:57:27,613 DEBUG TRAIN Batch 173/4200 loss 21.700821 loss_att 12.209291 loss_ctc 43.847721 loss_ctc_origin 32.754669 loss_ctc0 69.731506 lr 0.00063621 rank 0
2022-08-25 20:57:57,180 DEBUG TRAIN Batch 173/4300 loss 19.604708 loss_att 8.580284 loss_ctc 45.328362 loss_ctc_origin 30.919950 loss_ctc0 78.947983 lr 0.00063618 rank 0
2022-08-25 20:58:26,576 DEBUG TRAIN Batch 173/4400 loss 21.072933 loss_att 8.864265 loss_ctc 49.559826 loss_ctc_origin 29.491234 loss_ctc0 96.386536 lr 0.00063615 rank 0
2022-08-25 20:59:01,510 DEBUG TRAIN Batch 173/4500 loss 43.967331 loss_att 25.360657 loss_ctc 87.382904 loss_ctc_origin 51.947735 loss_ctc0 170.064957 lr 0.00063611 rank 0
2022-08-25 20:59:16,745 WARNING NaN or Inf found in input tensor.
2022-08-25 20:59:29,413 DEBUG TRAIN Batch 173/4600 loss 54.539871 loss_att 27.982492 loss_ctc 116.507080 loss_ctc_origin 60.420155 loss_ctc0 247.376556 lr 0.00063608 rank 0
2022-08-25 20:59:58,240 DEBUG TRAIN Batch 173/4700 loss 17.514215 loss_att 8.465645 loss_ctc 38.627548 loss_ctc_origin 27.824619 loss_ctc0 63.834377 lr 0.00063605 rank 0
2022-08-25 21:00:27,307 DEBUG TRAIN Batch 173/4800 loss 22.164009 loss_att 9.630219 loss_ctc 51.409515 loss_ctc_origin 38.996918 loss_ctc0 80.372238 lr 0.00063602 rank 0
2022-08-25 21:00:51,406 WARNING NaN or Inf found in input tensor.
2022-08-25 21:00:55,904 DEBUG TRAIN Batch 173/4900 loss 22.735744 loss_att 9.278913 loss_ctc 54.135014 loss_ctc_origin 35.665146 loss_ctc0 97.231369 lr 0.00063599 rank 0
2022-08-25 21:01:25,548 DEBUG TRAIN Batch 173/5000 loss 40.231750 loss_att 24.079784 loss_ctc 77.919678 loss_ctc_origin 42.566788 loss_ctc0 160.409760 lr 0.00063595 rank 0
2022-08-25 21:01:46,065 WARNING NaN or Inf found in input tensor.
2022-08-25 21:01:53,150 DEBUG TRAIN Batch 173/5100 loss 58.228317 loss_att 32.208221 loss_ctc 118.941872 loss_ctc_origin 63.643341 loss_ctc0 247.971756 lr 0.00063592 rank 0
2022-08-25 21:02:20,757 DEBUG TRAIN Batch 173/5200 loss 21.323750 loss_att 12.673386 loss_ctc 41.507931 loss_ctc_origin 29.835793 loss_ctc0 68.742920 lr 0.00063589 rank 0
2022-08-25 21:02:39,484 WARNING NaN or Inf found in input tensor.
2022-08-25 21:02:49,943 DEBUG TRAIN Batch 173/5300 loss 21.717991 loss_att 8.294061 loss_ctc 53.040489 loss_ctc_origin 39.963608 loss_ctc0 83.553200 lr 0.00063586 rank 0
2022-08-25 21:03:18,898 DEBUG TRAIN Batch 173/5400 loss 22.853806 loss_att 9.709833 loss_ctc 53.523071 loss_ctc_origin 32.881149 loss_ctc0 101.687561 lr 0.00063583 rank 0
2022-08-25 21:03:48,007 DEBUG TRAIN Batch 173/5500 loss 48.837456 loss_att 29.036201 loss_ctc 95.040375 loss_ctc_origin 60.458191 loss_ctc0 175.732117 lr 0.00063579 rank 0
2022-08-25 21:04:02,089 WARNING NaN or Inf found in input tensor.
2022-08-25 21:04:09,372 WARNING NaN or Inf found in input tensor.
2022-08-25 21:04:16,680 DEBUG TRAIN Batch 173/5600 loss 58.082008 loss_att 32.271355 loss_ctc 118.306854 loss_ctc_origin 64.915405 loss_ctc0 242.886902 lr 0.00063576 rank 0
2022-08-25 21:04:40,296 DEBUG CV Batch 173/0 loss 12.626305 loss_att 9.150934 loss_ctc 20.735500 loss_ctc_origin 14.701763 loss_ctc0 34.814224 history loss 11.883581 rank 0
2022-08-25 21:04:51,055 DEBUG CV Batch 173/100 loss 20.620407 loss_att 16.455986 loss_ctc 30.337387 loss_ctc_origin 20.387270 loss_ctc0 53.554329 history loss 26.652177 rank 0
2022-08-25 21:05:00,964 DEBUG CV Batch 173/200 loss 24.766321 loss_att 18.793003 loss_ctc 38.704063 loss_ctc_origin 28.872532 loss_ctc0 61.644306 history loss 27.816787 rank 0
2022-08-25 21:05:11,000 DEBUG CV Batch 173/300 loss 22.352196 loss_att 17.063660 loss_ctc 34.692112 loss_ctc_origin 18.915485 loss_ctc0 71.504242 history loss 26.894545 rank 0
2022-08-25 21:05:22,072 DEBUG CV Batch 173/400 loss 37.021854 loss_att 29.787960 loss_ctc 53.900936 loss_ctc_origin 36.068298 loss_ctc0 95.510422 history loss 25.216700 rank 0
2022-08-25 21:05:33,245 DEBUG CV Batch 173/500 loss 16.718012 loss_att 12.857099 loss_ctc 25.726810 loss_ctc_origin 18.469948 loss_ctc0 42.659489 history loss 24.878599 rank 0
2022-08-25 21:05:44,370 DEBUG CV Batch 173/600 loss 18.564415 loss_att 13.180920 loss_ctc 31.125902 loss_ctc_origin 21.269583 loss_ctc0 54.123978 history loss 24.728735 rank 0
2022-08-25 21:05:54,536 DEBUG CV Batch 173/700 loss 18.676151 loss_att 12.939805 loss_ctc 32.060955 loss_ctc_origin 18.363327 loss_ctc0 64.022087 history loss 24.385325 rank 0
2022-08-25 21:06:05,299 DEBUG CV Batch 173/800 loss 21.718056 loss_att 16.811489 loss_ctc 33.166710 loss_ctc_origin 17.587162 loss_ctc0 69.518982 history loss 24.323150 rank 0
2022-08-25 21:06:15,923 INFO Epoch 173 CV info cv_loss 24.38571444860413
2022-08-25 21:06:15,923 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/173.pt
2022-08-25 21:06:16,391 INFO Epoch 174 TRAIN info lr 0.0006357342033194025
2022-08-25 21:06:16,395 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 21:06:43,084 DEBUG TRAIN Batch 174/0 loss 51.841583 loss_att 32.634808 loss_ctc 96.657394 loss_ctc_origin 59.553299 loss_ctc0 183.233612 lr 0.00063573 rank 0
2022-08-25 21:07:11,861 DEBUG TRAIN Batch 174/100 loss 55.077248 loss_att 29.412439 loss_ctc 114.961792 loss_ctc_origin 55.586128 loss_ctc0 253.504974 lr 0.00063570 rank 0
2022-08-25 21:07:39,997 DEBUG TRAIN Batch 174/200 loss 20.650890 loss_att 10.523393 loss_ctc 44.281715 loss_ctc_origin 34.900978 loss_ctc0 66.170105 lr 0.00063567 rank 0
2022-08-25 21:08:08,760 DEBUG TRAIN Batch 174/300 loss 19.398785 loss_att 7.194864 loss_ctc 47.874596 loss_ctc_origin 33.335594 loss_ctc0 81.798935 lr 0.00063564 rank 0
2022-08-25 21:08:36,337 DEBUG TRAIN Batch 174/400 loss 21.536783 loss_att 8.386944 loss_ctc 52.219742 loss_ctc_origin 33.241631 loss_ctc0 96.501999 lr 0.00063560 rank 0
2022-08-25 21:09:05,179 DEBUG TRAIN Batch 174/500 loss 42.899220 loss_att 27.352634 loss_ctc 79.174583 loss_ctc_origin 47.507416 loss_ctc0 153.064636 lr 0.00063557 rank 0
2022-08-25 21:09:33,992 DEBUG TRAIN Batch 174/600 loss 44.462891 loss_att 22.391659 loss_ctc 95.962425 loss_ctc_origin 42.194382 loss_ctc0 221.421188 lr 0.00063554 rank 0
2022-08-25 21:10:03,014 DEBUG TRAIN Batch 174/700 loss 18.250114 loss_att 8.947754 loss_ctc 39.955620 loss_ctc_origin 28.792015 loss_ctc0 66.004036 lr 0.00063551 rank 0
2022-08-25 21:10:31,921 DEBUG TRAIN Batch 174/800 loss 21.407042 loss_att 8.596548 loss_ctc 51.298195 loss_ctc_origin 37.704281 loss_ctc0 83.017334 lr 0.00063548 rank 0
2022-08-25 21:11:01,203 DEBUG TRAIN Batch 174/900 loss 22.178604 loss_att 8.630765 loss_ctc 53.790230 loss_ctc_origin 33.716141 loss_ctc0 100.629776 lr 0.00063544 rank 0
2022-08-25 21:11:29,899 DEBUG TRAIN Batch 174/1000 loss 43.275787 loss_att 24.440807 loss_ctc 87.224068 loss_ctc_origin 52.975071 loss_ctc0 167.138382 lr 0.00063541 rank 0
2022-08-25 21:11:57,925 DEBUG TRAIN Batch 174/1100 loss 49.459290 loss_att 25.073008 loss_ctc 106.360611 loss_ctc_origin 49.719421 loss_ctc0 238.523376 lr 0.00063538 rank 0
2022-08-25 21:12:27,323 DEBUG TRAIN Batch 174/1200 loss 15.260292 loss_att 7.256740 loss_ctc 33.935246 loss_ctc_origin 21.000923 loss_ctc0 64.115326 lr 0.00063535 rank 0
2022-08-25 21:12:56,539 DEBUG TRAIN Batch 174/1300 loss 17.840452 loss_att 7.736046 loss_ctc 41.417397 loss_ctc_origin 27.012369 loss_ctc0 75.029121 lr 0.00063532 rank 0
2022-08-25 21:13:26,236 DEBUG TRAIN Batch 174/1400 loss 24.600700 loss_att 10.185915 loss_ctc 58.235199 loss_ctc_origin 37.894562 loss_ctc0 105.696678 lr 0.00063528 rank 0
2022-08-25 21:13:59,829 DEBUG TRAIN Batch 174/1500 loss 52.274315 loss_att 31.834736 loss_ctc 99.966667 loss_ctc_origin 65.212120 loss_ctc0 181.060608 lr 0.00063525 rank 0
2022-08-25 21:14:00,640 WARNING NaN or Inf found in input tensor.
2022-08-25 21:14:28,123 DEBUG TRAIN Batch 174/1600 loss 58.391182 loss_att 31.833395 loss_ctc 120.359352 loss_ctc_origin 63.419418 loss_ctc0 253.219193 lr 0.00063522 rank 0
2022-08-25 21:14:56,337 DEBUG TRAIN Batch 174/1700 loss 19.173267 loss_att 10.513735 loss_ctc 39.378845 loss_ctc_origin 28.429565 loss_ctc0 64.927155 lr 0.00063519 rank 0
2022-08-25 21:15:08,866 WARNING NaN or Inf found in input tensor.
2022-08-25 21:15:25,231 DEBUG TRAIN Batch 174/1800 loss 18.428944 loss_att 7.660885 loss_ctc 43.554413 loss_ctc_origin 26.648876 loss_ctc0 83.000664 lr 0.00063516 rank 0
2022-08-25 21:15:54,354 DEBUG TRAIN Batch 174/1900 loss 24.641869 loss_att 10.912658 loss_ctc 56.676693 loss_ctc_origin 39.499744 loss_ctc0 96.756241 lr 0.00063512 rank 0
2022-08-25 21:16:23,388 DEBUG TRAIN Batch 174/2000 loss 44.029015 loss_att 25.846792 loss_ctc 86.454193 loss_ctc_origin 49.012424 loss_ctc0 173.818329 lr 0.00063509 rank 0
2022-08-25 21:16:52,066 DEBUG TRAIN Batch 174/2100 loss 51.479614 loss_att 27.906178 loss_ctc 106.484291 loss_ctc_origin 60.177940 loss_ctc0 214.532440 lr 0.00063506 rank 0
2022-08-25 21:17:20,884 DEBUG TRAIN Batch 174/2200 loss 20.438349 loss_att 10.682965 loss_ctc 43.200909 loss_ctc_origin 31.069410 loss_ctc0 71.507736 lr 0.00063503 rank 0
2022-08-25 21:17:48,740 DEBUG TRAIN Batch 174/2300 loss 17.566584 loss_att 7.406389 loss_ctc 41.273705 loss_ctc_origin 27.997240 loss_ctc0 72.252121 lr 0.00063500 rank 0
2022-08-25 21:18:19,268 DEBUG TRAIN Batch 174/2400 loss 22.468594 loss_att 9.224536 loss_ctc 53.371387 loss_ctc_origin 34.057869 loss_ctc0 98.436264 lr 0.00063496 rank 0
2022-08-25 21:18:48,382 DEBUG TRAIN Batch 174/2500 loss 42.475700 loss_att 28.309948 loss_ctc 75.529114 loss_ctc_origin 44.661469 loss_ctc0 147.553619 lr 0.00063493 rank 0
2022-08-25 21:19:17,071 DEBUG TRAIN Batch 174/2600 loss 50.299232 loss_att 28.702646 loss_ctc 100.691269 loss_ctc_origin 54.723454 loss_ctc0 207.949509 lr 0.00063490 rank 0
2022-08-25 21:19:45,760 DEBUG TRAIN Batch 174/2700 loss 18.149380 loss_att 10.687406 loss_ctc 35.560650 loss_ctc_origin 23.916113 loss_ctc0 62.731232 lr 0.00063487 rank 0
2022-08-25 21:20:14,795 DEBUG TRAIN Batch 174/2800 loss 16.008589 loss_att 6.236101 loss_ctc 38.811058 loss_ctc_origin 24.618076 loss_ctc0 71.928009 lr 0.00063484 rank 0
2022-08-25 21:20:43,238 DEBUG TRAIN Batch 174/2900 loss 22.912060 loss_att 10.058947 loss_ctc 52.902657 loss_ctc_origin 35.395889 loss_ctc0 93.751770 lr 0.00063480 rank 0
2022-08-25 21:21:18,521 DEBUG TRAIN Batch 174/3000 loss 44.349400 loss_att 28.290188 loss_ctc 81.820892 loss_ctc_origin 48.206627 loss_ctc0 160.254181 lr 0.00063477 rank 0
2022-08-25 21:21:26,427 WARNING NaN or Inf found in input tensor.
2022-08-25 21:21:47,479 DEBUG TRAIN Batch 174/3100 loss 50.940048 loss_att 28.172794 loss_ctc 104.063644 loss_ctc_origin 55.005051 loss_ctc0 218.533691 lr 0.00063474 rank 0
2022-08-25 21:22:15,659 DEBUG TRAIN Batch 174/3200 loss 16.241360 loss_att 7.958265 loss_ctc 35.568577 loss_ctc_origin 23.209332 loss_ctc0 64.406815 lr 0.00063471 rank 0
2022-08-25 21:22:44,053 DEBUG TRAIN Batch 174/3300 loss 18.398327 loss_att 7.673186 loss_ctc 43.423653 loss_ctc_origin 28.651676 loss_ctc0 77.891586 lr 0.00063468 rank 0
2022-08-25 21:23:12,458 DEBUG TRAIN Batch 174/3400 loss 22.151917 loss_att 9.678069 loss_ctc 51.257561 loss_ctc_origin 33.370594 loss_ctc0 92.993813 lr 0.00063464 rank 0
2022-08-25 21:23:42,485 DEBUG TRAIN Batch 174/3500 loss 52.870846 loss_att 34.802418 loss_ctc 95.030510 loss_ctc_origin 60.756874 loss_ctc0 175.002319 lr 0.00063461 rank 0
2022-08-25 21:24:11,341 DEBUG TRAIN Batch 174/3600 loss 57.364624 loss_att 33.571209 loss_ctc 112.882599 loss_ctc_origin 60.364738 loss_ctc0 235.424255 lr 0.00063458 rank 0
2022-08-25 21:24:40,504 DEBUG TRAIN Batch 174/3700 loss 19.407021 loss_att 10.064599 loss_ctc 41.206001 loss_ctc_origin 30.248758 loss_ctc0 66.772888 lr 0.00063455 rank 0
2022-08-25 21:25:09,572 DEBUG TRAIN Batch 174/3800 loss 20.959059 loss_att 9.260132 loss_ctc 48.256554 loss_ctc_origin 33.637516 loss_ctc0 82.367638 lr 0.00063452 rank 0
2022-08-25 21:25:38,609 DEBUG TRAIN Batch 174/3900 loss 23.287457 loss_att 9.826043 loss_ctc 54.697418 loss_ctc_origin 36.967621 loss_ctc0 96.066940 lr 0.00063448 rank 0
2022-08-25 21:26:07,192 DEBUG TRAIN Batch 174/4000 loss 43.321602 loss_att 26.860744 loss_ctc 81.730263 loss_ctc_origin 53.079308 loss_ctc0 148.582489 lr 0.00063445 rank 0
2022-08-25 21:26:36,332 DEBUG TRAIN Batch 174/4100 loss 58.211597 loss_att 33.836720 loss_ctc 115.086304 loss_ctc_origin 62.680447 loss_ctc0 237.366638 lr 0.00063442 rank 0
2022-08-25 21:27:06,224 DEBUG TRAIN Batch 174/4200 loss 18.512375 loss_att 9.467273 loss_ctc 39.617611 loss_ctc_origin 29.076157 loss_ctc0 64.214333 lr 0.00063439 rank 0
2022-08-25 21:27:36,387 DEBUG TRAIN Batch 174/4300 loss 18.567202 loss_att 7.345209 loss_ctc 44.751850 loss_ctc_origin 29.338198 loss_ctc0 80.717041 lr 0.00063436 rank 0
2022-08-25 21:28:04,019 DEBUG TRAIN Batch 174/4400 loss 19.786713 loss_att 7.919664 loss_ctc 47.476486 loss_ctc_origin 28.282064 loss_ctc0 92.263458 lr 0.00063432 rank 0
2022-08-25 21:28:38,672 DEBUG TRAIN Batch 174/4500 loss 43.131241 loss_att 28.706829 loss_ctc 76.788193 loss_ctc_origin 47.307415 loss_ctc0 145.576691 lr 0.00063429 rank 0
2022-08-25 21:29:07,541 DEBUG TRAIN Batch 174/4600 loss 47.127136 loss_att 24.186031 loss_ctc 100.656380 loss_ctc_origin 48.844856 loss_ctc0 221.549927 lr 0.00063426 rank 0
2022-08-25 21:29:36,261 DEBUG TRAIN Batch 174/4700 loss 19.622608 loss_att 11.012838 loss_ctc 39.712070 loss_ctc_origin 28.889198 loss_ctc0 64.965439 lr 0.00063423 rank 0
2022-08-25 21:30:04,255 DEBUG TRAIN Batch 174/4800 loss 19.667786 loss_att 8.376436 loss_ctc 46.014267 loss_ctc_origin 31.472961 loss_ctc0 79.943985 lr 0.00063420 rank 0
2022-08-25 21:30:33,266 DEBUG TRAIN Batch 174/4900 loss 20.200733 loss_att 8.393973 loss_ctc 47.749840 loss_ctc_origin 30.899954 loss_ctc0 87.066246 lr 0.00063417 rank 0
2022-08-25 21:31:02,389 DEBUG TRAIN Batch 174/5000 loss 43.552586 loss_att 28.338158 loss_ctc 79.052917 loss_ctc_origin 45.232300 loss_ctc0 157.967682 lr 0.00063413 rank 0
2022-08-25 21:31:10,123 WARNING NaN or Inf found in input tensor.
2022-08-25 21:31:30,001 DEBUG TRAIN Batch 174/5100 loss 46.545929 loss_att 23.351046 loss_ctc 100.667328 loss_ctc_origin 55.848274 loss_ctc0 205.245117 lr 0.00063410 rank 0
2022-08-25 21:31:58,628 DEBUG TRAIN Batch 174/5200 loss 19.393425 loss_att 10.826689 loss_ctc 39.382477 loss_ctc_origin 29.264475 loss_ctc0 62.991146 lr 0.00063407 rank 0
2022-08-25 21:32:27,837 DEBUG TRAIN Batch 174/5300 loss 20.217340 loss_att 8.961788 loss_ctc 46.480293 loss_ctc_origin 32.875977 loss_ctc0 78.223694 lr 0.00063404 rank 0
2022-08-25 21:32:55,378 DEBUG TRAIN Batch 174/5400 loss 20.961580 loss_att 8.589569 loss_ctc 49.829605 loss_ctc_origin 30.599806 loss_ctc0 94.699127 lr 0.00063401 rank 0
2022-08-25 21:33:24,986 DEBUG TRAIN Batch 174/5500 loss 45.519226 loss_att 29.755592 loss_ctc 82.301025 loss_ctc_origin 49.457336 loss_ctc0 158.936279 lr 0.00063397 rank 0
2022-08-25 21:33:53,116 DEBUG TRAIN Batch 174/5600 loss 56.406219 loss_att 32.898067 loss_ctc 111.258560 loss_ctc_origin 68.950165 loss_ctc0 209.978134 lr 0.00063394 rank 0
2022-08-25 21:34:15,502 DEBUG CV Batch 174/0 loss 12.683846 loss_att 9.277296 loss_ctc 20.632462 loss_ctc_origin 14.440517 loss_ctc0 35.080330 history loss 11.937737 rank 0
2022-08-25 21:34:26,466 DEBUG CV Batch 174/100 loss 20.742867 loss_att 16.528910 loss_ctc 30.575432 loss_ctc_origin 20.825783 loss_ctc0 53.324608 history loss 26.368121 rank 0
2022-08-25 21:34:36,223 DEBUG CV Batch 174/200 loss 25.847385 loss_att 19.852524 loss_ctc 39.835396 loss_ctc_origin 30.501987 loss_ctc0 61.613342 history loss 27.647760 rank 0
2022-08-25 21:34:46,479 DEBUG CV Batch 174/300 loss 22.824553 loss_att 17.240273 loss_ctc 35.854538 loss_ctc_origin 20.362446 loss_ctc0 72.002747 history loss 26.836490 rank 0
2022-08-25 21:34:57,313 DEBUG CV Batch 174/400 loss 37.847794 loss_att 30.675873 loss_ctc 54.582279 loss_ctc_origin 37.360317 loss_ctc0 94.766853 history loss 25.165418 rank 0
2022-08-25 21:35:08,339 DEBUG CV Batch 174/500 loss 16.488775 loss_att 12.618689 loss_ctc 25.518976 loss_ctc_origin 18.396030 loss_ctc0 42.139183 history loss 24.808963 rank 0
2022-08-25 21:35:19,016 DEBUG CV Batch 174/600 loss 17.593555 loss_att 12.189943 loss_ctc 30.201984 loss_ctc_origin 19.785614 loss_ctc0 54.506844 history loss 24.648809 rank 0
2022-08-25 21:35:28,980 DEBUG CV Batch 174/700 loss 19.328232 loss_att 13.840431 loss_ctc 32.133095 loss_ctc_origin 18.583275 loss_ctc0 63.749336 history loss 24.319752 rank 0
2022-08-25 21:35:39,633 DEBUG CV Batch 174/800 loss 21.616789 loss_att 17.024254 loss_ctc 32.332703 loss_ctc_origin 16.727600 loss_ctc0 68.744598 history loss 24.276806 rank 0
2022-08-25 21:35:49,972 INFO Epoch 174 CV info cv_loss 24.33797180107619
2022-08-25 21:35:49,973 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/174.pt
2022-08-25 21:35:50,412 INFO Epoch 175 TRAIN info lr 0.0006339152176074699
2022-08-25 21:35:50,416 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 21:36:17,454 DEBUG TRAIN Batch 175/0 loss 38.943024 loss_att 23.331158 loss_ctc 75.370712 loss_ctc_origin 45.619804 loss_ctc0 144.789505 lr 0.00063391 rank 0
2022-08-25 21:36:45,615 DEBUG TRAIN Batch 175/100 loss 59.908501 loss_att 34.769382 loss_ctc 118.566444 loss_ctc_origin 68.587166 loss_ctc0 235.184738 lr 0.00063388 rank 0
2022-08-25 21:37:13,704 DEBUG TRAIN Batch 175/200 loss 19.451803 loss_att 10.347350 loss_ctc 40.695526 loss_ctc_origin 28.722519 loss_ctc0 68.632538 lr 0.00063385 rank 0
2022-08-25 21:37:42,709 DEBUG TRAIN Batch 175/300 loss 18.431484 loss_att 7.260186 loss_ctc 44.497841 loss_ctc_origin 30.769115 loss_ctc0 76.531540 lr 0.00063382 rank 0
2022-08-25 21:38:11,910 DEBUG TRAIN Batch 175/400 loss 21.225117 loss_att 8.754393 loss_ctc 50.323471 loss_ctc_origin 31.965923 loss_ctc0 93.157753 lr 0.00063379 rank 0
2022-08-25 21:38:41,286 DEBUG TRAIN Batch 175/500 loss 44.958473 loss_att 28.610893 loss_ctc 83.102829 loss_ctc_origin 51.632210 loss_ctc0 156.534256 lr 0.00063375 rank 0
2022-08-25 21:39:09,241 DEBUG TRAIN Batch 175/600 loss 48.556046 loss_att 26.443106 loss_ctc 100.152893 loss_ctc_origin 55.005363 loss_ctc0 205.497131 lr 0.00063372 rank 0
2022-08-25 21:39:38,308 DEBUG TRAIN Batch 175/700 loss 17.432217 loss_att 9.620090 loss_ctc 35.660515 loss_ctc_origin 24.074621 loss_ctc0 62.694271 lr 0.00063369 rank 0
2022-08-25 21:40:07,942 DEBUG TRAIN Batch 175/800 loss 20.520271 loss_att 8.332605 loss_ctc 48.958153 loss_ctc_origin 32.963993 loss_ctc0 86.277863 lr 0.00063366 rank 0
2022-08-25 21:40:37,148 DEBUG TRAIN Batch 175/900 loss 21.661047 loss_att 9.124103 loss_ctc 50.913918 loss_ctc_origin 31.895706 loss_ctc0 95.289734 lr 0.00063363 rank 0
2022-08-25 21:41:04,185 DEBUG TRAIN Batch 175/1000 loss 41.296093 loss_att 25.921150 loss_ctc 77.170959 loss_ctc_origin 46.705956 loss_ctc0 148.255951 lr 0.00063360 rank 0
2022-08-25 21:41:33,877 DEBUG TRAIN Batch 175/1100 loss 62.009354 loss_att 38.975555 loss_ctc 115.754868 loss_ctc_origin 73.192108 loss_ctc0 215.067963 lr 0.00063356 rank 0
2022-08-25 21:42:01,431 DEBUG TRAIN Batch 175/1200 loss 16.525141 loss_att 7.970469 loss_ctc 36.486038 loss_ctc_origin 23.601227 loss_ctc0 66.550598 lr 0.00063353 rank 0
2022-08-25 21:42:30,524 DEBUG TRAIN Batch 175/1300 loss 18.327021 loss_att 7.593493 loss_ctc 43.371918 loss_ctc_origin 26.804783 loss_ctc0 82.028557 lr 0.00063350 rank 0
2022-08-25 21:43:00,092 DEBUG TRAIN Batch 175/1400 loss 19.785820 loss_att 7.708854 loss_ctc 47.965405 loss_ctc_origin 29.084370 loss_ctc0 92.021149 lr 0.00063347 rank 0
2022-08-25 21:43:34,607 DEBUG TRAIN Batch 175/1500 loss 40.273609 loss_att 25.642897 loss_ctc 74.411934 loss_ctc_origin 44.612984 loss_ctc0 143.942810 lr 0.00063344 rank 0
2022-08-25 21:44:03,170 DEBUG TRAIN Batch 175/1600 loss 46.544720 loss_att 22.658237 loss_ctc 102.279839 loss_ctc_origin 55.044670 loss_ctc0 212.495224 lr 0.00063341 rank 0
2022-08-25 21:44:31,749 DEBUG TRAIN Batch 175/1700 loss 17.795441 loss_att 9.898408 loss_ctc 36.221848 loss_ctc_origin 25.331587 loss_ctc0 61.632458 lr 0.00063337 rank 0
2022-08-25 21:45:00,652 DEBUG TRAIN Batch 175/1800 loss 17.737511 loss_att 7.954297 loss_ctc 40.565010 loss_ctc_origin 25.763790 loss_ctc0 75.101181 lr 0.00063334 rank 0
2022-08-25 21:45:29,583 DEBUG TRAIN Batch 175/1900 loss 23.679579 loss_att 10.204485 loss_ctc 55.121464 loss_ctc_origin 37.973854 loss_ctc0 95.132553 lr 0.00063331 rank 0
2022-08-25 21:45:58,651 DEBUG TRAIN Batch 175/2000 loss 36.793533 loss_att 22.316006 loss_ctc 70.574432 loss_ctc_origin 46.169888 loss_ctc0 127.518356 lr 0.00063328 rank 0
2022-08-25 21:46:26,869 DEBUG TRAIN Batch 175/2100 loss 20.841354 loss_att 13.925438 loss_ctc 36.978493 loss_ctc_origin 28.287935 loss_ctc0 57.256462 lr 0.00063325 rank 0
2022-08-25 21:46:54,657 DEBUG TRAIN Batch 175/2200 loss 18.452541 loss_att 8.747339 loss_ctc 41.098011 loss_ctc_origin 28.661282 loss_ctc0 70.117043 lr 0.00063321 rank 0
2022-08-25 21:47:23,564 DEBUG TRAIN Batch 175/2300 loss 20.263956 loss_att 9.187115 loss_ctc 46.109917 loss_ctc_origin 33.078293 loss_ctc0 76.517044 lr 0.00063318 rank 0
2022-08-25 21:47:50,617 DEBUG TRAIN Batch 175/2400 loss 23.489470 loss_att 9.651844 loss_ctc 55.777260 loss_ctc_origin 37.437637 loss_ctc0 98.569702 lr 0.00063315 rank 0
2022-08-25 21:48:19,176 DEBUG TRAIN Batch 175/2500 loss 45.834297 loss_att 29.054028 loss_ctc 84.988266 loss_ctc_origin 53.989799 loss_ctc0 157.318008 lr 0.00063312 rank 0
2022-08-25 21:48:47,505 DEBUG TRAIN Batch 175/2600 loss 50.423603 loss_att 26.884762 loss_ctc 105.347565 loss_ctc_origin 54.279633 loss_ctc0 224.506073 lr 0.00063309 rank 0
2022-08-25 21:49:15,818 DEBUG TRAIN Batch 175/2700 loss 21.653706 loss_att 11.912582 loss_ctc 44.382996 loss_ctc_origin 33.979858 loss_ctc0 68.656982 lr 0.00063306 rank 0
2022-08-25 21:49:45,793 DEBUG TRAIN Batch 175/2800 loss 18.666603 loss_att 8.679720 loss_ctc 41.969326 loss_ctc_origin 26.694229 loss_ctc0 77.611214 lr 0.00063302 rank 0
2022-08-25 21:50:14,438 DEBUG TRAIN Batch 175/2900 loss 26.226507 loss_att 11.403324 loss_ctc 60.813931 loss_ctc_origin 41.125332 loss_ctc0 106.753998 lr 0.00063299 rank 0
2022-08-25 21:50:49,365 DEBUG TRAIN Batch 175/3000 loss 42.716827 loss_att 28.081177 loss_ctc 76.866669 loss_ctc_origin 45.706009 loss_ctc0 149.574860 lr 0.00063296 rank 0
2022-08-25 21:51:17,761 DEBUG TRAIN Batch 175/3100 loss 59.552574 loss_att 31.949226 loss_ctc 123.960388 loss_ctc_origin 72.905937 loss_ctc0 243.087418 lr 0.00063293 rank 0
2022-08-25 21:51:47,074 DEBUG TRAIN Batch 175/3200 loss 18.820393 loss_att 10.268089 loss_ctc 38.775764 loss_ctc_origin 27.984497 loss_ctc0 63.955383 lr 0.00063290 rank 0
2022-08-25 21:52:15,841 DEBUG TRAIN Batch 175/3300 loss 19.676331 loss_att 8.558481 loss_ctc 45.617977 loss_ctc_origin 31.233881 loss_ctc0 79.180870 lr 0.00063287 rank 0
2022-08-25 21:52:43,402 DEBUG TRAIN Batch 175/3400 loss 20.221828 loss_att 7.713695 loss_ctc 49.407475 loss_ctc_origin 32.551937 loss_ctc0 88.737061 lr 0.00063283 rank 0
2022-08-25 21:53:12,660 DEBUG TRAIN Batch 175/3500 loss 49.435753 loss_att 31.963100 loss_ctc 90.205276 loss_ctc_origin 59.151299 loss_ctc0 162.664551 lr 0.00063280 rank 0
2022-08-25 21:53:41,976 DEBUG TRAIN Batch 175/3600 loss 53.828724 loss_att 32.131401 loss_ctc 104.455811 loss_ctc_origin 62.802353 loss_ctc0 201.647186 lr 0.00063277 rank 0
2022-08-25 21:54:10,007 DEBUG TRAIN Batch 175/3700 loss 21.478930 loss_att 12.909039 loss_ctc 41.475342 loss_ctc_origin 31.274754 loss_ctc0 65.276718 lr 0.00063274 rank 0
2022-08-25 21:54:15,528 WARNING NaN or Inf found in input tensor.
2022-08-25 21:54:39,031 DEBUG TRAIN Batch 175/3800 loss 17.824389 loss_att 7.361359 loss_ctc 42.238121 loss_ctc_origin 26.920914 loss_ctc0 77.978279 lr 0.00063271 rank 0
2022-08-25 21:55:06,295 DEBUG TRAIN Batch 175/3900 loss 22.303900 loss_att 9.661775 loss_ctc 51.802193 loss_ctc_origin 34.484100 loss_ctc0 92.211075 lr 0.00063268 rank 0
2022-08-25 21:55:35,631 DEBUG TRAIN Batch 175/4000 loss 50.666672 loss_att 35.274719 loss_ctc 86.581223 loss_ctc_origin 58.863457 loss_ctc0 151.256012 lr 0.00063264 rank 0
2022-08-25 21:56:03,997 DEBUG TRAIN Batch 175/4100 loss 58.198906 loss_att 33.908360 loss_ctc 114.876846 loss_ctc_origin 66.457809 loss_ctc0 227.854614 lr 0.00063261 rank 0
2022-08-25 21:56:32,026 DEBUG TRAIN Batch 175/4200 loss 17.656460 loss_att 10.198366 loss_ctc 35.058678 loss_ctc_origin 25.998100 loss_ctc0 56.200016 lr 0.00063258 rank 0
2022-08-25 21:57:01,747 DEBUG TRAIN Batch 175/4300 loss 20.520145 loss_att 8.518518 loss_ctc 48.523941 loss_ctc_origin 33.855438 loss_ctc0 82.750443 lr 0.00063255 rank 0
2022-08-25 21:57:30,568 DEBUG TRAIN Batch 175/4400 loss 23.952312 loss_att 10.446550 loss_ctc 55.465752 loss_ctc_origin 37.040829 loss_ctc0 98.457230 lr 0.00063252 rank 0
2022-08-25 21:58:05,436 DEBUG TRAIN Batch 175/4500 loss 51.340397 loss_att 33.830727 loss_ctc 92.196289 loss_ctc_origin 58.091904 loss_ctc0 171.773178 lr 0.00063249 rank 0
2022-08-25 21:58:34,310 DEBUG TRAIN Batch 175/4600 loss 55.251747 loss_att 31.950911 loss_ctc 109.620369 loss_ctc_origin 62.082741 loss_ctc0 220.541489 lr 0.00063245 rank 0
2022-08-25 21:59:02,329 DEBUG TRAIN Batch 175/4700 loss 18.763323 loss_att 10.573123 loss_ctc 37.873787 loss_ctc_origin 27.831665 loss_ctc0 61.305412 lr 0.00063242 rank 0
2022-08-25 21:59:31,537 DEBUG TRAIN Batch 175/4800 loss 17.447311 loss_att 6.613466 loss_ctc 42.726280 loss_ctc_origin 30.314487 loss_ctc0 71.687134 lr 0.00063239 rank 0
2022-08-25 22:00:01,042 DEBUG TRAIN Batch 175/4900 loss 23.451435 loss_att 10.000693 loss_ctc 54.836494 loss_ctc_origin 35.912117 loss_ctc0 98.993370 lr 0.00063236 rank 0
2022-08-25 22:00:31,161 DEBUG TRAIN Batch 175/5000 loss 62.471138 loss_att 47.209328 loss_ctc 98.082031 loss_ctc_origin 68.139954 loss_ctc0 167.946854 lr 0.00063233 rank 0
2022-08-25 22:00:59,715 DEBUG TRAIN Batch 175/5100 loss 55.572731 loss_att 32.900894 loss_ctc 108.473671 loss_ctc_origin 61.095802 loss_ctc0 219.022034 lr 0.00063230 rank 0
2022-08-25 22:01:28,999 DEBUG TRAIN Batch 175/5200 loss 20.970133 loss_att 11.271585 loss_ctc 43.600075 loss_ctc_origin 32.476597 loss_ctc0 69.554863 lr 0.00063226 rank 0
2022-08-25 22:01:57,786 DEBUG TRAIN Batch 175/5300 loss 18.543507 loss_att 6.429814 loss_ctc 46.808792 loss_ctc_origin 32.222878 loss_ctc0 80.842590 lr 0.00063223 rank 0
2022-08-25 22:02:27,087 DEBUG TRAIN Batch 175/5400 loss 22.231773 loss_att 9.489367 loss_ctc 51.964050 loss_ctc_origin 33.404350 loss_ctc0 95.270004 lr 0.00063220 rank 0
2022-08-25 22:02:55,785 DEBUG TRAIN Batch 175/5500 loss 54.375519 loss_att 37.006935 loss_ctc 94.902222 loss_ctc_origin 65.197380 loss_ctc0 164.213501 lr 0.00063217 rank 0
2022-08-25 22:03:24,412 DEBUG TRAIN Batch 175/5600 loss 53.233925 loss_att 26.826012 loss_ctc 114.852386 loss_ctc_origin 61.986420 loss_ctc0 238.206299 lr 0.00063214 rank 0
2022-08-25 22:03:47,844 DEBUG CV Batch 175/0 loss 12.272322 loss_att 8.967781 loss_ctc 19.982918 loss_ctc_origin 14.048747 loss_ctc0 33.829315 history loss 11.550420 rank 0
2022-08-25 22:03:58,844 DEBUG CV Batch 175/100 loss 19.681934 loss_att 15.555834 loss_ctc 29.309498 loss_ctc_origin 19.293667 loss_ctc0 52.679768 history loss 25.823897 rank 0
2022-08-25 22:04:08,682 DEBUG CV Batch 175/200 loss 24.029270 loss_att 18.553541 loss_ctc 36.805969 loss_ctc_origin 25.941105 loss_ctc0 62.157326 history loss 27.234720 rank 0
2022-08-25 22:04:18,642 DEBUG CV Batch 175/300 loss 22.498859 loss_att 17.156944 loss_ctc 34.963326 loss_ctc_origin 19.298683 loss_ctc0 71.514160 history loss 26.375841 rank 0
2022-08-25 22:04:29,696 DEBUG CV Batch 175/400 loss 36.606270 loss_att 29.434353 loss_ctc 53.340744 loss_ctc_origin 35.847149 loss_ctc0 94.159134 history loss 24.768224 rank 0
2022-08-25 22:04:40,863 DEBUG CV Batch 175/500 loss 15.978029 loss_att 12.153885 loss_ctc 24.901033 loss_ctc_origin 17.545547 loss_ctc0 42.063831 history loss 24.469903 rank 0
2022-08-25 22:04:51,736 DEBUG CV Batch 175/600 loss 17.720999 loss_att 12.561234 loss_ctc 29.760448 loss_ctc_origin 19.231112 loss_ctc0 54.328899 history loss 24.288964 rank 0
2022-08-25 22:05:02,129 DEBUG CV Batch 175/700 loss 18.318295 loss_att 12.498169 loss_ctc 31.898590 loss_ctc_origin 18.369722 loss_ctc0 63.465942 history loss 23.977398 rank 0
2022-08-25 22:05:12,641 DEBUG CV Batch 175/800 loss 21.531698 loss_att 16.697857 loss_ctc 32.810661 loss_ctc_origin 17.445253 loss_ctc0 68.663277 history loss 23.945912 rank 0
2022-08-25 22:05:23,243 INFO Epoch 175 CV info cv_loss 24.03900546938391
2022-08-25 22:05:23,243 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/175.pt
2022-08-25 22:05:23,736 INFO Epoch 176 TRAIN info lr 0.0006321117567194859
2022-08-25 22:05:23,739 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 22:05:50,155 DEBUG TRAIN Batch 176/0 loss 48.137680 loss_att 31.947285 loss_ctc 85.915276 loss_ctc_origin 55.973446 loss_ctc0 155.779541 lr 0.00063211 rank 0
2022-08-25 22:06:19,423 DEBUG TRAIN Batch 176/100 loss 49.442543 loss_att 24.990120 loss_ctc 106.498184 loss_ctc_origin 54.537262 loss_ctc0 227.740326 lr 0.00063208 rank 0
2022-08-25 22:06:47,482 DEBUG TRAIN Batch 176/200 loss 20.298512 loss_att 10.079316 loss_ctc 44.143303 loss_ctc_origin 32.421829 loss_ctc0 71.493408 lr 0.00063205 rank 0
2022-08-25 22:07:16,136 DEBUG TRAIN Batch 176/300 loss 19.870125 loss_att 7.866806 loss_ctc 47.877869 loss_ctc_origin 33.720993 loss_ctc0 80.910583 lr 0.00063202 rank 0
2022-08-25 22:07:44,849 DEBUG TRAIN Batch 176/400 loss 21.491692 loss_att 8.961983 loss_ctc 50.727676 loss_ctc_origin 31.649187 loss_ctc0 95.244156 lr 0.00063198 rank 0
2022-08-25 22:08:15,113 DEBUG TRAIN Batch 176/500 loss 44.124382 loss_att 26.067057 loss_ctc 86.258141 loss_ctc_origin 53.078011 loss_ctc0 163.678436 lr 0.00063195 rank 0
2022-08-25 22:08:15,820 WARNING NaN or Inf found in input tensor.
2022-08-25 22:08:42,396 DEBUG TRAIN Batch 176/600 loss 55.294731 loss_att 30.684649 loss_ctc 112.718254 loss_ctc_origin 68.142265 loss_ctc0 216.728882 lr 0.00063192 rank 0
2022-08-25 22:09:10,661 DEBUG TRAIN Batch 176/700 loss 21.031315 loss_att 9.801849 loss_ctc 47.233398 loss_ctc_origin 36.272778 loss_ctc0 72.808174 lr 0.00063189 rank 0
2022-08-25 22:09:39,306 DEBUG TRAIN Batch 176/800 loss 22.456326 loss_att 9.915546 loss_ctc 51.718140 loss_ctc_origin 37.667171 loss_ctc0 84.503723 lr 0.00063186 rank 0
2022-08-25 22:10:08,296 DEBUG TRAIN Batch 176/900 loss 21.827047 loss_att 9.376526 loss_ctc 50.878262 loss_ctc_origin 31.483105 loss_ctc0 96.133621 lr 0.00063183 rank 0
2022-08-25 22:10:37,645 DEBUG TRAIN Batch 176/1000 loss 53.368759 loss_att 35.628738 loss_ctc 94.762146 loss_ctc_origin 68.704376 loss_ctc0 155.563599 lr 0.00063180 rank 0
2022-08-25 22:11:05,613 DEBUG TRAIN Batch 176/1100 loss 57.203629 loss_att 35.850479 loss_ctc 107.027641 loss_ctc_origin 59.821007 loss_ctc0 217.176453 lr 0.00063176 rank 0
2022-08-25 22:11:34,892 DEBUG TRAIN Batch 176/1200 loss 16.144323 loss_att 8.227308 loss_ctc 34.617355 loss_ctc_origin 21.086601 loss_ctc0 66.189117 lr 0.00063173 rank 0
2022-08-25 22:11:54,273 WARNING NaN or Inf found in input tensor.
2022-08-25 22:12:03,660 DEBUG TRAIN Batch 176/1300 loss 20.421896 loss_att 7.537754 loss_ctc 50.484894 loss_ctc_origin 37.030495 loss_ctc0 81.878494 lr 0.00063170 rank 0
2022-08-25 22:12:33,265 DEBUG TRAIN Batch 176/1400 loss 23.292025 loss_att 9.312828 loss_ctc 55.910149 loss_ctc_origin 40.518391 loss_ctc0 91.824249 lr 0.00063167 rank 0
2022-08-25 22:13:07,470 DEBUG TRAIN Batch 176/1500 loss 49.605247 loss_att 32.674908 loss_ctc 89.109367 loss_ctc_origin 60.249508 loss_ctc0 156.449036 lr 0.00063164 rank 0
2022-08-25 22:13:36,276 DEBUG TRAIN Batch 176/1600 loss 47.484932 loss_att 26.992287 loss_ctc 95.301102 loss_ctc_origin 49.772079 loss_ctc0 201.535477 lr 0.00063161 rank 0
2022-08-25 22:14:04,851 DEBUG TRAIN Batch 176/1700 loss 17.565310 loss_att 9.792215 loss_ctc 35.702526 loss_ctc_origin 23.083706 loss_ctc0 65.146439 lr 0.00063157 rank 0
2022-08-25 22:14:34,050 DEBUG TRAIN Batch 176/1800 loss 20.995729 loss_att 8.931067 loss_ctc 49.146606 loss_ctc_origin 34.707092 loss_ctc0 82.838806 lr 0.00063154 rank 0
2022-08-25 22:15:02,072 DEBUG TRAIN Batch 176/1900 loss 23.883591 loss_att 9.908008 loss_ctc 56.493279 loss_ctc_origin 38.171207 loss_ctc0 99.244781 lr 0.00063151 rank 0
2022-08-25 22:15:31,078 DEBUG TRAIN Batch 176/2000 loss 41.020439 loss_att 27.487600 loss_ctc 72.597061 loss_ctc_origin 46.361683 loss_ctc0 133.812927 lr 0.00063148 rank 0
2022-08-25 22:15:58,745 DEBUG TRAIN Batch 176/2100 loss 47.147564 loss_att 25.537081 loss_ctc 97.572021 loss_ctc_origin 54.212173 loss_ctc0 198.744995 lr 0.00063145 rank 0
2022-08-25 22:16:25,309 WARNING NaN or Inf found in input tensor.
2022-08-25 22:16:26,992 DEBUG TRAIN Batch 176/2200 loss 20.858175 loss_att 11.529009 loss_ctc 42.626228 loss_ctc_origin 33.477455 loss_ctc0 63.973366 lr 0.00063142 rank 0
2022-08-25 22:16:32,473 WARNING NaN or Inf found in input tensor.
2022-08-25 22:16:55,243 DEBUG TRAIN Batch 176/2300 loss 18.651390 loss_att 8.124087 loss_ctc 43.215092 loss_ctc_origin 28.461777 loss_ctc0 77.639496 lr 0.00063139 rank 0
2022-08-25 22:17:12,977 WARNING NaN or Inf found in input tensor.
2022-08-25 22:17:24,706 DEBUG TRAIN Batch 176/2400 loss 24.108252 loss_att 10.661737 loss_ctc 55.483444 loss_ctc_origin 38.670944 loss_ctc0 94.712608 lr 0.00063135 rank 0
2022-08-25 22:17:53,669 DEBUG TRAIN Batch 176/2500 loss 45.054268 loss_att 30.095839 loss_ctc 79.957260 loss_ctc_origin 51.157066 loss_ctc0 147.157715 lr 0.00063132 rank 0
2022-08-25 22:18:22,208 DEBUG TRAIN Batch 176/2600 loss 55.174446 loss_att 30.898094 loss_ctc 111.819260 loss_ctc_origin 67.884323 loss_ctc0 214.334106 lr 0.00063129 rank 0
2022-08-25 22:18:50,134 DEBUG TRAIN Batch 176/2700 loss 19.593693 loss_att 9.400073 loss_ctc 43.378807 loss_ctc_origin 32.811775 loss_ctc0 68.035210 lr 0.00063126 rank 0
2022-08-25 22:19:19,136 DEBUG TRAIN Batch 176/2800 loss 21.818512 loss_att 8.350395 loss_ctc 53.244118 loss_ctc_origin 38.317177 loss_ctc0 88.073639 lr 0.00063123 rank 0
2022-08-25 22:19:47,447 DEBUG TRAIN Batch 176/2900 loss 21.094810 loss_att 9.198912 loss_ctc 48.851906 loss_ctc_origin 31.895481 loss_ctc0 88.416901 lr 0.00063120 rank 0
2022-08-25 22:19:56,817 WARNING NaN or Inf found in input tensor.
2022-08-25 22:20:22,973 DEBUG TRAIN Batch 176/3000 loss 50.756805 loss_att 35.541653 loss_ctc 86.258827 loss_ctc_origin 57.322159 loss_ctc0 153.777710 lr 0.00063117 rank 0
2022-08-25 22:20:52,082 DEBUG TRAIN Batch 176/3100 loss 54.902649 loss_att 28.852777 loss_ctc 115.685669 loss_ctc_origin 62.832745 loss_ctc0 239.009155 lr 0.00063113 rank 0
2022-08-25 22:21:20,349 DEBUG TRAIN Batch 176/3200 loss 16.490171 loss_att 8.864906 loss_ctc 34.282455 loss_ctc_origin 22.920937 loss_ctc0 60.792664 lr 0.00063110 rank 0
2022-08-25 22:21:49,358 DEBUG TRAIN Batch 176/3300 loss 20.981686 loss_att 8.658792 loss_ctc 49.735104 loss_ctc_origin 37.639061 loss_ctc0 77.959206 lr 0.00063107 rank 0
2022-08-25 22:22:18,238 DEBUG TRAIN Batch 176/3400 loss 20.679081 loss_att 8.334562 loss_ctc 49.482956 loss_ctc_origin 31.589897 loss_ctc0 91.233429 lr 0.00063104 rank 0
2022-08-25 22:22:47,611 DEBUG TRAIN Batch 176/3500 loss 50.666443 loss_att 34.004269 loss_ctc 89.544846 loss_ctc_origin 54.212379 loss_ctc0 171.987274 lr 0.00063101 rank 0
2022-08-25 22:23:15,231 DEBUG TRAIN Batch 176/3600 loss 49.175751 loss_att 27.438755 loss_ctc 99.895409 loss_ctc_origin 50.836815 loss_ctc0 214.365448 lr 0.00063098 rank 0
2022-08-25 22:23:43,627 DEBUG TRAIN Batch 176/3700 loss 20.240978 loss_att 11.014534 loss_ctc 41.769348 loss_ctc_origin 31.507431 loss_ctc0 65.713821 lr 0.00063095 rank 0
2022-08-25 22:24:12,746 DEBUG TRAIN Batch 176/3800 loss 19.598324 loss_att 8.533175 loss_ctc 45.417004 loss_ctc_origin 28.700699 loss_ctc0 84.421715 lr 0.00063091 rank 0
2022-08-25 22:24:42,051 DEBUG TRAIN Batch 176/3900 loss 22.891161 loss_att 9.454826 loss_ctc 54.242611 loss_ctc_origin 35.664848 loss_ctc0 97.590721 lr 0.00063088 rank 0
2022-08-25 22:24:56,760 WARNING NaN or Inf found in input tensor.
2022-08-25 22:25:10,304 DEBUG TRAIN Batch 176/4000 loss 43.374588 loss_att 27.601685 loss_ctc 80.178024 loss_ctc_origin 51.482681 loss_ctc0 147.133820 lr 0.00063085 rank 0
2022-08-25 22:25:39,330 DEBUG TRAIN Batch 176/4100 loss 54.360184 loss_att 28.567066 loss_ctc 114.544128 loss_ctc_origin 70.503693 loss_ctc0 217.305145 lr 0.00063082 rank 0
2022-08-25 22:26:08,273 DEBUG TRAIN Batch 176/4200 loss 20.222290 loss_att 11.276531 loss_ctc 41.095730 loss_ctc_origin 31.138741 loss_ctc0 64.328705 lr 0.00063079 rank 0
2022-08-25 22:26:37,430 DEBUG TRAIN Batch 176/4300 loss 20.481415 loss_att 8.529282 loss_ctc 48.369724 loss_ctc_origin 35.021935 loss_ctc0 79.514565 lr 0.00063076 rank 0
2022-08-25 22:27:05,904 DEBUG TRAIN Batch 176/4400 loss 23.377686 loss_att 10.432833 loss_ctc 53.582344 loss_ctc_origin 35.183052 loss_ctc0 96.514023 lr 0.00063073 rank 0
2022-08-25 22:27:13,910 WARNING NaN or Inf found in input tensor.
2022-08-25 22:27:39,095 DEBUG TRAIN Batch 176/4500 loss 43.264824 loss_att 28.028061 loss_ctc 78.817261 loss_ctc_origin 49.749142 loss_ctc0 146.642883 lr 0.00063069 rank 0
2022-08-25 22:28:08,121 DEBUG TRAIN Batch 176/4600 loss 51.597763 loss_att 28.970442 loss_ctc 104.394844 loss_ctc_origin 59.993027 loss_ctc0 207.999084 lr 0.00063066 rank 0
2022-08-25 22:28:37,079 DEBUG TRAIN Batch 176/4700 loss 22.183266 loss_att 10.914352 loss_ctc 48.477394 loss_ctc_origin 37.244251 loss_ctc0 74.688065 lr 0.00063063 rank 0
2022-08-25 22:28:42,521 WARNING NaN or Inf found in input tensor.
2022-08-25 22:29:05,005 DEBUG TRAIN Batch 176/4800 loss 21.020596 loss_att 8.033674 loss_ctc 51.323410 loss_ctc_origin 36.619785 loss_ctc0 85.631866 lr 0.00063060 rank 0
2022-08-25 22:29:34,675 DEBUG TRAIN Batch 176/4900 loss 23.417614 loss_att 10.936814 loss_ctc 52.539478 loss_ctc_origin 35.493622 loss_ctc0 92.313141 lr 0.00063057 rank 0
2022-08-25 22:29:37,393 WARNING NaN or Inf found in input tensor.
2022-08-25 22:30:03,679 DEBUG TRAIN Batch 176/5000 loss 35.020866 loss_att 22.819901 loss_ctc 63.489777 loss_ctc_origin 38.752460 loss_ctc0 121.210175 lr 0.00063054 rank 0
2022-08-25 22:30:11,524 WARNING NaN or Inf found in input tensor.
2022-08-25 22:30:32,455 DEBUG TRAIN Batch 176/5100 loss 49.068592 loss_att 27.887888 loss_ctc 98.490234 loss_ctc_origin 51.734940 loss_ctc0 207.585907 lr 0.00063051 rank 0
2022-08-25 22:31:01,764 DEBUG TRAIN Batch 176/5200 loss 19.574978 loss_att 10.772253 loss_ctc 40.114670 loss_ctc_origin 28.777073 loss_ctc0 66.569061 lr 0.00063048 rank 0
2022-08-25 22:31:30,258 DEBUG TRAIN Batch 176/5300 loss 20.424667 loss_att 9.135411 loss_ctc 46.766262 loss_ctc_origin 31.220558 loss_ctc0 83.039566 lr 0.00063044 rank 0
2022-08-25 22:31:59,884 DEBUG TRAIN Batch 176/5400 loss 20.631001 loss_att 7.916503 loss_ctc 50.298161 loss_ctc_origin 29.838966 loss_ctc0 98.036278 lr 0.00063041 rank 0
2022-08-25 22:32:27,960 DEBUG TRAIN Batch 176/5500 loss 41.324074 loss_att 26.868370 loss_ctc 75.054047 loss_ctc_origin 50.157333 loss_ctc0 133.146378 lr 0.00063038 rank 0
2022-08-25 22:32:48,781 WARNING NaN or Inf found in input tensor.
2022-08-25 22:32:56,060 DEBUG TRAIN Batch 176/5600 loss 54.484543 loss_att 30.091553 loss_ctc 111.401520 loss_ctc_origin 59.592384 loss_ctc0 232.289505 lr 0.00063035 rank 0
2022-08-25 22:33:18,796 DEBUG CV Batch 176/0 loss 12.905783 loss_att 9.559776 loss_ctc 20.713129 loss_ctc_origin 14.437624 loss_ctc0 35.355972 history loss 12.146619 rank 0
2022-08-25 22:33:29,988 DEBUG CV Batch 176/100 loss 19.674173 loss_att 15.661764 loss_ctc 29.036461 loss_ctc_origin 18.356918 loss_ctc0 53.955391 history loss 26.312840 rank 0
2022-08-25 22:33:39,658 DEBUG CV Batch 176/200 loss 25.120670 loss_att 19.419701 loss_ctc 38.422935 loss_ctc_origin 27.965218 loss_ctc0 62.824287 history loss 27.733239 rank 0
2022-08-25 22:33:49,859 DEBUG CV Batch 176/300 loss 23.063801 loss_att 17.705059 loss_ctc 35.567528 loss_ctc_origin 19.777081 loss_ctc0 72.411911 history loss 26.917692 rank 0
2022-08-25 22:34:00,903 DEBUG CV Batch 176/400 loss 38.090691 loss_att 30.869125 loss_ctc 54.941010 loss_ctc_origin 37.625626 loss_ctc0 95.343575 history loss 25.280856 rank 0
2022-08-25 22:34:11,918 DEBUG CV Batch 176/500 loss 15.889355 loss_att 11.811237 loss_ctc 25.404961 loss_ctc_origin 17.905516 loss_ctc0 42.903667 history loss 24.928711 rank 0
2022-08-25 22:34:22,746 DEBUG CV Batch 176/600 loss 16.828739 loss_att 11.779918 loss_ctc 28.609325 loss_ctc_origin 17.368587 loss_ctc0 54.837715 history loss 24.748827 rank 0
2022-08-25 22:34:33,104 DEBUG CV Batch 176/700 loss 19.618828 loss_att 13.789537 loss_ctc 33.220505 loss_ctc_origin 20.100340 loss_ctc0 63.834217 history loss 24.423144 rank 0
2022-08-25 22:34:43,574 DEBUG CV Batch 176/800 loss 21.655972 loss_att 16.813194 loss_ctc 32.955784 loss_ctc_origin 17.669453 loss_ctc0 68.623886 history loss 24.370827 rank 0
2022-08-25 22:34:54,150 INFO Epoch 176 CV info cv_loss 24.447952165069122
2022-08-25 22:34:54,151 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/176.pt
2022-08-25 22:34:54,632 INFO Epoch 177 TRAIN info lr 0.0006303236010670921
2022-08-25 22:34:54,636 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 22:35:21,837 DEBUG TRAIN Batch 177/0 loss 38.272614 loss_att 23.562578 loss_ctc 72.596031 loss_ctc_origin 44.393208 loss_ctc0 138.402618 lr 0.00063032 rank 0
2022-08-25 22:35:50,618 DEBUG TRAIN Batch 177/100 loss 54.263741 loss_att 32.667007 loss_ctc 104.656113 loss_ctc_origin 65.059143 loss_ctc0 197.049042 lr 0.00063029 rank 0
2022-08-25 22:36:18,102 WARNING NaN or Inf found in input tensor.
2022-08-25 22:36:19,640 DEBUG TRAIN Batch 177/200 loss 18.746843 loss_att 9.682691 loss_ctc 39.896530 loss_ctc_origin 27.907177 loss_ctc0 67.871696 lr 0.00063026 rank 0
2022-08-25 22:36:47,054 DEBUG TRAIN Batch 177/300 loss 14.376789 loss_att 5.449606 loss_ctc 35.206882 loss_ctc_origin 20.968208 loss_ctc0 68.430450 lr 0.00063023 rank 0
2022-08-25 22:37:11,410 WARNING NaN or Inf found in input tensor.
2022-08-25 22:37:15,643 DEBUG TRAIN Batch 177/400 loss 26.840046 loss_att 11.751276 loss_ctc 62.047176 loss_ctc_origin 44.277958 loss_ctc0 103.508682 lr 0.00063020 rank 0
2022-08-25 22:37:44,918 DEBUG TRAIN Batch 177/500 loss 44.973499 loss_att 30.341991 loss_ctc 79.113686 loss_ctc_origin 57.668999 loss_ctc0 129.151291 lr 0.00063017 rank 0
2022-08-25 22:38:13,746 DEBUG TRAIN Batch 177/600 loss 56.875595 loss_att 34.307388 loss_ctc 109.534744 loss_ctc_origin 67.563660 loss_ctc0 207.467285 lr 0.00063013 rank 0
2022-08-25 22:38:41,814 DEBUG TRAIN Batch 177/700 loss 20.955227 loss_att 11.162933 loss_ctc 43.803909 loss_ctc_origin 32.765022 loss_ctc0 69.561310 lr 0.00063010 rank 0
2022-08-25 22:39:10,645 DEBUG TRAIN Batch 177/800 loss 18.607811 loss_att 7.155701 loss_ctc 45.329399 loss_ctc_origin 30.182434 loss_ctc0 80.672325 lr 0.00063007 rank 0
2022-08-25 22:39:40,556 DEBUG TRAIN Batch 177/900 loss 22.041365 loss_att 9.208481 loss_ctc 51.984756 loss_ctc_origin 34.928299 loss_ctc0 91.783165 lr 0.00063004 rank 0
2022-08-25 22:40:10,100 DEBUG TRAIN Batch 177/1000 loss 41.922279 loss_att 29.482311 loss_ctc 70.948868 loss_ctc_origin 46.499454 loss_ctc0 127.997482 lr 0.00063001 rank 0
2022-08-25 22:40:25,225 WARNING NaN or Inf found in input tensor.
2022-08-25 22:40:39,139 DEBUG TRAIN Batch 177/1100 loss 44.799896 loss_att 22.949301 loss_ctc 95.784622 loss_ctc_origin 51.192711 loss_ctc0 199.832413 lr 0.00062998 rank 0
2022-08-25 22:41:08,286 DEBUG TRAIN Batch 177/1200 loss 17.785721 loss_att 8.690592 loss_ctc 39.007687 loss_ctc_origin 27.250509 loss_ctc0 66.441101 lr 0.00062995 rank 0
2022-08-25 22:41:37,725 DEBUG TRAIN Batch 177/1300 loss 17.640270 loss_att 6.965514 loss_ctc 42.548035 loss_ctc_origin 27.874924 loss_ctc0 76.785294 lr 0.00062992 rank 0
2022-08-25 22:42:06,802 DEBUG TRAIN Batch 177/1400 loss 22.500566 loss_att 9.850849 loss_ctc 52.016571 loss_ctc_origin 34.011139 loss_ctc0 94.029251 lr 0.00062988 rank 0
2022-08-25 22:42:42,592 DEBUG TRAIN Batch 177/1500 loss 46.426086 loss_att 31.144093 loss_ctc 82.084076 loss_ctc_origin 51.805485 loss_ctc0 152.734100 lr 0.00062985 rank 0
2022-08-25 22:43:12,302 DEBUG TRAIN Batch 177/1600 loss 48.659447 loss_att 26.467585 loss_ctc 100.440460 loss_ctc_origin 56.713497 loss_ctc0 202.470047 lr 0.00062982 rank 0
2022-08-25 22:43:41,439 DEBUG TRAIN Batch 177/1700 loss 19.656815 loss_att 10.271480 loss_ctc 41.555927 loss_ctc_origin 29.343609 loss_ctc0 70.051338 lr 0.00062979 rank 0
2022-08-25 22:43:46,938 WARNING NaN or Inf found in input tensor.
2022-08-25 22:44:09,864 DEBUG TRAIN Batch 177/1800 loss 17.378685 loss_att 7.859838 loss_ctc 39.589325 loss_ctc_origin 24.816534 loss_ctc0 74.059158 lr 0.00062976 rank 0
2022-08-25 22:44:38,065 DEBUG TRAIN Batch 177/1900 loss 21.740280 loss_att 9.265991 loss_ctc 50.846954 loss_ctc_origin 34.422340 loss_ctc0 89.171051 lr 0.00062973 rank 0
2022-08-25 22:45:00,854 WARNING NaN or Inf found in input tensor.
2022-08-25 22:45:07,035 DEBUG TRAIN Batch 177/2000 loss 45.270767 loss_att 29.040993 loss_ctc 83.140244 loss_ctc_origin 52.517628 loss_ctc0 154.593002 lr 0.00062970 rank 0
2022-08-25 22:45:07,698 WARNING NaN or Inf found in input tensor.
2022-08-25 22:45:29,112 WARNING NaN or Inf found in input tensor.
2022-08-25 22:45:36,233 DEBUG TRAIN Batch 177/2100 loss 51.588596 loss_att 31.421392 loss_ctc 98.645401 loss_ctc_origin 54.225990 loss_ctc0 202.290680 lr 0.00062967 rank 0
2022-08-25 22:46:04,672 DEBUG TRAIN Batch 177/2200 loss 19.040720 loss_att 9.827244 loss_ctc 40.538830 loss_ctc_origin 30.215778 loss_ctc0 64.625946 lr 0.00062963 rank 0
2022-08-25 22:46:33,606 DEBUG TRAIN Batch 177/2300 loss 18.761341 loss_att 8.225482 loss_ctc 43.345009 loss_ctc_origin 28.754988 loss_ctc0 77.388390 lr 0.00062960 rank 0
2022-08-25 22:47:03,364 DEBUG TRAIN Batch 177/2400 loss 23.339638 loss_att 9.324195 loss_ctc 56.042336 loss_ctc_origin 35.682823 loss_ctc0 103.547867 lr 0.00062957 rank 0
2022-08-25 22:47:32,699 DEBUG TRAIN Batch 177/2500 loss 39.716118 loss_att 24.644634 loss_ctc 74.882919 loss_ctc_origin 45.177376 loss_ctc0 144.195862 lr 0.00062954 rank 0
2022-08-25 22:48:01,679 DEBUG TRAIN Batch 177/2600 loss 52.686646 loss_att 29.115913 loss_ctc 107.685005 loss_ctc_origin 64.475914 loss_ctc0 208.506210 lr 0.00062951 rank 0
2022-08-25 22:48:30,185 DEBUG TRAIN Batch 177/2700 loss 21.816080 loss_att 10.427984 loss_ctc 48.388302 loss_ctc_origin 39.453152 loss_ctc0 69.236984 lr 0.00062948 rank 0
2022-08-25 22:48:59,660 DEBUG TRAIN Batch 177/2800 loss 21.992348 loss_att 9.541541 loss_ctc 51.044228 loss_ctc_origin 35.485809 loss_ctc0 87.347198 lr 0.00062945 rank 0
2022-08-25 22:49:26,816 DEBUG TRAIN Batch 177/2900 loss 20.152149 loss_att 8.120123 loss_ctc 48.226875 loss_ctc_origin 30.048145 loss_ctc0 90.643906 lr 0.00062942 rank 0
2022-08-25 22:50:03,605 DEBUG TRAIN Batch 177/3000 loss 44.906040 loss_att 31.115108 loss_ctc 77.084885 loss_ctc_origin 48.774605 loss_ctc0 143.142181 lr 0.00062939 rank 0
2022-08-25 22:50:32,468 DEBUG TRAIN Batch 177/3100 loss 46.646374 loss_att 25.834709 loss_ctc 95.206924 loss_ctc_origin 50.760338 loss_ctc0 198.915619 lr 0.00062935 rank 0
2022-08-25 22:51:01,178 DEBUG TRAIN Batch 177/3200 loss 21.210175 loss_att 11.980129 loss_ctc 42.746948 loss_ctc_origin 31.863916 loss_ctc0 68.140686 lr 0.00062932 rank 0
2022-08-25 22:51:30,107 DEBUG TRAIN Batch 177/3300 loss 16.546856 loss_att 6.221452 loss_ctc 40.639458 loss_ctc_origin 24.608665 loss_ctc0 78.044632 lr 0.00062929 rank 0
2022-08-25 22:51:59,191 DEBUG TRAIN Batch 177/3400 loss 22.499804 loss_att 9.131179 loss_ctc 53.693260 loss_ctc_origin 34.729031 loss_ctc0 97.943123 lr 0.00062926 rank 0
2022-08-25 22:52:29,309 DEBUG TRAIN Batch 177/3500 loss 43.640083 loss_att 28.992222 loss_ctc 77.818428 loss_ctc_origin 48.798492 loss_ctc0 145.531616 lr 0.00062923 rank 0
2022-08-25 22:52:30,102 WARNING NaN or Inf found in input tensor.
2022-08-25 22:52:57,744 DEBUG TRAIN Batch 177/3600 loss 46.810722 loss_att 27.561722 loss_ctc 91.725060 loss_ctc_origin 55.249535 loss_ctc0 176.834610 lr 0.00062920 rank 0
2022-08-25 22:53:26,730 DEBUG TRAIN Batch 177/3700 loss 20.389177 loss_att 9.970982 loss_ctc 44.698296 loss_ctc_origin 31.607840 loss_ctc0 75.242691 lr 0.00062917 rank 0
2022-08-25 22:53:55,580 DEBUG TRAIN Batch 177/3800 loss 17.814537 loss_att 6.588385 loss_ctc 44.008888 loss_ctc_origin 28.686417 loss_ctc0 79.761322 lr 0.00062914 rank 0
2022-08-25 22:54:24,213 DEBUG TRAIN Batch 177/3900 loss 22.803280 loss_att 9.425407 loss_ctc 54.018318 loss_ctc_origin 37.003685 loss_ctc0 93.719131 lr 0.00062911 rank 0
2022-08-25 22:54:52,876 DEBUG TRAIN Batch 177/4000 loss 49.732948 loss_att 32.181259 loss_ctc 90.686890 loss_ctc_origin 55.569016 loss_ctc0 172.628586 lr 0.00062907 rank 0
2022-08-25 22:55:21,104 DEBUG TRAIN Batch 177/4100 loss 55.570885 loss_att 27.065388 loss_ctc 122.083710 loss_ctc_origin 61.419838 loss_ctc0 263.632751 lr 0.00062904 rank 0
2022-08-25 22:55:52,352 DEBUG TRAIN Batch 177/4200 loss 16.081348 loss_att 7.723400 loss_ctc 35.583229 loss_ctc_origin 24.958239 loss_ctc0 60.374882 lr 0.00062901 rank 0
2022-08-25 22:56:02,818 WARNING NaN or Inf found in input tensor.
2022-08-25 22:56:19,760 DEBUG TRAIN Batch 177/4300 loss 19.982105 loss_att 9.039032 loss_ctc 45.515938 loss_ctc_origin 31.349688 loss_ctc0 78.570526 lr 0.00062898 rank 0
2022-08-25 22:56:48,580 DEBUG TRAIN Batch 177/4400 loss 19.896633 loss_att 7.909457 loss_ctc 47.866707 loss_ctc_origin 30.695246 loss_ctc0 87.933456 lr 0.00062895 rank 0
2022-08-25 22:57:22,986 DEBUG TRAIN Batch 177/4500 loss 51.228943 loss_att 34.235336 loss_ctc 90.880692 loss_ctc_origin 56.117329 loss_ctc0 171.995178 lr 0.00062892 rank 0
2022-08-25 22:57:51,637 DEBUG TRAIN Batch 177/4600 loss 59.419121 loss_att 35.809509 loss_ctc 114.508209 loss_ctc_origin 64.702232 loss_ctc0 230.722168 lr 0.00062889 rank 0
2022-08-25 22:58:19,535 DEBUG TRAIN Batch 177/4700 loss 23.723890 loss_att 13.469010 loss_ctc 47.651939 loss_ctc_origin 37.869801 loss_ctc0 70.476921 lr 0.00062886 rank 0
2022-08-25 22:58:24,968 WARNING NaN or Inf found in input tensor.
2022-08-25 22:58:48,561 DEBUG TRAIN Batch 177/4800 loss 19.450397 loss_att 8.888920 loss_ctc 44.093845 loss_ctc_origin 30.891701 loss_ctc0 74.898849 lr 0.00062883 rank 0
2022-08-25 22:59:17,384 DEBUG TRAIN Batch 177/4900 loss 23.611622 loss_att 10.361759 loss_ctc 54.527969 loss_ctc_origin 36.612167 loss_ctc0 96.331497 lr 0.00062879 rank 0
2022-08-25 22:59:46,491 DEBUG TRAIN Batch 177/5000 loss 51.637745 loss_att 35.756977 loss_ctc 88.692863 loss_ctc_origin 56.878731 loss_ctc0 162.925842 lr 0.00062876 rank 0
2022-08-25 23:00:14,977 DEBUG TRAIN Batch 177/5100 loss 59.767876 loss_att 31.987347 loss_ctc 124.589111 loss_ctc_origin 74.468193 loss_ctc0 241.537903 lr 0.00062873 rank 0
2022-08-25 23:00:42,233 WARNING NaN or Inf found in input tensor.
2022-08-25 23:00:43,851 DEBUG TRAIN Batch 177/5200 loss 19.716295 loss_att 10.688379 loss_ctc 40.781433 loss_ctc_origin 29.319714 loss_ctc0 67.525436 lr 0.00062870 rank 0
2022-08-25 23:01:12,494 DEBUG TRAIN Batch 177/5300 loss 21.878035 loss_att 9.188383 loss_ctc 51.487221 loss_ctc_origin 37.656487 loss_ctc0 83.758934 lr 0.00062867 rank 0
2022-08-25 23:01:41,905 DEBUG TRAIN Batch 177/5400 loss 21.727173 loss_att 8.881737 loss_ctc 51.699852 loss_ctc_origin 33.918636 loss_ctc0 93.189354 lr 0.00062864 rank 0
2022-08-25 23:02:10,638 DEBUG TRAIN Batch 177/5500 loss 50.491119 loss_att 31.918743 loss_ctc 93.826660 loss_ctc_origin 59.899055 loss_ctc0 172.991089 lr 0.00062861 rank 0
2022-08-25 23:02:39,267 DEBUG TRAIN Batch 177/5600 loss 60.063774 loss_att 33.188148 loss_ctc 122.773560 loss_ctc_origin 67.798019 loss_ctc0 251.049820 lr 0.00062858 rank 0
2022-08-25 23:03:02,193 DEBUG CV Batch 177/0 loss 12.845081 loss_att 9.473150 loss_ctc 20.712919 loss_ctc_origin 15.057037 loss_ctc0 33.909977 history loss 12.089488 rank 0
2022-08-25 23:03:13,153 DEBUG CV Batch 177/100 loss 20.886143 loss_att 16.662731 loss_ctc 30.740772 loss_ctc_origin 21.141039 loss_ctc0 53.140152 history loss 26.846328 rank 0
2022-08-25 23:03:23,071 DEBUG CV Batch 177/200 loss 25.334549 loss_att 19.432497 loss_ctc 39.105999 loss_ctc_origin 28.939678 loss_ctc0 62.827415 history loss 28.137670 rank 0
2022-08-25 23:03:33,477 DEBUG CV Batch 177/300 loss 23.684555 loss_att 17.874653 loss_ctc 37.240993 loss_ctc_origin 22.128857 loss_ctc0 72.502647 history loss 27.202939 rank 0
2022-08-25 23:03:44,533 DEBUG CV Batch 177/400 loss 38.068642 loss_att 31.171314 loss_ctc 54.162399 loss_ctc_origin 36.957966 loss_ctc0 94.306068 history loss 25.536823 rank 0
2022-08-25 23:03:55,556 DEBUG CV Batch 177/500 loss 16.960772 loss_att 12.997844 loss_ctc 26.207603 loss_ctc_origin 19.501495 loss_ctc0 41.855183 history loss 25.158642 rank 0
2022-08-25 23:04:06,394 DEBUG CV Batch 177/600 loss 17.754662 loss_att 12.762192 loss_ctc 29.403761 loss_ctc_origin 18.827394 loss_ctc0 54.081944 history loss 25.002709 rank 0
2022-08-25 23:04:16,561 DEBUG CV Batch 177/700 loss 18.340683 loss_att 12.675968 loss_ctc 31.558353 loss_ctc_origin 18.209766 loss_ctc0 62.705055 history loss 24.677120 rank 0
2022-08-25 23:04:27,302 DEBUG CV Batch 177/800 loss 21.681343 loss_att 16.763542 loss_ctc 33.156212 loss_ctc_origin 17.911745 loss_ctc0 68.726639 history loss 24.617166 rank 0
2022-08-25 23:04:37,539 INFO Epoch 177 CV info cv_loss 24.71047361342882
2022-08-25 23:04:37,539 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/177.pt
2022-08-25 23:04:37,976 INFO Epoch 178 TRAIN info lr 0.0006285505353857775
2022-08-25 23:04:37,979 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 23:05:05,266 DEBUG TRAIN Batch 178/0 loss 53.401691 loss_att 37.426544 loss_ctc 90.677032 loss_ctc_origin 62.033539 loss_ctc0 157.511841 lr 0.00062855 rank 0
2022-08-25 23:05:20,133 WARNING NaN or Inf found in input tensor.
2022-08-25 23:05:34,256 DEBUG TRAIN Batch 178/100 loss 60.430878 loss_att 34.166962 loss_ctc 121.713348 loss_ctc_origin 71.305710 loss_ctc0 239.331177 lr 0.00062852 rank 0
2022-08-25 23:06:02,061 WARNING NaN or Inf found in input tensor.
2022-08-25 23:06:03,688 DEBUG TRAIN Batch 178/200 loss 19.139975 loss_att 9.058496 loss_ctc 42.663422 loss_ctc_origin 30.402767 loss_ctc0 71.271606 lr 0.00062849 rank 0
2022-08-25 23:06:32,307 DEBUG TRAIN Batch 178/300 loss 17.038431 loss_att 7.449083 loss_ctc 39.413574 loss_ctc_origin 22.658092 loss_ctc0 78.509705 lr 0.00062846 rank 0
2022-08-25 23:07:02,679 DEBUG TRAIN Batch 178/400 loss 21.480436 loss_att 8.609940 loss_ctc 51.511593 loss_ctc_origin 36.141682 loss_ctc0 87.374718 lr 0.00062843 rank 0
2022-08-25 23:07:31,731 DEBUG TRAIN Batch 178/500 loss 49.149727 loss_att 31.628925 loss_ctc 90.031593 loss_ctc_origin 60.055119 loss_ctc0 159.976700 lr 0.00062839 rank 0
2022-08-25 23:07:39,668 WARNING NaN or Inf found in input tensor.
2022-08-25 23:08:00,412 DEBUG TRAIN Batch 178/600 loss 64.215256 loss_att 37.736374 loss_ctc 125.999313 loss_ctc_origin 69.486519 loss_ctc0 257.862488 lr 0.00062836 rank 0
2022-08-25 23:08:28,832 DEBUG TRAIN Batch 178/700 loss 16.079081 loss_att 7.656821 loss_ctc 35.731018 loss_ctc_origin 23.629326 loss_ctc0 63.968300 lr 0.00062833 rank 0
2022-08-25 23:08:57,302 DEBUG TRAIN Batch 178/800 loss 22.284595 loss_att 9.604525 loss_ctc 51.871429 loss_ctc_origin 36.346062 loss_ctc0 88.097282 lr 0.00062830 rank 0
2022-08-25 23:09:25,867 DEBUG TRAIN Batch 178/900 loss 28.243965 loss_att 12.789279 loss_ctc 64.304893 loss_ctc_origin 47.403519 loss_ctc0 103.741447 lr 0.00062827 rank 0
2022-08-25 23:09:54,890 DEBUG TRAIN Batch 178/1000 loss 45.994080 loss_att 30.878094 loss_ctc 81.264709 loss_ctc_origin 48.983742 loss_ctc0 156.586945 lr 0.00062824 rank 0
2022-08-25 23:10:22,833 DEBUG TRAIN Batch 178/1100 loss 52.689850 loss_att 28.109535 loss_ctc 110.043915 loss_ctc_origin 60.747955 loss_ctc0 225.067825 lr 0.00062821 rank 0
2022-08-25 23:10:50,304 WARNING NaN or Inf found in input tensor.
2022-08-25 23:10:51,845 DEBUG TRAIN Batch 178/1200 loss 16.220943 loss_att 8.416080 loss_ctc 34.432293 loss_ctc_origin 22.441940 loss_ctc0 62.409779 lr 0.00062818 rank 0
2022-08-25 23:11:21,162 DEBUG TRAIN Batch 178/1300 loss 17.809996 loss_att 6.194237 loss_ctc 44.913429 loss_ctc_origin 28.451683 loss_ctc0 83.324173 lr 0.00062815 rank 0
2022-08-25 23:11:49,902 DEBUG TRAIN Batch 178/1400 loss 23.007505 loss_att 10.557898 loss_ctc 52.056587 loss_ctc_origin 32.888088 loss_ctc0 96.783081 lr 0.00062812 rank 0
2022-08-25 23:11:59,669 WARNING NaN or Inf found in input tensor.
2022-08-25 23:12:25,556 DEBUG TRAIN Batch 178/1500 loss 46.440399 loss_att 31.715000 loss_ctc 80.799652 loss_ctc_origin 50.943352 loss_ctc0 150.464355 lr 0.00062808 rank 0
2022-08-25 23:12:53,814 WARNING NaN or Inf found in input tensor.
2022-08-25 23:12:54,581 DEBUG TRAIN Batch 178/1600 loss 50.050713 loss_att 28.674688 loss_ctc 99.928093 loss_ctc_origin 53.096588 loss_ctc0 209.201599 lr 0.00062805 rank 0
2022-08-25 23:13:23,082 DEBUG TRAIN Batch 178/1700 loss 21.397640 loss_att 12.812967 loss_ctc 41.428543 loss_ctc_origin 30.615685 loss_ctc0 66.658539 lr 0.00062802 rank 0
2022-08-25 23:13:51,707 DEBUG TRAIN Batch 178/1800 loss 19.301582 loss_att 7.846663 loss_ctc 46.029724 loss_ctc_origin 30.363064 loss_ctc0 82.585266 lr 0.00062799 rank 0
2022-08-25 23:14:21,197 DEBUG TRAIN Batch 178/1900 loss 22.512344 loss_att 8.503832 loss_ctc 55.198868 loss_ctc_origin 38.051079 loss_ctc0 95.210373 lr 0.00062796 rank 0
2022-08-25 23:14:50,686 DEBUG TRAIN Batch 178/2000 loss 50.211746 loss_att 33.640545 loss_ctc 88.877884 loss_ctc_origin 54.796448 loss_ctc0 168.401230 lr 0.00062793 rank 0
2022-08-25 23:15:20,126 DEBUG TRAIN Batch 178/2100 loss 39.826481 loss_att 21.395559 loss_ctc 82.831963 loss_ctc_origin 44.643574 loss_ctc0 171.938202 lr 0.00062790 rank 0
2022-08-25 23:15:47,875 DEBUG TRAIN Batch 178/2200 loss 19.426794 loss_att 9.669356 loss_ctc 42.194145 loss_ctc_origin 30.435642 loss_ctc0 69.630653 lr 0.00062787 rank 0
2022-08-25 23:16:15,581 DEBUG TRAIN Batch 178/2300 loss 18.033802 loss_att 6.731574 loss_ctc 44.405663 loss_ctc_origin 30.641146 loss_ctc0 76.522865 lr 0.00062784 rank 0
2022-08-25 23:16:44,305 DEBUG TRAIN Batch 178/2400 loss 20.600296 loss_att 8.135162 loss_ctc 49.685608 loss_ctc_origin 31.981026 loss_ctc0 90.996300 lr 0.00062781 rank 0
2022-08-25 23:17:12,554 DEBUG TRAIN Batch 178/2500 loss 43.295349 loss_att 30.016413 loss_ctc 74.279526 loss_ctc_origin 48.880562 loss_ctc0 133.543777 lr 0.00062777 rank 0
2022-08-25 23:17:41,206 DEBUG TRAIN Batch 178/2600 loss 52.582359 loss_att 29.812145 loss_ctc 105.712860 loss_ctc_origin 61.392303 loss_ctc0 209.127487 lr 0.00062774 rank 0
2022-08-25 23:18:10,659 DEBUG TRAIN Batch 178/2700 loss 16.922993 loss_att 9.288488 loss_ctc 34.736832 loss_ctc_origin 23.795071 loss_ctc0 60.267601 lr 0.00062771 rank 0
2022-08-25 23:18:40,084 DEBUG TRAIN Batch 178/2800 loss 19.214918 loss_att 7.758987 loss_ctc 45.945419 loss_ctc_origin 31.015265 loss_ctc0 80.782433 lr 0.00062768 rank 0
2022-08-25 23:19:07,909 DEBUG TRAIN Batch 178/2900 loss 20.793463 loss_att 7.868419 loss_ctc 50.951897 loss_ctc_origin 32.442642 loss_ctc0 94.140160 lr 0.00062765 rank 0
2022-08-25 23:19:43,776 DEBUG TRAIN Batch 178/3000 loss 47.145706 loss_att 28.135571 loss_ctc 91.502693 loss_ctc_origin 57.646194 loss_ctc0 170.501175 lr 0.00062762 rank 0
2022-08-25 23:20:12,535 DEBUG TRAIN Batch 178/3100 loss 50.709450 loss_att 27.414186 loss_ctc 105.065063 loss_ctc_origin 61.811783 loss_ctc0 205.989380 lr 0.00062759 rank 0
2022-08-25 23:20:41,664 DEBUG TRAIN Batch 178/3200 loss 18.012589 loss_att 10.419283 loss_ctc 35.730305 loss_ctc_origin 25.506002 loss_ctc0 59.587006 lr 0.00062756 rank 0
2022-08-25 23:21:11,126 DEBUG TRAIN Batch 178/3300 loss 19.111588 loss_att 6.814608 loss_ctc 47.804543 loss_ctc_origin 30.115507 loss_ctc0 89.078964 lr 0.00062753 rank 0
2022-08-25 23:21:39,737 DEBUG TRAIN Batch 178/3400 loss 19.283491 loss_att 8.742162 loss_ctc 43.879925 loss_ctc_origin 27.875916 loss_ctc0 81.222610 lr 0.00062750 rank 0
2022-08-25 23:22:08,769 DEBUG TRAIN Batch 178/3500 loss 41.852180 loss_att 27.616774 loss_ctc 75.068130 loss_ctc_origin 50.976234 loss_ctc0 131.282562 lr 0.00062747 rank 0
2022-08-25 23:22:37,475 DEBUG TRAIN Batch 178/3600 loss 55.619526 loss_att 35.737686 loss_ctc 102.010483 loss_ctc_origin 61.482239 loss_ctc0 196.576370 lr 0.00062743 rank 0
2022-08-25 23:23:05,847 DEBUG TRAIN Batch 178/3700 loss 19.336586 loss_att 9.347194 loss_ctc 42.645164 loss_ctc_origin 29.115454 loss_ctc0 74.214493 lr 0.00062740 rank 0
2022-08-25 23:23:34,101 DEBUG TRAIN Batch 178/3800 loss 23.052275 loss_att 9.597106 loss_ctc 54.447670 loss_ctc_origin 40.182198 loss_ctc0 87.733765 lr 0.00062737 rank 0
2022-08-25 23:24:02,831 DEBUG TRAIN Batch 178/3900 loss 20.380938 loss_att 8.401107 loss_ctc 48.333874 loss_ctc_origin 28.864286 loss_ctc0 93.762909 lr 0.00062734 rank 0
2022-08-25 23:24:32,322 DEBUG TRAIN Batch 178/4000 loss 32.658699 loss_att 19.787201 loss_ctc 62.692192 loss_ctc_origin 32.956360 loss_ctc0 132.075790 lr 0.00062731 rank 0
2022-08-25 23:25:00,580 DEBUG TRAIN Batch 178/4100 loss 52.193817 loss_att 30.870947 loss_ctc 101.947182 loss_ctc_origin 53.689159 loss_ctc0 214.549225 lr 0.00062728 rank 0
2022-08-25 23:25:29,452 DEBUG TRAIN Batch 178/4200 loss 20.618433 loss_att 11.023771 loss_ctc 43.005974 loss_ctc_origin 32.687286 loss_ctc0 67.082909 lr 0.00062725 rank 0
2022-08-25 23:25:58,538 DEBUG TRAIN Batch 178/4300 loss 19.314054 loss_att 8.038422 loss_ctc 45.623863 loss_ctc_origin 32.151123 loss_ctc0 77.060257 lr 0.00062722 rank 0
2022-08-25 23:26:27,381 DEBUG TRAIN Batch 178/4400 loss 19.059288 loss_att 7.762488 loss_ctc 45.418484 loss_ctc_origin 25.933575 loss_ctc0 90.883270 lr 0.00062719 rank 0
2022-08-25 23:27:02,435 DEBUG TRAIN Batch 178/4500 loss 38.058746 loss_att 24.405073 loss_ctc 69.917320 loss_ctc_origin 42.050682 loss_ctc0 134.939484 lr 0.00062716 rank 0
2022-08-25 23:27:31,466 DEBUG TRAIN Batch 178/4600 loss 53.370399 loss_att 28.957603 loss_ctc 110.333572 loss_ctc_origin 54.935753 loss_ctc0 239.595154 lr 0.00062713 rank 0
2022-08-25 23:28:00,732 DEBUG TRAIN Batch 178/4700 loss 18.074385 loss_att 10.190368 loss_ctc 36.470425 loss_ctc_origin 24.523767 loss_ctc0 64.345955 lr 0.00062710 rank 0
2022-08-25 23:28:29,423 DEBUG TRAIN Batch 178/4800 loss 20.557457 loss_att 8.085564 loss_ctc 49.658543 loss_ctc_origin 34.550137 loss_ctc0 84.911491 lr 0.00062706 rank 0
2022-08-25 23:28:57,401 DEBUG TRAIN Batch 178/4900 loss 27.193344 loss_att 13.096025 loss_ctc 60.087090 loss_ctc_origin 39.742619 loss_ctc0 107.557526 lr 0.00062703 rank 0
2022-08-25 23:29:27,390 DEBUG TRAIN Batch 178/5000 loss 47.556656 loss_att 32.298294 loss_ctc 83.159508 loss_ctc_origin 49.874847 loss_ctc0 160.823715 lr 0.00062700 rank 0
2022-08-25 23:29:55,003 DEBUG TRAIN Batch 178/5100 loss 49.958969 loss_att 26.720547 loss_ctc 104.181946 loss_ctc_origin 54.139503 loss_ctc0 220.947632 lr 0.00062697 rank 0
2022-08-25 23:30:23,329 DEBUG TRAIN Batch 178/5200 loss 17.366070 loss_att 8.488131 loss_ctc 38.081257 loss_ctc_origin 25.775240 loss_ctc0 66.795296 lr 0.00062694 rank 0
2022-08-25 23:30:51,634 DEBUG TRAIN Batch 178/5300 loss 17.148258 loss_att 6.170761 loss_ctc 42.762413 loss_ctc_origin 27.897392 loss_ctc0 77.447472 lr 0.00062691 rank 0
2022-08-25 23:31:20,751 DEBUG TRAIN Batch 178/5400 loss 24.244974 loss_att 10.856176 loss_ctc 55.485500 loss_ctc_origin 38.652428 loss_ctc0 94.762665 lr 0.00062688 rank 0
2022-08-25 23:31:51,180 DEBUG TRAIN Batch 178/5500 loss 40.422123 loss_att 23.934608 loss_ctc 78.892990 loss_ctc_origin 47.251457 loss_ctc0 152.723236 lr 0.00062685 rank 0
2022-08-25 23:32:19,796 DEBUG TRAIN Batch 178/5600 loss 50.596367 loss_att 28.139940 loss_ctc 102.994698 loss_ctc_origin 55.175072 loss_ctc0 214.573807 lr 0.00062682 rank 0
2022-08-25 23:32:43,162 DEBUG CV Batch 178/0 loss 11.824997 loss_att 8.753259 loss_ctc 18.992384 loss_ctc_origin 12.677765 loss_ctc0 33.726494 history loss 11.129409 rank 0
2022-08-25 23:32:54,126 DEBUG CV Batch 178/100 loss 20.357323 loss_att 16.397457 loss_ctc 29.597010 loss_ctc_origin 19.776161 loss_ctc0 52.512321 history loss 25.844868 rank 0
2022-08-25 23:33:04,104 DEBUG CV Batch 178/200 loss 24.693935 loss_att 19.452770 loss_ctc 36.923317 loss_ctc_origin 26.650179 loss_ctc0 60.893974 history loss 27.210647 rank 0
2022-08-25 23:33:14,480 DEBUG CV Batch 178/300 loss 23.115108 loss_att 17.640303 loss_ctc 35.889656 loss_ctc_origin 20.814795 loss_ctc0 71.064331 history loss 26.335411 rank 0
2022-08-25 23:33:25,287 DEBUG CV Batch 178/400 loss 36.913597 loss_att 29.604982 loss_ctc 53.967026 loss_ctc_origin 36.919548 loss_ctc0 93.744476 history loss 24.723552 rank 0
2022-08-25 23:33:36,556 DEBUG CV Batch 178/500 loss 16.832916 loss_att 12.955054 loss_ctc 25.881258 loss_ctc_origin 18.702778 loss_ctc0 42.631042 history loss 24.367468 rank 0
2022-08-25 23:33:47,227 DEBUG CV Batch 178/600 loss 16.551914 loss_att 11.611111 loss_ctc 28.080454 loss_ctc_origin 17.252323 loss_ctc0 53.346088 history loss 24.201037 rank 0
2022-08-25 23:33:57,431 DEBUG CV Batch 178/700 loss 18.390633 loss_att 12.587290 loss_ctc 31.931767 loss_ctc_origin 18.523670 loss_ctc0 63.217327 history loss 23.876823 rank 0
2022-08-25 23:34:08,127 DEBUG CV Batch 178/800 loss 21.890617 loss_att 17.268040 loss_ctc 32.676628 loss_ctc_origin 17.595436 loss_ctc0 67.866074 history loss 23.849015 rank 0
2022-08-25 23:34:18,591 INFO Epoch 178 CV info cv_loss 23.95106694965758
2022-08-25 23:34:18,591 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/178.pt
2022-08-25 23:34:19,037 INFO Epoch 179 TRAIN info lr 0.0006267923486260252
2022-08-25 23:34:19,041 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-25 23:34:45,786 DEBUG TRAIN Batch 179/0 loss 38.563370 loss_att 26.665462 loss_ctc 66.325150 loss_ctc_origin 41.360229 loss_ctc0 124.576645 lr 0.00062679 rank 0
2022-08-25 23:35:14,909 DEBUG TRAIN Batch 179/100 loss 48.452038 loss_att 25.877806 loss_ctc 101.125244 loss_ctc_origin 53.179985 loss_ctc0 212.997498 lr 0.00062676 rank 0
2022-08-25 23:35:43,914 DEBUG TRAIN Batch 179/200 loss 18.251694 loss_att 8.222341 loss_ctc 41.653515 loss_ctc_origin 29.775919 loss_ctc0 69.367905 lr 0.00062673 rank 0
2022-08-25 23:36:13,335 DEBUG TRAIN Batch 179/300 loss 19.563768 loss_att 7.771969 loss_ctc 47.077965 loss_ctc_origin 34.530006 loss_ctc0 76.356537 lr 0.00062670 rank 0
2022-08-25 23:36:41,527 DEBUG TRAIN Batch 179/400 loss 22.033562 loss_att 9.087086 loss_ctc 52.242001 loss_ctc_origin 33.216560 loss_ctc0 96.634689 lr 0.00062667 rank 0
2022-08-25 23:37:10,684 WARNING NaN or Inf found in input tensor.
2022-08-25 23:37:10,732 DEBUG TRAIN Batch 179/500 loss inf loss_att 32.946190 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00062664 rank 0
2022-08-25 23:37:39,013 DEBUG TRAIN Batch 179/600 loss 53.440212 loss_att 30.824280 loss_ctc 106.210716 loss_ctc_origin 65.656509 loss_ctc0 200.837189 lr 0.00062661 rank 0
2022-08-25 23:38:07,815 DEBUG TRAIN Batch 179/700 loss 17.343096 loss_att 6.523258 loss_ctc 42.589378 loss_ctc_origin 29.748623 loss_ctc0 72.551140 lr 0.00062658 rank 0
2022-08-25 23:38:36,145 DEBUG TRAIN Batch 179/800 loss 18.844112 loss_att 7.008054 loss_ctc 46.461578 loss_ctc_origin 30.505264 loss_ctc0 83.692978 lr 0.00062655 rank 0
2022-08-25 23:39:05,511 DEBUG TRAIN Batch 179/900 loss 23.367067 loss_att 9.079104 loss_ctc 56.705643 loss_ctc_origin 40.881271 loss_ctc0 93.629166 lr 0.00062651 rank 0
2022-08-25 23:39:34,419 DEBUG TRAIN Batch 179/1000 loss 49.795502 loss_att 34.762459 loss_ctc 84.872589 loss_ctc_origin 54.426640 loss_ctc0 155.913116 lr 0.00062648 rank 0
2022-08-25 23:40:03,520 DEBUG TRAIN Batch 179/1100 loss 48.186081 loss_att 26.997505 loss_ctc 97.626099 loss_ctc_origin 52.507454 loss_ctc0 202.902939 lr 0.00062645 rank 0
2022-08-25 23:40:31,900 DEBUG TRAIN Batch 179/1200 loss 23.369295 loss_att 12.231598 loss_ctc 49.357254 loss_ctc_origin 38.452271 loss_ctc0 74.802216 lr 0.00062642 rank 0
2022-08-25 23:41:01,774 DEBUG TRAIN Batch 179/1300 loss 17.947617 loss_att 6.934545 loss_ctc 43.644783 loss_ctc_origin 26.037922 loss_ctc0 84.727463 lr 0.00062639 rank 0
2022-08-25 23:41:30,345 DEBUG TRAIN Batch 179/1400 loss 21.598654 loss_att 8.685410 loss_ctc 51.729557 loss_ctc_origin 30.859606 loss_ctc0 100.426102 lr 0.00062636 rank 0
2022-08-25 23:42:05,855 DEBUG TRAIN Batch 179/1500 loss 45.929104 loss_att 29.196524 loss_ctc 84.971786 loss_ctc_origin 50.947853 loss_ctc0 164.360962 lr 0.00062633 rank 0
2022-08-25 23:42:13,748 WARNING NaN or Inf found in input tensor.
2022-08-25 23:42:34,336 DEBUG TRAIN Batch 179/1600 loss 47.078316 loss_att 25.128662 loss_ctc 98.294174 loss_ctc_origin 49.587017 loss_ctc0 211.944214 lr 0.00062630 rank 0
2022-08-25 23:43:02,326 DEBUG TRAIN Batch 179/1700 loss 17.345324 loss_att 8.359073 loss_ctc 38.313240 loss_ctc_origin 26.508089 loss_ctc0 65.858597 lr 0.00062627 rank 0
2022-08-25 23:43:31,908 DEBUG TRAIN Batch 179/1800 loss 18.723232 loss_att 7.714801 loss_ctc 44.409569 loss_ctc_origin 27.683743 loss_ctc0 83.436493 lr 0.00062624 rank 0
2022-08-25 23:44:00,961 DEBUG TRAIN Batch 179/1900 loss 20.150436 loss_att 8.720413 loss_ctc 46.820488 loss_ctc_origin 29.479378 loss_ctc0 87.283066 lr 0.00062621 rank 0
2022-08-25 23:44:30,406 DEBUG TRAIN Batch 179/2000 loss 31.934471 loss_att 20.596256 loss_ctc 58.390305 loss_ctc_origin 32.928864 loss_ctc0 117.800331 lr 0.00062618 rank 0
2022-08-25 23:44:59,009 DEBUG TRAIN Batch 179/2100 loss 44.595737 loss_att 25.092514 loss_ctc 90.103256 loss_ctc_origin 50.167866 loss_ctc0 183.285843 lr 0.00062615 rank 0
2022-08-25 23:45:28,006 DEBUG TRAIN Batch 179/2200 loss 20.413624 loss_att 10.746853 loss_ctc 42.969418 loss_ctc_origin 32.758492 loss_ctc0 66.794907 lr 0.00062612 rank 0
2022-08-25 23:45:56,476 DEBUG TRAIN Batch 179/2300 loss 17.346422 loss_att 7.716248 loss_ctc 39.816826 loss_ctc_origin 25.919100 loss_ctc0 72.244858 lr 0.00062608 rank 0
2022-08-25 23:46:25,435 DEBUG TRAIN Batch 179/2400 loss 19.828485 loss_att 7.474939 loss_ctc 48.653427 loss_ctc_origin 27.173943 loss_ctc0 98.772224 lr 0.00062605 rank 0
2022-08-25 23:46:54,152 DEBUG TRAIN Batch 179/2500 loss 37.803566 loss_att 24.551849 loss_ctc 68.724228 loss_ctc_origin 41.340305 loss_ctc0 132.620041 lr 0.00062602 rank 0
2022-08-25 23:47:23,206 DEBUG TRAIN Batch 179/2600 loss 47.818802 loss_att 25.209042 loss_ctc 100.574905 loss_ctc_origin 57.073181 loss_ctc0 202.078934 lr 0.00062599 rank 0
2022-08-25 23:47:51,658 DEBUG TRAIN Batch 179/2700 loss 18.596275 loss_att 9.067219 loss_ctc 40.830742 loss_ctc_origin 28.355747 loss_ctc0 69.939072 lr 0.00062596 rank 0
2022-08-25 23:48:20,429 DEBUG TRAIN Batch 179/2800 loss 19.609398 loss_att 8.742945 loss_ctc 44.964455 loss_ctc_origin 29.182014 loss_ctc0 81.790138 lr 0.00062593 rank 0
2022-08-25 23:48:31,466 WARNING NaN or Inf found in input tensor.
2022-08-25 23:48:49,479 DEBUG TRAIN Batch 179/2900 loss 21.757292 loss_att 8.332025 loss_ctc 53.082916 loss_ctc_origin 35.256172 loss_ctc0 94.678650 lr 0.00062590 rank 0
2022-08-25 23:49:24,634 DEBUG TRAIN Batch 179/3000 loss 43.191986 loss_att 29.769638 loss_ctc 74.510803 loss_ctc_origin 46.355728 loss_ctc0 140.205978 lr 0.00062587 rank 0
2022-08-25 23:49:32,463 WARNING NaN or Inf found in input tensor.
2022-08-25 23:49:53,259 DEBUG TRAIN Batch 179/3100 loss 45.204269 loss_att 26.032471 loss_ctc 89.938461 loss_ctc_origin 52.938564 loss_ctc0 176.271530 lr 0.00062584 rank 0
2022-08-25 23:50:21,132 DEBUG TRAIN Batch 179/3200 loss 21.948189 loss_att 11.702017 loss_ctc 45.855923 loss_ctc_origin 34.044945 loss_ctc0 73.414871 lr 0.00062581 rank 0
2022-08-25 23:50:49,667 DEBUG TRAIN Batch 179/3300 loss 18.918442 loss_att 7.273088 loss_ctc 46.090935 loss_ctc_origin 30.485922 loss_ctc0 82.502625 lr 0.00062578 rank 0
2022-08-25 23:51:18,193 DEBUG TRAIN Batch 179/3400 loss 21.912735 loss_att 9.037180 loss_ctc 51.955692 loss_ctc_origin 30.684053 loss_ctc0 101.589508 lr 0.00062575 rank 0
2022-08-25 23:51:47,606 DEBUG TRAIN Batch 179/3500 loss 35.392952 loss_att 22.392071 loss_ctc 65.728340 loss_ctc_origin 41.294449 loss_ctc0 122.740753 lr 0.00062572 rank 0
2022-08-25 23:51:55,564 WARNING NaN or Inf found in input tensor.
2022-08-25 23:52:15,717 DEBUG TRAIN Batch 179/3600 loss 46.535255 loss_att 27.329863 loss_ctc 91.347839 loss_ctc_origin 56.665855 loss_ctc0 172.272476 lr 0.00062569 rank 0
2022-08-25 23:52:44,519 DEBUG TRAIN Batch 179/3700 loss 18.978088 loss_att 10.748631 loss_ctc 38.180161 loss_ctc_origin 26.192989 loss_ctc0 66.150230 lr 0.00062566 rank 0
2022-08-25 23:53:14,334 DEBUG TRAIN Batch 179/3800 loss 18.495619 loss_att 7.515672 loss_ctc 44.115494 loss_ctc_origin 30.124596 loss_ctc0 76.760910 lr 0.00062562 rank 0
2022-08-25 23:53:43,382 DEBUG TRAIN Batch 179/3900 loss 21.267181 loss_att 8.517812 loss_ctc 51.015709 loss_ctc_origin 33.551216 loss_ctc0 91.766197 lr 0.00062559 rank 0
2022-08-25 23:54:12,353 DEBUG TRAIN Batch 179/4000 loss 53.136234 loss_att 36.475761 loss_ctc 92.010666 loss_ctc_origin 59.240326 loss_ctc0 168.474792 lr 0.00062556 rank 0
2022-08-25 23:54:41,171 WARNING NaN or Inf found in input tensor.
2022-08-25 23:54:41,215 DEBUG TRAIN Batch 179/4100 loss nan loss_att 36.037231 loss_ctc nan loss_ctc_origin 61.843662 loss_ctc0 nan lr 0.00062553 rank 0
2022-08-25 23:55:09,090 DEBUG TRAIN Batch 179/4200 loss 19.617798 loss_att 9.639936 loss_ctc 42.899475 loss_ctc_origin 32.625324 loss_ctc0 66.872498 lr 0.00062550 rank 0
2022-08-25 23:55:37,660 DEBUG TRAIN Batch 179/4300 loss 20.909840 loss_att 8.417240 loss_ctc 50.059238 loss_ctc_origin 35.591221 loss_ctc0 83.817940 lr 0.00062547 rank 0
2022-08-25 23:56:08,240 DEBUG TRAIN Batch 179/4400 loss 19.304930 loss_att 7.348722 loss_ctc 47.202744 loss_ctc_origin 27.986233 loss_ctc0 92.041260 lr 0.00062544 rank 0
2022-08-25 23:56:44,090 DEBUG TRAIN Batch 179/4500 loss 38.435036 loss_att 25.758730 loss_ctc 68.013077 loss_ctc_origin 43.655205 loss_ctc0 124.848122 lr 0.00062541 rank 0
2022-08-25 23:57:13,114 DEBUG TRAIN Batch 179/4600 loss 57.902466 loss_att 37.530338 loss_ctc 105.437431 loss_ctc_origin 68.028214 loss_ctc0 192.725601 lr 0.00062538 rank 0
2022-08-25 23:57:42,623 DEBUG TRAIN Batch 179/4700 loss 17.815063 loss_att 8.521302 loss_ctc 39.500507 loss_ctc_origin 29.140587 loss_ctc0 63.673653 lr 0.00062535 rank 0
2022-08-25 23:58:11,539 DEBUG TRAIN Batch 179/4800 loss 13.692940 loss_att 4.603724 loss_ctc 34.901108 loss_ctc_origin 20.284447 loss_ctc0 69.006653 lr 0.00062532 rank 0
2022-08-25 23:58:39,990 DEBUG TRAIN Batch 179/4900 loss 22.364115 loss_att 9.288774 loss_ctc 52.873241 loss_ctc_origin 35.375694 loss_ctc0 93.700851 lr 0.00062529 rank 0
2022-08-25 23:59:09,064 DEBUG TRAIN Batch 179/5000 loss 40.274261 loss_att 24.627556 loss_ctc 76.783249 loss_ctc_origin 47.552750 loss_ctc0 144.987747 lr 0.00062526 rank 0
2022-08-25 23:59:37,792 DEBUG TRAIN Batch 179/5100 loss 33.533039 loss_att 15.702274 loss_ctc 75.138153 loss_ctc_origin 31.407259 loss_ctc0 177.176910 lr 0.00062523 rank 0
2022-08-26 00:00:05,138 DEBUG TRAIN Batch 179/5200 loss 19.110460 loss_att 9.670818 loss_ctc 41.136292 loss_ctc_origin 30.139387 loss_ctc0 66.795731 lr 0.00062520 rank 0
2022-08-26 00:00:34,233 DEBUG TRAIN Batch 179/5300 loss 18.191633 loss_att 7.244871 loss_ctc 43.734077 loss_ctc_origin 28.493910 loss_ctc0 79.294464 lr 0.00062517 rank 0
2022-08-26 00:01:02,134 DEBUG TRAIN Batch 179/5400 loss 20.565849 loss_att 8.277748 loss_ctc 49.238083 loss_ctc_origin 31.988615 loss_ctc0 89.486832 lr 0.00062514 rank 0
2022-08-26 00:01:30,569 DEBUG TRAIN Batch 179/5500 loss 42.181267 loss_att 26.321875 loss_ctc 79.186508 loss_ctc_origin 48.620285 loss_ctc0 150.507675 lr 0.00062511 rank 0
2022-08-26 00:01:56,980 DEBUG TRAIN Batch 179/5600 loss 47.771358 loss_att 27.310751 loss_ctc 95.512772 loss_ctc_origin 57.105263 loss_ctc0 185.130280 lr 0.00062507 rank 0
2022-08-26 00:02:20,606 DEBUG CV Batch 179/0 loss 11.724024 loss_att 8.604392 loss_ctc 19.003166 loss_ctc_origin 12.675936 loss_ctc0 33.766708 history loss 11.034375 rank 0
2022-08-26 00:02:31,363 DEBUG CV Batch 179/100 loss 21.052608 loss_att 17.308533 loss_ctc 29.788788 loss_ctc_origin 19.870609 loss_ctc0 52.931206 history loss 25.961588 rank 0
2022-08-26 00:02:41,277 DEBUG CV Batch 179/200 loss 24.590612 loss_att 19.177380 loss_ctc 37.221489 loss_ctc_origin 26.676121 loss_ctc0 61.827347 history loss 27.374182 rank 0
2022-08-26 00:02:51,389 DEBUG CV Batch 179/300 loss 23.542955 loss_att 18.017548 loss_ctc 36.435574 loss_ctc_origin 21.226244 loss_ctc0 71.924011 history loss 26.504697 rank 0
2022-08-26 00:03:02,256 DEBUG CV Batch 179/400 loss 36.788910 loss_att 30.189754 loss_ctc 52.186943 loss_ctc_origin 34.307865 loss_ctc0 93.904785 history loss 24.811173 rank 0
2022-08-26 00:03:13,292 DEBUG CV Batch 179/500 loss 16.309423 loss_att 12.124153 loss_ctc 26.075054 loss_ctc_origin 19.099815 loss_ctc0 42.350613 history loss 24.425108 rank 0
2022-08-26 00:03:24,387 DEBUG CV Batch 179/600 loss 17.284344 loss_att 12.301191 loss_ctc 28.911694 loss_ctc_origin 18.218710 loss_ctc0 53.861984 history loss 24.213930 rank 0
2022-08-26 00:03:35,069 DEBUG CV Batch 179/700 loss 18.710625 loss_att 13.098310 loss_ctc 31.806025 loss_ctc_origin 18.296101 loss_ctc0 63.329182 history loss 23.893746 rank 0
2022-08-26 00:03:45,761 DEBUG CV Batch 179/800 loss 21.406788 loss_att 16.901766 loss_ctc 31.918507 loss_ctc_origin 16.428347 loss_ctc0 68.062210 history loss 23.854927 rank 0
2022-08-26 00:03:56,292 INFO Epoch 179 CV info cv_loss 23.945648893088865
2022-08-26 00:03:56,292 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/179.pt
2022-08-26 00:03:56,727 INFO Epoch 180 TRAIN info lr 0.0006250488338477911
2022-08-26 00:03:56,730 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 00:04:24,194 DEBUG TRAIN Batch 180/0 loss 39.639275 loss_att 23.604439 loss_ctc 77.053879 loss_ctc_origin 45.284031 loss_ctc0 151.183502 lr 0.00062505 rank 0
2022-08-26 00:04:52,864 DEBUG TRAIN Batch 180/100 loss 42.836372 loss_att 21.149586 loss_ctc 93.438873 loss_ctc_origin 47.437637 loss_ctc0 200.775101 lr 0.00062502 rank 0
2022-08-26 00:05:21,467 DEBUG TRAIN Batch 180/200 loss 17.972557 loss_att 8.621784 loss_ctc 39.791023 loss_ctc_origin 26.412630 loss_ctc0 71.007278 lr 0.00062499 rank 0
2022-08-26 00:05:50,171 DEBUG TRAIN Batch 180/300 loss 19.974211 loss_att 8.002331 loss_ctc 47.908592 loss_ctc_origin 33.739227 loss_ctc0 80.970444 lr 0.00062496 rank 0
2022-08-26 00:06:19,090 DEBUG TRAIN Batch 180/400 loss 21.629723 loss_att 9.469558 loss_ctc 50.003441 loss_ctc_origin 31.679575 loss_ctc0 92.759125 lr 0.00062493 rank 0
2022-08-26 00:06:49,012 DEBUG TRAIN Batch 180/500 loss 40.301682 loss_att 24.794228 loss_ctc 76.485733 loss_ctc_origin 47.873787 loss_ctc0 143.246948 lr 0.00062490 rank 0
2022-08-26 00:07:16,791 WARNING NaN or Inf found in input tensor.
2022-08-26 00:07:17,558 DEBUG TRAIN Batch 180/600 loss 48.251099 loss_att 26.084698 loss_ctc 99.972702 loss_ctc_origin 53.424194 loss_ctc0 208.585892 lr 0.00062486 rank 0
2022-08-26 00:07:45,839 DEBUG TRAIN Batch 180/700 loss 20.684530 loss_att 9.838650 loss_ctc 45.991581 loss_ctc_origin 36.348312 loss_ctc0 68.492538 lr 0.00062483 rank 0
2022-08-26 00:08:14,946 DEBUG TRAIN Batch 180/800 loss 19.004908 loss_att 7.893547 loss_ctc 44.931412 loss_ctc_origin 30.526613 loss_ctc0 78.542603 lr 0.00062480 rank 0
2022-08-26 00:08:43,415 DEBUG TRAIN Batch 180/900 loss 20.260414 loss_att 8.016957 loss_ctc 48.828476 loss_ctc_origin 28.455490 loss_ctc0 96.365448 lr 0.00062477 rank 0
2022-08-26 00:09:13,270 DEBUG TRAIN Batch 180/1000 loss 42.870201 loss_att 27.486912 loss_ctc 78.764542 loss_ctc_origin 52.361191 loss_ctc0 140.372345 lr 0.00062474 rank 0
2022-08-26 00:09:41,972 WARNING NaN or Inf found in input tensor.
2022-08-26 00:09:42,016 DEBUG TRAIN Batch 180/1100 loss nan loss_att 31.025654 loss_ctc nan loss_ctc_origin 56.831612 loss_ctc0 nan lr 0.00062471 rank 0
2022-08-26 00:10:10,108 WARNING NaN or Inf found in input tensor.
2022-08-26 00:10:11,801 DEBUG TRAIN Batch 180/1200 loss 15.446909 loss_att 7.081123 loss_ctc 34.967075 loss_ctc_origin 21.242207 loss_ctc0 66.991768 lr 0.00062468 rank 0
2022-08-26 00:10:41,259 DEBUG TRAIN Batch 180/1300 loss 17.641277 loss_att 7.073206 loss_ctc 42.300110 loss_ctc_origin 28.452993 loss_ctc0 74.610046 lr 0.00062465 rank 0
2022-08-26 00:11:09,691 DEBUG TRAIN Batch 180/1400 loss 20.029469 loss_att 8.375849 loss_ctc 47.221245 loss_ctc_origin 30.881233 loss_ctc0 85.347939 lr 0.00062462 rank 0
2022-08-26 00:11:44,662 DEBUG TRAIN Batch 180/1500 loss 43.639198 loss_att 28.490318 loss_ctc 78.986588 loss_ctc_origin 49.429554 loss_ctc0 147.953003 lr 0.00062459 rank 0
2022-08-26 00:12:14,089 DEBUG TRAIN Batch 180/1600 loss 57.775150 loss_att 32.835388 loss_ctc 115.967926 loss_ctc_origin 63.373505 loss_ctc0 238.688232 lr 0.00062456 rank 0
2022-08-26 00:12:42,567 DEBUG TRAIN Batch 180/1700 loss 21.298849 loss_att 11.074884 loss_ctc 45.154766 loss_ctc_origin 35.948425 loss_ctc0 66.636230 lr 0.00062453 rank 0
2022-08-26 00:13:11,600 DEBUG TRAIN Batch 180/1800 loss 18.281858 loss_att 7.132733 loss_ctc 44.296486 loss_ctc_origin 32.355896 loss_ctc0 72.157867 lr 0.00062450 rank 0
2022-08-26 00:13:40,894 DEBUG TRAIN Batch 180/1900 loss 20.529400 loss_att 8.669685 loss_ctc 48.202065 loss_ctc_origin 29.392212 loss_ctc0 92.091713 lr 0.00062447 rank 0
2022-08-26 00:13:50,064 WARNING NaN or Inf found in input tensor.
2022-08-26 00:14:11,160 DEBUG TRAIN Batch 180/2000 loss 35.863056 loss_att 21.203915 loss_ctc 70.067719 loss_ctc_origin 40.452560 loss_ctc0 139.169754 lr 0.00062444 rank 0
2022-08-26 00:14:40,289 DEBUG TRAIN Batch 180/2100 loss 54.294895 loss_att 28.602018 loss_ctc 114.244934 loss_ctc_origin 56.268066 loss_ctc0 249.524292 lr 0.00062441 rank 0
2022-08-26 00:15:08,313 DEBUG TRAIN Batch 180/2200 loss 20.266352 loss_att 11.932995 loss_ctc 39.710850 loss_ctc_origin 27.342442 loss_ctc0 68.570465 lr 0.00062438 rank 0
2022-08-26 00:15:37,037 DEBUG TRAIN Batch 180/2300 loss 22.710419 loss_att 9.815186 loss_ctc 52.799297 loss_ctc_origin 40.382450 loss_ctc0 81.771935 lr 0.00062435 rank 0
2022-08-26 00:16:06,457 DEBUG TRAIN Batch 180/2400 loss 19.068842 loss_att 6.732076 loss_ctc 47.854630 loss_ctc_origin 30.944263 loss_ctc0 87.312157 lr 0.00062432 rank 0
2022-08-26 00:16:36,131 WARNING NaN or Inf found in input tensor.
2022-08-26 00:16:36,172 DEBUG TRAIN Batch 180/2500 loss inf loss_att 24.892490 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00062429 rank 0
2022-08-26 00:16:57,831 WARNING NaN or Inf found in input tensor.
2022-08-26 00:17:04,799 DEBUG TRAIN Batch 180/2600 loss 52.591972 loss_att 31.684040 loss_ctc 101.377151 loss_ctc_origin 59.426456 loss_ctc0 199.262100 lr 0.00062426 rank 0
2022-08-26 00:17:33,016 DEBUG TRAIN Batch 180/2700 loss 22.241621 loss_att 12.138042 loss_ctc 45.816635 loss_ctc_origin 34.176659 loss_ctc0 72.976578 lr 0.00062423 rank 0
2022-08-26 00:18:00,946 DEBUG TRAIN Batch 180/2800 loss 16.243532 loss_att 6.789001 loss_ctc 38.304104 loss_ctc_origin 23.184143 loss_ctc0 73.584015 lr 0.00062419 rank 0
2022-08-26 00:18:29,669 DEBUG TRAIN Batch 180/2900 loss 21.386581 loss_att 8.387747 loss_ctc 51.717194 loss_ctc_origin 31.579845 loss_ctc0 98.704338 lr 0.00062416 rank 0
2022-08-26 00:19:04,742 DEBUG TRAIN Batch 180/3000 loss 44.223099 loss_att 27.156706 loss_ctc 84.044678 loss_ctc_origin 54.014206 loss_ctc0 154.115784 lr 0.00062413 rank 0
2022-08-26 00:19:33,928 DEBUG TRAIN Batch 180/3100 loss 52.872551 loss_att 28.704044 loss_ctc 109.265724 loss_ctc_origin 67.725388 loss_ctc0 206.193161 lr 0.00062410 rank 0
2022-08-26 00:20:01,192 WARNING NaN or Inf found in input tensor.
2022-08-26 00:20:02,768 DEBUG TRAIN Batch 180/3200 loss 21.809040 loss_att 12.988737 loss_ctc 42.389748 loss_ctc_origin 32.158142 loss_ctc0 66.263496 lr 0.00062407 rank 0
2022-08-26 00:20:31,552 DEBUG TRAIN Batch 180/3300 loss 14.454428 loss_att 5.782633 loss_ctc 34.688614 loss_ctc_origin 20.106363 loss_ctc0 68.713867 lr 0.00062404 rank 0
2022-08-26 00:21:00,173 DEBUG TRAIN Batch 180/3400 loss 17.604216 loss_att 6.709752 loss_ctc 43.024628 loss_ctc_origin 24.266281 loss_ctc0 86.794098 lr 0.00062401 rank 0
2022-08-26 00:21:29,627 DEBUG TRAIN Batch 180/3500 loss 45.648132 loss_att 29.833452 loss_ctc 82.549042 loss_ctc_origin 50.617214 loss_ctc0 157.056656 lr 0.00062398 rank 0
2022-08-26 00:21:57,992 DEBUG TRAIN Batch 180/3600 loss 54.215328 loss_att 27.961498 loss_ctc 115.474258 loss_ctc_origin 73.059265 loss_ctc0 214.442566 lr 0.00062395 rank 0
2022-08-26 00:22:27,519 DEBUG TRAIN Batch 180/3700 loss 21.631901 loss_att 10.831766 loss_ctc 46.832214 loss_ctc_origin 36.235123 loss_ctc0 71.558754 lr 0.00062392 rank 0
2022-08-26 00:22:33,122 WARNING NaN or Inf found in input tensor.
2022-08-26 00:22:57,234 DEBUG TRAIN Batch 180/3800 loss 20.341154 loss_att 7.247532 loss_ctc 50.892937 loss_ctc_origin 38.576527 loss_ctc0 79.631226 lr 0.00062389 rank 0
2022-08-26 00:23:26,822 DEBUG TRAIN Batch 180/3900 loss 23.058426 loss_att 10.648193 loss_ctc 52.015629 loss_ctc_origin 35.264450 loss_ctc0 91.101715 lr 0.00062386 rank 0
2022-08-26 00:23:55,622 DEBUG TRAIN Batch 180/4000 loss 53.105309 loss_att 36.292381 loss_ctc 92.335464 loss_ctc_origin 65.257843 loss_ctc0 155.516571 lr 0.00062383 rank 0
2022-08-26 00:24:10,350 WARNING NaN or Inf found in input tensor.
2022-08-26 00:24:17,398 WARNING NaN or Inf found in input tensor.
2022-08-26 00:24:24,707 DEBUG TRAIN Batch 180/4100 loss 51.381878 loss_att 27.489086 loss_ctc 107.131729 loss_ctc_origin 67.128357 loss_ctc0 200.472931 lr 0.00062380 rank 0
2022-08-26 00:24:53,327 DEBUG TRAIN Batch 180/4200 loss 18.641777 loss_att 9.953823 loss_ctc 38.913666 loss_ctc_origin 28.177471 loss_ctc0 63.964790 lr 0.00062377 rank 0
2022-08-26 00:25:21,933 DEBUG TRAIN Batch 180/4300 loss 18.754837 loss_att 7.666213 loss_ctc 44.628288 loss_ctc_origin 29.446606 loss_ctc0 80.052216 lr 0.00062374 rank 0
2022-08-26 00:25:50,177 DEBUG TRAIN Batch 180/4400 loss 20.645569 loss_att 8.758974 loss_ctc 48.380959 loss_ctc_origin 31.313068 loss_ctc0 88.206032 lr 0.00062371 rank 0
2022-08-26 00:26:25,306 DEBUG TRAIN Batch 180/4500 loss 41.644882 loss_att 26.601109 loss_ctc 76.747017 loss_ctc_origin 46.125134 loss_ctc0 148.198074 lr 0.00062368 rank 0
2022-08-26 00:26:53,363 DEBUG TRAIN Batch 180/4600 loss 38.855850 loss_att 19.615120 loss_ctc 83.750877 loss_ctc_origin 43.150970 loss_ctc0 178.483978 lr 0.00062365 rank 0
2022-08-26 00:27:20,741 DEBUG TRAIN Batch 180/4700 loss 21.791008 loss_att 12.049364 loss_ctc 44.521503 loss_ctc_origin 33.835274 loss_ctc0 69.456039 lr 0.00062362 rank 0
2022-08-26 00:27:47,808 DEBUG TRAIN Batch 180/4800 loss 15.913184 loss_att 6.635464 loss_ctc 37.561195 loss_ctc_origin 25.299730 loss_ctc0 66.171280 lr 0.00062359 rank 0
2022-08-26 00:28:14,815 DEBUG TRAIN Batch 180/4900 loss 18.508848 loss_att 7.478625 loss_ctc 44.246033 loss_ctc_origin 25.991209 loss_ctc0 86.840614 lr 0.00062356 rank 0
2022-08-26 00:28:42,620 DEBUG TRAIN Batch 180/5000 loss 36.989037 loss_att 24.388781 loss_ctc 66.389633 loss_ctc_origin 40.399017 loss_ctc0 127.034386 lr 0.00062353 rank 0
2022-08-26 00:29:10,445 DEBUG TRAIN Batch 180/5100 loss 41.835949 loss_att 23.239101 loss_ctc 85.228592 loss_ctc_origin 47.429790 loss_ctc0 173.425812 lr 0.00062350 rank 0
2022-08-26 00:29:37,646 DEBUG TRAIN Batch 180/5200 loss 18.961174 loss_att 8.543644 loss_ctc 43.268745 loss_ctc_origin 30.051615 loss_ctc0 74.108704 lr 0.00062347 rank 0
2022-08-26 00:30:02,048 WARNING NaN or Inf found in input tensor.
2022-08-26 00:30:04,795 DEBUG TRAIN Batch 180/5300 loss 17.256615 loss_att 7.356552 loss_ctc 40.356758 loss_ctc_origin 27.686962 loss_ctc0 69.919624 lr 0.00062344 rank 0
2022-08-26 00:30:31,629 DEBUG TRAIN Batch 180/5400 loss 22.495193 loss_att 9.617382 loss_ctc 52.543419 loss_ctc_origin 35.948578 loss_ctc0 91.264709 lr 0.00062341 rank 0
2022-08-26 00:30:34,312 WARNING NaN or Inf found in input tensor.
2022-08-26 00:31:00,037 DEBUG TRAIN Batch 180/5500 loss 37.826103 loss_att 24.330769 loss_ctc 69.315216 loss_ctc_origin 41.995964 loss_ctc0 133.060120 lr 0.00062338 rank 0
2022-08-26 00:31:26,296 DEBUG TRAIN Batch 180/5600 loss 40.612186 loss_att 22.047295 loss_ctc 83.930267 loss_ctc_origin 39.653786 loss_ctc0 187.242050 lr 0.00062335 rank 0
2022-08-26 00:31:49,466 DEBUG CV Batch 180/0 loss 11.871031 loss_att 8.872763 loss_ctc 18.866991 loss_ctc_origin 12.539365 loss_ctc0 33.631451 history loss 11.172735 rank 0
2022-08-26 00:31:59,428 DEBUG CV Batch 180/100 loss 20.279350 loss_att 16.033230 loss_ctc 30.186966 loss_ctc_origin 20.552460 loss_ctc0 52.667480 history loss 25.693135 rank 0
2022-08-26 00:32:08,359 DEBUG CV Batch 180/200 loss 25.128792 loss_att 19.314356 loss_ctc 38.695808 loss_ctc_origin 29.097721 loss_ctc0 61.091335 history loss 27.165645 rank 0
2022-08-26 00:32:17,838 DEBUG CV Batch 180/300 loss 22.667879 loss_att 16.921387 loss_ctc 36.076359 loss_ctc_origin 21.054379 loss_ctc0 71.127647 history loss 26.263225 rank 0
2022-08-26 00:32:28,183 DEBUG CV Batch 180/400 loss 36.847191 loss_att 29.723400 loss_ctc 53.469368 loss_ctc_origin 36.239933 loss_ctc0 93.671387 history loss 24.619283 rank 0
2022-08-26 00:32:39,189 DEBUG CV Batch 180/500 loss 16.261164 loss_att 12.374459 loss_ctc 25.330137 loss_ctc_origin 18.331882 loss_ctc0 41.659397 history loss 24.302222 rank 0
2022-08-26 00:32:49,014 DEBUG CV Batch 180/600 loss 17.852818 loss_att 12.638739 loss_ctc 30.019003 loss_ctc_origin 19.829973 loss_ctc0 53.793400 history loss 24.165127 rank 0
2022-08-26 00:32:58,488 DEBUG CV Batch 180/700 loss 18.184982 loss_att 12.479648 loss_ctc 31.497433 loss_ctc_origin 18.030384 loss_ctc0 62.920540 history loss 23.831959 rank 0
2022-08-26 00:33:09,452 DEBUG CV Batch 180/800 loss 21.672173 loss_att 17.138189 loss_ctc 32.251465 loss_ctc_origin 16.715729 loss_ctc0 68.501511 history loss 23.769406 rank 0
2022-08-26 00:33:19,801 INFO Epoch 180 CV info cv_loss 23.830231224108516
2022-08-26 00:33:19,801 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/180.pt
2022-08-26 00:33:20,295 INFO Epoch 181 TRAIN info lr 0.0006233197881181917
2022-08-26 00:33:20,299 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 00:33:47,877 DEBUG TRAIN Batch 181/0 loss 42.517052 loss_att 27.513565 loss_ctc 77.525192 loss_ctc_origin 53.973137 loss_ctc0 132.479980 lr 0.00062332 rank 0
2022-08-26 00:33:48,693 WARNING NaN or Inf found in input tensor.
2022-08-26 00:34:16,730 DEBUG TRAIN Batch 181/100 loss 41.379616 loss_att 19.769053 loss_ctc 91.804260 loss_ctc_origin 40.917702 loss_ctc0 210.539551 lr 0.00062329 rank 0
2022-08-26 00:34:45,736 DEBUG TRAIN Batch 181/200 loss 20.254831 loss_att 10.695297 loss_ctc 42.560410 loss_ctc_origin 32.117134 loss_ctc0 66.928047 lr 0.00062326 rank 0
2022-08-26 00:35:14,826 DEBUG TRAIN Batch 181/300 loss 21.236568 loss_att 9.213774 loss_ctc 49.289753 loss_ctc_origin 36.242195 loss_ctc0 79.734055 lr 0.00062323 rank 0
2022-08-26 00:35:43,739 DEBUG TRAIN Batch 181/400 loss 24.395042 loss_att 11.101651 loss_ctc 55.412949 loss_ctc_origin 39.347961 loss_ctc0 92.897919 lr 0.00062320 rank 0
2022-08-26 00:36:13,927 DEBUG TRAIN Batch 181/500 loss 40.493492 loss_att 23.574154 loss_ctc 79.971954 loss_ctc_origin 48.909588 loss_ctc0 152.450806 lr 0.00062317 rank 0
2022-08-26 00:36:43,057 DEBUG TRAIN Batch 181/600 loss 49.939861 loss_att 29.730011 loss_ctc 97.096176 loss_ctc_origin 51.473770 loss_ctc0 203.548431 lr 0.00062314 rank 0
2022-08-26 00:37:11,679 DEBUG TRAIN Batch 181/700 loss 18.472519 loss_att 9.292803 loss_ctc 39.891853 loss_ctc_origin 28.721447 loss_ctc0 65.956131 lr 0.00062311 rank 0
2022-08-26 00:37:40,403 DEBUG TRAIN Batch 181/800 loss 20.540625 loss_att 8.454794 loss_ctc 48.740894 loss_ctc_origin 32.648239 loss_ctc0 86.290421 lr 0.00062308 rank 0
2022-08-26 00:38:09,911 DEBUG TRAIN Batch 181/900 loss 19.748676 loss_att 8.556744 loss_ctc 45.863182 loss_ctc_origin 27.174088 loss_ctc0 89.471077 lr 0.00062305 rank 0
2022-08-26 00:38:25,468 WARNING NaN or Inf found in input tensor.
2022-08-26 00:38:37,353 DEBUG TRAIN Batch 181/1000 loss 37.928810 loss_att 23.623787 loss_ctc 71.307198 loss_ctc_origin 41.894360 loss_ctc0 139.937149 lr 0.00062302 rank 0
2022-08-26 00:38:52,001 WARNING NaN or Inf found in input tensor.
2022-08-26 00:39:06,444 DEBUG TRAIN Batch 181/1100 loss 53.709183 loss_att 27.499371 loss_ctc 114.865402 loss_ctc_origin 58.828850 loss_ctc0 245.617371 lr 0.00062299 rank 0
2022-08-26 00:39:35,085 DEBUG TRAIN Batch 181/1200 loss 19.334442 loss_att 10.221123 loss_ctc 40.598854 loss_ctc_origin 30.896500 loss_ctc0 63.237675 lr 0.00062296 rank 0
2022-08-26 00:39:47,183 WARNING NaN or Inf found in input tensor.
2022-08-26 00:40:04,814 DEBUG TRAIN Batch 181/1300 loss 20.727505 loss_att 8.375347 loss_ctc 49.549202 loss_ctc_origin 35.729908 loss_ctc0 81.794212 lr 0.00062293 rank 0
2022-08-26 00:40:28,202 WARNING NaN or Inf found in input tensor.
2022-08-26 00:40:32,822 DEBUG TRAIN Batch 181/1400 loss 21.957996 loss_att 9.823437 loss_ctc 50.271965 loss_ctc_origin 32.077030 loss_ctc0 92.726807 lr 0.00062290 rank 0
2022-08-26 00:41:07,192 DEBUG TRAIN Batch 181/1500 loss 32.035015 loss_att 20.062901 loss_ctc 59.969948 loss_ctc_origin 32.944290 loss_ctc0 123.029800 lr 0.00062286 rank 0
2022-08-26 00:41:15,262 WARNING NaN or Inf found in input tensor.
2022-08-26 00:41:22,512 WARNING NaN or Inf found in input tensor.
2022-08-26 00:41:35,916 DEBUG TRAIN Batch 181/1600 loss 49.985218 loss_att 28.330074 loss_ctc 100.513885 loss_ctc_origin 58.412231 loss_ctc0 198.751083 lr 0.00062283 rank 0
2022-08-26 00:42:05,151 DEBUG TRAIN Batch 181/1700 loss 20.599613 loss_att 10.766233 loss_ctc 43.544167 loss_ctc_origin 31.949808 loss_ctc0 70.597672 lr 0.00062280 rank 0
2022-08-26 00:42:34,378 DEBUG TRAIN Batch 181/1800 loss 19.255928 loss_att 6.981619 loss_ctc 47.895977 loss_ctc_origin 32.211845 loss_ctc0 84.492279 lr 0.00062277 rank 0
2022-08-26 00:43:02,681 DEBUG TRAIN Batch 181/1900 loss 22.752048 loss_att 9.938876 loss_ctc 52.649445 loss_ctc_origin 36.498936 loss_ctc0 90.333961 lr 0.00062274 rank 0
2022-08-26 00:43:32,209 DEBUG TRAIN Batch 181/2000 loss 37.577961 loss_att 23.423437 loss_ctc 70.605179 loss_ctc_origin 43.741276 loss_ctc0 133.287598 lr 0.00062271 rank 0
2022-08-26 00:43:39,962 WARNING NaN or Inf found in input tensor.
2022-08-26 00:44:00,645 DEBUG TRAIN Batch 181/2100 loss 43.801086 loss_att 21.631884 loss_ctc 95.529228 loss_ctc_origin 43.372551 loss_ctc0 217.228119 lr 0.00062268 rank 0
2022-08-26 00:44:29,360 DEBUG TRAIN Batch 181/2200 loss 21.997093 loss_att 11.942416 loss_ctc 45.458004 loss_ctc_origin 34.614998 loss_ctc0 70.758354 lr 0.00062265 rank 0
2022-08-26 00:44:34,814 WARNING NaN or Inf found in input tensor.
2022-08-26 00:44:57,944 DEBUG TRAIN Batch 181/2300 loss 17.207687 loss_att 7.622462 loss_ctc 39.573212 loss_ctc_origin 25.333878 loss_ctc0 72.798325 lr 0.00062262 rank 0
2022-08-26 00:45:27,216 DEBUG TRAIN Batch 181/2400 loss 20.282610 loss_att 8.344582 loss_ctc 48.138008 loss_ctc_origin 31.214342 loss_ctc0 87.626564 lr 0.00062259 rank 0
2022-08-26 00:45:56,553 DEBUG TRAIN Batch 181/2500 loss 35.087013 loss_att 21.516651 loss_ctc 66.751183 loss_ctc_origin 37.377201 loss_ctc0 135.290466 lr 0.00062256 rank 0
2022-08-26 00:46:25,430 DEBUG TRAIN Batch 181/2600 loss 47.196198 loss_att 26.145407 loss_ctc 96.314713 loss_ctc_origin 53.468903 loss_ctc0 196.288284 lr 0.00062253 rank 0
2022-08-26 00:46:53,298 WARNING NaN or Inf found in input tensor.
2022-08-26 00:46:54,865 DEBUG TRAIN Batch 181/2700 loss 18.045511 loss_att 8.815026 loss_ctc 39.583309 loss_ctc_origin 27.930325 loss_ctc0 66.773605 lr 0.00062250 rank 0
2022-08-26 00:47:24,528 DEBUG TRAIN Batch 181/2800 loss 19.563725 loss_att 9.146791 loss_ctc 43.869904 loss_ctc_origin 31.739008 loss_ctc0 72.175323 lr 0.00062247 rank 0
2022-08-26 00:47:53,078 DEBUG TRAIN Batch 181/2900 loss 18.454287 loss_att 7.122343 loss_ctc 44.895485 loss_ctc_origin 26.613628 loss_ctc0 87.553154 lr 0.00062244 rank 0
2022-08-26 00:48:29,231 DEBUG TRAIN Batch 181/3000 loss 42.842628 loss_att 27.923525 loss_ctc 77.653870 loss_ctc_origin 46.577766 loss_ctc0 150.164795 lr 0.00062241 rank 0
2022-08-26 00:48:44,490 WARNING NaN or Inf found in input tensor.
2022-08-26 00:48:58,445 DEBUG TRAIN Batch 181/3100 loss 44.948364 loss_att 23.141827 loss_ctc 95.830276 loss_ctc_origin 47.833153 loss_ctc0 207.823563 lr 0.00062238 rank 0
2022-08-26 00:49:26,839 DEBUG TRAIN Batch 181/3200 loss 19.611004 loss_att 11.131717 loss_ctc 39.396004 loss_ctc_origin 28.596315 loss_ctc0 64.595284 lr 0.00062235 rank 0
2022-08-26 00:49:55,573 DEBUG TRAIN Batch 181/3300 loss 18.293917 loss_att 7.968835 loss_ctc 42.385773 loss_ctc_origin 28.915298 loss_ctc0 73.816879 lr 0.00062232 rank 0
2022-08-26 00:50:25,112 DEBUG TRAIN Batch 181/3400 loss 24.630600 loss_att 10.060680 loss_ctc 58.627075 loss_ctc_origin 40.078423 loss_ctc0 101.907257 lr 0.00062229 rank 0
2022-08-26 00:50:54,488 DEBUG TRAIN Batch 181/3500 loss 44.727520 loss_att 29.391642 loss_ctc 80.511238 loss_ctc_origin 53.324631 loss_ctc0 143.946655 lr 0.00062226 rank 0
2022-08-26 00:51:22,766 DEBUG TRAIN Batch 181/3600 loss 43.079182 loss_att 22.010275 loss_ctc 92.239960 loss_ctc_origin 45.802128 loss_ctc0 200.594879 lr 0.00062223 rank 0
2022-08-26 00:51:51,612 DEBUG TRAIN Batch 181/3700 loss 21.375692 loss_att 11.952017 loss_ctc 43.364269 loss_ctc_origin 30.648605 loss_ctc0 73.034149 lr 0.00062220 rank 0
2022-08-26 00:52:21,633 DEBUG TRAIN Batch 181/3800 loss 17.213881 loss_att 8.324173 loss_ctc 37.956528 loss_ctc_origin 23.229370 loss_ctc0 72.319885 lr 0.00062217 rank 0
2022-08-26 00:52:45,793 WARNING NaN or Inf found in input tensor.
2022-08-26 00:52:50,153 DEBUG TRAIN Batch 181/3900 loss 23.004093 loss_att 9.714694 loss_ctc 54.012691 loss_ctc_origin 35.605198 loss_ctc0 96.963509 lr 0.00062214 rank 0
2022-08-26 00:53:19,018 DEBUG TRAIN Batch 181/4000 loss 43.244370 loss_att 27.551971 loss_ctc 79.859970 loss_ctc_origin 53.339622 loss_ctc0 141.740768 lr 0.00062211 rank 0
2022-08-26 00:53:33,844 WARNING NaN or Inf found in input tensor.
2022-08-26 00:53:48,293 DEBUG TRAIN Batch 181/4100 loss 52.001839 loss_att 30.503012 loss_ctc 102.165771 loss_ctc_origin 63.798225 loss_ctc0 191.690033 lr 0.00062208 rank 0
2022-08-26 00:54:17,325 DEBUG TRAIN Batch 181/4200 loss 18.431097 loss_att 10.034451 loss_ctc 38.023270 loss_ctc_origin 28.145905 loss_ctc0 61.070450 lr 0.00062205 rank 0
2022-08-26 00:54:47,237 DEBUG TRAIN Batch 181/4300 loss 19.959557 loss_att 8.003736 loss_ctc 47.856468 loss_ctc_origin 31.241102 loss_ctc0 86.625656 lr 0.00062202 rank 0
2022-08-26 00:55:16,362 DEBUG TRAIN Batch 181/4400 loss 21.786572 loss_att 9.301025 loss_ctc 50.919510 loss_ctc_origin 32.456795 loss_ctc0 93.999176 lr 0.00062199 rank 0
2022-08-26 00:55:51,759 DEBUG TRAIN Batch 181/4500 loss 38.744797 loss_att 23.741495 loss_ctc 73.752502 loss_ctc_origin 39.872540 loss_ctc0 152.805756 lr 0.00062196 rank 0
2022-08-26 00:56:20,692 DEBUG TRAIN Batch 181/4600 loss 47.826218 loss_att 28.996754 loss_ctc 91.761635 loss_ctc_origin 50.525558 loss_ctc0 187.979141 lr 0.00062193 rank 0
2022-08-26 00:56:49,977 DEBUG TRAIN Batch 181/4700 loss 18.937977 loss_att 9.640232 loss_ctc 40.632713 loss_ctc_origin 28.813137 loss_ctc0 68.211716 lr 0.00062190 rank 0
2022-08-26 00:57:18,149 DEBUG TRAIN Batch 181/4800 loss 16.234764 loss_att 7.868402 loss_ctc 35.756279 loss_ctc_origin 22.106689 loss_ctc0 67.605316 lr 0.00062187 rank 0
2022-08-26 00:57:46,891 DEBUG TRAIN Batch 181/4900 loss 27.571064 loss_att 11.771379 loss_ctc 64.436996 loss_ctc_origin 46.535351 loss_ctc0 106.207489 lr 0.00062184 rank 0
2022-08-26 00:58:16,001 DEBUG TRAIN Batch 181/5000 loss 34.424843 loss_att 21.008772 loss_ctc 65.729004 loss_ctc_origin 39.730984 loss_ctc0 126.391060 lr 0.00062181 rank 0
2022-08-26 00:58:23,540 WARNING NaN or Inf found in input tensor.
2022-08-26 00:58:43,890 DEBUG TRAIN Batch 181/5100 loss 49.032234 loss_att 28.699537 loss_ctc 96.475189 loss_ctc_origin 56.993988 loss_ctc0 188.598007 lr 0.00062178 rank 0
2022-08-26 00:59:12,448 DEBUG TRAIN Batch 181/5200 loss 17.053228 loss_att 7.431931 loss_ctc 39.502926 loss_ctc_origin 25.695786 loss_ctc0 71.719589 lr 0.00062175 rank 0
2022-08-26 00:59:41,540 DEBUG TRAIN Batch 181/5300 loss 22.304701 loss_att 9.240304 loss_ctc 52.788292 loss_ctc_origin 38.402119 loss_ctc0 86.356033 lr 0.00062172 rank 0
2022-08-26 01:00:09,909 DEBUG TRAIN Batch 181/5400 loss 22.739773 loss_att 10.099850 loss_ctc 52.232929 loss_ctc_origin 32.923698 loss_ctc0 97.287796 lr 0.00062169 rank 0
2022-08-26 01:00:38,250 DEBUG TRAIN Batch 181/5500 loss 33.560402 loss_att 20.165901 loss_ctc 64.814232 loss_ctc_origin 39.375538 loss_ctc0 124.171188 lr 0.00062166 rank 0
2022-08-26 01:01:00,084 WARNING NaN or Inf found in input tensor.
2022-08-26 01:01:07,267 DEBUG TRAIN Batch 181/5600 loss 42.198021 loss_att 21.274178 loss_ctc 91.020325 loss_ctc_origin 45.406540 loss_ctc0 197.452484 lr 0.00062163 rank 0
2022-08-26 01:01:30,798 DEBUG CV Batch 181/0 loss 12.073246 loss_att 9.060127 loss_ctc 19.103855 loss_ctc_origin 12.688041 loss_ctc0 34.074089 history loss 11.363055 rank 0
2022-08-26 01:01:42,096 DEBUG CV Batch 181/100 loss 20.343958 loss_att 16.160252 loss_ctc 30.105938 loss_ctc_origin 20.404587 loss_ctc0 52.742424 history loss 26.628133 rank 0
2022-08-26 01:01:51,442 DEBUG CV Batch 181/200 loss 26.370308 loss_att 20.689499 loss_ctc 39.625526 loss_ctc_origin 29.987980 loss_ctc0 62.113140 history loss 28.234765 rank 0
2022-08-26 01:02:01,315 DEBUG CV Batch 181/300 loss 22.935030 loss_att 17.506144 loss_ctc 35.602432 loss_ctc_origin 20.416046 loss_ctc0 71.037331 history loss 27.307011 rank 0
2022-08-26 01:02:12,042 DEBUG CV Batch 181/400 loss 37.829269 loss_att 30.954485 loss_ctc 53.870430 loss_ctc_origin 36.631329 loss_ctc0 94.095001 history loss 25.517593 rank 0
2022-08-26 01:02:23,168 DEBUG CV Batch 181/500 loss 15.697281 loss_att 11.564569 loss_ctc 25.340275 loss_ctc_origin 18.491385 loss_ctc0 41.321014 history loss 25.124266 rank 0
2022-08-26 01:02:34,084 DEBUG CV Batch 181/600 loss 17.598690 loss_att 12.143356 loss_ctc 30.327803 loss_ctc_origin 20.355320 loss_ctc0 53.596928 history loss 24.885728 rank 0
2022-08-26 01:02:44,357 DEBUG CV Batch 181/700 loss 18.504120 loss_att 12.840078 loss_ctc 31.720215 loss_ctc_origin 18.369282 loss_ctc0 62.872387 history loss 24.534247 rank 0
2022-08-26 01:02:54,751 DEBUG CV Batch 181/800 loss 21.418640 loss_att 16.533485 loss_ctc 32.817333 loss_ctc_origin 17.575369 loss_ctc0 68.381912 history loss 24.465920 rank 0
2022-08-26 01:03:05,212 INFO Epoch 181 CV info cv_loss 24.54828390160201
2022-08-26 01:03:05,212 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/181.pt
2022-08-26 01:03:05,717 INFO Epoch 182 TRAIN info lr 0.0006216050124122895
2022-08-26 01:03:05,720 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 01:03:31,878 DEBUG TRAIN Batch 182/0 loss 46.904938 loss_att 31.417091 loss_ctc 83.043243 loss_ctc_origin 59.398499 loss_ctc0 138.214310 lr 0.00062160 rank 0
2022-08-26 01:04:00,744 DEBUG TRAIN Batch 182/100 loss 46.728821 loss_att 25.756493 loss_ctc 95.664246 loss_ctc_origin 62.818016 loss_ctc0 172.305435 lr 0.00062157 rank 0
2022-08-26 01:04:30,179 DEBUG TRAIN Batch 182/200 loss 18.927124 loss_att 9.423231 loss_ctc 41.102875 loss_ctc_origin 29.769539 loss_ctc0 67.547325 lr 0.00062154 rank 0
2022-08-26 01:04:59,648 DEBUG TRAIN Batch 182/300 loss 21.086052 loss_att 8.981768 loss_ctc 49.329380 loss_ctc_origin 36.553970 loss_ctc0 79.138672 lr 0.00062151 rank 0
2022-08-26 01:05:28,553 DEBUG TRAIN Batch 182/400 loss 22.767557 loss_att 8.708117 loss_ctc 55.572914 loss_ctc_origin 38.425545 loss_ctc0 95.583450 lr 0.00062148 rank 0
2022-08-26 01:05:31,388 WARNING NaN or Inf found in input tensor.
2022-08-26 01:05:57,901 DEBUG TRAIN Batch 182/500 loss 37.671852 loss_att 22.387421 loss_ctc 73.335533 loss_ctc_origin 41.767303 loss_ctc0 146.994720 lr 0.00062145 rank 0
2022-08-26 01:06:26,495 DEBUG TRAIN Batch 182/600 loss 42.326149 loss_att 21.413422 loss_ctc 91.122513 loss_ctc_origin 44.537708 loss_ctc0 199.820374 lr 0.00062142 rank 0
2022-08-26 01:06:54,422 DEBUG TRAIN Batch 182/700 loss 18.839436 loss_att 8.818331 loss_ctc 42.222012 loss_ctc_origin 31.592869 loss_ctc0 67.023346 lr 0.00062139 rank 0
2022-08-26 01:07:23,201 DEBUG TRAIN Batch 182/800 loss 17.923735 loss_att 7.636581 loss_ctc 41.927090 loss_ctc_origin 27.979172 loss_ctc0 74.472229 lr 0.00062136 rank 0
2022-08-26 01:07:52,025 DEBUG TRAIN Batch 182/900 loss 24.178473 loss_att 9.800461 loss_ctc 57.727165 loss_ctc_origin 39.788700 loss_ctc0 99.583580 lr 0.00062133 rank 0
2022-08-26 01:08:20,617 DEBUG TRAIN Batch 182/1000 loss 39.475121 loss_att 26.706783 loss_ctc 69.267899 loss_ctc_origin 45.976456 loss_ctc0 123.614594 lr 0.00062130 rank 0
2022-08-26 01:08:49,422 DEBUG TRAIN Batch 182/1100 loss 58.794960 loss_att 35.372246 loss_ctc 113.447945 loss_ctc_origin 73.932152 loss_ctc0 205.651459 lr 0.00062127 rank 0
2022-08-26 01:09:17,523 DEBUG TRAIN Batch 182/1200 loss 18.572683 loss_att 10.245975 loss_ctc 38.001671 loss_ctc_origin 27.185757 loss_ctc0 63.238804 lr 0.00062124 rank 0
2022-08-26 01:09:48,037 DEBUG TRAIN Batch 182/1300 loss 16.151501 loss_att 6.802780 loss_ctc 37.965179 loss_ctc_origin 23.489666 loss_ctc0 71.741379 lr 0.00062121 rank 0
2022-08-26 01:10:16,774 DEBUG TRAIN Batch 182/1400 loss 20.866070 loss_att 8.258068 loss_ctc 50.284737 loss_ctc_origin 32.650875 loss_ctc0 91.430412 lr 0.00062118 rank 0
2022-08-26 01:10:50,628 DEBUG TRAIN Batch 182/1500 loss 48.027336 loss_att 31.619707 loss_ctc 86.311806 loss_ctc_origin 55.759529 loss_ctc0 157.600449 lr 0.00062115 rank 0
2022-08-26 01:11:19,844 DEBUG TRAIN Batch 182/1600 loss 49.171528 loss_att 28.664297 loss_ctc 97.021729 loss_ctc_origin 54.291012 loss_ctc0 196.726715 lr 0.00062112 rank 0
2022-08-26 01:11:48,866 DEBUG TRAIN Batch 182/1700 loss 22.901432 loss_att 12.615545 loss_ctc 46.901836 loss_ctc_origin 36.635811 loss_ctc0 70.855896 lr 0.00062109 rank 0
2022-08-26 01:12:16,748 DEBUG TRAIN Batch 182/1800 loss 17.485603 loss_att 7.473691 loss_ctc 40.846729 loss_ctc_origin 26.997580 loss_ctc0 73.161407 lr 0.00062106 rank 0
2022-08-26 01:12:45,591 DEBUG TRAIN Batch 182/1900 loss 21.197908 loss_att 8.596447 loss_ctc 50.601318 loss_ctc_origin 31.545527 loss_ctc0 95.064835 lr 0.00062103 rank 0
2022-08-26 01:13:14,239 DEBUG TRAIN Batch 182/2000 loss 37.098183 loss_att 21.269184 loss_ctc 74.032516 loss_ctc_origin 43.801842 loss_ctc0 144.570740 lr 0.00062100 rank 0
2022-08-26 01:13:42,978 DEBUG TRAIN Batch 182/2100 loss 45.450512 loss_att 24.138559 loss_ctc 95.178398 loss_ctc_origin 50.317295 loss_ctc0 199.854294 lr 0.00062097 rank 0
2022-08-26 01:14:10,419 DEBUG TRAIN Batch 182/2200 loss 17.577179 loss_att 10.131261 loss_ctc 34.950989 loss_ctc_origin 22.026527 loss_ctc0 65.108063 lr 0.00062094 rank 0
2022-08-26 01:14:39,131 DEBUG TRAIN Batch 182/2300 loss 16.497780 loss_att 6.167796 loss_ctc 40.601074 loss_ctc_origin 28.015167 loss_ctc0 69.968185 lr 0.00062091 rank 0
2022-08-26 01:15:06,906 DEBUG TRAIN Batch 182/2400 loss 18.128998 loss_att 6.598366 loss_ctc 45.033806 loss_ctc_origin 27.234631 loss_ctc0 86.565216 lr 0.00062088 rank 0
2022-08-26 01:15:35,276 DEBUG TRAIN Batch 182/2500 loss 33.452942 loss_att 17.254066 loss_ctc 71.250320 loss_ctc_origin 38.859959 loss_ctc0 146.827835 lr 0.00062085 rank 0
2022-08-26 01:15:35,949 WARNING NaN or Inf found in input tensor.
2022-08-26 01:16:02,807 DEBUG TRAIN Batch 182/2600 loss 51.239128 loss_att 29.162271 loss_ctc 102.751801 loss_ctc_origin 57.221745 loss_ctc0 208.988602 lr 0.00062082 rank 0
2022-08-26 01:16:30,924 DEBUG TRAIN Batch 182/2700 loss 15.074301 loss_att 7.222190 loss_ctc 33.395889 loss_ctc_origin 21.988480 loss_ctc0 60.013168 lr 0.00062079 rank 0
2022-08-26 01:16:42,273 WARNING NaN or Inf found in input tensor.
2022-08-26 01:16:59,529 DEBUG TRAIN Batch 182/2800 loss 23.575859 loss_att 10.121078 loss_ctc 54.970345 loss_ctc_origin 40.788071 loss_ctc0 88.062317 lr 0.00062076 rank 0
2022-08-26 01:17:28,507 DEBUG TRAIN Batch 182/2900 loss 22.948456 loss_att 10.395727 loss_ctc 52.238155 loss_ctc_origin 33.206963 loss_ctc0 96.644272 lr 0.00062073 rank 0
2022-08-26 01:18:03,231 DEBUG TRAIN Batch 182/3000 loss 40.433975 loss_att 26.790977 loss_ctc 72.267639 loss_ctc_origin 44.638916 loss_ctc0 136.734665 lr 0.00062071 rank 0
2022-08-26 01:18:32,003 DEBUG TRAIN Batch 182/3100 loss 46.186272 loss_att 27.605133 loss_ctc 89.542252 loss_ctc_origin 46.470085 loss_ctc0 190.043976 lr 0.00062068 rank 0
2022-08-26 01:19:00,767 DEBUG TRAIN Batch 182/3200 loss 18.549564 loss_att 9.449572 loss_ctc 39.782879 loss_ctc_origin 27.060339 loss_ctc0 69.468803 lr 0.00062065 rank 0
2022-08-26 01:19:29,416 DEBUG TRAIN Batch 182/3300 loss 18.206537 loss_att 7.739155 loss_ctc 42.630424 loss_ctc_origin 27.965679 loss_ctc0 76.848160 lr 0.00062062 rank 0
2022-08-26 01:19:57,452 DEBUG TRAIN Batch 182/3400 loss 22.738329 loss_att 9.102855 loss_ctc 54.554436 loss_ctc_origin 35.181747 loss_ctc0 99.757370 lr 0.00062059 rank 0
2022-08-26 01:20:25,713 DEBUG TRAIN Batch 182/3500 loss 37.229362 loss_att 25.039749 loss_ctc 65.671783 loss_ctc_origin 45.777069 loss_ctc0 112.092789 lr 0.00062056 rank 0
2022-08-26 01:20:54,015 DEBUG TRAIN Batch 182/3600 loss 43.859695 loss_att 20.609966 loss_ctc 98.109055 loss_ctc_origin 57.429321 loss_ctc0 193.028412 lr 0.00062053 rank 0
2022-08-26 01:21:22,422 DEBUG TRAIN Batch 182/3700 loss 19.557491 loss_att 10.516313 loss_ctc 40.653572 loss_ctc_origin 30.384651 loss_ctc0 64.614388 lr 0.00062050 rank 0
2022-08-26 01:21:50,455 DEBUG TRAIN Batch 182/3800 loss 18.570620 loss_att 8.450805 loss_ctc 42.183517 loss_ctc_origin 27.091671 loss_ctc0 77.397827 lr 0.00062047 rank 0
2022-08-26 01:22:20,779 DEBUG TRAIN Batch 182/3900 loss 21.450153 loss_att 9.463158 loss_ctc 49.419804 loss_ctc_origin 28.036427 loss_ctc0 99.314346 lr 0.00062044 rank 0
2022-08-26 01:22:49,804 DEBUG TRAIN Batch 182/4000 loss 48.638435 loss_att 33.561150 loss_ctc 83.818771 loss_ctc_origin 52.418499 loss_ctc0 157.086090 lr 0.00062041 rank 0
2022-08-26 01:23:17,275 DEBUG TRAIN Batch 182/4100 loss 51.852154 loss_att 30.881290 loss_ctc 100.784164 loss_ctc_origin 56.811054 loss_ctc0 203.388062 lr 0.00062038 rank 0
2022-08-26 01:23:45,311 DEBUG TRAIN Batch 182/4200 loss 16.969080 loss_att 8.921242 loss_ctc 35.747368 loss_ctc_origin 23.547733 loss_ctc0 64.213173 lr 0.00062035 rank 0
2022-08-26 01:24:14,449 DEBUG TRAIN Batch 182/4300 loss 17.387972 loss_att 7.783464 loss_ctc 39.798489 loss_ctc_origin 25.843410 loss_ctc0 72.360336 lr 0.00062032 rank 0
2022-08-26 01:24:42,020 DEBUG TRAIN Batch 182/4400 loss 21.451422 loss_att 9.211042 loss_ctc 50.012306 loss_ctc_origin 32.639496 loss_ctc0 90.548866 lr 0.00062029 rank 0
2022-08-26 01:25:17,055 DEBUG TRAIN Batch 182/4500 loss 43.528206 loss_att 27.648930 loss_ctc 80.579857 loss_ctc_origin 45.800308 loss_ctc0 161.732132 lr 0.00062026 rank 0
2022-08-26 01:25:32,442 WARNING NaN or Inf found in input tensor.
2022-08-26 01:25:46,288 DEBUG TRAIN Batch 182/4600 loss 49.474304 loss_att 26.657524 loss_ctc 102.713448 loss_ctc_origin 56.757313 loss_ctc0 209.944427 lr 0.00062023 rank 0
2022-08-26 01:26:13,103 DEBUG TRAIN Batch 182/4700 loss 18.726496 loss_att 10.238024 loss_ctc 38.532928 loss_ctc_origin 25.877871 loss_ctc0 68.061401 lr 0.00062020 rank 0
2022-08-26 01:26:39,828 DEBUG TRAIN Batch 182/4800 loss 18.054802 loss_att 6.416531 loss_ctc 45.210770 loss_ctc_origin 29.095161 loss_ctc0 82.813858 lr 0.00062017 rank 0
2022-08-26 01:27:07,666 DEBUG TRAIN Batch 182/4900 loss 22.392897 loss_att 8.938241 loss_ctc 53.787086 loss_ctc_origin 34.544544 loss_ctc0 98.686356 lr 0.00062014 rank 0
2022-08-26 01:27:35,846 DEBUG TRAIN Batch 182/5000 loss 37.687576 loss_att 24.851486 loss_ctc 67.638458 loss_ctc_origin 36.561531 loss_ctc0 140.151291 lr 0.00062011 rank 0
2022-08-26 01:27:43,721 WARNING NaN or Inf found in input tensor.
2022-08-26 01:28:03,522 DEBUG TRAIN Batch 182/5100 loss 48.123085 loss_att 24.518768 loss_ctc 103.199814 loss_ctc_origin 59.777729 loss_ctc0 204.518021 lr 0.00062008 rank 0
2022-08-26 01:28:30,268 DEBUG TRAIN Batch 182/5200 loss 19.541851 loss_att 9.759969 loss_ctc 42.366241 loss_ctc_origin 32.651447 loss_ctc0 65.034088 lr 0.00062005 rank 0
2022-08-26 01:28:57,721 DEBUG TRAIN Batch 182/5300 loss 18.372192 loss_att 7.253644 loss_ctc 44.315468 loss_ctc_origin 30.414675 loss_ctc0 76.750656 lr 0.00062002 rank 0
2022-08-26 01:29:14,320 WARNING NaN or Inf found in input tensor.
2022-08-26 01:29:25,569 DEBUG TRAIN Batch 182/5400 loss 23.385220 loss_att 9.018651 loss_ctc 56.907211 loss_ctc_origin 37.998268 loss_ctc0 101.028076 lr 0.00061999 rank 0
2022-08-26 01:29:53,563 DEBUG TRAIN Batch 182/5500 loss 47.912628 loss_att 33.100533 loss_ctc 82.474174 loss_ctc_origin 60.988541 loss_ctc0 132.607315 lr 0.00061996 rank 0
2022-08-26 01:30:20,933 DEBUG TRAIN Batch 182/5600 loss 51.653965 loss_att 32.926018 loss_ctc 95.352509 loss_ctc_origin 61.469372 loss_ctc0 174.413162 lr 0.00061993 rank 0
2022-08-26 01:30:43,336 DEBUG CV Batch 182/0 loss 11.840052 loss_att 8.512484 loss_ctc 19.604378 loss_ctc_origin 13.527081 loss_ctc0 33.784737 history loss 11.143578 rank 0
2022-08-26 01:30:53,551 DEBUG CV Batch 182/100 loss 20.070190 loss_att 16.105202 loss_ctc 29.321831 loss_ctc_origin 19.182474 loss_ctc0 52.980331 history loss 26.186770 rank 0
2022-08-26 01:31:03,130 DEBUG CV Batch 182/200 loss 25.368837 loss_att 19.776562 loss_ctc 38.417480 loss_ctc_origin 28.579659 loss_ctc0 61.372395 history loss 27.486525 rank 0
2022-08-26 01:31:12,939 DEBUG CV Batch 182/300 loss 22.138847 loss_att 16.964893 loss_ctc 34.211403 loss_ctc_origin 18.450565 loss_ctc0 70.986679 history loss 26.548191 rank 0
2022-08-26 01:31:22,740 DEBUG CV Batch 182/400 loss 37.182659 loss_att 30.247351 loss_ctc 53.365044 loss_ctc_origin 35.853294 loss_ctc0 94.225784 history loss 24.849566 rank 0
2022-08-26 01:31:32,764 DEBUG CV Batch 182/500 loss 16.406258 loss_att 11.920860 loss_ctc 26.872189 loss_ctc_origin 20.480869 loss_ctc0 41.785271 history loss 24.493677 rank 0
2022-08-26 01:31:42,474 DEBUG CV Batch 182/600 loss 16.954338 loss_att 11.705095 loss_ctc 29.202576 loss_ctc_origin 18.653645 loss_ctc0 53.816746 history loss 24.305866 rank 0
2022-08-26 01:31:51,915 DEBUG CV Batch 182/700 loss 18.123024 loss_att 12.670221 loss_ctc 30.846233 loss_ctc_origin 16.863262 loss_ctc0 63.473167 history loss 23.966636 rank 0
2022-08-26 01:32:01,727 DEBUG CV Batch 182/800 loss 21.240398 loss_att 16.656750 loss_ctc 31.935575 loss_ctc_origin 16.290823 loss_ctc0 68.439995 history loss 23.914145 rank 0
2022-08-26 01:32:11,643 INFO Epoch 182 CV info cv_loss 23.99670252956748
2022-08-26 01:32:11,643 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/182.pt
2022-08-26 01:32:12,118 INFO Epoch 183 TRAIN info lr 0.0006199043115168639
2022-08-26 01:32:12,121 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 01:32:39,130 DEBUG TRAIN Batch 183/0 loss 41.663139 loss_att 26.074627 loss_ctc 78.036331 loss_ctc_origin 48.983772 loss_ctc0 145.825623 lr 0.00061990 rank 0
2022-08-26 01:33:08,289 DEBUG TRAIN Batch 183/100 loss 50.512619 loss_att 27.084610 loss_ctc 105.177963 loss_ctc_origin 58.611794 loss_ctc0 213.832367 lr 0.00061987 rank 0
2022-08-26 01:33:36,681 DEBUG TRAIN Batch 183/200 loss 17.011499 loss_att 8.721567 loss_ctc 36.354675 loss_ctc_origin 24.846434 loss_ctc0 63.207237 lr 0.00061984 rank 0
2022-08-26 01:34:04,573 DEBUG TRAIN Batch 183/300 loss 15.646490 loss_att 6.207273 loss_ctc 37.671329 loss_ctc_origin 22.396275 loss_ctc0 73.313126 lr 0.00061981 rank 0
2022-08-26 01:34:31,892 DEBUG TRAIN Batch 183/400 loss 21.279902 loss_att 7.807177 loss_ctc 52.716259 loss_ctc_origin 33.710033 loss_ctc0 97.064117 lr 0.00061978 rank 0
2022-08-26 01:35:01,841 DEBUG TRAIN Batch 183/500 loss 44.264858 loss_att 28.937447 loss_ctc 80.028816 loss_ctc_origin 52.245232 loss_ctc0 144.857178 lr 0.00061975 rank 0
2022-08-26 01:35:30,190 DEBUG TRAIN Batch 183/600 loss 45.434605 loss_att 25.812756 loss_ctc 91.218918 loss_ctc_origin 52.190498 loss_ctc0 182.285233 lr 0.00061972 rank 0
2022-08-26 01:35:58,229 DEBUG TRAIN Batch 183/700 loss 19.794992 loss_att 9.996888 loss_ctc 42.657234 loss_ctc_origin 32.405815 loss_ctc0 66.577202 lr 0.00061969 rank 0
2022-08-26 01:36:25,746 DEBUG TRAIN Batch 183/800 loss 18.751228 loss_att 7.887823 loss_ctc 44.099171 loss_ctc_origin 29.908749 loss_ctc0 77.210159 lr 0.00061967 rank 0
2022-08-26 01:36:53,482 DEBUG TRAIN Batch 183/900 loss 19.933079 loss_att 8.711846 loss_ctc 46.115952 loss_ctc_origin 27.984577 loss_ctc0 88.422501 lr 0.00061964 rank 0
2022-08-26 01:37:22,056 DEBUG TRAIN Batch 183/1000 loss 42.856316 loss_att 29.094400 loss_ctc 74.967445 loss_ctc_origin 50.129738 loss_ctc0 132.922089 lr 0.00061961 rank 0
2022-08-26 01:37:36,770 WARNING NaN or Inf found in input tensor.
2022-08-26 01:37:50,235 DEBUG TRAIN Batch 183/1100 loss 45.891674 loss_att 24.686640 loss_ctc 95.370087 loss_ctc_origin 54.172462 loss_ctc0 191.497864 lr 0.00061958 rank 0
2022-08-26 01:38:19,230 DEBUG TRAIN Batch 183/1200 loss 20.740435 loss_att 10.569126 loss_ctc 44.473484 loss_ctc_origin 33.853100 loss_ctc0 69.254379 lr 0.00061955 rank 0
2022-08-26 01:38:47,453 DEBUG TRAIN Batch 183/1300 loss 18.821903 loss_att 7.649097 loss_ctc 44.891781 loss_ctc_origin 30.933968 loss_ctc0 77.460014 lr 0.00061952 rank 0
2022-08-26 01:39:16,086 DEBUG TRAIN Batch 183/1400 loss 19.162956 loss_att 6.818144 loss_ctc 47.967514 loss_ctc_origin 29.994711 loss_ctc0 89.904053 lr 0.00061949 rank 0
2022-08-26 01:39:50,735 DEBUG TRAIN Batch 183/1500 loss 43.037117 loss_att 26.862787 loss_ctc 80.777206 loss_ctc_origin 48.990067 loss_ctc0 154.947205 lr 0.00061946 rank 0
2022-08-26 01:40:19,713 DEBUG TRAIN Batch 183/1600 loss 45.793983 loss_att 24.869574 loss_ctc 94.617599 loss_ctc_origin 50.928482 loss_ctc0 196.558853 lr 0.00061943 rank 0
2022-08-26 01:40:48,143 DEBUG TRAIN Batch 183/1700 loss 16.170597 loss_att 7.387873 loss_ctc 36.663620 loss_ctc_origin 24.916069 loss_ctc0 64.074570 lr 0.00061940 rank 0
2022-08-26 01:41:16,682 DEBUG TRAIN Batch 183/1800 loss 21.267288 loss_att 9.076795 loss_ctc 49.711769 loss_ctc_origin 35.335915 loss_ctc0 83.255424 lr 0.00061937 rank 0
2022-08-26 01:41:45,060 DEBUG TRAIN Batch 183/1900 loss 20.306208 loss_att 7.551119 loss_ctc 50.068081 loss_ctc_origin 32.399597 loss_ctc0 91.294540 lr 0.00061934 rank 0
2022-08-26 01:42:14,535 DEBUG TRAIN Batch 183/2000 loss 38.249146 loss_att 22.208817 loss_ctc 75.676575 loss_ctc_origin 45.341545 loss_ctc0 146.458313 lr 0.00061931 rank 0
2022-08-26 01:42:42,404 DEBUG TRAIN Batch 183/2100 loss 41.540222 loss_att 21.556377 loss_ctc 88.169197 loss_ctc_origin 45.410851 loss_ctc0 187.938675 lr 0.00061928 rank 0
2022-08-26 01:43:11,428 DEBUG TRAIN Batch 183/2200 loss 16.482409 loss_att 8.301602 loss_ctc 35.570953 loss_ctc_origin 23.931450 loss_ctc0 62.729786 lr 0.00061925 rank 0
2022-08-26 01:43:39,370 DEBUG TRAIN Batch 183/2300 loss 22.231655 loss_att 8.792093 loss_ctc 53.590630 loss_ctc_origin 39.268829 loss_ctc0 87.008163 lr 0.00061922 rank 0
2022-08-26 01:44:04,535 WARNING NaN or Inf found in input tensor.
2022-08-26 01:44:09,064 DEBUG TRAIN Batch 183/2400 loss 23.277042 loss_att 9.159890 loss_ctc 56.217064 loss_ctc_origin 40.515636 loss_ctc0 92.853729 lr 0.00061919 rank 0
2022-08-26 01:44:37,591 DEBUG TRAIN Batch 183/2500 loss 50.480026 loss_att 34.871819 loss_ctc 86.899178 loss_ctc_origin 63.952606 loss_ctc0 140.441177 lr 0.00061916 rank 0
2022-08-26 01:45:06,510 DEBUG TRAIN Batch 183/2600 loss 47.203056 loss_att 25.277266 loss_ctc 98.363228 loss_ctc_origin 61.770332 loss_ctc0 183.746643 lr 0.00061913 rank 0
2022-08-26 01:45:34,775 WARNING NaN or Inf found in input tensor.
2022-08-26 01:45:36,378 DEBUG TRAIN Batch 183/2700 loss 15.895351 loss_att 8.261021 loss_ctc 33.708790 loss_ctc_origin 21.627098 loss_ctc0 61.899403 lr 0.00061910 rank 0
2022-08-26 01:46:05,703 DEBUG TRAIN Batch 183/2800 loss 18.045977 loss_att 8.188713 loss_ctc 41.046257 loss_ctc_origin 26.857777 loss_ctc0 74.152710 lr 0.00061907 rank 0
2022-08-26 01:46:29,648 WARNING NaN or Inf found in input tensor.
2022-08-26 01:46:34,077 DEBUG TRAIN Batch 183/2900 loss 24.987690 loss_att 10.799720 loss_ctc 58.092949 loss_ctc_origin 40.563648 loss_ctc0 98.994652 lr 0.00061904 rank 0
2022-08-26 01:47:09,162 DEBUG TRAIN Batch 183/3000 loss 48.301407 loss_att 30.656471 loss_ctc 89.472923 loss_ctc_origin 58.579140 loss_ctc0 161.558411 lr 0.00061901 rank 0
2022-08-26 01:47:38,553 DEBUG TRAIN Batch 183/3100 loss 52.843983 loss_att 29.988283 loss_ctc 106.173943 loss_ctc_origin 55.366711 loss_ctc0 224.724136 lr 0.00061898 rank 0
2022-08-26 01:48:07,438 DEBUG TRAIN Batch 183/3200 loss 18.729630 loss_att 7.057513 loss_ctc 45.964569 loss_ctc_origin 32.979565 loss_ctc0 76.262901 lr 0.00061895 rank 0
2022-08-26 01:48:36,482 DEBUG TRAIN Batch 183/3300 loss 20.991362 loss_att 8.269255 loss_ctc 50.676273 loss_ctc_origin 35.917259 loss_ctc0 85.113976 lr 0.00061892 rank 0
2022-08-26 01:49:06,178 DEBUG TRAIN Batch 183/3400 loss 20.690937 loss_att 8.187075 loss_ctc 49.866615 loss_ctc_origin 31.366795 loss_ctc0 93.032867 lr 0.00061889 rank 0
2022-08-26 01:49:35,907 DEBUG TRAIN Batch 183/3500 loss 39.828255 loss_att 24.221987 loss_ctc 76.242874 loss_ctc_origin 47.044304 loss_ctc0 144.372864 lr 0.00061886 rank 0
2022-08-26 01:49:56,827 WARNING NaN or Inf found in input tensor.
2022-08-26 01:50:03,877 DEBUG TRAIN Batch 183/3600 loss 50.611046 loss_att 29.522890 loss_ctc 99.816742 loss_ctc_origin 61.381332 loss_ctc0 189.499374 lr 0.00061883 rank 0
2022-08-26 01:50:31,908 DEBUG TRAIN Batch 183/3700 loss 18.720633 loss_att 10.051899 loss_ctc 38.947678 loss_ctc_origin 28.257782 loss_ctc0 63.890770 lr 0.00061880 rank 0
2022-08-26 01:50:37,456 WARNING NaN or Inf found in input tensor.
2022-08-26 01:51:00,545 DEBUG TRAIN Batch 183/3800 loss 15.840679 loss_att 6.448842 loss_ctc 37.754963 loss_ctc_origin 22.168142 loss_ctc0 74.124207 lr 0.00061877 rank 0
2022-08-26 01:51:28,584 DEBUG TRAIN Batch 183/3900 loss 21.051191 loss_att 8.639896 loss_ctc 50.010880 loss_ctc_origin 30.872030 loss_ctc0 94.668190 lr 0.00061875 rank 0
2022-08-26 01:51:57,771 DEBUG TRAIN Batch 183/4000 loss 36.720085 loss_att 22.500069 loss_ctc 69.900131 loss_ctc_origin 44.428429 loss_ctc0 129.334106 lr 0.00061872 rank 0
2022-08-26 01:52:26,246 DEBUG TRAIN Batch 183/4100 loss 44.855358 loss_att 28.476149 loss_ctc 83.073509 loss_ctc_origin 43.122200 loss_ctc0 176.293228 lr 0.00061869 rank 0
2022-08-26 01:52:52,497 WARNING NaN or Inf found in input tensor.
2022-08-26 01:52:54,075 DEBUG TRAIN Batch 183/4200 loss 16.351858 loss_att 7.931487 loss_ctc 35.999390 loss_ctc_origin 24.553204 loss_ctc0 62.707153 lr 0.00061866 rank 0
2022-08-26 01:53:23,309 DEBUG TRAIN Batch 183/4300 loss 19.013008 loss_att 8.256178 loss_ctc 44.112274 loss_ctc_origin 29.952415 loss_ctc0 77.151947 lr 0.00061863 rank 0
2022-08-26 01:53:51,480 DEBUG TRAIN Batch 183/4400 loss 18.033962 loss_att 6.709317 loss_ctc 44.458138 loss_ctc_origin 27.219913 loss_ctc0 84.680664 lr 0.00061860 rank 0
2022-08-26 01:54:25,716 DEBUG TRAIN Batch 183/4500 loss 36.633942 loss_att 24.645195 loss_ctc 64.607681 loss_ctc_origin 39.394440 loss_ctc0 123.438583 lr 0.00061857 rank 0
2022-08-26 01:54:54,604 DEBUG TRAIN Batch 183/4600 loss 43.443306 loss_att 22.966946 loss_ctc 91.221466 loss_ctc_origin 51.878815 loss_ctc0 183.020996 lr 0.00061854 rank 0
2022-08-26 01:55:22,600 DEBUG TRAIN Batch 183/4700 loss 21.168402 loss_att 12.805061 loss_ctc 40.682861 loss_ctc_origin 29.434467 loss_ctc0 66.929115 lr 0.00061851 rank 0
2022-08-26 01:55:51,877 DEBUG TRAIN Batch 183/4800 loss 18.686680 loss_att 8.689815 loss_ctc 42.012699 loss_ctc_origin 26.765547 loss_ctc0 77.589386 lr 0.00061848 rank 0
2022-08-26 01:56:15,922 WARNING NaN or Inf found in input tensor.
2022-08-26 01:56:20,361 DEBUG TRAIN Batch 183/4900 loss 20.140884 loss_att 8.841619 loss_ctc 46.505836 loss_ctc_origin 28.124170 loss_ctc0 89.396385 lr 0.00061845 rank 0
2022-08-26 01:56:49,312 DEBUG TRAIN Batch 183/5000 loss 42.920959 loss_att 30.540150 loss_ctc 71.809517 loss_ctc_origin 48.108189 loss_ctc0 127.112617 lr 0.00061842 rank 0
2022-08-26 01:56:49,993 WARNING NaN or Inf found in input tensor.
2022-08-26 01:57:17,556 DEBUG TRAIN Batch 183/5100 loss 48.981667 loss_att 25.846153 loss_ctc 102.964539 loss_ctc_origin 56.954842 loss_ctc0 210.320496 lr 0.00061839 rank 0
2022-08-26 01:57:45,932 DEBUG TRAIN Batch 183/5200 loss 19.486217 loss_att 9.092816 loss_ctc 43.737484 loss_ctc_origin 30.171787 loss_ctc0 75.390778 lr 0.00061836 rank 0
2022-08-26 01:58:14,589 DEBUG TRAIN Batch 183/5300 loss 18.055710 loss_att 6.895296 loss_ctc 44.096676 loss_ctc_origin 30.140610 loss_ctc0 76.660828 lr 0.00061833 rank 0
2022-08-26 01:58:44,262 DEBUG TRAIN Batch 183/5400 loss 22.923670 loss_att 9.805204 loss_ctc 53.533417 loss_ctc_origin 37.044399 loss_ctc0 92.007782 lr 0.00061830 rank 0
2022-08-26 01:59:12,061 DEBUG TRAIN Batch 183/5500 loss 40.369202 loss_att 25.261129 loss_ctc 75.621376 loss_ctc_origin 47.832336 loss_ctc0 140.462463 lr 0.00061827 rank 0
2022-08-26 01:59:32,664 WARNING NaN or Inf found in input tensor.
2022-08-26 01:59:40,016 DEBUG TRAIN Batch 183/5600 loss 34.794220 loss_att 17.402521 loss_ctc 75.374847 loss_ctc_origin 35.321285 loss_ctc0 168.833145 lr 0.00061824 rank 0
2022-08-26 02:00:03,417 DEBUG CV Batch 183/0 loss 11.850222 loss_att 8.799213 loss_ctc 18.969242 loss_ctc_origin 12.386562 loss_ctc0 34.328831 history loss 11.153150 rank 0
2022-08-26 02:00:14,265 DEBUG CV Batch 183/100 loss 20.555004 loss_att 16.821337 loss_ctc 29.266895 loss_ctc_origin 19.171917 loss_ctc0 52.821846 history loss 26.074336 rank 0
2022-08-26 02:00:23,986 DEBUG CV Batch 183/200 loss 24.870766 loss_att 19.507692 loss_ctc 37.384605 loss_ctc_origin 26.695879 loss_ctc0 62.324970 history loss 27.362537 rank 0
2022-08-26 02:00:34,238 DEBUG CV Batch 183/300 loss 23.045578 loss_att 17.353840 loss_ctc 36.326298 loss_ctc_origin 20.860775 loss_ctc0 72.412521 history loss 26.506206 rank 0
2022-08-26 02:00:45,052 DEBUG CV Batch 183/400 loss 36.423679 loss_att 29.293404 loss_ctc 53.060986 loss_ctc_origin 35.656307 loss_ctc0 93.671898 history loss 24.855649 rank 0
2022-08-26 02:00:55,702 DEBUG CV Batch 183/500 loss 16.645084 loss_att 12.251539 loss_ctc 26.896687 loss_ctc_origin 20.348663 loss_ctc0 42.175407 history loss 24.530889 rank 0
2022-08-26 02:01:06,536 DEBUG CV Batch 183/600 loss 17.742485 loss_att 12.378988 loss_ctc 30.257305 loss_ctc_origin 20.110832 loss_ctc0 53.932411 history loss 24.392212 rank 0
2022-08-26 02:01:16,659 DEBUG CV Batch 183/700 loss 18.540176 loss_att 12.974485 loss_ctc 31.526787 loss_ctc_origin 18.007008 loss_ctc0 63.072933 history loss 24.068774 rank 0
2022-08-26 02:01:27,186 DEBUG CV Batch 183/800 loss 21.592808 loss_att 16.894554 loss_ctc 32.555401 loss_ctc_origin 16.811272 loss_ctc0 69.291695 history loss 24.019784 rank 0
2022-08-26 02:01:37,772 INFO Epoch 183 CV info cv_loss 24.100853313510747
2022-08-26 02:01:37,773 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/183.pt
2022-08-26 02:01:38,230 INFO Epoch 184 TRAIN info lr 0.0006182174939370617
2022-08-26 02:01:38,233 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 02:02:05,121 DEBUG TRAIN Batch 184/0 loss 32.709446 loss_att 20.705044 loss_ctc 60.719719 loss_ctc_origin 32.520058 loss_ctc0 126.518913 lr 0.00061822 rank 0
2022-08-26 02:02:33,717 DEBUG TRAIN Batch 184/100 loss 44.984741 loss_att 24.213360 loss_ctc 93.451302 loss_ctc_origin 49.977390 loss_ctc0 194.890427 lr 0.00061819 rank 0
2022-08-26 02:03:01,607 DEBUG TRAIN Batch 184/200 loss 16.449760 loss_att 8.342828 loss_ctc 35.365936 loss_ctc_origin 24.325386 loss_ctc0 61.127216 lr 0.00061816 rank 0
2022-08-26 02:03:30,464 DEBUG TRAIN Batch 184/300 loss 15.716402 loss_att 6.192454 loss_ctc 37.938946 loss_ctc_origin 23.507061 loss_ctc0 71.613342 lr 0.00061813 rank 0
2022-08-26 02:03:53,938 WARNING NaN or Inf found in input tensor.
2022-08-26 02:03:58,289 DEBUG TRAIN Batch 184/400 loss 18.496197 loss_att 7.747576 loss_ctc 43.576309 loss_ctc_origin 25.655262 loss_ctc0 85.392090 lr 0.00061810 rank 0
2022-08-26 02:04:28,236 DEBUG TRAIN Batch 184/500 loss 33.702778 loss_att 22.802156 loss_ctc 59.137558 loss_ctc_origin 38.769012 loss_ctc0 106.664169 lr 0.00061807 rank 0
2022-08-26 02:04:57,244 DEBUG TRAIN Batch 184/600 loss 38.048691 loss_att 21.315908 loss_ctc 77.091843 loss_ctc_origin 38.014938 loss_ctc0 168.271271 lr 0.00061804 rank 0
2022-08-26 02:05:27,019 DEBUG TRAIN Batch 184/700 loss 16.810780 loss_att 7.363931 loss_ctc 38.853420 loss_ctc_origin 25.229481 loss_ctc0 70.642609 lr 0.00061801 rank 0
2022-08-26 02:05:55,457 DEBUG TRAIN Batch 184/800 loss 19.756506 loss_att 7.728130 loss_ctc 47.822716 loss_ctc_origin 32.631561 loss_ctc0 83.268738 lr 0.00061798 rank 0
2022-08-26 02:06:23,893 DEBUG TRAIN Batch 184/900 loss 22.279772 loss_att 9.329460 loss_ctc 52.497162 loss_ctc_origin 34.682022 loss_ctc0 94.065826 lr 0.00061795 rank 0
2022-08-26 02:06:52,107 DEBUG TRAIN Batch 184/1000 loss 39.155113 loss_att 26.351000 loss_ctc 69.031372 loss_ctc_origin 47.040070 loss_ctc0 120.344398 lr 0.00061792 rank 0
2022-08-26 02:07:21,399 DEBUG TRAIN Batch 184/1100 loss 45.499683 loss_att 25.778067 loss_ctc 91.516785 loss_ctc_origin 55.026459 loss_ctc0 176.660889 lr 0.00061789 rank 0
2022-08-26 02:07:50,552 DEBUG TRAIN Batch 184/1200 loss 20.333000 loss_att 9.775312 loss_ctc 44.967606 loss_ctc_origin 33.871738 loss_ctc0 70.857956 lr 0.00061786 rank 0
2022-08-26 02:08:19,223 DEBUG TRAIN Batch 184/1300 loss 18.635015 loss_att 7.125455 loss_ctc 45.490654 loss_ctc_origin 28.389641 loss_ctc0 85.393021 lr 0.00061783 rank 0
2022-08-26 02:08:48,607 DEBUG TRAIN Batch 184/1400 loss 23.171200 loss_att 10.113110 loss_ctc 53.640076 loss_ctc_origin 36.736851 loss_ctc0 93.080933 lr 0.00061780 rank 0
2022-08-26 02:09:24,074 DEBUG TRAIN Batch 184/1500 loss 41.719254 loss_att 27.122808 loss_ctc 75.777618 loss_ctc_origin 45.958664 loss_ctc0 145.355164 lr 0.00061777 rank 0
2022-08-26 02:09:53,156 DEBUG TRAIN Batch 184/1600 loss 51.100342 loss_att 30.386120 loss_ctc 99.433517 loss_ctc_origin 56.566589 loss_ctc0 199.456329 lr 0.00061774 rank 0
2022-08-26 02:10:19,873 WARNING NaN or Inf found in input tensor.
2022-08-26 02:10:21,515 DEBUG TRAIN Batch 184/1700 loss 18.281736 loss_att 9.379877 loss_ctc 39.052742 loss_ctc_origin 28.932356 loss_ctc0 62.666965 lr 0.00061771 rank 0
2022-08-26 02:10:27,027 WARNING NaN or Inf found in input tensor.
2022-08-26 02:10:50,175 DEBUG TRAIN Batch 184/1800 loss 17.257418 loss_att 6.504778 loss_ctc 42.346909 loss_ctc_origin 27.649832 loss_ctc0 76.640091 lr 0.00061769 rank 0
2022-08-26 02:11:18,789 DEBUG TRAIN Batch 184/1900 loss 19.007759 loss_att 7.670603 loss_ctc 45.461121 loss_ctc_origin 26.859180 loss_ctc0 88.865646 lr 0.00061766 rank 0
2022-08-26 02:11:47,541 DEBUG TRAIN Batch 184/2000 loss 51.963623 loss_att 36.054207 loss_ctc 89.085594 loss_ctc_origin 57.621651 loss_ctc0 162.501450 lr 0.00061763 rank 0
2022-08-26 02:12:08,344 WARNING NaN or Inf found in input tensor.
2022-08-26 02:12:16,119 WARNING NaN or Inf found in input tensor.
2022-08-26 02:12:16,166 DEBUG TRAIN Batch 184/2100 loss nan loss_att 30.436142 loss_ctc nan loss_ctc_origin 55.835495 loss_ctc0 nan lr 0.00061760 rank 0
2022-08-26 02:12:43,244 WARNING NaN or Inf found in input tensor.
2022-08-26 02:12:44,872 DEBUG TRAIN Batch 184/2200 loss 22.110142 loss_att 10.749082 loss_ctc 48.619286 loss_ctc_origin 36.873917 loss_ctc0 76.025154 lr 0.00061757 rank 0
2022-08-26 02:12:50,353 WARNING NaN or Inf found in input tensor.
2022-08-26 02:13:13,750 DEBUG TRAIN Batch 184/2300 loss 17.578346 loss_att 7.455619 loss_ctc 41.198044 loss_ctc_origin 27.075092 loss_ctc0 74.151596 lr 0.00061754 rank 0
2022-08-26 02:13:42,663 DEBUG TRAIN Batch 184/2400 loss 21.055771 loss_att 8.578579 loss_ctc 50.169216 loss_ctc_origin 30.593340 loss_ctc0 95.846252 lr 0.00061751 rank 0
2022-08-26 02:14:10,755 DEBUG TRAIN Batch 184/2500 loss 32.664467 loss_att 19.549860 loss_ctc 63.265217 loss_ctc_origin 34.107868 loss_ctc0 131.299026 lr 0.00061748 rank 0
2022-08-26 02:14:39,274 DEBUG TRAIN Batch 184/2600 loss 54.593178 loss_att 30.943546 loss_ctc 109.775658 loss_ctc_origin 66.971413 loss_ctc0 209.652222 lr 0.00061745 rank 0
2022-08-26 02:15:07,461 DEBUG TRAIN Batch 184/2700 loss 19.803122 loss_att 10.676129 loss_ctc 41.099434 loss_ctc_origin 29.283991 loss_ctc0 68.668800 lr 0.00061742 rank 0
2022-08-26 02:15:36,767 DEBUG TRAIN Batch 184/2800 loss 17.895845 loss_att 6.928720 loss_ctc 43.485802 loss_ctc_origin 26.514458 loss_ctc0 83.085594 lr 0.00061739 rank 0
2022-08-26 02:16:05,740 DEBUG TRAIN Batch 184/2900 loss 18.711029 loss_att 6.525640 loss_ctc 47.143600 loss_ctc_origin 27.297440 loss_ctc0 93.451309 lr 0.00061736 rank 0
2022-08-26 02:16:41,259 DEBUG TRAIN Batch 184/3000 loss 48.088020 loss_att 31.720583 loss_ctc 86.278709 loss_ctc_origin 49.352829 loss_ctc0 172.439102 lr 0.00061733 rank 0
2022-08-26 02:17:09,929 WARNING NaN or Inf found in input tensor.
2022-08-26 02:17:09,972 DEBUG TRAIN Batch 184/3100 loss nan loss_att 29.598690 loss_ctc nan loss_ctc_origin 58.644447 loss_ctc0 nan lr 0.00061730 rank 0
2022-08-26 02:17:38,266 DEBUG TRAIN Batch 184/3200 loss 16.023485 loss_att 6.934537 loss_ctc 37.231030 loss_ctc_origin 24.768209 loss_ctc0 66.310944 lr 0.00061727 rank 0
2022-08-26 02:18:06,511 DEBUG TRAIN Batch 184/3300 loss 20.654200 loss_att 8.437550 loss_ctc 49.159714 loss_ctc_origin 35.687447 loss_ctc0 80.595001 lr 0.00061724 rank 0
2022-08-26 02:18:34,626 DEBUG TRAIN Batch 184/3400 loss 20.646347 loss_att 8.766285 loss_ctc 48.366493 loss_ctc_origin 29.504681 loss_ctc0 92.377380 lr 0.00061721 rank 0
2022-08-26 02:19:03,665 DEBUG TRAIN Batch 184/3500 loss 52.702423 loss_att 33.306175 loss_ctc 97.960327 loss_ctc_origin 64.679825 loss_ctc0 175.614838 lr 0.00061719 rank 0
2022-08-26 02:19:31,529 DEBUG TRAIN Batch 184/3600 loss 47.123013 loss_att 26.490438 loss_ctc 95.265686 loss_ctc_origin 48.874310 loss_ctc0 203.512207 lr 0.00061716 rank 0
2022-08-26 02:20:00,202 DEBUG TRAIN Batch 184/3700 loss 20.224100 loss_att 9.907529 loss_ctc 44.296097 loss_ctc_origin 30.809509 loss_ctc0 75.764793 lr 0.00061713 rank 0
2022-08-26 02:20:29,185 DEBUG TRAIN Batch 184/3800 loss 20.801708 loss_att 9.840525 loss_ctc 46.377800 loss_ctc_origin 34.884163 loss_ctc0 73.196289 lr 0.00061710 rank 0
2022-08-26 02:20:57,541 DEBUG TRAIN Batch 184/3900 loss 24.388441 loss_att 9.896791 loss_ctc 58.202290 loss_ctc_origin 40.674644 loss_ctc0 99.100128 lr 0.00061707 rank 0
2022-08-26 02:21:26,422 DEBUG TRAIN Batch 184/4000 loss 51.721199 loss_att 33.779625 loss_ctc 93.584869 loss_ctc_origin 55.992645 loss_ctc0 181.300049 lr 0.00061704 rank 0
2022-08-26 02:21:54,373 DEBUG TRAIN Batch 184/4100 loss 51.642281 loss_att 28.667328 loss_ctc 105.250504 loss_ctc_origin 57.252750 loss_ctc0 217.245270 lr 0.00061701 rank 0
2022-08-26 02:22:22,147 DEBUG TRAIN Batch 184/4200 loss 17.599709 loss_att 8.509947 loss_ctc 38.809155 loss_ctc_origin 26.266157 loss_ctc0 68.076141 lr 0.00061698 rank 0
2022-08-26 02:22:51,517 DEBUG TRAIN Batch 184/4300 loss 15.597383 loss_att 5.976656 loss_ctc 38.045750 loss_ctc_origin 22.726063 loss_ctc0 73.791679 lr 0.00061695 rank 0
2022-08-26 02:23:19,070 DEBUG TRAIN Batch 184/4400 loss 21.946918 loss_att 8.196449 loss_ctc 54.031342 loss_ctc_origin 35.873882 loss_ctc0 96.398743 lr 0.00061692 rank 0
2022-08-26 02:23:55,793 DEBUG TRAIN Batch 184/4500 loss 43.438438 loss_att 27.799158 loss_ctc 79.930099 loss_ctc_origin 46.626076 loss_ctc0 157.639496 lr 0.00061689 rank 0
2022-08-26 02:24:24,903 DEBUG TRAIN Batch 184/4600 loss 34.796482 loss_att 18.955511 loss_ctc 71.758743 loss_ctc_origin 32.580666 loss_ctc0 163.174255 lr 0.00061686 rank 0
2022-08-26 02:24:53,507 DEBUG TRAIN Batch 184/4700 loss 21.700977 loss_att 12.311178 loss_ctc 43.610512 loss_ctc_origin 31.783695 loss_ctc0 71.206421 lr 0.00061683 rank 0
2022-08-26 02:25:22,183 DEBUG TRAIN Batch 184/4800 loss 21.176161 loss_att 8.495472 loss_ctc 50.764431 loss_ctc_origin 35.095596 loss_ctc0 87.325043 lr 0.00061680 rank 0
2022-08-26 02:25:51,150 DEBUG TRAIN Batch 184/4900 loss 24.615259 loss_att 10.651787 loss_ctc 57.196693 loss_ctc_origin 37.871712 loss_ctc0 102.288315 lr 0.00061677 rank 0
2022-08-26 02:26:12,942 WARNING NaN or Inf found in input tensor.
2022-08-26 02:26:20,163 DEBUG TRAIN Batch 184/5000 loss 46.175644 loss_att 27.117800 loss_ctc 90.643936 loss_ctc_origin 54.386337 loss_ctc0 175.244995 lr 0.00061674 rank 0
2022-08-26 02:26:48,976 DEBUG TRAIN Batch 184/5100 loss 51.037262 loss_att 27.948666 loss_ctc 104.910652 loss_ctc_origin 54.608810 loss_ctc0 222.281616 lr 0.00061672 rank 0
2022-08-26 02:27:17,846 DEBUG TRAIN Batch 184/5200 loss 21.535717 loss_att 11.230211 loss_ctc 45.581894 loss_ctc_origin 33.383537 loss_ctc0 74.044724 lr 0.00061669 rank 0
2022-08-26 02:27:46,580 DEBUG TRAIN Batch 184/5300 loss 19.711712 loss_att 8.816250 loss_ctc 45.134453 loss_ctc_origin 29.629858 loss_ctc0 81.311844 lr 0.00061666 rank 0
2022-08-26 02:28:15,311 DEBUG TRAIN Batch 184/5400 loss 21.960329 loss_att 8.581410 loss_ctc 53.177803 loss_ctc_origin 33.249100 loss_ctc0 99.678108 lr 0.00061663 rank 0
2022-08-26 02:28:45,434 DEBUG TRAIN Batch 184/5500 loss 38.297325 loss_att 23.213970 loss_ctc 73.491821 loss_ctc_origin 41.414444 loss_ctc0 148.339020 lr 0.00061660 rank 0
2022-08-26 02:29:13,302 DEBUG TRAIN Batch 184/5600 loss 57.491539 loss_att 33.059887 loss_ctc 114.498734 loss_ctc_origin 63.628330 loss_ctc0 233.196335 lr 0.00061657 rank 0
2022-08-26 02:29:36,668 DEBUG CV Batch 184/0 loss 11.974931 loss_att 8.758898 loss_ctc 19.479008 loss_ctc_origin 13.147366 loss_ctc0 34.252838 history loss 11.270523 rank 0
2022-08-26 02:29:47,627 DEBUG CV Batch 184/100 loss 20.180384 loss_att 16.068291 loss_ctc 29.775265 loss_ctc_origin 19.900841 loss_ctc0 52.815582 history loss 26.126099 rank 0
2022-08-26 02:29:58,146 DEBUG CV Batch 184/200 loss 24.185886 loss_att 18.373795 loss_ctc 37.747437 loss_ctc_origin 27.032673 loss_ctc0 62.748554 history loss 27.344802 rank 0
2022-08-26 02:30:07,921 DEBUG CV Batch 184/300 loss 21.764484 loss_att 16.044109 loss_ctc 35.112030 loss_ctc_origin 19.261692 loss_ctc0 72.096146 history loss 26.515114 rank 0
2022-08-26 02:30:18,799 DEBUG CV Batch 184/400 loss 38.051903 loss_att 30.671135 loss_ctc 55.273693 loss_ctc_origin 38.384354 loss_ctc0 94.682152 history loss 24.853473 rank 0
2022-08-26 02:30:30,049 DEBUG CV Batch 184/500 loss 15.859962 loss_att 11.493202 loss_ctc 26.049068 loss_ctc_origin 18.995735 loss_ctc0 42.506844 history loss 24.547984 rank 0
2022-08-26 02:30:40,791 DEBUG CV Batch 184/600 loss 17.524155 loss_att 12.609659 loss_ctc 28.991306 loss_ctc_origin 18.166870 loss_ctc0 54.248318 history loss 24.399152 rank 0
2022-08-26 02:30:51,219 DEBUG CV Batch 184/700 loss 18.459900 loss_att 12.950503 loss_ctc 31.315159 loss_ctc_origin 17.360430 loss_ctc0 63.876190 history loss 24.083456 rank 0
2022-08-26 02:31:01,737 DEBUG CV Batch 184/800 loss 22.372097 loss_att 17.766991 loss_ctc 33.117340 loss_ctc_origin 17.632685 loss_ctc0 69.248199 history loss 24.057494 rank 0
2022-08-26 02:31:12,284 INFO Epoch 184 CV info cv_loss 24.129111398545266
2022-08-26 02:31:12,284 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/184.pt
2022-08-26 02:31:12,767 INFO Epoch 185 TRAIN info lr 0.0006165443718058283
2022-08-26 02:31:12,771 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 02:31:39,087 DEBUG TRAIN Batch 185/0 loss 44.646889 loss_att 29.479488 loss_ctc 80.037491 loss_ctc_origin 47.505501 loss_ctc0 155.945465 lr 0.00061654 rank 0
2022-08-26 02:32:07,794 DEBUG TRAIN Batch 185/100 loss 47.942795 loss_att 27.125229 loss_ctc 96.517105 loss_ctc_origin 48.582031 loss_ctc0 208.365601 lr 0.00061651 rank 0
2022-08-26 02:32:35,385 WARNING NaN or Inf found in input tensor.
2022-08-26 02:32:36,948 DEBUG TRAIN Batch 185/200 loss 19.389648 loss_att 10.832893 loss_ctc 39.355412 loss_ctc_origin 29.984596 loss_ctc0 61.220642 lr 0.00061648 rank 0
2022-08-26 02:32:49,544 WARNING NaN or Inf found in input tensor.
2022-08-26 02:33:06,326 DEBUG TRAIN Batch 185/300 loss 16.929054 loss_att 7.380828 loss_ctc 39.208252 loss_ctc_origin 24.074703 loss_ctc0 74.519867 lr 0.00061646 rank 0
2022-08-26 02:33:35,230 DEBUG TRAIN Batch 185/400 loss 16.830124 loss_att 5.904486 loss_ctc 42.323280 loss_ctc_origin 23.542404 loss_ctc0 86.145325 lr 0.00061643 rank 0
2022-08-26 02:33:43,798 WARNING NaN or Inf found in input tensor.
2022-08-26 02:34:03,804 DEBUG TRAIN Batch 185/500 loss 38.950195 loss_att 24.630831 loss_ctc 72.362053 loss_ctc_origin 41.755035 loss_ctc0 143.778427 lr 0.00061640 rank 0
2022-08-26 02:34:04,475 WARNING NaN or Inf found in input tensor.
2022-08-26 02:34:33,886 DEBUG TRAIN Batch 185/600 loss 49.883648 loss_att 24.969440 loss_ctc 108.016800 loss_ctc_origin 53.918671 loss_ctc0 234.245773 lr 0.00061637 rank 0
2022-08-26 02:35:02,446 DEBUG TRAIN Batch 185/700 loss 15.829394 loss_att 7.347641 loss_ctc 35.620152 loss_ctc_origin 22.802200 loss_ctc0 65.528702 lr 0.00061634 rank 0
2022-08-26 02:35:30,591 DEBUG TRAIN Batch 185/800 loss 16.678814 loss_att 6.054833 loss_ctc 41.468102 loss_ctc_origin 28.148880 loss_ctc0 72.546280 lr 0.00061631 rank 0
2022-08-26 02:35:58,701 DEBUG TRAIN Batch 185/900 loss 18.241575 loss_att 6.547782 loss_ctc 45.527092 loss_ctc_origin 25.543596 loss_ctc0 92.155235 lr 0.00061628 rank 0
2022-08-26 02:36:26,952 DEBUG TRAIN Batch 185/1000 loss 41.941765 loss_att 27.246733 loss_ctc 76.230171 loss_ctc_origin 46.988976 loss_ctc0 144.459625 lr 0.00061625 rank 0
2022-08-26 02:36:48,188 WARNING NaN or Inf found in input tensor.
2022-08-26 02:36:54,779 DEBUG TRAIN Batch 185/1100 loss 55.124077 loss_att 30.089468 loss_ctc 113.538170 loss_ctc_origin 62.273594 loss_ctc0 233.155518 lr 0.00061622 rank 0
2022-08-26 02:37:23,067 DEBUG TRAIN Batch 185/1200 loss 22.605900 loss_att 12.144537 loss_ctc 47.015747 loss_ctc_origin 35.378281 loss_ctc0 74.169846 lr 0.00061619 rank 0
2022-08-26 02:37:52,272 DEBUG TRAIN Batch 185/1300 loss 18.784077 loss_att 6.916267 loss_ctc 46.475628 loss_ctc_origin 29.805912 loss_ctc0 85.371628 lr 0.00061616 rank 0
2022-08-26 02:38:20,420 DEBUG TRAIN Batch 185/1400 loss 20.831114 loss_att 8.583068 loss_ctc 49.409885 loss_ctc_origin 28.817211 loss_ctc0 97.459457 lr 0.00061613 rank 0
2022-08-26 02:38:56,819 DEBUG TRAIN Batch 185/1500 loss 43.018749 loss_att 27.179012 loss_ctc 79.978134 loss_ctc_origin 50.597298 loss_ctc0 148.533417 lr 0.00061610 rank 0
2022-08-26 02:39:04,514 WARNING NaN or Inf found in input tensor.
2022-08-26 02:39:25,346 DEBUG TRAIN Batch 185/1600 loss 50.479202 loss_att 27.693533 loss_ctc 103.645760 loss_ctc_origin 48.830948 loss_ctc0 231.546967 lr 0.00061608 rank 0
2022-08-26 02:39:52,419 WARNING NaN or Inf found in input tensor.
2022-08-26 02:39:53,933 DEBUG TRAIN Batch 185/1700 loss 18.227341 loss_att 9.532001 loss_ctc 38.516464 loss_ctc_origin 26.572269 loss_ctc0 66.386261 lr 0.00061605 rank 0
2022-08-26 02:40:23,517 DEBUG TRAIN Batch 185/1800 loss 19.419832 loss_att 8.143934 loss_ctc 45.730263 loss_ctc_origin 33.086197 loss_ctc0 75.233078 lr 0.00061602 rank 0
2022-08-26 02:40:33,862 WARNING NaN or Inf found in input tensor.
2022-08-26 02:40:47,621 WARNING NaN or Inf found in input tensor.
2022-08-26 02:40:51,861 DEBUG TRAIN Batch 185/1900 loss 19.830603 loss_att 8.392676 loss_ctc 46.519096 loss_ctc_origin 28.375874 loss_ctc0 88.853271 lr 0.00061599 rank 0
2022-08-26 02:41:21,034 DEBUG TRAIN Batch 185/2000 loss 41.085072 loss_att 25.893082 loss_ctc 76.533051 loss_ctc_origin 47.512154 loss_ctc0 144.248489 lr 0.00061596 rank 0
2022-08-26 02:41:49,791 DEBUG TRAIN Batch 185/2100 loss 42.176987 loss_att 20.556242 loss_ctc 92.625389 loss_ctc_origin 42.935711 loss_ctc0 208.567963 lr 0.00061593 rank 0
2022-08-26 02:42:18,187 DEBUG TRAIN Batch 185/2200 loss 18.618534 loss_att 9.705268 loss_ctc 39.416153 loss_ctc_origin 28.078587 loss_ctc0 65.870476 lr 0.00061590 rank 0
2022-08-26 02:42:46,908 DEBUG TRAIN Batch 185/2300 loss 21.686626 loss_att 9.769324 loss_ctc 49.493660 loss_ctc_origin 34.725845 loss_ctc0 83.951881 lr 0.00061587 rank 0
2022-08-26 02:43:16,175 DEBUG TRAIN Batch 185/2400 loss 19.861910 loss_att 8.202284 loss_ctc 47.067703 loss_ctc_origin 28.005255 loss_ctc0 91.546753 lr 0.00061584 rank 0
2022-08-26 02:43:44,719 DEBUG TRAIN Batch 185/2500 loss 37.447777 loss_att 23.990786 loss_ctc 68.847427 loss_ctc_origin 41.479153 loss_ctc0 132.706726 lr 0.00061581 rank 0
2022-08-26 02:44:14,115 DEBUG TRAIN Batch 185/2600 loss 48.235519 loss_att 25.553551 loss_ctc 101.160110 loss_ctc_origin 50.086998 loss_ctc0 220.330688 lr 0.00061578 rank 0
2022-08-26 02:44:43,334 DEBUG TRAIN Batch 185/2700 loss 19.050016 loss_att 9.538765 loss_ctc 41.242935 loss_ctc_origin 29.657875 loss_ctc0 68.274734 lr 0.00061575 rank 0
2022-08-26 02:45:12,009 DEBUG TRAIN Batch 185/2800 loss 23.089130 loss_att 10.668818 loss_ctc 52.069862 loss_ctc_origin 37.460304 loss_ctc0 86.158829 lr 0.00061572 rank 0
2022-08-26 02:45:41,290 DEBUG TRAIN Batch 185/2900 loss 24.740074 loss_att 10.977290 loss_ctc 56.853237 loss_ctc_origin 37.579964 loss_ctc0 101.824203 lr 0.00061570 rank 0
2022-08-26 02:46:15,700 DEBUG TRAIN Batch 185/3000 loss 41.006378 loss_att 27.404451 loss_ctc 72.744209 loss_ctc_origin 48.901970 loss_ctc0 128.376099 lr 0.00061567 rank 0
2022-08-26 02:46:44,828 DEBUG TRAIN Batch 185/3100 loss 53.834694 loss_att 29.860001 loss_ctc 109.775642 loss_ctc_origin 63.791492 loss_ctc0 217.071991 lr 0.00061564 rank 0
2022-08-26 02:47:13,683 DEBUG TRAIN Batch 185/3200 loss 19.741747 loss_att 9.961958 loss_ctc 42.561253 loss_ctc_origin 30.468786 loss_ctc0 70.777008 lr 0.00061561 rank 0
2022-08-26 02:47:42,622 DEBUG TRAIN Batch 185/3300 loss 19.720024 loss_att 8.451439 loss_ctc 46.013390 loss_ctc_origin 32.098137 loss_ctc0 78.482307 lr 0.00061558 rank 0
2022-08-26 02:48:11,483 DEBUG TRAIN Batch 185/3400 loss 22.042702 loss_att 7.830869 loss_ctc 55.203644 loss_ctc_origin 35.773399 loss_ctc0 100.540878 lr 0.00061555 rank 0
2022-08-26 02:48:41,162 DEBUG TRAIN Batch 185/3500 loss 47.125065 loss_att 31.823689 loss_ctc 82.828278 loss_ctc_origin 56.580505 loss_ctc0 144.073090 lr 0.00061552 rank 0
2022-08-26 02:49:09,347 DEBUG TRAIN Batch 185/3600 loss 49.971230 loss_att 26.926445 loss_ctc 103.742386 loss_ctc_origin 53.478935 loss_ctc0 221.023743 lr 0.00061549 rank 0
2022-08-26 02:49:37,659 DEBUG TRAIN Batch 185/3700 loss 16.971756 loss_att 8.979865 loss_ctc 35.619499 loss_ctc_origin 24.084976 loss_ctc0 62.533379 lr 0.00061546 rank 0
2022-08-26 02:50:06,683 DEBUG TRAIN Batch 185/3800 loss 17.694386 loss_att 7.702837 loss_ctc 41.007996 loss_ctc_origin 27.530291 loss_ctc0 72.455963 lr 0.00061543 rank 0
2022-08-26 02:50:24,631 WARNING NaN or Inf found in input tensor.
2022-08-26 02:50:31,656 WARNING NaN or Inf found in input tensor.
2022-08-26 02:50:35,976 DEBUG TRAIN Batch 185/3900 loss 23.098648 loss_att 9.814220 loss_ctc 54.095650 loss_ctc_origin 37.475517 loss_ctc0 92.875946 lr 0.00061540 rank 0
2022-08-26 02:51:04,693 DEBUG TRAIN Batch 185/4000 loss 46.760960 loss_att 28.895027 loss_ctc 88.448135 loss_ctc_origin 52.009529 loss_ctc0 173.471527 lr 0.00061537 rank 0
2022-08-26 02:51:32,051 DEBUG TRAIN Batch 185/4100 loss 49.062149 loss_att 27.372217 loss_ctc 99.671982 loss_ctc_origin 50.993759 loss_ctc0 213.254486 lr 0.00061535 rank 0
2022-08-26 02:51:58,713 WARNING NaN or Inf found in input tensor.
2022-08-26 02:52:00,169 DEBUG TRAIN Batch 185/4200 loss 19.089470 loss_att 10.165123 loss_ctc 39.912949 loss_ctc_origin 27.454391 loss_ctc0 68.982910 lr 0.00061532 rank 0
2022-08-26 02:52:29,120 DEBUG TRAIN Batch 185/4300 loss 19.211840 loss_att 8.089171 loss_ctc 45.164734 loss_ctc_origin 30.043158 loss_ctc0 80.448410 lr 0.00061529 rank 0
2022-08-26 02:52:54,741 WARNING NaN or Inf found in input tensor.
2022-08-26 02:52:59,003 DEBUG TRAIN Batch 185/4400 loss 23.430683 loss_att 10.294626 loss_ctc 54.081482 loss_ctc_origin 37.105312 loss_ctc0 93.692535 lr 0.00061526 rank 0
2022-08-26 02:53:33,939 DEBUG TRAIN Batch 185/4500 loss 39.281952 loss_att 26.685490 loss_ctc 68.673691 loss_ctc_origin 41.862408 loss_ctc0 131.233368 lr 0.00061523 rank 0
2022-08-26 02:54:02,261 DEBUG TRAIN Batch 185/4600 loss 52.674927 loss_att 29.572166 loss_ctc 106.581375 loss_ctc_origin 54.621387 loss_ctc0 227.821350 lr 0.00061520 rank 0
2022-08-26 02:54:08,629 WARNING NaN or Inf found in input tensor.
2022-08-26 02:54:30,718 DEBUG TRAIN Batch 185/4700 loss 22.871357 loss_att 12.927940 loss_ctc 46.072666 loss_ctc_origin 35.071304 loss_ctc0 71.742508 lr 0.00061517 rank 0
2022-08-26 02:54:59,511 DEBUG TRAIN Batch 185/4800 loss 20.880926 loss_att 8.677582 loss_ctc 49.355392 loss_ctc_origin 37.339039 loss_ctc0 77.393539 lr 0.00061514 rank 0
2022-08-26 02:55:23,652 WARNING NaN or Inf found in input tensor.
2022-08-26 02:55:28,113 DEBUG TRAIN Batch 185/4900 loss 20.838364 loss_att 7.712062 loss_ctc 51.466400 loss_ctc_origin 31.558804 loss_ctc0 97.917450 lr 0.00061511 rank 0
2022-08-26 02:55:30,776 WARNING NaN or Inf found in input tensor.
2022-08-26 02:55:57,220 DEBUG TRAIN Batch 185/5000 loss 42.031563 loss_att 26.760517 loss_ctc 77.664001 loss_ctc_origin 49.478844 loss_ctc0 143.429382 lr 0.00061508 rank 0
2022-08-26 02:55:57,941 WARNING NaN or Inf found in input tensor.
2022-08-26 02:56:26,250 DEBUG TRAIN Batch 185/5100 loss 47.990852 loss_att 22.655329 loss_ctc 107.107071 loss_ctc_origin 50.619843 loss_ctc0 238.910614 lr 0.00061505 rank 0
2022-08-26 02:56:55,444 DEBUG TRAIN Batch 185/5200 loss 21.793301 loss_att 10.797357 loss_ctc 47.450500 loss_ctc_origin 37.217758 loss_ctc0 71.326889 lr 0.00061503 rank 0
2022-08-26 02:57:24,809 DEBUG TRAIN Batch 185/5300 loss 20.323561 loss_att 9.351255 loss_ctc 45.925606 loss_ctc_origin 31.029701 loss_ctc0 80.682716 lr 0.00061500 rank 0
2022-08-26 02:57:51,628 DEBUG TRAIN Batch 185/5400 loss 20.114437 loss_att 8.259958 loss_ctc 47.774887 loss_ctc_origin 31.412792 loss_ctc0 85.953102 lr 0.00061497 rank 0
2022-08-26 02:58:21,306 DEBUG TRAIN Batch 185/5500 loss 43.075653 loss_att 25.817505 loss_ctc 83.344666 loss_ctc_origin 49.381050 loss_ctc0 162.593094 lr 0.00061494 rank 0
2022-08-26 02:58:50,083 DEBUG TRAIN Batch 185/5600 loss 51.363480 loss_att 28.801876 loss_ctc 104.007217 loss_ctc_origin 64.506058 loss_ctc0 196.176590 lr 0.00061491 rank 0
2022-08-26 02:59:16,518 DEBUG CV Batch 185/0 loss 12.089087 loss_att 8.965935 loss_ctc 19.376442 loss_ctc_origin 12.957338 loss_ctc0 34.354347 history loss 11.377964 rank 0
2022-08-26 02:59:27,698 DEBUG CV Batch 185/100 loss 20.398867 loss_att 16.554626 loss_ctc 29.368759 loss_ctc_origin 19.098476 loss_ctc0 53.332748 history loss 26.837009 rank 0
2022-08-26 02:59:38,048 DEBUG CV Batch 185/200 loss 26.731831 loss_att 20.537912 loss_ctc 41.184303 loss_ctc_origin 31.613396 loss_ctc0 63.516411 history loss 28.524470 rank 0
2022-08-26 02:59:47,880 DEBUG CV Batch 185/300 loss 22.639341 loss_att 17.160561 loss_ctc 35.423164 loss_ctc_origin 19.638500 loss_ctc0 72.254044 history loss 27.817203 rank 0
2022-08-26 02:59:58,555 DEBUG CV Batch 185/400 loss 39.444832 loss_att 31.843094 loss_ctc 57.182228 loss_ctc_origin 41.144176 loss_ctc0 94.604347 history loss 26.044017 rank 0
2022-08-26 03:00:09,672 DEBUG CV Batch 185/500 loss 16.962860 loss_att 12.602673 loss_ctc 27.136633 loss_ctc_origin 20.506752 loss_ctc0 42.606354 history loss 25.676736 rank 0
2022-08-26 03:00:20,786 DEBUG CV Batch 185/600 loss 18.516079 loss_att 13.201794 loss_ctc 30.916075 loss_ctc_origin 20.465622 loss_ctc0 55.300465 history loss 25.482297 rank 0
2022-08-26 03:00:31,308 DEBUG CV Batch 185/700 loss 19.391523 loss_att 13.542624 loss_ctc 33.038956 loss_ctc_origin 19.545055 loss_ctc0 64.524719 history loss 25.120055 rank 0
2022-08-26 03:00:42,077 DEBUG CV Batch 185/800 loss 22.248272 loss_att 17.585529 loss_ctc 33.128006 loss_ctc_origin 17.479126 loss_ctc0 69.642059 history loss 25.098836 rank 0
2022-08-26 03:00:52,344 INFO Epoch 185 CV info cv_loss 25.16412477059949
2022-08-26 03:00:52,345 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/185.pt
2022-08-26 03:00:52,806 INFO Epoch 186 TRAIN info lr 0.0006148847607960191
2022-08-26 03:00:52,809 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 03:01:19,477 DEBUG TRAIN Batch 186/0 loss 51.603455 loss_att 36.224743 loss_ctc 87.487122 loss_ctc_origin 60.509285 loss_ctc0 150.435394 lr 0.00061488 rank 0
2022-08-26 03:01:47,847 DEBUG TRAIN Batch 186/100 loss 52.810436 loss_att 29.146255 loss_ctc 108.026855 loss_ctc_origin 56.266216 loss_ctc0 228.801666 lr 0.00061485 rank 0
2022-08-26 03:02:15,222 WARNING NaN or Inf found in input tensor.
2022-08-26 03:02:16,795 DEBUG TRAIN Batch 186/200 loss 19.068207 loss_att 9.863184 loss_ctc 40.546593 loss_ctc_origin 29.225901 loss_ctc0 66.961548 lr 0.00061483 rank 0
2022-08-26 03:02:46,252 DEBUG TRAIN Batch 186/300 loss 17.678158 loss_att 7.385022 loss_ctc 41.695469 loss_ctc_origin 26.501514 loss_ctc0 77.148026 lr 0.00061480 rank 0
2022-08-26 03:03:15,126 DEBUG TRAIN Batch 186/400 loss 21.819920 loss_att 8.695024 loss_ctc 52.444672 loss_ctc_origin 36.653267 loss_ctc0 89.291275 lr 0.00061477 rank 0
2022-08-26 03:03:44,314 DEBUG TRAIN Batch 186/500 loss 45.063446 loss_att 32.273106 loss_ctc 74.907578 loss_ctc_origin 46.216949 loss_ctc0 141.852356 lr 0.00061474 rank 0
2022-08-26 03:04:12,470 DEBUG TRAIN Batch 186/600 loss 50.514320 loss_att 27.793343 loss_ctc 103.529930 loss_ctc_origin 52.846016 loss_ctc0 221.792389 lr 0.00061471 rank 0
2022-08-26 03:04:41,825 DEBUG TRAIN Batch 186/700 loss 21.700024 loss_att 12.494368 loss_ctc 43.179882 loss_ctc_origin 32.191223 loss_ctc0 68.820084 lr 0.00061468 rank 0
2022-08-26 03:05:10,014 DEBUG TRAIN Batch 186/800 loss 19.020901 loss_att 7.270903 loss_ctc 46.437561 loss_ctc_origin 32.697739 loss_ctc0 78.497147 lr 0.00061465 rank 0
2022-08-26 03:05:40,246 DEBUG TRAIN Batch 186/900 loss 23.826883 loss_att 9.529154 loss_ctc 57.188248 loss_ctc_origin 39.289101 loss_ctc0 98.952911 lr 0.00061462 rank 0
2022-08-26 03:06:07,677 DEBUG TRAIN Batch 186/1000 loss 43.321159 loss_att 27.414839 loss_ctc 80.435898 loss_ctc_origin 52.052528 loss_ctc0 146.663773 lr 0.00061459 rank 0
2022-08-26 03:06:35,013 DEBUG TRAIN Batch 186/1100 loss 50.826267 loss_att 28.140083 loss_ctc 103.760696 loss_ctc_origin 56.076317 loss_ctc0 215.024231 lr 0.00061456 rank 0
2022-08-26 03:07:02,410 DEBUG TRAIN Batch 186/1200 loss 21.774429 loss_att 11.516685 loss_ctc 45.709160 loss_ctc_origin 36.082054 loss_ctc0 68.172409 lr 0.00061454 rank 0
2022-08-26 03:07:31,105 DEBUG TRAIN Batch 186/1300 loss 20.263582 loss_att 8.249218 loss_ctc 48.297096 loss_ctc_origin 34.490681 loss_ctc0 80.512070 lr 0.00061451 rank 0
2022-08-26 03:08:00,051 DEBUG TRAIN Batch 186/1400 loss 20.079926 loss_att 8.348185 loss_ctc 47.453991 loss_ctc_origin 33.014107 loss_ctc0 81.147049 lr 0.00061448 rank 0
2022-08-26 03:08:35,322 DEBUG TRAIN Batch 186/1500 loss 46.691872 loss_att 29.756952 loss_ctc 86.206688 loss_ctc_origin 53.937428 loss_ctc0 161.501617 lr 0.00061445 rank 0
2022-08-26 03:09:04,135 DEBUG TRAIN Batch 186/1600 loss 48.233791 loss_att 26.892836 loss_ctc 98.029350 loss_ctc_origin 52.575272 loss_ctc0 204.088867 lr 0.00061442 rank 0
2022-08-26 03:09:32,859 DEBUG TRAIN Batch 186/1700 loss 19.153717 loss_att 10.091352 loss_ctc 40.299240 loss_ctc_origin 29.996086 loss_ctc0 64.339928 lr 0.00061439 rank 0
2022-08-26 03:10:01,454 DEBUG TRAIN Batch 186/1800 loss 19.533363 loss_att 6.945266 loss_ctc 48.905586 loss_ctc_origin 35.587982 loss_ctc0 79.979996 lr 0.00061436 rank 0
2022-08-26 03:10:29,622 DEBUG TRAIN Batch 186/1900 loss 22.349272 loss_att 8.409581 loss_ctc 54.875210 loss_ctc_origin 36.048080 loss_ctc0 98.805176 lr 0.00061433 rank 0
2022-08-26 03:10:59,307 DEBUG TRAIN Batch 186/2000 loss 38.645538 loss_att 25.787012 loss_ctc 68.648758 loss_ctc_origin 41.255554 loss_ctc0 132.566223 lr 0.00061430 rank 0
2022-08-26 03:11:27,526 DEBUG TRAIN Batch 186/2100 loss 46.390083 loss_att 24.212879 loss_ctc 98.136887 loss_ctc_origin 53.187683 loss_ctc0 203.018341 lr 0.00061427 rank 0
2022-08-26 03:11:55,126 DEBUG TRAIN Batch 186/2200 loss 22.497368 loss_att 11.328619 loss_ctc 48.557777 loss_ctc_origin 37.091171 loss_ctc0 75.313187 lr 0.00061425 rank 0
2022-08-26 03:12:23,869 DEBUG TRAIN Batch 186/2300 loss 21.441994 loss_att 8.836974 loss_ctc 50.853706 loss_ctc_origin 35.933197 loss_ctc0 85.668221 lr 0.00061422 rank 0
2022-08-26 03:12:51,550 DEBUG TRAIN Batch 186/2400 loss 21.775238 loss_att 9.084733 loss_ctc 51.386417 loss_ctc_origin 36.037758 loss_ctc0 87.199951 lr 0.00061419 rank 0
2022-08-26 03:13:20,973 DEBUG TRAIN Batch 186/2500 loss 46.766129 loss_att 30.339334 loss_ctc 85.095306 loss_ctc_origin 53.791187 loss_ctc0 158.138229 lr 0.00061416 rank 0
2022-08-26 03:13:49,860 DEBUG TRAIN Batch 186/2600 loss 48.797440 loss_att 25.821440 loss_ctc 102.408104 loss_ctc_origin 53.996975 loss_ctc0 215.367401 lr 0.00061413 rank 0
2022-08-26 03:14:18,526 DEBUG TRAIN Batch 186/2700 loss 18.771757 loss_att 8.718826 loss_ctc 42.228596 loss_ctc_origin 30.313107 loss_ctc0 70.031403 lr 0.00061410 rank 0
2022-08-26 03:14:46,158 DEBUG TRAIN Batch 186/2800 loss 16.810341 loss_att 7.636353 loss_ctc 38.216309 loss_ctc_origin 23.328354 loss_ctc0 72.954872 lr 0.00061407 rank 0
2022-08-26 03:15:13,604 DEBUG TRAIN Batch 186/2900 loss 25.570097 loss_att 10.688522 loss_ctc 60.293770 loss_ctc_origin 42.536358 loss_ctc0 101.727722 lr 0.00061404 rank 0
2022-08-26 03:15:48,656 DEBUG TRAIN Batch 186/3000 loss 35.035770 loss_att 22.175163 loss_ctc 65.043854 loss_ctc_origin 38.985085 loss_ctc0 125.847649 lr 0.00061401 rank 0
2022-08-26 03:16:16,679 DEBUG TRAIN Batch 186/3100 loss 48.517128 loss_att 25.015781 loss_ctc 103.353607 loss_ctc_origin 52.549061 loss_ctc0 221.897522 lr 0.00061398 rank 0
2022-08-26 03:16:44,726 DEBUG TRAIN Batch 186/3200 loss 17.853924 loss_att 9.155998 loss_ctc 38.149086 loss_ctc_origin 26.273205 loss_ctc0 65.859467 lr 0.00061396 rank 0
2022-08-26 03:17:13,119 DEBUG TRAIN Batch 186/3300 loss 19.472931 loss_att 8.567554 loss_ctc 44.918808 loss_ctc_origin 32.386482 loss_ctc0 74.160889 lr 0.00061393 rank 0
2022-08-26 03:17:41,341 DEBUG TRAIN Batch 186/3400 loss 24.610905 loss_att 9.676916 loss_ctc 59.456875 loss_ctc_origin 43.687798 loss_ctc0 96.251389 lr 0.00061390 rank 0
2022-08-26 03:18:10,534 DEBUG TRAIN Batch 186/3500 loss 49.417789 loss_att 33.151306 loss_ctc 87.372917 loss_ctc_origin 54.288040 loss_ctc0 164.570953 lr 0.00061387 rank 0
2022-08-26 03:18:38,872 DEBUG TRAIN Batch 186/3600 loss 54.378696 loss_att 30.655125 loss_ctc 109.733688 loss_ctc_origin 67.400162 loss_ctc0 208.511932 lr 0.00061384 rank 0
2022-08-26 03:19:08,032 DEBUG TRAIN Batch 186/3700 loss 23.554478 loss_att 13.106550 loss_ctc 47.932976 loss_ctc_origin 37.209976 loss_ctc0 72.953308 lr 0.00061381 rank 0
2022-08-26 03:19:36,261 DEBUG TRAIN Batch 186/3800 loss 19.844152 loss_att 8.380911 loss_ctc 46.591713 loss_ctc_origin 32.654984 loss_ctc0 79.110748 lr 0.00061378 rank 0
2022-08-26 03:20:00,281 WARNING NaN or Inf found in input tensor.
2022-08-26 03:20:04,597 DEBUG TRAIN Batch 186/3900 loss 22.734423 loss_att 9.425907 loss_ctc 53.787624 loss_ctc_origin 34.486214 loss_ctc0 98.824249 lr 0.00061375 rank 0
2022-08-26 03:20:33,527 DEBUG TRAIN Batch 186/4000 loss 46.203831 loss_att 29.844368 loss_ctc 84.375908 loss_ctc_origin 51.737091 loss_ctc0 160.533142 lr 0.00061372 rank 0
2022-08-26 03:21:03,231 DEBUG TRAIN Batch 186/4100 loss 52.278954 loss_att 31.169975 loss_ctc 101.533234 loss_ctc_origin 60.362541 loss_ctc0 197.598175 lr 0.00061370 rank 0
2022-08-26 03:21:32,185 DEBUG TRAIN Batch 186/4200 loss 18.567055 loss_att 9.950977 loss_ctc 38.671238 loss_ctc_origin 27.623631 loss_ctc0 64.448990 lr 0.00061367 rank 0
2022-08-26 03:22:00,233 DEBUG TRAIN Batch 186/4300 loss 20.386196 loss_att 8.648730 loss_ctc 47.773613 loss_ctc_origin 32.545959 loss_ctc0 83.304802 lr 0.00061364 rank 0
2022-08-26 03:22:28,863 DEBUG TRAIN Batch 186/4400 loss 20.000830 loss_att 8.506811 loss_ctc 46.820202 loss_ctc_origin 28.687551 loss_ctc0 89.129715 lr 0.00061361 rank 0
2022-08-26 03:23:04,897 DEBUG TRAIN Batch 186/4500 loss 46.990356 loss_att 30.779396 loss_ctc 84.815926 loss_ctc_origin 51.561234 loss_ctc0 162.410202 lr 0.00061358 rank 0
2022-08-26 03:23:33,895 DEBUG TRAIN Batch 186/4600 loss 45.698441 loss_att 22.754169 loss_ctc 99.235069 loss_ctc_origin 44.769341 loss_ctc0 226.321747 lr 0.00061355 rank 0
2022-08-26 03:24:00,997 DEBUG TRAIN Batch 186/4700 loss 18.803045 loss_att 9.863780 loss_ctc 39.661331 loss_ctc_origin 28.596992 loss_ctc0 65.478111 lr 0.00061352 rank 0
2022-08-26 03:24:28,550 DEBUG TRAIN Batch 186/4800 loss 19.867249 loss_att 8.239781 loss_ctc 46.998001 loss_ctc_origin 32.465839 loss_ctc0 80.906372 lr 0.00061349 rank 0
2022-08-26 03:24:52,751 WARNING NaN or Inf found in input tensor.
2022-08-26 03:24:57,228 DEBUG TRAIN Batch 186/4900 loss 21.354321 loss_att 7.997261 loss_ctc 52.520790 loss_ctc_origin 34.781498 loss_ctc0 93.912476 lr 0.00061346 rank 0
2022-08-26 03:25:24,613 DEBUG TRAIN Batch 186/5000 loss 45.273102 loss_att 29.500839 loss_ctc 82.075043 loss_ctc_origin 54.353973 loss_ctc0 146.757538 lr 0.00061344 rank 0
2022-08-26 03:25:51,935 DEBUG TRAIN Batch 186/5100 loss 47.948120 loss_att 27.575932 loss_ctc 95.483215 loss_ctc_origin 51.066032 loss_ctc0 199.123306 lr 0.00061341 rank 0
2022-08-26 03:26:19,384 DEBUG TRAIN Batch 186/5200 loss 19.410072 loss_att 9.694478 loss_ctc 42.079788 loss_ctc_origin 29.683456 loss_ctc0 71.004562 lr 0.00061338 rank 0
2022-08-26 03:26:45,841 DEBUG TRAIN Batch 186/5300 loss 20.247042 loss_att 10.228481 loss_ctc 43.623680 loss_ctc_origin 31.278612 loss_ctc0 72.428833 lr 0.00061335 rank 0
2022-08-26 03:27:13,796 DEBUG TRAIN Batch 186/5400 loss 21.520391 loss_att 8.967091 loss_ctc 50.811424 loss_ctc_origin 28.302105 loss_ctc0 103.333160 lr 0.00061332 rank 0
2022-08-26 03:27:34,414 WARNING NaN or Inf found in input tensor.
2022-08-26 03:27:41,414 DEBUG TRAIN Batch 186/5500 loss 41.756317 loss_att 26.143730 loss_ctc 78.185684 loss_ctc_origin 44.561577 loss_ctc0 156.641937 lr 0.00061329 rank 0
2022-08-26 03:28:08,230 DEBUG TRAIN Batch 186/5600 loss 54.045441 loss_att 29.023359 loss_ctc 112.430298 loss_ctc_origin 67.436554 loss_ctc0 217.415710 lr 0.00061326 rank 0
2022-08-26 03:28:31,417 DEBUG CV Batch 186/0 loss 11.076187 loss_att 8.005257 loss_ctc 18.241690 loss_ctc_origin 11.299549 loss_ctc0 34.440018 history loss 10.424647 rank 0
2022-08-26 03:28:42,252 DEBUG CV Batch 186/100 loss 20.119995 loss_att 15.853675 loss_ctc 30.074743 loss_ctc_origin 20.369633 loss_ctc0 52.720001 history loss 26.076421 rank 0
2022-08-26 03:28:53,044 DEBUG CV Batch 186/200 loss 25.348755 loss_att 19.825941 loss_ctc 38.235317 loss_ctc_origin 27.856842 loss_ctc0 62.451759 history loss 27.640840 rank 0
2022-08-26 03:29:03,680 DEBUG CV Batch 186/300 loss 22.302151 loss_att 16.663927 loss_ctc 35.458004 loss_ctc_origin 19.762613 loss_ctc0 72.080582 history loss 26.726890 rank 0
2022-08-26 03:29:14,494 DEBUG CV Batch 186/400 loss 37.577187 loss_att 30.744617 loss_ctc 53.519844 loss_ctc_origin 36.005505 loss_ctc0 94.386627 history loss 25.107002 rank 0
2022-08-26 03:29:25,364 DEBUG CV Batch 186/500 loss 16.120646 loss_att 11.832129 loss_ctc 26.127186 loss_ctc_origin 19.051418 loss_ctc0 42.637306 history loss 24.772748 rank 0
2022-08-26 03:29:34,793 DEBUG CV Batch 186/600 loss 17.358509 loss_att 12.385263 loss_ctc 28.962749 loss_ctc_origin 18.187241 loss_ctc0 54.105602 history loss 24.604726 rank 0
2022-08-26 03:29:43,486 DEBUG CV Batch 186/700 loss 18.646460 loss_att 13.146073 loss_ctc 31.480694 loss_ctc_origin 18.041481 loss_ctc0 62.838852 history loss 24.265246 rank 0
2022-08-26 03:29:52,094 DEBUG CV Batch 186/800 loss 21.549017 loss_att 17.086100 loss_ctc 31.962490 loss_ctc_origin 16.642426 loss_ctc0 67.709312 history loss 24.236070 rank 0
2022-08-26 03:30:00,605 INFO Epoch 186 CV info cv_loss 24.319059723277412
2022-08-26 03:30:00,605 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/186.pt
2022-08-26 03:30:01,052 INFO Epoch 187 TRAIN info lr 0.0006132384800350999
2022-08-26 03:30:01,055 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 03:30:27,462 DEBUG TRAIN Batch 187/0 loss 39.920261 loss_att 24.928202 loss_ctc 74.901733 loss_ctc_origin 45.058578 loss_ctc0 144.535767 lr 0.00061324 rank 0
2022-08-26 03:30:35,081 WARNING NaN or Inf found in input tensor.
2022-08-26 03:30:55,545 DEBUG TRAIN Batch 187/100 loss 46.280590 loss_att 22.546625 loss_ctc 101.659843 loss_ctc_origin 52.549583 loss_ctc0 216.250458 lr 0.00061321 rank 0
2022-08-26 03:31:23,003 DEBUG TRAIN Batch 187/200 loss 20.515808 loss_att 11.977524 loss_ctc 40.438465 loss_ctc_origin 30.951696 loss_ctc0 62.574257 lr 0.00061318 rank 0
2022-08-26 03:31:51,101 DEBUG TRAIN Batch 187/300 loss 17.420246 loss_att 8.026562 loss_ctc 39.338844 loss_ctc_origin 23.769855 loss_ctc0 75.666481 lr 0.00061315 rank 0
2022-08-26 03:32:19,888 DEBUG TRAIN Batch 187/400 loss 19.501980 loss_att 7.555207 loss_ctc 47.377777 loss_ctc_origin 30.525839 loss_ctc0 86.698959 lr 0.00061312 rank 0
2022-08-26 03:32:22,472 WARNING NaN or Inf found in input tensor.
2022-08-26 03:32:47,186 DEBUG TRAIN Batch 187/500 loss 45.509590 loss_att 28.040966 loss_ctc 86.269707 loss_ctc_origin 60.941895 loss_ctc0 145.367935 lr 0.00061309 rank 0
2022-08-26 03:33:14,422 DEBUG TRAIN Batch 187/600 loss 46.386398 loss_att 24.484604 loss_ctc 97.490578 loss_ctc_origin 48.599300 loss_ctc0 211.570221 lr 0.00061306 rank 0
2022-08-26 03:33:41,758 DEBUG TRAIN Batch 187/700 loss 20.399275 loss_att 11.130192 loss_ctc 42.027130 loss_ctc_origin 31.678150 loss_ctc0 66.174751 lr 0.00061304 rank 0
2022-08-26 03:34:10,059 DEBUG TRAIN Batch 187/800 loss 18.696280 loss_att 8.005888 loss_ctc 43.640526 loss_ctc_origin 27.281700 loss_ctc0 81.811111 lr 0.00061301 rank 0
2022-08-26 03:34:37,659 DEBUG TRAIN Batch 187/900 loss 20.143126 loss_att 7.999402 loss_ctc 48.478481 loss_ctc_origin 30.388111 loss_ctc0 90.689346 lr 0.00061298 rank 0
2022-08-26 03:35:05,203 DEBUG TRAIN Batch 187/1000 loss 39.330147 loss_att 24.854214 loss_ctc 73.107315 loss_ctc_origin 41.330818 loss_ctc0 147.252472 lr 0.00061295 rank 0
2022-08-26 03:35:31,414 DEBUG TRAIN Batch 187/1100 loss 50.759609 loss_att 29.162636 loss_ctc 101.152542 loss_ctc_origin 57.055248 loss_ctc0 204.046219 lr 0.00061292 rank 0
2022-08-26 03:35:58,513 DEBUG TRAIN Batch 187/1200 loss 21.189232 loss_att 10.138619 loss_ctc 46.973991 loss_ctc_origin 36.900444 loss_ctc0 70.478928 lr 0.00061289 rank 0
2022-08-26 03:36:25,137 DEBUG TRAIN Batch 187/1300 loss 21.393873 loss_att 9.987320 loss_ctc 48.009163 loss_ctc_origin 33.564919 loss_ctc0 81.712402 lr 0.00061286 rank 0
2022-08-26 03:36:53,314 DEBUG TRAIN Batch 187/1400 loss 26.075762 loss_att 10.933182 loss_ctc 61.408447 loss_ctc_origin 43.651718 loss_ctc0 102.840820 lr 0.00061283 rank 0
2022-08-26 03:37:23,846 DEBUG TRAIN Batch 187/1500 loss 45.723743 loss_att 32.251694 loss_ctc 77.158524 loss_ctc_origin 51.600239 loss_ctc0 136.794510 lr 0.00061281 rank 0
2022-08-26 03:37:51,115 DEBUG TRAIN Batch 187/1600 loss 53.168411 loss_att 32.267776 loss_ctc 101.936554 loss_ctc_origin 57.223186 loss_ctc0 206.267731 lr 0.00061278 rank 0
2022-08-26 03:38:17,760 DEBUG TRAIN Batch 187/1700 loss 23.753899 loss_att 12.240079 loss_ctc 50.619480 loss_ctc_origin 40.802460 loss_ctc0 73.525856 lr 0.00061275 rank 0
2022-08-26 03:38:45,583 DEBUG TRAIN Batch 187/1800 loss 23.690901 loss_att 10.040269 loss_ctc 55.542370 loss_ctc_origin 38.927471 loss_ctc0 94.310463 lr 0.00061272 rank 0
2022-08-26 03:39:13,373 DEBUG TRAIN Batch 187/1900 loss 20.572275 loss_att 8.062970 loss_ctc 49.760651 loss_ctc_origin 29.789249 loss_ctc0 96.360580 lr 0.00061269 rank 0
2022-08-26 03:39:40,870 DEBUG TRAIN Batch 187/2000 loss 34.531715 loss_att 20.166166 loss_ctc 68.051331 loss_ctc_origin 38.472980 loss_ctc0 137.067490 lr 0.00061266 rank 0
2022-08-26 03:40:07,658 DEBUG TRAIN Batch 187/2100 loss 53.676125 loss_att 28.690996 loss_ctc 111.974762 loss_ctc_origin 69.190239 loss_ctc0 211.805298 lr 0.00061263 rank 0
2022-08-26 03:40:36,008 DEBUG TRAIN Batch 187/2200 loss 14.314701 loss_att 7.135485 loss_ctc 31.066208 loss_ctc_origin 19.003819 loss_ctc0 59.211781 lr 0.00061260 rank 0
2022-08-26 03:41:02,839 DEBUG TRAIN Batch 187/2300 loss 18.686863 loss_att 8.347764 loss_ctc 42.811424 loss_ctc_origin 29.272194 loss_ctc0 74.402954 lr 0.00061258 rank 0
2022-08-26 03:41:31,119 DEBUG TRAIN Batch 187/2400 loss 20.113632 loss_att 8.186167 loss_ctc 47.944382 loss_ctc_origin 29.620392 loss_ctc0 90.700348 lr 0.00061255 rank 0
2022-08-26 03:41:58,907 DEBUG TRAIN Batch 187/2500 loss 35.098461 loss_att 20.694029 loss_ctc 68.708801 loss_ctc_origin 41.508625 loss_ctc0 132.175873 lr 0.00061252 rank 0
2022-08-26 03:42:26,626 DEBUG TRAIN Batch 187/2600 loss 56.794441 loss_att 34.859215 loss_ctc 107.976624 loss_ctc_origin 70.022820 loss_ctc0 196.535507 lr 0.00061249 rank 0
2022-08-26 03:42:53,775 DEBUG TRAIN Batch 187/2700 loss 24.819653 loss_att 14.194571 loss_ctc 49.611507 loss_ctc_origin 40.249393 loss_ctc0 71.456436 lr 0.00061246 rank 0
2022-08-26 03:43:21,746 DEBUG TRAIN Batch 187/2800 loss 15.690908 loss_att 6.556062 loss_ctc 37.005547 loss_ctc_origin 21.950983 loss_ctc0 72.132858 lr 0.00061243 rank 0
2022-08-26 03:43:49,985 DEBUG TRAIN Batch 187/2900 loss 24.189039 loss_att 10.984957 loss_ctc 54.998558 loss_ctc_origin 38.133118 loss_ctc0 94.351257 lr 0.00061240 rank 0
2022-08-26 03:44:23,783 DEBUG TRAIN Batch 187/3000 loss 43.544205 loss_att 28.598827 loss_ctc 78.416748 loss_ctc_origin 47.293579 loss_ctc0 151.037476 lr 0.00061237 rank 0
2022-08-26 03:44:51,349 DEBUG TRAIN Batch 187/3100 loss 43.880577 loss_att 22.333618 loss_ctc 94.156815 loss_ctc_origin 53.072090 loss_ctc0 190.021149 lr 0.00061235 rank 0
2022-08-26 03:45:19,098 DEBUG TRAIN Batch 187/3200 loss 19.565632 loss_att 9.537197 loss_ctc 42.965309 loss_ctc_origin 32.142441 loss_ctc0 68.218658 lr 0.00061232 rank 0
2022-08-26 03:45:46,150 DEBUG TRAIN Batch 187/3300 loss 17.804132 loss_att 6.989686 loss_ctc 43.037842 loss_ctc_origin 26.095203 loss_ctc0 82.570656 lr 0.00061229 rank 0
2022-08-26 03:46:13,707 DEBUG TRAIN Batch 187/3400 loss 21.780067 loss_att 8.686096 loss_ctc 52.332664 loss_ctc_origin 32.930435 loss_ctc0 97.604530 lr 0.00061226 rank 0
2022-08-26 03:46:41,583 DEBUG TRAIN Batch 187/3500 loss 45.859505 loss_att 28.882072 loss_ctc 85.473511 loss_ctc_origin 47.307583 loss_ctc0 174.527328 lr 0.00061223 rank 0
2022-08-26 03:47:08,540 DEBUG TRAIN Batch 187/3600 loss 60.134491 loss_att 35.490677 loss_ctc 117.636719 loss_ctc_origin 64.469719 loss_ctc0 241.693054 lr 0.00061220 rank 0
2022-08-26 03:47:35,405 DEBUG TRAIN Batch 187/3700 loss 16.457163 loss_att 8.430450 loss_ctc 35.186157 loss_ctc_origin 23.556499 loss_ctc0 62.322018 lr 0.00061217 rank 0
2022-08-26 03:48:01,918 DEBUG TRAIN Batch 187/3800 loss 15.778358 loss_att 6.342427 loss_ctc 37.795532 loss_ctc_origin 23.123463 loss_ctc0 72.030350 lr 0.00061214 rank 0
2022-08-26 03:48:29,549 DEBUG TRAIN Batch 187/3900 loss 24.638739 loss_att 11.147895 loss_ctc 56.117371 loss_ctc_origin 37.371902 loss_ctc0 99.856796 lr 0.00061212 rank 0
2022-08-26 03:48:56,671 DEBUG TRAIN Batch 187/4000 loss 42.112167 loss_att 27.118301 loss_ctc 77.097855 loss_ctc_origin 46.290668 loss_ctc0 148.981262 lr 0.00061209 rank 0
2022-08-26 03:49:24,001 DEBUG TRAIN Batch 187/4100 loss 51.356178 loss_att 27.333549 loss_ctc 107.408974 loss_ctc_origin 50.702843 loss_ctc0 239.723267 lr 0.00061206 rank 0
2022-08-26 03:49:51,064 DEBUG TRAIN Batch 187/4200 loss 18.791763 loss_att 8.848785 loss_ctc 41.992043 loss_ctc_origin 31.235304 loss_ctc0 67.091103 lr 0.00061203 rank 0
2022-08-26 03:50:20,512 DEBUG TRAIN Batch 187/4300 loss 19.736675 loss_att 8.359138 loss_ctc 46.284264 loss_ctc_origin 30.255482 loss_ctc0 83.684746 lr 0.00061200 rank 0
2022-08-26 03:50:45,739 DEBUG TRAIN Batch 187/4400 loss 22.626596 loss_att 10.110592 loss_ctc 51.830605 loss_ctc_origin 35.208313 loss_ctc0 90.615952 lr 0.00061197 rank 0
2022-08-26 03:51:18,531 DEBUG TRAIN Batch 187/4500 loss 48.969170 loss_att 30.428883 loss_ctc 92.229843 loss_ctc_origin 54.447365 loss_ctc0 180.388947 lr 0.00061194 rank 0
2022-08-26 03:51:46,953 DEBUG TRAIN Batch 187/4600 loss 63.433975 loss_att 37.952293 loss_ctc 122.891235 loss_ctc_origin 68.354019 loss_ctc0 250.144745 lr 0.00061192 rank 0
2022-08-26 03:52:14,855 DEBUG TRAIN Batch 187/4700 loss 22.221619 loss_att 12.217673 loss_ctc 45.564156 loss_ctc_origin 34.751305 loss_ctc0 70.794136 lr 0.00061189 rank 0
2022-08-26 03:52:42,396 DEBUG TRAIN Batch 187/4800 loss 21.310774 loss_att 9.704756 loss_ctc 48.391483 loss_ctc_origin 33.639214 loss_ctc0 82.813446 lr 0.00061186 rank 0
2022-08-26 03:53:09,453 DEBUG TRAIN Batch 187/4900 loss 21.826696 loss_att 9.196754 loss_ctc 51.296558 loss_ctc_origin 32.550274 loss_ctc0 95.037888 lr 0.00061183 rank 0
2022-08-26 03:53:37,633 DEBUG TRAIN Batch 187/5000 loss 49.733276 loss_att 33.098137 loss_ctc 88.548599 loss_ctc_origin 59.890968 loss_ctc0 155.416412 lr 0.00061180 rank 0
2022-08-26 03:54:04,883 DEBUG TRAIN Batch 187/5100 loss 51.712395 loss_att 27.030262 loss_ctc 109.304039 loss_ctc_origin 62.358246 loss_ctc0 218.844208 lr 0.00061177 rank 0
2022-08-26 03:54:33,877 DEBUG TRAIN Batch 187/5200 loss 21.428408 loss_att 10.051799 loss_ctc 47.973824 loss_ctc_origin 36.976418 loss_ctc0 73.634438 lr 0.00061174 rank 0
2022-08-26 03:54:39,207 WARNING NaN or Inf found in input tensor.
2022-08-26 03:55:01,216 DEBUG TRAIN Batch 187/5300 loss 17.164778 loss_att 7.091076 loss_ctc 40.670082 loss_ctc_origin 25.464155 loss_ctc0 76.150574 lr 0.00061172 rank 0
2022-08-26 03:55:29,486 DEBUG TRAIN Batch 187/5400 loss 20.677597 loss_att 8.531782 loss_ctc 49.017830 loss_ctc_origin 32.193718 loss_ctc0 88.274078 lr 0.00061169 rank 0
2022-08-26 03:55:58,313 DEBUG TRAIN Batch 187/5500 loss 50.757912 loss_att 33.397308 loss_ctc 91.265991 loss_ctc_origin 58.289436 loss_ctc0 168.211273 lr 0.00061166 rank 0
2022-08-26 03:56:26,671 DEBUG TRAIN Batch 187/5600 loss 26.885792 loss_att 16.120159 loss_ctc 52.005596 loss_ctc_origin 28.764965 loss_ctc0 106.233734 lr 0.00061163 rank 0
2022-08-26 03:56:49,127 DEBUG CV Batch 187/0 loss 12.888498 loss_att 9.984884 loss_ctc 19.663599 loss_ctc_origin 13.368624 loss_ctc0 34.351875 history loss 12.130351 rank 0
2022-08-26 03:56:59,737 DEBUG CV Batch 187/100 loss 19.750553 loss_att 15.837973 loss_ctc 28.879910 loss_ctc_origin 18.576244 loss_ctc0 52.921791 history loss 25.934192 rank 0
2022-08-26 03:57:09,085 DEBUG CV Batch 187/200 loss 24.392719 loss_att 18.647173 loss_ctc 37.798996 loss_ctc_origin 27.296947 loss_ctc0 62.303780 history loss 27.420535 rank 0
2022-08-26 03:57:19,026 DEBUG CV Batch 187/300 loss 22.378344 loss_att 16.854572 loss_ctc 35.267143 loss_ctc_origin 19.305534 loss_ctc0 72.510895 history loss 26.486408 rank 0
2022-08-26 03:57:29,255 DEBUG CV Batch 187/400 loss 37.664455 loss_att 30.792564 loss_ctc 53.698868 loss_ctc_origin 36.390007 loss_ctc0 94.086212 history loss 24.857943 rank 0
2022-08-26 03:57:39,491 DEBUG CV Batch 187/500 loss 15.544655 loss_att 11.177006 loss_ctc 25.735836 loss_ctc_origin 18.609739 loss_ctc0 42.363392 history loss 24.533512 rank 0
2022-08-26 03:57:49,721 DEBUG CV Batch 187/600 loss 16.879484 loss_att 11.638827 loss_ctc 29.107683 loss_ctc_origin 18.563328 loss_ctc0 53.711174 history loss 24.353930 rank 0
2022-08-26 03:57:59,399 DEBUG CV Batch 187/700 loss 18.857224 loss_att 13.559665 loss_ctc 31.218193 loss_ctc_origin 17.586285 loss_ctc0 63.025978 history loss 24.009081 rank 0
2022-08-26 03:58:09,835 DEBUG CV Batch 187/800 loss 21.907608 loss_att 17.436932 loss_ctc 32.339188 loss_ctc_origin 17.004644 loss_ctc0 68.119781 history loss 23.974878 rank 0
2022-08-26 03:58:20,034 INFO Epoch 187 CV info cv_loss 24.044006268843493
2022-08-26 03:58:20,035 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/187.pt
2022-08-26 03:58:20,501 INFO Epoch 188 TRAIN info lr 0.000611605352022346
2022-08-26 03:58:20,504 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 03:58:46,304 DEBUG TRAIN Batch 188/0 loss 38.530487 loss_att 23.416277 loss_ctc 73.796967 loss_ctc_origin 46.268349 loss_ctc0 138.030396 lr 0.00061160 rank 0
2022-08-26 03:59:13,670 DEBUG TRAIN Batch 188/100 loss 52.208710 loss_att 31.575317 loss_ctc 100.353287 loss_ctc_origin 59.554573 loss_ctc0 195.550293 lr 0.00061158 rank 0
2022-08-26 03:59:42,152 DEBUG TRAIN Batch 188/200 loss 19.379465 loss_att 9.886858 loss_ctc 41.528877 loss_ctc_origin 29.360676 loss_ctc0 69.921341 lr 0.00061155 rank 0
2022-08-26 04:00:10,372 DEBUG TRAIN Batch 188/300 loss 18.330936 loss_att 7.128092 loss_ctc 44.470901 loss_ctc_origin 29.783230 loss_ctc0 78.742142 lr 0.00061152 rank 0
2022-08-26 04:00:38,440 DEBUG TRAIN Batch 188/400 loss 19.265785 loss_att 7.455195 loss_ctc 46.823830 loss_ctc_origin 29.302929 loss_ctc0 87.705933 lr 0.00061149 rank 0
2022-08-26 04:01:05,901 DEBUG TRAIN Batch 188/500 loss 51.231331 loss_att 34.397480 loss_ctc 90.510307 loss_ctc_origin 61.304520 loss_ctc0 158.657150 lr 0.00061146 rank 0
2022-08-26 04:01:13,756 WARNING NaN or Inf found in input tensor.
2022-08-26 04:01:32,996 DEBUG TRAIN Batch 188/600 loss 51.648087 loss_att 29.316662 loss_ctc 103.754738 loss_ctc_origin 57.211788 loss_ctc0 212.354950 lr 0.00061143 rank 0
2022-08-26 04:02:01,159 DEBUG TRAIN Batch 188/700 loss 18.674984 loss_att 9.146477 loss_ctc 40.908165 loss_ctc_origin 29.401167 loss_ctc0 67.757828 lr 0.00061140 rank 0
2022-08-26 04:02:29,266 DEBUG TRAIN Batch 188/800 loss 18.088528 loss_att 6.725520 loss_ctc 44.602207 loss_ctc_origin 29.464161 loss_ctc0 79.924316 lr 0.00061138 rank 0
2022-08-26 04:02:56,706 DEBUG TRAIN Batch 188/900 loss 17.566452 loss_att 7.220335 loss_ctc 41.707390 loss_ctc_origin 23.996136 loss_ctc0 83.033646 lr 0.00061135 rank 0
2022-08-26 04:03:24,415 DEBUG TRAIN Batch 188/1000 loss 40.134621 loss_att 26.030750 loss_ctc 73.043655 loss_ctc_origin 44.295292 loss_ctc0 140.123154 lr 0.00061132 rank 0
2022-08-26 04:03:51,812 DEBUG TRAIN Batch 188/1100 loss 54.391174 loss_att 32.950008 loss_ctc 104.420547 loss_ctc_origin 65.972786 loss_ctc0 194.131989 lr 0.00061129 rank 0
2022-08-26 04:04:18,825 WARNING NaN or Inf found in input tensor.
2022-08-26 04:04:20,411 DEBUG TRAIN Batch 188/1200 loss 18.956125 loss_att 10.624261 loss_ctc 38.397141 loss_ctc_origin 26.517401 loss_ctc0 66.116531 lr 0.00061126 rank 0
2022-08-26 04:04:48,017 DEBUG TRAIN Batch 188/1300 loss 18.436073 loss_att 8.257421 loss_ctc 42.186264 loss_ctc_origin 26.834616 loss_ctc0 78.006775 lr 0.00061123 rank 0
2022-08-26 04:05:15,880 DEBUG TRAIN Batch 188/1400 loss 22.030031 loss_att 10.158424 loss_ctc 49.730446 loss_ctc_origin 31.529537 loss_ctc0 92.199234 lr 0.00061120 rank 0
2022-08-26 04:05:49,932 DEBUG TRAIN Batch 188/1500 loss 52.030220 loss_att 33.806328 loss_ctc 94.552643 loss_ctc_origin 62.784973 loss_ctc0 168.677185 lr 0.00061118 rank 0
2022-08-26 04:06:05,013 WARNING NaN or Inf found in input tensor.
2022-08-26 04:06:17,673 DEBUG TRAIN Batch 188/1600 loss 58.644226 loss_att 34.702705 loss_ctc 114.507767 loss_ctc_origin 67.245117 loss_ctc0 224.787262 lr 0.00061115 rank 0
2022-08-26 04:06:45,313 DEBUG TRAIN Batch 188/1700 loss 18.816643 loss_att 10.608379 loss_ctc 37.969254 loss_ctc_origin 26.612885 loss_ctc0 64.467438 lr 0.00061112 rank 0
2022-08-26 04:07:12,855 DEBUG TRAIN Batch 188/1800 loss 17.503286 loss_att 6.199185 loss_ctc 43.879520 loss_ctc_origin 25.957773 loss_ctc0 85.696930 lr 0.00061109 rank 0
2022-08-26 04:07:40,255 DEBUG TRAIN Batch 188/1900 loss 20.731663 loss_att 7.014646 loss_ctc 52.738033 loss_ctc_origin 35.741570 loss_ctc0 92.396446 lr 0.00061106 rank 0
2022-08-26 04:08:08,604 DEBUG TRAIN Batch 188/2000 loss 44.631134 loss_att 28.808502 loss_ctc 81.550613 loss_ctc_origin 46.462021 loss_ctc0 163.423981 lr 0.00061103 rank 0
2022-08-26 04:08:35,964 DEBUG TRAIN Batch 188/2100 loss 51.831348 loss_att 26.018967 loss_ctc 112.060242 loss_ctc_origin 56.998505 loss_ctc0 240.537628 lr 0.00061100 rank 0
2022-08-26 04:09:03,214 DEBUG TRAIN Batch 188/2200 loss 17.010977 loss_att 7.610485 loss_ctc 38.945454 loss_ctc_origin 25.118671 loss_ctc0 71.207947 lr 0.00061098 rank 0
2022-08-26 04:09:32,061 DEBUG TRAIN Batch 188/2300 loss 17.514603 loss_att 7.142545 loss_ctc 41.716072 loss_ctc_origin 27.547180 loss_ctc0 74.776825 lr 0.00061095 rank 0
2022-08-26 04:09:59,550 DEBUG TRAIN Batch 188/2400 loss 20.211666 loss_att 7.906007 loss_ctc 48.924866 loss_ctc_origin 30.426342 loss_ctc0 92.088089 lr 0.00061092 rank 0
2022-08-26 04:10:27,207 DEBUG TRAIN Batch 188/2500 loss 41.602547 loss_att 24.491371 loss_ctc 81.528625 loss_ctc_origin 48.917885 loss_ctc0 157.620346 lr 0.00061089 rank 0
2022-08-26 04:10:54,963 DEBUG TRAIN Batch 188/2600 loss 59.966652 loss_att 36.263451 loss_ctc 115.274124 loss_ctc_origin 66.549049 loss_ctc0 228.965942 lr 0.00061086 rank 0
2022-08-26 04:11:22,234 DEBUG TRAIN Batch 188/2700 loss 17.051861 loss_att 8.884697 loss_ctc 36.108578 loss_ctc_origin 24.317387 loss_ctc0 63.621353 lr 0.00061083 rank 0
2022-08-26 04:11:49,488 DEBUG TRAIN Batch 188/2800 loss 18.275446 loss_att 8.102764 loss_ctc 42.011703 loss_ctc_origin 27.159323 loss_ctc0 76.667259 lr 0.00061081 rank 0
2022-08-26 04:12:16,498 DEBUG TRAIN Batch 188/2900 loss 21.404232 loss_att 9.664097 loss_ctc 48.797874 loss_ctc_origin 31.554516 loss_ctc0 89.032364 lr 0.00061078 rank 0
2022-08-26 04:12:49,035 DEBUG TRAIN Batch 188/3000 loss 42.062325 loss_att 27.258343 loss_ctc 76.604950 loss_ctc_origin 45.967453 loss_ctc0 148.092453 lr 0.00061075 rank 0
2022-08-26 04:13:17,021 DEBUG TRAIN Batch 188/3100 loss 49.172367 loss_att 25.103512 loss_ctc 105.333023 loss_ctc_origin 52.708679 loss_ctc0 228.123138 lr 0.00061072 rank 0
2022-08-26 04:13:44,573 DEBUG TRAIN Batch 188/3200 loss 23.541718 loss_att 14.716128 loss_ctc 44.134758 loss_ctc_origin 34.547581 loss_ctc0 66.504837 lr 0.00061069 rank 0
2022-08-26 04:13:50,018 WARNING NaN or Inf found in input tensor.
2022-08-26 04:14:12,412 DEBUG TRAIN Batch 188/3300 loss 17.103622 loss_att 6.688806 loss_ctc 41.404861 loss_ctc_origin 28.586250 loss_ctc0 71.314964 lr 0.00061066 rank 0
2022-08-26 04:14:37,749 DEBUG TRAIN Batch 188/3400 loss 18.740086 loss_att 7.369140 loss_ctc 45.272289 loss_ctc_origin 26.351259 loss_ctc0 89.421356 lr 0.00061063 rank 0
2022-08-26 04:14:57,254 WARNING NaN or Inf found in input tensor.
2022-08-26 04:15:04,453 DEBUG TRAIN Batch 188/3500 loss 42.895782 loss_att 27.966091 loss_ctc 77.731720 loss_ctc_origin 50.700081 loss_ctc0 140.805542 lr 0.00061061 rank 0
2022-08-26 04:15:23,330 WARNING NaN or Inf found in input tensor.
2022-08-26 04:15:30,412 DEBUG TRAIN Batch 188/3600 loss 48.177143 loss_att 25.959311 loss_ctc 100.018753 loss_ctc_origin 51.067619 loss_ctc0 214.238068 lr 0.00061058 rank 0
2022-08-26 04:15:56,449 DEBUG TRAIN Batch 188/3700 loss 24.239605 loss_att 13.295897 loss_ctc 49.774918 loss_ctc_origin 40.595070 loss_ctc0 71.194572 lr 0.00061055 rank 0
2022-08-26 04:16:23,787 DEBUG TRAIN Batch 188/3800 loss 20.916584 loss_att 8.160604 loss_ctc 50.680534 loss_ctc_origin 37.098137 loss_ctc0 82.372803 lr 0.00061052 rank 0
2022-08-26 04:16:51,220 DEBUG TRAIN Batch 188/3900 loss 19.005360 loss_att 7.541824 loss_ctc 45.753609 loss_ctc_origin 27.912895 loss_ctc0 87.381943 lr 0.00061049 rank 0
2022-08-26 04:17:18,882 DEBUG TRAIN Batch 188/4000 loss 44.487835 loss_att 27.421633 loss_ctc 84.308968 loss_ctc_origin 48.289112 loss_ctc0 168.355286 lr 0.00061046 rank 0
2022-08-26 04:17:39,708 WARNING NaN or Inf found in input tensor.
2022-08-26 04:17:46,558 DEBUG TRAIN Batch 188/4100 loss 52.504917 loss_att 29.357044 loss_ctc 106.516617 loss_ctc_origin 59.012077 loss_ctc0 217.360519 lr 0.00061044 rank 0
2022-08-26 04:18:14,833 DEBUG TRAIN Batch 188/4200 loss 18.103027 loss_att 9.289080 loss_ctc 38.668907 loss_ctc_origin 26.331387 loss_ctc0 67.456451 lr 0.00061041 rank 0
2022-08-26 04:18:42,994 DEBUG TRAIN Batch 188/4300 loss 17.288383 loss_att 6.856544 loss_ctc 41.629341 loss_ctc_origin 27.789536 loss_ctc0 73.922211 lr 0.00061038 rank 0
2022-08-26 04:19:11,317 DEBUG TRAIN Batch 188/4400 loss 23.470661 loss_att 9.310789 loss_ctc 56.510361 loss_ctc_origin 37.693718 loss_ctc0 100.415863 lr 0.00061035 rank 0
2022-08-26 04:19:44,577 DEBUG TRAIN Batch 188/4500 loss 46.703323 loss_att 28.449150 loss_ctc 89.296387 loss_ctc_origin 54.749580 loss_ctc0 169.905609 lr 0.00061032 rank 0
2022-08-26 04:20:12,885 DEBUG TRAIN Batch 188/4600 loss 56.406776 loss_att 31.473158 loss_ctc 114.585220 loss_ctc_origin 66.827583 loss_ctc0 226.019699 lr 0.00061029 rank 0
2022-08-26 04:20:40,694 DEBUG TRAIN Batch 188/4700 loss 19.361532 loss_att 10.629699 loss_ctc 39.735809 loss_ctc_origin 27.123272 loss_ctc0 69.165062 lr 0.00061026 rank 0
2022-08-26 04:21:08,503 DEBUG TRAIN Batch 188/4800 loss 21.098465 loss_att 8.968567 loss_ctc 49.401558 loss_ctc_origin 36.209446 loss_ctc0 80.183151 lr 0.00061024 rank 0
2022-08-26 04:21:19,190 WARNING NaN or Inf found in input tensor.
2022-08-26 04:21:31,704 WARNING NaN or Inf found in input tensor.
2022-08-26 04:21:36,075 DEBUG TRAIN Batch 188/4900 loss 24.590023 loss_att 10.633497 loss_ctc 57.155243 loss_ctc_origin 37.285843 loss_ctc0 103.517166 lr 0.00061021 rank 0
2022-08-26 04:22:04,570 DEBUG TRAIN Batch 188/5000 loss 43.486298 loss_att 28.116003 loss_ctc 79.350311 loss_ctc_origin 49.709763 loss_ctc0 148.511597 lr 0.00061018 rank 0
2022-08-26 04:22:31,652 DEBUG TRAIN Batch 188/5100 loss 53.009781 loss_att 28.466396 loss_ctc 110.277679 loss_ctc_origin 62.066422 loss_ctc0 222.770599 lr 0.00061015 rank 0
2022-08-26 04:22:59,833 DEBUG TRAIN Batch 188/5200 loss 16.777468 loss_att 8.284030 loss_ctc 36.595490 loss_ctc_origin 24.381645 loss_ctc0 65.094460 lr 0.00061012 rank 0
2022-08-26 04:23:28,015 DEBUG TRAIN Batch 188/5300 loss 18.643740 loss_att 7.346487 loss_ctc 45.003994 loss_ctc_origin 29.050201 loss_ctc0 82.229507 lr 0.00061009 rank 0
2022-08-26 04:23:55,495 DEBUG TRAIN Batch 188/5400 loss 19.589436 loss_att 7.801549 loss_ctc 47.094505 loss_ctc_origin 29.812254 loss_ctc0 87.419746 lr 0.00061007 rank 0
2022-08-26 04:24:22,588 DEBUG TRAIN Batch 188/5500 loss 43.475544 loss_att 28.959492 loss_ctc 77.346329 loss_ctc_origin 54.000946 loss_ctc0 131.818878 lr 0.00061004 rank 0
2022-08-26 04:24:51,036 DEBUG TRAIN Batch 188/5600 loss 51.374580 loss_att 29.824139 loss_ctc 101.658936 loss_ctc_origin 55.813557 loss_ctc0 208.631500 lr 0.00061001 rank 0
2022-08-26 04:25:13,732 DEBUG CV Batch 188/0 loss 12.121782 loss_att 8.961750 loss_ctc 19.495192 loss_ctc_origin 12.876702 loss_ctc0 34.938332 history loss 11.408736 rank 0
2022-08-26 04:25:23,436 DEBUG CV Batch 188/100 loss 19.829422 loss_att 15.869965 loss_ctc 29.068151 loss_ctc_origin 18.901657 loss_ctc0 52.789970 history loss 25.725406 rank 0
2022-08-26 04:25:32,489 DEBUG CV Batch 188/200 loss 24.636501 loss_att 19.240114 loss_ctc 37.228069 loss_ctc_origin 26.569937 loss_ctc0 62.097042 history loss 27.053655 rank 0
2022-08-26 04:25:41,664 DEBUG CV Batch 188/300 loss 22.047710 loss_att 16.826767 loss_ctc 34.229908 loss_ctc_origin 18.396553 loss_ctc0 71.174400 history loss 26.162424 rank 0
2022-08-26 04:25:51,438 DEBUG CV Batch 188/400 loss 37.501434 loss_att 30.120396 loss_ctc 54.723850 loss_ctc_origin 37.634605 loss_ctc0 94.598755 history loss 24.560172 rank 0
2022-08-26 04:26:00,957 DEBUG CV Batch 188/500 loss 15.895256 loss_att 11.492468 loss_ctc 26.168428 loss_ctc_origin 19.244926 loss_ctc0 42.323265 history loss 24.234198 rank 0
2022-08-26 04:26:10,771 DEBUG CV Batch 188/600 loss 16.819492 loss_att 11.617206 loss_ctc 28.958160 loss_ctc_origin 18.381897 loss_ctc0 53.636108 history loss 24.076350 rank 0
2022-08-26 04:26:19,921 DEBUG CV Batch 188/700 loss 18.343754 loss_att 12.676957 loss_ctc 31.566280 loss_ctc_origin 18.052588 loss_ctc0 63.098228 history loss 23.757949 rank 0
2022-08-26 04:26:29,402 DEBUG CV Batch 188/800 loss 21.578266 loss_att 16.785259 loss_ctc 32.761944 loss_ctc_origin 17.577740 loss_ctc0 68.191757 history loss 23.726459 rank 0
2022-08-26 04:26:39,120 INFO Epoch 188 CV info cv_loss 23.804061569072218
2022-08-26 04:26:39,120 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/188.pt
2022-08-26 04:26:39,581 INFO Epoch 189 TRAIN info lr 0.0006099852025484549
2022-08-26 04:26:39,584 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 04:27:05,346 DEBUG TRAIN Batch 189/0 loss 40.215973 loss_att 26.249252 loss_ctc 72.804985 loss_ctc_origin 45.978626 loss_ctc0 135.399811 lr 0.00060998 rank 0
2022-08-26 04:27:33,036 DEBUG TRAIN Batch 189/100 loss 47.550766 loss_att 26.462217 loss_ctc 96.757385 loss_ctc_origin 50.274521 loss_ctc0 205.217377 lr 0.00060996 rank 0
2022-08-26 04:28:01,170 DEBUG TRAIN Batch 189/200 loss 19.976782 loss_att 10.332182 loss_ctc 42.480846 loss_ctc_origin 33.259018 loss_ctc0 63.998440 lr 0.00060993 rank 0
2022-08-26 04:28:28,876 DEBUG TRAIN Batch 189/300 loss 19.127804 loss_att 8.342822 loss_ctc 44.292763 loss_ctc_origin 28.864210 loss_ctc0 80.292725 lr 0.00060990 rank 0
2022-08-26 04:28:58,176 DEBUG TRAIN Batch 189/400 loss 20.189175 loss_att 7.207203 loss_ctc 50.480438 loss_ctc_origin 31.353298 loss_ctc0 95.110428 lr 0.00060987 rank 0
2022-08-26 04:29:26,263 DEBUG TRAIN Batch 189/500 loss 46.388096 loss_att 29.153439 loss_ctc 86.602295 loss_ctc_origin 52.862354 loss_ctc0 165.328827 lr 0.00060984 rank 0
2022-08-26 04:29:52,519 DEBUG TRAIN Batch 189/600 loss 49.500397 loss_att 26.215942 loss_ctc 103.830780 loss_ctc_origin 48.660019 loss_ctc0 232.562561 lr 0.00060981 rank 0
2022-08-26 04:30:19,883 DEBUG TRAIN Batch 189/700 loss 18.310249 loss_att 8.623224 loss_ctc 40.913307 loss_ctc_origin 29.668806 loss_ctc0 67.150467 lr 0.00060979 rank 0
2022-08-26 04:30:25,181 WARNING NaN or Inf found in input tensor.
2022-08-26 04:30:47,222 DEBUG TRAIN Batch 189/800 loss 16.088469 loss_att 6.639490 loss_ctc 38.136086 loss_ctc_origin 22.538057 loss_ctc0 74.531479 lr 0.00060976 rank 0
2022-08-26 04:31:16,258 DEBUG TRAIN Batch 189/900 loss 21.859877 loss_att 9.505709 loss_ctc 50.686264 loss_ctc_origin 33.126465 loss_ctc0 91.659134 lr 0.00060973 rank 0
2022-08-26 04:31:41,916 DEBUG TRAIN Batch 189/1000 loss 49.469032 loss_att 32.965752 loss_ctc 87.976685 loss_ctc_origin 57.345539 loss_ctc0 159.449371 lr 0.00060970 rank 0
2022-08-26 04:32:09,994 DEBUG TRAIN Batch 189/1100 loss 60.871429 loss_att 37.013680 loss_ctc 116.539520 loss_ctc_origin 70.762131 loss_ctc0 223.353424 lr 0.00060967 rank 0
2022-08-26 04:32:35,529 WARNING NaN or Inf found in input tensor.
2022-08-26 04:32:37,103 DEBUG TRAIN Batch 189/1200 loss 18.862185 loss_att 9.655479 loss_ctc 40.344498 loss_ctc_origin 28.334120 loss_ctc0 68.368706 lr 0.00060964 rank 0
2022-08-26 04:33:03,267 DEBUG TRAIN Batch 189/1300 loss 18.894623 loss_att 7.526870 loss_ctc 45.419380 loss_ctc_origin 31.194698 loss_ctc0 78.610306 lr 0.00060962 rank 0
2022-08-26 04:33:30,797 DEBUG TRAIN Batch 189/1400 loss 20.347969 loss_att 8.111921 loss_ctc 48.898750 loss_ctc_origin 30.716803 loss_ctc0 91.323288 lr 0.00060959 rank 0
2022-08-26 04:34:03,113 DEBUG TRAIN Batch 189/1500 loss 50.979332 loss_att 33.985607 loss_ctc 90.631363 loss_ctc_origin 59.868324 loss_ctc0 162.411774 lr 0.00060956 rank 0
2022-08-26 04:34:30,579 DEBUG TRAIN Batch 189/1600 loss 56.206966 loss_att 32.947678 loss_ctc 110.478638 loss_ctc_origin 68.139145 loss_ctc0 209.270782 lr 0.00060953 rank 0
2022-08-26 04:34:56,579 WARNING NaN or Inf found in input tensor.
2022-08-26 04:34:58,205 DEBUG TRAIN Batch 189/1700 loss 18.213333 loss_att 8.799027 loss_ctc 40.180046 loss_ctc_origin 27.555395 loss_ctc0 69.637566 lr 0.00060950 rank 0
2022-08-26 04:35:25,593 DEBUG TRAIN Batch 189/1800 loss 17.879009 loss_att 6.841009 loss_ctc 43.634338 loss_ctc_origin 26.930424 loss_ctc0 82.610138 lr 0.00060947 rank 0
2022-08-26 04:35:53,366 DEBUG TRAIN Batch 189/1900 loss 21.033909 loss_att 7.738808 loss_ctc 52.055813 loss_ctc_origin 31.683786 loss_ctc0 99.590538 lr 0.00060945 rank 0
2022-08-26 04:36:20,901 DEBUG TRAIN Batch 189/2000 loss 44.545837 loss_att 28.677586 loss_ctc 81.571747 loss_ctc_origin 51.847466 loss_ctc0 150.928406 lr 0.00060942 rank 0
2022-08-26 04:36:48,602 DEBUG TRAIN Batch 189/2100 loss 58.767040 loss_att 32.303555 loss_ctc 120.515175 loss_ctc_origin 76.061401 loss_ctc0 224.240631 lr 0.00060939 rank 0
2022-08-26 04:37:16,008 DEBUG TRAIN Batch 189/2200 loss 16.701630 loss_att 9.080803 loss_ctc 34.483559 loss_ctc_origin 23.549446 loss_ctc0 59.996479 lr 0.00060936 rank 0
2022-08-26 04:37:40,159 WARNING NaN or Inf found in input tensor.
2022-08-26 04:37:43,405 DEBUG TRAIN Batch 189/2300 loss 20.726357 loss_att 9.741486 loss_ctc 46.357719 loss_ctc_origin 33.487724 loss_ctc0 76.387711 lr 0.00060933 rank 0
2022-08-26 04:38:11,106 DEBUG TRAIN Batch 189/2400 loss 18.908421 loss_att 7.197183 loss_ctc 46.234642 loss_ctc_origin 26.564735 loss_ctc0 92.131081 lr 0.00060930 rank 0
2022-08-26 04:38:39,370 DEBUG TRAIN Batch 189/2500 loss 45.127159 loss_att 28.886778 loss_ctc 83.021385 loss_ctc_origin 51.044514 loss_ctc0 157.634079 lr 0.00060928 rank 0
2022-08-26 04:39:06,579 DEBUG TRAIN Batch 189/2600 loss 55.575424 loss_att 34.086029 loss_ctc 105.717346 loss_ctc_origin 63.049183 loss_ctc0 205.276382 lr 0.00060925 rank 0
2022-08-26 04:39:34,642 DEBUG TRAIN Batch 189/2700 loss 21.168688 loss_att 10.650124 loss_ctc 45.712006 loss_ctc_origin 34.872971 loss_ctc0 71.003082 lr 0.00060922 rank 0
2022-08-26 04:40:03,946 DEBUG TRAIN Batch 189/2800 loss 18.057964 loss_att 7.271451 loss_ctc 43.226494 loss_ctc_origin 27.361559 loss_ctc0 80.244675 lr 0.00060919 rank 0
2022-08-26 04:40:30,797 DEBUG TRAIN Batch 189/2900 loss 22.003164 loss_att 8.772740 loss_ctc 52.874153 loss_ctc_origin 32.369812 loss_ctc0 100.717606 lr 0.00060916 rank 0
2022-08-26 04:40:39,007 WARNING NaN or Inf found in input tensor.
2022-08-26 04:41:04,221 DEBUG TRAIN Batch 189/3000 loss 54.642975 loss_att 37.969055 loss_ctc 93.548782 loss_ctc_origin 62.600922 loss_ctc0 165.760468 lr 0.00060913 rank 0
2022-08-26 04:41:32,480 DEBUG TRAIN Batch 189/3100 loss 58.465324 loss_att 31.409290 loss_ctc 121.596069 loss_ctc_origin 72.192444 loss_ctc0 236.871185 lr 0.00060911 rank 0
2022-08-26 04:41:59,521 DEBUG TRAIN Batch 189/3200 loss 17.838486 loss_att 9.547192 loss_ctc 37.184834 loss_ctc_origin 26.188669 loss_ctc0 62.842548 lr 0.00060908 rank 0
2022-08-26 04:42:27,985 DEBUG TRAIN Batch 189/3300 loss 19.641708 loss_att 8.194967 loss_ctc 46.350769 loss_ctc_origin 31.493671 loss_ctc0 81.017326 lr 0.00060905 rank 0
2022-08-26 04:42:55,868 DEBUG TRAIN Batch 189/3400 loss 22.383198 loss_att 9.275969 loss_ctc 52.966728 loss_ctc_origin 35.876144 loss_ctc0 92.844765 lr 0.00060902 rank 0
2022-08-26 04:43:24,534 DEBUG TRAIN Batch 189/3500 loss 43.887589 loss_att 29.433655 loss_ctc 77.613434 loss_ctc_origin 46.964951 loss_ctc0 149.126556 lr 0.00060899 rank 0
2022-08-26 04:43:51,647 DEBUG TRAIN Batch 189/3600 loss 58.748436 loss_att 34.052868 loss_ctc 116.371429 loss_ctc_origin 69.364777 loss_ctc0 226.053619 lr 0.00060897 rank 0
2022-08-26 04:44:18,765 DEBUG TRAIN Batch 189/3700 loss 17.472551 loss_att 8.095787 loss_ctc 39.351669 loss_ctc_origin 26.699352 loss_ctc0 68.873734 lr 0.00060894 rank 0
2022-08-26 04:44:45,621 DEBUG TRAIN Batch 189/3800 loss 16.967360 loss_att 6.808207 loss_ctc 40.672047 loss_ctc_origin 24.169838 loss_ctc0 79.177200 lr 0.00060891 rank 0
2022-08-26 04:45:13,562 DEBUG TRAIN Batch 189/3900 loss 21.420872 loss_att 8.862861 loss_ctc 50.722893 loss_ctc_origin 33.267735 loss_ctc0 91.451591 lr 0.00060888 rank 0
2022-08-26 04:45:41,166 DEBUG TRAIN Batch 189/4000 loss 44.266918 loss_att 29.207649 loss_ctc 79.405212 loss_ctc_origin 50.983913 loss_ctc0 145.721573 lr 0.00060885 rank 0
2022-08-26 04:46:07,685 DEBUG TRAIN Batch 189/4100 loss 50.487274 loss_att 27.488228 loss_ctc 104.151718 loss_ctc_origin 58.833973 loss_ctc0 209.893127 lr 0.00060882 rank 0
2022-08-26 04:46:35,586 DEBUG TRAIN Batch 189/4200 loss 15.965780 loss_att 7.644360 loss_ctc 35.382427 loss_ctc_origin 22.023693 loss_ctc0 66.552803 lr 0.00060880 rank 0
2022-08-26 04:47:02,941 DEBUG TRAIN Batch 189/4300 loss 21.265839 loss_att 8.533601 loss_ctc 50.974396 loss_ctc_origin 33.556438 loss_ctc0 91.616287 lr 0.00060877 rank 0
2022-08-26 04:47:31,994 DEBUG TRAIN Batch 189/4400 loss 24.737797 loss_att 10.449135 loss_ctc 58.078007 loss_ctc_origin 41.096016 loss_ctc0 97.702652 lr 0.00060874 rank 0
2022-08-26 04:48:03,852 DEBUG TRAIN Batch 189/4500 loss 44.724030 loss_att 28.695665 loss_ctc 82.123550 loss_ctc_origin 50.113960 loss_ctc0 156.812576 lr 0.00060871 rank 0
2022-08-26 04:48:31,824 DEBUG TRAIN Batch 189/4600 loss 56.806171 loss_att 29.783428 loss_ctc 119.859238 loss_ctc_origin 70.399109 loss_ctc0 235.266174 lr 0.00060868 rank 0
2022-08-26 04:48:59,907 DEBUG TRAIN Batch 189/4700 loss 20.608791 loss_att 11.449958 loss_ctc 41.979404 loss_ctc_origin 31.397415 loss_ctc0 66.670715 lr 0.00060866 rank 0
2022-08-26 04:49:27,363 DEBUG TRAIN Batch 189/4800 loss 15.812373 loss_att 6.646325 loss_ctc 37.199818 loss_ctc_origin 20.462259 loss_ctc0 76.254120 lr 0.00060863 rank 0
2022-08-26 04:49:55,354 DEBUG TRAIN Batch 189/4900 loss 22.922832 loss_att 9.945314 loss_ctc 53.203705 loss_ctc_origin 34.258896 loss_ctc0 97.408264 lr 0.00060860 rank 0
2022-08-26 04:50:23,719 DEBUG TRAIN Batch 189/5000 loss 48.434574 loss_att 29.743036 loss_ctc 92.048157 loss_ctc_origin 58.839016 loss_ctc0 169.536163 lr 0.00060857 rank 0
2022-08-26 04:50:24,347 WARNING NaN or Inf found in input tensor.
2022-08-26 04:50:50,927 DEBUG TRAIN Batch 189/5100 loss 59.507713 loss_att 34.886467 loss_ctc 116.957283 loss_ctc_origin 66.495560 loss_ctc0 234.701294 lr 0.00060854 rank 0
2022-08-26 04:51:19,423 DEBUG TRAIN Batch 189/5200 loss 23.227966 loss_att 11.277275 loss_ctc 51.112907 loss_ctc_origin 39.890625 loss_ctc0 77.298241 lr 0.00060851 rank 0
2022-08-26 04:51:46,899 DEBUG TRAIN Batch 189/5300 loss 17.500427 loss_att 6.787777 loss_ctc 42.496605 loss_ctc_origin 27.861946 loss_ctc0 76.644142 lr 0.00060849 rank 0
2022-08-26 04:52:15,189 DEBUG TRAIN Batch 189/5400 loss 18.987886 loss_att 8.213142 loss_ctc 44.128956 loss_ctc_origin 26.082647 loss_ctc0 86.237007 lr 0.00060846 rank 0
2022-08-26 04:52:42,364 DEBUG TRAIN Batch 189/5500 loss 47.429817 loss_att 28.937103 loss_ctc 90.579483 loss_ctc_origin 54.135624 loss_ctc0 175.615143 lr 0.00060843 rank 0
2022-08-26 04:53:09,869 DEBUG TRAIN Batch 189/5600 loss 52.416035 loss_att 26.546728 loss_ctc 112.777740 loss_ctc_origin 62.003830 loss_ctc0 231.250183 lr 0.00060840 rank 0
2022-08-26 04:53:32,602 DEBUG CV Batch 189/0 loss 11.756758 loss_att 8.812355 loss_ctc 18.627033 loss_ctc_origin 11.886185 loss_ctc0 34.355682 history loss 11.065184 rank 0
2022-08-26 04:53:42,828 DEBUG CV Batch 189/100 loss 19.745325 loss_att 15.951956 loss_ctc 28.596519 loss_ctc_origin 18.169125 loss_ctc0 52.927109 history loss 26.359538 rank 0
2022-08-26 04:53:52,375 DEBUG CV Batch 189/200 loss 25.315228 loss_att 19.864626 loss_ctc 38.033298 loss_ctc_origin 27.575329 loss_ctc0 62.435226 history loss 27.690167 rank 0
2022-08-26 04:54:02,227 DEBUG CV Batch 189/300 loss 23.026730 loss_att 17.083570 loss_ctc 36.894104 loss_ctc_origin 21.924002 loss_ctc0 71.824341 history loss 26.806861 rank 0
2022-08-26 04:54:12,680 DEBUG CV Batch 189/400 loss 37.335285 loss_att 30.339121 loss_ctc 53.659668 loss_ctc_origin 36.272354 loss_ctc0 94.230057 history loss 25.111193 rank 0
2022-08-26 04:54:22,890 DEBUG CV Batch 189/500 loss 15.744995 loss_att 11.442082 loss_ctc 25.785122 loss_ctc_origin 18.624908 loss_ctc0 42.492287 history loss 24.744076 rank 0
2022-08-26 04:54:33,417 DEBUG CV Batch 189/600 loss 17.194294 loss_att 11.964179 loss_ctc 29.397896 loss_ctc_origin 18.753456 loss_ctc0 54.234924 history loss 24.542084 rank 0
2022-08-26 04:54:43,424 DEBUG CV Batch 189/700 loss 18.470421 loss_att 12.784994 loss_ctc 31.736416 loss_ctc_origin 17.942938 loss_ctc0 63.921196 history loss 24.216227 rank 0
2022-08-26 04:54:53,405 DEBUG CV Batch 189/800 loss 22.026138 loss_att 17.407516 loss_ctc 32.802925 loss_ctc_origin 17.771118 loss_ctc0 67.877136 history loss 24.172811 rank 0
2022-08-26 04:55:03,568 INFO Epoch 189 CV info cv_loss 24.24608549809118
2022-08-26 04:55:03,568 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/189.pt
2022-08-26 04:55:04,010 INFO Epoch 190 TRAIN info lr 0.0006083778606174872
2022-08-26 04:55:04,013 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 04:55:29,357 DEBUG TRAIN Batch 190/0 loss 46.174301 loss_att 29.769608 loss_ctc 84.451912 loss_ctc_origin 48.634075 loss_ctc0 168.026855 lr 0.00060838 rank 0
2022-08-26 04:55:57,108 DEBUG TRAIN Batch 190/100 loss 53.990055 loss_att 29.341894 loss_ctc 111.502426 loss_ctc_origin 61.581802 loss_ctc0 227.983871 lr 0.00060835 rank 0
2022-08-26 04:56:24,490 DEBUG TRAIN Batch 190/200 loss 19.393852 loss_att 9.779243 loss_ctc 41.827942 loss_ctc_origin 29.219095 loss_ctc0 71.248581 lr 0.00060832 rank 0
2022-08-26 04:56:52,224 DEBUG TRAIN Batch 190/300 loss 16.031332 loss_att 6.312397 loss_ctc 38.708847 loss_ctc_origin 24.293858 loss_ctc0 72.343826 lr 0.00060829 rank 0
2022-08-26 04:57:20,154 DEBUG TRAIN Batch 190/400 loss 21.842251 loss_att 8.237623 loss_ctc 53.586380 loss_ctc_origin 33.423241 loss_ctc0 100.633705 lr 0.00060826 rank 0
2022-08-26 04:57:47,996 DEBUG TRAIN Batch 190/500 loss 53.237179 loss_att 35.351440 loss_ctc 94.970566 loss_ctc_origin 65.247658 loss_ctc0 164.324005 lr 0.00060824 rank 0
2022-08-26 04:58:14,693 DEBUG TRAIN Batch 190/600 loss 54.678841 loss_att 30.821117 loss_ctc 110.346848 loss_ctc_origin 60.287407 loss_ctc0 227.152191 lr 0.00060821 rank 0
2022-08-26 04:58:40,675 DEBUG TRAIN Batch 190/700 loss 18.818266 loss_att 9.557775 loss_ctc 40.426079 loss_ctc_origin 30.125736 loss_ctc0 64.460213 lr 0.00060818 rank 0
2022-08-26 04:59:08,022 DEBUG TRAIN Batch 190/800 loss 18.695719 loss_att 7.566883 loss_ctc 44.663002 loss_ctc_origin 28.570263 loss_ctc0 82.212715 lr 0.00060815 rank 0
2022-08-26 04:59:35,954 DEBUG TRAIN Batch 190/900 loss 20.907310 loss_att 8.965021 loss_ctc 48.772648 loss_ctc_origin 30.158363 loss_ctc0 92.205978 lr 0.00060812 rank 0
2022-08-26 05:00:04,502 DEBUG TRAIN Batch 190/1000 loss 51.423809 loss_att 35.362076 loss_ctc 88.901184 loss_ctc_origin 61.695450 loss_ctc0 152.381226 lr 0.00060810 rank 0
2022-08-26 05:00:32,600 DEBUG TRAIN Batch 190/1100 loss 58.800575 loss_att 32.862736 loss_ctc 119.322205 loss_ctc_origin 72.389267 loss_ctc0 228.832397 lr 0.00060807 rank 0
2022-08-26 05:01:00,858 DEBUG TRAIN Batch 190/1200 loss 16.779652 loss_att 6.613559 loss_ctc 40.500534 loss_ctc_origin 28.323925 loss_ctc0 68.912613 lr 0.00060804 rank 0
2022-08-26 05:01:28,571 DEBUG TRAIN Batch 190/1300 loss 17.892332 loss_att 7.377070 loss_ctc 42.427940 loss_ctc_origin 27.721994 loss_ctc0 76.741806 lr 0.00060801 rank 0
2022-08-26 05:01:51,517 WARNING NaN or Inf found in input tensor.
2022-08-26 05:01:55,915 DEBUG TRAIN Batch 190/1400 loss 18.372858 loss_att 8.118782 loss_ctc 42.299034 loss_ctc_origin 25.300705 loss_ctc0 81.961807 lr 0.00060798 rank 0
2022-08-26 05:02:30,117 DEBUG TRAIN Batch 190/1500 loss 53.097446 loss_att 35.428329 loss_ctc 94.325386 loss_ctc_origin 60.711159 loss_ctc0 172.758575 lr 0.00060795 rank 0
2022-08-26 05:02:57,543 DEBUG TRAIN Batch 190/1600 loss 58.915657 loss_att 33.948341 loss_ctc 117.172729 loss_ctc_origin 70.415848 loss_ctc0 226.272125 lr 0.00060793 rank 0
2022-08-26 05:03:25,511 DEBUG TRAIN Batch 190/1700 loss 16.681053 loss_att 8.768637 loss_ctc 35.143356 loss_ctc_origin 22.566208 loss_ctc0 64.490028 lr 0.00060790 rank 0
2022-08-26 05:03:54,211 DEBUG TRAIN Batch 190/1800 loss 16.872635 loss_att 6.408005 loss_ctc 41.290100 loss_ctc_origin 25.798206 loss_ctc0 77.437851 lr 0.00060787 rank 0
2022-08-26 05:04:21,929 DEBUG TRAIN Batch 190/1900 loss 19.511177 loss_att 7.800241 loss_ctc 46.836697 loss_ctc_origin 26.623890 loss_ctc0 93.999908 lr 0.00060784 rank 0
2022-08-26 05:04:49,554 DEBUG TRAIN Batch 190/2000 loss 53.779156 loss_att 34.415520 loss_ctc 98.960968 loss_ctc_origin 68.352104 loss_ctc0 170.381653 lr 0.00060781 rank 0
2022-08-26 05:05:17,081 DEBUG TRAIN Batch 190/2100 loss 51.656357 loss_att 28.056490 loss_ctc 106.722710 loss_ctc_origin 54.071697 loss_ctc0 229.575058 lr 0.00060779 rank 0
2022-08-26 05:05:44,996 DEBUG TRAIN Batch 190/2200 loss 20.236858 loss_att 10.873052 loss_ctc 42.085739 loss_ctc_origin 31.428873 loss_ctc0 66.951759 lr 0.00060776 rank 0
2022-08-26 05:06:12,691 DEBUG TRAIN Batch 190/2300 loss 14.756392 loss_att 4.902066 loss_ctc 37.749817 loss_ctc_origin 22.520994 loss_ctc0 73.283737 lr 0.00060773 rank 0
2022-08-26 05:06:29,250 WARNING NaN or Inf found in input tensor.
2022-08-26 05:06:40,250 DEBUG TRAIN Batch 190/2400 loss 19.298374 loss_att 7.864717 loss_ctc 45.976906 loss_ctc_origin 27.518051 loss_ctc0 89.047562 lr 0.00060770 rank 0
2022-08-26 05:07:08,294 DEBUG TRAIN Batch 190/2500 loss 44.542992 loss_att 28.897682 loss_ctc 81.048721 loss_ctc_origin 51.744255 loss_ctc0 149.425812 lr 0.00060767 rank 0
2022-08-26 05:07:35,273 DEBUG TRAIN Batch 190/2600 loss 55.950783 loss_att 32.858185 loss_ctc 109.833511 loss_ctc_origin 65.207474 loss_ctc0 213.960938 lr 0.00060765 rank 0
2022-08-26 05:08:03,207 DEBUG TRAIN Batch 190/2700 loss 17.921097 loss_att 9.429320 loss_ctc 37.735237 loss_ctc_origin 27.228964 loss_ctc0 62.249878 lr 0.00060762 rank 0
2022-08-26 05:08:30,356 DEBUG TRAIN Batch 190/2800 loss 21.562710 loss_att 8.136427 loss_ctc 52.890701 loss_ctc_origin 39.321667 loss_ctc0 84.551788 lr 0.00060759 rank 0
2022-08-26 05:08:58,337 DEBUG TRAIN Batch 190/2900 loss 23.234898 loss_att 9.660279 loss_ctc 54.909004 loss_ctc_origin 36.032608 loss_ctc0 98.953918 lr 0.00060756 rank 0
2022-08-26 05:09:31,966 DEBUG TRAIN Batch 190/3000 loss 43.629578 loss_att 28.662075 loss_ctc 78.553757 loss_ctc_origin 48.338768 loss_ctc0 149.055405 lr 0.00060753 rank 0
2022-08-26 05:10:00,380 DEBUG TRAIN Batch 190/3100 loss 53.159286 loss_att 27.404266 loss_ctc 113.254333 loss_ctc_origin 62.346703 loss_ctc0 232.038788 lr 0.00060751 rank 0
2022-08-26 05:10:27,897 DEBUG TRAIN Batch 190/3200 loss 18.485468 loss_att 8.612183 loss_ctc 41.523132 loss_ctc_origin 31.518448 loss_ctc0 64.867386 lr 0.00060748 rank 0
2022-08-26 05:10:56,005 DEBUG TRAIN Batch 190/3300 loss 18.901505 loss_att 7.569553 loss_ctc 45.342724 loss_ctc_origin 30.193878 loss_ctc0 80.690033 lr 0.00060745 rank 0
2022-08-26 05:11:23,023 DEBUG TRAIN Batch 190/3400 loss 22.167221 loss_att 9.701853 loss_ctc 51.253082 loss_ctc_origin 32.779129 loss_ctc0 94.358963 lr 0.00060742 rank 0
2022-08-26 05:11:51,235 DEBUG TRAIN Batch 190/3500 loss 40.507584 loss_att 22.489407 loss_ctc 82.549988 loss_ctc_origin 47.848129 loss_ctc0 163.520966 lr 0.00060739 rank 0
2022-08-26 05:12:18,444 DEBUG TRAIN Batch 190/3600 loss 51.842712 loss_att 27.784233 loss_ctc 107.979156 loss_ctc_origin 53.740875 loss_ctc0 234.535126 lr 0.00060737 rank 0
2022-08-26 05:12:45,019 DEBUG TRAIN Batch 190/3700 loss 16.668419 loss_att 8.197323 loss_ctc 36.434307 loss_ctc_origin 24.763218 loss_ctc0 63.666847 lr 0.00060734 rank 0
2022-08-26 05:13:12,940 DEBUG TRAIN Batch 190/3800 loss 17.658331 loss_att 7.261033 loss_ctc 41.918694 loss_ctc_origin 27.026953 loss_ctc0 76.666077 lr 0.00060731 rank 0
2022-08-26 05:13:39,962 DEBUG TRAIN Batch 190/3900 loss 20.713505 loss_att 8.077404 loss_ctc 50.197739 loss_ctc_origin 34.688904 loss_ctc0 86.385010 lr 0.00060728 rank 0
2022-08-26 05:14:07,550 DEBUG TRAIN Batch 190/4000 loss 41.306198 loss_att 23.707336 loss_ctc 82.370201 loss_ctc_origin 48.115860 loss_ctc0 162.296982 lr 0.00060725 rank 0
2022-08-26 05:14:34,677 DEBUG TRAIN Batch 190/4100 loss 53.147160 loss_att 27.105129 loss_ctc 113.911888 loss_ctc_origin 60.140228 loss_ctc0 239.379074 lr 0.00060723 rank 0
2022-08-26 05:15:01,915 DEBUG TRAIN Batch 190/4200 loss 18.871708 loss_att 11.364737 loss_ctc 36.387978 loss_ctc_origin 25.130367 loss_ctc0 62.655731 lr 0.00060720 rank 0
2022-08-26 05:15:29,542 DEBUG TRAIN Batch 190/4300 loss 17.544167 loss_att 6.865292 loss_ctc 42.461536 loss_ctc_origin 28.593555 loss_ctc0 74.820160 lr 0.00060717 rank 0
2022-08-26 05:15:57,002 DEBUG TRAIN Batch 190/4400 loss 18.187532 loss_att 6.810906 loss_ctc 44.732990 loss_ctc_origin 27.112829 loss_ctc0 85.846695 lr 0.00060714 rank 0
2022-08-26 05:16:31,246 DEBUG TRAIN Batch 190/4500 loss 50.808334 loss_att 32.914146 loss_ctc 92.561447 loss_ctc_origin 61.475285 loss_ctc0 165.095825 lr 0.00060711 rank 0
2022-08-26 05:16:59,336 DEBUG TRAIN Batch 190/4600 loss 55.638317 loss_att 31.311375 loss_ctc 112.401184 loss_ctc_origin 62.426407 loss_ctc0 229.009003 lr 0.00060709 rank 0
2022-08-26 05:17:26,802 DEBUG TRAIN Batch 190/4700 loss 23.915451 loss_att 13.202308 loss_ctc 48.912785 loss_ctc_origin 40.707184 loss_ctc0 68.059189 lr 0.00060706 rank 0
2022-08-26 05:17:54,202 DEBUG TRAIN Batch 190/4800 loss 16.378920 loss_att 6.475812 loss_ctc 39.486168 loss_ctc_origin 25.539478 loss_ctc0 72.028442 lr 0.00060703 rank 0
2022-08-26 05:18:22,663 DEBUG TRAIN Batch 190/4900 loss 23.852070 loss_att 10.775393 loss_ctc 54.364315 loss_ctc_origin 37.377884 loss_ctc0 93.999321 lr 0.00060700 rank 0
2022-08-26 05:18:50,614 DEBUG TRAIN Batch 190/5000 loss 50.921494 loss_att 32.972225 loss_ctc 92.803123 loss_ctc_origin 59.416126 loss_ctc0 170.706100 lr 0.00060697 rank 0
2022-08-26 05:19:17,850 DEBUG TRAIN Batch 190/5100 loss 65.690048 loss_att 36.580303 loss_ctc 133.612762 loss_ctc_origin 80.399612 loss_ctc0 257.776794 lr 0.00060695 rank 0
2022-08-26 05:19:45,377 DEBUG TRAIN Batch 190/5200 loss 17.937687 loss_att 9.063108 loss_ctc 38.645035 loss_ctc_origin 27.301895 loss_ctc0 65.112366 lr 0.00060692 rank 0
2022-08-26 05:20:12,816 DEBUG TRAIN Batch 190/5300 loss 21.765060 loss_att 8.620440 loss_ctc 52.435837 loss_ctc_origin 38.534775 loss_ctc0 84.871635 lr 0.00060689 rank 0
2022-08-26 05:20:40,570 DEBUG TRAIN Batch 190/5400 loss 20.118271 loss_att 8.939188 loss_ctc 46.202797 loss_ctc_origin 28.597322 loss_ctc0 87.282227 lr 0.00060686 rank 0
2022-08-26 05:21:08,733 DEBUG TRAIN Batch 190/5500 loss 53.055443 loss_att 33.187050 loss_ctc 99.415024 loss_ctc_origin 59.786934 loss_ctc0 191.880554 lr 0.00060683 rank 0
2022-08-26 05:21:36,477 DEBUG TRAIN Batch 190/5600 loss 62.599430 loss_att 35.675774 loss_ctc 125.421295 loss_ctc_origin 73.374626 loss_ctc0 246.863510 lr 0.00060681 rank 0
2022-08-26 05:21:59,724 DEBUG CV Batch 190/0 loss 11.914452 loss_att 8.947572 loss_ctc 18.837173 loss_ctc_origin 12.114588 loss_ctc0 34.523205 history loss 11.213602 rank 0
2022-08-26 05:22:10,439 DEBUG CV Batch 190/100 loss 20.110294 loss_att 16.146803 loss_ctc 29.358442 loss_ctc_origin 19.169140 loss_ctc0 53.133480 history loss 26.328618 rank 0
2022-08-26 05:22:20,121 DEBUG CV Batch 190/200 loss 24.420036 loss_att 19.120674 loss_ctc 36.785210 loss_ctc_origin 25.918453 loss_ctc0 62.140972 history loss 27.714265 rank 0
2022-08-26 05:22:30,038 DEBUG CV Batch 190/300 loss 22.402502 loss_att 17.041859 loss_ctc 34.910667 loss_ctc_origin 19.222528 loss_ctc0 71.516327 history loss 26.765705 rank 0
2022-08-26 05:22:40,299 DEBUG CV Batch 190/400 loss 37.014160 loss_att 29.762186 loss_ctc 53.935432 loss_ctc_origin 36.304718 loss_ctc0 95.073761 history loss 25.082449 rank 0
2022-08-26 05:22:50,643 DEBUG CV Batch 190/500 loss 16.188005 loss_att 11.801726 loss_ctc 26.422657 loss_ctc_origin 19.325459 loss_ctc0 42.982788 history loss 24.721168 rank 0
2022-08-26 05:23:01,034 DEBUG CV Batch 190/600 loss 17.180481 loss_att 12.047708 loss_ctc 29.156952 loss_ctc_origin 18.350594 loss_ctc0 54.371784 history loss 24.510157 rank 0
2022-08-26 05:23:11,081 DEBUG CV Batch 190/700 loss 18.595051 loss_att 13.022724 loss_ctc 31.597147 loss_ctc_origin 17.844315 loss_ctc0 63.687088 history loss 24.187264 rank 0
2022-08-26 05:23:21,285 DEBUG CV Batch 190/800 loss 22.119162 loss_att 17.286085 loss_ctc 33.396339 loss_ctc_origin 18.555214 loss_ctc0 68.025635 history loss 24.148999 rank 0
2022-08-26 05:23:31,863 INFO Epoch 190 CV info cv_loss 24.231916768291104
2022-08-26 05:23:31,863 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/190.pt
2022-08-26 05:23:32,294 INFO Epoch 191 TRAIN info lr 0.0006067831583710604
2022-08-26 05:23:32,297 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 05:23:58,265 DEBUG TRAIN Batch 191/0 loss 52.753281 loss_att 32.937836 loss_ctc 98.989326 loss_ctc_origin 62.647251 loss_ctc0 183.787491 lr 0.00060678 rank 0
2022-08-26 05:24:25,386 DEBUG TRAIN Batch 191/100 loss 58.791641 loss_att 33.276295 loss_ctc 118.327454 loss_ctc_origin 61.438244 loss_ctc0 251.068909 lr 0.00060675 rank 0
2022-08-26 05:24:52,237 DEBUG TRAIN Batch 191/200 loss 18.350765 loss_att 7.955621 loss_ctc 42.606098 loss_ctc_origin 31.159542 loss_ctc0 69.314728 lr 0.00060673 rank 0
2022-08-26 05:25:20,205 DEBUG TRAIN Batch 191/300 loss 18.338974 loss_att 7.191887 loss_ctc 44.348839 loss_ctc_origin 29.943398 loss_ctc0 77.961540 lr 0.00060670 rank 0
2022-08-26 05:25:47,504 DEBUG TRAIN Batch 191/400 loss 20.316650 loss_att 8.023883 loss_ctc 48.999771 loss_ctc_origin 30.587475 loss_ctc0 91.961792 lr 0.00060667 rank 0
2022-08-26 05:26:16,677 DEBUG TRAIN Batch 191/500 loss 48.867668 loss_att 32.553303 loss_ctc 86.934525 loss_ctc_origin 52.002602 loss_ctc0 168.442322 lr 0.00060664 rank 0
2022-08-26 05:26:43,314 DEBUG TRAIN Batch 191/600 loss 67.652885 loss_att 39.957726 loss_ctc 132.274933 loss_ctc_origin 77.390808 loss_ctc0 260.337891 lr 0.00060661 rank 0
2022-08-26 05:27:10,928 DEBUG TRAIN Batch 191/700 loss 19.252932 loss_att 10.099962 loss_ctc 40.609856 loss_ctc_origin 30.105816 loss_ctc0 65.119278 lr 0.00060659 rank 0
2022-08-26 05:27:16,271 WARNING NaN or Inf found in input tensor.
2022-08-26 05:27:38,695 DEBUG TRAIN Batch 191/800 loss 16.768623 loss_att 6.412494 loss_ctc 40.932926 loss_ctc_origin 23.874428 loss_ctc0 80.736084 lr 0.00060656 rank 0
2022-08-26 05:28:06,413 DEBUG TRAIN Batch 191/900 loss 22.940605 loss_att 9.509470 loss_ctc 54.279915 loss_ctc_origin 34.019203 loss_ctc0 101.554901 lr 0.00060653 rank 0
2022-08-26 05:28:33,893 DEBUG TRAIN Batch 191/1000 loss 49.747269 loss_att 31.195375 loss_ctc 93.035011 loss_ctc_origin 60.060585 loss_ctc0 169.975342 lr 0.00060650 rank 0
2022-08-26 05:29:01,209 DEBUG TRAIN Batch 191/1100 loss 71.461472 loss_att 41.758736 loss_ctc 140.767838 loss_ctc_origin 85.969757 loss_ctc0 268.630005 lr 0.00060648 rank 0
2022-08-26 05:29:28,429 DEBUG TRAIN Batch 191/1200 loss 18.391802 loss_att 11.456619 loss_ctc 34.573895 loss_ctc_origin 23.724161 loss_ctc0 59.889938 lr 0.00060645 rank 0
2022-08-26 05:29:45,916 WARNING NaN or Inf found in input tensor.
2022-08-26 05:29:55,560 DEBUG TRAIN Batch 191/1300 loss 18.473259 loss_att 8.316097 loss_ctc 42.173302 loss_ctc_origin 26.655962 loss_ctc0 78.380417 lr 0.00060642 rank 0
2022-08-26 05:30:18,342 WARNING NaN or Inf found in input tensor.
2022-08-26 05:30:22,839 DEBUG TRAIN Batch 191/1400 loss 20.011421 loss_att 8.042384 loss_ctc 47.939175 loss_ctc_origin 32.111935 loss_ctc0 84.869400 lr 0.00060639 rank 0
2022-08-26 05:30:56,151 DEBUG TRAIN Batch 191/1500 loss 57.839867 loss_att 38.390297 loss_ctc 103.222198 loss_ctc_origin 64.113602 loss_ctc0 194.475586 lr 0.00060636 rank 0
2022-08-26 05:31:24,233 DEBUG TRAIN Batch 191/1600 loss 63.795071 loss_att 33.615101 loss_ctc 134.214996 loss_ctc_origin 78.517525 loss_ctc0 264.175751 lr 0.00060634 rank 0
2022-08-26 05:31:51,583 DEBUG TRAIN Batch 191/1700 loss 19.979820 loss_att 11.714402 loss_ctc 39.265789 loss_ctc_origin 28.597401 loss_ctc0 64.158691 lr 0.00060631 rank 0
2022-08-26 05:32:19,100 DEBUG TRAIN Batch 191/1800 loss 20.461901 loss_att 8.070934 loss_ctc 49.374153 loss_ctc_origin 34.616299 loss_ctc0 83.809151 lr 0.00060628 rank 0
2022-08-26 05:32:45,934 DEBUG TRAIN Batch 191/1900 loss 20.517572 loss_att 8.476459 loss_ctc 48.613503 loss_ctc_origin 29.894997 loss_ctc0 92.290009 lr 0.00060625 rank 0
2022-08-26 05:33:13,543 DEBUG TRAIN Batch 191/2000 loss 44.285774 loss_att 27.039911 loss_ctc 84.526108 loss_ctc_origin 48.886353 loss_ctc0 167.685516 lr 0.00060622 rank 0
2022-08-26 05:33:40,932 DEBUG TRAIN Batch 191/2100 loss 64.058479 loss_att 35.815506 loss_ctc 129.958740 loss_ctc_origin 65.606354 loss_ctc0 280.114288 lr 0.00060620 rank 0
2022-08-26 05:34:08,820 DEBUG TRAIN Batch 191/2200 loss 21.807331 loss_att 13.359104 loss_ctc 41.519859 loss_ctc_origin 31.313858 loss_ctc0 65.333862 lr 0.00060617 rank 0
2022-08-26 05:34:33,499 WARNING NaN or Inf found in input tensor.
2022-08-26 05:34:36,730 DEBUG TRAIN Batch 191/2300 loss 18.793667 loss_att 7.114261 loss_ctc 46.045616 loss_ctc_origin 33.999680 loss_ctc0 74.152794 lr 0.00060614 rank 0
2022-08-26 05:35:04,443 DEBUG TRAIN Batch 191/2400 loss 20.451916 loss_att 8.707836 loss_ctc 47.854767 loss_ctc_origin 26.639835 loss_ctc0 97.356270 lr 0.00060611 rank 0
2022-08-26 05:35:32,064 DEBUG TRAIN Batch 191/2500 loss 42.987061 loss_att 25.742830 loss_ctc 83.223587 loss_ctc_origin 45.647591 loss_ctc0 170.900909 lr 0.00060609 rank 0
2022-08-26 05:35:59,120 DEBUG TRAIN Batch 191/2600 loss 54.742752 loss_att 30.172203 loss_ctc 112.074020 loss_ctc_origin 58.446934 loss_ctc0 237.203888 lr 0.00060606 rank 0
2022-08-26 05:36:26,775 DEBUG TRAIN Batch 191/2700 loss 18.354795 loss_att 9.885970 loss_ctc 38.115387 loss_ctc_origin 26.281864 loss_ctc0 65.726936 lr 0.00060603 rank 0
2022-08-26 05:36:54,988 DEBUG TRAIN Batch 191/2800 loss 20.090212 loss_att 8.770585 loss_ctc 46.502670 loss_ctc_origin 34.081852 loss_ctc0 75.484581 lr 0.00060600 rank 0
2022-08-26 05:37:23,783 DEBUG TRAIN Batch 191/2900 loss 23.782108 loss_att 10.185661 loss_ctc 55.507149 loss_ctc_origin 35.692474 loss_ctc0 101.741386 lr 0.00060597 rank 0
2022-08-26 05:37:57,171 DEBUG TRAIN Batch 191/3000 loss 45.672310 loss_att 28.495743 loss_ctc 85.750961 loss_ctc_origin 52.441830 loss_ctc0 163.472260 lr 0.00060595 rank 0
2022-08-26 05:37:57,963 WARNING NaN or Inf found in input tensor.
2022-08-26 05:38:25,266 DEBUG TRAIN Batch 191/3100 loss 58.795536 loss_att 34.226604 loss_ctc 116.123047 loss_ctc_origin 61.005222 loss_ctc0 244.731293 lr 0.00060592 rank 0
2022-08-26 05:38:51,025 WARNING NaN or Inf found in input tensor.
2022-08-26 05:38:52,620 DEBUG TRAIN Batch 191/3200 loss 18.355438 loss_att 10.218971 loss_ctc 37.340527 loss_ctc_origin 26.705252 loss_ctc0 62.156166 lr 0.00060589 rank 0
2022-08-26 05:39:20,259 DEBUG TRAIN Batch 191/3300 loss 18.915817 loss_att 8.204016 loss_ctc 43.910023 loss_ctc_origin 29.426086 loss_ctc0 77.705872 lr 0.00060586 rank 0
2022-08-26 05:39:47,569 DEBUG TRAIN Batch 191/3400 loss 21.850370 loss_att 8.502644 loss_ctc 52.995064 loss_ctc_origin 35.572926 loss_ctc0 93.646721 lr 0.00060583 rank 0
2022-08-26 05:40:15,261 DEBUG TRAIN Batch 191/3500 loss 50.805378 loss_att 30.837711 loss_ctc 97.396599 loss_ctc_origin 62.843811 loss_ctc0 178.019775 lr 0.00060581 rank 0
2022-08-26 05:40:42,510 DEBUG TRAIN Batch 191/3600 loss 64.576752 loss_att 36.336750 loss_ctc 130.470093 loss_ctc_origin 66.473373 loss_ctc0 279.795776 lr 0.00060578 rank 0
2022-08-26 05:41:10,626 DEBUG TRAIN Batch 191/3700 loss 19.895351 loss_att 10.693983 loss_ctc 41.365211 loss_ctc_origin 30.934570 loss_ctc0 65.703377 lr 0.00060575 rank 0
2022-08-26 05:41:37,688 DEBUG TRAIN Batch 191/3800 loss 18.661602 loss_att 7.242965 loss_ctc 45.305092 loss_ctc_origin 29.005800 loss_ctc0 83.336761 lr 0.00060572 rank 0
2022-08-26 05:42:05,521 DEBUG TRAIN Batch 191/3900 loss 21.185064 loss_att 9.160585 loss_ctc 49.242180 loss_ctc_origin 33.363708 loss_ctc0 86.291946 lr 0.00060570 rank 0
2022-08-26 05:42:32,163 DEBUG TRAIN Batch 191/4000 loss 51.961685 loss_att 31.470074 loss_ctc 99.775436 loss_ctc_origin 60.594406 loss_ctc0 191.197830 lr 0.00060567 rank 0
2022-08-26 05:42:45,832 WARNING NaN or Inf found in input tensor.
2022-08-26 05:42:52,540 WARNING NaN or Inf found in input tensor.
2022-08-26 05:42:59,152 DEBUG TRAIN Batch 191/4100 loss 65.725151 loss_att 35.784878 loss_ctc 135.585785 loss_ctc_origin 70.044334 loss_ctc0 288.515808 lr 0.00060564 rank 0
2022-08-26 05:43:27,181 DEBUG TRAIN Batch 191/4200 loss 25.137142 loss_att 14.634598 loss_ctc 49.643082 loss_ctc_origin 39.486343 loss_ctc0 73.342133 lr 0.00060561 rank 0
2022-08-26 05:43:55,147 DEBUG TRAIN Batch 191/4300 loss 17.222120 loss_att 7.083105 loss_ctc 40.879822 loss_ctc_origin 25.860964 loss_ctc0 75.923828 lr 0.00060558 rank 0
2022-08-26 05:44:22,988 DEBUG TRAIN Batch 191/4400 loss 20.052113 loss_att 7.816481 loss_ctc 48.601921 loss_ctc_origin 30.281219 loss_ctc0 91.350212 lr 0.00060556 rank 0
2022-08-26 05:44:56,192 DEBUG TRAIN Batch 191/4500 loss 51.586044 loss_att 30.466379 loss_ctc 100.865250 loss_ctc_origin 59.953873 loss_ctc0 196.325119 lr 0.00060553 rank 0
2022-08-26 05:45:24,281 DEBUG TRAIN Batch 191/4600 loss 63.988132 loss_att 33.454269 loss_ctc 135.233810 loss_ctc_origin 79.934555 loss_ctc0 264.265411 lr 0.00060550 rank 0
2022-08-26 05:45:37,416 WARNING NaN or Inf found in input tensor.
2022-08-26 05:45:50,125 WARNING NaN or Inf found in input tensor.
2022-08-26 05:45:51,664 DEBUG TRAIN Batch 191/4700 loss 16.394518 loss_att 7.679773 loss_ctc 36.728920 loss_ctc_origin 24.905312 loss_ctc0 64.317329 lr 0.00060547 rank 0
2022-08-26 05:46:20,095 DEBUG TRAIN Batch 191/4800 loss 16.792564 loss_att 7.186746 loss_ctc 39.206139 loss_ctc_origin 25.192591 loss_ctc0 71.904411 lr 0.00060545 rank 0
2022-08-26 05:46:47,454 DEBUG TRAIN Batch 191/4900 loss 20.451511 loss_att 7.742834 loss_ctc 50.105091 loss_ctc_origin 29.868446 loss_ctc0 97.323929 lr 0.00060542 rank 0
2022-08-26 05:47:15,269 DEBUG TRAIN Batch 191/5000 loss 48.037712 loss_att 31.214184 loss_ctc 87.292618 loss_ctc_origin 51.452744 loss_ctc0 170.919006 lr 0.00060539 rank 0
2022-08-26 05:47:43,295 DEBUG TRAIN Batch 191/5100 loss 64.285576 loss_att 36.827805 loss_ctc 128.353699 loss_ctc_origin 69.509201 loss_ctc0 265.657501 lr 0.00060536 rank 0
2022-08-26 05:48:10,696 DEBUG TRAIN Batch 191/5200 loss 18.385906 loss_att 9.866896 loss_ctc 38.263592 loss_ctc_origin 26.527210 loss_ctc0 65.648483 lr 0.00060534 rank 0
2022-08-26 05:48:39,185 DEBUG TRAIN Batch 191/5300 loss 19.603203 loss_att 8.091413 loss_ctc 46.464046 loss_ctc_origin 30.115564 loss_ctc0 84.610504 lr 0.00060531 rank 0
2022-08-26 05:49:06,723 DEBUG TRAIN Batch 191/5400 loss 22.547031 loss_att 9.808430 loss_ctc 52.270435 loss_ctc_origin 34.872173 loss_ctc0 92.866379 lr 0.00060528 rank 0
2022-08-26 05:49:34,372 DEBUG TRAIN Batch 191/5500 loss 53.303001 loss_att 34.680210 loss_ctc 96.756180 loss_ctc_origin 59.451111 loss_ctc0 183.801331 lr 0.00060525 rank 0
2022-08-26 05:50:02,341 DEBUG TRAIN Batch 191/5600 loss 58.270638 loss_att 32.199921 loss_ctc 119.102310 loss_ctc_origin 61.735394 loss_ctc0 252.958435 lr 0.00060522 rank 0
2022-08-26 05:50:25,021 DEBUG CV Batch 191/0 loss 12.397448 loss_att 9.631560 loss_ctc 18.851183 loss_ctc_origin 12.343846 loss_ctc0 34.034966 history loss 11.668186 rank 0
2022-08-26 05:50:35,264 DEBUG CV Batch 191/100 loss 20.103882 loss_att 16.501713 loss_ctc 28.508942 loss_ctc_origin 18.445988 loss_ctc0 51.989162 history loss 26.425012 rank 0
2022-08-26 05:50:44,662 DEBUG CV Batch 191/200 loss 26.201481 loss_att 20.999636 loss_ctc 38.339119 loss_ctc_origin 27.950539 loss_ctc0 62.579140 history loss 27.733048 rank 0
2022-08-26 05:50:54,038 DEBUG CV Batch 191/300 loss 21.528397 loss_att 16.293110 loss_ctc 33.744068 loss_ctc_origin 17.724361 loss_ctc0 71.123383 history loss 26.834734 rank 0
2022-08-26 05:51:04,694 DEBUG CV Batch 191/400 loss 37.494179 loss_att 29.987572 loss_ctc 55.009590 loss_ctc_origin 37.882477 loss_ctc0 94.972847 history loss 25.175524 rank 0
2022-08-26 05:51:14,986 DEBUG CV Batch 191/500 loss 16.333626 loss_att 11.805501 loss_ctc 26.899250 loss_ctc_origin 20.441862 loss_ctc0 41.966492 history loss 24.840901 rank 0
2022-08-26 05:51:25,348 DEBUG CV Batch 191/600 loss 17.685505 loss_att 12.700771 loss_ctc 29.316544 loss_ctc_origin 18.957027 loss_ctc0 53.488747 history loss 24.634929 rank 0
2022-08-26 05:51:35,242 DEBUG CV Batch 191/700 loss 18.753761 loss_att 13.348672 loss_ctc 31.365635 loss_ctc_origin 17.749369 loss_ctc0 63.136925 history loss 24.296666 rank 0
2022-08-26 05:51:45,489 DEBUG CV Batch 191/800 loss 21.494118 loss_att 16.648468 loss_ctc 32.800629 loss_ctc_origin 17.821054 loss_ctc0 67.752968 history loss 24.248167 rank 0
2022-08-26 05:51:55,847 INFO Epoch 191 CV info cv_loss 24.329509886076455
2022-08-26 05:51:55,847 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/191.pt
2022-08-26 05:51:56,280 INFO Epoch 192 TRAIN info lr 0.0006052009310147154
2022-08-26 05:51:56,284 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 05:52:22,249 DEBUG TRAIN Batch 192/0 loss 53.402096 loss_att 32.414139 loss_ctc 102.373993 loss_ctc_origin 59.916031 loss_ctc0 201.442566 lr 0.00060520 rank 0
2022-08-26 05:52:49,327 DEBUG TRAIN Batch 192/100 loss 55.548676 loss_att 27.434378 loss_ctc 121.148705 loss_ctc_origin 66.264038 loss_ctc0 249.212921 lr 0.00060517 rank 0
2022-08-26 05:53:16,960 DEBUG TRAIN Batch 192/200 loss 22.559856 loss_att 11.406438 loss_ctc 48.584496 loss_ctc_origin 39.518875 loss_ctc0 69.737610 lr 0.00060514 rank 0
2022-08-26 05:53:44,919 DEBUG TRAIN Batch 192/300 loss 16.742634 loss_att 6.228266 loss_ctc 41.276157 loss_ctc_origin 25.812185 loss_ctc0 77.358757 lr 0.00060512 rank 0
2022-08-26 05:54:13,345 DEBUG TRAIN Batch 192/400 loss 21.237886 loss_att 8.983243 loss_ctc 49.832054 loss_ctc_origin 29.711752 loss_ctc0 96.779419 lr 0.00060509 rank 0
2022-08-26 05:54:41,742 DEBUG TRAIN Batch 192/500 loss 41.856049 loss_att 25.225508 loss_ctc 80.660645 loss_ctc_origin 44.589832 loss_ctc0 164.825867 lr 0.00060506 rank 0
2022-08-26 05:55:08,809 DEBUG TRAIN Batch 192/600 loss 58.599037 loss_att 31.461735 loss_ctc 121.919395 loss_ctc_origin 68.258286 loss_ctc0 247.128647 lr 0.00060503 rank 0
2022-08-26 05:55:35,850 DEBUG TRAIN Batch 192/700 loss 24.022644 loss_att 12.620281 loss_ctc 50.628159 loss_ctc_origin 41.677765 loss_ctc0 71.512413 lr 0.00060501 rank 0
2022-08-26 05:56:03,354 DEBUG TRAIN Batch 192/800 loss 20.927811 loss_att 9.297807 loss_ctc 48.064484 loss_ctc_origin 32.072872 loss_ctc0 85.378250 lr 0.00060498 rank 0
2022-08-26 05:56:31,055 DEBUG TRAIN Batch 192/900 loss 21.864391 loss_att 8.199475 loss_ctc 53.749199 loss_ctc_origin 32.179817 loss_ctc0 104.077759 lr 0.00060495 rank 0
2022-08-26 05:56:51,028 WARNING NaN or Inf found in input tensor.
2022-08-26 05:56:58,062 DEBUG TRAIN Batch 192/1000 loss 42.628296 loss_att 25.782461 loss_ctc 81.935242 loss_ctc_origin 46.457237 loss_ctc0 164.717255 lr 0.00060492 rank 0
2022-08-26 05:57:26,643 DEBUG TRAIN Batch 192/1100 loss 59.983681 loss_att 31.751249 loss_ctc 125.859344 loss_ctc_origin 70.212601 loss_ctc0 255.701752 lr 0.00060490 rank 0
2022-08-26 05:57:53,611 DEBUG TRAIN Batch 192/1200 loss 16.353683 loss_att 8.281588 loss_ctc 35.188576 loss_ctc_origin 23.511984 loss_ctc0 62.433945 lr 0.00060487 rank 0
2022-08-26 05:58:20,505 DEBUG TRAIN Batch 192/1300 loss 18.365774 loss_att 7.383107 loss_ctc 43.991997 loss_ctc_origin 28.867256 loss_ctc0 79.283051 lr 0.00060484 rank 0
2022-08-26 05:58:48,723 DEBUG TRAIN Batch 192/1400 loss 22.294342 loss_att 9.030767 loss_ctc 53.242683 loss_ctc_origin 35.297085 loss_ctc0 95.115738 lr 0.00060481 rank 0
2022-08-26 05:59:21,874 DEBUG TRAIN Batch 192/1500 loss 39.941845 loss_att 23.085159 loss_ctc 79.274109 loss_ctc_origin 41.140808 loss_ctc0 168.251801 lr 0.00060478 rank 0
2022-08-26 05:59:36,672 WARNING NaN or Inf found in input tensor.
2022-08-26 05:59:49,828 DEBUG TRAIN Batch 192/1600 loss 56.771332 loss_att 29.954124 loss_ctc 119.344818 loss_ctc_origin 57.951859 loss_ctc0 262.595062 lr 0.00060476 rank 0
2022-08-26 06:00:16,820 WARNING NaN or Inf found in input tensor.
2022-08-26 06:00:18,582 DEBUG TRAIN Batch 192/1700 loss 18.949051 loss_att 8.849803 loss_ctc 42.513962 loss_ctc_origin 28.353767 loss_ctc0 75.554420 lr 0.00060473 rank 0
2022-08-26 06:00:45,717 DEBUG TRAIN Batch 192/1800 loss 18.659908 loss_att 7.352401 loss_ctc 45.044090 loss_ctc_origin 28.229454 loss_ctc0 84.278229 lr 0.00060470 rank 0
2022-08-26 06:01:13,074 DEBUG TRAIN Batch 192/1900 loss 20.177956 loss_att 8.950734 loss_ctc 46.374802 loss_ctc_origin 29.265350 loss_ctc0 86.296852 lr 0.00060467 rank 0
2022-08-26 06:01:40,820 DEBUG TRAIN Batch 192/2000 loss 46.962811 loss_att 30.797434 loss_ctc 84.682022 loss_ctc_origin 55.215378 loss_ctc0 153.437515 lr 0.00060465 rank 0
2022-08-26 06:02:08,817 DEBUG TRAIN Batch 192/2100 loss 57.793633 loss_att 32.825920 loss_ctc 116.051613 loss_ctc_origin 68.210983 loss_ctc0 227.679749 lr 0.00060462 rank 0
2022-08-26 06:02:36,324 DEBUG TRAIN Batch 192/2200 loss 13.484808 loss_att 6.338251 loss_ctc 30.160107 loss_ctc_origin 18.114729 loss_ctc0 58.265987 lr 0.00060459 rank 0
2022-08-26 06:03:03,381 DEBUG TRAIN Batch 192/2300 loss 20.824413 loss_att 9.162339 loss_ctc 48.035919 loss_ctc_origin 34.688526 loss_ctc0 79.179832 lr 0.00060456 rank 0
2022-08-26 06:03:31,600 DEBUG TRAIN Batch 192/2400 loss 25.536346 loss_att 10.625307 loss_ctc 60.328766 loss_ctc_origin 42.572174 loss_ctc0 101.760818 lr 0.00060454 rank 0
2022-08-26 06:03:59,743 DEBUG TRAIN Batch 192/2500 loss 54.412430 loss_att 36.984871 loss_ctc 95.076721 loss_ctc_origin 66.396629 loss_ctc0 161.996918 lr 0.00060451 rank 0
2022-08-26 06:04:25,780 DEBUG TRAIN Batch 192/2600 loss 57.589600 loss_att 32.072151 loss_ctc 117.130302 loss_ctc_origin 73.539398 loss_ctc0 218.842407 lr 0.00060448 rank 0
2022-08-26 06:04:53,682 DEBUG TRAIN Batch 192/2700 loss 20.434380 loss_att 11.566351 loss_ctc 41.126450 loss_ctc_origin 32.508690 loss_ctc0 61.234550 lr 0.00060445 rank 0
2022-08-26 06:05:20,183 DEBUG TRAIN Batch 192/2800 loss 21.190266 loss_att 8.913858 loss_ctc 49.835213 loss_ctc_origin 36.523636 loss_ctc0 80.895561 lr 0.00060443 rank 0
2022-08-26 06:05:30,858 WARNING NaN or Inf found in input tensor.
2022-08-26 06:05:48,532 DEBUG TRAIN Batch 192/2900 loss 21.855885 loss_att 9.289454 loss_ctc 51.177551 loss_ctc_origin 33.259556 loss_ctc0 92.986206 lr 0.00060440 rank 0
2022-08-26 06:06:20,983 DEBUG TRAIN Batch 192/3000 loss 34.529041 loss_att 19.977985 loss_ctc 68.481506 loss_ctc_origin 39.980621 loss_ctc0 134.983566 lr 0.00060437 rank 0
2022-08-26 06:06:47,467 DEBUG TRAIN Batch 192/3100 loss 57.751549 loss_att 35.963078 loss_ctc 108.591309 loss_ctc_origin 68.195251 loss_ctc0 202.848785 lr 0.00060434 rank 0
2022-08-26 06:07:14,203 DEBUG TRAIN Batch 192/3200 loss 18.806190 loss_att 9.070603 loss_ctc 41.522560 loss_ctc_origin 28.986588 loss_ctc0 70.773163 lr 0.00060432 rank 0
2022-08-26 06:07:41,664 DEBUG TRAIN Batch 192/3300 loss 15.728777 loss_att 6.690030 loss_ctc 36.819187 loss_ctc_origin 21.569160 loss_ctc0 72.402580 lr 0.00060429 rank 0
2022-08-26 06:08:09,325 DEBUG TRAIN Batch 192/3400 loss 23.416920 loss_att 9.853718 loss_ctc 55.064388 loss_ctc_origin 38.091862 loss_ctc0 94.666946 lr 0.00060426 rank 0
2022-08-26 06:08:36,682 DEBUG TRAIN Batch 192/3500 loss 45.274704 loss_att 29.913342 loss_ctc 81.117889 loss_ctc_origin 54.800468 loss_ctc0 142.525208 lr 0.00060423 rank 0
2022-08-26 06:09:03,982 DEBUG TRAIN Batch 192/3600 loss 64.349815 loss_att 43.373920 loss_ctc 113.293564 loss_ctc_origin 74.107941 loss_ctc0 204.726669 lr 0.00060420 rank 0
2022-08-26 06:09:29,535 WARNING NaN or Inf found in input tensor.
2022-08-26 06:09:31,106 DEBUG TRAIN Batch 192/3700 loss 16.366192 loss_att 7.763473 loss_ctc 36.439205 loss_ctc_origin 24.661531 loss_ctc0 63.920444 lr 0.00060418 rank 0
2022-08-26 06:09:59,291 DEBUG TRAIN Batch 192/3800 loss 19.056446 loss_att 7.027081 loss_ctc 47.124962 loss_ctc_origin 32.194721 loss_ctc0 81.962189 lr 0.00060415 rank 0
2022-08-26 06:10:26,981 DEBUG TRAIN Batch 192/3900 loss 24.769709 loss_att 9.908182 loss_ctc 59.446602 loss_ctc_origin 40.625130 loss_ctc0 103.363373 lr 0.00060412 rank 0
2022-08-26 06:10:55,249 DEBUG TRAIN Batch 192/4000 loss 50.129166 loss_att 29.880821 loss_ctc 97.375298 loss_ctc_origin 64.240662 loss_ctc0 174.689438 lr 0.00060409 rank 0
2022-08-26 06:11:22,512 DEBUG TRAIN Batch 192/4100 loss 56.929386 loss_att 33.253811 loss_ctc 112.172394 loss_ctc_origin 67.773407 loss_ctc0 215.770020 lr 0.00060407 rank 0
2022-08-26 06:11:49,336 DEBUG TRAIN Batch 192/4200 loss 19.534185 loss_att 9.033898 loss_ctc 44.034855 loss_ctc_origin 31.217985 loss_ctc0 73.940887 lr 0.00060404 rank 0
2022-08-26 06:12:16,961 DEBUG TRAIN Batch 192/4300 loss 20.583771 loss_att 8.585571 loss_ctc 48.579567 loss_ctc_origin 34.285522 loss_ctc0 81.932335 lr 0.00060401 rank 0
2022-08-26 06:12:33,355 WARNING NaN or Inf found in input tensor.
2022-08-26 06:12:44,582 DEBUG TRAIN Batch 192/4400 loss 22.861252 loss_att 9.157911 loss_ctc 54.835709 loss_ctc_origin 36.093010 loss_ctc0 98.568672 lr 0.00060398 rank 0
2022-08-26 06:13:17,758 DEBUG TRAIN Batch 192/4500 loss 52.332397 loss_att 35.929119 loss_ctc 90.606720 loss_ctc_origin 58.671360 loss_ctc0 165.122543 lr 0.00060396 rank 0
2022-08-26 06:13:32,714 WARNING NaN or Inf found in input tensor.
2022-08-26 06:13:45,536 DEBUG TRAIN Batch 192/4600 loss 52.502445 loss_att 30.628830 loss_ctc 103.540878 loss_ctc_origin 64.069847 loss_ctc0 195.639954 lr 0.00060393 rank 0
2022-08-26 06:14:12,948 DEBUG TRAIN Batch 192/4700 loss 20.177458 loss_att 10.110786 loss_ctc 43.666355 loss_ctc_origin 32.724640 loss_ctc0 69.197021 lr 0.00060390 rank 0
2022-08-26 06:14:18,118 WARNING NaN or Inf found in input tensor.
2022-08-26 06:14:41,377 DEBUG TRAIN Batch 192/4800 loss 20.404057 loss_att 8.494211 loss_ctc 48.193695 loss_ctc_origin 34.330917 loss_ctc0 80.540176 lr 0.00060387 rank 0
2022-08-26 06:15:10,099 DEBUG TRAIN Batch 192/4900 loss 20.376728 loss_att 8.102030 loss_ctc 49.017693 loss_ctc_origin 29.354948 loss_ctc0 94.897430 lr 0.00060385 rank 0
2022-08-26 06:15:38,652 DEBUG TRAIN Batch 192/5000 loss 46.080772 loss_att 28.732553 loss_ctc 86.559952 loss_ctc_origin 57.950413 loss_ctc0 153.315521 lr 0.00060382 rank 0
2022-08-26 06:16:05,411 DEBUG TRAIN Batch 192/5100 loss 58.933826 loss_att 33.729462 loss_ctc 117.744003 loss_ctc_origin 70.217346 loss_ctc0 228.639511 lr 0.00060379 rank 0
2022-08-26 06:16:32,024 WARNING NaN or Inf found in input tensor.
2022-08-26 06:16:33,594 DEBUG TRAIN Batch 192/5200 loss 20.385513 loss_att 11.112855 loss_ctc 42.021713 loss_ctc_origin 30.226337 loss_ctc0 69.544258 lr 0.00060376 rank 0
2022-08-26 06:17:01,300 DEBUG TRAIN Batch 192/5300 loss 16.998898 loss_att 7.025700 loss_ctc 40.269688 loss_ctc_origin 25.761297 loss_ctc0 74.122597 lr 0.00060374 rank 0
2022-08-26 06:17:28,798 DEBUG TRAIN Batch 192/5400 loss 24.148518 loss_att 11.545490 loss_ctc 53.555576 loss_ctc_origin 36.672623 loss_ctc0 92.949135 lr 0.00060371 rank 0
2022-08-26 06:17:55,486 DEBUG TRAIN Batch 192/5500 loss 54.091270 loss_att 35.850502 loss_ctc 96.653061 loss_ctc_origin 64.727341 loss_ctc0 171.146393 lr 0.00060368 rank 0
2022-08-26 06:18:23,987 DEBUG TRAIN Batch 192/5600 loss 66.220406 loss_att 37.544186 loss_ctc 133.131577 loss_ctc_origin 83.460167 loss_ctc0 249.031525 lr 0.00060365 rank 0
2022-08-26 06:18:47,162 DEBUG CV Batch 192/0 loss 11.861752 loss_att 8.813831 loss_ctc 18.973566 loss_ctc_origin 12.515829 loss_ctc0 34.041618 history loss 11.164001 rank 0
2022-08-26 06:18:57,337 DEBUG CV Batch 192/100 loss 20.406639 loss_att 16.806965 loss_ctc 28.805882 loss_ctc_origin 18.725420 loss_ctc0 52.326958 history loss 26.560634 rank 0
2022-08-26 06:19:06,719 DEBUG CV Batch 192/200 loss 27.504299 loss_att 22.188885 loss_ctc 39.906929 loss_ctc_origin 30.283548 loss_ctc0 62.361477 history loss 27.977705 rank 0
2022-08-26 06:19:16,350 DEBUG CV Batch 192/300 loss 21.750885 loss_att 16.063583 loss_ctc 35.021252 loss_ctc_origin 19.462881 loss_ctc0 71.324112 history loss 27.109969 rank 0
2022-08-26 06:19:26,557 DEBUG CV Batch 192/400 loss 36.980247 loss_att 29.627848 loss_ctc 54.135841 loss_ctc_origin 36.841415 loss_ctc0 94.489502 history loss 25.386150 rank 0
2022-08-26 06:19:37,117 DEBUG CV Batch 192/500 loss 16.563999 loss_att 12.200645 loss_ctc 26.745159 loss_ctc_origin 20.339602 loss_ctc0 41.691456 history loss 25.023444 rank 0
2022-08-26 06:19:47,299 DEBUG CV Batch 192/600 loss 17.527542 loss_att 12.290272 loss_ctc 29.747833 loss_ctc_origin 19.442293 loss_ctc0 53.794086 history loss 24.829664 rank 0
2022-08-26 06:19:57,063 DEBUG CV Batch 192/700 loss 18.659500 loss_att 12.986381 loss_ctc 31.896774 loss_ctc_origin 18.463852 loss_ctc0 63.240257 history loss 24.471187 rank 0
2022-08-26 06:20:07,205 DEBUG CV Batch 192/800 loss 21.715397 loss_att 16.949261 loss_ctc 32.836380 loss_ctc_origin 17.562527 loss_ctc0 68.475365 history loss 24.432929 rank 0
2022-08-26 06:20:17,187 INFO Epoch 192 CV info cv_loss 24.519812215886397
2022-08-26 06:20:17,187 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/192.pt
2022-08-26 06:20:17,666 INFO Epoch 193 TRAIN info lr 0.0006036310167463852
2022-08-26 06:20:17,670 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 06:20:44,142 DEBUG TRAIN Batch 193/0 loss 39.886742 loss_att 25.101032 loss_ctc 74.386734 loss_ctc_origin 46.914665 loss_ctc0 138.488220 lr 0.00060363 rank 0
2022-08-26 06:21:10,923 DEBUG TRAIN Batch 193/100 loss 63.466095 loss_att 37.632668 loss_ctc 123.744080 loss_ctc_origin 69.688454 loss_ctc0 249.873871 lr 0.00060360 rank 0
2022-08-26 06:21:37,939 DEBUG TRAIN Batch 193/200 loss 24.295853 loss_att 13.047888 loss_ctc 50.541100 loss_ctc_origin 39.845818 loss_ctc0 75.496758 lr 0.00060357 rank 0
2022-08-26 06:21:43,484 WARNING NaN or Inf found in input tensor.
2022-08-26 06:22:05,973 DEBUG TRAIN Batch 193/300 loss 19.646137 loss_att 7.559935 loss_ctc 47.847275 loss_ctc_origin 34.661957 loss_ctc0 78.613014 lr 0.00060355 rank 0
2022-08-26 06:22:33,868 DEBUG TRAIN Batch 193/400 loss 17.047499 loss_att 6.704445 loss_ctc 41.181290 loss_ctc_origin 25.453800 loss_ctc0 77.878769 lr 0.00060352 rank 0
2022-08-26 06:23:02,958 DEBUG TRAIN Batch 193/500 loss 47.775009 loss_att 31.733864 loss_ctc 85.204346 loss_ctc_origin 53.655502 loss_ctc0 158.818298 lr 0.00060349 rank 0
2022-08-26 06:23:10,724 WARNING NaN or Inf found in input tensor.
2022-08-26 06:23:29,925 DEBUG TRAIN Batch 193/600 loss 59.257271 loss_att 32.105984 loss_ctc 122.610260 loss_ctc_origin 72.906708 loss_ctc0 238.585205 lr 0.00060347 rank 0
2022-08-26 06:23:57,604 DEBUG TRAIN Batch 193/700 loss 19.169704 loss_att 9.980804 loss_ctc 40.610466 loss_ctc_origin 29.522762 loss_ctc0 66.481781 lr 0.00060344 rank 0
2022-08-26 06:24:26,761 DEBUG TRAIN Batch 193/800 loss 18.873932 loss_att 8.546481 loss_ctc 42.971313 loss_ctc_origin 28.326725 loss_ctc0 77.142021 lr 0.00060341 rank 0
2022-08-26 06:24:53,670 DEBUG TRAIN Batch 193/900 loss 23.113258 loss_att 9.546980 loss_ctc 54.767906 loss_ctc_origin 36.912304 loss_ctc0 96.430969 lr 0.00060338 rank 0
2022-08-26 06:25:22,798 DEBUG TRAIN Batch 193/1000 loss 41.675575 loss_att 23.757940 loss_ctc 83.483383 loss_ctc_origin 50.963676 loss_ctc0 159.362701 lr 0.00060336 rank 0
2022-08-26 06:25:49,100 DEBUG TRAIN Batch 193/1100 loss 63.313652 loss_att 37.258423 loss_ctc 124.109192 loss_ctc_origin 74.905457 loss_ctc0 238.917892 lr 0.00060333 rank 0
2022-08-26 06:26:16,338 DEBUG TRAIN Batch 193/1200 loss 18.715349 loss_att 7.937563 loss_ctc 43.863518 loss_ctc_origin 30.867622 loss_ctc0 74.187271 lr 0.00060330 rank 0
2022-08-26 06:26:44,987 DEBUG TRAIN Batch 193/1300 loss 17.874758 loss_att 6.197633 loss_ctc 45.121380 loss_ctc_origin 28.627632 loss_ctc0 83.606789 lr 0.00060327 rank 0
2022-08-26 06:27:13,404 DEBUG TRAIN Batch 193/1400 loss 23.758829 loss_att 10.338234 loss_ctc 55.073551 loss_ctc_origin 36.736801 loss_ctc0 97.859299 lr 0.00060325 rank 0
2022-08-26 06:27:45,021 DEBUG TRAIN Batch 193/1500 loss 52.689003 loss_att 35.293655 loss_ctc 93.278137 loss_ctc_origin 63.856941 loss_ctc0 161.927582 lr 0.00060322 rank 0
2022-08-26 06:28:12,061 DEBUG TRAIN Batch 193/1600 loss 55.377716 loss_att 30.016624 loss_ctc 114.553589 loss_ctc_origin 66.395210 loss_ctc0 226.923126 lr 0.00060319 rank 0
2022-08-26 06:28:39,816 DEBUG TRAIN Batch 193/1700 loss 18.312925 loss_att 9.947942 loss_ctc 37.831219 loss_ctc_origin 25.800819 loss_ctc0 65.902145 lr 0.00060316 rank 0
2022-08-26 06:29:07,951 DEBUG TRAIN Batch 193/1800 loss 22.043695 loss_att 8.849966 loss_ctc 52.829063 loss_ctc_origin 38.046810 loss_ctc0 87.320992 lr 0.00060314 rank 0
2022-08-26 06:29:36,276 DEBUG TRAIN Batch 193/1900 loss 22.990047 loss_att 9.206219 loss_ctc 55.152313 loss_ctc_origin 35.141109 loss_ctc0 101.845123 lr 0.00060311 rank 0
2022-08-26 06:30:04,787 DEBUG TRAIN Batch 193/2000 loss 41.482521 loss_att 23.650497 loss_ctc 83.090576 loss_ctc_origin 51.399109 loss_ctc0 157.037354 lr 0.00060308 rank 0
2022-08-26 06:30:31,974 DEBUG TRAIN Batch 193/2100 loss 56.615738 loss_att 32.493187 loss_ctc 112.901688 loss_ctc_origin 63.370010 loss_ctc0 228.475616 lr 0.00060305 rank 0
2022-08-26 06:30:58,686 WARNING NaN or Inf found in input tensor.
2022-08-26 06:31:00,260 DEBUG TRAIN Batch 193/2200 loss 18.726551 loss_att 8.826359 loss_ctc 41.827000 loss_ctc_origin 28.486347 loss_ctc0 72.955185 lr 0.00060303 rank 0
2022-08-26 06:31:05,639 WARNING NaN or Inf found in input tensor.
2022-08-26 06:31:27,977 DEBUG TRAIN Batch 193/2300 loss 17.041725 loss_att 7.148785 loss_ctc 40.125252 loss_ctc_origin 26.315907 loss_ctc0 72.347061 lr 0.00060300 rank 0
2022-08-26 06:31:55,716 DEBUG TRAIN Batch 193/2400 loss 18.966608 loss_att 8.186878 loss_ctc 44.119308 loss_ctc_origin 27.351284 loss_ctc0 83.244690 lr 0.00060297 rank 0
2022-08-26 06:31:58,328 WARNING NaN or Inf found in input tensor.
2022-08-26 06:32:24,285 DEBUG TRAIN Batch 193/2500 loss 46.295940 loss_att 30.167774 loss_ctc 83.928329 loss_ctc_origin 57.913788 loss_ctc0 144.628937 lr 0.00060294 rank 0
2022-08-26 06:32:51,260 DEBUG TRAIN Batch 193/2600 loss 48.951710 loss_att 27.352053 loss_ctc 99.350906 loss_ctc_origin 59.675922 loss_ctc0 191.925873 lr 0.00060292 rank 0
2022-08-26 06:33:18,213 DEBUG TRAIN Batch 193/2700 loss 16.878151 loss_att 7.433393 loss_ctc 38.915916 loss_ctc_origin 28.403427 loss_ctc0 63.445061 lr 0.00060289 rank 0
2022-08-26 06:33:45,817 DEBUG TRAIN Batch 193/2800 loss 18.002193 loss_att 7.686761 loss_ctc 42.071533 loss_ctc_origin 26.337746 loss_ctc0 78.783691 lr 0.00060286 rank 0
2022-08-26 06:34:14,401 DEBUG TRAIN Batch 193/2900 loss 20.170420 loss_att 8.316126 loss_ctc 47.830437 loss_ctc_origin 30.082100 loss_ctc0 89.243217 lr 0.00060283 rank 0
2022-08-26 06:34:47,018 DEBUG TRAIN Batch 193/3000 loss 44.171516 loss_att 30.075790 loss_ctc 77.061539 loss_ctc_origin 47.875984 loss_ctc0 145.161163 lr 0.00060281 rank 0
2022-08-26 06:35:15,222 DEBUG TRAIN Batch 193/3100 loss 46.775471 loss_att 24.966570 loss_ctc 97.662903 loss_ctc_origin 48.674858 loss_ctc0 211.968353 lr 0.00060278 rank 0
2022-08-26 06:35:46,272 DEBUG TRAIN Batch 193/3200 loss 20.353336 loss_att 10.299037 loss_ctc 43.813362 loss_ctc_origin 33.248341 loss_ctc0 68.465073 lr 0.00060275 rank 0
2022-08-26 06:36:15,410 DEBUG TRAIN Batch 193/3300 loss 18.512730 loss_att 7.599729 loss_ctc 43.976395 loss_ctc_origin 28.044004 loss_ctc0 81.151962 lr 0.00060272 rank 0
2022-08-26 06:36:40,088 WARNING NaN or Inf found in input tensor.
2022-08-26 06:36:44,724 DEBUG TRAIN Batch 193/3400 loss 25.219187 loss_att 10.283344 loss_ctc 60.069481 loss_ctc_origin 45.055813 loss_ctc0 95.101379 lr 0.00060270 rank 0
2022-08-26 06:37:14,004 DEBUG TRAIN Batch 193/3500 loss 48.493752 loss_att 32.352043 loss_ctc 86.157738 loss_ctc_origin 52.584583 loss_ctc0 164.495087 lr 0.00060267 rank 0
2022-08-26 06:37:42,037 DEBUG TRAIN Batch 193/3600 loss 61.421158 loss_att 35.699539 loss_ctc 121.438263 loss_ctc_origin 70.784180 loss_ctc0 239.631134 lr 0.00060264 rank 0
2022-08-26 06:38:08,853 DEBUG TRAIN Batch 193/3700 loss 20.210764 loss_att 11.016302 loss_ctc 41.664505 loss_ctc_origin 30.572826 loss_ctc0 67.545090 lr 0.00060262 rank 0
2022-08-26 06:38:36,146 DEBUG TRAIN Batch 193/3800 loss 17.092323 loss_att 7.244170 loss_ctc 40.071342 loss_ctc_origin 25.121517 loss_ctc0 74.954269 lr 0.00060259 rank 0
2022-08-26 06:39:03,130 DEBUG TRAIN Batch 193/3900 loss 18.638037 loss_att 6.262897 loss_ctc 47.513359 loss_ctc_origin 27.381432 loss_ctc0 94.487854 lr 0.00060256 rank 0
2022-08-26 06:39:30,498 DEBUG TRAIN Batch 193/4000 loss 43.305435 loss_att 28.374083 loss_ctc 78.145248 loss_ctc_origin 52.061066 loss_ctc0 139.008331 lr 0.00060253 rank 0
2022-08-26 06:39:57,684 DEBUG TRAIN Batch 193/4100 loss 53.921989 loss_att 29.466963 loss_ctc 110.983711 loss_ctc_origin 56.757236 loss_ctc0 237.512146 lr 0.00060251 rank 0
2022-08-26 06:40:25,036 DEBUG TRAIN Batch 193/4200 loss 19.774723 loss_att 11.018679 loss_ctc 40.205490 loss_ctc_origin 29.933216 loss_ctc0 64.174126 lr 0.00060248 rank 0
2022-08-26 06:40:52,826 DEBUG TRAIN Batch 193/4300 loss 20.070704 loss_att 8.432291 loss_ctc 47.226997 loss_ctc_origin 32.359734 loss_ctc0 81.917267 lr 0.00060245 rank 0
2022-08-26 06:41:20,440 DEBUG TRAIN Batch 193/4400 loss 23.155661 loss_att 9.731777 loss_ctc 54.478054 loss_ctc_origin 36.354973 loss_ctc0 96.765244 lr 0.00060242 rank 0
2022-08-26 06:41:54,005 DEBUG TRAIN Batch 193/4500 loss 45.634659 loss_att 29.864990 loss_ctc 82.430542 loss_ctc_origin 57.285896 loss_ctc0 141.101379 lr 0.00060240 rank 0
2022-08-26 06:42:22,080 DEBUG TRAIN Batch 193/4600 loss 59.911884 loss_att 31.856155 loss_ctc 125.375252 loss_ctc_origin 68.173492 loss_ctc0 258.846008 lr 0.00060237 rank 0
2022-08-26 06:42:48,533 DEBUG TRAIN Batch 193/4700 loss 23.086525 loss_att 13.371146 loss_ctc 45.755737 loss_ctc_origin 34.747787 loss_ctc0 71.440948 lr 0.00060234 rank 0
2022-08-26 06:43:16,128 DEBUG TRAIN Batch 193/4800 loss 20.567225 loss_att 9.206102 loss_ctc 47.076508 loss_ctc_origin 32.364601 loss_ctc0 81.404297 lr 0.00060231 rank 0
2022-08-26 06:43:44,088 DEBUG TRAIN Batch 193/4900 loss 22.511742 loss_att 9.670427 loss_ctc 52.474804 loss_ctc_origin 35.148361 loss_ctc0 92.903168 lr 0.00060229 rank 0
2022-08-26 06:44:11,803 DEBUG TRAIN Batch 193/5000 loss 52.722153 loss_att 36.271160 loss_ctc 91.107788 loss_ctc_origin 61.343739 loss_ctc0 160.557220 lr 0.00060226 rank 0
2022-08-26 06:44:38,798 DEBUG TRAIN Batch 193/5100 loss 59.882809 loss_att 33.098869 loss_ctc 122.378662 loss_ctc_origin 73.744431 loss_ctc0 235.858536 lr 0.00060223 rank 0
2022-08-26 06:45:05,869 DEBUG TRAIN Batch 193/5200 loss 19.843643 loss_att 9.618431 loss_ctc 43.702469 loss_ctc_origin 32.436268 loss_ctc0 69.990265 lr 0.00060221 rank 0
2022-08-26 06:45:33,296 DEBUG TRAIN Batch 193/5300 loss 21.657776 loss_att 9.383446 loss_ctc 50.297874 loss_ctc_origin 37.996780 loss_ctc0 79.000427 lr 0.00060218 rank 0
2022-08-26 06:46:00,648 DEBUG TRAIN Batch 193/5400 loss 20.922518 loss_att 9.042109 loss_ctc 48.643471 loss_ctc_origin 30.886801 loss_ctc0 90.075706 lr 0.00060215 rank 0
2022-08-26 06:46:29,102 DEBUG TRAIN Batch 193/5500 loss 48.608837 loss_att 31.122753 loss_ctc 89.409698 loss_ctc_origin 52.562958 loss_ctc0 175.385406 lr 0.00060212 rank 0
2022-08-26 06:46:56,449 DEBUG TRAIN Batch 193/5600 loss 60.807972 loss_att 34.863457 loss_ctc 121.345177 loss_ctc_origin 63.811787 loss_ctc0 255.589737 lr 0.00060210 rank 0
2022-08-26 06:47:19,008 DEBUG CV Batch 193/0 loss 11.489297 loss_att 8.371049 loss_ctc 18.765209 loss_ctc_origin 12.255939 loss_ctc0 33.953499 history loss 10.813456 rank 0
2022-08-26 06:47:29,437 DEBUG CV Batch 193/100 loss 20.884594 loss_att 16.844669 loss_ctc 30.311089 loss_ctc_origin 20.745232 loss_ctc0 52.631416 history loss 26.137278 rank 0
2022-08-26 06:47:38,719 DEBUG CV Batch 193/200 loss 24.769421 loss_att 19.150684 loss_ctc 37.879807 loss_ctc_origin 27.618420 loss_ctc0 61.823036 history loss 27.589327 rank 0
2022-08-26 06:47:48,396 DEBUG CV Batch 193/300 loss 22.087818 loss_att 16.449268 loss_ctc 35.244431 loss_ctc_origin 19.566250 loss_ctc0 71.826843 history loss 26.699958 rank 0
2022-08-26 06:47:58,606 DEBUG CV Batch 193/400 loss 37.451645 loss_att 29.985592 loss_ctc 54.872433 loss_ctc_origin 37.718803 loss_ctc0 94.897568 history loss 25.028473 rank 0
2022-08-26 06:48:09,534 DEBUG CV Batch 193/500 loss 16.331373 loss_att 11.837864 loss_ctc 26.816227 loss_ctc_origin 20.417534 loss_ctc0 41.746506 history loss 24.723218 rank 0
2022-08-26 06:48:19,115 DEBUG CV Batch 193/600 loss 17.027424 loss_att 11.862206 loss_ctc 29.079601 loss_ctc_origin 18.199131 loss_ctc0 54.467361 history loss 24.585370 rank 0
2022-08-26 06:48:28,827 DEBUG CV Batch 193/700 loss 17.971123 loss_att 12.410709 loss_ctc 30.945423 loss_ctc_origin 17.401806 loss_ctc0 62.547195 history loss 24.253906 rank 0
2022-08-26 06:48:38,979 DEBUG CV Batch 193/800 loss 21.970669 loss_att 17.288275 loss_ctc 32.896255 loss_ctc_origin 17.681864 loss_ctc0 68.396500 history loss 24.223216 rank 0
2022-08-26 06:48:48,917 INFO Epoch 193 CV info cv_loss 24.311615948235406
2022-08-26 06:48:48,917 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/193.pt
2022-08-26 06:48:49,339 INFO Epoch 194 TRAIN info lr 0.0006020732566868936
2022-08-26 06:48:49,342 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 06:49:14,454 DEBUG TRAIN Batch 194/0 loss 57.736897 loss_att 39.222824 loss_ctc 100.936394 loss_ctc_origin 67.919205 loss_ctc0 177.976501 lr 0.00060207 rank 0
2022-08-26 06:49:42,024 DEBUG TRAIN Batch 194/100 loss 59.551647 loss_att 30.209896 loss_ctc 128.015732 loss_ctc_origin 69.369232 loss_ctc0 264.857544 lr 0.00060204 rank 0
2022-08-26 06:50:09,325 DEBUG TRAIN Batch 194/200 loss 18.936565 loss_att 8.445342 loss_ctc 43.416084 loss_ctc_origin 29.915401 loss_ctc0 74.917671 lr 0.00060202 rank 0
2022-08-26 06:50:36,698 DEBUG TRAIN Batch 194/300 loss 16.758553 loss_att 6.619160 loss_ctc 40.417133 loss_ctc_origin 25.412596 loss_ctc0 75.427719 lr 0.00060199 rank 0
2022-08-26 06:51:04,926 DEBUG TRAIN Batch 194/400 loss 21.727207 loss_att 9.011292 loss_ctc 51.397678 loss_ctc_origin 34.661438 loss_ctc0 90.448906 lr 0.00060196 rank 0
2022-08-26 06:51:33,534 DEBUG TRAIN Batch 194/500 loss 53.365631 loss_att 35.984634 loss_ctc 93.921288 loss_ctc_origin 64.542847 loss_ctc0 162.470978 lr 0.00060194 rank 0
2022-08-26 06:52:01,946 DEBUG TRAIN Batch 194/600 loss 63.788483 loss_att 37.008224 loss_ctc 126.275742 loss_ctc_origin 74.859879 loss_ctc0 246.246094 lr 0.00060191 rank 0
2022-08-26 06:52:29,344 DEBUG TRAIN Batch 194/700 loss 17.568142 loss_att 8.496317 loss_ctc 38.735733 loss_ctc_origin 28.385439 loss_ctc0 62.886421 lr 0.00060188 rank 0
2022-08-26 06:52:57,490 DEBUG TRAIN Batch 194/800 loss 17.968229 loss_att 7.042010 loss_ctc 43.462738 loss_ctc_origin 28.173397 loss_ctc0 79.137871 lr 0.00060185 rank 0
2022-08-26 06:53:25,012 DEBUG TRAIN Batch 194/900 loss 19.995508 loss_att 8.451573 loss_ctc 46.931355 loss_ctc_origin 27.958008 loss_ctc0 91.202499 lr 0.00060183 rank 0
2022-08-26 06:53:27,693 WARNING NaN or Inf found in input tensor.
2022-08-26 06:53:53,687 DEBUG TRAIN Batch 194/1000 loss 50.591782 loss_att 33.547127 loss_ctc 90.362633 loss_ctc_origin 56.450298 loss_ctc0 169.491409 lr 0.00060180 rank 0
2022-08-26 06:54:22,048 DEBUG TRAIN Batch 194/1100 loss 62.211121 loss_att 34.046387 loss_ctc 127.928833 loss_ctc_origin 76.112610 loss_ctc0 248.833328 lr 0.00060177 rank 0
2022-08-26 06:54:46,552 WARNING NaN or Inf found in input tensor.
2022-08-26 06:54:48,089 DEBUG TRAIN Batch 194/1200 loss 14.847733 loss_att 6.967774 loss_ctc 33.234299 loss_ctc_origin 22.533735 loss_ctc0 58.202274 lr 0.00060175 rank 0
2022-08-26 06:54:58,860 WARNING NaN or Inf found in input tensor.
2022-08-26 06:55:15,318 DEBUG TRAIN Batch 194/1300 loss 16.940693 loss_att 6.418384 loss_ctc 41.492744 loss_ctc_origin 25.512852 loss_ctc0 78.779167 lr 0.00060172 rank 0
2022-08-26 06:55:39,232 WARNING NaN or Inf found in input tensor.
2022-08-26 06:55:43,809 DEBUG TRAIN Batch 194/1400 loss 22.748199 loss_att 9.356045 loss_ctc 53.996559 loss_ctc_origin 35.768093 loss_ctc0 96.529648 lr 0.00060169 rank 0
2022-08-26 06:56:17,025 DEBUG TRAIN Batch 194/1500 loss 52.002380 loss_att 34.207832 loss_ctc 93.522987 loss_ctc_origin 59.752090 loss_ctc0 172.321747 lr 0.00060166 rank 0
2022-08-26 06:56:17,840 WARNING NaN or Inf found in input tensor.
2022-08-26 06:56:24,953 WARNING NaN or Inf found in input tensor.
2022-08-26 06:56:44,524 DEBUG TRAIN Batch 194/1600 loss 67.318481 loss_att 42.015488 loss_ctc 126.358803 loss_ctc_origin 73.265709 loss_ctc0 250.242676 lr 0.00060164 rank 0
2022-08-26 06:57:12,740 DEBUG TRAIN Batch 194/1700 loss 22.933531 loss_att 12.674273 loss_ctc 46.871796 loss_ctc_origin 36.390106 loss_ctc0 71.329071 lr 0.00060161 rank 0
2022-08-26 06:57:40,746 DEBUG TRAIN Batch 194/1800 loss 16.887722 loss_att 6.612844 loss_ctc 40.862438 loss_ctc_origin 26.754831 loss_ctc0 73.780182 lr 0.00060158 rank 0
2022-08-26 06:58:04,626 WARNING NaN or Inf found in input tensor.
2022-08-26 06:58:08,956 DEBUG TRAIN Batch 194/1900 loss 20.313591 loss_att 8.924488 loss_ctc 46.888161 loss_ctc_origin 30.627617 loss_ctc0 84.829422 lr 0.00060155 rank 0
2022-08-26 06:58:37,421 DEBUG TRAIN Batch 194/2000 loss 59.762741 loss_att 41.948215 loss_ctc 101.329971 loss_ctc_origin 65.648384 loss_ctc0 184.586990 lr 0.00060153 rank 0
2022-08-26 06:59:04,474 DEBUG TRAIN Batch 194/2100 loss 68.876465 loss_att 40.940193 loss_ctc 134.061096 loss_ctc_origin 84.059036 loss_ctc0 250.732590 lr 0.00060150 rank 0
2022-08-26 06:59:31,198 DEBUG TRAIN Batch 194/2200 loss 20.778084 loss_att 12.461209 loss_ctc 40.184120 loss_ctc_origin 29.838501 loss_ctc0 64.323898 lr 0.00060147 rank 0
2022-08-26 06:59:59,398 DEBUG TRAIN Batch 194/2300 loss 18.780365 loss_att 8.259659 loss_ctc 43.328674 loss_ctc_origin 29.075087 loss_ctc0 76.587036 lr 0.00060145 rank 0
2022-08-26 07:00:26,831 DEBUG TRAIN Batch 194/2400 loss 20.296417 loss_att 8.070229 loss_ctc 48.824188 loss_ctc_origin 30.351606 loss_ctc0 91.926872 lr 0.00060142 rank 0
2022-08-26 07:00:54,085 DEBUG TRAIN Batch 194/2500 loss 43.301277 loss_att 26.912647 loss_ctc 81.541412 loss_ctc_origin 49.703243 loss_ctc0 155.830475 lr 0.00060139 rank 0
2022-08-26 07:01:21,522 DEBUG TRAIN Batch 194/2600 loss 67.049446 loss_att 37.859814 loss_ctc 135.158585 loss_ctc_origin 79.087265 loss_ctc0 265.991669 lr 0.00060136 rank 0
2022-08-26 07:01:48,533 DEBUG TRAIN Batch 194/2700 loss 20.794212 loss_att 11.075662 loss_ctc 43.470833 loss_ctc_origin 35.104233 loss_ctc0 62.992905 lr 0.00060134 rank 0
2022-08-26 07:01:59,087 WARNING NaN or Inf found in input tensor.
2022-08-26 07:02:15,284 DEBUG TRAIN Batch 194/2800 loss 18.185040 loss_att 7.352255 loss_ctc 43.461533 loss_ctc_origin 26.018406 loss_ctc0 84.162170 lr 0.00060131 rank 0
2022-08-26 07:02:43,398 DEBUG TRAIN Batch 194/2900 loss 21.977465 loss_att 8.620416 loss_ctc 53.143909 loss_ctc_origin 33.626816 loss_ctc0 98.683792 lr 0.00060128 rank 0
2022-08-26 07:03:16,890 DEBUG TRAIN Batch 194/3000 loss 47.971283 loss_att 32.405472 loss_ctc 84.291504 loss_ctc_origin 52.942066 loss_ctc0 157.440201 lr 0.00060126 rank 0
2022-08-26 07:03:43,984 DEBUG TRAIN Batch 194/3100 loss 58.193489 loss_att 32.701035 loss_ctc 117.675880 loss_ctc_origin 64.812592 loss_ctc0 241.023544 lr 0.00060123 rank 0
2022-08-26 07:04:11,724 DEBUG TRAIN Batch 194/3200 loss 20.981449 loss_att 12.380772 loss_ctc 41.049698 loss_ctc_origin 30.084682 loss_ctc0 66.634735 lr 0.00060120 rank 0
2022-08-26 07:04:39,166 DEBUG TRAIN Batch 194/3300 loss 18.175400 loss_att 7.655214 loss_ctc 42.722500 loss_ctc_origin 29.566225 loss_ctc0 73.420471 lr 0.00060117 rank 0
2022-08-26 07:05:07,337 DEBUG TRAIN Batch 194/3400 loss 21.709133 loss_att 9.347561 loss_ctc 50.552803 loss_ctc_origin 31.201746 loss_ctc0 95.705261 lr 0.00060115 rank 0
2022-08-26 07:05:35,645 DEBUG TRAIN Batch 194/3500 loss 51.311470 loss_att 33.913315 loss_ctc 91.907166 loss_ctc_origin 57.770630 loss_ctc0 171.559082 lr 0.00060112 rank 0
2022-08-26 07:06:02,020 DEBUG TRAIN Batch 194/3600 loss 61.597351 loss_att 37.276016 loss_ctc 118.347122 loss_ctc_origin 72.458054 loss_ctc0 225.421600 lr 0.00060109 rank 0
2022-08-26 07:06:29,274 DEBUG TRAIN Batch 194/3700 loss 17.756510 loss_att 8.590617 loss_ctc 39.143593 loss_ctc_origin 28.927094 loss_ctc0 62.982101 lr 0.00060107 rank 0
2022-08-26 07:06:56,228 DEBUG TRAIN Batch 194/3800 loss 16.427732 loss_att 7.133574 loss_ctc 38.114105 loss_ctc_origin 23.028984 loss_ctc0 73.312721 lr 0.00060104 rank 0
2022-08-26 07:07:23,770 DEBUG TRAIN Batch 194/3900 loss 22.594540 loss_att 9.016131 loss_ctc 54.277489 loss_ctc_origin 35.785995 loss_ctc0 97.424309 lr 0.00060101 rank 0
2022-08-26 07:07:52,187 DEBUG TRAIN Batch 194/4000 loss 48.076149 loss_att 31.766743 loss_ctc 86.131432 loss_ctc_origin 52.201035 loss_ctc0 165.302353 lr 0.00060098 rank 0
2022-08-26 07:08:04,785 WARNING NaN or Inf found in input tensor.
2022-08-26 07:08:18,562 DEBUG TRAIN Batch 194/4100 loss 58.044060 loss_att 35.103355 loss_ctc 111.572372 loss_ctc_origin 66.487381 loss_ctc0 216.770660 lr 0.00060096 rank 0
2022-08-26 07:08:46,748 DEBUG TRAIN Batch 194/4200 loss 22.395054 loss_att 12.078133 loss_ctc 46.467865 loss_ctc_origin 35.206482 loss_ctc0 72.744415 lr 0.00060093 rank 0
2022-08-26 07:09:14,280 DEBUG TRAIN Batch 194/4300 loss 19.567581 loss_att 6.936175 loss_ctc 49.040855 loss_ctc_origin 33.100601 loss_ctc0 86.234787 lr 0.00060090 rank 0
2022-08-26 07:09:42,086 DEBUG TRAIN Batch 194/4400 loss 20.869232 loss_att 7.560967 loss_ctc 51.921844 loss_ctc_origin 30.476601 loss_ctc0 101.960747 lr 0.00060088 rank 0
2022-08-26 07:10:15,777 DEBUG TRAIN Batch 194/4500 loss 43.192417 loss_att 30.245565 loss_ctc 73.401733 loss_ctc_origin 46.918976 loss_ctc0 135.194855 lr 0.00060085 rank 0
2022-08-26 07:10:43,279 DEBUG TRAIN Batch 194/4600 loss 53.436432 loss_att 31.798698 loss_ctc 103.924469 loss_ctc_origin 63.518562 loss_ctc0 198.204895 lr 0.00060082 rank 0
2022-08-26 07:11:09,902 DEBUG TRAIN Batch 194/4700 loss 20.731552 loss_att 12.509482 loss_ctc 39.916382 loss_ctc_origin 30.869907 loss_ctc0 61.024818 lr 0.00060079 rank 0
2022-08-26 07:11:22,225 WARNING NaN or Inf found in input tensor.
2022-08-26 07:11:38,161 DEBUG TRAIN Batch 194/4800 loss 19.668484 loss_att 8.223603 loss_ctc 46.373203 loss_ctc_origin 31.781105 loss_ctc0 80.421432 lr 0.00060077 rank 0
2022-08-26 07:12:06,330 DEBUG TRAIN Batch 194/4900 loss 19.487650 loss_att 7.975151 loss_ctc 46.350143 loss_ctc_origin 27.541470 loss_ctc0 90.237045 lr 0.00060074 rank 0
2022-08-26 07:12:34,814 DEBUG TRAIN Batch 194/5000 loss 47.564095 loss_att 31.549782 loss_ctc 84.930832 loss_ctc_origin 57.333031 loss_ctc0 149.325714 lr 0.00060071 rank 0
2022-08-26 07:13:02,920 DEBUG TRAIN Batch 194/5100 loss 48.741364 loss_att 24.422401 loss_ctc 105.485611 loss_ctc_origin 65.980576 loss_ctc0 197.664017 lr 0.00060069 rank 0
2022-08-26 07:13:30,393 DEBUG TRAIN Batch 194/5200 loss 16.048510 loss_att 6.898308 loss_ctc 37.398979 loss_ctc_origin 26.301626 loss_ctc0 63.292793 lr 0.00060066 rank 0
2022-08-26 07:13:58,630 DEBUG TRAIN Batch 194/5300 loss 19.710171 loss_att 7.714522 loss_ctc 47.700020 loss_ctc_origin 33.416439 loss_ctc0 81.028374 lr 0.00060063 rank 0
2022-08-26 07:14:22,166 WARNING NaN or Inf found in input tensor.
2022-08-26 07:14:26,540 DEBUG TRAIN Batch 194/5400 loss 22.063284 loss_att 9.359253 loss_ctc 51.706024 loss_ctc_origin 35.986683 loss_ctc0 88.384491 lr 0.00060060 rank 0
2022-08-26 07:14:54,564 DEBUG TRAIN Batch 194/5500 loss 48.547840 loss_att 33.815289 loss_ctc 82.923790 loss_ctc_origin 55.099182 loss_ctc0 147.847870 lr 0.00060058 rank 0
2022-08-26 07:15:22,057 DEBUG TRAIN Batch 194/5600 loss 60.303787 loss_att 33.678150 loss_ctc 122.430267 loss_ctc_origin 69.535721 loss_ctc0 245.850861 lr 0.00060055 rank 0
2022-08-26 07:15:44,582 DEBUG CV Batch 194/0 loss 11.501987 loss_att 8.532663 loss_ctc 18.430410 loss_ctc_origin 11.467934 loss_ctc0 34.676189 history loss 10.825400 rank 0
2022-08-26 07:15:55,141 DEBUG CV Batch 194/100 loss 19.601131 loss_att 15.707170 loss_ctc 28.687038 loss_ctc_origin 18.201441 loss_ctc0 53.153435 history loss 26.133233 rank 0
2022-08-26 07:16:05,391 DEBUG CV Batch 194/200 loss 25.446857 loss_att 19.959200 loss_ctc 38.251396 loss_ctc_origin 27.759489 loss_ctc0 62.732502 history loss 27.533102 rank 0
2022-08-26 07:16:15,770 DEBUG CV Batch 194/300 loss 22.421415 loss_att 16.974146 loss_ctc 35.131710 loss_ctc_origin 19.232941 loss_ctc0 72.228836 history loss 26.742833 rank 0
2022-08-26 07:16:26,249 DEBUG CV Batch 194/400 loss 38.126369 loss_att 30.562939 loss_ctc 55.774376 loss_ctc_origin 38.539246 loss_ctc0 95.989670 history loss 25.099136 rank 0
2022-08-26 07:16:35,423 DEBUG CV Batch 194/500 loss 16.523056 loss_att 12.027165 loss_ctc 27.013462 loss_ctc_origin 20.374592 loss_ctc0 42.504158 history loss 24.764722 rank 0
2022-08-26 07:16:45,260 DEBUG CV Batch 194/600 loss 17.234024 loss_att 12.234493 loss_ctc 28.899593 loss_ctc_origin 17.784964 loss_ctc0 54.833729 history loss 24.623116 rank 0
2022-08-26 07:16:55,009 DEBUG CV Batch 194/700 loss 18.729576 loss_att 12.903713 loss_ctc 32.323250 loss_ctc_origin 18.661848 loss_ctc0 64.199860 history loss 24.267712 rank 0
2022-08-26 07:17:05,534 DEBUG CV Batch 194/800 loss 22.116196 loss_att 17.258121 loss_ctc 33.451702 loss_ctc_origin 17.784962 loss_ctc0 70.007423 history loss 24.240692 rank 0
2022-08-26 07:17:15,949 INFO Epoch 194 CV info cv_loss 24.303996811610684
2022-08-26 07:17:15,949 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/194.pt
2022-08-26 07:17:16,448 INFO Epoch 195 TRAIN info lr 0.0006005274948124166
2022-08-26 07:17:16,452 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 07:17:42,666 DEBUG TRAIN Batch 195/0 loss 57.004349 loss_att 37.195763 loss_ctc 103.224380 loss_ctc_origin 75.014740 loss_ctc0 169.046875 lr 0.00060053 rank 0
2022-08-26 07:17:50,461 WARNING NaN or Inf found in input tensor.
2022-08-26 07:18:09,428 DEBUG TRAIN Batch 195/100 loss 62.445892 loss_att 35.934593 loss_ctc 124.305588 loss_ctc_origin 75.042831 loss_ctc0 239.252014 lr 0.00060050 rank 0
2022-08-26 07:18:35,326 WARNING NaN or Inf found in input tensor.
2022-08-26 07:18:36,956 DEBUG TRAIN Batch 195/200 loss 19.983505 loss_att 11.883490 loss_ctc 38.883545 loss_ctc_origin 28.103254 loss_ctc0 64.037552 lr 0.00060047 rank 0
2022-08-26 07:18:42,516 WARNING NaN or Inf found in input tensor.
2022-08-26 07:19:04,682 DEBUG TRAIN Batch 195/300 loss 19.268059 loss_att 7.287742 loss_ctc 47.222130 loss_ctc_origin 30.654968 loss_ctc0 85.878838 lr 0.00060045 rank 0
2022-08-26 07:19:33,548 DEBUG TRAIN Batch 195/400 loss 19.183182 loss_att 7.917475 loss_ctc 45.469830 loss_ctc_origin 27.164413 loss_ctc0 88.182465 lr 0.00060042 rank 0
2022-08-26 07:20:01,786 DEBUG TRAIN Batch 195/500 loss 49.398849 loss_att 33.202923 loss_ctc 87.189331 loss_ctc_origin 55.910831 loss_ctc0 160.172485 lr 0.00060039 rank 0
2022-08-26 07:20:28,664 DEBUG TRAIN Batch 195/600 loss 65.325974 loss_att 44.417805 loss_ctc 114.111687 loss_ctc_origin 78.345535 loss_ctc0 197.566040 lr 0.00060036 rank 0
2022-08-26 07:20:55,636 DEBUG TRAIN Batch 195/700 loss 17.899841 loss_att 8.801079 loss_ctc 39.130287 loss_ctc_origin 27.106783 loss_ctc0 67.185127 lr 0.00060034 rank 0
2022-08-26 07:21:23,790 DEBUG TRAIN Batch 195/800 loss 20.273285 loss_att 8.359781 loss_ctc 48.071461 loss_ctc_origin 33.304771 loss_ctc0 82.527069 lr 0.00060031 rank 0
2022-08-26 07:21:51,531 DEBUG TRAIN Batch 195/900 loss 21.228956 loss_att 7.292747 loss_ctc 53.746773 loss_ctc_origin 34.278526 loss_ctc0 99.172668 lr 0.00060028 rank 0
2022-08-26 07:22:18,931 WARNING NaN or Inf found in input tensor.
2022-08-26 07:22:18,972 DEBUG TRAIN Batch 195/1000 loss inf loss_att 41.006439 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00060026 rank 0
2022-08-26 07:22:46,481 DEBUG TRAIN Batch 195/1100 loss 64.581039 loss_att 40.308598 loss_ctc 121.216721 loss_ctc_origin 79.753860 loss_ctc0 217.963409 lr 0.00060023 rank 0
2022-08-26 07:23:12,378 WARNING NaN or Inf found in input tensor.
2022-08-26 07:23:13,892 DEBUG TRAIN Batch 195/1200 loss 18.279547 loss_att 9.535995 loss_ctc 38.681168 loss_ctc_origin 27.114691 loss_ctc0 65.669601 lr 0.00060020 rank 0
2022-08-26 07:23:42,245 DEBUG TRAIN Batch 195/1300 loss 21.107471 loss_att 8.467700 loss_ctc 50.600273 loss_ctc_origin 36.878460 loss_ctc0 82.617828 lr 0.00060017 rank 0
2022-08-26 07:24:08,893 DEBUG TRAIN Batch 195/1400 loss 20.409325 loss_att 8.744352 loss_ctc 47.627590 loss_ctc_origin 29.526241 loss_ctc0 89.864067 lr 0.00060015 rank 0
2022-08-26 07:24:44,284 DEBUG TRAIN Batch 195/1500 loss 48.072304 loss_att 32.621635 loss_ctc 84.123871 loss_ctc_origin 54.961639 loss_ctc0 152.169052 lr 0.00060012 rank 0
2022-08-26 07:25:11,138 DEBUG TRAIN Batch 195/1600 loss 68.145302 loss_att 42.014477 loss_ctc 129.117218 loss_ctc_origin 86.103935 loss_ctc0 229.481537 lr 0.00060009 rank 0
2022-08-26 07:25:37,312 DEBUG TRAIN Batch 195/1700 loss 16.903877 loss_att 8.258714 loss_ctc 37.075928 loss_ctc_origin 24.703684 loss_ctc0 65.944489 lr 0.00060007 rank 0
2022-08-26 07:26:04,516 DEBUG TRAIN Batch 195/1800 loss 19.616158 loss_att 7.890560 loss_ctc 46.975883 loss_ctc_origin 33.194515 loss_ctc0 79.132416 lr 0.00060004 rank 0
2022-08-26 07:26:32,492 DEBUG TRAIN Batch 195/1900 loss 20.073256 loss_att 7.660308 loss_ctc 49.036797 loss_ctc_origin 30.730839 loss_ctc0 91.750687 lr 0.00060001 rank 0
2022-08-26 07:27:01,440 DEBUG TRAIN Batch 195/2000 loss 50.326973 loss_att 34.184792 loss_ctc 87.992065 loss_ctc_origin 53.238136 loss_ctc0 169.084564 lr 0.00059999 rank 0
2022-08-26 07:27:27,863 DEBUG TRAIN Batch 195/2100 loss 61.703331 loss_att 35.020813 loss_ctc 123.962540 loss_ctc_origin 76.553101 loss_ctc0 234.584579 lr 0.00059996 rank 0
2022-08-26 07:27:55,732 DEBUG TRAIN Batch 195/2200 loss 19.100712 loss_att 9.832075 loss_ctc 40.727531 loss_ctc_origin 29.878147 loss_ctc0 66.042755 lr 0.00059993 rank 0
2022-08-26 07:28:24,154 DEBUG TRAIN Batch 195/2300 loss 18.227100 loss_att 7.795043 loss_ctc 42.568569 loss_ctc_origin 27.050936 loss_ctc0 78.776375 lr 0.00059990 rank 0
2022-08-26 07:28:52,960 DEBUG TRAIN Batch 195/2400 loss 18.707985 loss_att 7.724886 loss_ctc 44.335213 loss_ctc_origin 24.257652 loss_ctc0 91.182854 lr 0.00059988 rank 0
2022-08-26 07:29:21,283 DEBUG TRAIN Batch 195/2500 loss 45.812355 loss_att 28.267107 loss_ctc 86.751274 loss_ctc_origin 56.091763 loss_ctc0 158.290131 lr 0.00059985 rank 0
2022-08-26 07:29:49,735 DEBUG TRAIN Batch 195/2600 loss 67.420486 loss_att 45.334881 loss_ctc 118.953552 loss_ctc_origin 73.585304 loss_ctc0 224.812790 lr 0.00059982 rank 0
2022-08-26 07:30:16,371 DEBUG TRAIN Batch 195/2700 loss 20.770248 loss_att 11.592297 loss_ctc 42.185463 loss_ctc_origin 32.077950 loss_ctc0 65.769653 lr 0.00059980 rank 0
2022-08-26 07:30:45,506 DEBUG TRAIN Batch 195/2800 loss 19.921791 loss_att 9.086379 loss_ctc 45.204414 loss_ctc_origin 30.315296 loss_ctc0 79.945694 lr 0.00059977 rank 0
2022-08-26 07:31:12,375 DEBUG TRAIN Batch 195/2900 loss 22.763811 loss_att 9.962998 loss_ctc 52.632370 loss_ctc_origin 32.749573 loss_ctc0 99.025566 lr 0.00059974 rank 0
2022-08-26 07:31:45,423 DEBUG TRAIN Batch 195/3000 loss 50.177692 loss_att 34.943947 loss_ctc 85.723099 loss_ctc_origin 60.156422 loss_ctc0 145.378693 lr 0.00059972 rank 0
2022-08-26 07:32:12,816 DEBUG TRAIN Batch 195/3100 loss 59.373711 loss_att 34.017723 loss_ctc 118.537674 loss_ctc_origin 69.352760 loss_ctc0 233.302444 lr 0.00059969 rank 0
2022-08-26 07:32:38,622 WARNING NaN or Inf found in input tensor.
2022-08-26 07:32:40,319 DEBUG TRAIN Batch 195/3200 loss 17.959982 loss_att 8.248576 loss_ctc 40.619926 loss_ctc_origin 28.892315 loss_ctc0 67.984344 lr 0.00059966 rank 0
2022-08-26 07:33:08,112 DEBUG TRAIN Batch 195/3300 loss 18.604988 loss_att 6.663921 loss_ctc 46.467476 loss_ctc_origin 31.548512 loss_ctc0 81.278397 lr 0.00059964 rank 0
2022-08-26 07:33:36,155 DEBUG TRAIN Batch 195/3400 loss 24.830627 loss_att 10.463695 loss_ctc 58.353474 loss_ctc_origin 39.102581 loss_ctc0 103.272217 lr 0.00059961 rank 0
2022-08-26 07:34:04,272 DEBUG TRAIN Batch 195/3500 loss 49.856819 loss_att 33.236908 loss_ctc 88.636612 loss_ctc_origin 55.308640 loss_ctc0 166.401886 lr 0.00059958 rank 0
2022-08-26 07:34:32,057 DEBUG TRAIN Batch 195/3600 loss 58.297043 loss_att 29.498775 loss_ctc 125.492989 loss_ctc_origin 72.341995 loss_ctc0 249.511963 lr 0.00059955 rank 0
2022-08-26 07:35:01,459 DEBUG TRAIN Batch 195/3700 loss 17.678135 loss_att 8.217676 loss_ctc 39.752541 loss_ctc_origin 28.297749 loss_ctc0 66.480392 lr 0.00059953 rank 0
2022-08-26 07:35:17,914 WARNING NaN or Inf found in input tensor.
2022-08-26 07:35:27,549 DEBUG TRAIN Batch 195/3800 loss 19.751722 loss_att 8.106228 loss_ctc 46.924541 loss_ctc_origin 31.812750 loss_ctc0 82.185387 lr 0.00059950 rank 0
2022-08-26 07:35:55,241 DEBUG TRAIN Batch 195/3900 loss 24.342030 loss_att 12.020696 loss_ctc 53.091805 loss_ctc_origin 36.550026 loss_ctc0 91.689285 lr 0.00059947 rank 0
2022-08-26 07:36:23,620 DEBUG TRAIN Batch 195/4000 loss 48.376091 loss_att 33.978207 loss_ctc 81.971161 loss_ctc_origin 53.228661 loss_ctc0 149.036987 lr 0.00059945 rank 0
2022-08-26 07:36:50,938 DEBUG TRAIN Batch 195/4100 loss 62.125832 loss_att 36.741669 loss_ctc 121.355530 loss_ctc_origin 73.818367 loss_ctc0 232.275574 lr 0.00059942 rank 0
2022-08-26 07:37:18,837 DEBUG TRAIN Batch 195/4200 loss 21.825043 loss_att 12.719709 loss_ctc 43.070824 loss_ctc_origin 34.594807 loss_ctc0 62.848190 lr 0.00059939 rank 0
2022-08-26 07:37:46,936 DEBUG TRAIN Batch 195/4300 loss 20.644747 loss_att 8.339340 loss_ctc 49.357357 loss_ctc_origin 35.718029 loss_ctc0 81.182449 lr 0.00059937 rank 0
2022-08-26 07:38:15,007 DEBUG TRAIN Batch 195/4400 loss 23.793886 loss_att 9.403706 loss_ctc 57.370972 loss_ctc_origin 39.970852 loss_ctc0 97.971260 lr 0.00059934 rank 0
2022-08-26 07:38:47,916 DEBUG TRAIN Batch 195/4500 loss 45.193680 loss_att 30.490099 loss_ctc 79.502029 loss_ctc_origin 50.699524 loss_ctc0 146.707870 lr 0.00059931 rank 0
2022-08-26 07:39:15,458 DEBUG TRAIN Batch 195/4600 loss 46.923668 loss_att 27.680723 loss_ctc 91.823868 loss_ctc_origin 54.725601 loss_ctc0 178.386475 lr 0.00059929 rank 0
2022-08-26 07:39:43,095 DEBUG TRAIN Batch 195/4700 loss 21.043657 loss_att 11.002665 loss_ctc 44.472637 loss_ctc_origin 36.105145 loss_ctc0 63.996780 lr 0.00059926 rank 0
2022-08-26 07:40:11,250 DEBUG TRAIN Batch 195/4800 loss 17.314222 loss_att 7.529072 loss_ctc 40.146240 loss_ctc_origin 26.237782 loss_ctc0 72.599312 lr 0.00059923 rank 0
2022-08-26 07:40:38,915 DEBUG TRAIN Batch 195/4900 loss 21.584080 loss_att 8.464478 loss_ctc 52.196480 loss_ctc_origin 35.233582 loss_ctc0 91.776566 lr 0.00059920 rank 0
2022-08-26 07:41:07,456 DEBUG TRAIN Batch 195/5000 loss 39.900536 loss_att 22.963562 loss_ctc 79.420135 loss_ctc_origin 52.307400 loss_ctc0 142.683182 lr 0.00059918 rank 0
2022-08-26 07:41:34,922 DEBUG TRAIN Batch 195/5100 loss 59.694664 loss_att 35.297394 loss_ctc 116.621628 loss_ctc_origin 68.341812 loss_ctc0 229.274536 lr 0.00059915 rank 0
2022-08-26 07:42:02,245 DEBUG TRAIN Batch 195/5200 loss 21.441994 loss_att 11.624393 loss_ctc 44.349724 loss_ctc_origin 34.749306 loss_ctc0 66.750687 lr 0.00059912 rank 0
2022-08-26 07:42:29,593 DEBUG TRAIN Batch 195/5300 loss 18.312063 loss_att 7.223341 loss_ctc 44.185745 loss_ctc_origin 31.790588 loss_ctc0 73.107773 lr 0.00059910 rank 0
2022-08-26 07:42:46,142 WARNING NaN or Inf found in input tensor.
2022-08-26 07:42:53,316 WARNING NaN or Inf found in input tensor.
2022-08-26 07:42:57,966 DEBUG TRAIN Batch 195/5400 loss 21.587616 loss_att 9.432007 loss_ctc 49.950699 loss_ctc_origin 30.091549 loss_ctc0 96.288719 lr 0.00059907 rank 0
2022-08-26 07:43:25,127 DEBUG TRAIN Batch 195/5500 loss 51.009384 loss_att 34.989193 loss_ctc 88.389816 loss_ctc_origin 55.089333 loss_ctc0 166.090942 lr 0.00059904 rank 0
2022-08-26 07:43:52,651 DEBUG TRAIN Batch 195/5600 loss 59.319695 loss_att 36.084229 loss_ctc 113.535774 loss_ctc_origin 68.570709 loss_ctc0 218.454254 lr 0.00059902 rank 0
2022-08-26 07:44:15,761 DEBUG CV Batch 195/0 loss 12.038925 loss_att 8.852066 loss_ctc 19.474928 loss_ctc_origin 13.020420 loss_ctc0 34.535446 history loss 11.330753 rank 0
2022-08-26 07:44:26,115 DEBUG CV Batch 195/100 loss 19.519707 loss_att 15.170322 loss_ctc 29.668272 loss_ctc_origin 19.209879 loss_ctc0 54.071190 history loss 26.702351 rank 0
2022-08-26 07:44:35,468 DEBUG CV Batch 195/200 loss 25.535635 loss_att 19.667307 loss_ctc 39.228401 loss_ctc_origin 28.919415 loss_ctc0 63.282707 history loss 28.028645 rank 0
2022-08-26 07:44:45,257 DEBUG CV Batch 195/300 loss 22.372684 loss_att 16.812119 loss_ctc 35.347336 loss_ctc_origin 19.367718 loss_ctc0 72.633110 history loss 27.149949 rank 0
2022-08-26 07:44:55,311 DEBUG CV Batch 195/400 loss 38.402470 loss_att 30.864288 loss_ctc 55.991558 loss_ctc_origin 39.189735 loss_ctc0 95.195808 history loss 25.418939 rank 0
2022-08-26 07:45:05,690 DEBUG CV Batch 195/500 loss 16.892086 loss_att 12.761574 loss_ctc 26.529945 loss_ctc_origin 20.006968 loss_ctc0 41.750229 history loss 25.069505 rank 0
2022-08-26 07:45:15,991 DEBUG CV Batch 195/600 loss 17.864202 loss_att 12.755583 loss_ctc 29.784317 loss_ctc_origin 19.291311 loss_ctc0 54.267998 history loss 24.902968 rank 0
2022-08-26 07:45:25,992 DEBUG CV Batch 195/700 loss 19.046516 loss_att 13.343815 loss_ctc 32.352821 loss_ctc_origin 18.600971 loss_ctc0 64.440468 history loss 24.549425 rank 0
2022-08-26 07:45:36,257 DEBUG CV Batch 195/800 loss 22.894333 loss_att 18.034086 loss_ctc 34.234909 loss_ctc_origin 19.278915 loss_ctc0 69.132233 history loss 24.507833 rank 0
2022-08-26 07:45:46,346 INFO Epoch 195 CV info cv_loss 24.566618802684413
2022-08-26 07:45:46,346 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/195.pt
2022-08-26 07:45:46,825 INFO Epoch 196 TRAIN info lr 0.0005989935778888424
2022-08-26 07:45:46,829 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 07:46:12,903 DEBUG TRAIN Batch 196/0 loss 59.907654 loss_att 39.694908 loss_ctc 107.070732 loss_ctc_origin 74.165085 loss_ctc0 183.850571 lr 0.00059899 rank 0
2022-08-26 07:46:40,683 DEBUG TRAIN Batch 196/100 loss 57.474800 loss_att 32.074646 loss_ctc 116.741821 loss_ctc_origin 59.577423 loss_ctc0 250.125427 lr 0.00059897 rank 0
2022-08-26 07:47:08,407 DEBUG TRAIN Batch 196/200 loss 21.805511 loss_att 10.880722 loss_ctc 47.296684 loss_ctc_origin 37.273125 loss_ctc0 70.684998 lr 0.00059894 rank 0
2022-08-26 07:47:14,061 WARNING NaN or Inf found in input tensor.
2022-08-26 07:47:36,379 DEBUG TRAIN Batch 196/300 loss 19.255726 loss_att 8.354563 loss_ctc 44.691772 loss_ctc_origin 29.775087 loss_ctc0 79.497375 lr 0.00059891 rank 0
2022-08-26 07:48:04,368 DEBUG TRAIN Batch 196/400 loss 24.085867 loss_att 10.453669 loss_ctc 55.894325 loss_ctc_origin 38.036602 loss_ctc0 97.562347 lr 0.00059889 rank 0
2022-08-26 07:48:12,936 WARNING NaN or Inf found in input tensor.
2022-08-26 07:48:33,094 DEBUG TRAIN Batch 196/500 loss 53.185719 loss_att 35.855591 loss_ctc 93.622681 loss_ctc_origin 66.822083 loss_ctc0 156.157394 lr 0.00059886 rank 0
2022-08-26 07:48:40,949 WARNING NaN or Inf found in input tensor.
2022-08-26 07:48:53,047 WARNING NaN or Inf found in input tensor.
2022-08-26 07:49:00,212 DEBUG TRAIN Batch 196/600 loss 62.215500 loss_att 36.251602 loss_ctc 122.797920 loss_ctc_origin 78.842262 loss_ctc0 225.361115 lr 0.00059883 rank 0
2022-08-26 07:49:25,664 WARNING NaN or Inf found in input tensor.
2022-08-26 07:49:27,184 DEBUG TRAIN Batch 196/700 loss 22.354940 loss_att 11.928144 loss_ctc 46.684132 loss_ctc_origin 36.504417 loss_ctc0 70.436798 lr 0.00059880 rank 0
2022-08-26 07:49:55,249 DEBUG TRAIN Batch 196/800 loss 18.762194 loss_att 7.357183 loss_ctc 45.373882 loss_ctc_origin 28.621349 loss_ctc0 84.463120 lr 0.00059878 rank 0
2022-08-26 07:50:22,888 DEBUG TRAIN Batch 196/900 loss 20.101992 loss_att 7.723399 loss_ctc 48.985374 loss_ctc_origin 32.072685 loss_ctc0 88.448318 lr 0.00059875 rank 0
2022-08-26 07:50:49,774 DEBUG TRAIN Batch 196/1000 loss 49.199333 loss_att 31.407505 loss_ctc 90.713600 loss_ctc_origin 61.712715 loss_ctc0 158.382339 lr 0.00059872 rank 0
2022-08-26 07:51:17,056 DEBUG TRAIN Batch 196/1100 loss 65.153648 loss_att 40.844616 loss_ctc 121.874710 loss_ctc_origin 77.485123 loss_ctc0 225.450409 lr 0.00059870 rank 0
2022-08-26 07:51:44,903 DEBUG TRAIN Batch 196/1200 loss 16.244473 loss_att 9.039567 loss_ctc 33.055916 loss_ctc_origin 21.938118 loss_ctc0 58.997444 lr 0.00059867 rank 0
2022-08-26 07:52:13,367 DEBUG TRAIN Batch 196/1300 loss 19.289635 loss_att 8.953233 loss_ctc 43.407906 loss_ctc_origin 29.411589 loss_ctc0 76.065971 lr 0.00059864 rank 0
2022-08-26 07:52:41,098 DEBUG TRAIN Batch 196/1400 loss 22.661129 loss_att 8.684830 loss_ctc 55.272491 loss_ctc_origin 38.680748 loss_ctc0 93.986557 lr 0.00059862 rank 0
2022-08-26 07:52:50,104 WARNING NaN or Inf found in input tensor.
2022-08-26 07:53:14,845 DEBUG TRAIN Batch 196/1500 loss 44.084251 loss_att 26.956648 loss_ctc 84.048653 loss_ctc_origin 57.239323 loss_ctc0 146.603760 lr 0.00059859 rank 0
2022-08-26 07:53:42,315 DEBUG TRAIN Batch 196/1600 loss 60.634769 loss_att 34.473305 loss_ctc 121.678177 loss_ctc_origin 74.060577 loss_ctc0 232.785919 lr 0.00059856 rank 0
2022-08-26 07:54:08,800 DEBUG TRAIN Batch 196/1700 loss 20.825584 loss_att 12.012022 loss_ctc 41.390564 loss_ctc_origin 31.608599 loss_ctc0 64.215149 lr 0.00059854 rank 0
2022-08-26 07:54:37,203 DEBUG TRAIN Batch 196/1800 loss 17.242620 loss_att 6.847874 loss_ctc 41.497028 loss_ctc_origin 26.109493 loss_ctc0 77.401276 lr 0.00059851 rank 0
2022-08-26 07:55:04,860 DEBUG TRAIN Batch 196/1900 loss 21.059549 loss_att 8.231619 loss_ctc 50.991383 loss_ctc_origin 32.515484 loss_ctc0 94.101814 lr 0.00059848 rank 0
2022-08-26 07:55:33,811 DEBUG TRAIN Batch 196/2000 loss 48.572647 loss_att 32.219349 loss_ctc 86.730347 loss_ctc_origin 57.709770 loss_ctc0 154.445007 lr 0.00059846 rank 0
2022-08-26 07:56:00,372 DEBUG TRAIN Batch 196/2100 loss 60.721245 loss_att 36.408607 loss_ctc 117.450729 loss_ctc_origin 72.435699 loss_ctc0 222.485809 lr 0.00059843 rank 0
2022-08-26 07:56:27,950 DEBUG TRAIN Batch 196/2200 loss 17.326609 loss_att 8.067178 loss_ctc 38.931946 loss_ctc_origin 25.797316 loss_ctc0 69.579422 lr 0.00059840 rank 0
2022-08-26 07:56:56,329 DEBUG TRAIN Batch 196/2300 loss 20.000156 loss_att 9.203170 loss_ctc 45.193119 loss_ctc_origin 32.199760 loss_ctc0 75.510956 lr 0.00059838 rank 0
2022-08-26 07:57:23,488 DEBUG TRAIN Batch 196/2400 loss 19.788172 loss_att 7.087280 loss_ctc 49.423584 loss_ctc_origin 30.641703 loss_ctc0 93.247971 lr 0.00059835 rank 0
2022-08-26 07:57:52,210 DEBUG TRAIN Batch 196/2500 loss 44.409348 loss_att 26.909279 loss_ctc 85.242844 loss_ctc_origin 52.114540 loss_ctc0 162.542206 lr 0.00059832 rank 0
2022-08-26 07:58:20,680 DEBUG TRAIN Batch 196/2600 loss 55.373459 loss_att 30.664230 loss_ctc 113.028320 loss_ctc_origin 64.655899 loss_ctc0 225.897308 lr 0.00059830 rank 0
2022-08-26 07:58:47,832 DEBUG TRAIN Batch 196/2700 loss 17.698086 loss_att 9.233616 loss_ctc 37.448517 loss_ctc_origin 26.596943 loss_ctc0 62.768860 lr 0.00059827 rank 0
2022-08-26 07:59:15,370 DEBUG TRAIN Batch 196/2800 loss 19.515942 loss_att 8.441515 loss_ctc 45.356270 loss_ctc_origin 31.060656 loss_ctc0 78.712700 lr 0.00059824 rank 0
2022-08-26 07:59:42,760 DEBUG TRAIN Batch 196/2900 loss 22.445774 loss_att 9.718462 loss_ctc 52.142838 loss_ctc_origin 34.500786 loss_ctc0 93.307632 lr 0.00059821 rank 0
2022-08-26 08:00:15,815 DEBUG TRAIN Batch 196/3000 loss 39.739494 loss_att 25.282257 loss_ctc 73.473038 loss_ctc_origin 49.557945 loss_ctc0 129.274933 lr 0.00059819 rank 0
2022-08-26 08:00:43,048 DEBUG TRAIN Batch 196/3100 loss 58.230087 loss_att 36.270878 loss_ctc 109.468239 loss_ctc_origin 69.991379 loss_ctc0 201.580902 lr 0.00059816 rank 0
2022-08-26 08:01:09,780 DEBUG TRAIN Batch 196/3200 loss 23.602753 loss_att 13.045349 loss_ctc 48.236694 loss_ctc_origin 36.585289 loss_ctc0 75.423309 lr 0.00059813 rank 0
2022-08-26 08:01:15,098 WARNING NaN or Inf found in input tensor.
2022-08-26 08:01:22,076 WARNING NaN or Inf found in input tensor.
2022-08-26 08:01:37,299 DEBUG TRAIN Batch 196/3300 loss 17.393967 loss_att 7.057781 loss_ctc 41.511730 loss_ctc_origin 26.419323 loss_ctc0 76.727341 lr 0.00059811 rank 0
2022-08-26 08:02:05,125 DEBUG TRAIN Batch 196/3400 loss 23.347033 loss_att 9.407978 loss_ctc 55.871490 loss_ctc_origin 38.261356 loss_ctc0 96.961807 lr 0.00059808 rank 0
2022-08-26 08:02:33,247 DEBUG TRAIN Batch 196/3500 loss 44.847839 loss_att 31.228161 loss_ctc 76.627090 loss_ctc_origin 49.467213 loss_ctc0 140.000153 lr 0.00059805 rank 0
2022-08-26 08:02:59,967 WARNING NaN or Inf found in input tensor.
2022-08-26 08:03:00,010 DEBUG TRAIN Batch 196/3600 loss nan loss_att 31.335526 loss_ctc nan loss_ctc_origin 58.909927 loss_ctc0 nan lr 0.00059803 rank 0
2022-08-26 08:03:27,321 DEBUG TRAIN Batch 196/3700 loss 18.977442 loss_att 10.116394 loss_ctc 39.653221 loss_ctc_origin 27.942999 loss_ctc0 66.977066 lr 0.00059800 rank 0
2022-08-26 08:03:55,132 DEBUG TRAIN Batch 196/3800 loss 18.563478 loss_att 7.543692 loss_ctc 44.276314 loss_ctc_origin 29.406956 loss_ctc0 78.971481 lr 0.00059797 rank 0
2022-08-26 08:04:23,458 DEBUG TRAIN Batch 196/3900 loss 19.890600 loss_att 7.969599 loss_ctc 47.706268 loss_ctc_origin 29.172813 loss_ctc0 90.950996 lr 0.00059795 rank 0
2022-08-26 08:04:50,913 DEBUG TRAIN Batch 196/4000 loss 44.275337 loss_att 26.704872 loss_ctc 85.273087 loss_ctc_origin 57.476704 loss_ctc0 150.131317 lr 0.00059792 rank 0
2022-08-26 08:05:18,796 DEBUG TRAIN Batch 196/4100 loss 53.133728 loss_att 26.793072 loss_ctc 114.595261 loss_ctc_origin 61.068607 loss_ctc0 239.490784 lr 0.00059789 rank 0
2022-08-26 08:05:45,591 DEBUG TRAIN Batch 196/4200 loss 17.388760 loss_att 8.789084 loss_ctc 37.454670 loss_ctc_origin 25.500832 loss_ctc0 65.346954 lr 0.00059787 rank 0
2022-08-26 08:06:12,529 DEBUG TRAIN Batch 196/4300 loss 20.377293 loss_att 9.851658 loss_ctc 44.937107 loss_ctc_origin 30.509090 loss_ctc0 78.602478 lr 0.00059784 rank 0
2022-08-26 08:06:39,916 DEBUG TRAIN Batch 196/4400 loss 19.489254 loss_att 8.256664 loss_ctc 45.698627 loss_ctc_origin 25.410875 loss_ctc0 93.036713 lr 0.00059781 rank 0
2022-08-26 08:07:13,249 DEBUG TRAIN Batch 196/4500 loss 52.349609 loss_att 35.494362 loss_ctc 91.678528 loss_ctc_origin 63.511536 loss_ctc0 157.401505 lr 0.00059779 rank 0
2022-08-26 08:07:41,094 DEBUG TRAIN Batch 196/4600 loss 53.845463 loss_att 29.696613 loss_ctc 110.192780 loss_ctc_origin 63.415325 loss_ctc0 219.340179 lr 0.00059776 rank 0
2022-08-26 08:08:08,762 DEBUG TRAIN Batch 196/4700 loss 21.165041 loss_att 11.958950 loss_ctc 42.645920 loss_ctc_origin 31.331600 loss_ctc0 69.045998 lr 0.00059773 rank 0
2022-08-26 08:08:36,293 DEBUG TRAIN Batch 196/4800 loss 18.326389 loss_att 7.501094 loss_ctc 43.585411 loss_ctc_origin 30.817368 loss_ctc0 73.377502 lr 0.00059771 rank 0
2022-08-26 08:09:03,861 DEBUG TRAIN Batch 196/4900 loss 21.532417 loss_att 8.243091 loss_ctc 52.540844 loss_ctc_origin 34.558659 loss_ctc0 94.499275 lr 0.00059768 rank 0
2022-08-26 08:09:31,317 DEBUG TRAIN Batch 196/5000 loss 45.902428 loss_att 30.489088 loss_ctc 81.866890 loss_ctc_origin 52.169708 loss_ctc0 151.160309 lr 0.00059765 rank 0
2022-08-26 08:09:38,761 WARNING NaN or Inf found in input tensor.
2022-08-26 08:09:58,700 DEBUG TRAIN Batch 196/5100 loss 60.069733 loss_att 37.503334 loss_ctc 112.724670 loss_ctc_origin 72.698151 loss_ctc0 206.119858 lr 0.00059763 rank 0
2022-08-26 08:10:26,808 DEBUG TRAIN Batch 196/5200 loss 16.391129 loss_att 7.490953 loss_ctc 37.158203 loss_ctc_origin 24.474531 loss_ctc0 66.753433 lr 0.00059760 rank 0
2022-08-26 08:10:54,118 DEBUG TRAIN Batch 196/5300 loss 16.476524 loss_att 7.092215 loss_ctc 38.373245 loss_ctc_origin 23.972120 loss_ctc0 71.975868 lr 0.00059757 rank 0
2022-08-26 08:11:16,935 WARNING NaN or Inf found in input tensor.
2022-08-26 08:11:21,250 DEBUG TRAIN Batch 196/5400 loss 21.040545 loss_att 8.611156 loss_ctc 50.042446 loss_ctc_origin 32.602009 loss_ctc0 90.736801 lr 0.00059755 rank 0
2022-08-26 08:11:48,470 DEBUG TRAIN Batch 196/5500 loss 47.091484 loss_att 31.935429 loss_ctc 82.455620 loss_ctc_origin 51.513603 loss_ctc0 154.653656 lr 0.00059752 rank 0
2022-08-26 08:12:01,522 WARNING NaN or Inf found in input tensor.
2022-08-26 08:12:15,533 DEBUG TRAIN Batch 196/5600 loss 54.464268 loss_att 31.938221 loss_ctc 107.025040 loss_ctc_origin 60.946373 loss_ctc0 214.541931 lr 0.00059749 rank 0
2022-08-26 08:12:37,720 DEBUG CV Batch 196/0 loss 12.043127 loss_att 9.037123 loss_ctc 19.057135 loss_ctc_origin 12.648098 loss_ctc0 34.011555 history loss 11.334708 rank 0
2022-08-26 08:12:48,041 DEBUG CV Batch 196/100 loss 19.888992 loss_att 15.613171 loss_ctc 29.865908 loss_ctc_origin 19.825777 loss_ctc0 53.292877 history loss 26.552907 rank 0
2022-08-26 08:12:57,433 DEBUG CV Batch 196/200 loss 25.723057 loss_att 20.103464 loss_ctc 38.835442 loss_ctc_origin 28.381268 loss_ctc0 63.228519 history loss 28.049443 rank 0
2022-08-26 08:13:07,296 DEBUG CV Batch 196/300 loss 22.330341 loss_att 16.846050 loss_ctc 35.127022 loss_ctc_origin 18.982067 loss_ctc0 72.798584 history loss 27.125464 rank 0
2022-08-26 08:13:17,581 DEBUG CV Batch 196/400 loss 38.485462 loss_att 31.128424 loss_ctc 55.651886 loss_ctc_origin 38.694466 loss_ctc0 95.219200 history loss 25.419892 rank 0
2022-08-26 08:13:28,200 DEBUG CV Batch 196/500 loss 16.596268 loss_att 12.476648 loss_ctc 26.208714 loss_ctc_origin 19.258556 loss_ctc0 42.425743 history loss 25.086767 rank 0
2022-08-26 08:13:38,266 DEBUG CV Batch 196/600 loss 17.076700 loss_att 11.876889 loss_ctc 29.209591 loss_ctc_origin 18.696659 loss_ctc0 53.739761 history loss 24.949688 rank 0
2022-08-26 08:13:48,092 DEBUG CV Batch 196/700 loss 19.291840 loss_att 13.586178 loss_ctc 32.605053 loss_ctc_origin 18.982718 loss_ctc0 64.390495 history loss 24.592734 rank 0
2022-08-26 08:13:57,945 DEBUG CV Batch 196/800 loss 22.289623 loss_att 17.410767 loss_ctc 33.673622 loss_ctc_origin 18.307560 loss_ctc0 69.527771 history loss 24.551815 rank 0
2022-08-26 08:14:07,742 INFO Epoch 196 CV info cv_loss 24.630602382037665
2022-08-26 08:14:07,743 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/196.pt
2022-08-26 08:14:08,172 INFO Epoch 197 TRAIN info lr 0.0005974713554079648
2022-08-26 08:14:08,175 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 08:14:33,760 DEBUG TRAIN Batch 197/0 loss 40.843113 loss_att 27.239700 loss_ctc 72.584412 loss_ctc_origin 48.731285 loss_ctc0 128.241714 lr 0.00059747 rank 0
2022-08-26 08:15:01,348 DEBUG TRAIN Batch 197/100 loss 54.219589 loss_att 29.068048 loss_ctc 112.906509 loss_ctc_origin 68.362999 loss_ctc0 216.841339 lr 0.00059744 rank 0
2022-08-26 08:15:28,792 DEBUG TRAIN Batch 197/200 loss 21.247038 loss_att 10.912975 loss_ctc 45.359848 loss_ctc_origin 35.936268 loss_ctc0 67.348198 lr 0.00059742 rank 0
2022-08-26 08:15:56,179 DEBUG TRAIN Batch 197/300 loss 18.590368 loss_att 6.938761 loss_ctc 45.777451 loss_ctc_origin 29.797560 loss_ctc0 83.063858 lr 0.00059739 rank 0
2022-08-26 08:16:23,945 DEBUG TRAIN Batch 197/400 loss 22.309816 loss_att 9.465366 loss_ctc 52.280197 loss_ctc_origin 33.175701 loss_ctc0 96.857346 lr 0.00059736 rank 0
2022-08-26 08:16:51,904 DEBUG TRAIN Batch 197/500 loss 25.898174 loss_att 17.590475 loss_ctc 45.282803 loss_ctc_origin 32.453117 loss_ctc0 75.218735 lr 0.00059734 rank 0
2022-08-26 08:17:18,762 DEBUG TRAIN Batch 197/600 loss 45.613808 loss_att 27.088398 loss_ctc 88.839760 loss_ctc_origin 51.159508 loss_ctc0 176.760345 lr 0.00059731 rank 0
2022-08-26 08:17:46,778 DEBUG TRAIN Batch 197/700 loss 20.599934 loss_att 9.854237 loss_ctc 45.673225 loss_ctc_origin 33.109489 loss_ctc0 74.988609 lr 0.00059728 rank 0
2022-08-26 08:18:13,608 DEBUG TRAIN Batch 197/800 loss 19.905100 loss_att 8.780937 loss_ctc 45.861477 loss_ctc_origin 31.823627 loss_ctc0 78.616455 lr 0.00059726 rank 0
2022-08-26 08:18:41,507 DEBUG TRAIN Batch 197/900 loss 25.099636 loss_att 10.875282 loss_ctc 58.289795 loss_ctc_origin 38.244774 loss_ctc0 105.061516 lr 0.00059723 rank 0
2022-08-26 08:19:10,012 DEBUG TRAIN Batch 197/1000 loss 43.226421 loss_att 29.038998 loss_ctc 76.330414 loss_ctc_origin 52.617477 loss_ctc0 131.660583 lr 0.00059720 rank 0
2022-08-26 08:19:37,762 DEBUG TRAIN Batch 197/1100 loss 62.987453 loss_att 37.542915 loss_ctc 122.358032 loss_ctc_origin 71.609192 loss_ctc0 240.771973 lr 0.00059718 rank 0
2022-08-26 08:20:03,633 WARNING NaN or Inf found in input tensor.
2022-08-26 08:20:05,225 DEBUG TRAIN Batch 197/1200 loss 23.466913 loss_att 12.067452 loss_ctc 50.065651 loss_ctc_origin 38.604141 loss_ctc0 76.809174 lr 0.00059715 rank 0
2022-08-26 08:20:33,865 DEBUG TRAIN Batch 197/1300 loss 22.109966 loss_att 8.822820 loss_ctc 53.113308 loss_ctc_origin 36.651627 loss_ctc0 91.523895 lr 0.00059712 rank 0
2022-08-26 08:21:01,608 DEBUG TRAIN Batch 197/1400 loss 19.937260 loss_att 8.184744 loss_ctc 47.359795 loss_ctc_origin 28.128105 loss_ctc0 92.233734 lr 0.00059710 rank 0
2022-08-26 08:21:34,116 DEBUG TRAIN Batch 197/1500 loss 52.377823 loss_att 36.646339 loss_ctc 89.084610 loss_ctc_origin 57.859932 loss_ctc0 161.942169 lr 0.00059707 rank 0
2022-08-26 08:22:00,895 DEBUG TRAIN Batch 197/1600 loss 61.759460 loss_att 37.099144 loss_ctc 119.300201 loss_ctc_origin 74.154594 loss_ctc0 224.639969 lr 0.00059704 rank 0
2022-08-26 08:22:28,022 DEBUG TRAIN Batch 197/1700 loss 21.771900 loss_att 11.031489 loss_ctc 46.832855 loss_ctc_origin 35.849037 loss_ctc0 72.461769 lr 0.00059702 rank 0
2022-08-26 08:22:54,357 DEBUG TRAIN Batch 197/1800 loss 23.574701 loss_att 10.176773 loss_ctc 54.836529 loss_ctc_origin 40.223389 loss_ctc0 88.933853 lr 0.00059699 rank 0
2022-08-26 08:23:22,160 DEBUG TRAIN Batch 197/1900 loss 22.528582 loss_att 8.930977 loss_ctc 54.256325 loss_ctc_origin 37.155411 loss_ctc0 94.158463 lr 0.00059696 rank 0
2022-08-26 08:23:51,127 DEBUG TRAIN Batch 197/2000 loss 46.680725 loss_att 32.265713 loss_ctc 80.315742 loss_ctc_origin 60.585838 loss_ctc0 126.352180 lr 0.00059694 rank 0
2022-08-26 08:24:17,829 DEBUG TRAIN Batch 197/2100 loss 61.054810 loss_att 34.580242 loss_ctc 122.828796 loss_ctc_origin 82.073494 loss_ctc0 217.924500 lr 0.00059691 rank 0
2022-08-26 08:24:44,630 DEBUG TRAIN Batch 197/2200 loss 19.629890 loss_att 9.215137 loss_ctc 43.930981 loss_ctc_origin 32.149662 loss_ctc0 71.420723 lr 0.00059688 rank 0
2022-08-26 08:25:11,172 DEBUG TRAIN Batch 197/2300 loss 22.618761 loss_att 8.619328 loss_ctc 55.284103 loss_ctc_origin 41.714638 loss_ctc0 86.946182 lr 0.00059686 rank 0
2022-08-26 08:25:34,592 WARNING NaN or Inf found in input tensor.
2022-08-26 08:25:39,003 DEBUG TRAIN Batch 197/2400 loss 21.148094 loss_att 8.850323 loss_ctc 49.842896 loss_ctc_origin 33.662411 loss_ctc0 87.597366 lr 0.00059683 rank 0
2022-08-26 08:26:06,450 DEBUG TRAIN Batch 197/2500 loss 45.203621 loss_att 29.861664 loss_ctc 81.001511 loss_ctc_origin 53.868301 loss_ctc0 144.312347 lr 0.00059680 rank 0
2022-08-26 08:26:19,995 WARNING NaN or Inf found in input tensor.
2022-08-26 08:26:33,925 DEBUG TRAIN Batch 197/2600 loss 55.767502 loss_att 35.189316 loss_ctc 103.783264 loss_ctc_origin 64.366676 loss_ctc0 195.755295 lr 0.00059678 rank 0
2022-08-26 08:27:01,825 DEBUG TRAIN Batch 197/2700 loss 21.848230 loss_att 9.688026 loss_ctc 50.222038 loss_ctc_origin 38.197456 loss_ctc0 78.279404 lr 0.00059675 rank 0
2022-08-26 08:27:30,320 DEBUG TRAIN Batch 197/2800 loss 21.011822 loss_att 7.420241 loss_ctc 52.725510 loss_ctc_origin 38.141781 loss_ctc0 86.754204 lr 0.00059673 rank 0
2022-08-26 08:27:57,686 DEBUG TRAIN Batch 197/2900 loss 21.211466 loss_att 8.599812 loss_ctc 50.638657 loss_ctc_origin 31.882479 loss_ctc0 94.403061 lr 0.00059670 rank 0
2022-08-26 08:28:05,545 WARNING NaN or Inf found in input tensor.
2022-08-26 08:28:30,464 DEBUG TRAIN Batch 197/3000 loss 46.944115 loss_att 30.948812 loss_ctc 84.266479 loss_ctc_origin 58.141499 loss_ctc0 145.224777 lr 0.00059667 rank 0
2022-08-26 08:28:45,392 WARNING NaN or Inf found in input tensor.
2022-08-26 08:28:57,707 WARNING NaN or Inf found in input tensor.
2022-08-26 08:28:57,748 DEBUG TRAIN Batch 197/3100 loss nan loss_att 36.191391 loss_ctc nan loss_ctc_origin 67.323196 loss_ctc0 nan lr 0.00059665 rank 0
2022-08-26 08:29:25,283 DEBUG TRAIN Batch 197/3200 loss 17.451395 loss_att 9.966835 loss_ctc 34.915367 loss_ctc_origin 24.207108 loss_ctc0 59.901314 lr 0.00059662 rank 0
2022-08-26 08:29:30,761 WARNING NaN or Inf found in input tensor.
2022-08-26 08:29:52,404 DEBUG TRAIN Batch 197/3300 loss 19.791710 loss_att 8.366924 loss_ctc 46.449543 loss_ctc_origin 31.067877 loss_ctc0 82.340096 lr 0.00059659 rank 0
2022-08-26 08:30:19,952 DEBUG TRAIN Batch 197/3400 loss 23.085909 loss_att 9.811617 loss_ctc 54.059258 loss_ctc_origin 34.283432 loss_ctc0 100.202843 lr 0.00059657 rank 0
2022-08-26 08:30:47,896 DEBUG TRAIN Batch 197/3500 loss 41.892075 loss_att 26.906603 loss_ctc 76.858170 loss_ctc_origin 49.967155 loss_ctc0 139.603867 lr 0.00059654 rank 0
2022-08-26 08:31:15,202 DEBUG TRAIN Batch 197/3600 loss 52.943718 loss_att 30.612730 loss_ctc 105.049347 loss_ctc_origin 67.954414 loss_ctc0 191.604187 lr 0.00059651 rank 0
2022-08-26 08:31:42,778 DEBUG TRAIN Batch 197/3700 loss 21.211008 loss_att 11.144795 loss_ctc 44.698833 loss_ctc_origin 33.283054 loss_ctc0 71.335648 lr 0.00059649 rank 0
2022-08-26 08:32:10,444 DEBUG TRAIN Batch 197/3800 loss 19.806253 loss_att 8.232794 loss_ctc 46.810989 loss_ctc_origin 31.085772 loss_ctc0 83.503159 lr 0.00059646 rank 0
2022-08-26 08:32:27,167 WARNING NaN or Inf found in input tensor.
2022-08-26 08:32:38,191 DEBUG TRAIN Batch 197/3900 loss 20.537678 loss_att 9.044084 loss_ctc 47.356064 loss_ctc_origin 27.990387 loss_ctc0 92.542641 lr 0.00059643 rank 0
2022-08-26 08:33:05,450 DEBUG TRAIN Batch 197/4000 loss 37.659462 loss_att 24.160950 loss_ctc 69.155983 loss_ctc_origin 44.081146 loss_ctc0 127.663933 lr 0.00059641 rank 0
2022-08-26 08:33:31,775 DEBUG TRAIN Batch 197/4100 loss 52.312050 loss_att 30.931938 loss_ctc 102.198975 loss_ctc_origin 66.013367 loss_ctc0 186.632065 lr 0.00059638 rank 0
2022-08-26 08:33:59,780 DEBUG TRAIN Batch 197/4200 loss 18.239382 loss_att 9.014214 loss_ctc 39.764774 loss_ctc_origin 27.704185 loss_ctc0 67.906151 lr 0.00059635 rank 0
2022-08-26 08:34:27,015 DEBUG TRAIN Batch 197/4300 loss 18.032988 loss_att 7.397557 loss_ctc 42.848988 loss_ctc_origin 29.065331 loss_ctc0 75.010849 lr 0.00059633 rank 0
2022-08-26 08:34:56,669 DEBUG TRAIN Batch 197/4400 loss 19.253077 loss_att 7.972975 loss_ctc 45.573311 loss_ctc_origin 27.927492 loss_ctc0 86.746887 lr 0.00059630 rank 0
2022-08-26 08:35:29,712 DEBUG TRAIN Batch 197/4500 loss 56.976349 loss_att 38.787182 loss_ctc 99.417725 loss_ctc_origin 72.684906 loss_ctc0 161.794281 lr 0.00059627 rank 0
2022-08-26 08:35:58,349 DEBUG TRAIN Batch 197/4600 loss 57.291214 loss_att 30.743183 loss_ctc 119.236618 loss_ctc_origin 72.988647 loss_ctc0 227.148529 lr 0.00059625 rank 0
2022-08-26 08:36:26,105 DEBUG TRAIN Batch 197/4700 loss 18.693583 loss_att 9.626001 loss_ctc 39.851273 loss_ctc_origin 27.756033 loss_ctc0 68.073502 lr 0.00059622 rank 0
2022-08-26 08:36:53,894 DEBUG TRAIN Batch 197/4800 loss 18.100002 loss_att 7.119729 loss_ctc 43.720638 loss_ctc_origin 28.482944 loss_ctc0 79.275253 lr 0.00059619 rank 0
2022-08-26 08:37:21,360 DEBUG TRAIN Batch 197/4900 loss 24.673306 loss_att 9.778266 loss_ctc 59.428394 loss_ctc_origin 41.564007 loss_ctc0 101.111961 lr 0.00059617 rank 0
2022-08-26 08:37:49,020 DEBUG TRAIN Batch 197/5000 loss 55.140251 loss_att 37.682034 loss_ctc 95.876091 loss_ctc_origin 69.734413 loss_ctc0 156.873337 lr 0.00059614 rank 0
2022-08-26 08:38:15,871 DEBUG TRAIN Batch 197/5100 loss 63.722183 loss_att 37.390678 loss_ctc 125.162354 loss_ctc_origin 74.608482 loss_ctc0 243.121368 lr 0.00059612 rank 0
2022-08-26 08:38:43,628 DEBUG TRAIN Batch 197/5200 loss 17.738089 loss_att 10.063834 loss_ctc 35.644684 loss_ctc_origin 23.595211 loss_ctc0 63.760124 lr 0.00059609 rank 0
2022-08-26 08:39:11,705 DEBUG TRAIN Batch 197/5300 loss 19.186899 loss_att 8.449343 loss_ctc 44.241196 loss_ctc_origin 30.121029 loss_ctc0 77.188248 lr 0.00059606 rank 0
2022-08-26 08:39:28,334 WARNING NaN or Inf found in input tensor.
2022-08-26 08:39:35,451 WARNING NaN or Inf found in input tensor.
2022-08-26 08:39:39,794 DEBUG TRAIN Batch 197/5400 loss 21.569592 loss_att 8.867453 loss_ctc 51.207916 loss_ctc_origin 32.090122 loss_ctc0 95.816093 lr 0.00059604 rank 0
2022-08-26 08:40:08,190 DEBUG TRAIN Batch 197/5500 loss 42.276810 loss_att 27.935738 loss_ctc 75.739319 loss_ctc_origin 49.465881 loss_ctc0 137.044006 lr 0.00059601 rank 0
2022-08-26 08:40:34,489 DEBUG TRAIN Batch 197/5600 loss 62.676926 loss_att 37.097538 loss_ctc 122.362152 loss_ctc_origin 86.356216 loss_ctc0 206.375977 lr 0.00059598 rank 0
2022-08-26 08:40:57,093 DEBUG CV Batch 197/0 loss 11.940142 loss_att 8.800327 loss_ctc 19.266376 loss_ctc_origin 12.777595 loss_ctc0 34.406872 history loss 11.237780 rank 0
2022-08-26 08:41:07,630 DEBUG CV Batch 197/100 loss 20.528210 loss_att 16.248154 loss_ctc 30.515003 loss_ctc_origin 21.084396 loss_ctc0 52.519753 history loss 26.219364 rank 0
2022-08-26 08:41:16,967 DEBUG CV Batch 197/200 loss 25.222065 loss_att 19.873692 loss_ctc 37.701607 loss_ctc_origin 27.268215 loss_ctc0 62.046185 history loss 27.527099 rank 0
2022-08-26 08:41:26,474 DEBUG CV Batch 197/300 loss 22.216854 loss_att 16.612686 loss_ctc 35.293243 loss_ctc_origin 19.492912 loss_ctc0 72.160675 history loss 26.648863 rank 0
2022-08-26 08:41:36,301 DEBUG CV Batch 197/400 loss 37.517136 loss_att 29.991295 loss_ctc 55.077423 loss_ctc_origin 38.158714 loss_ctc0 94.554413 history loss 24.978091 rank 0
2022-08-26 08:41:46,533 DEBUG CV Batch 197/500 loss 16.137403 loss_att 11.836277 loss_ctc 26.173367 loss_ctc_origin 19.325005 loss_ctc0 42.152878 history loss 24.645120 rank 0
2022-08-26 08:41:56,645 DEBUG CV Batch 197/600 loss 16.740040 loss_att 11.518604 loss_ctc 28.923391 loss_ctc_origin 18.279305 loss_ctc0 53.759590 history loss 24.508143 rank 0
2022-08-26 08:42:06,340 DEBUG CV Batch 197/700 loss 18.675972 loss_att 13.255636 loss_ctc 31.323423 loss_ctc_origin 17.616938 loss_ctc0 63.305225 history loss 24.167038 rank 0
2022-08-26 08:42:16,454 DEBUG CV Batch 197/800 loss 22.497923 loss_att 17.771875 loss_ctc 33.525368 loss_ctc_origin 18.320293 loss_ctc0 69.003876 history loss 24.127412 rank 0
2022-08-26 08:42:26,571 INFO Epoch 197 CV info cv_loss 24.20707322418411
2022-08-26 08:42:26,572 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/197.pt
2022-08-26 08:42:27,029 INFO Epoch 198 TRAIN info lr 0.0005959606795254529
2022-08-26 08:42:27,033 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 08:42:53,011 DEBUG TRAIN Batch 198/0 loss 52.828747 loss_att 36.429028 loss_ctc 91.094757 loss_ctc_origin 67.372955 loss_ctc0 146.445618 lr 0.00059596 rank 0
2022-08-26 08:43:20,580 DEBUG TRAIN Batch 198/100 loss 55.382576 loss_att 30.313267 loss_ctc 113.877640 loss_ctc_origin 63.324249 loss_ctc0 231.835541 lr 0.00059593 rank 0
2022-08-26 08:43:47,986 DEBUG TRAIN Batch 198/200 loss 18.897999 loss_att 9.294230 loss_ctc 41.306793 loss_ctc_origin 29.247606 loss_ctc0 69.444901 lr 0.00059591 rank 0
2022-08-26 08:44:15,101 DEBUG TRAIN Batch 198/300 loss 18.981470 loss_att 7.611193 loss_ctc 45.512119 loss_ctc_origin 30.648212 loss_ctc0 80.194565 lr 0.00059588 rank 0
2022-08-26 08:44:42,699 DEBUG TRAIN Batch 198/400 loss 23.176357 loss_att 10.705667 loss_ctc 52.274635 loss_ctc_origin 32.880100 loss_ctc0 97.528557 lr 0.00059585 rank 0
2022-08-26 08:45:10,662 DEBUG TRAIN Batch 198/500 loss 49.050049 loss_att 33.784645 loss_ctc 84.669327 loss_ctc_origin 60.960876 loss_ctc0 139.989044 lr 0.00059583 rank 0
2022-08-26 08:45:30,896 WARNING NaN or Inf found in input tensor.
2022-08-26 08:45:38,040 DEBUG TRAIN Batch 198/600 loss 61.263641 loss_att 36.570286 loss_ctc 118.881470 loss_ctc_origin 66.858902 loss_ctc0 240.267456 lr 0.00059580 rank 0
2022-08-26 08:46:05,404 DEBUG TRAIN Batch 198/700 loss 17.677721 loss_att 8.838478 loss_ctc 38.302620 loss_ctc_origin 27.149027 loss_ctc0 64.327675 lr 0.00059577 rank 0
2022-08-26 08:46:32,695 DEBUG TRAIN Batch 198/800 loss 18.039940 loss_att 6.418513 loss_ctc 45.156597 loss_ctc_origin 29.273258 loss_ctc0 82.217720 lr 0.00059575 rank 0
2022-08-26 08:46:55,673 WARNING NaN or Inf found in input tensor.
2022-08-26 08:46:59,959 DEBUG TRAIN Batch 198/900 loss 20.990292 loss_att 8.294355 loss_ctc 50.614140 loss_ctc_origin 30.635748 loss_ctc0 97.230385 lr 0.00059572 rank 0
2022-08-26 08:47:27,668 DEBUG TRAIN Batch 198/1000 loss 48.974480 loss_att 33.710716 loss_ctc 84.589920 loss_ctc_origin 59.349537 loss_ctc0 143.484161 lr 0.00059570 rank 0
2022-08-26 08:47:56,191 DEBUG TRAIN Batch 198/1100 loss 60.788086 loss_att 36.125031 loss_ctc 118.335205 loss_ctc_origin 81.941650 loss_ctc0 203.253479 lr 0.00059567 rank 0
2022-08-26 08:48:14,888 WARNING NaN or Inf found in input tensor.
2022-08-26 08:48:24,405 DEBUG TRAIN Batch 198/1200 loss 17.702606 loss_att 8.752522 loss_ctc 38.586136 loss_ctc_origin 25.520426 loss_ctc0 69.072784 lr 0.00059564 rank 0
2022-08-26 08:48:52,107 DEBUG TRAIN Batch 198/1300 loss 20.688148 loss_att 7.996955 loss_ctc 50.300934 loss_ctc_origin 33.782974 loss_ctc0 88.842834 lr 0.00059562 rank 0
2022-08-26 08:49:19,702 DEBUG TRAIN Batch 198/1400 loss 18.728397 loss_att 7.056111 loss_ctc 45.963730 loss_ctc_origin 27.282732 loss_ctc0 89.552719 lr 0.00059559 rank 0
2022-08-26 08:49:53,038 DEBUG TRAIN Batch 198/1500 loss 45.163261 loss_att 28.622753 loss_ctc 83.757774 loss_ctc_origin 54.130928 loss_ctc0 152.887085 lr 0.00059556 rank 0
2022-08-26 08:50:21,087 DEBUG TRAIN Batch 198/1600 loss 64.744858 loss_att 35.654259 loss_ctc 132.622925 loss_ctc_origin 84.579796 loss_ctc0 244.723541 lr 0.00059554 rank 0
2022-08-26 08:50:48,738 DEBUG TRAIN Batch 198/1700 loss 21.492908 loss_att 10.920679 loss_ctc 46.161442 loss_ctc_origin 36.088844 loss_ctc0 69.664169 lr 0.00059551 rank 0
2022-08-26 08:51:15,330 DEBUG TRAIN Batch 198/1800 loss 16.190331 loss_att 6.634742 loss_ctc 38.486706 loss_ctc_origin 21.953554 loss_ctc0 77.064056 lr 0.00059548 rank 0
2022-08-26 08:51:42,250 DEBUG TRAIN Batch 198/1900 loss 23.439365 loss_att 9.706236 loss_ctc 55.483330 loss_ctc_origin 37.266655 loss_ctc0 97.988899 lr 0.00059546 rank 0
2022-08-26 08:52:10,514 DEBUG TRAIN Batch 198/2000 loss 48.624817 loss_att 33.651237 loss_ctc 83.563171 loss_ctc_origin 54.160137 loss_ctc0 152.170258 lr 0.00059543 rank 0
2022-08-26 08:52:38,444 DEBUG TRAIN Batch 198/2100 loss 56.030212 loss_att 29.781536 loss_ctc 117.277130 loss_ctc_origin 65.792542 loss_ctc0 237.407837 lr 0.00059540 rank 0
2022-08-26 08:53:04,365 WARNING NaN or Inf found in input tensor.
2022-08-26 08:53:05,890 DEBUG TRAIN Batch 198/2200 loss 18.189529 loss_att 8.310791 loss_ctc 41.239922 loss_ctc_origin 30.082024 loss_ctc0 67.275017 lr 0.00059538 rank 0
2022-08-26 08:53:33,593 DEBUG TRAIN Batch 198/2300 loss 18.471855 loss_att 6.812857 loss_ctc 45.676186 loss_ctc_origin 29.948154 loss_ctc0 82.374924 lr 0.00059535 rank 0
2022-08-26 08:54:02,001 DEBUG TRAIN Batch 198/2400 loss 18.609308 loss_att 7.140782 loss_ctc 45.369202 loss_ctc_origin 26.942005 loss_ctc0 88.365990 lr 0.00059533 rank 0
2022-08-26 08:54:29,761 DEBUG TRAIN Batch 198/2500 loss 57.530109 loss_att 40.411461 loss_ctc 97.473618 loss_ctc_origin 68.368759 loss_ctc0 165.384949 lr 0.00059530 rank 0
2022-08-26 08:54:57,065 DEBUG TRAIN Batch 198/2600 loss 61.791225 loss_att 37.883068 loss_ctc 117.576927 loss_ctc_origin 75.868431 loss_ctc0 214.896729 lr 0.00059527 rank 0
2022-08-26 08:55:24,299 DEBUG TRAIN Batch 198/2700 loss 19.728451 loss_att 10.314743 loss_ctc 41.693764 loss_ctc_origin 30.399170 loss_ctc0 68.047821 lr 0.00059525 rank 0
2022-08-26 08:55:52,614 DEBUG TRAIN Batch 198/2800 loss 17.882439 loss_att 6.873186 loss_ctc 43.570694 loss_ctc_origin 26.482231 loss_ctc0 83.443771 lr 0.00059522 rank 0
2022-08-26 08:56:16,633 WARNING NaN or Inf found in input tensor.
2022-08-26 08:56:21,050 DEBUG TRAIN Batch 198/2900 loss 21.624584 loss_att 8.808588 loss_ctc 51.528572 loss_ctc_origin 34.423061 loss_ctc0 91.441437 lr 0.00059519 rank 0
2022-08-26 08:56:55,329 DEBUG TRAIN Batch 198/3000 loss 49.101273 loss_att 33.436005 loss_ctc 85.653564 loss_ctc_origin 64.579445 loss_ctc0 134.826508 lr 0.00059517 rank 0
2022-08-26 08:57:23,453 DEBUG TRAIN Batch 198/3100 loss 66.108849 loss_att 40.228897 loss_ctc 126.495407 loss_ctc_origin 85.614250 loss_ctc0 221.884766 lr 0.00059514 rank 0
2022-08-26 08:57:51,849 DEBUG TRAIN Batch 198/3200 loss 17.616415 loss_att 8.663118 loss_ctc 38.507439 loss_ctc_origin 26.692492 loss_ctc0 66.075653 lr 0.00059511 rank 0
2022-08-26 08:58:19,995 DEBUG TRAIN Batch 198/3300 loss 16.261024 loss_att 6.764294 loss_ctc 38.420067 loss_ctc_origin 24.557186 loss_ctc0 70.766785 lr 0.00059509 rank 0
2022-08-26 08:58:48,546 DEBUG TRAIN Batch 198/3400 loss 22.055834 loss_att 9.108070 loss_ctc 52.267281 loss_ctc_origin 33.452599 loss_ctc0 96.168205 lr 0.00059506 rank 0
2022-08-26 08:59:17,164 DEBUG TRAIN Batch 198/3500 loss 54.870373 loss_att 38.927299 loss_ctc 92.070877 loss_ctc_origin 74.814568 loss_ctc0 132.335602 lr 0.00059504 rank 0
2022-08-26 08:59:25,091 WARNING NaN or Inf found in input tensor.
2022-08-26 08:59:44,992 DEBUG TRAIN Batch 198/3600 loss 51.659370 loss_att 27.416103 loss_ctc 108.226990 loss_ctc_origin 68.080215 loss_ctc0 201.902786 lr 0.00059501 rank 0
2022-08-26 09:00:12,977 DEBUG TRAIN Batch 198/3700 loss 20.400105 loss_att 10.107927 loss_ctc 44.415184 loss_ctc_origin 31.528988 loss_ctc0 74.482971 lr 0.00059498 rank 0
2022-08-26 09:00:41,364 DEBUG TRAIN Batch 198/3800 loss 18.486166 loss_att 6.969981 loss_ctc 45.357262 loss_ctc_origin 30.960297 loss_ctc0 78.950180 lr 0.00059496 rank 0
2022-08-26 09:01:08,973 DEBUG TRAIN Batch 198/3900 loss 19.592421 loss_att 7.543827 loss_ctc 47.705803 loss_ctc_origin 25.530684 loss_ctc0 99.447739 lr 0.00059493 rank 0
2022-08-26 09:01:37,994 DEBUG TRAIN Batch 198/4000 loss 54.633713 loss_att 37.320450 loss_ctc 95.031326 loss_ctc_origin 70.241928 loss_ctc0 152.873260 lr 0.00059490 rank 0
2022-08-26 09:02:05,544 WARNING NaN or Inf found in input tensor.
2022-08-26 09:02:06,308 DEBUG TRAIN Batch 198/4100 loss 60.305664 loss_att 35.409195 loss_ctc 118.397415 loss_ctc_origin 78.254944 loss_ctc0 212.063171 lr 0.00059488 rank 0
2022-08-26 09:02:34,285 DEBUG TRAIN Batch 198/4200 loss 16.763477 loss_att 8.038376 loss_ctc 37.122047 loss_ctc_origin 25.963900 loss_ctc0 63.157730 lr 0.00059485 rank 0
2022-08-26 09:03:01,703 DEBUG TRAIN Batch 198/4300 loss 19.495857 loss_att 7.106098 loss_ctc 48.405296 loss_ctc_origin 33.844963 loss_ctc0 82.379410 lr 0.00059483 rank 0
2022-08-26 09:03:29,024 DEBUG TRAIN Batch 198/4400 loss 21.218767 loss_att 7.755949 loss_ctc 52.632008 loss_ctc_origin 31.572853 loss_ctc0 101.770035 lr 0.00059480 rank 0
2022-08-26 09:04:02,767 DEBUG TRAIN Batch 198/4500 loss 51.722656 loss_att 35.530163 loss_ctc 89.505142 loss_ctc_origin 65.280029 loss_ctc0 146.030396 lr 0.00059477 rank 0
2022-08-26 09:04:29,318 DEBUG TRAIN Batch 198/4600 loss 53.369759 loss_att 29.621445 loss_ctc 108.782486 loss_ctc_origin 64.126480 loss_ctc0 212.979828 lr 0.00059475 rank 0
2022-08-26 09:04:55,531 DEBUG TRAIN Batch 198/4700 loss 18.342457 loss_att 9.021273 loss_ctc 40.091885 loss_ctc_origin 28.275517 loss_ctc0 67.663406 lr 0.00059472 rank 0
2022-08-26 09:05:22,245 DEBUG TRAIN Batch 198/4800 loss 19.432058 loss_att 8.062843 loss_ctc 45.960228 loss_ctc_origin 29.765610 loss_ctc0 83.747665 lr 0.00059469 rank 0
2022-08-26 09:05:44,503 WARNING NaN or Inf found in input tensor.
2022-08-26 09:05:48,812 DEBUG TRAIN Batch 198/4900 loss 22.167248 loss_att 9.932046 loss_ctc 50.716049 loss_ctc_origin 34.022522 loss_ctc0 89.667618 lr 0.00059467 rank 0
2022-08-26 09:06:16,200 DEBUG TRAIN Batch 198/5000 loss 45.799484 loss_att 30.777271 loss_ctc 80.851303 loss_ctc_origin 51.927021 loss_ctc0 148.341278 lr 0.00059464 rank 0
2022-08-26 09:06:42,761 DEBUG TRAIN Batch 198/5100 loss 51.562496 loss_att 28.306038 loss_ctc 105.827560 loss_ctc_origin 59.940426 loss_ctc0 212.897522 lr 0.00059461 rank 0
2022-08-26 09:07:08,086 DEBUG TRAIN Batch 198/5200 loss 16.177158 loss_att 8.656399 loss_ctc 33.725594 loss_ctc_origin 20.339741 loss_ctc0 64.959251 lr 0.00059459 rank 0
2022-08-26 09:07:34,975 DEBUG TRAIN Batch 198/5300 loss 20.576906 loss_att 9.016632 loss_ctc 47.550880 loss_ctc_origin 32.185341 loss_ctc0 83.403809 lr 0.00059456 rank 0
2022-08-26 09:08:01,701 DEBUG TRAIN Batch 198/5400 loss 20.678789 loss_att 7.878335 loss_ctc 50.546513 loss_ctc_origin 32.878677 loss_ctc0 91.771461 lr 0.00059454 rank 0
2022-08-26 09:08:27,700 DEBUG TRAIN Batch 198/5500 loss 46.531311 loss_att 29.505455 loss_ctc 86.258301 loss_ctc_origin 57.982967 loss_ctc0 152.234070 lr 0.00059451 rank 0
2022-08-26 09:08:39,517 WARNING NaN or Inf found in input tensor.
2022-08-26 09:08:53,245 DEBUG TRAIN Batch 198/5600 loss 56.721107 loss_att 33.376343 loss_ctc 111.192223 loss_ctc_origin 67.776131 loss_ctc0 212.496429 lr 0.00059448 rank 0
2022-08-26 09:09:16,056 DEBUG CV Batch 198/0 loss 12.896945 loss_att 9.707626 loss_ctc 20.338688 loss_ctc_origin 14.411955 loss_ctc0 34.167732 history loss 12.138301 rank 0
2022-08-26 09:09:26,444 DEBUG CV Batch 198/100 loss 20.393068 loss_att 15.957972 loss_ctc 30.741627 loss_ctc_origin 21.449108 loss_ctc0 52.424168 history loss 26.320592 rank 0
2022-08-26 09:09:36,298 DEBUG CV Batch 198/200 loss 24.966442 loss_att 20.001492 loss_ctc 36.551327 loss_ctc_origin 25.941984 loss_ctc0 61.306454 history loss 27.517253 rank 0
2022-08-26 09:09:46,258 DEBUG CV Batch 198/300 loss 22.386145 loss_att 16.740065 loss_ctc 35.560329 loss_ctc_origin 20.316311 loss_ctc0 71.129707 history loss 26.629033 rank 0
2022-08-26 09:09:56,414 DEBUG CV Batch 198/400 loss 38.062038 loss_att 30.852272 loss_ctc 54.884823 loss_ctc_origin 38.010597 loss_ctc0 94.258011 history loss 24.967091 rank 0
2022-08-26 09:10:06,853 DEBUG CV Batch 198/500 loss 16.332344 loss_att 12.069279 loss_ctc 26.279495 loss_ctc_origin 19.440039 loss_ctc0 42.238228 history loss 24.611068 rank 0
2022-08-26 09:10:17,186 DEBUG CV Batch 198/600 loss 16.927088 loss_att 11.934611 loss_ctc 28.576199 loss_ctc_origin 18.196289 loss_ctc0 52.795990 history loss 24.421217 rank 0
2022-08-26 09:10:27,420 DEBUG CV Batch 198/700 loss 18.859673 loss_att 13.052267 loss_ctc 32.410282 loss_ctc_origin 18.986286 loss_ctc0 63.732937 history loss 24.102597 rank 0
2022-08-26 09:10:37,814 DEBUG CV Batch 198/800 loss 21.344349 loss_att 16.801302 loss_ctc 31.944792 loss_ctc_origin 16.450933 loss_ctc0 68.097122 history loss 24.062691 rank 0
2022-08-26 09:10:47,788 INFO Epoch 198 CV info cv_loss 24.14247183587735
2022-08-26 09:10:47,788 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/198.pt
2022-08-26 09:10:48,228 INFO Epoch 199 TRAIN info lr 0.0005944614050005359
2022-08-26 09:10:48,231 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 09:11:14,316 DEBUG TRAIN Batch 199/0 loss 55.348537 loss_att 40.061111 loss_ctc 91.019196 loss_ctc_origin 61.570114 loss_ctc0 159.733719 lr 0.00059446 rank 0
2022-08-26 09:11:28,784 WARNING NaN or Inf found in input tensor.
2022-08-26 09:11:42,015 WARNING NaN or Inf found in input tensor.
2022-08-26 09:11:42,059 DEBUG TRAIN Batch 199/100 loss nan loss_att 33.004162 loss_ctc nan loss_ctc_origin 69.322144 loss_ctc0 nan lr 0.00059443 rank 0
2022-08-26 09:12:09,824 DEBUG TRAIN Batch 199/200 loss 19.672508 loss_att 10.403162 loss_ctc 41.300980 loss_ctc_origin 30.688435 loss_ctc0 66.063591 lr 0.00059441 rank 0
2022-08-26 09:12:15,175 WARNING NaN or Inf found in input tensor.
2022-08-26 09:12:38,089 DEBUG TRAIN Batch 199/300 loss 16.917496 loss_att 6.722001 loss_ctc 40.706985 loss_ctc_origin 25.948338 loss_ctc0 75.143829 lr 0.00059438 rank 0
2022-08-26 09:13:06,209 DEBUG TRAIN Batch 199/400 loss 21.281893 loss_att 8.887173 loss_ctc 50.202904 loss_ctc_origin 32.429646 loss_ctc0 91.673843 lr 0.00059436 rank 0
2022-08-26 09:13:34,175 DEBUG TRAIN Batch 199/500 loss 40.281273 loss_att 25.529400 loss_ctc 74.702316 loss_ctc_origin 47.476448 loss_ctc0 138.229340 lr 0.00059433 rank 0
2022-08-26 09:13:54,866 WARNING NaN or Inf found in input tensor.
2022-08-26 09:14:01,854 DEBUG TRAIN Batch 199/600 loss 55.893169 loss_att 31.935131 loss_ctc 111.795250 loss_ctc_origin 69.117218 loss_ctc0 211.377319 lr 0.00059430 rank 0
2022-08-26 09:14:29,248 DEBUG TRAIN Batch 199/700 loss 19.575893 loss_att 10.568913 loss_ctc 40.592178 loss_ctc_origin 28.343464 loss_ctc0 69.172516 lr 0.00059428 rank 0
2022-08-26 09:14:56,924 DEBUG TRAIN Batch 199/800 loss 17.753105 loss_att 6.855940 loss_ctc 43.179825 loss_ctc_origin 26.362949 loss_ctc0 82.419205 lr 0.00059425 rank 0
2022-08-26 09:15:20,069 WARNING NaN or Inf found in input tensor.
2022-08-26 09:15:24,229 DEBUG TRAIN Batch 199/900 loss 21.829254 loss_att 8.985018 loss_ctc 51.799141 loss_ctc_origin 32.266193 loss_ctc0 97.376022 lr 0.00059422 rank 0
2022-08-26 09:15:51,260 DEBUG TRAIN Batch 199/1000 loss 42.900681 loss_att 28.758457 loss_ctc 75.899200 loss_ctc_origin 49.951500 loss_ctc0 136.443848 lr 0.00059420 rank 0
2022-08-26 09:16:19,448 DEBUG TRAIN Batch 199/1100 loss 56.964939 loss_att 31.865065 loss_ctc 115.531311 loss_ctc_origin 69.111877 loss_ctc0 223.843292 lr 0.00059417 rank 0
2022-08-26 09:16:45,612 WARNING NaN or Inf found in input tensor.
2022-08-26 09:16:47,184 DEBUG TRAIN Batch 199/1200 loss 19.125191 loss_att 10.946609 loss_ctc 38.208546 loss_ctc_origin 28.213295 loss_ctc0 61.530800 lr 0.00059415 rank 0
2022-08-26 09:17:15,262 DEBUG TRAIN Batch 199/1300 loss 15.646800 loss_att 5.463108 loss_ctc 39.408745 loss_ctc_origin 25.364126 loss_ctc0 72.179527 lr 0.00059412 rank 0
2022-08-26 09:17:43,492 DEBUG TRAIN Batch 199/1400 loss 20.497135 loss_att 6.849795 loss_ctc 52.340927 loss_ctc_origin 32.160473 loss_ctc0 99.428642 lr 0.00059409 rank 0
2022-08-26 09:18:15,519 DEBUG TRAIN Batch 199/1500 loss 40.605957 loss_att 25.660498 loss_ctc 75.478699 loss_ctc_origin 45.293858 loss_ctc0 145.909973 lr 0.00059407 rank 0
2022-08-26 09:18:43,339 DEBUG TRAIN Batch 199/1600 loss 56.777519 loss_att 33.836868 loss_ctc 110.305695 loss_ctc_origin 65.940903 loss_ctc0 213.823547 lr 0.00059404 rank 0
2022-08-26 09:19:10,029 DEBUG TRAIN Batch 199/1700 loss 19.873831 loss_att 9.260849 loss_ctc 44.637451 loss_ctc_origin 30.900070 loss_ctc0 76.691345 lr 0.00059401 rank 0
2022-08-26 09:19:37,879 DEBUG TRAIN Batch 199/1800 loss 17.915562 loss_att 7.121597 loss_ctc 43.101479 loss_ctc_origin 27.059647 loss_ctc0 80.532425 lr 0.00059399 rank 0
2022-08-26 09:20:06,219 DEBUG TRAIN Batch 199/1900 loss 21.628811 loss_att 8.877508 loss_ctc 51.381851 loss_ctc_origin 32.064018 loss_ctc0 96.456787 lr 0.00059396 rank 0
2022-08-26 09:20:33,537 DEBUG TRAIN Batch 199/2000 loss 47.984070 loss_att 29.912853 loss_ctc 90.150230 loss_ctc_origin 62.960552 loss_ctc0 153.592804 lr 0.00059394 rank 0
2022-08-26 09:20:40,761 WARNING NaN or Inf found in input tensor.
2022-08-26 09:21:01,147 DEBUG TRAIN Batch 199/2100 loss 49.759567 loss_att 26.594763 loss_ctc 103.810776 loss_ctc_origin 57.404533 loss_ctc0 212.092010 lr 0.00059391 rank 0
2022-08-26 09:21:29,308 DEBUG TRAIN Batch 199/2200 loss 17.770645 loss_att 9.274361 loss_ctc 37.595306 loss_ctc_origin 25.805744 loss_ctc0 65.104294 lr 0.00059388 rank 0
2022-08-26 09:21:56,856 DEBUG TRAIN Batch 199/2300 loss 19.735346 loss_att 8.602497 loss_ctc 45.711990 loss_ctc_origin 32.400429 loss_ctc0 76.772308 lr 0.00059386 rank 0
2022-08-26 09:22:24,673 DEBUG TRAIN Batch 199/2400 loss 23.003967 loss_att 9.229019 loss_ctc 55.145508 loss_ctc_origin 35.843872 loss_ctc0 100.182663 lr 0.00059383 rank 0
2022-08-26 09:22:39,079 WARNING NaN or Inf found in input tensor.
2022-08-26 09:22:52,325 DEBUG TRAIN Batch 199/2500 loss 53.721199 loss_att 36.300014 loss_ctc 94.370636 loss_ctc_origin 68.187729 loss_ctc0 155.464066 lr 0.00059380 rank 0
2022-08-26 09:23:20,859 DEBUG TRAIN Batch 199/2600 loss 55.461922 loss_att 35.839466 loss_ctc 101.247650 loss_ctc_origin 63.810581 loss_ctc0 188.600800 lr 0.00059378 rank 0
2022-08-26 09:23:48,852 DEBUG TRAIN Batch 199/2700 loss 20.874371 loss_att 11.478320 loss_ctc 42.798485 loss_ctc_origin 33.451691 loss_ctc0 64.607666 lr 0.00059375 rank 0
2022-08-26 09:24:16,543 DEBUG TRAIN Batch 199/2800 loss 19.331074 loss_att 7.753796 loss_ctc 46.344719 loss_ctc_origin 28.827927 loss_ctc0 87.217232 lr 0.00059373 rank 0
2022-08-26 09:24:44,592 DEBUG TRAIN Batch 199/2900 loss 21.045050 loss_att 7.946412 loss_ctc 51.608536 loss_ctc_origin 33.907398 loss_ctc0 92.911194 lr 0.00059370 rank 0
2022-08-26 09:25:17,865 DEBUG TRAIN Batch 199/3000 loss 43.482410 loss_att 28.765545 loss_ctc 77.821762 loss_ctc_origin 51.751503 loss_ctc0 138.652374 lr 0.00059367 rank 0
2022-08-26 09:25:45,835 DEBUG TRAIN Batch 199/3100 loss 53.265236 loss_att 30.107937 loss_ctc 107.298920 loss_ctc_origin 67.316368 loss_ctc0 200.591553 lr 0.00059365 rank 0
2022-08-26 09:26:13,586 DEBUG TRAIN Batch 199/3200 loss 20.621254 loss_att 9.634513 loss_ctc 46.256981 loss_ctc_origin 35.420288 loss_ctc0 71.542595 lr 0.00059362 rank 0
2022-08-26 09:26:40,743 DEBUG TRAIN Batch 199/3300 loss 17.994080 loss_att 7.800098 loss_ctc 41.780037 loss_ctc_origin 27.204071 loss_ctc0 75.790634 lr 0.00059360 rank 0
2022-08-26 09:27:07,144 DEBUG TRAIN Batch 199/3400 loss 23.764238 loss_att 9.970873 loss_ctc 55.948757 loss_ctc_origin 37.486389 loss_ctc0 99.027611 lr 0.00059357 rank 0
2022-08-26 09:27:34,267 DEBUG TRAIN Batch 199/3500 loss 48.259670 loss_att 33.829464 loss_ctc 81.930153 loss_ctc_origin 59.327499 loss_ctc0 134.669678 lr 0.00059354 rank 0
2022-08-26 09:28:00,808 DEBUG TRAIN Batch 199/3600 loss 49.964920 loss_att 26.312906 loss_ctc 105.152954 loss_ctc_origin 62.275963 loss_ctc0 205.199265 lr 0.00059352 rank 0
2022-08-26 09:28:27,488 WARNING NaN or Inf found in input tensor.
2022-08-26 09:28:29,198 DEBUG TRAIN Batch 199/3700 loss 20.426798 loss_att 10.165041 loss_ctc 44.370895 loss_ctc_origin 31.602222 loss_ctc0 74.164459 lr 0.00059349 rank 0
2022-08-26 09:28:34,728 WARNING NaN or Inf found in input tensor.
2022-08-26 09:28:56,150 DEBUG TRAIN Batch 199/3800 loss 16.294571 loss_att 5.305794 loss_ctc 41.935051 loss_ctc_origin 25.682966 loss_ctc0 79.856583 lr 0.00059347 rank 0
2022-08-26 09:29:23,552 DEBUG TRAIN Batch 199/3900 loss 18.909010 loss_att 7.675067 loss_ctc 45.121540 loss_ctc_origin 24.124889 loss_ctc0 94.113724 lr 0.00059344 rank 0
2022-08-26 09:29:51,563 DEBUG TRAIN Batch 199/4000 loss 44.776527 loss_att 30.573204 loss_ctc 77.917618 loss_ctc_origin 50.890396 loss_ctc0 140.981125 lr 0.00059341 rank 0
2022-08-26 09:30:17,943 DEBUG TRAIN Batch 199/4100 loss 50.876957 loss_att 28.628937 loss_ctc 102.789001 loss_ctc_origin 57.946556 loss_ctc0 207.421387 lr 0.00059339 rank 0
2022-08-26 09:30:43,553 DEBUG TRAIN Batch 199/4200 loss 19.460646 loss_att 8.941110 loss_ctc 44.006229 loss_ctc_origin 33.107857 loss_ctc0 69.435768 lr 0.00059336 rank 0
2022-08-26 09:31:11,759 DEBUG TRAIN Batch 199/4300 loss 18.830473 loss_att 8.191507 loss_ctc 43.654724 loss_ctc_origin 30.228592 loss_ctc0 74.982361 lr 0.00059333 rank 0
2022-08-26 09:31:28,631 WARNING NaN or Inf found in input tensor.
2022-08-26 09:31:40,087 DEBUG TRAIN Batch 199/4400 loss 24.456589 loss_att 10.647728 loss_ctc 56.677261 loss_ctc_origin 38.386459 loss_ctc0 99.355789 lr 0.00059331 rank 0
2022-08-26 09:32:12,297 DEBUG TRAIN Batch 199/4500 loss 48.177628 loss_att 32.268524 loss_ctc 85.298859 loss_ctc_origin 57.285969 loss_ctc0 150.662247 lr 0.00059328 rank 0
2022-08-26 09:32:39,853 DEBUG TRAIN Batch 199/4600 loss 57.190083 loss_att 36.350307 loss_ctc 105.816223 loss_ctc_origin 61.341011 loss_ctc0 209.591705 lr 0.00059326 rank 0
2022-08-26 09:33:06,423 WARNING NaN or Inf found in input tensor.
2022-08-26 09:33:08,039 DEBUG TRAIN Batch 199/4700 loss 19.394930 loss_att 9.043669 loss_ctc 43.547874 loss_ctc_origin 32.983669 loss_ctc0 68.197693 lr 0.00059323 rank 0
2022-08-26 09:33:35,097 DEBUG TRAIN Batch 199/4800 loss 16.400173 loss_att 6.473472 loss_ctc 39.562477 loss_ctc_origin 24.758675 loss_ctc0 74.104675 lr 0.00059320 rank 0
2022-08-26 09:34:02,466 DEBUG TRAIN Batch 199/4900 loss 19.951185 loss_att 8.178897 loss_ctc 47.419853 loss_ctc_origin 30.260811 loss_ctc0 87.457611 lr 0.00059318 rank 0
2022-08-26 09:34:30,039 DEBUG TRAIN Batch 199/5000 loss 46.976818 loss_att 30.643185 loss_ctc 85.088623 loss_ctc_origin 58.350227 loss_ctc0 147.478210 lr 0.00059315 rank 0
2022-08-26 09:34:57,656 DEBUG TRAIN Batch 199/5100 loss 56.606682 loss_att 34.002655 loss_ctc 109.349411 loss_ctc_origin 66.458008 loss_ctc0 209.429352 lr 0.00059313 rank 0
2022-08-26 09:35:24,673 DEBUG TRAIN Batch 199/5200 loss 20.994499 loss_att 11.733784 loss_ctc 42.602837 loss_ctc_origin 31.388388 loss_ctc0 68.769882 lr 0.00059310 rank 0
2022-08-26 09:35:52,460 DEBUG TRAIN Batch 199/5300 loss 18.016092 loss_att 7.957427 loss_ctc 41.486313 loss_ctc_origin 27.693314 loss_ctc0 73.669975 lr 0.00059307 rank 0
2022-08-26 09:36:19,529 DEBUG TRAIN Batch 199/5400 loss 20.539345 loss_att 8.751266 loss_ctc 48.044861 loss_ctc_origin 28.791275 loss_ctc0 92.969894 lr 0.00059305 rank 0
2022-08-26 09:36:47,347 DEBUG TRAIN Batch 199/5500 loss 47.834373 loss_att 30.769266 loss_ctc 87.652954 loss_ctc_origin 59.748730 loss_ctc0 152.762817 lr 0.00059302 rank 0
2022-08-26 09:37:16,545 DEBUG TRAIN Batch 199/5600 loss 47.954422 loss_att 25.984009 loss_ctc 99.218719 loss_ctc_origin 58.741131 loss_ctc0 193.666412 lr 0.00059300 rank 0
2022-08-26 09:37:39,352 DEBUG CV Batch 199/0 loss 11.290539 loss_att 8.288383 loss_ctc 18.295567 loss_ctc_origin 11.799795 loss_ctc0 33.452366 history loss 10.626389 rank 0
2022-08-26 09:37:49,645 DEBUG CV Batch 199/100 loss 20.634916 loss_att 16.359600 loss_ctc 30.610653 loss_ctc_origin 21.048065 loss_ctc0 52.923359 history loss 25.832812 rank 0
2022-08-26 09:37:59,317 DEBUG CV Batch 199/200 loss 24.835747 loss_att 19.593437 loss_ctc 37.067799 loss_ctc_origin 26.567303 loss_ctc0 61.568958 history loss 27.258896 rank 0
2022-08-26 09:38:09,172 DEBUG CV Batch 199/300 loss 22.435448 loss_att 16.816315 loss_ctc 35.546753 loss_ctc_origin 20.052551 loss_ctc0 71.699890 history loss 26.314049 rank 0
2022-08-26 09:38:19,594 DEBUG CV Batch 199/400 loss 38.134571 loss_att 30.948036 loss_ctc 54.903149 loss_ctc_origin 37.677452 loss_ctc0 95.096436 history loss 24.715952 rank 0
2022-08-26 09:38:30,548 DEBUG CV Batch 199/500 loss 15.940166 loss_att 11.527670 loss_ctc 26.235992 loss_ctc_origin 19.597530 loss_ctc0 41.725731 history loss 24.391776 rank 0
2022-08-26 09:38:40,862 DEBUG CV Batch 199/600 loss 17.194277 loss_att 12.092245 loss_ctc 29.099018 loss_ctc_origin 18.935020 loss_ctc0 52.815014 history loss 24.221395 rank 0
2022-08-26 09:38:50,567 DEBUG CV Batch 199/700 loss 18.243359 loss_att 13.030896 loss_ctc 30.405771 loss_ctc_origin 16.728971 loss_ctc0 62.318302 history loss 23.882913 rank 0
2022-08-26 09:39:00,726 DEBUG CV Batch 199/800 loss 21.525181 loss_att 16.710419 loss_ctc 32.759624 loss_ctc_origin 17.507385 loss_ctc0 68.348183 history loss 23.841352 rank 0
2022-08-26 09:39:10,578 INFO Epoch 199 CV info cv_loss 23.919202548823353
2022-08-26 09:39:10,578 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/199.pt
2022-08-26 09:39:11,010 INFO Epoch 200 TRAIN info lr 0.0005929733891373501
2022-08-26 09:39:11,014 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 09:39:36,322 DEBUG TRAIN Batch 200/0 loss 44.352173 loss_att 26.528385 loss_ctc 85.941002 loss_ctc_origin 53.361855 loss_ctc0 161.959000 lr 0.00059297 rank 0
2022-08-26 09:39:44,234 WARNING NaN or Inf found in input tensor.
2022-08-26 09:40:04,339 DEBUG TRAIN Batch 200/100 loss 47.917725 loss_att 21.999790 loss_ctc 108.392899 loss_ctc_origin 56.634094 loss_ctc0 229.163422 lr 0.00059295 rank 0
2022-08-26 09:40:32,124 DEBUG TRAIN Batch 200/200 loss 16.780817 loss_att 6.769156 loss_ctc 40.141357 loss_ctc_origin 28.264549 loss_ctc0 67.853897 lr 0.00059292 rank 0
2022-08-26 09:40:59,885 DEBUG TRAIN Batch 200/300 loss 20.653082 loss_att 8.608603 loss_ctc 48.756866 loss_ctc_origin 35.691006 loss_ctc0 79.243881 lr 0.00059289 rank 0
2022-08-26 09:41:10,079 WARNING NaN or Inf found in input tensor.
2022-08-26 09:41:28,863 DEBUG TRAIN Batch 200/400 loss 20.788296 loss_att 8.270298 loss_ctc 49.996956 loss_ctc_origin 33.142200 loss_ctc0 89.324715 lr 0.00059287 rank 0
2022-08-26 09:41:57,575 DEBUG TRAIN Batch 200/500 loss 45.887512 loss_att 30.481197 loss_ctc 81.835587 loss_ctc_origin 58.765060 loss_ctc0 135.666809 lr 0.00059284 rank 0
2022-08-26 09:42:25,085 DEBUG TRAIN Batch 200/600 loss 56.364174 loss_att 33.564281 loss_ctc 109.563919 loss_ctc_origin 59.275070 loss_ctc0 226.904541 lr 0.00059282 rank 0
2022-08-26 09:42:52,709 DEBUG TRAIN Batch 200/700 loss 22.320633 loss_att 12.139885 loss_ctc 46.075706 loss_ctc_origin 35.633049 loss_ctc0 70.441910 lr 0.00059279 rank 0
2022-08-26 09:43:20,202 DEBUG TRAIN Batch 200/800 loss 18.462769 loss_att 7.739310 loss_ctc 43.484169 loss_ctc_origin 28.525608 loss_ctc0 78.387482 lr 0.00059276 rank 0
2022-08-26 09:43:48,212 DEBUG TRAIN Batch 200/900 loss 20.363028 loss_att 7.965661 loss_ctc 49.290215 loss_ctc_origin 29.871189 loss_ctc0 94.601280 lr 0.00059274 rank 0
2022-08-26 09:44:16,744 DEBUG TRAIN Batch 200/1000 loss 44.754520 loss_att 32.003342 loss_ctc 74.507271 loss_ctc_origin 47.752228 loss_ctc0 136.935699 lr 0.00059271 rank 0
2022-08-26 09:44:29,625 WARNING NaN or Inf found in input tensor.
2022-08-26 09:44:43,576 DEBUG TRAIN Batch 200/1100 loss 59.004284 loss_att 35.970367 loss_ctc 112.750092 loss_ctc_origin 72.950531 loss_ctc0 205.615738 lr 0.00059269 rank 0
2022-08-26 09:45:11,843 DEBUG TRAIN Batch 200/1200 loss 19.829868 loss_att 10.304726 loss_ctc 42.055199 loss_ctc_origin 31.157059 loss_ctc0 67.484192 lr 0.00059266 rank 0
2022-08-26 09:45:39,670 DEBUG TRAIN Batch 200/1300 loss 20.154232 loss_att 8.513658 loss_ctc 47.315571 loss_ctc_origin 32.604805 loss_ctc0 81.640694 lr 0.00059263 rank 0
2022-08-26 09:46:07,186 DEBUG TRAIN Batch 200/1400 loss 19.398224 loss_att 7.860439 loss_ctc 46.319725 loss_ctc_origin 27.341457 loss_ctc0 90.602348 lr 0.00059261 rank 0
2022-08-26 09:46:39,911 DEBUG TRAIN Batch 200/1500 loss 36.143463 loss_att 21.959450 loss_ctc 69.239494 loss_ctc_origin 41.428841 loss_ctc0 134.131012 lr 0.00059258 rank 0
2022-08-26 09:46:55,584 WARNING NaN or Inf found in input tensor.
2022-08-26 09:47:07,756 DEBUG TRAIN Batch 200/1600 loss 57.997078 loss_att 35.199211 loss_ctc 111.192093 loss_ctc_origin 69.331558 loss_ctc0 208.866669 lr 0.00059256 rank 0
2022-08-26 09:47:34,850 DEBUG TRAIN Batch 200/1700 loss 16.973650 loss_att 8.196208 loss_ctc 37.454346 loss_ctc_origin 26.256733 loss_ctc0 63.582108 lr 0.00059253 rank 0
2022-08-26 09:48:01,669 DEBUG TRAIN Batch 200/1800 loss 15.311056 loss_att 6.344212 loss_ctc 36.233692 loss_ctc_origin 22.545353 loss_ctc0 68.173149 lr 0.00059250 rank 0
2022-08-26 09:48:04,575 WARNING NaN or Inf found in input tensor.
2022-08-26 09:48:29,042 DEBUG TRAIN Batch 200/1900 loss 20.840733 loss_att 8.124447 loss_ctc 50.512062 loss_ctc_origin 29.737667 loss_ctc0 98.985649 lr 0.00059248 rank 0
2022-08-26 09:48:58,043 DEBUG TRAIN Batch 200/2000 loss 43.894485 loss_att 26.984737 loss_ctc 83.350555 loss_ctc_origin 53.494381 loss_ctc0 153.014938 lr 0.00059245 rank 0
2022-08-26 09:49:24,842 DEBUG TRAIN Batch 200/2100 loss 60.018578 loss_att 36.965492 loss_ctc 113.809113 loss_ctc_origin 68.958725 loss_ctc0 218.460022 lr 0.00059243 rank 0
2022-08-26 09:49:52,150 DEBUG TRAIN Batch 200/2200 loss 16.567778 loss_att 8.679970 loss_ctc 34.972664 loss_ctc_origin 22.791733 loss_ctc0 63.394833 lr 0.00059240 rank 0
2022-08-26 09:50:19,833 DEBUG TRAIN Batch 200/2300 loss 22.157475 loss_att 9.288856 loss_ctc 52.184250 loss_ctc_origin 39.507847 loss_ctc0 81.762512 lr 0.00059237 rank 0
2022-08-26 09:50:48,193 DEBUG TRAIN Batch 200/2400 loss 21.439915 loss_att 8.775192 loss_ctc 50.990936 loss_ctc_origin 32.759621 loss_ctc0 93.530670 lr 0.00059235 rank 0
2022-08-26 09:51:15,302 DEBUG TRAIN Batch 200/2500 loss 51.020805 loss_att 36.268631 loss_ctc 85.442551 loss_ctc_origin 58.652580 loss_ctc0 147.952484 lr 0.00059232 rank 0
2022-08-26 09:51:42,410 DEBUG TRAIN Batch 200/2600 loss 59.640129 loss_att 32.409061 loss_ctc 123.179291 loss_ctc_origin 79.961639 loss_ctc0 224.020477 lr 0.00059230 rank 0
2022-08-26 09:52:09,966 DEBUG TRAIN Batch 200/2700 loss 14.168328 loss_att 7.189900 loss_ctc 30.451324 loss_ctc_origin 17.452236 loss_ctc0 60.782532 lr 0.00059227 rank 0
2022-08-26 09:52:37,435 DEBUG TRAIN Batch 200/2800 loss 18.752953 loss_att 7.198012 loss_ctc 45.714478 loss_ctc_origin 31.481482 loss_ctc0 78.924805 lr 0.00059224 rank 0
2022-08-26 09:53:04,286 DEBUG TRAIN Batch 200/2900 loss 22.905739 loss_att 8.585544 loss_ctc 56.319527 loss_ctc_origin 39.280151 loss_ctc0 96.078072 lr 0.00059222 rank 0
2022-08-26 09:53:37,709 DEBUG TRAIN Batch 200/3000 loss 46.357162 loss_att 30.483566 loss_ctc 83.395554 loss_ctc_origin 52.818649 loss_ctc0 154.741669 lr 0.00059219 rank 0
2022-08-26 09:53:45,752 WARNING NaN or Inf found in input tensor.
2022-08-26 09:54:05,226 WARNING NaN or Inf found in input tensor.
2022-08-26 09:54:05,283 DEBUG TRAIN Batch 200/3100 loss nan loss_att 32.703850 loss_ctc nan loss_ctc_origin 66.736771 loss_ctc0 nan lr 0.00059217 rank 0
2022-08-26 09:54:30,491 WARNING NaN or Inf found in input tensor.
2022-08-26 09:54:32,261 DEBUG TRAIN Batch 200/3200 loss 16.296978 loss_att 7.663950 loss_ctc 36.440704 loss_ctc_origin 23.034565 loss_ctc0 67.721695 lr 0.00059214 rank 0
2022-08-26 09:55:00,126 DEBUG TRAIN Batch 200/3300 loss 16.365889 loss_att 6.588006 loss_ctc 39.180946 loss_ctc_origin 24.866159 loss_ctc0 72.582115 lr 0.00059211 rank 0
2022-08-26 09:55:28,126 DEBUG TRAIN Batch 200/3400 loss 19.457443 loss_att 7.686525 loss_ctc 46.922913 loss_ctc_origin 25.823605 loss_ctc0 96.154633 lr 0.00059209 rank 0
2022-08-26 09:55:57,340 DEBUG TRAIN Batch 200/3500 loss 41.644608 loss_att 26.194996 loss_ctc 77.693710 loss_ctc_origin 47.384331 loss_ctc0 148.415604 lr 0.00059206 rank 0
2022-08-26 09:56:18,123 WARNING NaN or Inf found in input tensor.
2022-08-26 09:56:25,186 DEBUG TRAIN Batch 200/3600 loss 59.162445 loss_att 36.462524 loss_ctc 112.128922 loss_ctc_origin 63.543938 loss_ctc0 225.493866 lr 0.00059204 rank 0
2022-08-26 09:56:52,653 DEBUG TRAIN Batch 200/3700 loss 17.565546 loss_att 9.066421 loss_ctc 37.396835 loss_ctc_origin 27.244392 loss_ctc0 61.085865 lr 0.00059201 rank 0
2022-08-26 09:57:20,857 DEBUG TRAIN Batch 200/3800 loss 17.436733 loss_att 7.212735 loss_ctc 41.292728 loss_ctc_origin 25.563702 loss_ctc0 77.993790 lr 0.00059198 rank 0
2022-08-26 09:57:47,356 DEBUG TRAIN Batch 200/3900 loss 25.887474 loss_att 10.560444 loss_ctc 61.650543 loss_ctc_origin 43.373665 loss_ctc0 104.296593 lr 0.00059196 rank 0
2022-08-26 09:58:15,809 DEBUG TRAIN Batch 200/4000 loss 44.252361 loss_att 28.738544 loss_ctc 80.451263 loss_ctc_origin 53.660103 loss_ctc0 142.963959 lr 0.00059193 rank 0
2022-08-26 09:58:16,485 WARNING NaN or Inf found in input tensor.
2022-08-26 09:58:43,452 DEBUG TRAIN Batch 200/4100 loss 57.756989 loss_att 33.811775 loss_ctc 113.629150 loss_ctc_origin 70.643768 loss_ctc0 213.928375 lr 0.00059191 rank 0
2022-08-26 09:59:11,289 DEBUG TRAIN Batch 200/4200 loss 17.827068 loss_att 9.073750 loss_ctc 38.251480 loss_ctc_origin 27.572906 loss_ctc0 63.168156 lr 0.00059188 rank 0
2022-08-26 09:59:37,153 DEBUG TRAIN Batch 200/4300 loss 17.138861 loss_att 6.614304 loss_ctc 41.696159 loss_ctc_origin 26.863152 loss_ctc0 76.306503 lr 0.00059185 rank 0
2022-08-26 10:00:06,150 DEBUG TRAIN Batch 200/4400 loss 22.847801 loss_att 9.941673 loss_ctc 52.962093 loss_ctc_origin 33.236652 loss_ctc0 98.988121 lr 0.00059183 rank 0
2022-08-26 10:00:39,261 DEBUG TRAIN Batch 200/4500 loss 48.281975 loss_att 33.870140 loss_ctc 81.909584 loss_ctc_origin 55.863480 loss_ctc0 142.683823 lr 0.00059180 rank 0
2022-08-26 10:01:07,023 DEBUG TRAIN Batch 200/4600 loss 58.772736 loss_att 34.063103 loss_ctc 116.428551 loss_ctc_origin 71.379387 loss_ctc0 221.543274 lr 0.00059178 rank 0
2022-08-26 10:01:34,498 DEBUG TRAIN Batch 200/4700 loss 17.510529 loss_att 9.274397 loss_ctc 36.728172 loss_ctc_origin 25.064999 loss_ctc0 63.942242 lr 0.00059175 rank 0
2022-08-26 10:02:02,246 DEBUG TRAIN Batch 200/4800 loss 15.283988 loss_att 5.551223 loss_ctc 37.993774 loss_ctc_origin 22.468929 loss_ctc0 74.218414 lr 0.00059173 rank 0
2022-08-26 10:02:30,170 DEBUG TRAIN Batch 200/4900 loss 21.678669 loss_att 9.491360 loss_ctc 50.115723 loss_ctc_origin 32.581985 loss_ctc0 91.027771 lr 0.00059170 rank 0
2022-08-26 10:02:58,594 DEBUG TRAIN Batch 200/5000 loss 50.741558 loss_att 36.161781 loss_ctc 84.761040 loss_ctc_origin 54.139614 loss_ctc0 156.211029 lr 0.00059167 rank 0
2022-08-26 10:03:25,668 DEBUG TRAIN Batch 200/5100 loss 55.631577 loss_att 29.809658 loss_ctc 115.882721 loss_ctc_origin 70.184410 loss_ctc0 222.512085 lr 0.00059165 rank 0
2022-08-26 10:03:52,609 DEBUG TRAIN Batch 200/5200 loss 17.258804 loss_att 8.753086 loss_ctc 37.105476 loss_ctc_origin 25.169483 loss_ctc0 64.956131 lr 0.00059162 rank 0
2022-08-26 10:04:11,453 WARNING NaN or Inf found in input tensor.
2022-08-26 10:04:21,609 DEBUG TRAIN Batch 200/5300 loss 20.753540 loss_att 8.140792 loss_ctc 50.183289 loss_ctc_origin 34.748566 loss_ctc0 86.197632 lr 0.00059160 rank 0
2022-08-26 10:04:48,835 DEBUG TRAIN Batch 200/5400 loss 20.398209 loss_att 9.661230 loss_ctc 45.451160 loss_ctc_origin 28.541233 loss_ctc0 84.907654 lr 0.00059157 rank 0
2022-08-26 10:05:17,606 DEBUG TRAIN Batch 200/5500 loss 46.821945 loss_att 30.836138 loss_ctc 84.122154 loss_ctc_origin 58.903072 loss_ctc0 142.966675 lr 0.00059154 rank 0
2022-08-26 10:05:44,756 DEBUG TRAIN Batch 200/5600 loss 55.952499 loss_att 32.357670 loss_ctc 111.007103 loss_ctc_origin 68.758499 loss_ctc0 209.587173 lr 0.00059152 rank 0
2022-08-26 10:06:07,699 DEBUG CV Batch 200/0 loss 11.606168 loss_att 8.375077 loss_ctc 19.145378 loss_ctc_origin 12.725300 loss_ctc0 34.125561 history loss 10.923452 rank 0
2022-08-26 10:06:18,020 DEBUG CV Batch 200/100 loss 20.485868 loss_att 16.384651 loss_ctc 30.055374 loss_ctc_origin 20.023987 loss_ctc0 53.461941 history loss 25.954449 rank 0
2022-08-26 10:06:27,417 DEBUG CV Batch 200/200 loss 24.043980 loss_att 18.474472 loss_ctc 37.039497 loss_ctc_origin 26.178310 loss_ctc0 62.382256 history loss 27.272447 rank 0
2022-08-26 10:06:37,270 DEBUG CV Batch 200/300 loss 22.416122 loss_att 16.901997 loss_ctc 35.282417 loss_ctc_origin 19.481525 loss_ctc0 72.151169 history loss 26.422515 rank 0
2022-08-26 10:06:47,228 DEBUG CV Batch 200/400 loss 36.862888 loss_att 29.572905 loss_ctc 53.872849 loss_ctc_origin 36.156849 loss_ctc0 95.210182 history loss 24.785985 rank 0
2022-08-26 10:06:57,709 DEBUG CV Batch 200/500 loss 16.621887 loss_att 12.415623 loss_ctc 26.436501 loss_ctc_origin 19.687054 loss_ctc0 42.185211 history loss 24.468516 rank 0
2022-08-26 10:07:07,971 DEBUG CV Batch 200/600 loss 17.420486 loss_att 12.248863 loss_ctc 29.487606 loss_ctc_origin 19.203165 loss_ctc0 53.484634 history loss 24.314073 rank 0
2022-08-26 10:07:17,934 DEBUG CV Batch 200/700 loss 18.145531 loss_att 12.752308 loss_ctc 30.729717 loss_ctc_origin 16.860697 loss_ctc0 63.090767 history loss 23.987737 rank 0
2022-08-26 10:07:28,436 DEBUG CV Batch 200/800 loss 21.341328 loss_att 16.751877 loss_ctc 32.050049 loss_ctc_origin 16.559227 loss_ctc0 68.195297 history loss 23.959984 rank 0
2022-08-26 10:07:38,337 INFO Epoch 200 CV info cv_loss 24.039359459018662
2022-08-26 10:07:38,338 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/200.pt
2022-08-26 10:07:38,816 INFO Epoch 201 TRAIN info lr 0.0005914964917278911
2022-08-26 10:07:38,819 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 10:08:05,166 DEBUG TRAIN Batch 201/0 loss 47.171394 loss_att 32.405903 loss_ctc 81.624199 loss_ctc_origin 56.700935 loss_ctc0 139.778473 lr 0.00059150 rank 0
2022-08-26 10:08:19,823 WARNING NaN or Inf found in input tensor.
2022-08-26 10:08:33,672 DEBUG TRAIN Batch 201/100 loss 56.326527 loss_att 30.575165 loss_ctc 116.413040 loss_ctc_origin 69.348083 loss_ctc0 226.231262 lr 0.00059147 rank 0
2022-08-26 10:08:59,472 DEBUG TRAIN Batch 201/200 loss 18.877056 loss_att 11.372622 loss_ctc 36.387405 loss_ctc_origin 25.174435 loss_ctc0 62.551003 lr 0.00059144 rank 0
2022-08-26 10:09:25,532 DEBUG TRAIN Batch 201/300 loss 15.977478 loss_att 6.384340 loss_ctc 38.361465 loss_ctc_origin 23.262455 loss_ctc0 73.592484 lr 0.00059142 rank 0
2022-08-26 10:09:54,031 DEBUG TRAIN Batch 201/400 loss 19.818245 loss_att 7.831209 loss_ctc 47.787991 loss_ctc_origin 32.240288 loss_ctc0 84.065964 lr 0.00059139 rank 0
2022-08-26 10:10:21,927 DEBUG TRAIN Batch 201/500 loss 50.086609 loss_att 34.562946 loss_ctc 86.308487 loss_ctc_origin 62.067520 loss_ctc0 142.870728 lr 0.00059137 rank 0
2022-08-26 10:10:48,996 DEBUG TRAIN Batch 201/600 loss 59.668819 loss_att 34.561665 loss_ctc 118.252174 loss_ctc_origin 66.896156 loss_ctc0 238.082886 lr 0.00059134 rank 0
2022-08-26 10:11:16,712 DEBUG TRAIN Batch 201/700 loss 15.742691 loss_att 8.089402 loss_ctc 33.600365 loss_ctc_origin 20.882137 loss_ctc0 63.276230 lr 0.00059131 rank 0
2022-08-26 10:11:43,794 DEBUG TRAIN Batch 201/800 loss 19.759077 loss_att 8.004324 loss_ctc 47.186832 loss_ctc_origin 32.777908 loss_ctc0 80.807648 lr 0.00059129 rank 0
2022-08-26 10:12:12,755 DEBUG TRAIN Batch 201/900 loss 20.586651 loss_att 7.990050 loss_ctc 49.978714 loss_ctc_origin 32.574234 loss_ctc0 90.589157 lr 0.00059126 rank 0
2022-08-26 10:12:39,989 DEBUG TRAIN Batch 201/1000 loss 46.360382 loss_att 31.112576 loss_ctc 81.938599 loss_ctc_origin 53.402779 loss_ctc0 148.522186 lr 0.00059124 rank 0
2022-08-26 10:13:08,562 DEBUG TRAIN Batch 201/1100 loss 56.186119 loss_att 32.844257 loss_ctc 110.650467 loss_ctc_origin 66.873352 loss_ctc0 212.797058 lr 0.00059121 rank 0
2022-08-26 10:13:34,882 DEBUG TRAIN Batch 201/1200 loss 16.434809 loss_att 7.855772 loss_ctc 36.452560 loss_ctc_origin 24.556063 loss_ctc0 64.211052 lr 0.00059119 rank 0
2022-08-26 10:14:02,813 DEBUG TRAIN Batch 201/1300 loss 16.423429 loss_att 7.172585 loss_ctc 38.008732 loss_ctc_origin 24.983061 loss_ctc0 68.401962 lr 0.00059116 rank 0
2022-08-26 10:14:26,894 WARNING NaN or Inf found in input tensor.
2022-08-26 10:14:31,256 DEBUG TRAIN Batch 201/1400 loss 20.092167 loss_att 8.075921 loss_ctc 48.130074 loss_ctc_origin 30.515316 loss_ctc0 89.231163 lr 0.00059113 rank 0
2022-08-26 10:15:04,594 DEBUG TRAIN Batch 201/1500 loss 46.429550 loss_att 30.568888 loss_ctc 83.437759 loss_ctc_origin 56.407990 loss_ctc0 146.507233 lr 0.00059111 rank 0
2022-08-26 10:15:32,106 DEBUG TRAIN Batch 201/1600 loss 50.798641 loss_att 26.851971 loss_ctc 106.674202 loss_ctc_origin 64.170929 loss_ctc0 205.848495 lr 0.00059108 rank 0
2022-08-26 10:16:00,048 DEBUG TRAIN Batch 201/1700 loss 15.240501 loss_att 7.153962 loss_ctc 34.109093 loss_ctc_origin 21.863136 loss_ctc0 62.682995 lr 0.00059106 rank 0
2022-08-26 10:16:28,020 DEBUG TRAIN Batch 201/1800 loss 15.948088 loss_att 6.771452 loss_ctc 37.360237 loss_ctc_origin 22.904160 loss_ctc0 71.091080 lr 0.00059103 rank 0
2022-08-26 10:16:56,126 DEBUG TRAIN Batch 201/1900 loss 22.178455 loss_att 9.577474 loss_ctc 51.580746 loss_ctc_origin 34.380928 loss_ctc0 91.713654 lr 0.00059100 rank 0
2022-08-26 10:17:24,657 DEBUG TRAIN Batch 201/2000 loss 49.939350 loss_att 33.398384 loss_ctc 88.534935 loss_ctc_origin 60.716240 loss_ctc0 153.445221 lr 0.00059098 rank 0
2022-08-26 10:17:52,617 DEBUG TRAIN Batch 201/2100 loss 60.539757 loss_att 33.033833 loss_ctc 124.720245 loss_ctc_origin 81.246643 loss_ctc0 226.158630 lr 0.00059095 rank 0
2022-08-26 10:18:18,464 WARNING NaN or Inf found in input tensor.
2022-08-26 10:18:20,046 DEBUG TRAIN Batch 201/2200 loss 17.060360 loss_att 8.282864 loss_ctc 37.541183 loss_ctc_origin 25.316738 loss_ctc0 66.064880 lr 0.00059093 rank 0
2022-08-26 10:18:46,762 DEBUG TRAIN Batch 201/2300 loss 17.878773 loss_att 6.745682 loss_ctc 43.855980 loss_ctc_origin 28.746799 loss_ctc0 79.110725 lr 0.00059090 rank 0
2022-08-26 10:19:16,116 DEBUG TRAIN Batch 201/2400 loss 19.021919 loss_att 7.775073 loss_ctc 45.264557 loss_ctc_origin 26.182850 loss_ctc0 89.788544 lr 0.00059088 rank 0
2022-08-26 10:19:42,439 DEBUG TRAIN Batch 201/2500 loss 46.215240 loss_att 29.373549 loss_ctc 85.512520 loss_ctc_origin 54.334686 loss_ctc0 158.260803 lr 0.00059085 rank 0
2022-08-26 10:20:10,529 DEBUG TRAIN Batch 201/2600 loss 55.080322 loss_att 29.593002 loss_ctc 114.550720 loss_ctc_origin 69.873589 loss_ctc0 218.797333 lr 0.00059082 rank 0
2022-08-26 10:20:36,664 DEBUG TRAIN Batch 201/2700 loss 20.198196 loss_att 10.724219 loss_ctc 42.304138 loss_ctc_origin 30.731245 loss_ctc0 69.307549 lr 0.00059080 rank 0
2022-08-26 10:21:04,696 DEBUG TRAIN Batch 201/2800 loss 18.582821 loss_att 7.172028 loss_ctc 45.208000 loss_ctc_origin 30.344084 loss_ctc0 79.890480 lr 0.00059077 rank 0
2022-08-26 10:21:32,855 DEBUG TRAIN Batch 201/2900 loss 22.274176 loss_att 9.246965 loss_ctc 52.670998 loss_ctc_origin 36.075676 loss_ctc0 91.393410 lr 0.00059075 rank 0
2022-08-26 10:22:06,791 DEBUG TRAIN Batch 201/3000 loss 50.766785 loss_att 34.545631 loss_ctc 88.616135 loss_ctc_origin 59.769646 loss_ctc0 155.924606 lr 0.00059072 rank 0
2022-08-26 10:22:34,847 DEBUG TRAIN Batch 201/3100 loss 56.152863 loss_att 33.395020 loss_ctc 109.254486 loss_ctc_origin 70.987595 loss_ctc0 198.543915 lr 0.00059070 rank 0
2022-08-26 10:23:02,449 DEBUG TRAIN Batch 201/3200 loss 20.793510 loss_att 10.930928 loss_ctc 43.806206 loss_ctc_origin 33.243465 loss_ctc0 68.452606 lr 0.00059067 rank 0
2022-08-26 10:23:29,104 DEBUG TRAIN Batch 201/3300 loss 17.827105 loss_att 7.941453 loss_ctc 40.893623 loss_ctc_origin 25.309153 loss_ctc0 77.257385 lr 0.00059064 rank 0
2022-08-26 10:23:39,900 WARNING NaN or Inf found in input tensor.
2022-08-26 10:23:58,024 DEBUG TRAIN Batch 201/3400 loss 20.556194 loss_att 7.853031 loss_ctc 50.196907 loss_ctc_origin 28.285131 loss_ctc0 101.324387 lr 0.00059062 rank 0
2022-08-26 10:24:26,719 DEBUG TRAIN Batch 201/3500 loss 41.774734 loss_att 26.826504 loss_ctc 76.653938 loss_ctc_origin 52.320030 loss_ctc0 133.433060 lr 0.00059059 rank 0
2022-08-26 10:24:54,292 DEBUG TRAIN Batch 201/3600 loss 57.347576 loss_att 33.707195 loss_ctc 112.508469 loss_ctc_origin 63.217804 loss_ctc0 227.520020 lr 0.00059057 rank 0
2022-08-26 10:25:20,576 DEBUG TRAIN Batch 201/3700 loss 22.001764 loss_att 12.402803 loss_ctc 44.399338 loss_ctc_origin 33.225574 loss_ctc0 70.471458 lr 0.00059054 rank 0
2022-08-26 10:25:26,151 WARNING NaN or Inf found in input tensor.
2022-08-26 10:25:48,213 DEBUG TRAIN Batch 201/3800 loss 15.909562 loss_att 5.938927 loss_ctc 39.174377 loss_ctc_origin 25.322723 loss_ctc0 71.494904 lr 0.00059051 rank 0
2022-08-26 10:26:16,159 DEBUG TRAIN Batch 201/3900 loss 19.570906 loss_att 7.748043 loss_ctc 47.157585 loss_ctc_origin 29.545525 loss_ctc0 88.252380 lr 0.00059049 rank 0
2022-08-26 10:26:43,043 DEBUG TRAIN Batch 201/4000 loss 44.259972 loss_att 28.540884 loss_ctc 80.937836 loss_ctc_origin 56.950726 loss_ctc0 136.907745 lr 0.00059046 rank 0
2022-08-26 10:27:10,994 DEBUG TRAIN Batch 201/4100 loss 55.207237 loss_att 31.721630 loss_ctc 110.006989 loss_ctc_origin 62.434196 loss_ctc0 221.010147 lr 0.00059044 rank 0
2022-08-26 10:27:38,906 DEBUG TRAIN Batch 201/4200 loss 19.406826 loss_att 9.208783 loss_ctc 43.202263 loss_ctc_origin 32.986649 loss_ctc0 67.038696 lr 0.00059041 rank 0
2022-08-26 10:28:08,617 DEBUG TRAIN Batch 201/4300 loss 17.224480 loss_att 6.741966 loss_ctc 41.683678 loss_ctc_origin 25.987183 loss_ctc0 78.308838 lr 0.00059039 rank 0
2022-08-26 10:28:35,987 DEBUG TRAIN Batch 201/4400 loss 17.006773 loss_att 5.598962 loss_ctc 43.624992 loss_ctc_origin 24.415749 loss_ctc0 88.446548 lr 0.00059036 rank 0
2022-08-26 10:29:10,673 DEBUG TRAIN Batch 201/4500 loss 41.333317 loss_att 26.548309 loss_ctc 75.831665 loss_ctc_origin 50.661995 loss_ctc0 134.560883 lr 0.00059033 rank 0
2022-08-26 10:29:39,408 DEBUG TRAIN Batch 201/4600 loss 57.281799 loss_att 32.973152 loss_ctc 114.001984 loss_ctc_origin 67.011299 loss_ctc0 223.646912 lr 0.00059031 rank 0
2022-08-26 10:30:07,665 DEBUG TRAIN Batch 201/4700 loss 18.797880 loss_att 10.525270 loss_ctc 38.100639 loss_ctc_origin 26.415253 loss_ctc0 65.366539 lr 0.00059028 rank 0
2022-08-26 10:30:35,667 DEBUG TRAIN Batch 201/4800 loss 18.812727 loss_att 6.822427 loss_ctc 46.790092 loss_ctc_origin 32.754326 loss_ctc0 79.540207 lr 0.00059026 rank 0
2022-08-26 10:31:03,625 DEBUG TRAIN Batch 201/4900 loss 22.266462 loss_att 8.892714 loss_ctc 53.471874 loss_ctc_origin 35.910004 loss_ctc0 94.449570 lr 0.00059023 rank 0
2022-08-26 10:31:32,020 DEBUG TRAIN Batch 201/5000 loss 46.822300 loss_att 29.867041 loss_ctc 86.384567 loss_ctc_origin 59.478554 loss_ctc0 149.165268 lr 0.00059021 rank 0
2022-08-26 10:31:52,991 WARNING NaN or Inf found in input tensor.
2022-08-26 10:32:00,148 DEBUG TRAIN Batch 201/5100 loss 56.021675 loss_att 31.998327 loss_ctc 112.076141 loss_ctc_origin 67.391525 loss_ctc0 216.340225 lr 0.00059018 rank 0
2022-08-26 10:32:25,651 WARNING NaN or Inf found in input tensor.
2022-08-26 10:32:27,256 DEBUG TRAIN Batch 201/5200 loss 20.501720 loss_att 11.137339 loss_ctc 42.351944 loss_ctc_origin 31.617998 loss_ctc0 67.397812 lr 0.00059015 rank 0
2022-08-26 10:32:55,618 DEBUG TRAIN Batch 201/5300 loss 19.722498 loss_att 8.023794 loss_ctc 47.019470 loss_ctc_origin 32.626888 loss_ctc0 80.602158 lr 0.00059013 rank 0
2022-08-26 10:33:24,789 DEBUG TRAIN Batch 201/5400 loss 20.732878 loss_att 8.275930 loss_ctc 49.799088 loss_ctc_origin 33.672028 loss_ctc0 87.428894 lr 0.00059010 rank 0
2022-08-26 10:33:51,730 DEBUG TRAIN Batch 201/5500 loss 50.425938 loss_att 32.214531 loss_ctc 92.919220 loss_ctc_origin 60.510410 loss_ctc0 168.539749 lr 0.00059008 rank 0
2022-08-26 10:34:11,975 WARNING NaN or Inf found in input tensor.
2022-08-26 10:34:18,963 DEBUG TRAIN Batch 201/5600 loss 63.730827 loss_att 39.266071 loss_ctc 120.815254 loss_ctc_origin 83.272797 loss_ctc0 208.414307 lr 0.00059005 rank 0
2022-08-26 10:34:42,015 DEBUG CV Batch 201/0 loss 12.027927 loss_att 8.918041 loss_ctc 19.284327 loss_ctc_origin 12.899162 loss_ctc0 34.183044 history loss 11.320402 rank 0
2022-08-26 10:34:52,383 DEBUG CV Batch 201/100 loss 20.958500 loss_att 16.854351 loss_ctc 30.534843 loss_ctc_origin 21.054392 loss_ctc0 52.655899 history loss 26.290889 rank 0
2022-08-26 10:35:02,320 DEBUG CV Batch 201/200 loss 24.699867 loss_att 19.021114 loss_ctc 37.950291 loss_ctc_origin 27.427547 loss_ctc0 62.503353 history loss 27.917907 rank 0
2022-08-26 10:35:12,883 DEBUG CV Batch 201/300 loss 22.476660 loss_att 17.261406 loss_ctc 34.645584 loss_ctc_origin 18.694815 loss_ctc0 71.864044 history loss 27.011260 rank 0
2022-08-26 10:35:23,458 DEBUG CV Batch 201/400 loss 37.874771 loss_att 30.187284 loss_ctc 55.812241 loss_ctc_origin 39.355083 loss_ctc0 94.212280 history loss 25.299179 rank 0
2022-08-26 10:35:34,255 DEBUG CV Batch 201/500 loss 16.548809 loss_att 12.129325 loss_ctc 26.860939 loss_ctc_origin 20.260303 loss_ctc0 42.262421 history loss 24.963068 rank 0
2022-08-26 10:35:44,666 DEBUG CV Batch 201/600 loss 18.034000 loss_att 12.843576 loss_ctc 30.144987 loss_ctc_origin 19.803841 loss_ctc0 54.274330 history loss 24.784828 rank 0
2022-08-26 10:35:53,778 DEBUG CV Batch 201/700 loss 19.247581 loss_att 13.687842 loss_ctc 32.220303 loss_ctc_origin 18.907726 loss_ctc0 63.282986 history loss 24.441547 rank 0
2022-08-26 10:36:03,122 DEBUG CV Batch 201/800 loss 22.916954 loss_att 18.160830 loss_ctc 34.014572 loss_ctc_origin 19.435352 loss_ctc0 68.032745 history loss 24.425063 rank 0
2022-08-26 10:36:13,223 INFO Epoch 201 CV info cv_loss 24.514398406153823
2022-08-26 10:36:13,224 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/201.pt
2022-08-26 10:36:13,700 INFO Epoch 202 TRAIN info lr 0.0005900305749965232
2022-08-26 10:36:13,704 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 10:36:39,529 DEBUG TRAIN Batch 202/0 loss 54.217484 loss_att 37.973660 loss_ctc 92.119743 loss_ctc_origin 67.223923 loss_ctc0 150.209991 lr 0.00059003 rank 0
2022-08-26 10:37:07,157 DEBUG TRAIN Batch 202/100 loss 61.546295 loss_att 39.996567 loss_ctc 111.828995 loss_ctc_origin 73.439095 loss_ctc0 201.405411 lr 0.00059000 rank 0
2022-08-26 10:37:34,426 DEBUG TRAIN Batch 202/200 loss 18.295288 loss_att 10.261122 loss_ctc 37.041672 loss_ctc_origin 25.484077 loss_ctc0 64.009384 lr 0.00058998 rank 0
2022-08-26 10:38:01,758 DEBUG TRAIN Batch 202/300 loss 19.823778 loss_att 7.629833 loss_ctc 48.276314 loss_ctc_origin 31.744648 loss_ctc0 86.850197 lr 0.00058995 rank 0
2022-08-26 10:38:30,369 DEBUG TRAIN Batch 202/400 loss 19.634647 loss_att 8.055063 loss_ctc 46.653675 loss_ctc_origin 28.775944 loss_ctc0 88.368378 lr 0.00058993 rank 0
2022-08-26 10:38:57,167 DEBUG TRAIN Batch 202/500 loss 48.633415 loss_att 31.641651 loss_ctc 88.280869 loss_ctc_origin 58.846378 loss_ctc0 156.961334 lr 0.00058990 rank 0
2022-08-26 10:39:23,342 DEBUG TRAIN Batch 202/600 loss 57.352390 loss_att 34.762318 loss_ctc 110.062553 loss_ctc_origin 68.827179 loss_ctc0 206.278427 lr 0.00058988 rank 0
2022-08-26 10:39:50,390 DEBUG TRAIN Batch 202/700 loss 20.477459 loss_att 9.178929 loss_ctc 46.840694 loss_ctc_origin 34.167168 loss_ctc0 76.412254 lr 0.00058985 rank 0
2022-08-26 10:39:55,887 WARNING NaN or Inf found in input tensor.
2022-08-26 10:40:18,469 DEBUG TRAIN Batch 202/800 loss 19.530077 loss_att 7.426972 loss_ctc 47.770653 loss_ctc_origin 33.716301 loss_ctc0 80.564133 lr 0.00058982 rank 0
2022-08-26 10:40:46,521 DEBUG TRAIN Batch 202/900 loss 24.121189 loss_att 9.761921 loss_ctc 57.626148 loss_ctc_origin 41.440910 loss_ctc0 95.391701 lr 0.00058980 rank 0
2022-08-26 10:41:14,290 DEBUG TRAIN Batch 202/1000 loss 47.687164 loss_att 32.050919 loss_ctc 84.171745 loss_ctc_origin 56.883904 loss_ctc0 147.843369 lr 0.00058977 rank 0
2022-08-26 10:41:42,551 DEBUG TRAIN Batch 202/1100 loss 54.469406 loss_att 30.757147 loss_ctc 109.798004 loss_ctc_origin 61.413383 loss_ctc0 222.695465 lr 0.00058975 rank 0
2022-08-26 10:42:08,922 DEBUG TRAIN Batch 202/1200 loss 21.395203 loss_att 9.900676 loss_ctc 48.215767 loss_ctc_origin 37.279198 loss_ctc0 73.734421 lr 0.00058972 rank 0
2022-08-26 10:42:20,024 WARNING NaN or Inf found in input tensor.
2022-08-26 10:42:36,509 DEBUG TRAIN Batch 202/1300 loss 14.717213 loss_att 5.775195 loss_ctc 35.581917 loss_ctc_origin 20.835911 loss_ctc0 69.989258 lr 0.00058970 rank 0
2022-08-26 10:43:07,142 DEBUG TRAIN Batch 202/1400 loss 21.509106 loss_att 8.875883 loss_ctc 50.986626 loss_ctc_origin 33.317993 loss_ctc0 92.213425 lr 0.00058967 rank 0
2022-08-26 10:43:38,406 DEBUG TRAIN Batch 202/1500 loss 51.861858 loss_att 35.461815 loss_ctc 90.128624 loss_ctc_origin 61.722557 loss_ctc0 156.409454 lr 0.00058964 rank 0
2022-08-26 10:43:53,366 WARNING NaN or Inf found in input tensor.
2022-08-26 10:44:06,452 DEBUG TRAIN Batch 202/1600 loss 58.053650 loss_att 32.671417 loss_ctc 117.278854 loss_ctc_origin 65.862122 loss_ctc0 237.251221 lr 0.00058962 rank 0
2022-08-26 10:44:34,223 DEBUG TRAIN Batch 202/1700 loss 20.110687 loss_att 11.550074 loss_ctc 40.085449 loss_ctc_origin 29.790028 loss_ctc0 64.108101 lr 0.00058959 rank 0
2022-08-26 10:45:01,752 DEBUG TRAIN Batch 202/1800 loss 21.916630 loss_att 9.607792 loss_ctc 50.637245 loss_ctc_origin 35.902092 loss_ctc0 85.019272 lr 0.00058957 rank 0
2022-08-26 10:45:25,478 WARNING NaN or Inf found in input tensor.
2022-08-26 10:45:29,987 DEBUG TRAIN Batch 202/1900 loss 25.816622 loss_att 10.712894 loss_ctc 61.058655 loss_ctc_origin 41.398510 loss_ctc0 106.932312 lr 0.00058954 rank 0
2022-08-26 10:45:57,833 DEBUG TRAIN Batch 202/2000 loss 50.875511 loss_att 33.335335 loss_ctc 91.802582 loss_ctc_origin 62.797665 loss_ctc0 159.480713 lr 0.00058952 rank 0
2022-08-26 10:46:24,926 DEBUG TRAIN Batch 202/2100 loss 57.022629 loss_att 32.364094 loss_ctc 114.559204 loss_ctc_origin 66.959869 loss_ctc0 225.624313 lr 0.00058949 rank 0
2022-08-26 10:46:52,690 DEBUG TRAIN Batch 202/2200 loss 17.752167 loss_att 9.035291 loss_ctc 38.091541 loss_ctc_origin 26.805649 loss_ctc0 64.425285 lr 0.00058947 rank 0
2022-08-26 10:47:20,036 DEBUG TRAIN Batch 202/2300 loss 18.488649 loss_att 8.018417 loss_ctc 42.919189 loss_ctc_origin 26.932446 loss_ctc0 80.221596 lr 0.00058944 rank 0
2022-08-26 10:47:47,895 DEBUG TRAIN Batch 202/2400 loss 22.007278 loss_att 8.608480 loss_ctc 53.271141 loss_ctc_origin 35.474396 loss_ctc0 94.796875 lr 0.00058941 rank 0
2022-08-26 10:48:16,523 DEBUG TRAIN Batch 202/2500 loss 43.589638 loss_att 30.344810 loss_ctc 74.494225 loss_ctc_origin 47.259914 loss_ctc0 138.040939 lr 0.00058939 rank 0
2022-08-26 10:48:43,389 DEBUG TRAIN Batch 202/2600 loss 53.336281 loss_att 30.360630 loss_ctc 106.946121 loss_ctc_origin 55.231590 loss_ctc0 227.613342 lr 0.00058936 rank 0
2022-08-26 10:49:10,524 DEBUG TRAIN Batch 202/2700 loss 15.930087 loss_att 6.972028 loss_ctc 36.832222 loss_ctc_origin 24.023064 loss_ctc0 66.720253 lr 0.00058934 rank 0
2022-08-26 10:49:37,818 DEBUG TRAIN Batch 202/2800 loss 21.499714 loss_att 8.708906 loss_ctc 51.344929 loss_ctc_origin 34.788963 loss_ctc0 89.975510 lr 0.00058931 rank 0
2022-08-26 10:50:04,958 DEBUG TRAIN Batch 202/2900 loss 22.479319 loss_att 9.623386 loss_ctc 52.476490 loss_ctc_origin 36.127266 loss_ctc0 90.624680 lr 0.00058929 rank 0
2022-08-26 10:50:39,589 DEBUG TRAIN Batch 202/3000 loss 51.707787 loss_att 37.490894 loss_ctc 84.880531 loss_ctc_origin 58.607704 loss_ctc0 146.183792 lr 0.00058926 rank 0
2022-08-26 10:51:07,895 DEBUG TRAIN Batch 202/3100 loss 53.825798 loss_att 30.877483 loss_ctc 107.371857 loss_ctc_origin 63.544075 loss_ctc0 209.636688 lr 0.00058924 rank 0
2022-08-26 10:51:36,235 DEBUG TRAIN Batch 202/3200 loss 22.057274 loss_att 12.352018 loss_ctc 44.702866 loss_ctc_origin 34.745346 loss_ctc0 67.937088 lr 0.00058921 rank 0
2022-08-26 10:52:02,130 DEBUG TRAIN Batch 202/3300 loss 20.005997 loss_att 7.272323 loss_ctc 49.717903 loss_ctc_origin 34.045715 loss_ctc0 86.286331 lr 0.00058918 rank 0
2022-08-26 10:52:30,395 DEBUG TRAIN Batch 202/3400 loss 20.187710 loss_att 8.787462 loss_ctc 46.788284 loss_ctc_origin 29.271027 loss_ctc0 87.661880 lr 0.00058916 rank 0
2022-08-26 10:52:58,353 DEBUG TRAIN Batch 202/3500 loss 45.515579 loss_att 30.026850 loss_ctc 81.655945 loss_ctc_origin 46.574295 loss_ctc0 163.513138 lr 0.00058913 rank 0
2022-08-26 10:53:26,403 DEBUG TRAIN Batch 202/3600 loss 48.584225 loss_att 24.624599 loss_ctc 104.490013 loss_ctc_origin 55.484917 loss_ctc0 218.835236 lr 0.00058911 rank 0
2022-08-26 10:53:54,543 DEBUG TRAIN Batch 202/3700 loss 18.473700 loss_att 9.020370 loss_ctc 40.531464 loss_ctc_origin 27.539009 loss_ctc0 70.847198 lr 0.00058908 rank 0
2022-08-26 10:54:21,529 DEBUG TRAIN Batch 202/3800 loss 19.315603 loss_att 6.926604 loss_ctc 48.223267 loss_ctc_origin 33.735008 loss_ctc0 82.029190 lr 0.00058906 rank 0
2022-08-26 10:54:49,726 DEBUG TRAIN Batch 202/3900 loss 18.392445 loss_att 7.322027 loss_ctc 44.223419 loss_ctc_origin 26.316662 loss_ctc0 86.005844 lr 0.00058903 rank 0
2022-08-26 10:55:17,833 DEBUG TRAIN Batch 202/4000 loss 50.066185 loss_att 33.436436 loss_ctc 88.868935 loss_ctc_origin 54.608547 loss_ctc0 168.809830 lr 0.00058901 rank 0
2022-08-26 10:55:44,931 DEBUG TRAIN Batch 202/4100 loss 53.112141 loss_att 29.586584 loss_ctc 108.005096 loss_ctc_origin 62.748482 loss_ctc0 213.603851 lr 0.00058898 rank 0
2022-08-26 10:56:12,201 DEBUG TRAIN Batch 202/4200 loss 22.404768 loss_att 13.020504 loss_ctc 44.301384 loss_ctc_origin 34.347031 loss_ctc0 67.528206 lr 0.00058895 rank 0
2022-08-26 10:56:41,424 DEBUG TRAIN Batch 202/4300 loss 19.809191 loss_att 8.506888 loss_ctc 46.181229 loss_ctc_origin 30.904722 loss_ctc0 81.826408 lr 0.00058893 rank 0
2022-08-26 10:57:08,906 DEBUG TRAIN Batch 202/4400 loss 20.072090 loss_att 7.658330 loss_ctc 49.037529 loss_ctc_origin 29.600258 loss_ctc0 94.391159 lr 0.00058890 rank 0
2022-08-26 10:57:42,682 DEBUG TRAIN Batch 202/4500 loss 38.457520 loss_att 26.395874 loss_ctc 66.601349 loss_ctc_origin 43.089516 loss_ctc0 121.462288 lr 0.00058888 rank 0
2022-08-26 10:58:11,003 DEBUG TRAIN Batch 202/4600 loss 48.126835 loss_att 23.849228 loss_ctc 104.774582 loss_ctc_origin 50.691422 loss_ctc0 230.968628 lr 0.00058885 rank 0
2022-08-26 10:58:39,261 DEBUG TRAIN Batch 202/4700 loss 18.030293 loss_att 7.789382 loss_ctc 41.925751 loss_ctc_origin 29.934334 loss_ctc0 69.905724 lr 0.00058883 rank 0
2022-08-26 10:59:07,068 DEBUG TRAIN Batch 202/4800 loss 17.874630 loss_att 7.112663 loss_ctc 42.985886 loss_ctc_origin 28.518620 loss_ctc0 76.742844 lr 0.00058880 rank 0
2022-08-26 10:59:35,681 DEBUG TRAIN Batch 202/4900 loss 17.262924 loss_att 6.899349 loss_ctc 41.444599 loss_ctc_origin 24.813433 loss_ctc0 80.250656 lr 0.00058878 rank 0
2022-08-26 11:00:04,178 DEBUG TRAIN Batch 202/5000 loss 36.227909 loss_att 20.973539 loss_ctc 71.821434 loss_ctc_origin 40.803806 loss_ctc0 144.195892 lr 0.00058875 rank 0
2022-08-26 11:00:31,348 DEBUG TRAIN Batch 202/5100 loss 55.007839 loss_att 30.451572 loss_ctc 112.305786 loss_ctc_origin 63.105354 loss_ctc0 227.106766 lr 0.00058872 rank 0
2022-08-26 11:00:59,177 DEBUG TRAIN Batch 202/5200 loss 21.948092 loss_att 14.173473 loss_ctc 40.088863 loss_ctc_origin 29.495731 loss_ctc0 64.806175 lr 0.00058870 rank 0
2022-08-26 11:01:27,306 DEBUG TRAIN Batch 202/5300 loss 18.445221 loss_att 8.161072 loss_ctc 42.441566 loss_ctc_origin 27.697514 loss_ctc0 76.844360 lr 0.00058867 rank 0
2022-08-26 11:01:51,257 WARNING NaN or Inf found in input tensor.
2022-08-26 11:01:55,653 DEBUG TRAIN Batch 202/5400 loss 21.711922 loss_att 8.432314 loss_ctc 52.697670 loss_ctc_origin 35.952236 loss_ctc0 91.770340 lr 0.00058865 rank 0
2022-08-26 11:02:23,498 DEBUG TRAIN Batch 202/5500 loss 64.194328 loss_att 45.295311 loss_ctc 108.292038 loss_ctc_origin 80.411209 loss_ctc0 173.347290 lr 0.00058862 rank 0
2022-08-26 11:02:24,133 WARNING NaN or Inf found in input tensor.
2022-08-26 11:02:50,741 DEBUG TRAIN Batch 202/5600 loss 56.343376 loss_att 30.883804 loss_ctc 115.749054 loss_ctc_origin 69.109314 loss_ctc0 224.575119 lr 0.00058860 rank 0
2022-08-26 11:03:12,410 DEBUG CV Batch 202/0 loss 11.906293 loss_att 8.953351 loss_ctc 18.796492 loss_ctc_origin 12.294363 loss_ctc0 33.968124 history loss 11.205923 rank 0
2022-08-26 11:03:22,895 DEBUG CV Batch 202/100 loss 20.398935 loss_att 16.312195 loss_ctc 29.934664 loss_ctc_origin 20.381973 loss_ctc0 52.224274 history loss 26.551486 rank 0
2022-08-26 11:03:32,814 DEBUG CV Batch 202/200 loss 23.470779 loss_att 18.030151 loss_ctc 36.165581 loss_ctc_origin 25.230846 loss_ctc0 61.679962 history loss 27.704153 rank 0
2022-08-26 11:03:42,084 DEBUG CV Batch 202/300 loss 22.637596 loss_att 17.175266 loss_ctc 35.383034 loss_ctc_origin 19.304291 loss_ctc0 72.900101 history loss 26.775449 rank 0
2022-08-26 11:03:51,711 DEBUG CV Batch 202/400 loss 37.175323 loss_att 29.509453 loss_ctc 55.062347 loss_ctc_origin 37.919670 loss_ctc0 95.061920 history loss 25.098425 rank 0
2022-08-26 11:04:01,875 DEBUG CV Batch 202/500 loss 16.337870 loss_att 11.930268 loss_ctc 26.622272 loss_ctc_origin 19.804058 loss_ctc0 42.531441 history loss 24.743085 rank 0
2022-08-26 11:04:11,881 DEBUG CV Batch 202/600 loss 17.490927 loss_att 12.449188 loss_ctc 29.254982 loss_ctc_origin 18.857807 loss_ctc0 53.515053 history loss 24.564524 rank 0
2022-08-26 11:04:21,294 DEBUG CV Batch 202/700 loss 18.026480 loss_att 12.755169 loss_ctc 30.326202 loss_ctc_origin 16.598576 loss_ctc0 62.357327 history loss 24.217139 rank 0
2022-08-26 11:04:30,734 DEBUG CV Batch 202/800 loss 22.910828 loss_att 18.281771 loss_ctc 33.711964 loss_ctc_origin 18.933611 loss_ctc0 68.194778 history loss 24.198293 rank 0
2022-08-26 11:04:40,054 INFO Epoch 202 CV info cv_loss 24.29042969580729
2022-08-26 11:04:40,054 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/202.pt
2022-08-26 11:04:40,546 INFO Epoch 203 TRAIN info lr 0.0005885755035459927
2022-08-26 11:04:40,550 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 11:05:05,921 DEBUG TRAIN Batch 203/0 loss 53.784569 loss_att 33.730339 loss_ctc 100.577774 loss_ctc_origin 68.264130 loss_ctc0 175.976257 lr 0.00058857 rank 0
2022-08-26 11:05:34,146 DEBUG TRAIN Batch 203/100 loss 71.192635 loss_att 43.392937 loss_ctc 136.058594 loss_ctc_origin 84.474884 loss_ctc0 256.420563 lr 0.00058855 rank 0
2022-08-26 11:06:02,429 DEBUG TRAIN Batch 203/200 loss 19.614859 loss_att 10.433405 loss_ctc 41.038246 loss_ctc_origin 30.572071 loss_ctc0 65.459312 lr 0.00058852 rank 0
2022-08-26 11:06:29,548 DEBUG TRAIN Batch 203/300 loss 18.145100 loss_att 6.924521 loss_ctc 44.326443 loss_ctc_origin 27.168507 loss_ctc0 84.361626 lr 0.00058850 rank 0
2022-08-26 11:06:57,316 DEBUG TRAIN Batch 203/400 loss 21.212416 loss_att 8.197007 loss_ctc 51.581703 loss_ctc_origin 32.287941 loss_ctc0 96.600479 lr 0.00058847 rank 0
2022-08-26 11:06:59,866 WARNING NaN or Inf found in input tensor.
2022-08-26 11:07:25,260 DEBUG TRAIN Batch 203/500 loss 52.815086 loss_att 34.755821 loss_ctc 94.953369 loss_ctc_origin 57.970886 loss_ctc0 181.245804 lr 0.00058845 rank 0
2022-08-26 11:07:52,147 DEBUG TRAIN Batch 203/600 loss 66.865738 loss_att 41.174110 loss_ctc 126.812866 loss_ctc_origin 75.759064 loss_ctc0 245.938416 lr 0.00058842 rank 0
2022-08-26 11:08:18,315 WARNING NaN or Inf found in input tensor.
2022-08-26 11:08:19,821 DEBUG TRAIN Batch 203/700 loss 20.873886 loss_att 11.687291 loss_ctc 42.309277 loss_ctc_origin 30.800625 loss_ctc0 69.162796 lr 0.00058840 rank 0
2022-08-26 11:08:48,073 DEBUG TRAIN Batch 203/800 loss 18.115421 loss_att 7.546944 loss_ctc 42.775200 loss_ctc_origin 27.875050 loss_ctc0 77.542206 lr 0.00058837 rank 0
2022-08-26 11:09:15,517 DEBUG TRAIN Batch 203/900 loss 18.954935 loss_att 7.258368 loss_ctc 46.246925 loss_ctc_origin 29.303732 loss_ctc0 85.781036 lr 0.00058835 rank 0
2022-08-26 11:09:43,783 DEBUG TRAIN Batch 203/1000 loss 49.493973 loss_att 35.706379 loss_ctc 81.665031 loss_ctc_origin 51.328007 loss_ctc0 152.451416 lr 0.00058832 rank 0
2022-08-26 11:10:12,097 DEBUG TRAIN Batch 203/1100 loss 60.231056 loss_att 34.583191 loss_ctc 120.076073 loss_ctc_origin 66.678589 loss_ctc0 244.670197 lr 0.00058829 rank 0
2022-08-26 11:10:41,689 DEBUG TRAIN Batch 203/1200 loss 21.585318 loss_att 11.856375 loss_ctc 44.286182 loss_ctc_origin 33.860733 loss_ctc0 68.612228 lr 0.00058827 rank 0
2022-08-26 11:11:09,691 DEBUG TRAIN Batch 203/1300 loss 17.913303 loss_att 6.321317 loss_ctc 44.961273 loss_ctc_origin 28.959782 loss_ctc0 82.298080 lr 0.00058824 rank 0
2022-08-26 11:11:38,025 DEBUG TRAIN Batch 203/1400 loss 20.688383 loss_att 8.122087 loss_ctc 50.009743 loss_ctc_origin 29.884838 loss_ctc0 96.967850 lr 0.00058822 rank 0
2022-08-26 11:12:11,583 DEBUG TRAIN Batch 203/1500 loss 48.668831 loss_att 31.633377 loss_ctc 88.418228 loss_ctc_origin 57.191711 loss_ctc0 161.280090 lr 0.00058819 rank 0
2022-08-26 11:12:39,304 DEBUG TRAIN Batch 203/1600 loss 52.380848 loss_att 29.641033 loss_ctc 105.440414 loss_ctc_origin 56.791004 loss_ctc0 218.955688 lr 0.00058817 rank 0
2022-08-26 11:13:07,363 DEBUG TRAIN Batch 203/1700 loss 20.004713 loss_att 10.752388 loss_ctc 41.593472 loss_ctc_origin 30.352253 loss_ctc0 67.822983 lr 0.00058814 rank 0
2022-08-26 11:13:34,748 DEBUG TRAIN Batch 203/1800 loss 16.676584 loss_att 6.625970 loss_ctc 40.128017 loss_ctc_origin 23.710171 loss_ctc0 78.436325 lr 0.00058812 rank 0
2022-08-26 11:14:03,411 DEBUG TRAIN Batch 203/1900 loss 18.529659 loss_att 7.571252 loss_ctc 44.099274 loss_ctc_origin 27.723652 loss_ctc0 82.309067 lr 0.00058809 rank 0
2022-08-26 11:14:31,425 DEBUG TRAIN Batch 203/2000 loss 55.334358 loss_att 36.570637 loss_ctc 99.116364 loss_ctc_origin 66.043243 loss_ctc0 176.286957 lr 0.00058807 rank 0
2022-08-26 11:14:59,129 DEBUG TRAIN Batch 203/2100 loss 63.222595 loss_att 35.636398 loss_ctc 127.590378 loss_ctc_origin 76.920929 loss_ctc0 245.819092 lr 0.00058804 rank 0
2022-08-26 11:15:25,698 DEBUG TRAIN Batch 203/2200 loss 17.894758 loss_att 9.895100 loss_ctc 36.560631 loss_ctc_origin 25.513718 loss_ctc0 62.336769 lr 0.00058801 rank 0
2022-08-26 11:15:53,328 DEBUG TRAIN Batch 203/2300 loss 18.200611 loss_att 7.196296 loss_ctc 43.877350 loss_ctc_origin 28.295956 loss_ctc0 80.233932 lr 0.00058799 rank 0
2022-08-26 11:16:18,037 WARNING NaN or Inf found in input tensor.
2022-08-26 11:16:22,584 DEBUG TRAIN Batch 203/2400 loss 20.535004 loss_att 8.056137 loss_ctc 49.652359 loss_ctc_origin 31.258358 loss_ctc0 92.571686 lr 0.00058796 rank 0
2022-08-26 11:16:48,732 DEBUG TRAIN Batch 203/2500 loss 51.275608 loss_att 33.400478 loss_ctc 92.984238 loss_ctc_origin 57.871147 loss_ctc0 174.914764 lr 0.00058794 rank 0
2022-08-26 11:17:16,309 DEBUG TRAIN Batch 203/2600 loss 62.677502 loss_att 31.377558 loss_ctc 135.710693 loss_ctc_origin 73.231735 loss_ctc0 281.494934 lr 0.00058791 rank 0
2022-08-26 11:17:43,632 DEBUG TRAIN Batch 203/2700 loss 19.079481 loss_att 9.518735 loss_ctc 41.387886 loss_ctc_origin 29.402283 loss_ctc0 69.354286 lr 0.00058789 rank 0
2022-08-26 11:18:11,222 DEBUG TRAIN Batch 203/2800 loss 17.647991 loss_att 7.755362 loss_ctc 40.730797 loss_ctc_origin 27.055447 loss_ctc0 72.639938 lr 0.00058786 rank 0
2022-08-26 11:18:38,535 DEBUG TRAIN Batch 203/2900 loss 19.325085 loss_att 7.065261 loss_ctc 47.931339 loss_ctc_origin 26.833094 loss_ctc0 97.160576 lr 0.00058784 rank 0
2022-08-26 11:19:12,494 DEBUG TRAIN Batch 203/3000 loss 51.702065 loss_att 34.641777 loss_ctc 91.509399 loss_ctc_origin 58.999908 loss_ctc0 167.364868 lr 0.00058781 rank 0
2022-08-26 11:19:41,003 DEBUG TRAIN Batch 203/3100 loss 61.608932 loss_att 33.265999 loss_ctc 127.742439 loss_ctc_origin 67.353210 loss_ctc0 268.650635 lr 0.00058779 rank 0
2022-08-26 11:20:08,724 DEBUG TRAIN Batch 203/3200 loss 17.483997 loss_att 9.368383 loss_ctc 36.420425 loss_ctc_origin 23.245125 loss_ctc0 67.162796 lr 0.00058776 rank 0
2022-08-26 11:20:36,850 DEBUG TRAIN Batch 203/3300 loss 20.408846 loss_att 8.998487 loss_ctc 47.033016 loss_ctc_origin 31.595966 loss_ctc0 83.052795 lr 0.00058774 rank 0
2022-08-26 11:21:04,985 DEBUG TRAIN Batch 203/3400 loss 21.492821 loss_att 8.901355 loss_ctc 50.872902 loss_ctc_origin 32.476349 loss_ctc0 93.798187 lr 0.00058771 rank 0
2022-08-26 11:21:32,628 DEBUG TRAIN Batch 203/3500 loss 53.490166 loss_att 34.176163 loss_ctc 98.556168 loss_ctc_origin 62.301258 loss_ctc0 183.150955 lr 0.00058768 rank 0
2022-08-26 11:21:59,494 DEBUG TRAIN Batch 203/3600 loss 55.403435 loss_att 29.916988 loss_ctc 114.871811 loss_ctc_origin 59.546394 loss_ctc0 243.964417 lr 0.00058766 rank 0
2022-08-26 11:22:27,070 DEBUG TRAIN Batch 203/3700 loss 15.816723 loss_att 7.715204 loss_ctc 34.720264 loss_ctc_origin 20.806881 loss_ctc0 67.184830 lr 0.00058763 rank 0
2022-08-26 11:22:56,112 DEBUG TRAIN Batch 203/3800 loss 25.011316 loss_att 11.838107 loss_ctc 55.748802 loss_ctc_origin 43.920509 loss_ctc0 83.348145 lr 0.00058761 rank 0
2022-08-26 11:23:23,885 DEBUG TRAIN Batch 203/3900 loss 21.942719 loss_att 8.442284 loss_ctc 53.443726 loss_ctc_origin 35.740677 loss_ctc0 94.750839 lr 0.00058758 rank 0
2022-08-26 11:23:50,778 DEBUG TRAIN Batch 203/4000 loss 45.046051 loss_att 29.146164 loss_ctc 82.145790 loss_ctc_origin 50.266048 loss_ctc0 156.531845 lr 0.00058756 rank 0
2022-08-26 11:24:19,894 DEBUG TRAIN Batch 203/4100 loss 58.462097 loss_att 32.193268 loss_ctc 119.756027 loss_ctc_origin 63.288170 loss_ctc0 251.514359 lr 0.00058753 rank 0
2022-08-26 11:24:46,053 DEBUG TRAIN Batch 203/4200 loss 18.476429 loss_att 10.511009 loss_ctc 37.062408 loss_ctc_origin 27.357491 loss_ctc0 59.707211 lr 0.00058751 rank 0
2022-08-26 11:24:58,034 WARNING NaN or Inf found in input tensor.
2022-08-26 11:25:13,885 DEBUG TRAIN Batch 203/4300 loss 20.014240 loss_att 8.022705 loss_ctc 47.994484 loss_ctc_origin 32.894489 loss_ctc0 83.227798 lr 0.00058748 rank 0
2022-08-26 11:25:42,692 DEBUG TRAIN Batch 203/4400 loss 22.092152 loss_att 9.194645 loss_ctc 52.186333 loss_ctc_origin 33.929375 loss_ctc0 94.785889 lr 0.00058746 rank 0
2022-08-26 11:26:15,358 DEBUG TRAIN Batch 203/4500 loss 45.812782 loss_att 31.751652 loss_ctc 78.622086 loss_ctc_origin 49.132401 loss_ctc0 147.431335 lr 0.00058743 rank 0
2022-08-26 11:26:43,340 DEBUG TRAIN Batch 203/4600 loss 65.635582 loss_att 38.712482 loss_ctc 128.456131 loss_ctc_origin 74.939293 loss_ctc0 253.328735 lr 0.00058741 rank 0
2022-08-26 11:27:11,136 DEBUG TRAIN Batch 203/4700 loss 19.599998 loss_att 10.275892 loss_ctc 41.356243 loss_ctc_origin 28.868586 loss_ctc0 70.494110 lr 0.00058738 rank 0
2022-08-26 11:27:37,899 DEBUG TRAIN Batch 203/4800 loss 19.270397 loss_att 7.722127 loss_ctc 46.216354 loss_ctc_origin 30.931314 loss_ctc0 81.881439 lr 0.00058735 rank 0
2022-08-26 11:28:05,861 DEBUG TRAIN Batch 203/4900 loss 22.899313 loss_att 9.903214 loss_ctc 53.223541 loss_ctc_origin 36.503551 loss_ctc0 92.236847 lr 0.00058733 rank 0
2022-08-26 11:28:33,851 DEBUG TRAIN Batch 203/5000 loss 51.493515 loss_att 33.294418 loss_ctc 93.958061 loss_ctc_origin 60.142239 loss_ctc0 172.861633 lr 0.00058730 rank 0
2022-08-26 11:28:53,889 WARNING NaN or Inf found in input tensor.
2022-08-26 11:29:00,613 DEBUG TRAIN Batch 203/5100 loss 61.415737 loss_att 35.254021 loss_ctc 122.459740 loss_ctc_origin 65.951897 loss_ctc0 254.311371 lr 0.00058728 rank 0
2022-08-26 11:29:27,863 DEBUG TRAIN Batch 203/5200 loss 20.283806 loss_att 12.068489 loss_ctc 39.452877 loss_ctc_origin 28.179054 loss_ctc0 65.758461 lr 0.00058725 rank 0
2022-08-26 11:29:55,349 DEBUG TRAIN Batch 203/5300 loss 19.326645 loss_att 7.316081 loss_ctc 47.351292 loss_ctc_origin 33.158611 loss_ctc0 80.467545 lr 0.00058723 rank 0
2022-08-26 11:30:23,176 DEBUG TRAIN Batch 203/5400 loss 18.775497 loss_att 7.015057 loss_ctc 46.216522 loss_ctc_origin 27.590279 loss_ctc0 89.677750 lr 0.00058720 rank 0
2022-08-26 11:30:51,283 DEBUG TRAIN Batch 203/5500 loss 50.820213 loss_att 33.169731 loss_ctc 92.004669 loss_ctc_origin 60.740730 loss_ctc0 164.953857 lr 0.00058718 rank 0
2022-08-26 11:31:18,733 DEBUG TRAIN Batch 203/5600 loss 66.945206 loss_att 40.861309 loss_ctc 127.807617 loss_ctc_origin 78.943176 loss_ctc0 241.824646 lr 0.00058715 rank 0
2022-08-26 11:31:41,131 DEBUG CV Batch 203/0 loss 11.372871 loss_att 8.441286 loss_ctc 18.213238 loss_ctc_origin 11.416602 loss_ctc0 34.072056 history loss 10.703879 rank 0
2022-08-26 11:31:51,911 DEBUG CV Batch 203/100 loss 20.627548 loss_att 16.683901 loss_ctc 29.829391 loss_ctc_origin 20.067669 loss_ctc0 52.606743 history loss 25.977292 rank 0
2022-08-26 11:32:00,993 DEBUG CV Batch 203/200 loss 23.441177 loss_att 18.372269 loss_ctc 35.268631 loss_ctc_origin 23.868008 loss_ctc0 61.870079 history loss 27.294722 rank 0
2022-08-26 11:32:11,071 DEBUG CV Batch 203/300 loss 22.806515 loss_att 17.321701 loss_ctc 35.604412 loss_ctc_origin 19.955147 loss_ctc0 72.119362 history loss 26.439414 rank 0
2022-08-26 11:32:21,270 DEBUG CV Batch 203/400 loss 38.114571 loss_att 30.725506 loss_ctc 55.355713 loss_ctc_origin 38.702106 loss_ctc0 94.214127 history loss 24.832647 rank 0
2022-08-26 11:32:31,628 DEBUG CV Batch 203/500 loss 15.841687 loss_att 11.475168 loss_ctc 26.030231 loss_ctc_origin 19.527683 loss_ctc0 41.202847 history loss 24.523071 rank 0
2022-08-26 11:32:41,730 DEBUG CV Batch 203/600 loss 17.145720 loss_att 12.072201 loss_ctc 28.983929 loss_ctc_origin 18.544432 loss_ctc0 53.342751 history loss 24.392629 rank 0
2022-08-26 11:32:51,673 DEBUG CV Batch 203/700 loss 17.934948 loss_att 12.591119 loss_ctc 30.403885 loss_ctc_origin 16.745899 loss_ctc0 62.272518 history loss 24.054874 rank 0
2022-08-26 11:33:02,725 DEBUG CV Batch 203/800 loss 22.078079 loss_att 17.472960 loss_ctc 32.823360 loss_ctc_origin 17.649673 loss_ctc0 68.228622 history loss 24.025995 rank 0
2022-08-26 11:33:12,561 INFO Epoch 203 CV info cv_loss 24.11632113797205
2022-08-26 11:33:12,561 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/203.pt
2022-08-26 11:33:13,051 INFO Epoch 204 TRAIN info lr 0.0005871311443048985
2022-08-26 11:33:13,054 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 11:33:38,330 DEBUG TRAIN Batch 204/0 loss 45.971184 loss_att 30.784100 loss_ctc 81.407715 loss_ctc_origin 51.101524 loss_ctc0 152.122147 lr 0.00058713 rank 0
2022-08-26 11:34:05,830 DEBUG TRAIN Batch 204/100 loss 62.499863 loss_att 34.919106 loss_ctc 126.854973 loss_ctc_origin 78.256607 loss_ctc0 240.251160 lr 0.00058710 rank 0
2022-08-26 11:34:33,992 DEBUG TRAIN Batch 204/200 loss 18.894342 loss_att 10.165213 loss_ctc 39.262314 loss_ctc_origin 27.655407 loss_ctc0 66.345093 lr 0.00058708 rank 0
2022-08-26 11:35:02,100 DEBUG TRAIN Batch 204/300 loss 20.438650 loss_att 8.093069 loss_ctc 49.245007 loss_ctc_origin 33.129696 loss_ctc0 86.847397 lr 0.00058705 rank 0
2022-08-26 11:35:29,531 DEBUG TRAIN Batch 204/400 loss 15.689341 loss_att 5.708863 loss_ctc 38.977119 loss_ctc_origin 20.592632 loss_ctc0 81.874252 lr 0.00058703 rank 0
2022-08-26 11:35:57,729 DEBUG TRAIN Batch 204/500 loss 49.908833 loss_att 30.856585 loss_ctc 94.364075 loss_ctc_origin 60.715603 loss_ctc0 172.877167 lr 0.00058700 rank 0
2022-08-26 11:36:24,849 DEBUG TRAIN Batch 204/600 loss 63.352394 loss_att 37.014019 loss_ctc 124.808594 loss_ctc_origin 75.224091 loss_ctc0 240.505737 lr 0.00058698 rank 0
2022-08-26 11:36:52,527 DEBUG TRAIN Batch 204/700 loss 20.540134 loss_att 10.948229 loss_ctc 42.921249 loss_ctc_origin 31.591154 loss_ctc0 69.358131 lr 0.00058695 rank 0
2022-08-26 11:37:19,999 DEBUG TRAIN Batch 204/800 loss 15.883765 loss_att 6.307026 loss_ctc 38.229488 loss_ctc_origin 22.447144 loss_ctc0 75.054955 lr 0.00058693 rank 0
2022-08-26 11:37:47,530 DEBUG TRAIN Batch 204/900 loss 20.994415 loss_att 8.177273 loss_ctc 50.901077 loss_ctc_origin 31.968996 loss_ctc0 95.075935 lr 0.00058690 rank 0
2022-08-26 11:38:15,746 DEBUG TRAIN Batch 204/1000 loss 43.674915 loss_att 29.328384 loss_ctc 77.150154 loss_ctc_origin 47.528336 loss_ctc0 146.267731 lr 0.00058688 rank 0
2022-08-26 11:38:43,210 DEBUG TRAIN Batch 204/1100 loss 60.346527 loss_att 34.607605 loss_ctc 120.404007 loss_ctc_origin 71.031097 loss_ctc0 235.607468 lr 0.00058685 rank 0
2022-08-26 11:39:10,718 DEBUG TRAIN Batch 204/1200 loss 22.176228 loss_att 12.816068 loss_ctc 44.016602 loss_ctc_origin 33.874111 loss_ctc0 67.682419 lr 0.00058683 rank 0
2022-08-26 11:39:38,603 DEBUG TRAIN Batch 204/1300 loss 19.627296 loss_att 8.670577 loss_ctc 45.192970 loss_ctc_origin 29.745089 loss_ctc0 81.238029 lr 0.00058680 rank 0
2022-08-26 11:40:06,143 DEBUG TRAIN Batch 204/1400 loss 20.256050 loss_att 8.131785 loss_ctc 48.546001 loss_ctc_origin 28.532257 loss_ctc0 95.244736 lr 0.00058678 rank 0
2022-08-26 11:40:38,436 DEBUG TRAIN Batch 204/1500 loss 49.666046 loss_att 31.300049 loss_ctc 92.520035 loss_ctc_origin 55.446064 loss_ctc0 179.025955 lr 0.00058675 rank 0
2022-08-26 11:41:05,934 DEBUG TRAIN Batch 204/1600 loss 61.577507 loss_att 31.864864 loss_ctc 130.906998 loss_ctc_origin 74.220993 loss_ctc0 263.174316 lr 0.00058673 rank 0
2022-08-26 11:41:32,961 DEBUG TRAIN Batch 204/1700 loss 22.060455 loss_att 12.344900 loss_ctc 44.730087 loss_ctc_origin 34.506287 loss_ctc0 68.585625 lr 0.00058670 rank 0
2022-08-26 11:42:01,085 DEBUG TRAIN Batch 204/1800 loss 18.415836 loss_att 7.123359 loss_ctc 44.764950 loss_ctc_origin 30.944801 loss_ctc0 77.011963 lr 0.00058668 rank 0
2022-08-26 11:42:28,199 DEBUG TRAIN Batch 204/1900 loss 19.003201 loss_att 7.051532 loss_ctc 46.890427 loss_ctc_origin 27.581577 loss_ctc0 91.944405 lr 0.00058665 rank 0
2022-08-26 11:42:56,013 DEBUG TRAIN Batch 204/2000 loss 45.062206 loss_att 28.170752 loss_ctc 84.475594 loss_ctc_origin 53.194984 loss_ctc0 157.463684 lr 0.00058662 rank 0
2022-08-26 11:43:24,387 DEBUG TRAIN Batch 204/2100 loss 61.897804 loss_att 37.196228 loss_ctc 119.534821 loss_ctc_origin 71.526306 loss_ctc0 231.554688 lr 0.00058660 rank 0
2022-08-26 11:43:50,953 DEBUG TRAIN Batch 204/2200 loss 15.976059 loss_att 8.208322 loss_ctc 34.100780 loss_ctc_origin 21.951704 loss_ctc0 62.448627 lr 0.00058657 rank 0
2022-08-26 11:44:18,945 DEBUG TRAIN Batch 204/2300 loss 18.814322 loss_att 7.129535 loss_ctc 46.078819 loss_ctc_origin 30.153992 loss_ctc0 83.236740 lr 0.00058655 rank 0
2022-08-26 11:44:42,835 WARNING NaN or Inf found in input tensor.
2022-08-26 11:44:46,886 DEBUG TRAIN Batch 204/2400 loss 19.867277 loss_att 7.731915 loss_ctc 48.183121 loss_ctc_origin 30.429077 loss_ctc0 89.609222 lr 0.00058652 rank 0
2022-08-26 11:45:14,837 DEBUG TRAIN Batch 204/2500 loss 48.019207 loss_att 30.222157 loss_ctc 89.545654 loss_ctc_origin 53.934345 loss_ctc0 172.638702 lr 0.00058650 rank 0
2022-08-26 11:45:43,913 DEBUG TRAIN Batch 204/2600 loss 59.636040 loss_att 33.953651 loss_ctc 119.561615 loss_ctc_origin 63.527527 loss_ctc0 250.307800 lr 0.00058647 rank 0
2022-08-26 11:46:11,799 DEBUG TRAIN Batch 204/2700 loss 19.771080 loss_att 10.674143 loss_ctc 40.997261 loss_ctc_origin 30.768906 loss_ctc0 64.863419 lr 0.00058645 rank 0
2022-08-26 11:46:38,723 DEBUG TRAIN Batch 204/2800 loss 18.540676 loss_att 7.702065 loss_ctc 43.830765 loss_ctc_origin 30.071360 loss_ctc0 75.936050 lr 0.00058642 rank 0
2022-08-26 11:47:05,624 DEBUG TRAIN Batch 204/2900 loss 20.110590 loss_att 7.439711 loss_ctc 49.675972 loss_ctc_origin 28.754765 loss_ctc0 98.492126 lr 0.00058640 rank 0
2022-08-26 11:47:39,552 DEBUG TRAIN Batch 204/3000 loss 46.204903 loss_att 29.534443 loss_ctc 85.102631 loss_ctc_origin 54.865337 loss_ctc0 155.656326 lr 0.00058637 rank 0
2022-08-26 11:48:07,629 DEBUG TRAIN Batch 204/3100 loss 62.358742 loss_att 36.982407 loss_ctc 121.570190 loss_ctc_origin 72.202408 loss_ctc0 236.761703 lr 0.00058635 rank 0
2022-08-26 11:48:35,034 DEBUG TRAIN Batch 204/3200 loss 18.349297 loss_att 9.654694 loss_ctc 38.636703 loss_ctc_origin 28.756420 loss_ctc0 61.690701 lr 0.00058632 rank 0
2022-08-26 11:49:01,874 DEBUG TRAIN Batch 204/3300 loss 18.417458 loss_att 7.196452 loss_ctc 44.599800 loss_ctc_origin 30.687885 loss_ctc0 77.060936 lr 0.00058630 rank 0
2022-08-26 11:49:29,512 DEBUG TRAIN Batch 204/3400 loss 18.292500 loss_att 7.250511 loss_ctc 44.057137 loss_ctc_origin 25.041685 loss_ctc0 88.426514 lr 0.00058627 rank 0
2022-08-26 11:49:58,930 DEBUG TRAIN Batch 204/3500 loss 43.084991 loss_att 30.286377 loss_ctc 72.948425 loss_ctc_origin 47.917946 loss_ctc0 131.352859 lr 0.00058625 rank 0
2022-08-26 11:50:26,034 DEBUG TRAIN Batch 204/3600 loss 37.991158 loss_att 20.220602 loss_ctc 79.455780 loss_ctc_origin 43.299786 loss_ctc0 163.819763 lr 0.00058622 rank 0
2022-08-26 11:50:53,042 DEBUG TRAIN Batch 204/3700 loss 19.589752 loss_att 9.491653 loss_ctc 43.151978 loss_ctc_origin 33.597874 loss_ctc0 65.444878 lr 0.00058620 rank 0
2022-08-26 11:51:22,423 DEBUG TRAIN Batch 204/3800 loss 16.975903 loss_att 6.608510 loss_ctc 41.166481 loss_ctc_origin 26.628448 loss_ctc0 75.088562 lr 0.00058617 rank 0
2022-08-26 11:51:37,567 WARNING NaN or Inf found in input tensor.
2022-08-26 11:51:43,976 WARNING NaN or Inf found in input tensor.
2022-08-26 11:51:48,018 DEBUG TRAIN Batch 204/3900 loss 19.606495 loss_att 7.897940 loss_ctc 46.926453 loss_ctc_origin 28.535316 loss_ctc0 89.839104 lr 0.00058615 rank 0
2022-08-26 11:52:16,046 DEBUG TRAIN Batch 204/4000 loss 41.315979 loss_att 26.963856 loss_ctc 74.804260 loss_ctc_origin 47.593178 loss_ctc0 138.296799 lr 0.00058612 rank 0
2022-08-26 11:52:43,377 DEBUG TRAIN Batch 204/4100 loss 64.003036 loss_att 37.161770 loss_ctc 126.632652 loss_ctc_origin 74.206772 loss_ctc0 248.959686 lr 0.00058610 rank 0
2022-08-26 11:53:12,326 DEBUG TRAIN Batch 204/4200 loss 20.293278 loss_att 11.665374 loss_ctc 40.425049 loss_ctc_origin 30.629112 loss_ctc0 63.282227 lr 0.00058607 rank 0
2022-08-26 11:53:39,786 DEBUG TRAIN Batch 204/4300 loss 20.015709 loss_att 8.205851 loss_ctc 47.572041 loss_ctc_origin 33.822475 loss_ctc0 79.654358 lr 0.00058605 rank 0
2022-08-26 11:54:08,456 DEBUG TRAIN Batch 204/4400 loss 24.559977 loss_att 9.891437 loss_ctc 58.786568 loss_ctc_origin 40.823761 loss_ctc0 100.699791 lr 0.00058602 rank 0
2022-08-26 11:54:42,850 DEBUG TRAIN Batch 204/4500 loss 49.192924 loss_att 31.504013 loss_ctc 90.467041 loss_ctc_origin 53.058441 loss_ctc0 177.753754 lr 0.00058599 rank 0
2022-08-26 11:55:10,808 DEBUG TRAIN Batch 204/4600 loss 66.476776 loss_att 39.794960 loss_ctc 128.734360 loss_ctc_origin 72.858673 loss_ctc0 259.110962 lr 0.00058597 rank 0
2022-08-26 11:55:39,202 DEBUG TRAIN Batch 204/4700 loss 16.774498 loss_att 8.934837 loss_ctc 35.067039 loss_ctc_origin 22.875710 loss_ctc0 63.513466 lr 0.00058594 rank 0
2022-08-26 11:56:06,325 DEBUG TRAIN Batch 204/4800 loss 21.697861 loss_att 9.240379 loss_ctc 50.765320 loss_ctc_origin 35.810387 loss_ctc0 85.660164 lr 0.00058592 rank 0
2022-08-26 11:56:34,356 DEBUG TRAIN Batch 204/4900 loss 23.558426 loss_att 8.936768 loss_ctc 57.675629 loss_ctc_origin 38.141903 loss_ctc0 103.254318 lr 0.00058589 rank 0
2022-08-26 11:57:03,114 WARNING NaN or Inf found in input tensor.
2022-08-26 11:57:03,154 DEBUG TRAIN Batch 204/5000 loss inf loss_att 41.249458 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00058587 rank 0
2022-08-26 11:57:31,961 DEBUG TRAIN Batch 204/5100 loss 66.557205 loss_att 40.260899 loss_ctc 127.915253 loss_ctc_origin 80.761444 loss_ctc0 237.940781 lr 0.00058584 rank 0
2022-08-26 11:57:58,805 DEBUG TRAIN Batch 204/5200 loss 15.593775 loss_att 6.530422 loss_ctc 36.741596 loss_ctc_origin 23.907200 loss_ctc0 66.688522 lr 0.00058582 rank 0
2022-08-26 11:58:25,928 DEBUG TRAIN Batch 204/5300 loss 17.022690 loss_att 7.148293 loss_ctc 40.062943 loss_ctc_origin 24.846069 loss_ctc0 75.568970 lr 0.00058579 rank 0
2022-08-26 11:58:54,173 DEBUG TRAIN Batch 204/5400 loss 23.059620 loss_att 8.793092 loss_ctc 56.348179 loss_ctc_origin 37.780682 loss_ctc0 99.672340 lr 0.00058577 rank 0
2022-08-26 11:59:20,890 DEBUG TRAIN Batch 204/5500 loss 53.714455 loss_att 36.126408 loss_ctc 94.753235 loss_ctc_origin 58.948204 loss_ctc0 178.298309 lr 0.00058574 rank 0
2022-08-26 11:59:48,566 DEBUG TRAIN Batch 204/5600 loss 64.123260 loss_att 35.438477 loss_ctc 131.054428 loss_ctc_origin 74.809296 loss_ctc0 262.293091 lr 0.00058572 rank 0
2022-08-26 12:00:10,452 DEBUG CV Batch 204/0 loss 11.375656 loss_att 8.597569 loss_ctc 17.857861 loss_ctc_origin 11.127715 loss_ctc0 33.561531 history loss 10.706500 rank 0
2022-08-26 12:00:20,993 DEBUG CV Batch 204/100 loss 20.441402 loss_att 16.698002 loss_ctc 29.175999 loss_ctc_origin 19.145037 loss_ctc0 52.581573 history loss 26.037359 rank 0
2022-08-26 12:00:30,525 DEBUG CV Batch 204/200 loss 25.385731 loss_att 19.630301 loss_ctc 38.815063 loss_ctc_origin 28.249706 loss_ctc0 63.467560 history loss 27.481376 rank 0
2022-08-26 12:00:40,122 DEBUG CV Batch 204/300 loss 21.714725 loss_att 16.413599 loss_ctc 34.084019 loss_ctc_origin 17.619963 loss_ctc0 72.500153 history loss 26.563180 rank 0
2022-08-26 12:00:50,549 DEBUG CV Batch 204/400 loss 37.723873 loss_att 30.276976 loss_ctc 55.099968 loss_ctc_origin 37.678383 loss_ctc0 95.750336 history loss 24.927670 rank 0
2022-08-26 12:01:01,222 DEBUG CV Batch 204/500 loss 15.599781 loss_att 10.920263 loss_ctc 26.518658 loss_ctc_origin 19.787006 loss_ctc0 42.225838 history loss 24.611643 rank 0
2022-08-26 12:01:11,544 DEBUG CV Batch 204/600 loss 17.059700 loss_att 12.033016 loss_ctc 28.788631 loss_ctc_origin 17.874941 loss_ctc0 54.253906 history loss 24.448658 rank 0
2022-08-26 12:01:21,337 DEBUG CV Batch 204/700 loss 17.617638 loss_att 12.251757 loss_ctc 30.138023 loss_ctc_origin 16.230873 loss_ctc0 62.588039 history loss 24.105922 rank 0
2022-08-26 12:01:31,131 DEBUG CV Batch 204/800 loss 22.026207 loss_att 17.215681 loss_ctc 33.250763 loss_ctc_origin 17.877604 loss_ctc0 69.121460 history loss 24.064961 rank 0
2022-08-26 12:01:40,977 INFO Epoch 204 CV info cv_loss 24.149436360652942
2022-08-26 12:01:40,978 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/204.pt
2022-08-26 12:01:41,517 INFO Epoch 205 TRAIN info lr 0.0005856973664765749
2022-08-26 12:01:41,520 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 12:02:06,780 DEBUG TRAIN Batch 205/0 loss 54.913292 loss_att 37.286503 loss_ctc 96.042473 loss_ctc_origin 66.431808 loss_ctc0 165.134018 lr 0.00058570 rank 0
2022-08-26 12:02:33,641 DEBUG TRAIN Batch 205/100 loss 61.813793 loss_att 35.399498 loss_ctc 123.447151 loss_ctc_origin 71.628540 loss_ctc0 244.357239 lr 0.00058567 rank 0
2022-08-26 12:03:01,742 DEBUG TRAIN Batch 205/200 loss 17.540239 loss_att 8.402351 loss_ctc 38.861977 loss_ctc_origin 26.961632 loss_ctc0 66.629448 lr 0.00058565 rank 0
2022-08-26 12:03:30,086 DEBUG TRAIN Batch 205/300 loss 18.309418 loss_att 7.293537 loss_ctc 44.013138 loss_ctc_origin 28.733675 loss_ctc0 79.665207 lr 0.00058562 rank 0
2022-08-26 12:03:57,632 DEBUG TRAIN Batch 205/400 loss 19.613699 loss_att 7.875112 loss_ctc 47.003735 loss_ctc_origin 28.560833 loss_ctc0 90.037170 lr 0.00058560 rank 0
2022-08-26 12:04:25,530 DEBUG TRAIN Batch 205/500 loss 57.435085 loss_att 36.167984 loss_ctc 107.058319 loss_ctc_origin 72.255569 loss_ctc0 188.264709 lr 0.00058557 rank 0
2022-08-26 12:04:51,811 DEBUG TRAIN Batch 205/600 loss 57.988792 loss_att 32.689320 loss_ctc 117.020889 loss_ctc_origin 68.585396 loss_ctc0 230.037018 lr 0.00058555 rank 0
2022-08-26 12:05:20,425 DEBUG TRAIN Batch 205/700 loss 19.792936 loss_att 9.236019 loss_ctc 44.425743 loss_ctc_origin 33.456673 loss_ctc0 70.020233 lr 0.00058552 rank 0
2022-08-26 12:05:25,727 WARNING NaN or Inf found in input tensor.
2022-08-26 12:05:48,670 DEBUG TRAIN Batch 205/800 loss 20.104269 loss_att 7.636244 loss_ctc 49.196327 loss_ctc_origin 33.537987 loss_ctc0 85.732452 lr 0.00058550 rank 0
2022-08-26 12:06:16,462 DEBUG TRAIN Batch 205/900 loss 20.403381 loss_att 6.889247 loss_ctc 51.936363 loss_ctc_origin 32.905598 loss_ctc0 96.341476 lr 0.00058547 rank 0
2022-08-26 12:06:43,446 DEBUG TRAIN Batch 205/1000 loss 54.081314 loss_att 33.942337 loss_ctc 101.072258 loss_ctc_origin 61.199280 loss_ctc0 194.109192 lr 0.00058545 rank 0
2022-08-26 12:06:56,968 WARNING NaN or Inf found in input tensor.
2022-08-26 12:07:10,091 DEBUG TRAIN Batch 205/1100 loss 60.803719 loss_att 36.477898 loss_ctc 117.563965 loss_ctc_origin 65.587044 loss_ctc0 238.843414 lr 0.00058542 rank 0
2022-08-26 12:07:37,433 DEBUG TRAIN Batch 205/1200 loss 17.980530 loss_att 8.738292 loss_ctc 39.545753 loss_ctc_origin 27.572723 loss_ctc0 67.482826 lr 0.00058540 rank 0
2022-08-26 12:08:06,110 DEBUG TRAIN Batch 205/1300 loss 17.935322 loss_att 6.796207 loss_ctc 43.926582 loss_ctc_origin 30.296558 loss_ctc0 75.729965 lr 0.00058537 rank 0
2022-08-26 12:08:31,709 DEBUG TRAIN Batch 205/1400 loss 22.866339 loss_att 8.603802 loss_ctc 56.145592 loss_ctc_origin 37.420158 loss_ctc0 99.838272 lr 0.00058535 rank 0
2022-08-26 12:09:06,580 DEBUG TRAIN Batch 205/1500 loss 51.480042 loss_att 32.800762 loss_ctc 95.065018 loss_ctc_origin 54.187130 loss_ctc0 190.446747 lr 0.00058532 rank 0
2022-08-26 12:09:33,933 DEBUG TRAIN Batch 205/1600 loss 55.259430 loss_att 31.288973 loss_ctc 111.190498 loss_ctc_origin 58.829803 loss_ctc0 233.365448 lr 0.00058529 rank 0
2022-08-26 12:10:01,021 DEBUG TRAIN Batch 205/1700 loss 18.663795 loss_att 8.955242 loss_ctc 41.317085 loss_ctc_origin 28.878334 loss_ctc0 70.340836 lr 0.00058527 rank 0
2022-08-26 12:10:27,478 DEBUG TRAIN Batch 205/1800 loss 18.043221 loss_att 7.573126 loss_ctc 42.473442 loss_ctc_origin 28.563913 loss_ctc0 74.929001 lr 0.00058524 rank 0
2022-08-26 12:10:55,227 DEBUG TRAIN Batch 205/1900 loss 22.869917 loss_att 9.876873 loss_ctc 53.187016 loss_ctc_origin 38.543213 loss_ctc0 87.355881 lr 0.00058522 rank 0
2022-08-26 12:11:22,340 DEBUG TRAIN Batch 205/2000 loss 56.214935 loss_att 38.133083 loss_ctc 98.405930 loss_ctc_origin 69.221886 loss_ctc0 166.502014 lr 0.00058519 rank 0
2022-08-26 12:11:49,411 DEBUG TRAIN Batch 205/2100 loss 64.027168 loss_att 36.752819 loss_ctc 127.667305 loss_ctc_origin 78.483475 loss_ctc0 242.429581 lr 0.00058517 rank 0
2022-08-26 12:12:17,184 DEBUG TRAIN Batch 205/2200 loss 19.181076 loss_att 8.457319 loss_ctc 44.203175 loss_ctc_origin 33.848969 loss_ctc0 68.362991 lr 0.00058514 rank 0
2022-08-26 12:12:44,818 DEBUG TRAIN Batch 205/2300 loss 16.156841 loss_att 7.039835 loss_ctc 37.429855 loss_ctc_origin 22.685848 loss_ctc0 71.832535 lr 0.00058512 rank 0
2022-08-26 12:13:12,804 DEBUG TRAIN Batch 205/2400 loss 19.175972 loss_att 7.912774 loss_ctc 45.456764 loss_ctc_origin 27.088741 loss_ctc0 88.315475 lr 0.00058509 rank 0
2022-08-26 12:13:40,876 DEBUG TRAIN Batch 205/2500 loss 45.902225 loss_att 31.555658 loss_ctc 79.377548 loss_ctc_origin 54.213493 loss_ctc0 138.093689 lr 0.00058507 rank 0
2022-08-26 12:14:10,870 DEBUG TRAIN Batch 205/2600 loss 49.290146 loss_att 24.861238 loss_ctc 106.290924 loss_ctc_origin 58.997089 loss_ctc0 216.643219 lr 0.00058504 rank 0
2022-08-26 12:14:37,433 DEBUG TRAIN Batch 205/2700 loss 20.141922 loss_att 10.516911 loss_ctc 42.600281 loss_ctc_origin 30.609369 loss_ctc0 70.579071 lr 0.00058502 rank 0
2022-08-26 12:15:04,327 DEBUG TRAIN Batch 205/2800 loss 15.818216 loss_att 6.464808 loss_ctc 37.642834 loss_ctc_origin 22.036392 loss_ctc0 74.057861 lr 0.00058499 rank 0
2022-08-26 12:15:30,781 DEBUG TRAIN Batch 205/2900 loss 17.550026 loss_att 6.532837 loss_ctc 43.256798 loss_ctc_origin 25.651756 loss_ctc0 84.335228 lr 0.00058497 rank 0
2022-08-26 12:16:04,299 DEBUG TRAIN Batch 205/3000 loss 49.257164 loss_att 33.783142 loss_ctc 85.363220 loss_ctc_origin 49.332363 loss_ctc0 169.435211 lr 0.00058494 rank 0
2022-08-26 12:16:32,392 DEBUG TRAIN Batch 205/3100 loss 52.908146 loss_att 27.615925 loss_ctc 111.923325 loss_ctc_origin 58.965397 loss_ctc0 235.491821 lr 0.00058492 rank 0
2022-08-26 12:16:59,127 DEBUG TRAIN Batch 205/3200 loss 20.440842 loss_att 9.228349 loss_ctc 46.603321 loss_ctc_origin 35.789268 loss_ctc0 71.836105 lr 0.00058489 rank 0
2022-08-26 12:17:26,955 DEBUG TRAIN Batch 205/3300 loss 16.846531 loss_att 7.252765 loss_ctc 39.231987 loss_ctc_origin 23.899231 loss_ctc0 75.008408 lr 0.00058487 rank 0
2022-08-26 12:17:55,508 DEBUG TRAIN Batch 205/3400 loss 19.712807 loss_att 8.421770 loss_ctc 46.058556 loss_ctc_origin 26.733938 loss_ctc0 91.149323 lr 0.00058484 rank 0
2022-08-26 12:18:23,257 DEBUG TRAIN Batch 205/3500 loss 51.276485 loss_att 36.745697 loss_ctc 85.181656 loss_ctc_origin 60.862457 loss_ctc0 141.926437 lr 0.00058482 rank 0
2022-08-26 12:18:51,273 DEBUG TRAIN Batch 205/3600 loss 60.014381 loss_att 34.592537 loss_ctc 119.332016 loss_ctc_origin 75.262421 loss_ctc0 222.161072 lr 0.00058479 rank 0
2022-08-26 12:19:19,335 DEBUG TRAIN Batch 205/3700 loss 19.765112 loss_att 9.913605 loss_ctc 42.751961 loss_ctc_origin 30.674877 loss_ctc0 70.931816 lr 0.00058477 rank 0
2022-08-26 12:19:47,857 DEBUG TRAIN Batch 205/3800 loss 18.513218 loss_att 8.272034 loss_ctc 42.409309 loss_ctc_origin 27.216192 loss_ctc0 77.859909 lr 0.00058474 rank 0
2022-08-26 12:20:03,613 WARNING NaN or Inf found in input tensor.
2022-08-26 12:20:14,761 DEBUG TRAIN Batch 205/3900 loss 21.369869 loss_att 8.735642 loss_ctc 50.849731 loss_ctc_origin 31.288794 loss_ctc0 96.491913 lr 0.00058472 rank 0
2022-08-26 12:20:42,152 DEBUG TRAIN Batch 205/4000 loss 48.195786 loss_att 33.245766 loss_ctc 83.079163 loss_ctc_origin 56.230656 loss_ctc0 145.725662 lr 0.00058469 rank 0
2022-08-26 12:21:09,634 DEBUG TRAIN Batch 205/4100 loss 53.528038 loss_att 29.878767 loss_ctc 108.709671 loss_ctc_origin 60.536736 loss_ctc0 221.113174 lr 0.00058467 rank 0
2022-08-26 12:21:38,981 DEBUG TRAIN Batch 205/4200 loss 20.035183 loss_att 10.422457 loss_ctc 42.464874 loss_ctc_origin 30.866047 loss_ctc0 69.528809 lr 0.00058464 rank 0
2022-08-26 12:22:05,861 DEBUG TRAIN Batch 205/4300 loss 20.538401 loss_att 8.947124 loss_ctc 47.584709 loss_ctc_origin 32.910469 loss_ctc0 81.824600 lr 0.00058462 rank 0
2022-08-26 12:22:36,570 DEBUG TRAIN Batch 205/4400 loss 18.300844 loss_att 6.994751 loss_ctc 44.681728 loss_ctc_origin 27.092197 loss_ctc0 85.723961 lr 0.00058459 rank 0
2022-08-26 12:23:06,545 DEBUG TRAIN Batch 205/4500 loss 52.312569 loss_att 33.099842 loss_ctc 97.142265 loss_ctc_origin 63.125618 loss_ctc0 176.514435 lr 0.00058457 rank 0
2022-08-26 12:23:33,417 DEBUG TRAIN Batch 205/4600 loss 62.915535 loss_att 37.401115 loss_ctc 122.449165 loss_ctc_origin 70.281288 loss_ctc0 244.174210 lr 0.00058454 rank 0
2022-08-26 12:24:00,570 DEBUG TRAIN Batch 205/4700 loss 20.418346 loss_att 10.904108 loss_ctc 42.618237 loss_ctc_origin 32.703186 loss_ctc0 65.753357 lr 0.00058452 rank 0
2022-08-26 12:24:27,438 DEBUG TRAIN Batch 205/4800 loss 16.600271 loss_att 6.332104 loss_ctc 40.559326 loss_ctc_origin 24.478374 loss_ctc0 78.081551 lr 0.00058449 rank 0
2022-08-26 12:24:54,995 DEBUG TRAIN Batch 205/4900 loss 20.114220 loss_att 8.446653 loss_ctc 47.338539 loss_ctc_origin 30.045691 loss_ctc0 87.688522 lr 0.00058447 rank 0
2022-08-26 12:25:23,669 DEBUG TRAIN Batch 205/5000 loss 49.169968 loss_att 32.568302 loss_ctc 87.907181 loss_ctc_origin 51.648746 loss_ctc0 172.510193 lr 0.00058444 rank 0
2022-08-26 12:25:50,534 DEBUG TRAIN Batch 205/5100 loss 59.775452 loss_att 34.818306 loss_ctc 118.008789 loss_ctc_origin 67.774597 loss_ctc0 235.221878 lr 0.00058442 rank 0
2022-08-26 12:26:17,273 DEBUG TRAIN Batch 205/5200 loss 19.656837 loss_att 8.793904 loss_ctc 45.003677 loss_ctc_origin 33.343727 loss_ctc0 72.210236 lr 0.00058439 rank 0
2022-08-26 12:26:45,258 DEBUG TRAIN Batch 205/5300 loss 17.570858 loss_att 5.978946 loss_ctc 44.618652 loss_ctc_origin 28.104973 loss_ctc0 83.150574 lr 0.00058437 rank 0
2022-08-26 12:27:12,763 DEBUG TRAIN Batch 205/5400 loss 20.486315 loss_att 8.211376 loss_ctc 49.127838 loss_ctc_origin 29.527941 loss_ctc0 94.860931 lr 0.00058434 rank 0
2022-08-26 12:27:41,912 DEBUG TRAIN Batch 205/5500 loss 44.280506 loss_att 25.694374 loss_ctc 87.648148 loss_ctc_origin 51.243481 loss_ctc0 172.592377 lr 0.00058432 rank 0
2022-08-26 12:28:08,937 DEBUG TRAIN Batch 205/5600 loss 62.956001 loss_att 37.014858 loss_ctc 123.485329 loss_ctc_origin 73.798904 loss_ctc0 239.420319 lr 0.00058429 rank 0
2022-08-26 12:28:31,002 DEBUG CV Batch 205/0 loss 12.620890 loss_att 9.443575 loss_ctc 20.034624 loss_ctc_origin 13.845600 loss_ctc0 34.475677 history loss 11.878484 rank 0
2022-08-26 12:28:41,802 DEBUG CV Batch 205/100 loss 20.022434 loss_att 15.964866 loss_ctc 29.490093 loss_ctc_origin 19.541019 loss_ctc0 52.704597 history loss 25.957890 rank 0
2022-08-26 12:28:51,139 DEBUG CV Batch 205/200 loss 25.631458 loss_att 20.359741 loss_ctc 37.932133 loss_ctc_origin 27.730120 loss_ctc0 61.736832 history loss 27.189514 rank 0
2022-08-26 12:29:01,178 DEBUG CV Batch 205/300 loss 21.383560 loss_att 16.042833 loss_ctc 33.845257 loss_ctc_origin 17.407391 loss_ctc0 72.200279 history loss 26.307632 rank 0
2022-08-26 12:29:11,614 DEBUG CV Batch 205/400 loss 37.277679 loss_att 29.893883 loss_ctc 54.506531 loss_ctc_origin 37.736149 loss_ctc0 93.637421 history loss 24.631596 rank 0
2022-08-26 12:29:22,188 DEBUG CV Batch 205/500 loss 16.294224 loss_att 11.924204 loss_ctc 26.490938 loss_ctc_origin 19.760361 loss_ctc0 42.195618 history loss 24.296346 rank 0
2022-08-26 12:29:32,558 DEBUG CV Batch 205/600 loss 16.290466 loss_att 11.435339 loss_ctc 27.619099 loss_ctc_origin 16.356930 loss_ctc0 53.897484 history loss 24.156857 rank 0
2022-08-26 12:29:42,097 DEBUG CV Batch 205/700 loss 17.812954 loss_att 12.530281 loss_ctc 30.139193 loss_ctc_origin 16.070913 loss_ctc0 62.965172 history loss 23.807175 rank 0
2022-08-26 12:29:52,280 DEBUG CV Batch 205/800 loss 21.605816 loss_att 16.815252 loss_ctc 32.783798 loss_ctc_origin 17.584709 loss_ctc0 68.248337 history loss 23.786781 rank 0
2022-08-26 12:30:02,339 INFO Epoch 205 CV info cv_loss 23.882237232895466
2022-08-26 12:30:02,340 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/205.pt
2022-08-26 12:30:02,790 INFO Epoch 206 TRAIN info lr 0.0005842740414893397
2022-08-26 12:30:02,794 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 12:30:28,841 DEBUG TRAIN Batch 206/0 loss 56.631012 loss_att 38.893635 loss_ctc 98.018219 loss_ctc_origin 70.507385 loss_ctc0 162.210175 lr 0.00058427 rank 0
2022-08-26 12:30:56,468 DEBUG TRAIN Batch 206/100 loss 54.679497 loss_att 29.374706 loss_ctc 113.723999 loss_ctc_origin 63.519218 loss_ctc0 230.868500 lr 0.00058425 rank 0
2022-08-26 12:31:23,818 DEBUG TRAIN Batch 206/200 loss 17.820902 loss_att 8.724722 loss_ctc 39.045319 loss_ctc_origin 27.185898 loss_ctc0 66.717293 lr 0.00058422 rank 0
2022-08-26 12:31:51,857 DEBUG TRAIN Batch 206/300 loss 18.985310 loss_att 8.172286 loss_ctc 44.215698 loss_ctc_origin 30.031633 loss_ctc0 77.311859 lr 0.00058420 rank 0
2022-08-26 12:31:56,223 WARNING NaN or Inf found in input tensor.
2022-08-26 12:32:20,617 DEBUG TRAIN Batch 206/400 loss 19.653074 loss_att 7.490154 loss_ctc 48.033218 loss_ctc_origin 30.456038 loss_ctc0 89.046646 lr 0.00058417 rank 0
2022-08-26 12:32:48,726 DEBUG TRAIN Batch 206/500 loss 45.068665 loss_att 28.957825 loss_ctc 82.660629 loss_ctc_origin 52.929184 loss_ctc0 152.033997 lr 0.00058415 rank 0
2022-08-26 12:33:16,251 DEBUG TRAIN Batch 206/600 loss 57.803970 loss_att 29.106628 loss_ctc 124.764435 loss_ctc_origin 65.246033 loss_ctc0 263.640686 lr 0.00058412 rank 0
2022-08-26 12:33:43,254 DEBUG TRAIN Batch 206/700 loss 20.003275 loss_att 9.762163 loss_ctc 43.899200 loss_ctc_origin 33.418861 loss_ctc0 68.353317 lr 0.00058410 rank 0
2022-08-26 12:34:09,950 DEBUG TRAIN Batch 206/800 loss 18.263739 loss_att 6.617614 loss_ctc 45.438026 loss_ctc_origin 30.617847 loss_ctc0 80.018433 lr 0.00058407 rank 0
2022-08-26 12:34:37,497 DEBUG TRAIN Batch 206/900 loss 19.937538 loss_att 8.174906 loss_ctc 47.383682 loss_ctc_origin 27.872446 loss_ctc0 92.909897 lr 0.00058405 rank 0
2022-08-26 12:35:07,405 DEBUG TRAIN Batch 206/1000 loss 43.796562 loss_att 26.761005 loss_ctc 83.546196 loss_ctc_origin 53.285564 loss_ctc0 154.154327 lr 0.00058402 rank 0
2022-08-26 12:35:32,351 DEBUG TRAIN Batch 206/1100 loss 63.248917 loss_att 34.171040 loss_ctc 131.097290 loss_ctc_origin 74.094315 loss_ctc0 264.104248 lr 0.00058400 rank 0
2022-08-26 12:35:59,082 DEBUG TRAIN Batch 206/1200 loss 19.273315 loss_att 8.797812 loss_ctc 43.716156 loss_ctc_origin 32.322227 loss_ctc0 70.301987 lr 0.00058397 rank 0
2022-08-26 12:36:27,259 DEBUG TRAIN Batch 206/1300 loss 21.075966 loss_att 8.722025 loss_ctc 49.901825 loss_ctc_origin 35.979088 loss_ctc0 82.388206 lr 0.00058395 rank 0
2022-08-26 12:36:55,578 DEBUG TRAIN Batch 206/1400 loss 22.825048 loss_att 9.476269 loss_ctc 53.972198 loss_ctc_origin 36.820930 loss_ctc0 93.991821 lr 0.00058392 rank 0
2022-08-26 12:37:28,808 DEBUG TRAIN Batch 206/1500 loss 33.867355 loss_att 19.928795 loss_ctc 66.390656 loss_ctc_origin 37.539543 loss_ctc0 133.709915 lr 0.00058390 rank 0
2022-08-26 12:37:55,714 DEBUG TRAIN Batch 206/1600 loss 58.104973 loss_att 31.613083 loss_ctc 119.919373 loss_ctc_origin 67.442520 loss_ctc0 242.365356 lr 0.00058387 rank 0
2022-08-26 12:38:22,681 DEBUG TRAIN Batch 206/1700 loss 20.785248 loss_att 12.009279 loss_ctc 41.262508 loss_ctc_origin 30.581606 loss_ctc0 66.184616 lr 0.00058385 rank 0
2022-08-26 12:38:48,930 DEBUG TRAIN Batch 206/1800 loss 20.215237 loss_att 9.084186 loss_ctc 46.187691 loss_ctc_origin 30.872599 loss_ctc0 81.922897 lr 0.00058382 rank 0
2022-08-26 12:39:16,220 DEBUG TRAIN Batch 206/1900 loss 22.286819 loss_att 9.384795 loss_ctc 52.391541 loss_ctc_origin 35.045815 loss_ctc0 92.864891 lr 0.00058380 rank 0
2022-08-26 12:39:43,403 DEBUG TRAIN Batch 206/2000 loss 51.907982 loss_att 34.146835 loss_ctc 93.350647 loss_ctc_origin 58.375736 loss_ctc0 174.958786 lr 0.00058378 rank 0
2022-08-26 12:40:09,461 DEBUG TRAIN Batch 206/2100 loss 68.201263 loss_att 40.555218 loss_ctc 132.708694 loss_ctc_origin 81.072357 loss_ctc0 253.193481 lr 0.00058375 rank 0
2022-08-26 12:40:36,770 DEBUG TRAIN Batch 206/2200 loss 16.551947 loss_att 8.503302 loss_ctc 35.332119 loss_ctc_origin 23.629265 loss_ctc0 62.638775 lr 0.00058373 rank 0
2022-08-26 12:41:04,285 DEBUG TRAIN Batch 206/2300 loss 17.658398 loss_att 6.426504 loss_ctc 43.866150 loss_ctc_origin 28.614704 loss_ctc0 79.452850 lr 0.00058370 rank 0
2022-08-26 12:41:31,938 DEBUG TRAIN Batch 206/2400 loss 22.497719 loss_att 9.188599 loss_ctc 53.552330 loss_ctc_origin 33.767151 loss_ctc0 99.717751 lr 0.00058368 rank 0
2022-08-26 12:42:01,123 DEBUG TRAIN Batch 206/2500 loss 53.056210 loss_att 36.119835 loss_ctc 92.574417 loss_ctc_origin 58.420929 loss_ctc0 172.265869 lr 0.00058365 rank 0
2022-08-26 12:42:29,488 DEBUG TRAIN Batch 206/2600 loss 60.683144 loss_att 31.675400 loss_ctc 128.367874 loss_ctc_origin 69.542038 loss_ctc0 265.628143 lr 0.00058363 rank 0
2022-08-26 12:42:55,285 DEBUG TRAIN Batch 206/2700 loss 21.311577 loss_att 12.384614 loss_ctc 42.141155 loss_ctc_origin 31.655796 loss_ctc0 66.606987 lr 0.00058360 rank 0
2022-08-26 12:43:22,006 DEBUG TRAIN Batch 206/2800 loss 19.415861 loss_att 8.217699 loss_ctc 45.544903 loss_ctc_origin 30.981804 loss_ctc0 79.525467 lr 0.00058358 rank 0
2022-08-26 12:43:49,335 DEBUG TRAIN Batch 206/2900 loss 23.661972 loss_att 9.777258 loss_ctc 56.059639 loss_ctc_origin 36.890480 loss_ctc0 100.787674 lr 0.00058355 rank 0
2022-08-26 12:44:04,675 WARNING NaN or Inf found in input tensor.
2022-08-26 12:44:21,948 DEBUG TRAIN Batch 206/3000 loss 48.581055 loss_att 33.631516 loss_ctc 83.463310 loss_ctc_origin 50.486164 loss_ctc0 160.409988 lr 0.00058353 rank 0
2022-08-26 12:44:49,147 DEBUG TRAIN Batch 206/3100 loss 58.355541 loss_att 33.973225 loss_ctc 115.247604 loss_ctc_origin 68.789673 loss_ctc0 223.649445 lr 0.00058350 rank 0
2022-08-26 12:45:15,189 WARNING NaN or Inf found in input tensor.
2022-08-26 12:45:16,743 DEBUG TRAIN Batch 206/3200 loss 16.712357 loss_att 7.774712 loss_ctc 37.566856 loss_ctc_origin 27.057041 loss_ctc0 62.089767 lr 0.00058348 rank 0
2022-08-26 12:45:44,267 DEBUG TRAIN Batch 206/3300 loss 17.914793 loss_att 7.043698 loss_ctc 43.280678 loss_ctc_origin 28.886227 loss_ctc0 76.867737 lr 0.00058345 rank 0
2022-08-26 12:46:11,893 DEBUG TRAIN Batch 206/3400 loss 21.789455 loss_att 8.450067 loss_ctc 52.914696 loss_ctc_origin 29.555805 loss_ctc0 107.418762 lr 0.00058343 rank 0
2022-08-26 12:46:21,022 WARNING NaN or Inf found in input tensor.
2022-08-26 12:46:40,915 DEBUG TRAIN Batch 206/3500 loss 52.938248 loss_att 36.202427 loss_ctc 91.988495 loss_ctc_origin 62.251240 loss_ctc0 161.375427 lr 0.00058340 rank 0
2022-08-26 12:46:48,505 WARNING NaN or Inf found in input tensor.
2022-08-26 12:47:08,506 DEBUG TRAIN Batch 206/3600 loss 68.950905 loss_att 43.574768 loss_ctc 128.161896 loss_ctc_origin 81.618515 loss_ctc0 236.763107 lr 0.00058338 rank 0
2022-08-26 12:47:36,406 DEBUG TRAIN Batch 206/3700 loss 19.305588 loss_att 9.705746 loss_ctc 41.705215 loss_ctc_origin 30.607706 loss_ctc0 67.599403 lr 0.00058335 rank 0
2022-08-26 12:48:04,803 DEBUG TRAIN Batch 206/3800 loss 24.298008 loss_att 10.087764 loss_ctc 57.455246 loss_ctc_origin 43.419022 loss_ctc0 90.206436 lr 0.00058333 rank 0
2022-08-26 12:48:33,123 DEBUG TRAIN Batch 206/3900 loss 20.185238 loss_att 8.004919 loss_ctc 48.605980 loss_ctc_origin 33.126621 loss_ctc0 84.724472 lr 0.00058330 rank 0
2022-08-26 12:48:47,786 WARNING NaN or Inf found in input tensor.
2022-08-26 12:49:00,602 DEBUG TRAIN Batch 206/4000 loss 59.216911 loss_att 42.823708 loss_ctc 97.467720 loss_ctc_origin 73.469948 loss_ctc0 153.462524 lr 0.00058328 rank 0
2022-08-26 12:49:27,823 DEBUG TRAIN Batch 206/4100 loss 59.370975 loss_att 35.527023 loss_ctc 115.006866 loss_ctc_origin 64.784424 loss_ctc0 232.192581 lr 0.00058325 rank 0
2022-08-26 12:49:54,321 WARNING NaN or Inf found in input tensor.
2022-08-26 12:49:55,801 DEBUG TRAIN Batch 206/4200 loss 20.207840 loss_att 10.677934 loss_ctc 42.444286 loss_ctc_origin 32.405807 loss_ctc0 65.867401 lr 0.00058323 rank 0
2022-08-26 12:50:24,596 DEBUG TRAIN Batch 206/4300 loss 21.575825 loss_att 8.336971 loss_ctc 52.466484 loss_ctc_origin 40.319695 loss_ctc0 80.808990 lr 0.00058320 rank 0
2022-08-26 12:50:51,634 DEBUG TRAIN Batch 206/4400 loss 19.873768 loss_att 7.658958 loss_ctc 48.374985 loss_ctc_origin 28.363384 loss_ctc0 95.068710 lr 0.00058318 rank 0
2022-08-26 12:51:25,447 DEBUG TRAIN Batch 206/4500 loss 53.994061 loss_att 37.918335 loss_ctc 91.504089 loss_ctc_origin 57.481621 loss_ctc0 170.889832 lr 0.00058315 rank 0
2022-08-26 12:51:26,225 WARNING NaN or Inf found in input tensor.
2022-08-26 12:51:53,685 DEBUG TRAIN Batch 206/4600 loss 64.655418 loss_att 36.507225 loss_ctc 130.334534 loss_ctc_origin 83.359955 loss_ctc0 239.941864 lr 0.00058313 rank 0
2022-08-26 12:52:22,543 DEBUG TRAIN Batch 206/4700 loss 20.385824 loss_att 9.005645 loss_ctc 46.939575 loss_ctc_origin 34.419037 loss_ctc0 76.154160 lr 0.00058310 rank 0
2022-08-26 12:52:50,848 DEBUG TRAIN Batch 206/4800 loss 17.143463 loss_att 7.203231 loss_ctc 40.337334 loss_ctc_origin 27.084894 loss_ctc0 71.259689 lr 0.00058308 rank 0
2022-08-26 12:53:18,461 DEBUG TRAIN Batch 206/4900 loss 22.220379 loss_att 9.866795 loss_ctc 51.045410 loss_ctc_origin 31.878654 loss_ctc0 95.767838 lr 0.00058306 rank 0
2022-08-26 12:53:46,714 DEBUG TRAIN Batch 206/5000 loss 42.650383 loss_att 26.709833 loss_ctc 79.845001 loss_ctc_origin 45.390945 loss_ctc0 160.237793 lr 0.00058303 rank 0
2022-08-26 12:53:54,123 WARNING NaN or Inf found in input tensor.
2022-08-26 12:54:13,488 DEBUG TRAIN Batch 206/5100 loss 61.820465 loss_att 35.505836 loss_ctc 123.221260 loss_ctc_origin 69.968620 loss_ctc0 247.477417 lr 0.00058301 rank 0
2022-08-26 12:54:40,541 DEBUG TRAIN Batch 206/5200 loss 17.606684 loss_att 8.628315 loss_ctc 38.556213 loss_ctc_origin 26.960478 loss_ctc0 65.612923 lr 0.00058298 rank 0
2022-08-26 12:55:08,913 DEBUG TRAIN Batch 206/5300 loss 22.460844 loss_att 9.785425 loss_ctc 52.036819 loss_ctc_origin 38.700325 loss_ctc0 83.155296 lr 0.00058296 rank 0
2022-08-26 12:55:37,072 DEBUG TRAIN Batch 206/5400 loss 22.910959 loss_att 10.315638 loss_ctc 52.300041 loss_ctc_origin 36.321632 loss_ctc0 89.582985 lr 0.00058293 rank 0
2022-08-26 12:56:04,936 DEBUG TRAIN Batch 206/5500 loss 39.690464 loss_att 24.278759 loss_ctc 75.651108 loss_ctc_origin 45.158371 loss_ctc0 146.800812 lr 0.00058291 rank 0
2022-08-26 12:56:32,343 DEBUG TRAIN Batch 206/5600 loss 64.905457 loss_att 39.393223 loss_ctc 124.433990 loss_ctc_origin 74.945663 loss_ctc0 239.906738 lr 0.00058288 rank 0
2022-08-26 12:56:53,818 DEBUG CV Batch 206/0 loss 11.683252 loss_att 8.577054 loss_ctc 18.931047 loss_ctc_origin 12.340432 loss_ctc0 34.309147 history loss 10.996002 rank 0
2022-08-26 12:57:04,395 DEBUG CV Batch 206/100 loss 20.610092 loss_att 16.878021 loss_ctc 29.318260 loss_ctc_origin 19.295332 loss_ctc0 52.705090 history loss 26.215617 rank 0
2022-08-26 12:57:13,620 DEBUG CV Batch 206/200 loss 25.239914 loss_att 19.848389 loss_ctc 37.820141 loss_ctc_origin 27.584110 loss_ctc0 61.704216 history loss 27.486281 rank 0
2022-08-26 12:57:23,528 DEBUG CV Batch 206/300 loss 22.635384 loss_att 17.212652 loss_ctc 35.288422 loss_ctc_origin 19.671162 loss_ctc0 71.728699 history loss 26.615446 rank 0
2022-08-26 12:57:34,069 DEBUG CV Batch 206/400 loss 36.949570 loss_att 29.219303 loss_ctc 54.986851 loss_ctc_origin 38.087002 loss_ctc0 94.419830 history loss 24.945387 rank 0
2022-08-26 12:57:44,660 DEBUG CV Batch 206/500 loss 16.893599 loss_att 12.792505 loss_ctc 26.462814 loss_ctc_origin 19.616541 loss_ctc0 42.437447 history loss 24.620901 rank 0
2022-08-26 12:57:55,313 DEBUG CV Batch 206/600 loss 17.804527 loss_att 12.440265 loss_ctc 30.321138 loss_ctc_origin 20.149918 loss_ctc0 54.053986 history loss 24.492844 rank 0
2022-08-26 12:58:05,470 DEBUG CV Batch 206/700 loss 18.907715 loss_att 13.405399 loss_ctc 31.746452 loss_ctc_origin 18.057234 loss_ctc0 63.687965 history loss 24.162061 rank 0
2022-08-26 12:58:15,854 DEBUG CV Batch 206/800 loss 21.627720 loss_att 16.713633 loss_ctc 33.093922 loss_ctc_origin 17.710079 loss_ctc0 68.989548 history loss 24.128259 rank 0
2022-08-26 12:58:26,069 INFO Epoch 206 CV info cv_loss 24.20236969579911
2022-08-26 12:58:26,069 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/206.pt
2022-08-26 12:58:26,512 INFO Epoch 207 TRAIN info lr 0.0005828610429480662
2022-08-26 12:58:26,516 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 12:58:52,086 DEBUG TRAIN Batch 207/0 loss 55.601448 loss_att 37.371483 loss_ctc 98.138023 loss_ctc_origin 63.953789 loss_ctc0 177.901230 lr 0.00058286 rank 0
2022-08-26 12:59:18,785 DEBUG TRAIN Batch 207/100 loss 58.598572 loss_att 28.718943 loss_ctc 128.317703 loss_ctc_origin 71.185944 loss_ctc0 261.625122 lr 0.00058284 rank 0
2022-08-26 12:59:46,664 DEBUG TRAIN Batch 207/200 loss 18.367496 loss_att 9.803253 loss_ctc 38.350727 loss_ctc_origin 25.922485 loss_ctc0 67.349960 lr 0.00058281 rank 0
2022-08-26 12:59:51,957 WARNING NaN or Inf found in input tensor.
2022-08-26 13:00:14,563 DEBUG TRAIN Batch 207/300 loss 16.884960 loss_att 7.273342 loss_ctc 39.312065 loss_ctc_origin 23.120991 loss_ctc0 77.091232 lr 0.00058279 rank 0
2022-08-26 13:00:42,453 DEBUG TRAIN Batch 207/400 loss 19.245163 loss_att 6.828801 loss_ctc 48.216667 loss_ctc_origin 29.362064 loss_ctc0 92.210747 lr 0.00058276 rank 0
2022-08-26 13:01:10,102 DEBUG TRAIN Batch 207/500 loss 51.954315 loss_att 34.239777 loss_ctc 93.288239 loss_ctc_origin 58.806385 loss_ctc0 173.745880 lr 0.00058274 rank 0
2022-08-26 13:01:37,908 DEBUG TRAIN Batch 207/600 loss 60.287922 loss_att 32.848763 loss_ctc 124.312622 loss_ctc_origin 72.728699 loss_ctc0 244.675110 lr 0.00058271 rank 0
2022-08-26 13:02:03,807 WARNING NaN or Inf found in input tensor.
2022-08-26 13:02:05,390 DEBUG TRAIN Batch 207/700 loss 19.895977 loss_att 8.994373 loss_ctc 45.333054 loss_ctc_origin 32.651405 loss_ctc0 74.923569 lr 0.00058269 rank 0
2022-08-26 13:02:10,828 WARNING NaN or Inf found in input tensor.
2022-08-26 13:02:32,433 DEBUG TRAIN Batch 207/800 loss 20.886688 loss_att 8.119870 loss_ctc 50.675926 loss_ctc_origin 36.993916 loss_ctc0 82.600616 lr 0.00058266 rank 0
2022-08-26 13:02:59,886 DEBUG TRAIN Batch 207/900 loss 20.815104 loss_att 8.523180 loss_ctc 49.496254 loss_ctc_origin 30.215494 loss_ctc0 94.484695 lr 0.00058264 rank 0
2022-08-26 13:03:20,906 WARNING NaN or Inf found in input tensor.
2022-08-26 13:03:27,444 DEBUG TRAIN Batch 207/1000 loss 52.839252 loss_att 36.604790 loss_ctc 90.719666 loss_ctc_origin 59.387203 loss_ctc0 163.828735 lr 0.00058261 rank 0
2022-08-26 13:03:55,228 DEBUG TRAIN Batch 207/1100 loss 55.542133 loss_att 29.791407 loss_ctc 115.627159 loss_ctc_origin 61.800877 loss_ctc0 241.221802 lr 0.00058259 rank 0
2022-08-26 13:04:23,814 DEBUG TRAIN Batch 207/1200 loss 17.050180 loss_att 8.801721 loss_ctc 36.296585 loss_ctc_origin 24.059381 loss_ctc0 64.850060 lr 0.00058256 rank 0
2022-08-26 13:04:53,154 DEBUG TRAIN Batch 207/1300 loss 17.079014 loss_att 6.867722 loss_ctc 40.905357 loss_ctc_origin 27.163486 loss_ctc0 72.969727 lr 0.00058254 rank 0
2022-08-26 13:05:14,962 WARNING NaN or Inf found in input tensor.
2022-08-26 13:05:19,352 DEBUG TRAIN Batch 207/1400 loss 18.718575 loss_att 6.772350 loss_ctc 46.593094 loss_ctc_origin 28.125048 loss_ctc0 89.685196 lr 0.00058251 rank 0
2022-08-26 13:05:50,422 DEBUG TRAIN Batch 207/1500 loss 51.850986 loss_att 34.338840 loss_ctc 92.712662 loss_ctc_origin 60.286636 loss_ctc0 168.373367 lr 0.00058249 rank 0
2022-08-26 13:06:17,990 DEBUG TRAIN Batch 207/1600 loss 70.193886 loss_att 41.575184 loss_ctc 136.970856 loss_ctc_origin 87.454956 loss_ctc0 252.507919 lr 0.00058246 rank 0
2022-08-26 13:06:45,205 DEBUG TRAIN Batch 207/1700 loss 17.460388 loss_att 9.366927 loss_ctc 36.345131 loss_ctc_origin 24.686264 loss_ctc0 63.549152 lr 0.00058244 rank 0
2022-08-26 13:07:13,020 DEBUG TRAIN Batch 207/1800 loss 16.450218 loss_att 6.691058 loss_ctc 39.221588 loss_ctc_origin 24.068922 loss_ctc0 74.577805 lr 0.00058242 rank 0
2022-08-26 13:07:41,523 DEBUG TRAIN Batch 207/1900 loss 22.334745 loss_att 9.173458 loss_ctc 53.044415 loss_ctc_origin 30.600409 loss_ctc0 105.413757 lr 0.00058239 rank 0
2022-08-26 13:08:10,037 DEBUG TRAIN Batch 207/2000 loss 54.110016 loss_att 36.835243 loss_ctc 94.417816 loss_ctc_origin 64.521225 loss_ctc0 164.176514 lr 0.00058237 rank 0
2022-08-26 13:08:37,304 DEBUG TRAIN Batch 207/2100 loss 66.158348 loss_att 39.032261 loss_ctc 129.452545 loss_ctc_origin 80.459824 loss_ctc0 243.768906 lr 0.00058234 rank 0
2022-08-26 13:09:03,952 DEBUG TRAIN Batch 207/2200 loss 21.772253 loss_att 11.649585 loss_ctc 45.391811 loss_ctc_origin 35.594517 loss_ctc0 68.252167 lr 0.00058232 rank 0
2022-08-26 13:09:32,514 DEBUG TRAIN Batch 207/2300 loss 18.826710 loss_att 8.104748 loss_ctc 43.844620 loss_ctc_origin 28.106348 loss_ctc0 80.567245 lr 0.00058229 rank 0
2022-08-26 13:10:01,104 DEBUG TRAIN Batch 207/2400 loss 22.072128 loss_att 8.878729 loss_ctc 52.856728 loss_ctc_origin 32.011234 loss_ctc0 101.496216 lr 0.00058227 rank 0
2022-08-26 13:10:28,394 DEBUG TRAIN Batch 207/2500 loss 53.550278 loss_att 37.887772 loss_ctc 90.096115 loss_ctc_origin 57.861843 loss_ctc0 165.309433 lr 0.00058224 rank 0
2022-08-26 13:10:56,280 DEBUG TRAIN Batch 207/2600 loss 62.963097 loss_att 37.778751 loss_ctc 121.726570 loss_ctc_origin 73.044380 loss_ctc0 235.318344 lr 0.00058222 rank 0
2022-08-26 13:11:23,748 DEBUG TRAIN Batch 207/2700 loss 16.032915 loss_att 6.733794 loss_ctc 37.730865 loss_ctc_origin 25.250351 loss_ctc0 66.852058 lr 0.00058219 rank 0
2022-08-26 13:11:51,946 DEBUG TRAIN Batch 207/2800 loss 19.873806 loss_att 8.457151 loss_ctc 46.512661 loss_ctc_origin 32.003304 loss_ctc0 80.367828 lr 0.00058217 rank 0
2022-08-26 13:12:20,527 DEBUG TRAIN Batch 207/2900 loss 20.726810 loss_att 7.777942 loss_ctc 50.940838 loss_ctc_origin 33.729469 loss_ctc0 91.100693 lr 0.00058214 rank 0
2022-08-26 13:12:56,050 DEBUG TRAIN Batch 207/3000 loss 50.078171 loss_att 32.493668 loss_ctc 91.108673 loss_ctc_origin 60.381180 loss_ctc0 162.806152 lr 0.00058212 rank 0
2022-08-26 13:13:10,248 WARNING NaN or Inf found in input tensor.
2022-08-26 13:13:22,885 DEBUG TRAIN Batch 207/3100 loss 65.448021 loss_att 39.721230 loss_ctc 125.477188 loss_ctc_origin 78.508255 loss_ctc0 235.071365 lr 0.00058209 rank 0
2022-08-26 13:13:51,229 DEBUG TRAIN Batch 207/3200 loss 19.668228 loss_att 9.982904 loss_ctc 42.267319 loss_ctc_origin 29.956093 loss_ctc0 70.993515 lr 0.00058207 rank 0
2022-08-26 13:14:19,027 DEBUG TRAIN Batch 207/3300 loss 20.408184 loss_att 7.625514 loss_ctc 50.234413 loss_ctc_origin 35.060734 loss_ctc0 85.639664 lr 0.00058204 rank 0
2022-08-26 13:14:46,024 DEBUG TRAIN Batch 207/3400 loss 21.707314 loss_att 7.750714 loss_ctc 54.272713 loss_ctc_origin 33.058525 loss_ctc0 103.772491 lr 0.00058202 rank 0
2022-08-26 13:15:13,930 DEBUG TRAIN Batch 207/3500 loss 55.733318 loss_att 37.928589 loss_ctc 97.277679 loss_ctc_origin 67.709885 loss_ctc0 166.269196 lr 0.00058200 rank 0
2022-08-26 13:15:41,339 DEBUG TRAIN Batch 207/3600 loss 66.585312 loss_att 42.562492 loss_ctc 122.638550 loss_ctc_origin 76.612839 loss_ctc0 230.031891 lr 0.00058197 rank 0
2022-08-26 13:16:09,760 DEBUG TRAIN Batch 207/3700 loss 18.072872 loss_att 10.018097 loss_ctc 36.867348 loss_ctc_origin 25.982674 loss_ctc0 62.264915 lr 0.00058195 rank 0
2022-08-26 13:16:36,734 DEBUG TRAIN Batch 207/3800 loss 20.415958 loss_att 7.734261 loss_ctc 50.006580 loss_ctc_origin 33.000889 loss_ctc0 89.686523 lr 0.00058192 rank 0
2022-08-26 13:17:04,973 DEBUG TRAIN Batch 207/3900 loss 20.458563 loss_att 8.064749 loss_ctc 49.377460 loss_ctc_origin 31.402239 loss_ctc0 91.319641 lr 0.00058190 rank 0
2022-08-26 13:17:33,321 DEBUG TRAIN Batch 207/4000 loss 56.106312 loss_att 37.906624 loss_ctc 98.572250 loss_ctc_origin 68.401054 loss_ctc0 168.971695 lr 0.00058187 rank 0
2022-08-26 13:17:33,962 WARNING NaN or Inf found in input tensor.
2022-08-26 13:18:00,787 DEBUG TRAIN Batch 207/4100 loss 64.790466 loss_att 37.504173 loss_ctc 128.458481 loss_ctc_origin 82.528343 loss_ctc0 235.628784 lr 0.00058185 rank 0
2022-08-26 13:18:28,598 DEBUG TRAIN Batch 207/4200 loss 18.323317 loss_att 7.592183 loss_ctc 43.362625 loss_ctc_origin 32.313187 loss_ctc0 69.144646 lr 0.00058182 rank 0
2022-08-26 13:18:56,253 DEBUG TRAIN Batch 207/4300 loss 22.308651 loss_att 8.705678 loss_ctc 54.048920 loss_ctc_origin 41.817471 loss_ctc0 82.588974 lr 0.00058180 rank 0
2022-08-26 13:19:20,994 WARNING NaN or Inf found in input tensor.
2022-08-26 13:19:25,152 DEBUG TRAIN Batch 207/4400 loss 20.522026 loss_att 8.119478 loss_ctc 49.461304 loss_ctc_origin 29.494373 loss_ctc0 96.050812 lr 0.00058177 rank 0
2022-08-26 13:19:59,095 DEBUG TRAIN Batch 207/4500 loss 50.448284 loss_att 34.145054 loss_ctc 88.489151 loss_ctc_origin 63.794266 loss_ctc0 146.110535 lr 0.00058175 rank 0
2022-08-26 13:20:27,043 DEBUG TRAIN Batch 207/4600 loss 70.158493 loss_att 44.204578 loss_ctc 130.717621 loss_ctc_origin 86.846329 loss_ctc0 233.083969 lr 0.00058172 rank 0
2022-08-26 13:20:53,012 WARNING NaN or Inf found in input tensor.
2022-08-26 13:20:54,510 DEBUG TRAIN Batch 207/4700 loss 19.578421 loss_att 8.597523 loss_ctc 45.200516 loss_ctc_origin 33.806900 loss_ctc0 71.785614 lr 0.00058170 rank 0
2022-08-26 13:21:23,475 DEBUG TRAIN Batch 207/4800 loss 20.885008 loss_att 7.987292 loss_ctc 50.979675 loss_ctc_origin 37.419556 loss_ctc0 82.619957 lr 0.00058168 rank 0
2022-08-26 13:21:51,320 DEBUG TRAIN Batch 207/4900 loss 19.866192 loss_att 8.584293 loss_ctc 46.190620 loss_ctc_origin 27.090527 loss_ctc0 90.757507 lr 0.00058165 rank 0
2022-08-26 13:22:19,581 DEBUG TRAIN Batch 207/5000 loss 50.985336 loss_att 33.857346 loss_ctc 90.950653 loss_ctc_origin 61.350681 loss_ctc0 160.017242 lr 0.00058163 rank 0
2022-08-26 13:22:47,123 DEBUG TRAIN Batch 207/5100 loss 56.965347 loss_att 29.741793 loss_ctc 120.486961 loss_ctc_origin 73.827789 loss_ctc0 229.358368 lr 0.00058160 rank 0
2022-08-26 13:23:15,036 DEBUG TRAIN Batch 207/5200 loss 16.982050 loss_att 8.190512 loss_ctc 37.495640 loss_ctc_origin 25.685829 loss_ctc0 65.051865 lr 0.00058158 rank 0
2022-08-26 13:23:42,155 DEBUG TRAIN Batch 207/5300 loss 21.099258 loss_att 9.798890 loss_ctc 47.466782 loss_ctc_origin 31.722980 loss_ctc0 84.202316 lr 0.00058155 rank 0
2022-08-26 13:24:09,476 DEBUG TRAIN Batch 207/5400 loss 21.241571 loss_att 8.922142 loss_ctc 49.986904 loss_ctc_origin 32.335022 loss_ctc0 91.174622 lr 0.00058153 rank 0
2022-08-26 13:24:36,904 DEBUG TRAIN Batch 207/5500 loss 53.900230 loss_att 36.130486 loss_ctc 95.362961 loss_ctc_origin 63.730724 loss_ctc0 169.171509 lr 0.00058150 rank 0
2022-08-26 13:25:04,982 DEBUG TRAIN Batch 207/5600 loss 56.380730 loss_att 30.933502 loss_ctc 115.757599 loss_ctc_origin 74.506546 loss_ctc0 212.010040 lr 0.00058148 rank 0
2022-08-26 13:25:26,441 DEBUG CV Batch 207/0 loss 12.371584 loss_att 9.364531 loss_ctc 19.388042 loss_ctc_origin 12.852275 loss_ctc0 34.638161 history loss 11.643844 rank 0
2022-08-26 13:25:36,929 DEBUG CV Batch 207/100 loss 22.648302 loss_att 18.362286 loss_ctc 32.649006 loss_ctc_origin 23.594845 loss_ctc0 53.775375 history loss 27.184541 rank 0
2022-08-26 13:25:46,880 DEBUG CV Batch 207/200 loss 26.337032 loss_att 20.767979 loss_ctc 39.331490 loss_ctc_origin 28.427277 loss_ctc0 64.774651 history loss 28.411549 rank 0
2022-08-26 13:25:56,492 DEBUG CV Batch 207/300 loss 22.615978 loss_att 17.148708 loss_ctc 35.372944 loss_ctc_origin 19.492840 loss_ctc0 72.426514 history loss 27.447456 rank 0
2022-08-26 13:26:07,220 DEBUG CV Batch 207/400 loss 38.644241 loss_att 31.064377 loss_ctc 56.330589 loss_ctc_origin 39.291355 loss_ctc0 96.088806 history loss 25.686285 rank 0
2022-08-26 13:26:17,576 DEBUG CV Batch 207/500 loss 17.280468 loss_att 12.925463 loss_ctc 27.442146 loss_ctc_origin 20.829559 loss_ctc0 42.871517 history loss 25.345827 rank 0
2022-08-26 13:26:27,741 DEBUG CV Batch 207/600 loss 17.730957 loss_att 12.577069 loss_ctc 29.756699 loss_ctc_origin 18.807024 loss_ctc0 55.305939 history loss 25.200835 rank 0
2022-08-26 13:26:37,532 DEBUG CV Batch 207/700 loss 18.739746 loss_att 13.085720 loss_ctc 31.932476 loss_ctc_origin 18.179441 loss_ctc0 64.022888 history loss 24.871170 rank 0
2022-08-26 13:26:47,966 DEBUG CV Batch 207/800 loss 22.490158 loss_att 17.657940 loss_ctc 33.765331 loss_ctc_origin 18.345587 loss_ctc0 69.744736 history loss 24.808396 rank 0
2022-08-26 13:26:58,272 INFO Epoch 207 CV info cv_loss 24.875816179601546
2022-08-26 13:26:58,272 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/207.pt
2022-08-26 13:26:58,773 INFO Epoch 208 TRAIN info lr 0.0005814582465870377
2022-08-26 13:26:58,777 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 13:27:25,212 DEBUG TRAIN Batch 208/0 loss 49.492157 loss_att 36.533600 loss_ctc 79.728790 loss_ctc_origin 52.611664 loss_ctc0 143.002090 lr 0.00058146 rank 0
2022-08-26 13:27:32,333 WARNING NaN or Inf found in input tensor.
2022-08-26 13:27:52,794 DEBUG TRAIN Batch 208/100 loss 55.373390 loss_att 32.938171 loss_ctc 107.722237 loss_ctc_origin 65.427788 loss_ctc0 206.409286 lr 0.00058143 rank 0
2022-08-26 13:28:20,652 DEBUG TRAIN Batch 208/200 loss 18.524708 loss_att 9.362835 loss_ctc 39.902409 loss_ctc_origin 26.400959 loss_ctc0 71.405792 lr 0.00058141 rank 0
2022-08-26 13:28:49,169 DEBUG TRAIN Batch 208/300 loss 18.055973 loss_att 6.948324 loss_ctc 43.973816 loss_ctc_origin 29.259682 loss_ctc0 78.306786 lr 0.00058138 rank 0
2022-08-26 13:29:16,785 DEBUG TRAIN Batch 208/400 loss 21.432112 loss_att 8.983218 loss_ctc 50.479527 loss_ctc_origin 33.585838 loss_ctc0 89.898132 lr 0.00058136 rank 0
2022-08-26 13:29:44,640 DEBUG TRAIN Batch 208/500 loss 50.010326 loss_att 32.086678 loss_ctc 91.832169 loss_ctc_origin 60.571800 loss_ctc0 164.773010 lr 0.00058133 rank 0
2022-08-26 13:30:12,256 DEBUG TRAIN Batch 208/600 loss 66.214951 loss_att 42.441330 loss_ctc 121.686722 loss_ctc_origin 72.248489 loss_ctc0 237.042618 lr 0.00058131 rank 0
2022-08-26 13:30:39,509 DEBUG TRAIN Batch 208/700 loss 20.885778 loss_att 10.404947 loss_ctc 45.341049 loss_ctc_origin 33.734009 loss_ctc0 72.424149 lr 0.00058129 rank 0
2022-08-26 13:31:07,966 DEBUG TRAIN Batch 208/800 loss 19.679699 loss_att 8.491575 loss_ctc 45.785316 loss_ctc_origin 30.265335 loss_ctc0 81.998596 lr 0.00058126 rank 0
2022-08-26 13:31:35,432 DEBUG TRAIN Batch 208/900 loss 18.723701 loss_att 6.841577 loss_ctc 46.448654 loss_ctc_origin 28.338705 loss_ctc0 88.705193 lr 0.00058124 rank 0
2022-08-26 13:32:02,372 DEBUG TRAIN Batch 208/1000 loss 48.149170 loss_att 32.766636 loss_ctc 84.041748 loss_ctc_origin 55.034359 loss_ctc0 151.725632 lr 0.00058121 rank 0
2022-08-26 13:32:31,459 DEBUG TRAIN Batch 208/1100 loss 59.342236 loss_att 33.341610 loss_ctc 120.010353 loss_ctc_origin 71.904037 loss_ctc0 232.258423 lr 0.00058119 rank 0
2022-08-26 13:33:00,220 DEBUG TRAIN Batch 208/1200 loss 20.265314 loss_att 9.149499 loss_ctc 46.202217 loss_ctc_origin 34.420502 loss_ctc0 73.692886 lr 0.00058116 rank 0
2022-08-26 13:33:29,569 DEBUG TRAIN Batch 208/1300 loss 17.766060 loss_att 8.082032 loss_ctc 40.362125 loss_ctc_origin 25.590849 loss_ctc0 74.828438 lr 0.00058114 rank 0
2022-08-26 13:33:56,749 DEBUG TRAIN Batch 208/1400 loss 19.476963 loss_att 7.422696 loss_ctc 47.603584 loss_ctc_origin 27.780533 loss_ctc0 93.857361 lr 0.00058111 rank 0
2022-08-26 13:34:30,576 DEBUG TRAIN Batch 208/1500 loss 35.050152 loss_att 23.528355 loss_ctc 61.934341 loss_ctc_origin 40.820000 loss_ctc0 111.201134 lr 0.00058109 rank 0
2022-08-26 13:34:58,545 DEBUG TRAIN Batch 208/1600 loss 54.365494 loss_att 26.931934 loss_ctc 118.377136 loss_ctc_origin 61.559361 loss_ctc0 250.951935 lr 0.00058106 rank 0
2022-08-26 13:35:26,088 DEBUG TRAIN Batch 208/1700 loss 18.873533 loss_att 8.846868 loss_ctc 42.269085 loss_ctc_origin 30.054295 loss_ctc0 70.770264 lr 0.00058104 rank 0
2022-08-26 13:35:53,496 DEBUG TRAIN Batch 208/1800 loss 18.145159 loss_att 7.213576 loss_ctc 43.652184 loss_ctc_origin 28.727119 loss_ctc0 78.477325 lr 0.00058102 rank 0
2022-08-26 13:36:21,231 DEBUG TRAIN Batch 208/1900 loss 18.311745 loss_att 7.845808 loss_ctc 42.732262 loss_ctc_origin 24.835320 loss_ctc0 84.491791 lr 0.00058099 rank 0
2022-08-26 13:36:49,262 DEBUG TRAIN Batch 208/2000 loss 53.429489 loss_att 33.400894 loss_ctc 100.162872 loss_ctc_origin 63.936020 loss_ctc0 184.692184 lr 0.00058097 rank 0
2022-08-26 13:37:16,616 DEBUG TRAIN Batch 208/2100 loss 67.008476 loss_att 37.059219 loss_ctc 136.890076 loss_ctc_origin 77.917694 loss_ctc0 274.492310 lr 0.00058094 rank 0
2022-08-26 13:37:41,668 WARNING NaN or Inf found in input tensor.
2022-08-26 13:37:43,279 DEBUG TRAIN Batch 208/2200 loss 18.600908 loss_att 8.946763 loss_ctc 41.127247 loss_ctc_origin 29.783810 loss_ctc0 67.595261 lr 0.00058092 rank 0
2022-08-26 13:38:11,623 DEBUG TRAIN Batch 208/2300 loss 20.370871 loss_att 9.721970 loss_ctc 45.218304 loss_ctc_origin 31.293247 loss_ctc0 77.710098 lr 0.00058089 rank 0
2022-08-26 13:38:38,787 DEBUG TRAIN Batch 208/2400 loss 20.950827 loss_att 8.707879 loss_ctc 49.517704 loss_ctc_origin 32.212845 loss_ctc0 89.895706 lr 0.00058087 rank 0
2022-08-26 13:39:07,370 DEBUG TRAIN Batch 208/2500 loss 52.294609 loss_att 31.609930 loss_ctc 100.558861 loss_ctc_origin 63.027439 loss_ctc0 188.132172 lr 0.00058084 rank 0
2022-08-26 13:39:36,131 DEBUG TRAIN Batch 208/2600 loss 73.597229 loss_att 45.602654 loss_ctc 138.917908 loss_ctc_origin 82.057587 loss_ctc0 271.591980 lr 0.00058082 rank 0
2022-08-26 13:40:02,820 DEBUG TRAIN Batch 208/2700 loss 19.249352 loss_att 8.710459 loss_ctc 43.840099 loss_ctc_origin 32.067253 loss_ctc0 71.310074 lr 0.00058079 rank 0
2022-08-26 13:40:20,579 WARNING NaN or Inf found in input tensor.
2022-08-26 13:40:29,927 DEBUG TRAIN Batch 208/2800 loss 18.683117 loss_att 7.557470 loss_ctc 44.642960 loss_ctc_origin 30.692844 loss_ctc0 77.193222 lr 0.00058077 rank 0
2022-08-26 13:40:58,258 DEBUG TRAIN Batch 208/2900 loss 21.212746 loss_att 8.385151 loss_ctc 51.143799 loss_ctc_origin 30.869976 loss_ctc0 98.449394 lr 0.00058075 rank 0
2022-08-26 13:41:31,575 DEBUG TRAIN Batch 208/3000 loss 62.894615 loss_att 42.552689 loss_ctc 110.359116 loss_ctc_origin 77.152252 loss_ctc0 187.841797 lr 0.00058072 rank 0
2022-08-26 13:41:58,551 DEBUG TRAIN Batch 208/3100 loss 66.945541 loss_att 40.313381 loss_ctc 129.087234 loss_ctc_origin 81.986099 loss_ctc0 238.989868 lr 0.00058070 rank 0
2022-08-26 13:42:26,602 DEBUG TRAIN Batch 208/3200 loss 17.739347 loss_att 7.870476 loss_ctc 40.766712 loss_ctc_origin 28.488689 loss_ctc0 69.415436 lr 0.00058067 rank 0
2022-08-26 13:42:53,500 DEBUG TRAIN Batch 208/3300 loss 17.004564 loss_att 7.128228 loss_ctc 40.049347 loss_ctc_origin 25.614326 loss_ctc0 73.731049 lr 0.00058065 rank 0
2022-08-26 13:43:03,754 WARNING NaN or Inf found in input tensor.
2022-08-26 13:43:22,511 DEBUG TRAIN Batch 208/3400 loss 20.531013 loss_att 8.160635 loss_ctc 49.395229 loss_ctc_origin 32.062542 loss_ctc0 89.838165 lr 0.00058062 rank 0
2022-08-26 13:43:25,261 WARNING NaN or Inf found in input tensor.
2022-08-26 13:43:50,279 DEBUG TRAIN Batch 208/3500 loss 56.199764 loss_att 36.447193 loss_ctc 102.289093 loss_ctc_origin 67.330696 loss_ctc0 183.858704 lr 0.00058060 rank 0
2022-08-26 13:44:18,156 DEBUG TRAIN Batch 208/3600 loss 70.646271 loss_att 42.898415 loss_ctc 135.391266 loss_ctc_origin 85.729309 loss_ctc0 251.269135 lr 0.00058057 rank 0
2022-08-26 13:44:45,426 DEBUG TRAIN Batch 208/3700 loss 15.783254 loss_att 7.503086 loss_ctc 35.103645 loss_ctc_origin 22.130707 loss_ctc0 65.373840 lr 0.00058055 rank 0
2022-08-26 13:45:12,743 DEBUG TRAIN Batch 208/3800 loss 20.140886 loss_att 7.687137 loss_ctc 49.199635 loss_ctc_origin 34.363861 loss_ctc0 83.816437 lr 0.00058053 rank 0
2022-08-26 13:45:40,656 DEBUG TRAIN Batch 208/3900 loss 20.199556 loss_att 7.511424 loss_ctc 49.805199 loss_ctc_origin 31.547333 loss_ctc0 92.406883 lr 0.00058050 rank 0
2022-08-26 13:46:07,910 DEBUG TRAIN Batch 208/4000 loss 50.049236 loss_att 32.139545 loss_ctc 91.838516 loss_ctc_origin 58.433483 loss_ctc0 169.783569 lr 0.00058048 rank 0
2022-08-26 13:46:35,781 DEBUG TRAIN Batch 208/4100 loss 62.608009 loss_att 34.277473 loss_ctc 128.712585 loss_ctc_origin 70.530777 loss_ctc0 264.470093 lr 0.00058045 rank 0
2022-08-26 13:47:03,799 DEBUG TRAIN Batch 208/4200 loss 19.216543 loss_att 9.064486 loss_ctc 42.904678 loss_ctc_origin 29.678555 loss_ctc0 73.765633 lr 0.00058043 rank 0
2022-08-26 13:47:15,214 WARNING NaN or Inf found in input tensor.
2022-08-26 13:47:31,568 DEBUG TRAIN Batch 208/4300 loss 16.916323 loss_att 6.553276 loss_ctc 41.096764 loss_ctc_origin 25.314121 loss_ctc0 77.922928 lr 0.00058040 rank 0
2022-08-26 13:48:00,106 DEBUG TRAIN Batch 208/4400 loss 20.854733 loss_att 7.649480 loss_ctc 51.666985 loss_ctc_origin 31.881649 loss_ctc0 97.832756 lr 0.00058038 rank 0
2022-08-26 13:48:33,298 DEBUG TRAIN Batch 208/4500 loss 49.953247 loss_att 31.742458 loss_ctc 92.445084 loss_ctc_origin 60.884102 loss_ctc0 166.087387 lr 0.00058035 rank 0
2022-08-26 13:49:01,537 DEBUG TRAIN Batch 208/4600 loss 66.401703 loss_att 34.689568 loss_ctc 140.396667 loss_ctc_origin 84.669319 loss_ctc0 270.427124 lr 0.00058033 rank 0
2022-08-26 13:49:29,151 DEBUG TRAIN Batch 208/4700 loss 17.149029 loss_att 8.445202 loss_ctc 37.457954 loss_ctc_origin 26.083834 loss_ctc0 63.997574 lr 0.00058031 rank 0
2022-08-26 13:49:41,318 WARNING NaN or Inf found in input tensor.
2022-08-26 13:49:57,222 DEBUG TRAIN Batch 208/4800 loss 16.729671 loss_att 7.363156 loss_ctc 38.584873 loss_ctc_origin 24.263790 loss_ctc0 72.000732 lr 0.00058028 rank 0
2022-08-26 13:50:24,446 DEBUG TRAIN Batch 208/4900 loss 20.796753 loss_att 8.557027 loss_ctc 49.356110 loss_ctc_origin 30.186726 loss_ctc0 94.084671 lr 0.00058026 rank 0
2022-08-26 13:50:52,799 DEBUG TRAIN Batch 208/5000 loss 55.610527 loss_att 34.311829 loss_ctc 105.307495 loss_ctc_origin 68.951538 loss_ctc0 190.138077 lr 0.00058023 rank 0
2022-08-26 13:51:00,717 WARNING NaN or Inf found in input tensor.
2022-08-26 13:51:20,372 DEBUG TRAIN Batch 208/5100 loss 62.836029 loss_att 35.067181 loss_ctc 127.630013 loss_ctc_origin 74.472046 loss_ctc0 251.665268 lr 0.00058021 rank 0
2022-08-26 13:51:47,842 DEBUG TRAIN Batch 208/5200 loss 18.266033 loss_att 9.179217 loss_ctc 39.468597 loss_ctc_origin 26.833485 loss_ctc0 68.950516 lr 0.00058018 rank 0
2022-08-26 13:52:14,981 DEBUG TRAIN Batch 208/5300 loss 17.991562 loss_att 6.780205 loss_ctc 44.151398 loss_ctc_origin 27.996096 loss_ctc0 81.847099 lr 0.00058016 rank 0
2022-08-26 13:52:44,159 DEBUG TRAIN Batch 208/5400 loss 18.616859 loss_att 7.171377 loss_ctc 45.322983 loss_ctc_origin 24.874020 loss_ctc0 93.037231 lr 0.00058013 rank 0
2022-08-26 13:53:12,487 DEBUG TRAIN Batch 208/5500 loss 27.002066 loss_att 20.432825 loss_ctc 42.330292 loss_ctc_origin 39.502579 loss_ctc0 48.928284 lr 0.00058011 rank 0
2022-08-26 13:53:38,894 DEBUG TRAIN Batch 208/5600 loss 57.003330 loss_att 32.072140 loss_ctc 115.176102 loss_ctc_origin 61.061188 loss_ctc0 241.444214 lr 0.00058009 rank 0
2022-08-26 13:54:00,481 DEBUG CV Batch 208/0 loss 11.512617 loss_att 8.346976 loss_ctc 18.899113 loss_ctc_origin 12.254232 loss_ctc0 34.403831 history loss 10.835404 rank 0
2022-08-26 13:54:11,156 DEBUG CV Batch 208/100 loss 20.834803 loss_att 16.812643 loss_ctc 30.219841 loss_ctc_origin 20.321260 loss_ctc0 53.316525 history loss 26.223511 rank 0
2022-08-26 13:54:20,911 DEBUG CV Batch 208/200 loss 24.073334 loss_att 18.685465 loss_ctc 36.645027 loss_ctc_origin 25.872992 loss_ctc0 61.779785 history loss 27.479704 rank 0
2022-08-26 13:54:31,053 DEBUG CV Batch 208/300 loss 21.988865 loss_att 16.554493 loss_ctc 34.669060 loss_ctc_origin 19.004173 loss_ctc0 71.220459 history loss 26.567204 rank 0
2022-08-26 13:54:41,601 DEBUG CV Batch 208/400 loss 37.610065 loss_att 30.434059 loss_ctc 54.354080 loss_ctc_origin 37.241920 loss_ctc0 94.282448 history loss 24.867005 rank 0
2022-08-26 13:54:52,177 DEBUG CV Batch 208/500 loss 16.358307 loss_att 12.075277 loss_ctc 26.352039 loss_ctc_origin 19.505989 loss_ctc0 42.326157 history loss 24.519680 rank 0
2022-08-26 13:55:02,571 DEBUG CV Batch 208/600 loss 17.147247 loss_att 12.185335 loss_ctc 28.725037 loss_ctc_origin 18.003525 loss_ctc0 53.741898 history loss 24.339865 rank 0
2022-08-26 13:55:12,463 DEBUG CV Batch 208/700 loss 18.052509 loss_att 12.610123 loss_ctc 30.751413 loss_ctc_origin 16.695034 loss_ctc0 63.549633 history loss 23.989765 rank 0
2022-08-26 13:55:22,717 DEBUG CV Batch 208/800 loss 22.148594 loss_att 17.294121 loss_ctc 33.475700 loss_ctc_origin 18.162243 loss_ctc0 69.207100 history loss 23.951652 rank 0
2022-08-26 13:55:32,829 INFO Epoch 208 CV info cv_loss 24.048640680036865
2022-08-26 13:55:32,829 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/208.pt
2022-08-26 13:55:33,294 INFO Epoch 209 TRAIN info lr 0.0005800655302240434
2022-08-26 13:55:33,297 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 13:55:58,560 DEBUG TRAIN Batch 209/0 loss 38.682800 loss_att 25.553596 loss_ctc 69.317596 loss_ctc_origin 44.177170 loss_ctc0 127.978577 lr 0.00058006 rank 0
2022-08-26 13:56:25,803 DEBUG TRAIN Batch 209/100 loss 57.923462 loss_att 31.481676 loss_ctc 119.620956 loss_ctc_origin 68.474030 loss_ctc0 238.963791 lr 0.00058004 rank 0
2022-08-26 13:56:54,360 DEBUG TRAIN Batch 209/200 loss 20.819511 loss_att 13.239452 loss_ctc 38.506317 loss_ctc_origin 27.788778 loss_ctc0 63.513901 lr 0.00058002 rank 0
2022-08-26 13:57:22,446 DEBUG TRAIN Batch 209/300 loss 18.204927 loss_att 7.672502 loss_ctc 42.780586 loss_ctc_origin 29.320726 loss_ctc0 74.186935 lr 0.00057999 rank 0
2022-08-26 13:57:50,425 DEBUG TRAIN Batch 209/400 loss 23.984913 loss_att 11.202795 loss_ctc 53.809849 loss_ctc_origin 35.177498 loss_ctc0 97.285332 lr 0.00057997 rank 0
2022-08-26 13:58:17,722 DEBUG TRAIN Batch 209/500 loss 40.645355 loss_att 25.313568 loss_ctc 76.419518 loss_ctc_origin 47.827072 loss_ctc0 143.135223 lr 0.00057994 rank 0
2022-08-26 13:58:46,285 DEBUG TRAIN Batch 209/600 loss 64.813705 loss_att 37.695541 loss_ctc 128.089417 loss_ctc_origin 75.683716 loss_ctc0 250.369354 lr 0.00057992 rank 0
2022-08-26 13:59:13,490 DEBUG TRAIN Batch 209/700 loss 20.150673 loss_att 12.474949 loss_ctc 38.060699 loss_ctc_origin 29.042635 loss_ctc0 59.102859 lr 0.00057989 rank 0
2022-08-26 13:59:19,747 WARNING NaN or Inf found in input tensor.
2022-08-26 13:59:40,704 DEBUG TRAIN Batch 209/800 loss 19.682524 loss_att 9.193047 loss_ctc 44.157967 loss_ctc_origin 30.154480 loss_ctc0 76.832771 lr 0.00057987 rank 0
2022-08-26 14:00:08,631 DEBUG TRAIN Batch 209/900 loss 23.944401 loss_att 10.395561 loss_ctc 55.558357 loss_ctc_origin 36.633095 loss_ctc0 99.717300 lr 0.00057985 rank 0
2022-08-26 14:00:34,487 DEBUG TRAIN Batch 209/1000 loss 49.268623 loss_att 30.553810 loss_ctc 92.936523 loss_ctc_origin 55.841286 loss_ctc0 179.492096 lr 0.00057982 rank 0
2022-08-26 14:01:01,956 DEBUG TRAIN Batch 209/1100 loss 61.273338 loss_att 33.147293 loss_ctc 126.900780 loss_ctc_origin 77.011993 loss_ctc0 243.307953 lr 0.00057980 rank 0
2022-08-26 14:01:30,427 DEBUG TRAIN Batch 209/1200 loss 23.506889 loss_att 11.309880 loss_ctc 51.966576 loss_ctc_origin 43.337360 loss_ctc0 72.101410 lr 0.00057977 rank 0
2022-08-26 14:01:58,458 DEBUG TRAIN Batch 209/1300 loss 20.774433 loss_att 7.700057 loss_ctc 51.281311 loss_ctc_origin 34.601791 loss_ctc0 90.200180 lr 0.00057975 rank 0
2022-08-26 14:02:25,420 DEBUG TRAIN Batch 209/1400 loss 19.464706 loss_att 8.109120 loss_ctc 45.961071 loss_ctc_origin 25.470005 loss_ctc0 93.773560 lr 0.00057972 rank 0
2022-08-26 14:03:00,421 DEBUG TRAIN Batch 209/1500 loss 56.083130 loss_att 33.785572 loss_ctc 108.110771 loss_ctc_origin 72.284653 loss_ctc0 191.705048 lr 0.00057970 rank 0
2022-08-26 14:03:14,857 WARNING NaN or Inf found in input tensor.
2022-08-26 14:03:28,088 DEBUG TRAIN Batch 209/1600 loss 58.209396 loss_att 30.055563 loss_ctc 123.901672 loss_ctc_origin 66.818253 loss_ctc0 257.096313 lr 0.00057967 rank 0
2022-08-26 14:03:55,808 DEBUG TRAIN Batch 209/1700 loss 19.732798 loss_att 9.612347 loss_ctc 43.347183 loss_ctc_origin 30.706734 loss_ctc0 72.841568 lr 0.00057965 rank 0
2022-08-26 14:04:22,982 DEBUG TRAIN Batch 209/1800 loss 18.023487 loss_att 6.585499 loss_ctc 44.712128 loss_ctc_origin 28.316677 loss_ctc0 82.968170 lr 0.00057963 rank 0
2022-08-26 14:04:51,083 DEBUG TRAIN Batch 209/1900 loss 21.450914 loss_att 8.788960 loss_ctc 50.995472 loss_ctc_origin 31.855995 loss_ctc0 95.654251 lr 0.00057960 rank 0
2022-08-26 14:05:19,946 DEBUG TRAIN Batch 209/2000 loss 52.213524 loss_att 36.054199 loss_ctc 89.918610 loss_ctc_origin 60.955940 loss_ctc0 157.498169 lr 0.00057958 rank 0
2022-08-26 14:05:47,749 DEBUG TRAIN Batch 209/2100 loss 68.146530 loss_att 38.236526 loss_ctc 137.936554 loss_ctc_origin 83.105988 loss_ctc0 265.874512 lr 0.00057955 rank 0
2022-08-26 14:06:14,242 DEBUG TRAIN Batch 209/2200 loss 18.334385 loss_att 10.286695 loss_ctc 37.112324 loss_ctc_origin 25.506351 loss_ctc0 64.192924 lr 0.00057953 rank 0
2022-08-26 14:06:41,694 DEBUG TRAIN Batch 209/2300 loss 16.509670 loss_att 6.726492 loss_ctc 39.337086 loss_ctc_origin 23.899799 loss_ctc0 75.357422 lr 0.00057950 rank 0
2022-08-26 14:07:09,830 DEBUG TRAIN Batch 209/2400 loss 23.192245 loss_att 9.288899 loss_ctc 55.633381 loss_ctc_origin 37.823517 loss_ctc0 97.189728 lr 0.00057948 rank 0
2022-08-26 14:07:30,882 WARNING NaN or Inf found in input tensor.
2022-08-26 14:07:37,599 DEBUG TRAIN Batch 209/2500 loss 52.224846 loss_att 32.739029 loss_ctc 97.691750 loss_ctc_origin 63.595673 loss_ctc0 177.249252 lr 0.00057946 rank 0
2022-08-26 14:08:05,036 DEBUG TRAIN Batch 209/2600 loss 73.291367 loss_att 44.144547 loss_ctc 141.300598 loss_ctc_origin 89.025757 loss_ctc0 263.275238 lr 0.00057943 rank 0
2022-08-26 14:08:33,328 DEBUG TRAIN Batch 209/2700 loss 18.903090 loss_att 9.715720 loss_ctc 40.340282 loss_ctc_origin 27.488976 loss_ctc0 70.326660 lr 0.00057941 rank 0
2022-08-26 14:09:00,472 DEBUG TRAIN Batch 209/2800 loss 22.418024 loss_att 9.186228 loss_ctc 53.292213 loss_ctc_origin 39.038338 loss_ctc0 86.551254 lr 0.00057938 rank 0
2022-08-26 14:09:16,866 WARNING NaN or Inf found in input tensor.
2022-08-26 14:09:23,397 WARNING NaN or Inf found in input tensor.
2022-08-26 14:09:27,404 DEBUG TRAIN Batch 209/2900 loss 22.309898 loss_att 8.726410 loss_ctc 54.004707 loss_ctc_origin 33.306511 loss_ctc0 102.300491 lr 0.00057936 rank 0
2022-08-26 14:09:37,069 WARNING NaN or Inf found in input tensor.
2022-08-26 14:10:03,478 DEBUG TRAIN Batch 209/3000 loss 51.753944 loss_att 31.851276 loss_ctc 98.193497 loss_ctc_origin 64.932663 loss_ctc0 175.802109 lr 0.00057933 rank 0
2022-08-26 14:10:31,092 DEBUG TRAIN Batch 209/3100 loss 64.614555 loss_att 38.469368 loss_ctc 125.619980 loss_ctc_origin 75.442154 loss_ctc0 242.701569 lr 0.00057931 rank 0
2022-08-26 14:10:58,415 DEBUG TRAIN Batch 209/3200 loss 22.073780 loss_att 11.576292 loss_ctc 46.567917 loss_ctc_origin 35.339352 loss_ctc0 72.767899 lr 0.00057929 rank 0
2022-08-26 14:11:26,035 DEBUG TRAIN Batch 209/3300 loss 19.100817 loss_att 7.599010 loss_ctc 45.938362 loss_ctc_origin 31.317427 loss_ctc0 80.053864 lr 0.00057926 rank 0
2022-08-26 14:11:53,429 DEBUG TRAIN Batch 209/3400 loss 19.986679 loss_att 8.385698 loss_ctc 47.055634 loss_ctc_origin 29.293627 loss_ctc0 88.500305 lr 0.00057924 rank 0
2022-08-26 14:12:21,238 DEBUG TRAIN Batch 209/3500 loss 54.264938 loss_att 36.837959 loss_ctc 94.927887 loss_ctc_origin 59.454582 loss_ctc0 177.698914 lr 0.00057921 rank 0
2022-08-26 14:12:48,287 DEBUG TRAIN Batch 209/3600 loss 61.355713 loss_att 33.030746 loss_ctc 127.447296 loss_ctc_origin 76.937775 loss_ctc0 245.302826 lr 0.00057919 rank 0
2022-08-26 14:13:16,082 DEBUG TRAIN Batch 209/3700 loss 21.208841 loss_att 9.699293 loss_ctc 48.064453 loss_ctc_origin 37.378792 loss_ctc0 72.997665 lr 0.00057916 rank 0
2022-08-26 14:13:44,650 DEBUG TRAIN Batch 209/3800 loss 18.174746 loss_att 7.846284 loss_ctc 42.274490 loss_ctc_origin 27.452042 loss_ctc0 76.860199 lr 0.00057914 rank 0
2022-08-26 14:14:14,044 DEBUG TRAIN Batch 209/3900 loss 19.161142 loss_att 7.897591 loss_ctc 45.442764 loss_ctc_origin 25.151360 loss_ctc0 92.789375 lr 0.00057912 rank 0
2022-08-26 14:14:41,339 DEBUG TRAIN Batch 209/4000 loss 50.632332 loss_att 34.842209 loss_ctc 87.475952 loss_ctc_origin 59.414646 loss_ctc0 152.952332 lr 0.00057909 rank 0
2022-08-26 14:15:07,514 DEBUG TRAIN Batch 209/4100 loss 67.095345 loss_att 40.780273 loss_ctc 128.497177 loss_ctc_origin 81.020111 loss_ctc0 239.276978 lr 0.00057907 rank 0
2022-08-26 14:15:33,749 WARNING NaN or Inf found in input tensor.
2022-08-26 14:15:35,400 DEBUG TRAIN Batch 209/4200 loss 18.856972 loss_att 8.021641 loss_ctc 44.139404 loss_ctc_origin 33.844093 loss_ctc0 68.161789 lr 0.00057904 rank 0
2022-08-26 14:16:03,780 DEBUG TRAIN Batch 209/4300 loss 18.531155 loss_att 7.201799 loss_ctc 44.966316 loss_ctc_origin 29.014229 loss_ctc0 82.187859 lr 0.00057902 rank 0
2022-08-26 14:16:27,134 WARNING NaN or Inf found in input tensor.
2022-08-26 14:16:31,587 DEBUG TRAIN Batch 209/4400 loss 20.168184 loss_att 8.026814 loss_ctc 48.498047 loss_ctc_origin 30.236111 loss_ctc0 91.109222 lr 0.00057899 rank 0
2022-08-26 14:17:03,534 DEBUG TRAIN Batch 209/4500 loss 45.579418 loss_att 28.985706 loss_ctc 84.298080 loss_ctc_origin 51.286125 loss_ctc0 161.325958 lr 0.00057897 rank 0
2022-08-26 14:17:31,714 DEBUG TRAIN Batch 209/4600 loss 56.722595 loss_att 32.741112 loss_ctc 112.679390 loss_ctc_origin 69.174500 loss_ctc0 214.190796 lr 0.00057895 rank 0
2022-08-26 14:17:59,246 DEBUG TRAIN Batch 209/4700 loss 16.957020 loss_att 8.381551 loss_ctc 36.966446 loss_ctc_origin 25.189102 loss_ctc0 64.446915 lr 0.00057892 rank 0
2022-08-26 14:18:26,903 DEBUG TRAIN Batch 209/4800 loss 18.094578 loss_att 7.570744 loss_ctc 42.650185 loss_ctc_origin 28.998104 loss_ctc0 74.505035 lr 0.00057890 rank 0
2022-08-26 14:18:55,406 DEBUG TRAIN Batch 209/4900 loss 21.589771 loss_att 8.825560 loss_ctc 51.372932 loss_ctc_origin 31.206337 loss_ctc0 98.428314 lr 0.00057887 rank 0
2022-08-26 14:19:24,177 DEBUG TRAIN Batch 209/5000 loss 52.342995 loss_att 35.670734 loss_ctc 91.244926 loss_ctc_origin 55.557678 loss_ctc0 174.515167 lr 0.00057885 rank 0
2022-08-26 14:19:31,132 WARNING NaN or Inf found in input tensor.
2022-08-26 14:19:52,089 DEBUG TRAIN Batch 209/5100 loss 66.507133 loss_att 40.201778 loss_ctc 127.886292 loss_ctc_origin 84.712845 loss_ctc0 228.624344 lr 0.00057882 rank 0
2022-08-26 14:20:18,214 DEBUG TRAIN Batch 209/5200 loss 17.928188 loss_att 10.236758 loss_ctc 35.874863 loss_ctc_origin 22.311302 loss_ctc0 67.523170 lr 0.00057880 rank 0
2022-08-26 14:20:46,980 DEBUG TRAIN Batch 209/5300 loss 16.008543 loss_att 6.494621 loss_ctc 38.207695 loss_ctc_origin 23.983063 loss_ctc0 71.398499 lr 0.00057878 rank 0
2022-08-26 14:21:14,514 DEBUG TRAIN Batch 209/5400 loss 19.078888 loss_att 7.509490 loss_ctc 46.074150 loss_ctc_origin 29.796772 loss_ctc0 84.054703 lr 0.00057875 rank 0
2022-08-26 14:21:42,202 DEBUG TRAIN Batch 209/5500 loss 54.536736 loss_att 35.135406 loss_ctc 99.806503 loss_ctc_origin 72.255486 loss_ctc0 164.092209 lr 0.00057873 rank 0
2022-08-26 14:22:09,355 DEBUG TRAIN Batch 209/5600 loss 57.034615 loss_att 32.536514 loss_ctc 114.196846 loss_ctc_origin 67.584274 loss_ctc0 222.959503 lr 0.00057870 rank 0
2022-08-26 14:22:30,965 DEBUG CV Batch 209/0 loss 12.706617 loss_att 9.801098 loss_ctc 19.486164 loss_ctc_origin 13.240528 loss_ctc0 34.059311 history loss 11.959169 rank 0
2022-08-26 14:22:41,451 DEBUG CV Batch 209/100 loss 20.484087 loss_att 16.274509 loss_ctc 30.306435 loss_ctc_origin 20.599758 loss_ctc0 52.955345 history loss 26.691533 rank 0
2022-08-26 14:22:51,000 DEBUG CV Batch 209/200 loss 25.350607 loss_att 19.775694 loss_ctc 38.358738 loss_ctc_origin 27.981504 loss_ctc0 62.572281 history loss 28.054536 rank 0
2022-08-26 14:23:00,711 DEBUG CV Batch 209/300 loss 22.665741 loss_att 17.294752 loss_ctc 35.198051 loss_ctc_origin 19.583294 loss_ctc0 71.632492 history loss 27.116779 rank 0
2022-08-26 14:23:11,039 DEBUG CV Batch 209/400 loss 38.939133 loss_att 31.552647 loss_ctc 56.174255 loss_ctc_origin 39.822853 loss_ctc0 94.327515 history loss 25.447429 rank 0
2022-08-26 14:23:21,912 DEBUG CV Batch 209/500 loss 16.515434 loss_att 11.936223 loss_ctc 27.200258 loss_ctc_origin 20.695860 loss_ctc0 42.377186 history loss 25.114747 rank 0
2022-08-26 14:23:32,045 DEBUG CV Batch 209/600 loss 18.133350 loss_att 13.167835 loss_ctc 29.719547 loss_ctc_origin 19.430149 loss_ctc0 53.728146 history loss 24.975442 rank 0
2022-08-26 14:23:41,949 DEBUG CV Batch 209/700 loss 18.845825 loss_att 13.572579 loss_ctc 31.150061 loss_ctc_origin 17.661449 loss_ctc0 62.623486 history loss 24.657078 rank 0
2022-08-26 14:23:52,149 DEBUG CV Batch 209/800 loss 21.559208 loss_att 16.756786 loss_ctc 32.764858 loss_ctc_origin 17.638130 loss_ctc0 68.060555 history loss 24.610973 rank 0
2022-08-26 14:24:03,118 INFO Epoch 209 CV info cv_loss 24.67611251333682
2022-08-26 14:24:03,119 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/209.pt
2022-08-26 14:24:03,602 INFO Epoch 210 TRAIN info lr 0.0005786827737156788
2022-08-26 14:24:03,605 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 14:24:29,707 DEBUG TRAIN Batch 210/0 loss 38.188190 loss_att 24.776134 loss_ctc 69.482986 loss_ctc_origin 45.346600 loss_ctc0 125.801208 lr 0.00057868 rank 0
2022-08-26 14:24:57,158 DEBUG TRAIN Batch 210/100 loss 61.186752 loss_att 34.238602 loss_ctc 124.065781 loss_ctc_origin 82.889793 loss_ctc0 220.143082 lr 0.00057866 rank 0
2022-08-26 14:25:24,616 DEBUG TRAIN Batch 210/200 loss 17.677780 loss_att 7.890774 loss_ctc 40.514126 loss_ctc_origin 28.480137 loss_ctc0 68.593430 lr 0.00057863 rank 0
2022-08-26 14:25:51,452 DEBUG TRAIN Batch 210/300 loss 18.537525 loss_att 8.204441 loss_ctc 42.648048 loss_ctc_origin 27.774937 loss_ctc0 77.351974 lr 0.00057861 rank 0
2022-08-26 14:26:20,169 DEBUG TRAIN Batch 210/400 loss 18.871893 loss_att 7.523995 loss_ctc 45.350319 loss_ctc_origin 25.129444 loss_ctc0 92.532349 lr 0.00057858 rank 0
2022-08-26 14:26:48,870 DEBUG TRAIN Batch 210/500 loss 50.140175 loss_att 33.282654 loss_ctc 89.474396 loss_ctc_origin 59.861366 loss_ctc0 158.571472 lr 0.00057856 rank 0
2022-08-26 14:27:16,060 DEBUG TRAIN Batch 210/600 loss 60.249191 loss_att 32.627724 loss_ctc 124.699265 loss_ctc_origin 77.922241 loss_ctc0 233.845642 lr 0.00057854 rank 0
2022-08-26 14:27:43,187 DEBUG TRAIN Batch 210/700 loss 17.987425 loss_att 8.741078 loss_ctc 39.562233 loss_ctc_origin 28.149353 loss_ctc0 66.192291 lr 0.00057851 rank 0
2022-08-26 14:28:10,819 DEBUG TRAIN Batch 210/800 loss 18.125496 loss_att 7.583111 loss_ctc 42.724392 loss_ctc_origin 27.182947 loss_ctc0 78.987762 lr 0.00057849 rank 0
2022-08-26 14:28:39,750 DEBUG TRAIN Batch 210/900 loss 20.309147 loss_att 7.786242 loss_ctc 49.529259 loss_ctc_origin 31.914131 loss_ctc0 90.631226 lr 0.00057846 rank 0
2022-08-26 14:29:06,621 DEBUG TRAIN Batch 210/1000 loss 46.989563 loss_att 28.851814 loss_ctc 89.310974 loss_ctc_origin 51.952785 loss_ctc0 176.480057 lr 0.00057844 rank 0
2022-08-26 14:29:34,262 DEBUG TRAIN Batch 210/1100 loss 65.809868 loss_att 39.017570 loss_ctc 128.325211 loss_ctc_origin 82.122810 loss_ctc0 236.130829 lr 0.00057842 rank 0
2022-08-26 14:30:02,016 DEBUG TRAIN Batch 210/1200 loss 19.697237 loss_att 10.065322 loss_ctc 42.171703 loss_ctc_origin 29.155006 loss_ctc0 72.543991 lr 0.00057839 rank 0
2022-08-26 14:30:30,594 DEBUG TRAIN Batch 210/1300 loss 19.246500 loss_att 7.056136 loss_ctc 47.690681 loss_ctc_origin 34.765450 loss_ctc0 77.849564 lr 0.00057837 rank 0
2022-08-26 14:30:55,901 WARNING NaN or Inf found in input tensor.
2022-08-26 14:31:00,292 DEBUG TRAIN Batch 210/1400 loss 20.875937 loss_att 8.107906 loss_ctc 50.668007 loss_ctc_origin 30.235035 loss_ctc0 98.344940 lr 0.00057834 rank 0
2022-08-26 14:31:31,071 DEBUG TRAIN Batch 210/1500 loss 48.985199 loss_att 33.691399 loss_ctc 84.670731 loss_ctc_origin 55.660828 loss_ctc0 152.360519 lr 0.00057832 rank 0
2022-08-26 14:31:45,577 WARNING NaN or Inf found in input tensor.
2022-08-26 14:31:58,497 DEBUG TRAIN Batch 210/1600 loss 59.008537 loss_att 32.209187 loss_ctc 121.540344 loss_ctc_origin 74.809700 loss_ctc0 230.578506 lr 0.00057829 rank 0
2022-08-26 14:32:10,699 WARNING NaN or Inf found in input tensor.
2022-08-26 14:32:25,779 DEBUG TRAIN Batch 210/1700 loss 17.470142 loss_att 9.120672 loss_ctc 36.952240 loss_ctc_origin 24.591415 loss_ctc0 65.794159 lr 0.00057827 rank 0
2022-08-26 14:32:53,295 DEBUG TRAIN Batch 210/1800 loss 14.704144 loss_att 5.755343 loss_ctc 35.584675 loss_ctc_origin 22.162155 loss_ctc0 66.903885 lr 0.00057825 rank 0
2022-08-26 14:33:21,540 DEBUG TRAIN Batch 210/1900 loss 21.460907 loss_att 7.984172 loss_ctc 52.906624 loss_ctc_origin 33.053490 loss_ctc0 99.230606 lr 0.00057822 rank 0
2022-08-26 14:33:50,181 DEBUG TRAIN Batch 210/2000 loss 54.885704 loss_att 37.995152 loss_ctc 94.296997 loss_ctc_origin 66.362358 loss_ctc0 159.477814 lr 0.00057820 rank 0
2022-08-26 14:34:18,133 DEBUG TRAIN Batch 210/2100 loss 62.097389 loss_att 37.156937 loss_ctc 120.291779 loss_ctc_origin 66.948135 loss_ctc0 244.760284 lr 0.00057817 rank 0
2022-08-26 14:34:45,139 DEBUG TRAIN Batch 210/2200 loss 20.941757 loss_att 9.262618 loss_ctc 48.193077 loss_ctc_origin 39.654793 loss_ctc0 68.115738 lr 0.00057815 rank 0
2022-08-26 14:35:12,825 DEBUG TRAIN Batch 210/2300 loss 17.776449 loss_att 6.885236 loss_ctc 43.189278 loss_ctc_origin 27.891062 loss_ctc0 78.885109 lr 0.00057813 rank 0
2022-08-26 14:35:41,577 DEBUG TRAIN Batch 210/2400 loss 18.604546 loss_att 6.678047 loss_ctc 46.433044 loss_ctc_origin 28.490654 loss_ctc0 88.298630 lr 0.00057810 rank 0
2022-08-26 14:36:08,048 DEBUG TRAIN Batch 210/2500 loss 45.394588 loss_att 28.767544 loss_ctc 84.191025 loss_ctc_origin 53.096031 loss_ctc0 156.746002 lr 0.00057808 rank 0
2022-08-26 14:36:34,857 DEBUG TRAIN Batch 210/2600 loss 59.906525 loss_att 33.085003 loss_ctc 122.490074 loss_ctc_origin 80.099792 loss_ctc0 221.400726 lr 0.00057805 rank 0
2022-08-26 14:36:54,868 WARNING NaN or Inf found in input tensor.
2022-08-26 14:37:03,879 DEBUG TRAIN Batch 210/2700 loss 19.520926 loss_att 10.077484 loss_ctc 41.555618 loss_ctc_origin 28.655212 loss_ctc0 71.656563 lr 0.00057803 rank 0
2022-08-26 14:37:32,641 DEBUG TRAIN Batch 210/2800 loss 20.461960 loss_att 8.456614 loss_ctc 48.474426 loss_ctc_origin 31.916145 loss_ctc0 87.110413 lr 0.00057800 rank 0
2022-08-26 14:37:58,559 DEBUG TRAIN Batch 210/2900 loss 20.551792 loss_att 8.592248 loss_ctc 48.457394 loss_ctc_origin 28.978897 loss_ctc0 93.907219 lr 0.00057798 rank 0
2022-08-26 14:38:32,226 DEBUG TRAIN Batch 210/3000 loss 50.680779 loss_att 33.746086 loss_ctc 90.195068 loss_ctc_origin 61.194435 loss_ctc0 157.863190 lr 0.00057796 rank 0
2022-08-26 14:38:46,779 WARNING NaN or Inf found in input tensor.
2022-08-26 14:38:59,956 DEBUG TRAIN Batch 210/3100 loss 61.587383 loss_att 35.238468 loss_ctc 123.068176 loss_ctc_origin 72.256737 loss_ctc0 241.628174 lr 0.00057793 rank 0
2022-08-26 14:39:28,095 DEBUG TRAIN Batch 210/3200 loss 15.596441 loss_att 6.782733 loss_ctc 36.161758 loss_ctc_origin 23.693317 loss_ctc0 65.254784 lr 0.00057791 rank 0
2022-08-26 14:39:54,799 DEBUG TRAIN Batch 210/3300 loss 20.647791 loss_att 7.936672 loss_ctc 50.307068 loss_ctc_origin 34.732086 loss_ctc0 86.648697 lr 0.00057788 rank 0
2022-08-26 14:40:22,532 DEBUG TRAIN Batch 210/3400 loss 21.984364 loss_att 9.427139 loss_ctc 51.284554 loss_ctc_origin 33.940201 loss_ctc0 91.754715 lr 0.00057786 rank 0
2022-08-26 14:40:50,741 DEBUG TRAIN Batch 210/3500 loss 49.250374 loss_att 31.529903 loss_ctc 90.598129 loss_ctc_origin 57.554558 loss_ctc0 167.699799 lr 0.00057784 rank 0
2022-08-26 14:41:17,678 DEBUG TRAIN Batch 210/3600 loss 66.698959 loss_att 42.204880 loss_ctc 123.851799 loss_ctc_origin 75.073769 loss_ctc0 237.667206 lr 0.00057781 rank 0
2022-08-26 14:41:45,087 DEBUG TRAIN Batch 210/3700 loss 20.381996 loss_att 9.777761 loss_ctc 45.125214 loss_ctc_origin 33.882973 loss_ctc0 71.357117 lr 0.00057779 rank 0
2022-08-26 14:42:12,702 DEBUG TRAIN Batch 210/3800 loss 16.126076 loss_att 6.958890 loss_ctc 37.516174 loss_ctc_origin 23.984859 loss_ctc0 69.089241 lr 0.00057776 rank 0
2022-08-26 14:42:40,415 DEBUG TRAIN Batch 210/3900 loss 19.900286 loss_att 7.620726 loss_ctc 48.552589 loss_ctc_origin 30.406139 loss_ctc0 90.894295 lr 0.00057774 rank 0
2022-08-26 14:43:08,583 DEBUG TRAIN Batch 210/4000 loss 62.042511 loss_att 44.510742 loss_ctc 102.949966 loss_ctc_origin 74.320953 loss_ctc0 169.750977 lr 0.00057772 rank 0
2022-08-26 14:43:36,135 DEBUG TRAIN Batch 210/4100 loss 65.891518 loss_att 37.348965 loss_ctc 132.490799 loss_ctc_origin 86.718353 loss_ctc0 239.293152 lr 0.00057769 rank 0
2022-08-26 14:44:04,352 DEBUG TRAIN Batch 210/4200 loss 17.859947 loss_att 8.898872 loss_ctc 38.769119 loss_ctc_origin 25.764898 loss_ctc0 69.112297 lr 0.00057767 rank 0
2022-08-26 14:44:31,816 DEBUG TRAIN Batch 210/4300 loss 17.520214 loss_att 6.022468 loss_ctc 44.348286 loss_ctc_origin 29.538567 loss_ctc0 78.904297 lr 0.00057764 rank 0
2022-08-26 14:44:47,565 WARNING NaN or Inf found in input tensor.
2022-08-26 14:44:58,512 DEBUG TRAIN Batch 210/4400 loss 17.661613 loss_att 6.965503 loss_ctc 42.619202 loss_ctc_origin 22.738592 loss_ctc0 89.007294 lr 0.00057762 rank 0
2022-08-26 14:45:32,387 DEBUG TRAIN Batch 210/4500 loss 54.674797 loss_att 38.930740 loss_ctc 91.410919 loss_ctc_origin 64.321152 loss_ctc0 154.620361 lr 0.00057759 rank 0
2022-08-26 14:46:00,211 DEBUG TRAIN Batch 210/4600 loss 62.038872 loss_att 37.993782 loss_ctc 118.144081 loss_ctc_origin 65.461349 loss_ctc0 241.070435 lr 0.00057757 rank 0
2022-08-26 14:46:27,989 DEBUG TRAIN Batch 210/4700 loss 19.696886 loss_att 9.036745 loss_ctc 44.570545 loss_ctc_origin 30.932650 loss_ctc0 76.392296 lr 0.00057755 rank 0
2022-08-26 14:46:56,797 DEBUG TRAIN Batch 210/4800 loss 17.922098 loss_att 7.821605 loss_ctc 41.489914 loss_ctc_origin 28.495697 loss_ctc0 71.809746 lr 0.00057752 rank 0
2022-08-26 14:47:08,346 WARNING NaN or Inf found in input tensor.
2022-08-26 14:47:23,927 DEBUG TRAIN Batch 210/4900 loss 19.077068 loss_att 6.989749 loss_ctc 47.280815 loss_ctc_origin 28.895813 loss_ctc0 90.179146 lr 0.00057750 rank 0
2022-08-26 14:47:51,491 DEBUG TRAIN Batch 210/5000 loss 54.790726 loss_att 39.181877 loss_ctc 91.211365 loss_ctc_origin 66.546707 loss_ctc0 148.762238 lr 0.00057747 rank 0
2022-08-26 14:48:19,450 DEBUG TRAIN Batch 210/5100 loss 61.467278 loss_att 38.027897 loss_ctc 116.159172 loss_ctc_origin 73.370407 loss_ctc0 215.999619 lr 0.00057745 rank 0
2022-08-26 14:48:46,864 DEBUG TRAIN Batch 210/5200 loss 21.475361 loss_att 10.425402 loss_ctc 47.258598 loss_ctc_origin 38.473614 loss_ctc0 67.756897 lr 0.00057743 rank 0
2022-08-26 14:49:13,965 DEBUG TRAIN Batch 210/5300 loss 15.540151 loss_att 6.372140 loss_ctc 36.932175 loss_ctc_origin 22.839657 loss_ctc0 69.814713 lr 0.00057740 rank 0
2022-08-26 14:49:41,605 DEBUG TRAIN Batch 210/5400 loss 19.338438 loss_att 7.338686 loss_ctc 47.337856 loss_ctc_origin 31.931366 loss_ctc0 83.286331 lr 0.00057738 rank 0
2022-08-26 14:50:09,962 DEBUG TRAIN Batch 210/5500 loss 40.959686 loss_att 26.168892 loss_ctc 75.471542 loss_ctc_origin 49.284348 loss_ctc0 136.575012 lr 0.00057735 rank 0
2022-08-26 14:50:37,302 DEBUG TRAIN Batch 210/5600 loss 59.573429 loss_att 35.035809 loss_ctc 116.827866 loss_ctc_origin 70.726120 loss_ctc0 224.398605 lr 0.00057733 rank 0
2022-08-26 14:50:58,785 DEBUG CV Batch 210/0 loss 12.691661 loss_att 9.719295 loss_ctc 19.627182 loss_ctc_origin 13.529487 loss_ctc0 33.855141 history loss 11.945093 rank 0
2022-08-26 14:51:09,076 DEBUG CV Batch 210/100 loss 19.982292 loss_att 15.596531 loss_ctc 30.215733 loss_ctc_origin 20.466789 loss_ctc0 52.963264 history loss 25.662691 rank 0
2022-08-26 14:51:18,452 DEBUG CV Batch 210/200 loss 25.032614 loss_att 19.092333 loss_ctc 38.893269 loss_ctc_origin 28.662975 loss_ctc0 62.763950 history loss 26.969338 rank 0
2022-08-26 14:51:28,460 DEBUG CV Batch 210/300 loss 21.768709 loss_att 16.007393 loss_ctc 35.211781 loss_ctc_origin 19.940275 loss_ctc0 70.845291 history loss 26.111909 rank 0
2022-08-26 14:51:38,605 DEBUG CV Batch 210/400 loss 37.261147 loss_att 30.089073 loss_ctc 53.995983 loss_ctc_origin 36.434296 loss_ctc0 94.973251 history loss 24.468324 rank 0
2022-08-26 14:51:49,415 DEBUG CV Batch 210/500 loss 15.680019 loss_att 11.640299 loss_ctc 25.106037 loss_ctc_origin 17.977514 loss_ctc0 41.739254 history loss 24.128667 rank 0
2022-08-26 14:51:59,938 DEBUG CV Batch 210/600 loss 17.280918 loss_att 12.090502 loss_ctc 29.391884 loss_ctc_origin 18.910732 loss_ctc0 53.847904 history loss 23.972570 rank 0
2022-08-26 14:52:09,888 DEBUG CV Batch 210/700 loss 17.742401 loss_att 12.516500 loss_ctc 29.936171 loss_ctc_origin 15.820642 loss_ctc0 62.872398 history loss 23.659798 rank 0
2022-08-26 14:52:20,084 DEBUG CV Batch 210/800 loss 21.835649 loss_att 16.871637 loss_ctc 33.418343 loss_ctc_origin 18.158577 loss_ctc0 69.024460 history loss 23.625352 rank 0
2022-08-26 14:52:30,197 INFO Epoch 210 CV info cv_loss 23.717462807662855
2022-08-26 14:52:30,197 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/210.pt
2022-08-26 14:52:30,673 INFO Epoch 211 TRAIN info lr 0.000577309858913812
2022-08-26 14:52:30,677 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 14:52:55,616 DEBUG TRAIN Batch 211/0 loss 43.829918 loss_att 26.849758 loss_ctc 83.450287 loss_ctc_origin 49.164246 loss_ctc0 163.451065 lr 0.00057731 rank 0
2022-08-26 14:53:24,250 DEBUG TRAIN Batch 211/100 loss 61.098530 loss_att 35.555378 loss_ctc 120.699219 loss_ctc_origin 72.908218 loss_ctc0 232.211548 lr 0.00057728 rank 0
2022-08-26 14:53:50,977 DEBUG TRAIN Batch 211/200 loss 18.278608 loss_att 10.216810 loss_ctc 37.089470 loss_ctc_origin 24.751856 loss_ctc0 65.877235 lr 0.00057726 rank 0
2022-08-26 14:54:19,768 DEBUG TRAIN Batch 211/300 loss 18.693077 loss_att 7.228088 loss_ctc 45.444717 loss_ctc_origin 30.551449 loss_ctc0 80.195679 lr 0.00057724 rank 0
2022-08-26 14:54:48,562 DEBUG TRAIN Batch 211/400 loss 20.753439 loss_att 9.072917 loss_ctc 48.007988 loss_ctc_origin 31.333443 loss_ctc0 86.915253 lr 0.00057721 rank 0
2022-08-26 14:55:15,621 DEBUG TRAIN Batch 211/500 loss 50.147541 loss_att 33.538189 loss_ctc 88.902695 loss_ctc_origin 58.950394 loss_ctc0 158.791412 lr 0.00057719 rank 0
2022-08-26 14:55:42,299 DEBUG TRAIN Batch 211/600 loss 57.593636 loss_att 32.342815 loss_ctc 116.512222 loss_ctc_origin 69.764145 loss_ctc0 225.591064 lr 0.00057716 rank 0
2022-08-26 14:56:09,511 DEBUG TRAIN Batch 211/700 loss 17.241163 loss_att 9.868238 loss_ctc 34.444656 loss_ctc_origin 23.964905 loss_ctc0 58.897419 lr 0.00057714 rank 0
2022-08-26 14:56:37,229 DEBUG TRAIN Batch 211/800 loss 19.442131 loss_att 8.479385 loss_ctc 45.021866 loss_ctc_origin 31.727030 loss_ctc0 76.043152 lr 0.00057712 rank 0
2022-08-26 14:57:06,015 DEBUG TRAIN Batch 211/900 loss 21.005938 loss_att 8.506025 loss_ctc 50.172401 loss_ctc_origin 31.167637 loss_ctc0 94.516861 lr 0.00057709 rank 0
2022-08-26 14:57:26,859 WARNING NaN or Inf found in input tensor.
2022-08-26 14:57:33,757 DEBUG TRAIN Batch 211/1000 loss 40.731308 loss_att 27.743019 loss_ctc 71.037315 loss_ctc_origin 47.829399 loss_ctc0 125.189117 lr 0.00057707 rank 0
2022-08-26 14:58:01,538 DEBUG TRAIN Batch 211/1100 loss 58.932922 loss_att 32.519405 loss_ctc 120.564453 loss_ctc_origin 68.863762 loss_ctc0 241.199402 lr 0.00057704 rank 0
2022-08-26 14:58:28,441 WARNING NaN or Inf found in input tensor.
2022-08-26 14:58:29,996 DEBUG TRAIN Batch 211/1200 loss 13.631309 loss_att 7.116387 loss_ctc 28.832790 loss_ctc_origin 16.920729 loss_ctc0 56.627598 lr 0.00057702 rank 0
2022-08-26 14:58:58,334 DEBUG TRAIN Batch 211/1300 loss 15.324617 loss_att 5.963001 loss_ctc 37.168388 loss_ctc_origin 20.363632 loss_ctc0 76.379486 lr 0.00057700 rank 0
2022-08-26 14:59:25,678 DEBUG TRAIN Batch 211/1400 loss 24.641262 loss_att 10.282328 loss_ctc 58.145439 loss_ctc_origin 37.318420 loss_ctc0 106.741806 lr 0.00057697 rank 0
2022-08-26 14:59:59,276 DEBUG TRAIN Batch 211/1500 loss 51.378006 loss_att 33.153519 loss_ctc 93.901817 loss_ctc_origin 61.482414 loss_ctc0 169.547089 lr 0.00057695 rank 0
2022-08-26 15:00:27,912 DEBUG TRAIN Batch 211/1600 loss 65.085190 loss_att 35.296780 loss_ctc 134.591476 loss_ctc_origin 78.936829 loss_ctc0 264.452332 lr 0.00057692 rank 0
2022-08-26 15:00:55,684 DEBUG TRAIN Batch 211/1700 loss 16.580935 loss_att 8.009739 loss_ctc 36.580391 loss_ctc_origin 24.032867 loss_ctc0 65.857948 lr 0.00057690 rank 0
2022-08-26 15:01:23,174 DEBUG TRAIN Batch 211/1800 loss 18.759705 loss_att 7.612083 loss_ctc 44.770824 loss_ctc_origin 29.928352 loss_ctc0 79.403259 lr 0.00057688 rank 0
2022-08-26 15:01:51,260 DEBUG TRAIN Batch 211/1900 loss 23.201204 loss_att 9.706571 loss_ctc 54.688679 loss_ctc_origin 37.484760 loss_ctc0 94.831154 lr 0.00057685 rank 0
2022-08-26 15:02:20,184 DEBUG TRAIN Batch 211/2000 loss 58.908024 loss_att 37.920914 loss_ctc 107.877937 loss_ctc_origin 70.600136 loss_ctc0 194.859467 lr 0.00057683 rank 0
2022-08-26 15:02:20,885 WARNING NaN or Inf found in input tensor.
2022-08-26 15:02:47,885 DEBUG TRAIN Batch 211/2100 loss 64.727730 loss_att 39.122372 loss_ctc 124.473572 loss_ctc_origin 75.699707 loss_ctc0 238.279236 lr 0.00057680 rank 0
2022-08-26 15:03:16,340 DEBUG TRAIN Batch 211/2200 loss 17.091162 loss_att 7.826112 loss_ctc 38.709610 loss_ctc_origin 28.131683 loss_ctc0 63.391426 lr 0.00057678 rank 0
2022-08-26 15:03:32,826 WARNING NaN or Inf found in input tensor.
2022-08-26 15:03:43,754 DEBUG TRAIN Batch 211/2300 loss 19.779778 loss_att 8.025521 loss_ctc 47.206375 loss_ctc_origin 32.899284 loss_ctc0 80.589592 lr 0.00057676 rank 0
2022-08-26 15:04:11,999 DEBUG TRAIN Batch 211/2400 loss 19.558029 loss_att 7.067265 loss_ctc 48.703148 loss_ctc_origin 29.851709 loss_ctc0 92.689835 lr 0.00057673 rank 0
2022-08-26 15:04:39,258 DEBUG TRAIN Batch 211/2500 loss 59.267517 loss_att 39.216385 loss_ctc 106.053497 loss_ctc_origin 78.661949 loss_ctc0 169.967102 lr 0.00057671 rank 0
2022-08-26 15:04:52,350 WARNING NaN or Inf found in input tensor.
2022-08-26 15:05:06,320 DEBUG TRAIN Batch 211/2600 loss 65.741882 loss_att 39.205433 loss_ctc 127.660248 loss_ctc_origin 74.021606 loss_ctc0 252.817062 lr 0.00057668 rank 0
2022-08-26 15:05:33,640 DEBUG TRAIN Batch 211/2700 loss 19.524704 loss_att 9.637609 loss_ctc 42.594593 loss_ctc_origin 31.968079 loss_ctc0 67.389793 lr 0.00057666 rank 0
2022-08-26 15:06:02,981 DEBUG TRAIN Batch 211/2800 loss 17.411011 loss_att 7.160650 loss_ctc 41.328522 loss_ctc_origin 27.833076 loss_ctc0 72.817894 lr 0.00057664 rank 0
2022-08-26 15:06:25,327 WARNING NaN or Inf found in input tensor.
2022-08-26 15:06:29,785 DEBUG TRAIN Batch 211/2900 loss 20.237724 loss_att 7.651373 loss_ctc 49.605873 loss_ctc_origin 29.202217 loss_ctc0 97.214401 lr 0.00057661 rank 0
2022-08-26 15:07:03,082 DEBUG TRAIN Batch 211/3000 loss 44.980095 loss_att 28.559391 loss_ctc 83.295059 loss_ctc_origin 48.733925 loss_ctc0 163.937683 lr 0.00057659 rank 0
2022-08-26 15:07:29,625 DEBUG TRAIN Batch 211/3100 loss 67.568153 loss_att 41.956978 loss_ctc 127.327560 loss_ctc_origin 80.350632 loss_ctc0 236.940399 lr 0.00057656 rank 0
2022-08-26 15:07:56,925 DEBUG TRAIN Batch 211/3200 loss 17.116365 loss_att 8.713863 loss_ctc 36.722202 loss_ctc_origin 24.478367 loss_ctc0 65.291145 lr 0.00057654 rank 0
2022-08-26 15:08:02,271 WARNING NaN or Inf found in input tensor.
2022-08-26 15:08:23,955 DEBUG TRAIN Batch 211/3300 loss 13.734914 loss_att 4.914550 loss_ctc 34.315762 loss_ctc_origin 18.865711 loss_ctc0 70.365875 lr 0.00057652 rank 0
2022-08-26 15:08:51,566 DEBUG TRAIN Batch 211/3400 loss 18.316982 loss_att 6.796351 loss_ctc 45.198456 loss_ctc_origin 25.921549 loss_ctc0 90.177902 lr 0.00057649 rank 0
2022-08-26 15:09:19,776 DEBUG TRAIN Batch 211/3500 loss 48.996719 loss_att 29.903824 loss_ctc 93.546799 loss_ctc_origin 60.628368 loss_ctc0 170.356476 lr 0.00057647 rank 0
2022-08-26 15:09:47,252 DEBUG TRAIN Batch 211/3600 loss 58.503159 loss_att 32.773643 loss_ctc 118.538689 loss_ctc_origin 62.181988 loss_ctc0 250.037659 lr 0.00057645 rank 0
2022-08-26 15:10:14,785 DEBUG TRAIN Batch 211/3700 loss 18.447500 loss_att 11.319201 loss_ctc 35.080200 loss_ctc_origin 24.063316 loss_ctc0 60.786263 lr 0.00057642 rank 0
2022-08-26 15:10:43,125 DEBUG TRAIN Batch 211/3800 loss 18.692253 loss_att 6.325256 loss_ctc 47.548576 loss_ctc_origin 32.177227 loss_ctc0 83.415054 lr 0.00057640 rank 0
2022-08-26 15:10:59,231 WARNING NaN or Inf found in input tensor.
2022-08-26 15:11:10,827 DEBUG TRAIN Batch 211/3900 loss 19.603765 loss_att 8.689810 loss_ctc 45.069660 loss_ctc_origin 28.218195 loss_ctc0 84.389740 lr 0.00057637 rank 0
2022-08-26 15:11:38,011 DEBUG TRAIN Batch 211/4000 loss 56.448219 loss_att 38.914131 loss_ctc 97.361084 loss_ctc_origin 61.391045 loss_ctc0 181.291153 lr 0.00057635 rank 0
2022-08-26 15:11:52,200 WARNING NaN or Inf found in input tensor.
2022-08-26 15:12:06,192 DEBUG TRAIN Batch 211/4100 loss 59.654324 loss_att 34.513321 loss_ctc 118.316658 loss_ctc_origin 70.112068 loss_ctc0 230.794037 lr 0.00057633 rank 0
2022-08-26 15:12:33,989 DEBUG TRAIN Batch 211/4200 loss 19.290127 loss_att 9.527377 loss_ctc 42.069878 loss_ctc_origin 30.348249 loss_ctc0 69.420349 lr 0.00057630 rank 0
2022-08-26 15:13:02,630 DEBUG TRAIN Batch 211/4300 loss 18.402071 loss_att 6.706102 loss_ctc 45.692665 loss_ctc_origin 28.104233 loss_ctc0 86.732338 lr 0.00057628 rank 0
2022-08-26 15:13:30,057 DEBUG TRAIN Batch 211/4400 loss 19.279667 loss_att 7.107406 loss_ctc 47.681610 loss_ctc_origin 30.090244 loss_ctc0 88.728134 lr 0.00057625 rank 0
2022-08-26 15:14:03,407 DEBUG TRAIN Batch 211/4500 loss 49.869034 loss_att 31.394035 loss_ctc 92.977356 loss_ctc_origin 61.055958 loss_ctc0 167.460602 lr 0.00057623 rank 0
2022-08-26 15:14:31,580 DEBUG TRAIN Batch 211/4600 loss 53.101830 loss_att 28.335999 loss_ctc 110.888763 loss_ctc_origin 57.389565 loss_ctc0 235.720215 lr 0.00057621 rank 0
2022-08-26 15:14:59,199 DEBUG TRAIN Batch 211/4700 loss 20.154831 loss_att 8.561913 loss_ctc 47.204971 loss_ctc_origin 34.171860 loss_ctc0 77.615555 lr 0.00057618 rank 0
2022-08-26 15:15:27,486 DEBUG TRAIN Batch 211/4800 loss 17.086498 loss_att 7.043329 loss_ctc 40.520557 loss_ctc_origin 25.939938 loss_ctc0 74.542007 lr 0.00057616 rank 0
2022-08-26 15:15:55,301 DEBUG TRAIN Batch 211/4900 loss 17.524557 loss_att 7.360089 loss_ctc 41.241646 loss_ctc_origin 23.716251 loss_ctc0 82.134239 lr 0.00057613 rank 0
2022-08-26 15:16:23,088 DEBUG TRAIN Batch 211/5000 loss 44.782143 loss_att 29.336033 loss_ctc 80.823059 loss_ctc_origin 49.807770 loss_ctc0 153.192078 lr 0.00057611 rank 0
2022-08-26 15:16:50,532 DEBUG TRAIN Batch 211/5100 loss 60.311073 loss_att 33.823994 loss_ctc 122.114258 loss_ctc_origin 76.485779 loss_ctc0 228.580719 lr 0.00057609 rank 0
2022-08-26 15:17:18,146 DEBUG TRAIN Batch 211/5200 loss 21.259670 loss_att 11.099368 loss_ctc 44.967041 loss_ctc_origin 35.110474 loss_ctc0 67.965698 lr 0.00057606 rank 0
2022-08-26 15:17:36,374 WARNING NaN or Inf found in input tensor.
2022-08-26 15:17:45,897 DEBUG TRAIN Batch 211/5300 loss 14.731613 loss_att 6.018862 loss_ctc 35.061367 loss_ctc_origin 21.003220 loss_ctc0 67.863708 lr 0.00057604 rank 0
2022-08-26 15:18:13,539 DEBUG TRAIN Batch 211/5400 loss 19.757273 loss_att 7.486125 loss_ctc 48.389950 loss_ctc_origin 28.738173 loss_ctc0 94.244095 lr 0.00057601 rank 0
2022-08-26 15:18:41,663 DEBUG TRAIN Batch 211/5500 loss 53.162460 loss_att 36.031269 loss_ctc 93.135231 loss_ctc_origin 63.146969 loss_ctc0 163.107834 lr 0.00057599 rank 0
2022-08-26 15:19:09,566 DEBUG TRAIN Batch 211/5600 loss 52.345741 loss_att 27.274208 loss_ctc 110.845978 loss_ctc_origin 60.063213 loss_ctc0 229.339081 lr 0.00057597 rank 0
2022-08-26 15:19:32,204 DEBUG CV Batch 211/0 loss 11.134130 loss_att 8.010776 loss_ctc 18.421959 loss_ctc_origin 11.791209 loss_ctc0 33.893711 history loss 10.479182 rank 0
2022-08-26 15:19:42,848 DEBUG CV Batch 211/100 loss 19.934868 loss_att 15.468191 loss_ctc 30.357115 loss_ctc_origin 20.717596 loss_ctc0 52.849323 history loss 25.499867 rank 0
2022-08-26 15:19:52,278 DEBUG CV Batch 211/200 loss 22.658552 loss_att 17.278980 loss_ctc 35.210884 loss_ctc_origin 23.848083 loss_ctc0 61.724075 history loss 26.744169 rank 0
2022-08-26 15:20:02,031 DEBUG CV Batch 211/300 loss 21.229511 loss_att 15.691158 loss_ctc 34.152336 loss_ctc_origin 18.182686 loss_ctc0 71.414856 history loss 25.824160 rank 0
2022-08-26 15:20:12,680 DEBUG CV Batch 211/400 loss 36.447609 loss_att 29.253593 loss_ctc 53.233646 loss_ctc_origin 35.945808 loss_ctc0 93.571930 history loss 24.184343 rank 0
2022-08-26 15:20:23,218 DEBUG CV Batch 211/500 loss 15.847228 loss_att 11.772947 loss_ctc 25.353882 loss_ctc_origin 18.198521 loss_ctc0 42.049721 history loss 23.858948 rank 0
2022-08-26 15:20:33,663 DEBUG CV Batch 211/600 loss 16.978956 loss_att 11.889671 loss_ctc 28.853952 loss_ctc_origin 18.182919 loss_ctc0 53.753033 history loss 23.707759 rank 0
2022-08-26 15:20:43,397 DEBUG CV Batch 211/700 loss 17.978916 loss_att 12.427883 loss_ctc 30.931324 loss_ctc_origin 17.116257 loss_ctc0 63.166473 history loss 23.383746 rank 0
2022-08-26 15:20:53,584 DEBUG CV Batch 211/800 loss 21.686462 loss_att 16.738089 loss_ctc 33.232666 loss_ctc_origin 17.832602 loss_ctc0 69.166153 history loss 23.345510 rank 0
2022-08-26 15:21:03,656 INFO Epoch 211 CV info cv_loss 23.437630505407732
2022-08-26 15:21:03,656 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/211.pt
2022-08-26 15:21:04,099 INFO Epoch 212 TRAIN info lr 0.0005759466696231806
2022-08-26 15:21:04,102 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 15:21:29,991 DEBUG TRAIN Batch 212/0 loss 47.454296 loss_att 28.877195 loss_ctc 90.800858 loss_ctc_origin 60.199265 loss_ctc0 162.204575 lr 0.00057595 rank 0
2022-08-26 15:21:37,884 WARNING NaN or Inf found in input tensor.
2022-08-26 15:21:57,640 DEBUG TRAIN Batch 212/100 loss 55.326485 loss_att 29.499096 loss_ctc 115.590393 loss_ctc_origin 66.052246 loss_ctc0 231.179382 lr 0.00057592 rank 0
2022-08-26 15:22:24,881 DEBUG TRAIN Batch 212/200 loss 20.429974 loss_att 9.783077 loss_ctc 45.272732 loss_ctc_origin 33.914127 loss_ctc0 71.776138 lr 0.00057590 rank 0
2022-08-26 15:22:52,775 DEBUG TRAIN Batch 212/300 loss 16.625767 loss_att 6.357756 loss_ctc 40.584457 loss_ctc_origin 26.706150 loss_ctc0 72.967163 lr 0.00057587 rank 0
2022-08-26 15:23:21,793 DEBUG TRAIN Batch 212/400 loss 19.523556 loss_att 7.715076 loss_ctc 47.076672 loss_ctc_origin 28.235840 loss_ctc0 91.038612 lr 0.00057585 rank 0
2022-08-26 15:23:49,629 DEBUG TRAIN Batch 212/500 loss 39.663502 loss_att 24.220379 loss_ctc 75.697449 loss_ctc_origin 49.159813 loss_ctc0 137.618591 lr 0.00057583 rank 0
2022-08-26 15:24:16,565 DEBUG TRAIN Batch 212/600 loss 56.730789 loss_att 33.144665 loss_ctc 111.765076 loss_ctc_origin 64.111443 loss_ctc0 222.956879 lr 0.00057580 rank 0
2022-08-26 15:24:43,954 DEBUG TRAIN Batch 212/700 loss 17.696211 loss_att 9.127745 loss_ctc 37.689301 loss_ctc_origin 25.331881 loss_ctc0 66.523285 lr 0.00057578 rank 0
2022-08-26 15:25:12,176 DEBUG TRAIN Batch 212/800 loss 15.433834 loss_att 6.116615 loss_ctc 37.174011 loss_ctc_origin 20.740963 loss_ctc0 75.517792 lr 0.00057575 rank 0
2022-08-26 15:25:39,554 DEBUG TRAIN Batch 212/900 loss 18.937218 loss_att 7.481376 loss_ctc 45.667515 loss_ctc_origin 28.176071 loss_ctc0 86.480881 lr 0.00057573 rank 0
2022-08-26 15:25:54,601 WARNING NaN or Inf found in input tensor.
2022-08-26 15:26:08,141 DEBUG TRAIN Batch 212/1000 loss 46.120872 loss_att 30.666388 loss_ctc 82.181335 loss_ctc_origin 52.716049 loss_ctc0 150.933685 lr 0.00057571 rank 0
2022-08-26 15:26:34,802 DEBUG TRAIN Batch 212/1100 loss 52.276184 loss_att 28.088945 loss_ctc 108.713074 loss_ctc_origin 58.233555 loss_ctc0 226.498596 lr 0.00057568 rank 0
2022-08-26 15:27:01,571 DEBUG TRAIN Batch 212/1200 loss 18.551201 loss_att 8.838906 loss_ctc 41.213223 loss_ctc_origin 28.871996 loss_ctc0 70.009415 lr 0.00057566 rank 0
2022-08-26 15:27:30,733 DEBUG TRAIN Batch 212/1300 loss 19.067753 loss_att 6.620915 loss_ctc 48.110374 loss_ctc_origin 32.785988 loss_ctc0 83.867279 lr 0.00057564 rank 0
2022-08-26 15:27:58,050 DEBUG TRAIN Batch 212/1400 loss 21.605087 loss_att 8.993907 loss_ctc 51.031170 loss_ctc_origin 31.183292 loss_ctc0 97.342880 lr 0.00057561 rank 0
2022-08-26 15:28:31,901 DEBUG TRAIN Batch 212/1500 loss 50.688210 loss_att 33.439941 loss_ctc 90.934166 loss_ctc_origin 60.197319 loss_ctc0 162.653473 lr 0.00057559 rank 0
2022-08-26 15:28:59,757 DEBUG TRAIN Batch 212/1600 loss 54.938499 loss_att 30.195839 loss_ctc 112.671371 loss_ctc_origin 63.232147 loss_ctc0 228.029541 lr 0.00057556 rank 0
2022-08-26 15:29:27,765 DEBUG TRAIN Batch 212/1700 loss 17.098879 loss_att 7.788538 loss_ctc 38.823006 loss_ctc_origin 26.863115 loss_ctc0 66.729416 lr 0.00057554 rank 0
2022-08-26 15:29:56,114 DEBUG TRAIN Batch 212/1800 loss 18.118206 loss_att 6.652431 loss_ctc 44.871674 loss_ctc_origin 31.428753 loss_ctc0 76.238487 lr 0.00057552 rank 0
2022-08-26 15:30:24,038 DEBUG TRAIN Batch 212/1900 loss 20.554653 loss_att 7.631004 loss_ctc 50.709835 loss_ctc_origin 32.935944 loss_ctc0 92.182243 lr 0.00057549 rank 0
2022-08-26 15:30:52,706 DEBUG TRAIN Batch 212/2000 loss 58.179413 loss_att 42.968803 loss_ctc 93.670837 loss_ctc_origin 69.854637 loss_ctc0 149.241974 lr 0.00057547 rank 0
2022-08-26 15:31:21,205 DEBUG TRAIN Batch 212/2100 loss 53.208534 loss_att 28.826067 loss_ctc 110.100952 loss_ctc_origin 58.840199 loss_ctc0 229.709351 lr 0.00057544 rank 0
2022-08-26 15:31:47,886 DEBUG TRAIN Batch 212/2200 loss 20.374899 loss_att 10.774717 loss_ctc 42.775322 loss_ctc_origin 30.300549 loss_ctc0 71.883118 lr 0.00057542 rank 0
2022-08-26 15:32:16,132 DEBUG TRAIN Batch 212/2300 loss 20.207109 loss_att 7.867853 loss_ctc 48.998703 loss_ctc_origin 32.080353 loss_ctc0 88.474846 lr 0.00057540 rank 0
2022-08-26 15:32:43,434 DEBUG TRAIN Batch 212/2400 loss 19.756924 loss_att 7.477612 loss_ctc 48.408649 loss_ctc_origin 29.220623 loss_ctc0 93.180710 lr 0.00057537 rank 0
2022-08-26 15:33:12,632 DEBUG TRAIN Batch 212/2500 loss 51.532372 loss_att 34.187847 loss_ctc 92.002922 loss_ctc_origin 61.116154 loss_ctc0 164.072037 lr 0.00057535 rank 0
2022-08-26 15:33:25,481 WARNING NaN or Inf found in input tensor.
2022-08-26 15:33:39,704 DEBUG TRAIN Batch 212/2600 loss 67.574181 loss_att 42.022972 loss_ctc 127.193665 loss_ctc_origin 80.053925 loss_ctc0 237.186401 lr 0.00057533 rank 0
2022-08-26 15:34:06,397 WARNING NaN or Inf found in input tensor.
2022-08-26 15:34:07,965 DEBUG TRAIN Batch 212/2700 loss 20.208977 loss_att 11.577818 loss_ctc 40.348343 loss_ctc_origin 28.053583 loss_ctc0 69.036118 lr 0.00057530 rank 0
2022-08-26 15:34:35,869 DEBUG TRAIN Batch 212/2800 loss 18.035946 loss_att 6.717206 loss_ctc 44.446335 loss_ctc_origin 30.273445 loss_ctc0 77.516411 lr 0.00057528 rank 0
2022-08-26 15:35:03,350 DEBUG TRAIN Batch 212/2900 loss 22.152798 loss_att 8.648416 loss_ctc 53.663025 loss_ctc_origin 36.313931 loss_ctc0 94.144249 lr 0.00057525 rank 0
2022-08-26 15:35:35,779 DEBUG TRAIN Batch 212/3000 loss 49.824638 loss_att 32.598251 loss_ctc 90.019547 loss_ctc_origin 54.782135 loss_ctc0 172.240173 lr 0.00057523 rank 0
2022-08-26 15:36:03,561 DEBUG TRAIN Batch 212/3100 loss 61.770187 loss_att 33.828671 loss_ctc 126.967056 loss_ctc_origin 73.118622 loss_ctc0 252.613403 lr 0.00057521 rank 0
2022-08-26 15:36:31,325 DEBUG TRAIN Batch 212/3200 loss 18.859728 loss_att 11.334217 loss_ctc 36.419250 loss_ctc_origin 26.356361 loss_ctc0 59.899323 lr 0.00057518 rank 0
2022-08-26 15:36:58,992 DEBUG TRAIN Batch 212/3300 loss 18.579773 loss_att 7.991814 loss_ctc 43.285011 loss_ctc_origin 30.169453 loss_ctc0 73.887978 lr 0.00057516 rank 0
2022-08-26 15:37:26,665 DEBUG TRAIN Batch 212/3400 loss 21.812279 loss_att 8.975653 loss_ctc 51.764408 loss_ctc_origin 31.787554 loss_ctc0 98.377068 lr 0.00057514 rank 0
2022-08-26 15:37:55,448 DEBUG TRAIN Batch 212/3500 loss 53.877625 loss_att 35.273994 loss_ctc 97.286087 loss_ctc_origin 67.512756 loss_ctc0 166.757187 lr 0.00057511 rank 0
2022-08-26 15:38:15,385 WARNING NaN or Inf found in input tensor.
2022-08-26 15:38:22,487 DEBUG TRAIN Batch 212/3600 loss 53.856350 loss_att 28.768459 loss_ctc 112.394760 loss_ctc_origin 63.703079 loss_ctc0 226.008667 lr 0.00057509 rank 0
2022-08-26 15:38:49,686 DEBUG TRAIN Batch 212/3700 loss 16.012215 loss_att 8.136183 loss_ctc 34.389626 loss_ctc_origin 22.582504 loss_ctc0 61.939579 lr 0.00057506 rank 0
2022-08-26 15:39:16,899 DEBUG TRAIN Batch 212/3800 loss 17.902668 loss_att 7.416337 loss_ctc 42.370773 loss_ctc_origin 27.668198 loss_ctc0 76.676773 lr 0.00057504 rank 0
2022-08-26 15:39:44,159 DEBUG TRAIN Batch 212/3900 loss 21.515133 loss_att 8.689954 loss_ctc 51.440552 loss_ctc_origin 34.656136 loss_ctc0 90.604179 lr 0.00057502 rank 0
2022-08-26 15:40:12,078 DEBUG TRAIN Batch 212/4000 loss 47.762665 loss_att 30.688080 loss_ctc 87.603363 loss_ctc_origin 57.653717 loss_ctc0 157.485855 lr 0.00057499 rank 0
2022-08-26 15:40:40,362 DEBUG TRAIN Batch 212/4100 loss 67.004616 loss_att 39.024818 loss_ctc 132.290802 loss_ctc_origin 78.938065 loss_ctc0 256.780518 lr 0.00057497 rank 0
2022-08-26 15:41:07,779 DEBUG TRAIN Batch 212/4200 loss 17.703545 loss_att 9.395232 loss_ctc 37.089607 loss_ctc_origin 25.408459 loss_ctc0 64.345619 lr 0.00057495 rank 0
2022-08-26 15:41:36,554 DEBUG TRAIN Batch 212/4300 loss 17.890862 loss_att 7.475477 loss_ctc 42.193420 loss_ctc_origin 27.146696 loss_ctc0 77.302444 lr 0.00057492 rank 0
2022-08-26 15:42:03,522 DEBUG TRAIN Batch 212/4400 loss 20.977325 loss_att 7.816525 loss_ctc 51.685856 loss_ctc_origin 29.893467 loss_ctc0 102.534760 lr 0.00057490 rank 0
2022-08-26 15:42:35,581 DEBUG TRAIN Batch 212/4500 loss 40.637882 loss_att 25.077568 loss_ctc 76.945282 loss_ctc_origin 50.766060 loss_ctc0 138.030136 lr 0.00057487 rank 0
2022-08-26 15:43:02,732 DEBUG TRAIN Batch 212/4600 loss 50.616848 loss_att 29.430254 loss_ctc 100.052231 loss_ctc_origin 58.985817 loss_ctc0 195.873871 lr 0.00057485 rank 0
2022-08-26 15:43:31,140 DEBUG TRAIN Batch 212/4700 loss 19.339754 loss_att 11.041555 loss_ctc 38.702217 loss_ctc_origin 27.481182 loss_ctc0 64.884628 lr 0.00057483 rank 0
2022-08-26 15:43:58,396 DEBUG TRAIN Batch 212/4800 loss 19.767746 loss_att 7.174971 loss_ctc 49.150887 loss_ctc_origin 32.275475 loss_ctc0 88.526840 lr 0.00057480 rank 0
2022-08-26 15:44:26,006 DEBUG TRAIN Batch 212/4900 loss 18.168667 loss_att 7.209591 loss_ctc 43.739845 loss_ctc_origin 25.645588 loss_ctc0 85.959770 lr 0.00057478 rank 0
2022-08-26 15:44:54,611 DEBUG TRAIN Batch 212/5000 loss 51.639332 loss_att 35.917824 loss_ctc 88.322845 loss_ctc_origin 62.281422 loss_ctc0 149.086151 lr 0.00057476 rank 0
2022-08-26 15:45:21,373 DEBUG TRAIN Batch 212/5100 loss 59.587971 loss_att 34.067444 loss_ctc 119.135864 loss_ctc_origin 70.588371 loss_ctc0 232.413345 lr 0.00057473 rank 0
2022-08-26 15:45:48,985 DEBUG TRAIN Batch 212/5200 loss 16.347021 loss_att 8.330490 loss_ctc 35.052261 loss_ctc_origin 23.916073 loss_ctc0 61.036701 lr 0.00057471 rank 0
2022-08-26 15:46:16,502 DEBUG TRAIN Batch 212/5300 loss 20.846127 loss_att 7.257207 loss_ctc 52.553604 loss_ctc_origin 37.410477 loss_ctc0 87.887558 lr 0.00057468 rank 0
2022-08-26 15:46:32,453 WARNING NaN or Inf found in input tensor.
2022-08-26 15:46:43,996 DEBUG TRAIN Batch 212/5400 loss 21.962120 loss_att 9.678419 loss_ctc 50.624084 loss_ctc_origin 33.357452 loss_ctc0 90.912895 lr 0.00057466 rank 0
2022-08-26 15:47:12,009 DEBUG TRAIN Batch 212/5500 loss 53.652374 loss_att 36.473701 loss_ctc 93.735947 loss_ctc_origin 62.462341 loss_ctc0 166.707703 lr 0.00057464 rank 0
2022-08-26 15:47:40,204 WARNING NaN or Inf found in input tensor.
2022-08-26 15:47:40,247 DEBUG TRAIN Batch 212/5600 loss nan loss_att 38.687965 loss_ctc nan loss_ctc_origin 72.172882 loss_ctc0 nan lr 0.00057461 rank 0
2022-08-26 15:48:03,577 DEBUG CV Batch 212/0 loss 12.151265 loss_att 9.133135 loss_ctc 19.193569 loss_ctc_origin 12.736848 loss_ctc0 34.259247 history loss 11.436485 rank 0
2022-08-26 15:48:13,825 DEBUG CV Batch 212/100 loss 19.821152 loss_att 15.495636 loss_ctc 29.914024 loss_ctc_origin 20.187721 loss_ctc0 52.608734 history loss 26.044876 rank 0
2022-08-26 15:48:23,102 DEBUG CV Batch 212/200 loss 24.887775 loss_att 19.417072 loss_ctc 37.652752 loss_ctc_origin 27.066254 loss_ctc0 62.354580 history loss 27.363032 rank 0
2022-08-26 15:48:33,032 DEBUG CV Batch 212/300 loss 22.219185 loss_att 16.661154 loss_ctc 35.187920 loss_ctc_origin 19.743618 loss_ctc0 71.224625 history loss 26.423159 rank 0
2022-08-26 15:48:43,475 DEBUG CV Batch 212/400 loss 37.364555 loss_att 30.103483 loss_ctc 54.307053 loss_ctc_origin 36.922958 loss_ctc0 94.869926 history loss 24.758704 rank 0
2022-08-26 15:48:53,946 DEBUG CV Batch 212/500 loss 16.866760 loss_att 12.559357 loss_ctc 26.917364 loss_ctc_origin 20.538433 loss_ctc0 41.801537 history loss 24.415153 rank 0
2022-08-26 15:49:04,105 DEBUG CV Batch 212/600 loss 16.764914 loss_att 11.675995 loss_ctc 28.639057 loss_ctc_origin 18.046684 loss_ctc0 53.354591 history loss 24.282613 rank 0
2022-08-26 15:49:13,933 DEBUG CV Batch 212/700 loss 18.670517 loss_att 13.254420 loss_ctc 31.308071 loss_ctc_origin 17.852692 loss_ctc0 62.703949 history loss 23.965003 rank 0
2022-08-26 15:49:24,229 DEBUG CV Batch 212/800 loss 21.943956 loss_att 16.886047 loss_ctc 33.745743 loss_ctc_origin 18.777031 loss_ctc0 68.672729 history loss 23.930278 rank 0
2022-08-26 15:49:34,676 INFO Epoch 212 CV info cv_loss 24.030759001839908
2022-08-26 15:49:34,676 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/212.pt
2022-08-26 15:49:35,165 INFO Epoch 213 TRAIN info lr 0.0005745930915600862
2022-08-26 15:49:35,169 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 15:50:01,195 DEBUG TRAIN Batch 213/0 loss 53.813484 loss_att 36.644341 loss_ctc 93.874817 loss_ctc_origin 68.186707 loss_ctc0 153.813751 lr 0.00057459 rank 0
2022-08-26 15:50:01,954 WARNING NaN or Inf found in input tensor.
2022-08-26 15:50:29,308 DEBUG TRAIN Batch 213/100 loss 58.001503 loss_att 31.392569 loss_ctc 120.089005 loss_ctc_origin 67.119637 loss_ctc0 243.684204 lr 0.00057457 rank 0
2022-08-26 15:50:58,174 DEBUG TRAIN Batch 213/200 loss 13.843691 loss_att 6.229457 loss_ctc 31.610237 loss_ctc_origin 18.876144 loss_ctc0 61.323120 lr 0.00057454 rank 0
2022-08-26 15:51:26,189 DEBUG TRAIN Batch 213/300 loss 18.355619 loss_att 7.880033 loss_ctc 42.798653 loss_ctc_origin 26.991039 loss_ctc0 79.683090 lr 0.00057452 rank 0
2022-08-26 15:51:54,965 DEBUG TRAIN Batch 213/400 loss 24.010292 loss_att 10.726372 loss_ctc 55.006104 loss_ctc_origin 37.365963 loss_ctc0 96.166420 lr 0.00057450 rank 0
2022-08-26 15:52:22,999 DEBUG TRAIN Batch 213/500 loss 43.635880 loss_att 29.289661 loss_ctc 77.110390 loss_ctc_origin 51.936882 loss_ctc0 135.848572 lr 0.00057447 rank 0
2022-08-26 15:52:50,347 DEBUG TRAIN Batch 213/600 loss 54.916832 loss_att 31.581234 loss_ctc 109.366562 loss_ctc_origin 62.133774 loss_ctc0 219.576370 lr 0.00057445 rank 0
2022-08-26 15:53:19,364 DEBUG TRAIN Batch 213/700 loss 19.286324 loss_att 11.288872 loss_ctc 37.947041 loss_ctc_origin 27.269321 loss_ctc0 62.861721 lr 0.00057443 rank 0
2022-08-26 15:53:46,437 DEBUG TRAIN Batch 213/800 loss 17.297260 loss_att 6.610034 loss_ctc 42.234119 loss_ctc_origin 26.782330 loss_ctc0 78.288292 lr 0.00057440 rank 0
2022-08-26 15:54:13,945 DEBUG TRAIN Batch 213/900 loss 22.133816 loss_att 7.543406 loss_ctc 56.178101 loss_ctc_origin 36.447235 loss_ctc0 102.216782 lr 0.00057438 rank 0
2022-08-26 15:54:41,581 DEBUG TRAIN Batch 213/1000 loss 42.089039 loss_att 26.862957 loss_ctc 77.616562 loss_ctc_origin 45.283985 loss_ctc0 153.059235 lr 0.00057436 rank 0
2022-08-26 15:55:10,023 DEBUG TRAIN Batch 213/1100 loss 54.025406 loss_att 32.683357 loss_ctc 103.823517 loss_ctc_origin 65.029716 loss_ctc0 194.342392 lr 0.00057433 rank 0
2022-08-26 15:55:38,006 DEBUG TRAIN Batch 213/1200 loss 20.829119 loss_att 12.305445 loss_ctc 40.717690 loss_ctc_origin 30.302008 loss_ctc0 65.020943 lr 0.00057431 rank 0
2022-08-26 15:56:06,281 DEBUG TRAIN Batch 213/1300 loss 19.017479 loss_att 7.897458 loss_ctc 44.964191 loss_ctc_origin 31.226221 loss_ctc0 77.019455 lr 0.00057428 rank 0
2022-08-26 15:56:35,010 DEBUG TRAIN Batch 213/1400 loss 20.332573 loss_att 8.699028 loss_ctc 47.477509 loss_ctc_origin 28.230793 loss_ctc0 92.386505 lr 0.00057426 rank 0
2022-08-26 15:57:08,763 DEBUG TRAIN Batch 213/1500 loss 48.293564 loss_att 32.104836 loss_ctc 86.067261 loss_ctc_origin 61.750847 loss_ctc0 142.805557 lr 0.00057424 rank 0
2022-08-26 15:57:36,516 DEBUG TRAIN Batch 213/1600 loss 59.315811 loss_att 32.597725 loss_ctc 121.658012 loss_ctc_origin 80.689545 loss_ctc0 217.251099 lr 0.00057421 rank 0
2022-08-26 15:58:04,511 DEBUG TRAIN Batch 213/1700 loss 16.773603 loss_att 8.240047 loss_ctc 36.685234 loss_ctc_origin 24.552341 loss_ctc0 64.995316 lr 0.00057419 rank 0
2022-08-26 15:58:31,957 DEBUG TRAIN Batch 213/1800 loss 17.813129 loss_att 6.856525 loss_ctc 43.378540 loss_ctc_origin 27.850840 loss_ctc0 79.609840 lr 0.00057417 rank 0
2022-08-26 15:58:59,570 DEBUG TRAIN Batch 213/1900 loss 18.274878 loss_att 7.269351 loss_ctc 43.954437 loss_ctc_origin 26.262878 loss_ctc0 85.234734 lr 0.00057414 rank 0
2022-08-26 15:59:28,043 DEBUG TRAIN Batch 213/2000 loss 40.881271 loss_att 26.394920 loss_ctc 74.682755 loss_ctc_origin 47.761292 loss_ctc0 137.499496 lr 0.00057412 rank 0
2022-08-26 15:59:56,082 DEBUG TRAIN Batch 213/2100 loss 60.393394 loss_att 36.504227 loss_ctc 116.134781 loss_ctc_origin 70.563599 loss_ctc0 222.467514 lr 0.00057409 rank 0
2022-08-26 16:00:23,751 DEBUG TRAIN Batch 213/2200 loss 19.678410 loss_att 11.065760 loss_ctc 39.774590 loss_ctc_origin 29.511637 loss_ctc0 63.721485 lr 0.00057407 rank 0
2022-08-26 16:00:51,223 DEBUG TRAIN Batch 213/2300 loss 17.216063 loss_att 7.185409 loss_ctc 40.620918 loss_ctc_origin 24.251762 loss_ctc0 78.815620 lr 0.00057405 rank 0
2022-08-26 16:01:19,948 DEBUG TRAIN Batch 213/2400 loss 21.147255 loss_att 8.060536 loss_ctc 51.682930 loss_ctc_origin 31.757498 loss_ctc0 98.175598 lr 0.00057402 rank 0
2022-08-26 16:01:48,226 DEBUG TRAIN Batch 213/2500 loss 47.108421 loss_att 30.560543 loss_ctc 85.720131 loss_ctc_origin 58.735851 loss_ctc0 148.683441 lr 0.00057400 rank 0
2022-08-26 16:02:15,213 DEBUG TRAIN Batch 213/2600 loss 59.084343 loss_att 34.246132 loss_ctc 117.040161 loss_ctc_origin 71.789360 loss_ctc0 222.625366 lr 0.00057398 rank 0
2022-08-26 16:02:41,652 DEBUG TRAIN Batch 213/2700 loss 20.705261 loss_att 12.214689 loss_ctc 40.516590 loss_ctc_origin 29.960365 loss_ctc0 65.147781 lr 0.00057395 rank 0
2022-08-26 16:03:09,355 DEBUG TRAIN Batch 213/2800 loss 18.855490 loss_att 7.761990 loss_ctc 44.740318 loss_ctc_origin 29.280632 loss_ctc0 80.812912 lr 0.00057393 rank 0
2022-08-26 16:03:35,052 DEBUG TRAIN Batch 213/2900 loss 20.831827 loss_att 8.000805 loss_ctc 50.770874 loss_ctc_origin 32.922035 loss_ctc0 92.418159 lr 0.00057391 rank 0
2022-08-26 16:04:06,829 DEBUG TRAIN Batch 213/3000 loss 49.943893 loss_att 32.645527 loss_ctc 90.306747 loss_ctc_origin 59.653900 loss_ctc0 161.830048 lr 0.00057388 rank 0
2022-08-26 16:04:33,603 DEBUG TRAIN Batch 213/3100 loss 53.014282 loss_att 28.716263 loss_ctc 109.709656 loss_ctc_origin 63.218040 loss_ctc0 218.190063 lr 0.00057386 rank 0
2022-08-26 16:05:02,118 DEBUG TRAIN Batch 213/3200 loss 21.138065 loss_att 10.561436 loss_ctc 45.816864 loss_ctc_origin 36.054733 loss_ctc0 68.595169 lr 0.00057383 rank 0
2022-08-26 16:05:30,194 DEBUG TRAIN Batch 213/3300 loss 16.251507 loss_att 6.277072 loss_ctc 39.525185 loss_ctc_origin 25.658909 loss_ctc0 71.879837 lr 0.00057381 rank 0
2022-08-26 16:05:57,795 DEBUG TRAIN Batch 213/3400 loss 20.222755 loss_att 8.878065 loss_ctc 46.693695 loss_ctc_origin 27.665710 loss_ctc0 91.092331 lr 0.00057379 rank 0
2022-08-26 16:06:26,728 DEBUG TRAIN Batch 213/3500 loss 47.817390 loss_att 31.719151 loss_ctc 85.379944 loss_ctc_origin 56.252640 loss_ctc0 153.343643 lr 0.00057376 rank 0
2022-08-26 16:06:53,924 DEBUG TRAIN Batch 213/3600 loss 53.538063 loss_att 30.829426 loss_ctc 106.524887 loss_ctc_origin 65.143272 loss_ctc0 203.081985 lr 0.00057374 rank 0
2022-08-26 16:07:20,562 DEBUG TRAIN Batch 213/3700 loss 17.871634 loss_att 9.721188 loss_ctc 36.889343 loss_ctc_origin 26.806583 loss_ctc0 60.415787 lr 0.00057372 rank 0
2022-08-26 16:07:48,377 DEBUG TRAIN Batch 213/3800 loss 16.553865 loss_att 6.334660 loss_ctc 40.398674 loss_ctc_origin 24.000717 loss_ctc0 78.660568 lr 0.00057369 rank 0
2022-08-26 16:08:17,703 DEBUG TRAIN Batch 213/3900 loss 19.958618 loss_att 8.342284 loss_ctc 47.063393 loss_ctc_origin 28.366798 loss_ctc0 90.688782 lr 0.00057367 rank 0
2022-08-26 16:08:45,034 DEBUG TRAIN Batch 213/4000 loss 53.977459 loss_att 37.223251 loss_ctc 93.070602 loss_ctc_origin 60.270851 loss_ctc0 169.603363 lr 0.00057365 rank 0
2022-08-26 16:09:13,093 DEBUG TRAIN Batch 213/4100 loss 49.987953 loss_att 28.009954 loss_ctc 101.269951 loss_ctc_origin 66.103111 loss_ctc0 183.325897 lr 0.00057362 rank 0
2022-08-26 16:09:31,225 WARNING NaN or Inf found in input tensor.
2022-08-26 16:09:40,848 DEBUG TRAIN Batch 213/4200 loss 18.641850 loss_att 8.643145 loss_ctc 41.972160 loss_ctc_origin 29.231396 loss_ctc0 71.700615 lr 0.00057360 rank 0
2022-08-26 16:09:51,907 WARNING NaN or Inf found in input tensor.
2022-08-26 16:10:08,744 DEBUG TRAIN Batch 213/4300 loss 19.516510 loss_att 7.811278 loss_ctc 46.828720 loss_ctc_origin 32.694530 loss_ctc0 79.808502 lr 0.00057358 rank 0
2022-08-26 16:10:36,113 DEBUG TRAIN Batch 213/4400 loss 22.334866 loss_att 8.615198 loss_ctc 54.347424 loss_ctc_origin 38.497536 loss_ctc0 91.330490 lr 0.00057355 rank 0
2022-08-26 16:11:09,942 DEBUG TRAIN Batch 213/4500 loss 40.939945 loss_att 26.603611 loss_ctc 74.391388 loss_ctc_origin 46.436943 loss_ctc0 139.618423 lr 0.00057353 rank 0
2022-08-26 16:11:37,071 DEBUG TRAIN Batch 213/4600 loss 54.392578 loss_att 31.068130 loss_ctc 108.816284 loss_ctc_origin 73.278015 loss_ctc0 191.738892 lr 0.00057350 rank 0
2022-08-26 16:12:04,593 DEBUG TRAIN Batch 213/4700 loss 16.920872 loss_att 8.740168 loss_ctc 36.009182 loss_ctc_origin 25.223644 loss_ctc0 61.175430 lr 0.00057348 rank 0
2022-08-26 16:12:32,318 DEBUG TRAIN Batch 213/4800 loss 18.415604 loss_att 6.512887 loss_ctc 46.188606 loss_ctc_origin 30.293110 loss_ctc0 83.278091 lr 0.00057346 rank 0
2022-08-26 16:13:00,155 DEBUG TRAIN Batch 213/4900 loss 16.733679 loss_att 6.669977 loss_ctc 40.215649 loss_ctc_origin 23.517807 loss_ctc0 79.177277 lr 0.00057343 rank 0
2022-08-26 16:13:27,996 DEBUG TRAIN Batch 213/5000 loss 48.385384 loss_att 33.269474 loss_ctc 83.655830 loss_ctc_origin 55.023182 loss_ctc0 150.465332 lr 0.00057341 rank 0
2022-08-26 16:13:35,280 WARNING NaN or Inf found in input tensor.
2022-08-26 16:13:48,518 WARNING NaN or Inf found in input tensor.
2022-08-26 16:13:55,690 DEBUG TRAIN Batch 213/5100 loss 51.959282 loss_att 29.038122 loss_ctc 105.441994 loss_ctc_origin 63.055489 loss_ctc0 204.343842 lr 0.00057339 rank 0
2022-08-26 16:14:22,506 DEBUG TRAIN Batch 213/5200 loss 16.966785 loss_att 9.286057 loss_ctc 34.888481 loss_ctc_origin 24.063097 loss_ctc0 60.147701 lr 0.00057336 rank 0
2022-08-26 16:14:49,634 DEBUG TRAIN Batch 213/5300 loss 23.520142 loss_att 9.572116 loss_ctc 56.065529 loss_ctc_origin 41.017284 loss_ctc0 91.178093 lr 0.00057334 rank 0
2022-08-26 16:15:17,310 DEBUG TRAIN Batch 213/5400 loss 24.173231 loss_att 10.311287 loss_ctc 56.517761 loss_ctc_origin 38.322201 loss_ctc0 98.974068 lr 0.00057332 rank 0
2022-08-26 16:15:44,498 DEBUG TRAIN Batch 213/5500 loss 46.995888 loss_att 31.891659 loss_ctc 82.239090 loss_ctc_origin 55.157970 loss_ctc0 145.428375 lr 0.00057329 rank 0
2022-08-26 16:16:12,715 DEBUG TRAIN Batch 213/5600 loss 52.325508 loss_att 30.719978 loss_ctc 102.738411 loss_ctc_origin 59.970257 loss_ctc0 202.530762 lr 0.00057327 rank 0
2022-08-26 16:16:35,509 DEBUG CV Batch 213/0 loss 12.065926 loss_att 9.146746 loss_ctc 18.877344 loss_ctc_origin 12.740133 loss_ctc0 33.197502 history loss 11.356165 rank 0
2022-08-26 16:16:45,932 DEBUG CV Batch 213/100 loss 19.379219 loss_att 15.544416 loss_ctc 28.327095 loss_ctc_origin 18.089954 loss_ctc0 52.213760 history loss 25.767644 rank 0
2022-08-26 16:16:55,399 DEBUG CV Batch 213/200 loss 25.399097 loss_att 19.683498 loss_ctc 38.735497 loss_ctc_origin 28.689133 loss_ctc0 62.177010 history loss 27.010285 rank 0
2022-08-26 16:17:05,024 DEBUG CV Batch 213/300 loss 22.033308 loss_att 16.635023 loss_ctc 34.629307 loss_ctc_origin 18.910898 loss_ctc0 71.305588 history loss 26.200072 rank 0
2022-08-26 16:17:15,018 DEBUG CV Batch 213/400 loss 37.129608 loss_att 29.535347 loss_ctc 54.849548 loss_ctc_origin 38.199135 loss_ctc0 93.700516 history loss 24.564668 rank 0
2022-08-26 16:17:25,335 DEBUG CV Batch 213/500 loss 15.596399 loss_att 11.229666 loss_ctc 25.785442 loss_ctc_origin 18.915394 loss_ctc0 41.815552 history loss 24.202450 rank 0
2022-08-26 16:17:35,439 DEBUG CV Batch 213/600 loss 16.767746 loss_att 11.802074 loss_ctc 28.354313 loss_ctc_origin 17.491966 loss_ctc0 53.699791 history loss 24.036721 rank 0
2022-08-26 16:17:44,945 DEBUG CV Batch 213/700 loss 18.887976 loss_att 13.481895 loss_ctc 31.502163 loss_ctc_origin 17.939087 loss_ctc0 63.149338 history loss 23.713742 rank 0
2022-08-26 16:17:54,627 DEBUG CV Batch 213/800 loss 21.124237 loss_att 16.343109 loss_ctc 32.280205 loss_ctc_origin 16.970680 loss_ctc0 68.002426 history loss 23.678070 rank 0
2022-08-26 16:18:04,459 INFO Epoch 213 CV info cv_loss 23.759547947356214
2022-08-26 16:18:04,459 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/213.pt
2022-08-26 16:18:04,892 INFO Epoch 214 TRAIN info lr 0.0005732490123121498
2022-08-26 16:18:04,896 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 16:18:30,447 DEBUG TRAIN Batch 214/0 loss 50.771397 loss_att 36.329659 loss_ctc 84.468781 loss_ctc_origin 58.183056 loss_ctc0 145.802139 lr 0.00057325 rank 0
2022-08-26 16:18:57,771 DEBUG TRAIN Batch 214/100 loss 56.549606 loss_att 31.732044 loss_ctc 114.457245 loss_ctc_origin 68.962563 loss_ctc0 220.611496 lr 0.00057322 rank 0
2022-08-26 16:19:25,198 DEBUG TRAIN Batch 214/200 loss 19.235983 loss_att 11.520414 loss_ctc 37.238976 loss_ctc_origin 25.746923 loss_ctc0 64.053764 lr 0.00057320 rank 0
2022-08-26 16:19:51,730 DEBUG TRAIN Batch 214/300 loss 19.995605 loss_att 6.338418 loss_ctc 51.862373 loss_ctc_origin 40.179726 loss_ctc0 79.121887 lr 0.00057318 rank 0
2022-08-26 16:20:20,002 DEBUG TRAIN Batch 214/400 loss 19.359085 loss_att 7.136533 loss_ctc 47.878372 loss_ctc_origin 29.112438 loss_ctc0 91.665543 lr 0.00057315 rank 0
2022-08-26 16:20:47,135 DEBUG TRAIN Batch 214/500 loss 42.660709 loss_att 27.269958 loss_ctc 78.572464 loss_ctc_origin 53.890892 loss_ctc0 136.162781 lr 0.00057313 rank 0
2022-08-26 16:20:54,742 WARNING NaN or Inf found in input tensor.
2022-08-26 16:21:14,292 DEBUG TRAIN Batch 214/600 loss 58.756233 loss_att 34.093227 loss_ctc 116.303238 loss_ctc_origin 72.914276 loss_ctc0 217.544128 lr 0.00057311 rank 0
2022-08-26 16:21:40,708 WARNING NaN or Inf found in input tensor.
2022-08-26 16:21:42,245 DEBUG TRAIN Batch 214/700 loss 17.486549 loss_att 9.644635 loss_ctc 35.784348 loss_ctc_origin 24.979240 loss_ctc0 60.996262 lr 0.00057308 rank 0
2022-08-26 16:22:09,465 DEBUG TRAIN Batch 214/800 loss 17.549587 loss_att 6.747023 loss_ctc 42.755569 loss_ctc_origin 26.568521 loss_ctc0 80.525345 lr 0.00057306 rank 0
2022-08-26 16:22:32,690 WARNING NaN or Inf found in input tensor.
2022-08-26 16:22:37,051 DEBUG TRAIN Batch 214/900 loss 21.680990 loss_att 8.286783 loss_ctc 52.934135 loss_ctc_origin 34.047626 loss_ctc0 97.002647 lr 0.00057304 rank 0
2022-08-26 16:23:04,527 DEBUG TRAIN Batch 214/1000 loss 47.843578 loss_att 30.587217 loss_ctc 88.108414 loss_ctc_origin 57.105042 loss_ctc0 160.449615 lr 0.00057301 rank 0
2022-08-26 16:23:05,966 WARNING NaN or Inf found in input tensor.
2022-08-26 16:23:32,625 DEBUG TRAIN Batch 214/1100 loss 59.599030 loss_att 37.818008 loss_ctc 110.421417 loss_ctc_origin 70.017242 loss_ctc0 204.697830 lr 0.00057299 rank 0
2022-08-26 16:24:00,372 DEBUG TRAIN Batch 214/1200 loss 19.008978 loss_att 8.550814 loss_ctc 43.411362 loss_ctc_origin 31.778315 loss_ctc0 70.555145 lr 0.00057297 rank 0
2022-08-26 16:24:28,528 DEBUG TRAIN Batch 214/1300 loss 17.209124 loss_att 7.102420 loss_ctc 40.791431 loss_ctc_origin 26.219397 loss_ctc0 74.792847 lr 0.00057294 rank 0
2022-08-26 16:24:56,870 DEBUG TRAIN Batch 214/1400 loss 21.713089 loss_att 8.714750 loss_ctc 52.042542 loss_ctc_origin 32.746685 loss_ctc0 97.066193 lr 0.00057292 rank 0
2022-08-26 16:25:30,107 DEBUG TRAIN Batch 214/1500 loss 49.174240 loss_att 34.316593 loss_ctc 83.842087 loss_ctc_origin 57.050404 loss_ctc0 146.356018 lr 0.00057290 rank 0
2022-08-26 16:25:58,313 DEBUG TRAIN Batch 214/1600 loss 61.739349 loss_att 37.565029 loss_ctc 118.146095 loss_ctc_origin 80.537140 loss_ctc0 205.900330 lr 0.00057287 rank 0
2022-08-26 16:26:25,824 DEBUG TRAIN Batch 214/1700 loss 17.453171 loss_att 9.273436 loss_ctc 36.539215 loss_ctc_origin 24.474052 loss_ctc0 64.691254 lr 0.00057285 rank 0
2022-08-26 16:26:53,278 DEBUG TRAIN Batch 214/1800 loss 18.115543 loss_att 6.586846 loss_ctc 45.015839 loss_ctc_origin 28.767851 loss_ctc0 82.927811 lr 0.00057282 rank 0
2022-08-26 16:27:20,779 DEBUG TRAIN Batch 214/1900 loss 20.424572 loss_att 8.543097 loss_ctc 48.148018 loss_ctc_origin 30.131578 loss_ctc0 90.186371 lr 0.00057280 rank 0
2022-08-26 16:27:49,153 DEBUG TRAIN Batch 214/2000 loss 55.698059 loss_att 38.534988 loss_ctc 95.745224 loss_ctc_origin 66.523079 loss_ctc0 163.930237 lr 0.00057278 rank 0
2022-08-26 16:28:16,996 DEBUG TRAIN Batch 214/2100 loss 50.210365 loss_att 30.090868 loss_ctc 97.155853 loss_ctc_origin 60.645790 loss_ctc0 182.345978 lr 0.00057275 rank 0
2022-08-26 16:28:45,437 DEBUG TRAIN Batch 214/2200 loss 18.116623 loss_att 7.467612 loss_ctc 42.964310 loss_ctc_origin 31.772829 loss_ctc0 69.077759 lr 0.00057273 rank 0
2022-08-26 16:29:11,468 DEBUG TRAIN Batch 214/2300 loss 19.521683 loss_att 8.072109 loss_ctc 46.237350 loss_ctc_origin 29.827816 loss_ctc0 84.526253 lr 0.00057271 rank 0
2022-08-26 16:29:38,974 DEBUG TRAIN Batch 214/2400 loss 21.466322 loss_att 8.461658 loss_ctc 51.810532 loss_ctc_origin 30.857803 loss_ctc0 100.700233 lr 0.00057268 rank 0
2022-08-26 16:30:06,905 DEBUG TRAIN Batch 214/2500 loss 40.897030 loss_att 25.495981 loss_ctc 76.832809 loss_ctc_origin 50.816544 loss_ctc0 137.537415 lr 0.00057266 rank 0
2022-08-26 16:30:33,799 DEBUG TRAIN Batch 214/2600 loss 52.325043 loss_att 33.551243 loss_ctc 96.130569 loss_ctc_origin 55.230564 loss_ctc0 191.563904 lr 0.00057264 rank 0
2022-08-26 16:31:01,576 DEBUG TRAIN Batch 214/2700 loss 20.807365 loss_att 11.638688 loss_ctc 42.200943 loss_ctc_origin 31.452791 loss_ctc0 67.279968 lr 0.00057261 rank 0
2022-08-26 16:31:29,779 DEBUG TRAIN Batch 214/2800 loss 21.052074 loss_att 10.370423 loss_ctc 45.975929 loss_ctc_origin 32.910614 loss_ctc0 76.461670 lr 0.00057259 rank 0
2022-08-26 16:31:57,060 DEBUG TRAIN Batch 214/2900 loss 22.899971 loss_att 8.499521 loss_ctc 56.501015 loss_ctc_origin 38.806244 loss_ctc0 97.788818 lr 0.00057257 rank 0
2022-08-26 16:32:31,228 DEBUG TRAIN Batch 214/3000 loss 37.712814 loss_att 26.132214 loss_ctc 64.734215 loss_ctc_origin 41.867638 loss_ctc0 118.089554 lr 0.00057254 rank 0
2022-08-26 16:32:38,932 WARNING NaN or Inf found in input tensor.
2022-08-26 16:32:58,424 DEBUG TRAIN Batch 214/3100 loss 58.962933 loss_att 36.558048 loss_ctc 111.240997 loss_ctc_origin 61.484032 loss_ctc0 227.340576 lr 0.00057252 rank 0
2022-08-26 16:33:24,144 WARNING NaN or Inf found in input tensor.
2022-08-26 16:33:25,640 DEBUG TRAIN Batch 214/3200 loss 18.597916 loss_att 8.953589 loss_ctc 41.101341 loss_ctc_origin 29.843033 loss_ctc0 67.370728 lr 0.00057250 rank 0
2022-08-26 16:33:53,742 DEBUG TRAIN Batch 214/3300 loss 17.770493 loss_att 7.794857 loss_ctc 41.046974 loss_ctc_origin 27.295050 loss_ctc0 73.134796 lr 0.00057247 rank 0
2022-08-26 16:34:22,669 DEBUG TRAIN Batch 214/3400 loss 21.385460 loss_att 8.925372 loss_ctc 50.459000 loss_ctc_origin 32.930676 loss_ctc0 91.358421 lr 0.00057245 rank 0
2022-08-26 16:34:49,105 DEBUG TRAIN Batch 214/3500 loss 52.064346 loss_att 35.833183 loss_ctc 89.937057 loss_ctc_origin 59.412746 loss_ctc0 161.160446 lr 0.00057243 rank 0
2022-08-26 16:35:17,276 DEBUG TRAIN Batch 214/3600 loss 52.094261 loss_att 27.724592 loss_ctc 108.956818 loss_ctc_origin 61.552082 loss_ctc0 219.567856 lr 0.00057240 rank 0
2022-08-26 16:35:44,773 DEBUG TRAIN Batch 214/3700 loss 19.616108 loss_att 10.874229 loss_ctc 40.013821 loss_ctc_origin 29.280891 loss_ctc0 65.057320 lr 0.00057238 rank 0
2022-08-26 16:36:13,727 DEBUG TRAIN Batch 214/3800 loss 15.857555 loss_att 5.927874 loss_ctc 39.026814 loss_ctc_origin 24.399094 loss_ctc0 73.158157 lr 0.00057236 rank 0
2022-08-26 16:36:42,040 DEBUG TRAIN Batch 214/3900 loss 23.210361 loss_att 8.847519 loss_ctc 56.723656 loss_ctc_origin 36.806000 loss_ctc0 103.198181 lr 0.00057233 rank 0
2022-08-26 16:37:09,587 DEBUG TRAIN Batch 214/4000 loss 45.160316 loss_att 29.073572 loss_ctc 82.696045 loss_ctc_origin 57.743546 loss_ctc0 140.918549 lr 0.00057231 rank 0
2022-08-26 16:37:36,701 DEBUG TRAIN Batch 214/4100 loss 57.874180 loss_att 34.537861 loss_ctc 112.325592 loss_ctc_origin 69.285660 loss_ctc0 212.752090 lr 0.00057229 rank 0
2022-08-26 16:38:03,769 DEBUG TRAIN Batch 214/4200 loss 19.369194 loss_att 10.644878 loss_ctc 39.725929 loss_ctc_origin 28.590546 loss_ctc0 65.708488 lr 0.00057226 rank 0
2022-08-26 16:38:31,957 DEBUG TRAIN Batch 214/4300 loss 18.500605 loss_att 6.717724 loss_ctc 45.993992 loss_ctc_origin 31.171387 loss_ctc0 80.580063 lr 0.00057224 rank 0
2022-08-26 16:38:59,663 DEBUG TRAIN Batch 214/4400 loss 19.905769 loss_att 7.127040 loss_ctc 49.722805 loss_ctc_origin 30.148197 loss_ctc0 95.396889 lr 0.00057221 rank 0
2022-08-26 16:39:34,070 DEBUG TRAIN Batch 214/4500 loss 54.265686 loss_att 36.386284 loss_ctc 95.984283 loss_ctc_origin 66.695702 loss_ctc0 164.324310 lr 0.00057219 rank 0
2022-08-26 16:40:01,555 DEBUG TRAIN Batch 214/4600 loss 52.671635 loss_att 32.160736 loss_ctc 100.530396 loss_ctc_origin 62.853355 loss_ctc0 188.443481 lr 0.00057217 rank 0
2022-08-26 16:40:30,477 DEBUG TRAIN Batch 214/4700 loss 19.877346 loss_att 11.846157 loss_ctc 38.616783 loss_ctc_origin 28.705734 loss_ctc0 61.742569 lr 0.00057214 rank 0
2022-08-26 16:40:58,744 DEBUG TRAIN Batch 214/4800 loss 16.014072 loss_att 5.930145 loss_ctc 39.543236 loss_ctc_origin 22.982372 loss_ctc0 78.185249 lr 0.00057212 rank 0
2022-08-26 16:41:27,022 DEBUG TRAIN Batch 214/4900 loss 19.983387 loss_att 7.491909 loss_ctc 49.130165 loss_ctc_origin 30.090948 loss_ctc0 93.555000 lr 0.00057210 rank 0
2022-08-26 16:41:55,420 DEBUG TRAIN Batch 214/5000 loss 52.261589 loss_att 33.501888 loss_ctc 96.034225 loss_ctc_origin 66.246597 loss_ctc0 165.538696 lr 0.00057207 rank 0
2022-08-26 16:42:22,908 DEBUG TRAIN Batch 214/5100 loss 55.634300 loss_att 32.880383 loss_ctc 108.726761 loss_ctc_origin 63.665874 loss_ctc0 213.868835 lr 0.00057205 rank 0
2022-08-26 16:42:50,321 DEBUG TRAIN Batch 214/5200 loss 14.697586 loss_att 7.449651 loss_ctc 31.609432 loss_ctc_origin 19.881058 loss_ctc0 58.975639 lr 0.00057203 rank 0
2022-08-26 16:43:17,910 DEBUG TRAIN Batch 214/5300 loss 18.777163 loss_att 7.277680 loss_ctc 45.609283 loss_ctc_origin 29.179619 loss_ctc0 83.945168 lr 0.00057200 rank 0
2022-08-26 16:43:45,144 DEBUG TRAIN Batch 214/5400 loss 20.560017 loss_att 8.457327 loss_ctc 48.799622 loss_ctc_origin 31.924990 loss_ctc0 88.173767 lr 0.00057198 rank 0
2022-08-26 16:44:14,010 DEBUG TRAIN Batch 214/5500 loss 56.189358 loss_att 40.569359 loss_ctc 92.636024 loss_ctc_origin 66.228333 loss_ctc0 154.253967 lr 0.00057196 rank 0
2022-08-26 16:44:41,388 DEBUG TRAIN Batch 214/5600 loss 60.363934 loss_att 34.409889 loss_ctc 120.923363 loss_ctc_origin 76.668983 loss_ctc0 224.183578 lr 0.00057193 rank 0
2022-08-26 16:44:53,981 WARNING NaN or Inf found in input tensor.
2022-08-26 16:45:04,240 DEBUG CV Batch 214/0 loss 11.179428 loss_att 8.056992 loss_ctc 18.465113 loss_ctc_origin 11.875121 loss_ctc0 33.841759 history loss 10.521815 rank 0
2022-08-26 16:45:14,866 DEBUG CV Batch 214/100 loss 19.976049 loss_att 15.539395 loss_ctc 30.328239 loss_ctc_origin 20.498753 loss_ctc0 53.263702 history loss 25.924213 rank 0
2022-08-26 16:45:24,511 DEBUG CV Batch 214/200 loss 25.578579 loss_att 19.723282 loss_ctc 39.240940 loss_ctc_origin 29.096571 loss_ctc0 62.911133 history loss 27.142880 rank 0
2022-08-26 16:45:34,272 DEBUG CV Batch 214/300 loss 21.742538 loss_att 16.167633 loss_ctc 34.750652 loss_ctc_origin 19.200226 loss_ctc0 71.034973 history loss 26.264174 rank 0
2022-08-26 16:45:44,599 DEBUG CV Batch 214/400 loss 36.716442 loss_att 29.298935 loss_ctc 54.023956 loss_ctc_origin 37.068016 loss_ctc0 93.587822 history loss 24.588692 rank 0
2022-08-26 16:45:54,864 DEBUG CV Batch 214/500 loss 15.804477 loss_att 11.297479 loss_ctc 26.320805 loss_ctc_origin 19.543423 loss_ctc0 42.134697 history loss 24.230265 rank 0
2022-08-26 16:46:05,319 DEBUG CV Batch 214/600 loss 17.678638 loss_att 12.570688 loss_ctc 29.597191 loss_ctc_origin 19.027884 loss_ctc0 54.258904 history loss 24.059135 rank 0
2022-08-26 16:46:15,041 DEBUG CV Batch 214/700 loss 18.084206 loss_att 12.822275 loss_ctc 30.362041 loss_ctc_origin 16.288340 loss_ctc0 63.200684 history loss 23.729251 rank 0
2022-08-26 16:46:24,924 DEBUG CV Batch 214/800 loss 20.861010 loss_att 16.162535 loss_ctc 31.824118 loss_ctc_origin 15.908506 loss_ctc0 68.960541 history loss 23.686289 rank 0
2022-08-26 16:46:34,930 INFO Epoch 214 CV info cv_loss 23.763831665737726
2022-08-26 16:46:34,931 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/214.pt
2022-08-26 16:46:35,363 INFO Epoch 215 TRAIN info lr 0.0005719143212990994
2022-08-26 16:46:35,366 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 16:47:01,252 DEBUG TRAIN Batch 215/0 loss 49.707497 loss_att 32.882751 loss_ctc 88.965240 loss_ctc_origin 58.317543 loss_ctc0 160.476532 lr 0.00057191 rank 0
2022-08-26 16:47:29,283 DEBUG TRAIN Batch 215/100 loss 58.338051 loss_att 34.821331 loss_ctc 113.210388 loss_ctc_origin 77.065453 loss_ctc0 197.548584 lr 0.00057189 rank 0
2022-08-26 16:47:56,799 DEBUG TRAIN Batch 215/200 loss 18.706581 loss_att 11.157372 loss_ctc 36.321396 loss_ctc_origin 25.607931 loss_ctc0 61.319473 lr 0.00057187 rank 0
2022-08-26 16:48:23,972 DEBUG TRAIN Batch 215/300 loss 15.949507 loss_att 5.580735 loss_ctc 40.143307 loss_ctc_origin 25.322266 loss_ctc0 74.725731 lr 0.00057184 rank 0
2022-08-26 16:48:52,496 DEBUG TRAIN Batch 215/400 loss 19.909985 loss_att 7.853685 loss_ctc 48.041351 loss_ctc_origin 28.783239 loss_ctc0 92.976944 lr 0.00057182 rank 0
2022-08-26 16:48:55,181 WARNING NaN or Inf found in input tensor.
2022-08-26 16:49:20,991 DEBUG TRAIN Batch 215/500 loss 50.501060 loss_att 32.441330 loss_ctc 92.640434 loss_ctc_origin 63.985050 loss_ctc0 159.502991 lr 0.00057180 rank 0
2022-08-26 16:49:48,072 DEBUG TRAIN Batch 215/600 loss 57.161713 loss_att 34.364616 loss_ctc 110.354935 loss_ctc_origin 65.094025 loss_ctc0 215.963715 lr 0.00057177 rank 0
2022-08-26 16:50:14,942 DEBUG TRAIN Batch 215/700 loss 19.377150 loss_att 10.128862 loss_ctc 40.956482 loss_ctc_origin 29.387856 loss_ctc0 67.949944 lr 0.00057175 rank 0
2022-08-26 16:50:20,431 WARNING NaN or Inf found in input tensor.
2022-08-26 16:50:43,464 DEBUG TRAIN Batch 215/800 loss 20.735142 loss_att 7.942616 loss_ctc 50.584370 loss_ctc_origin 34.735062 loss_ctc0 87.566086 lr 0.00057173 rank 0
2022-08-26 16:51:11,715 DEBUG TRAIN Batch 215/900 loss 19.481558 loss_att 8.009162 loss_ctc 46.250481 loss_ctc_origin 29.490396 loss_ctc0 85.357330 lr 0.00057170 rank 0
2022-08-26 16:51:40,153 DEBUG TRAIN Batch 215/1000 loss 45.776985 loss_att 30.841251 loss_ctc 80.627029 loss_ctc_origin 54.935181 loss_ctc0 140.574661 lr 0.00057168 rank 0
2022-08-26 16:51:40,886 WARNING NaN or Inf found in input tensor.
2022-08-26 16:52:08,234 DEBUG TRAIN Batch 215/1100 loss 48.238110 loss_att 26.133842 loss_ctc 99.814728 loss_ctc_origin 59.424416 loss_ctc0 194.058762 lr 0.00057166 rank 0
2022-08-26 16:52:35,929 DEBUG TRAIN Batch 215/1200 loss 16.095604 loss_att 7.697818 loss_ctc 35.690434 loss_ctc_origin 21.718452 loss_ctc0 68.291718 lr 0.00057163 rank 0
2022-08-26 16:53:03,691 DEBUG TRAIN Batch 215/1300 loss 19.841457 loss_att 7.989076 loss_ctc 47.497009 loss_ctc_origin 31.804642 loss_ctc0 84.112534 lr 0.00057161 rank 0
2022-08-26 16:53:26,937 WARNING NaN or Inf found in input tensor.
2022-08-26 16:53:31,428 DEBUG TRAIN Batch 215/1400 loss 22.059925 loss_att 8.604590 loss_ctc 53.455704 loss_ctc_origin 34.104328 loss_ctc0 98.608917 lr 0.00057159 rank 0
2022-08-26 16:54:05,104 DEBUG TRAIN Batch 215/1500 loss 45.250416 loss_att 29.134842 loss_ctc 82.853424 loss_ctc_origin 53.186348 loss_ctc0 152.076599 lr 0.00057156 rank 0
2022-08-26 16:54:32,804 DEBUG TRAIN Batch 215/1600 loss 48.033298 loss_att 25.063484 loss_ctc 101.629524 loss_ctc_origin 58.537712 loss_ctc0 202.177078 lr 0.00057154 rank 0
2022-08-26 16:55:01,653 DEBUG TRAIN Batch 215/1700 loss 18.661415 loss_att 9.159758 loss_ctc 40.831947 loss_ctc_origin 30.336864 loss_ctc0 65.320473 lr 0.00057152 rank 0
2022-08-26 16:55:30,052 DEBUG TRAIN Batch 215/1800 loss 17.476151 loss_att 6.739157 loss_ctc 42.529133 loss_ctc_origin 27.549240 loss_ctc0 77.482216 lr 0.00057149 rank 0
2022-08-26 16:55:57,734 DEBUG TRAIN Batch 215/1900 loss 21.366596 loss_att 8.270864 loss_ctc 51.923302 loss_ctc_origin 34.748947 loss_ctc0 91.996796 lr 0.00057147 rank 0
2022-08-26 16:56:26,054 DEBUG TRAIN Batch 215/2000 loss 36.961636 loss_att 22.036127 loss_ctc 71.787819 loss_ctc_origin 49.186417 loss_ctc0 124.524422 lr 0.00057145 rank 0
2022-08-26 16:56:53,494 DEBUG TRAIN Batch 215/2100 loss 46.583694 loss_att 26.173265 loss_ctc 94.208023 loss_ctc_origin 50.566582 loss_ctc0 196.038055 lr 0.00057142 rank 0
2022-08-26 16:57:21,483 DEBUG TRAIN Batch 215/2200 loss 20.070292 loss_att 9.673929 loss_ctc 44.328468 loss_ctc_origin 33.671104 loss_ctc0 69.195656 lr 0.00057140 rank 0
2022-08-26 16:57:48,994 DEBUG TRAIN Batch 215/2300 loss 19.047844 loss_att 8.361337 loss_ctc 43.983025 loss_ctc_origin 30.399965 loss_ctc0 75.676834 lr 0.00057138 rank 0
2022-08-26 16:58:18,243 DEBUG TRAIN Batch 215/2400 loss 19.303417 loss_att 7.338359 loss_ctc 47.221886 loss_ctc_origin 28.724602 loss_ctc0 90.382202 lr 0.00057135 rank 0
2022-08-26 16:58:45,869 DEBUG TRAIN Batch 215/2500 loss 41.615158 loss_att 25.210392 loss_ctc 79.892944 loss_ctc_origin 52.237518 loss_ctc0 144.422256 lr 0.00057133 rank 0
2022-08-26 16:59:12,502 WARNING NaN or Inf found in input tensor.
2022-08-26 16:59:13,310 DEBUG TRAIN Batch 215/2600 loss 61.733868 loss_att 37.947578 loss_ctc 117.235199 loss_ctc_origin 73.156937 loss_ctc0 220.084473 lr 0.00057131 rank 0
2022-08-26 16:59:40,740 DEBUG TRAIN Batch 215/2700 loss 17.751257 loss_att 9.276847 loss_ctc 37.524879 loss_ctc_origin 26.159986 loss_ctc0 64.042969 lr 0.00057128 rank 0
2022-08-26 17:00:08,897 DEBUG TRAIN Batch 215/2800 loss 15.870585 loss_att 5.754907 loss_ctc 39.473835 loss_ctc_origin 25.828890 loss_ctc0 71.312035 lr 0.00057126 rank 0
2022-08-26 17:00:35,435 DEBUG TRAIN Batch 215/2900 loss 18.678125 loss_att 7.654948 loss_ctc 44.398872 loss_ctc_origin 27.775211 loss_ctc0 83.187408 lr 0.00057124 rank 0
2022-08-26 17:01:10,092 DEBUG TRAIN Batch 215/3000 loss 49.592361 loss_att 30.978149 loss_ctc 93.025513 loss_ctc_origin 58.880737 loss_ctc0 172.696671 lr 0.00057121 rank 0
2022-08-26 17:01:36,876 DEBUG TRAIN Batch 215/3100 loss 53.267136 loss_att 29.340092 loss_ctc 109.096909 loss_ctc_origin 63.923203 loss_ctc0 214.502228 lr 0.00057119 rank 0
2022-08-26 17:02:04,041 DEBUG TRAIN Batch 215/3200 loss 17.516642 loss_att 8.701883 loss_ctc 38.084412 loss_ctc_origin 27.213774 loss_ctc0 63.449230 lr 0.00057117 rank 0
2022-08-26 17:02:31,585 DEBUG TRAIN Batch 215/3300 loss 20.812508 loss_att 8.908500 loss_ctc 48.588524 loss_ctc_origin 35.182396 loss_ctc0 79.869492 lr 0.00057114 rank 0
2022-08-26 17:02:58,837 DEBUG TRAIN Batch 215/3400 loss 19.685013 loss_att 7.890750 loss_ctc 47.204956 loss_ctc_origin 29.604979 loss_ctc0 88.271576 lr 0.00057112 rank 0
2022-08-26 17:03:27,632 DEBUG TRAIN Batch 215/3500 loss 43.681942 loss_att 27.126694 loss_ctc 82.310852 loss_ctc_origin 55.830864 loss_ctc0 144.097473 lr 0.00057110 rank 0
2022-08-26 17:03:55,500 DEBUG TRAIN Batch 215/3600 loss 60.729622 loss_att 39.012787 loss_ctc 111.402222 loss_ctc_origin 69.457924 loss_ctc0 209.272247 lr 0.00057107 rank 0
2022-08-26 17:04:22,443 DEBUG TRAIN Batch 215/3700 loss 16.360970 loss_att 7.361336 loss_ctc 37.360115 loss_ctc_origin 24.914001 loss_ctc0 66.401054 lr 0.00057105 rank 0
2022-08-26 17:04:51,325 DEBUG TRAIN Batch 215/3800 loss 15.587043 loss_att 6.520875 loss_ctc 36.741432 loss_ctc_origin 22.555437 loss_ctc0 69.842079 lr 0.00057103 rank 0
2022-08-26 17:05:21,156 DEBUG TRAIN Batch 215/3900 loss 21.111464 loss_att 8.182043 loss_ctc 51.280113 loss_ctc_origin 31.498095 loss_ctc0 97.438156 lr 0.00057100 rank 0
2022-08-26 17:05:47,302 DEBUG TRAIN Batch 215/4000 loss 42.053658 loss_att 26.081066 loss_ctc 79.323029 loss_ctc_origin 43.841988 loss_ctc0 162.112122 lr 0.00057098 rank 0
2022-08-26 17:06:14,731 DEBUG TRAIN Batch 215/4100 loss 51.066864 loss_att 25.006317 loss_ctc 111.874802 loss_ctc_origin 63.147415 loss_ctc0 225.572021 lr 0.00057096 rank 0
2022-08-26 17:06:41,805 DEBUG TRAIN Batch 215/4200 loss 19.024420 loss_att 9.206319 loss_ctc 41.933319 loss_ctc_origin 31.608135 loss_ctc0 66.025421 lr 0.00057093 rank 0
2022-08-26 17:07:10,072 DEBUG TRAIN Batch 215/4300 loss 18.456573 loss_att 7.252389 loss_ctc 44.599670 loss_ctc_origin 30.536728 loss_ctc0 77.413200 lr 0.00057091 rank 0
2022-08-26 17:07:36,961 DEBUG TRAIN Batch 215/4400 loss 21.850372 loss_att 8.373083 loss_ctc 53.297382 loss_ctc_origin 35.213249 loss_ctc0 95.493690 lr 0.00057089 rank 0
2022-08-26 17:08:10,904 DEBUG TRAIN Batch 215/4500 loss 47.421509 loss_att 28.561344 loss_ctc 91.428558 loss_ctc_origin 57.762173 loss_ctc0 169.983459 lr 0.00057086 rank 0
2022-08-26 17:08:38,190 DEBUG TRAIN Batch 215/4600 loss 49.774109 loss_att 26.748428 loss_ctc 103.500687 loss_ctc_origin 52.676018 loss_ctc0 222.091583 lr 0.00057084 rank 0
2022-08-26 17:09:05,119 DEBUG TRAIN Batch 215/4700 loss 20.807220 loss_att 12.495354 loss_ctc 40.201576 loss_ctc_origin 30.193989 loss_ctc0 63.552605 lr 0.00057082 rank 0
2022-08-26 17:09:33,618 DEBUG TRAIN Batch 215/4800 loss 23.630718 loss_att 8.479241 loss_ctc 58.984161 loss_ctc_origin 44.419739 loss_ctc0 92.967819 lr 0.00057079 rank 0
2022-08-26 17:10:01,048 DEBUG TRAIN Batch 215/4900 loss 19.914660 loss_att 7.878819 loss_ctc 47.998283 loss_ctc_origin 28.026577 loss_ctc0 94.598938 lr 0.00057077 rank 0
2022-08-26 17:10:28,134 DEBUG TRAIN Batch 215/5000 loss 47.073746 loss_att 30.432051 loss_ctc 85.904358 loss_ctc_origin 53.631332 loss_ctc0 161.208084 lr 0.00057075 rank 0
2022-08-26 17:10:35,658 WARNING NaN or Inf found in input tensor.
2022-08-26 17:10:54,895 DEBUG TRAIN Batch 215/5100 loss 60.703815 loss_att 31.010557 loss_ctc 129.988083 loss_ctc_origin 71.171982 loss_ctc0 267.225647 lr 0.00057072 rank 0
2022-08-26 17:11:21,803 DEBUG TRAIN Batch 215/5200 loss 21.948473 loss_att 11.168266 loss_ctc 47.102287 loss_ctc_origin 37.552338 loss_ctc0 69.385498 lr 0.00057070 rank 0
2022-08-26 17:11:49,551 DEBUG TRAIN Batch 215/5300 loss 18.954407 loss_att 7.539691 loss_ctc 45.588745 loss_ctc_origin 30.134138 loss_ctc0 81.649490 lr 0.00057068 rank 0
2022-08-26 17:12:18,245 DEBUG TRAIN Batch 215/5400 loss 18.967846 loss_att 7.236301 loss_ctc 46.341446 loss_ctc_origin 26.134300 loss_ctc0 93.491440 lr 0.00057065 rank 0
2022-08-26 17:12:45,672 DEBUG TRAIN Batch 215/5500 loss 43.366173 loss_att 25.393396 loss_ctc 85.302643 loss_ctc_origin 49.000301 loss_ctc0 170.008118 lr 0.00057063 rank 0
2022-08-26 17:13:13,556 DEBUG TRAIN Batch 215/5600 loss -6222406475550755552188122005504.000000 loss_att 36.977821 loss_ctc -20741354112551972097540956880896.000000 loss_ctc_origin 69.869514 loss_ctc0 -69137843818037721352792057053184.000000 lr 0.00057061 rank 0
2022-08-26 17:13:36,541 DEBUG CV Batch 215/0 loss 11.344654 loss_att 8.675379 loss_ctc 17.572964 loss_ctc_origin 10.602300 loss_ctc0 33.837845 history loss 10.677321 rank 0
2022-08-26 17:13:46,947 DEBUG CV Batch 215/100 loss 20.653191 loss_att 16.476353 loss_ctc 30.399147 loss_ctc_origin 20.940544 loss_ctc0 52.469219 history loss 26.009703 rank 0
2022-08-26 17:13:56,495 DEBUG CV Batch 215/200 loss 24.366491 loss_att 18.585781 loss_ctc 37.854813 loss_ctc_origin 27.033405 loss_ctc0 63.104752 history loss 27.271191 rank 0
2022-08-26 17:14:06,018 DEBUG CV Batch 215/300 loss 22.349373 loss_att 16.968533 loss_ctc 34.904663 loss_ctc_origin 19.253368 loss_ctc0 71.424347 history loss 26.422571 rank 0
2022-08-26 17:14:16,431 DEBUG CV Batch 215/400 loss 36.964378 loss_att 29.401754 loss_ctc 54.610497 loss_ctc_origin 37.667912 loss_ctc0 94.143188 history loss 24.771200 rank 0
2022-08-26 17:14:26,783 DEBUG CV Batch 215/500 loss 15.711334 loss_att 11.798558 loss_ctc 24.841145 loss_ctc_origin 17.837477 loss_ctc0 41.183037 history loss 24.412183 rank 0
2022-08-26 17:14:37,018 DEBUG CV Batch 215/600 loss 17.631104 loss_att 12.754825 loss_ctc 29.009089 loss_ctc_origin 18.725113 loss_ctc0 53.005028 history loss 24.240729 rank 0
2022-08-26 17:14:47,400 DEBUG CV Batch 215/700 loss 18.072472 loss_att 12.610233 loss_ctc 30.817698 loss_ctc_origin 17.256622 loss_ctc0 62.460205 history loss 23.921793 rank 0
2022-08-26 17:14:57,746 DEBUG CV Batch 215/800 loss 21.803490 loss_att 17.050526 loss_ctc 32.893738 loss_ctc_origin 17.525484 loss_ctc0 68.752998 history loss 23.871568 rank 0
2022-08-26 17:15:08,260 INFO Epoch 215 CV info cv_loss 23.96171292488512
2022-08-26 17:15:08,260 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/215.pt
2022-08-26 17:15:08,685 INFO Epoch 216 TRAIN info lr 0.0005705889097345563
2022-08-26 17:15:08,689 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 17:15:34,551 DEBUG TRAIN Batch 216/0 loss 48.890404 loss_att 30.050829 loss_ctc 92.849411 loss_ctc_origin 60.052742 loss_ctc0 169.374969 lr 0.00057059 rank 0
2022-08-26 17:15:35,365 WARNING NaN or Inf found in input tensor.
2022-08-26 17:16:02,890 DEBUG TRAIN Batch 216/100 loss 59.246990 loss_att 33.328613 loss_ctc 119.723206 loss_ctc_origin 70.934006 loss_ctc0 233.564636 lr 0.00057056 rank 0
2022-08-26 17:16:30,758 DEBUG TRAIN Batch 216/200 loss 15.308922 loss_att 7.886910 loss_ctc 32.626945 loss_ctc_origin 20.857550 loss_ctc0 60.088860 lr 0.00057054 rank 0
2022-08-26 17:16:59,449 DEBUG TRAIN Batch 216/300 loss 18.867655 loss_att 6.910916 loss_ctc 46.766708 loss_ctc_origin 30.827484 loss_ctc0 83.958229 lr 0.00057052 rank 0
2022-08-26 17:17:26,899 DEBUG TRAIN Batch 216/400 loss 23.737181 loss_att 9.583015 loss_ctc 56.763565 loss_ctc_origin 38.843361 loss_ctc0 98.577370 lr 0.00057050 rank 0
2022-08-26 17:17:54,906 DEBUG TRAIN Batch 216/500 loss 47.331085 loss_att 28.807095 loss_ctc 90.553726 loss_ctc_origin 57.058025 loss_ctc0 168.710358 lr 0.00057047 rank 0
2022-08-26 17:18:22,382 DEBUG TRAIN Batch 216/600 loss 56.770481 loss_att 29.934616 loss_ctc 119.387497 loss_ctc_origin 67.415657 loss_ctc0 240.655121 lr 0.00057045 rank 0
2022-08-26 17:18:50,978 DEBUG TRAIN Batch 216/700 loss 17.132498 loss_att 8.190087 loss_ctc 37.998123 loss_ctc_origin 23.514921 loss_ctc0 71.792252 lr 0.00057043 rank 0
2022-08-26 17:19:18,571 DEBUG TRAIN Batch 216/800 loss 17.692873 loss_att 6.543936 loss_ctc 43.707062 loss_ctc_origin 28.916407 loss_ctc0 78.218582 lr 0.00057040 rank 0
2022-08-26 17:19:35,518 WARNING NaN or Inf found in input tensor.
2022-08-26 17:19:46,890 DEBUG TRAIN Batch 216/900 loss 17.398682 loss_att 7.132411 loss_ctc 41.353310 loss_ctc_origin 24.650589 loss_ctc0 80.326317 lr 0.00057038 rank 0
2022-08-26 17:20:14,748 DEBUG TRAIN Batch 216/1000 loss 47.418259 loss_att 29.965981 loss_ctc 88.140236 loss_ctc_origin 55.796032 loss_ctc0 163.610046 lr 0.00057036 rank 0
2022-08-26 17:20:42,452 DEBUG TRAIN Batch 216/1100 loss 55.168365 loss_att 31.010660 loss_ctc 111.536339 loss_ctc_origin 60.363129 loss_ctc0 230.940491 lr 0.00057033 rank 0
2022-08-26 17:21:10,267 DEBUG TRAIN Batch 216/1200 loss 18.919031 loss_att 9.664083 loss_ctc 40.513912 loss_ctc_origin 29.510704 loss_ctc0 66.188065 lr 0.00057031 rank 0
2022-08-26 17:21:38,490 DEBUG TRAIN Batch 216/1300 loss 14.249730 loss_att 5.608653 loss_ctc 34.412243 loss_ctc_origin 19.375326 loss_ctc0 69.498383 lr 0.00057029 rank 0
2022-08-26 17:22:05,722 DEBUG TRAIN Batch 216/1400 loss 17.736031 loss_att 7.356593 loss_ctc 41.954712 loss_ctc_origin 23.196867 loss_ctc0 85.723007 lr 0.00057026 rank 0
2022-08-26 17:22:38,269 DEBUG TRAIN Batch 216/1500 loss 44.699459 loss_att 30.616991 loss_ctc 77.558548 loss_ctc_origin 50.084824 loss_ctc0 141.663910 lr 0.00057024 rank 0
2022-08-26 17:23:06,162 DEBUG TRAIN Batch 216/1600 loss 47.220509 loss_att 24.301989 loss_ctc 100.697052 loss_ctc_origin 50.776070 loss_ctc0 217.179321 lr 0.00057022 rank 0
2022-08-26 17:23:32,778 DEBUG TRAIN Batch 216/1700 loss 16.651121 loss_att 7.677816 loss_ctc 37.588829 loss_ctc_origin 26.658813 loss_ctc0 63.092205 lr 0.00057019 rank 0
2022-08-26 17:23:44,321 WARNING NaN or Inf found in input tensor.
2022-08-26 17:24:00,272 DEBUG TRAIN Batch 216/1800 loss 16.663200 loss_att 7.236587 loss_ctc 38.658634 loss_ctc_origin 23.655346 loss_ctc0 73.666306 lr 0.00057017 rank 0
2022-08-26 17:24:27,563 DEBUG TRAIN Batch 216/1900 loss 20.319298 loss_att 8.241767 loss_ctc 48.500198 loss_ctc_origin 28.825989 loss_ctc0 94.406685 lr 0.00057015 rank 0
2022-08-26 17:24:56,321 DEBUG TRAIN Batch 216/2000 loss 38.035927 loss_att 24.016376 loss_ctc 70.748215 loss_ctc_origin 45.461926 loss_ctc0 129.749542 lr 0.00057012 rank 0
2022-08-26 17:25:24,545 DEBUG TRAIN Batch 216/2100 loss 53.023170 loss_att 31.153862 loss_ctc 104.051552 loss_ctc_origin 52.977417 loss_ctc0 223.224518 lr 0.00057010 rank 0
2022-08-26 17:25:52,170 DEBUG TRAIN Batch 216/2200 loss 18.892689 loss_att 11.892546 loss_ctc 35.226357 loss_ctc_origin 25.890518 loss_ctc0 57.009979 lr 0.00057008 rank 0
2022-08-26 17:26:19,655 DEBUG TRAIN Batch 216/2300 loss 16.925489 loss_att 6.600649 loss_ctc 41.016785 loss_ctc_origin 25.898233 loss_ctc0 76.293411 lr 0.00057005 rank 0
2022-08-26 17:26:23,341 WARNING NaN or Inf found in input tensor.
2022-08-26 17:26:47,239 DEBUG TRAIN Batch 216/2400 loss 19.226166 loss_att 7.156894 loss_ctc 47.387802 loss_ctc_origin 26.882965 loss_ctc0 95.232414 lr 0.00057003 rank 0
2022-08-26 17:27:14,729 DEBUG TRAIN Batch 216/2500 loss 43.431400 loss_att 25.515501 loss_ctc 85.235161 loss_ctc_origin 52.566994 loss_ctc0 161.460876 lr 0.00057001 rank 0
2022-08-26 17:27:41,777 DEBUG TRAIN Batch 216/2600 loss 54.205322 loss_att 30.776691 loss_ctc 108.872131 loss_ctc_origin 65.275467 loss_ctc0 210.597687 lr 0.00056999 rank 0
2022-08-26 17:28:09,608 DEBUG TRAIN Batch 216/2700 loss 20.153053 loss_att 10.303856 loss_ctc 43.134514 loss_ctc_origin 32.648762 loss_ctc0 67.601273 lr 0.00056996 rank 0
2022-08-26 17:28:36,726 DEBUG TRAIN Batch 216/2800 loss 16.295591 loss_att 6.828890 loss_ctc 38.384560 loss_ctc_origin 22.624767 loss_ctc0 75.157402 lr 0.00056994 rank 0
2022-08-26 17:29:00,020 WARNING NaN or Inf found in input tensor.
2022-08-26 17:29:04,430 DEBUG TRAIN Batch 216/2900 loss 20.111097 loss_att 7.758514 loss_ctc 48.933788 loss_ctc_origin 28.583469 loss_ctc0 96.417862 lr 0.00056992 rank 0
2022-08-26 17:29:35,940 DEBUG TRAIN Batch 216/3000 loss 52.506531 loss_att 33.191994 loss_ctc 97.573776 loss_ctc_origin 67.123543 loss_ctc0 168.624329 lr 0.00056989 rank 0
2022-08-26 17:30:03,597 DEBUG TRAIN Batch 216/3100 loss 47.770126 loss_att 26.039478 loss_ctc 98.474976 loss_ctc_origin 54.902718 loss_ctc0 200.143585 lr 0.00056987 rank 0
2022-08-26 17:30:30,085 DEBUG TRAIN Batch 216/3200 loss 18.266558 loss_att 10.398656 loss_ctc 36.624992 loss_ctc_origin 24.355118 loss_ctc0 65.254707 lr 0.00056985 rank 0
2022-08-26 17:30:57,811 DEBUG TRAIN Batch 216/3300 loss 17.968697 loss_att 7.396459 loss_ctc 42.637253 loss_ctc_origin 25.583715 loss_ctc0 82.428848 lr 0.00056982 rank 0
2022-08-26 17:31:25,145 DEBUG TRAIN Batch 216/3400 loss 21.536552 loss_att 8.639563 loss_ctc 51.629524 loss_ctc_origin 32.373512 loss_ctc0 96.560211 lr 0.00056980 rank 0
2022-08-26 17:31:52,681 DEBUG TRAIN Batch 216/3500 loss 47.158554 loss_att 28.026882 loss_ctc 91.799126 loss_ctc_origin 55.175179 loss_ctc0 177.255005 lr 0.00056978 rank 0
2022-08-26 17:32:20,783 DEBUG TRAIN Batch 216/3600 loss 57.808941 loss_att 30.124533 loss_ctc 122.405884 loss_ctc_origin 62.029491 loss_ctc0 263.284119 lr 0.00056975 rank 0
2022-08-26 17:32:48,224 DEBUG TRAIN Batch 216/3700 loss 16.809059 loss_att 8.466883 loss_ctc 36.274139 loss_ctc_origin 24.849102 loss_ctc0 62.932568 lr 0.00056973 rank 0
2022-08-26 17:33:15,981 DEBUG TRAIN Batch 216/3800 loss 19.753242 loss_att 7.208714 loss_ctc 49.023804 loss_ctc_origin 32.984558 loss_ctc0 86.448715 lr 0.00056971 rank 0
2022-08-26 17:33:43,572 DEBUG TRAIN Batch 216/3900 loss 19.609478 loss_att 7.647046 loss_ctc 47.521820 loss_ctc_origin 29.127178 loss_ctc0 90.442650 lr 0.00056968 rank 0
2022-08-26 17:34:11,213 DEBUG TRAIN Batch 216/4000 loss 49.561947 loss_att 31.080593 loss_ctc 92.685104 loss_ctc_origin 56.357162 loss_ctc0 177.450287 lr 0.00056966 rank 0
2022-08-26 17:34:39,199 DEBUG TRAIN Batch 216/4100 loss 61.167526 loss_att 36.688602 loss_ctc 118.285004 loss_ctc_origin 75.480316 loss_ctc0 218.162598 lr 0.00056964 rank 0
2022-08-26 17:35:05,024 DEBUG TRAIN Batch 216/4200 loss 16.757458 loss_att 7.472639 loss_ctc 38.422031 loss_ctc_origin 27.941061 loss_ctc0 62.877628 lr 0.00056962 rank 0
2022-08-26 17:35:32,571 DEBUG TRAIN Batch 216/4300 loss 15.928476 loss_att 7.174469 loss_ctc 36.354492 loss_ctc_origin 23.503405 loss_ctc0 66.340363 lr 0.00056959 rank 0
2022-08-26 17:35:59,597 DEBUG TRAIN Batch 216/4400 loss 23.097893 loss_att 9.409817 loss_ctc 55.036736 loss_ctc_origin 37.648323 loss_ctc0 95.609695 lr 0.00056957 rank 0
2022-08-26 17:36:33,554 DEBUG TRAIN Batch 216/4500 loss 54.561836 loss_att 37.260910 loss_ctc 94.930664 loss_ctc_origin 66.094727 loss_ctc0 162.214523 lr 0.00056955 rank 0
2022-08-26 17:36:41,340 WARNING NaN or Inf found in input tensor.
2022-08-26 17:37:00,927 DEBUG TRAIN Batch 216/4600 loss 60.468781 loss_att 33.554138 loss_ctc 123.269615 loss_ctc_origin 77.035728 loss_ctc0 231.148682 lr 0.00056952 rank 0
2022-08-26 17:37:27,850 DEBUG TRAIN Batch 216/4700 loss 20.801216 loss_att 10.179515 loss_ctc 45.585186 loss_ctc_origin 33.878792 loss_ctc0 72.900101 lr 0.00056950 rank 0
2022-08-26 17:37:55,067 DEBUG TRAIN Batch 216/4800 loss 19.966509 loss_att 7.823890 loss_ctc 48.299286 loss_ctc_origin 34.256195 loss_ctc0 81.066498 lr 0.00056948 rank 0
2022-08-26 17:38:22,006 DEBUG TRAIN Batch 216/4900 loss 21.659340 loss_att 8.719660 loss_ctc 51.851929 loss_ctc_origin 33.667725 loss_ctc0 94.281731 lr 0.00056945 rank 0
2022-08-26 17:38:24,526 WARNING NaN or Inf found in input tensor.
2022-08-26 17:38:50,202 DEBUG TRAIN Batch 216/5000 loss 42.865635 loss_att 26.304241 loss_ctc 81.508888 loss_ctc_origin 51.557137 loss_ctc0 151.396301 lr 0.00056943 rank 0
2022-08-26 17:38:57,502 WARNING NaN or Inf found in input tensor.
2022-08-26 17:39:17,375 DEBUG TRAIN Batch 216/5100 loss 57.281227 loss_att 30.505806 loss_ctc 119.757202 loss_ctc_origin 65.282036 loss_ctc0 246.865906 lr 0.00056941 rank 0
2022-08-26 17:39:45,700 DEBUG TRAIN Batch 216/5200 loss 18.804064 loss_att 9.117141 loss_ctc 41.406883 loss_ctc_origin 30.035984 loss_ctc0 67.938988 lr 0.00056938 rank 0
2022-08-26 17:40:13,443 DEBUG TRAIN Batch 216/5300 loss 17.820225 loss_att 7.638129 loss_ctc 41.578445 loss_ctc_origin 24.734364 loss_ctc0 80.881294 lr 0.00056936 rank 0
2022-08-26 17:40:30,148 WARNING NaN or Inf found in input tensor.
2022-08-26 17:40:43,239 DEBUG TRAIN Batch 216/5400 loss 19.505623 loss_att 7.311984 loss_ctc 47.957443 loss_ctc_origin 28.405560 loss_ctc0 93.578499 lr 0.00056934 rank 0
2022-08-26 17:41:09,587 DEBUG TRAIN Batch 216/5500 loss 49.440315 loss_att 30.588009 loss_ctc 93.429024 loss_ctc_origin 59.072491 loss_ctc0 173.594269 lr 0.00056932 rank 0
2022-08-26 17:41:36,072 DEBUG TRAIN Batch 216/5600 loss 61.013557 loss_att 37.557678 loss_ctc 115.743942 loss_ctc_origin 68.163536 loss_ctc0 226.764862 lr 0.00056929 rank 0
2022-08-26 17:41:59,410 DEBUG CV Batch 216/0 loss 12.244996 loss_att 9.250512 loss_ctc 19.232124 loss_ctc_origin 12.640785 loss_ctc0 34.611912 history loss 11.524702 rank 0
2022-08-26 17:42:09,933 DEBUG CV Batch 216/100 loss 20.645828 loss_att 16.547009 loss_ctc 30.209740 loss_ctc_origin 20.372015 loss_ctc0 53.164425 history loss 26.228147 rank 0
2022-08-26 17:42:19,460 DEBUG CV Batch 216/200 loss 24.033497 loss_att 18.402256 loss_ctc 37.173058 loss_ctc_origin 26.143990 loss_ctc0 62.907555 history loss 27.298037 rank 0
2022-08-26 17:42:29,077 DEBUG CV Batch 216/300 loss 22.595978 loss_att 16.988337 loss_ctc 35.680477 loss_ctc_origin 20.105652 loss_ctc0 72.021729 history loss 26.417750 rank 0
2022-08-26 17:42:39,812 DEBUG CV Batch 216/400 loss 37.171997 loss_att 29.622612 loss_ctc 54.787231 loss_ctc_origin 37.333893 loss_ctc0 95.511696 history loss 24.787075 rank 0
2022-08-26 17:42:49,852 DEBUG CV Batch 216/500 loss 15.741914 loss_att 11.458566 loss_ctc 25.736391 loss_ctc_origin 18.499676 loss_ctc0 42.622059 history loss 24.458597 rank 0
2022-08-26 17:43:00,073 DEBUG CV Batch 216/600 loss 17.358616 loss_att 12.389246 loss_ctc 28.953808 loss_ctc_origin 18.292475 loss_ctc0 53.830254 history loss 24.300227 rank 0
2022-08-26 17:43:10,028 DEBUG CV Batch 216/700 loss 17.954193 loss_att 12.689505 loss_ctc 30.238464 loss_ctc_origin 16.109997 loss_ctc0 63.204891 history loss 23.955500 rank 0
2022-08-26 17:43:20,036 DEBUG CV Batch 216/800 loss 21.444473 loss_att 16.714148 loss_ctc 32.481895 loss_ctc_origin 16.768381 loss_ctc0 69.146759 history loss 23.912973 rank 0
2022-08-26 17:43:29,884 INFO Epoch 216 CV info cv_loss 23.984455970523996
2022-08-26 17:43:29,884 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/216.pt
2022-08-26 17:43:30,360 INFO Epoch 217 TRAIN info lr 0.0005692726705887919
2022-08-26 17:43:30,364 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 17:43:55,835 DEBUG TRAIN Batch 217/0 loss 52.031876 loss_att 34.953617 loss_ctc 91.881142 loss_ctc_origin 63.215660 loss_ctc0 158.767258 lr 0.00056927 rank 0
2022-08-26 17:44:23,070 WARNING NaN or Inf found in input tensor.
2022-08-26 17:44:23,831 DEBUG TRAIN Batch 217/100 loss 57.520336 loss_att 32.418236 loss_ctc 116.091904 loss_ctc_origin 71.215652 loss_ctc0 220.803131 lr 0.00056925 rank 0
2022-08-26 17:44:52,486 DEBUG TRAIN Batch 217/200 loss 16.544605 loss_att 7.631025 loss_ctc 37.342957 loss_ctc_origin 24.988064 loss_ctc0 66.171036 lr 0.00056923 rank 0
2022-08-26 17:45:19,871 DEBUG TRAIN Batch 217/300 loss 17.924435 loss_att 7.334580 loss_ctc 42.634094 loss_ctc_origin 28.276436 loss_ctc0 76.135300 lr 0.00056920 rank 0
2022-08-26 17:45:48,141 DEBUG TRAIN Batch 217/400 loss 23.200737 loss_att 9.200830 loss_ctc 55.867180 loss_ctc_origin 37.163219 loss_ctc0 99.509743 lr 0.00056918 rank 0
2022-08-26 17:46:14,706 DEBUG TRAIN Batch 217/500 loss 47.101894 loss_att 30.980888 loss_ctc 84.717575 loss_ctc_origin 52.496433 loss_ctc0 159.900223 lr 0.00056916 rank 0
2022-08-26 17:46:21,719 WARNING NaN or Inf found in input tensor.
2022-08-26 17:46:41,875 DEBUG TRAIN Batch 217/600 loss 54.026497 loss_att 32.510895 loss_ctc 104.229576 loss_ctc_origin 63.406303 loss_ctc0 199.483871 lr 0.00056913 rank 0
2022-08-26 17:47:09,257 DEBUG TRAIN Batch 217/700 loss 17.094954 loss_att 7.383255 loss_ctc 39.755585 loss_ctc_origin 28.148521 loss_ctc0 66.838730 lr 0.00056911 rank 0
2022-08-26 17:47:37,041 DEBUG TRAIN Batch 217/800 loss 19.118513 loss_att 7.389334 loss_ctc 46.486595 loss_ctc_origin 31.856087 loss_ctc0 80.624435 lr 0.00056909 rank 0
2022-08-26 17:48:05,368 DEBUG TRAIN Batch 217/900 loss 21.421858 loss_att 8.136761 loss_ctc 52.420414 loss_ctc_origin 34.277542 loss_ctc0 94.753777 lr 0.00056906 rank 0
2022-08-26 17:48:33,346 DEBUG TRAIN Batch 217/1000 loss 48.864521 loss_att 32.914024 loss_ctc 86.082344 loss_ctc_origin 56.471157 loss_ctc0 155.175110 lr 0.00056904 rank 0
2022-08-26 17:48:46,159 WARNING NaN or Inf found in input tensor.
2022-08-26 17:49:00,322 DEBUG TRAIN Batch 217/1100 loss 57.104927 loss_att 34.009277 loss_ctc 110.994781 loss_ctc_origin 71.793213 loss_ctc0 202.465088 lr 0.00056902 rank 0
2022-08-26 17:49:25,016 WARNING NaN or Inf found in input tensor.
2022-08-26 17:49:26,600 DEBUG TRAIN Batch 217/1200 loss 15.913296 loss_att 6.683804 loss_ctc 37.448776 loss_ctc_origin 25.852785 loss_ctc0 64.506088 lr 0.00056900 rank 0
2022-08-26 17:49:57,777 DEBUG TRAIN Batch 217/1300 loss 20.151707 loss_att 8.511701 loss_ctc 47.311722 loss_ctc_origin 32.988403 loss_ctc0 80.732788 lr 0.00056897 rank 0
2022-08-26 17:50:12,252 WARNING NaN or Inf found in input tensor.
2022-08-26 17:50:23,392 DEBUG TRAIN Batch 217/1400 loss 21.976044 loss_att 9.794371 loss_ctc 50.399948 loss_ctc_origin 34.036701 loss_ctc0 88.580849 lr 0.00056895 rank 0
2022-08-26 17:50:58,364 DEBUG TRAIN Batch 217/1500 loss 56.124538 loss_att 39.059425 loss_ctc 95.943138 loss_ctc_origin 68.632637 loss_ctc0 159.667633 lr 0.00056893 rank 0
2022-08-26 17:51:26,039 DEBUG TRAIN Batch 217/1600 loss 60.682243 loss_att 35.475094 loss_ctc 119.498917 loss_ctc_origin 72.773285 loss_ctc0 228.525391 lr 0.00056890 rank 0
2022-08-26 17:51:53,939 DEBUG TRAIN Batch 217/1700 loss 24.572693 loss_att 15.495077 loss_ctc 45.753799 loss_ctc_origin 35.331982 loss_ctc0 70.071365 lr 0.00056888 rank 0
2022-08-26 17:51:58,976 WARNING NaN or Inf found in input tensor.
2022-08-26 17:52:22,065 DEBUG TRAIN Batch 217/1800 loss 18.361216 loss_att 7.348883 loss_ctc 44.056660 loss_ctc_origin 27.712086 loss_ctc0 82.193993 lr 0.00056886 rank 0
2022-08-26 17:52:50,482 DEBUG TRAIN Batch 217/1900 loss 19.429182 loss_att 6.957683 loss_ctc 48.529346 loss_ctc_origin 30.491894 loss_ctc0 90.616730 lr 0.00056883 rank 0
2022-08-26 17:53:19,421 DEBUG TRAIN Batch 217/2000 loss 46.056633 loss_att 31.691795 loss_ctc 79.574585 loss_ctc_origin 55.859528 loss_ctc0 134.909729 lr 0.00056881 rank 0
2022-08-26 17:53:45,820 DEBUG TRAIN Batch 217/2100 loss 60.255196 loss_att 35.574486 loss_ctc 117.843506 loss_ctc_origin 69.491379 loss_ctc0 230.665115 lr 0.00056879 rank 0
2022-08-26 17:54:13,667 DEBUG TRAIN Batch 217/2200 loss 20.320995 loss_att 10.062439 loss_ctc 44.257622 loss_ctc_origin 32.653469 loss_ctc0 71.333984 lr 0.00056877 rank 0
2022-08-26 17:54:41,362 DEBUG TRAIN Batch 217/2300 loss 16.369452 loss_att 6.376128 loss_ctc 39.687206 loss_ctc_origin 23.139683 loss_ctc0 78.298096 lr 0.00056874 rank 0
2022-08-26 17:55:09,287 DEBUG TRAIN Batch 217/2400 loss 22.766544 loss_att 10.409800 loss_ctc 51.598946 loss_ctc_origin 34.008797 loss_ctc0 92.642624 lr 0.00056872 rank 0
2022-08-26 17:55:37,179 DEBUG TRAIN Batch 217/2500 loss 46.504818 loss_att 30.960823 loss_ctc 82.774139 loss_ctc_origin 57.397148 loss_ctc0 141.987122 lr 0.00056870 rank 0
2022-08-26 17:56:03,548 DEBUG TRAIN Batch 217/2600 loss 54.277946 loss_att 29.462355 loss_ctc 112.181000 loss_ctc_origin 62.558773 loss_ctc0 227.966202 lr 0.00056867 rank 0
2022-08-26 17:56:31,459 DEBUG TRAIN Batch 217/2700 loss 20.524630 loss_att 9.831507 loss_ctc 45.475250 loss_ctc_origin 36.865585 loss_ctc0 65.564468 lr 0.00056865 rank 0
2022-08-26 17:56:43,352 WARNING NaN or Inf found in input tensor.
2022-08-26 17:56:59,113 DEBUG TRAIN Batch 217/2800 loss 19.294912 loss_att 8.341883 loss_ctc 44.851982 loss_ctc_origin 28.480843 loss_ctc0 83.051308 lr 0.00056863 rank 0
2022-08-26 17:57:27,121 DEBUG TRAIN Batch 217/2900 loss 22.060242 loss_att 9.482250 loss_ctc 51.408882 loss_ctc_origin 31.007996 loss_ctc0 99.010956 lr 0.00056860 rank 0
2022-08-26 17:58:00,004 DEBUG TRAIN Batch 217/3000 loss 44.099724 loss_att 27.114687 loss_ctc 83.731476 loss_ctc_origin 56.902046 loss_ctc0 146.333466 lr 0.00056858 rank 0
2022-08-26 17:58:00,901 WARNING NaN or Inf found in input tensor.
2022-08-26 17:58:28,191 DEBUG TRAIN Batch 217/3100 loss 52.730961 loss_att 30.476109 loss_ctc 104.658951 loss_ctc_origin 58.804832 loss_ctc0 211.651871 lr 0.00056856 rank 0
2022-08-26 17:58:56,136 DEBUG TRAIN Batch 217/3200 loss 17.703068 loss_att 7.827003 loss_ctc 40.747215 loss_ctc_origin 28.239750 loss_ctc0 69.931305 lr 0.00056854 rank 0
2022-08-26 17:59:23,418 DEBUG TRAIN Batch 217/3300 loss 20.191179 loss_att 7.489438 loss_ctc 49.828575 loss_ctc_origin 32.983376 loss_ctc0 89.134041 lr 0.00056851 rank 0
2022-08-26 17:59:51,133 DEBUG TRAIN Batch 217/3400 loss 19.925262 loss_att 8.191308 loss_ctc 47.304489 loss_ctc_origin 29.183331 loss_ctc0 89.587181 lr 0.00056849 rank 0
2022-08-26 18:00:19,289 DEBUG TRAIN Batch 217/3500 loss 40.063728 loss_att 25.324381 loss_ctc 74.455544 loss_ctc_origin 41.459152 loss_ctc0 151.447128 lr 0.00056847 rank 0
2022-08-26 18:00:46,166 DEBUG TRAIN Batch 217/3600 loss 49.248833 loss_att 28.332533 loss_ctc 98.053528 loss_ctc_origin 54.904453 loss_ctc0 198.734711 lr 0.00056844 rank 0
2022-08-26 18:01:13,407 DEBUG TRAIN Batch 217/3700 loss 19.628849 loss_att 10.458670 loss_ctc 41.025928 loss_ctc_origin 28.333652 loss_ctc0 70.641235 lr 0.00056842 rank 0
2022-08-26 18:01:39,983 DEBUG TRAIN Batch 217/3800 loss 17.580090 loss_att 7.212890 loss_ctc 41.770222 loss_ctc_origin 26.039951 loss_ctc0 78.474182 lr 0.00056840 rank 0
2022-08-26 18:02:07,990 DEBUG TRAIN Batch 217/3900 loss 18.797131 loss_att 7.028177 loss_ctc 46.258018 loss_ctc_origin 25.081772 loss_ctc0 95.669266 lr 0.00056837 rank 0
2022-08-26 18:02:33,992 DEBUG TRAIN Batch 217/4000 loss 29.685028 loss_att 19.907917 loss_ctc 52.498287 loss_ctc_origin 37.680489 loss_ctc0 87.073151 lr 0.00056835 rank 0
2022-08-26 18:03:02,521 DEBUG TRAIN Batch 217/4100 loss 42.212872 loss_att 20.229208 loss_ctc 93.508087 loss_ctc_origin 52.163620 loss_ctc0 189.978516 lr 0.00056833 rank 0
2022-08-26 18:03:28,983 DEBUG TRAIN Batch 217/4200 loss 19.583832 loss_att 8.137621 loss_ctc 46.291656 loss_ctc_origin 34.932632 loss_ctc0 72.796036 lr 0.00056831 rank 0
2022-08-26 18:03:55,724 DEBUG TRAIN Batch 217/4300 loss 16.876194 loss_att 6.483825 loss_ctc 41.125053 loss_ctc_origin 25.533733 loss_ctc0 77.504807 lr 0.00056828 rank 0
2022-08-26 18:04:22,703 DEBUG TRAIN Batch 217/4400 loss 21.394833 loss_att 8.359792 loss_ctc 51.809925 loss_ctc_origin 34.389244 loss_ctc0 92.458183 lr 0.00056826 rank 0
2022-08-26 18:04:55,181 DEBUG TRAIN Batch 217/4500 loss 46.171310 loss_att 31.428175 loss_ctc 80.571968 loss_ctc_origin 50.679939 loss_ctc0 150.320038 lr 0.00056824 rank 0
2022-08-26 18:05:23,058 DEBUG TRAIN Batch 217/4600 loss 54.613457 loss_att 30.839727 loss_ctc 110.085495 loss_ctc_origin 66.081856 loss_ctc0 212.760635 lr 0.00056821 rank 0
2022-08-26 18:05:51,289 DEBUG TRAIN Batch 217/4700 loss 20.675638 loss_att 12.263857 loss_ctc 40.303127 loss_ctc_origin 30.850950 loss_ctc0 62.358208 lr 0.00056819 rank 0
2022-08-26 18:06:18,223 DEBUG TRAIN Batch 217/4800 loss 17.046669 loss_att 7.303053 loss_ctc 39.781769 loss_ctc_origin 25.039700 loss_ctc0 74.179924 lr 0.00056817 rank 0
2022-08-26 18:06:46,115 DEBUG TRAIN Batch 217/4900 loss 22.139378 loss_att 8.576906 loss_ctc 53.785141 loss_ctc_origin 31.786388 loss_ctc0 105.115570 lr 0.00056815 rank 0
2022-08-26 18:07:14,384 DEBUG TRAIN Batch 217/5000 loss 35.326176 loss_att 20.735168 loss_ctc 69.371857 loss_ctc_origin 37.840008 loss_ctc0 142.946167 lr 0.00056812 rank 0
2022-08-26 18:07:41,888 DEBUG TRAIN Batch 217/5100 loss 45.022476 loss_att 25.029655 loss_ctc 91.672394 loss_ctc_origin 47.844589 loss_ctc0 193.937286 lr 0.00056810 rank 0
2022-08-26 18:08:09,199 DEBUG TRAIN Batch 217/5200 loss 22.842459 loss_att 10.992963 loss_ctc 50.491280 loss_ctc_origin 42.298462 loss_ctc0 69.607857 lr 0.00056808 rank 0
2022-08-26 18:08:37,248 DEBUG TRAIN Batch 217/5300 loss 17.657324 loss_att 7.128216 loss_ctc 42.225243 loss_ctc_origin 26.819475 loss_ctc0 78.172035 lr 0.00056805 rank 0
2022-08-26 18:09:05,665 DEBUG TRAIN Batch 217/5400 loss 22.272045 loss_att 8.750393 loss_ctc 53.822563 loss_ctc_origin 34.517578 loss_ctc0 98.867523 lr 0.00056803 rank 0
2022-08-26 18:09:33,449 DEBUG TRAIN Batch 217/5500 loss 50.330761 loss_att 35.161327 loss_ctc 85.726105 loss_ctc_origin 59.814575 loss_ctc0 146.186325 lr 0.00056801 rank 0
2022-08-26 18:10:00,387 DEBUG TRAIN Batch 217/5600 loss 53.800503 loss_att 30.307961 loss_ctc 108.616425 loss_ctc_origin 62.436752 loss_ctc0 216.368988 lr 0.00056798 rank 0
2022-08-26 18:10:23,187 DEBUG CV Batch 217/0 loss 11.900029 loss_att 8.763693 loss_ctc 19.218147 loss_ctc_origin 12.614533 loss_ctc0 34.626579 history loss 11.200027 rank 0
2022-08-26 18:10:33,537 DEBUG CV Batch 217/100 loss 20.686237 loss_att 16.681393 loss_ctc 30.030872 loss_ctc_origin 19.994724 loss_ctc0 53.448547 history loss 26.065408 rank 0
2022-08-26 18:10:42,994 DEBUG CV Batch 217/200 loss 24.266724 loss_att 18.418959 loss_ctc 37.911507 loss_ctc_origin 27.334011 loss_ctc0 62.592331 history loss 27.216136 rank 0
2022-08-26 18:10:52,753 DEBUG CV Batch 217/300 loss 22.641453 loss_att 17.132099 loss_ctc 35.496613 loss_ctc_origin 20.030472 loss_ctc0 71.584267 history loss 26.331168 rank 0
2022-08-26 18:11:02,830 DEBUG CV Batch 217/400 loss 36.571651 loss_att 29.067226 loss_ctc 54.081978 loss_ctc_origin 36.739578 loss_ctc0 94.547569 history loss 24.649159 rank 0
2022-08-26 18:11:13,486 DEBUG CV Batch 217/500 loss 15.879354 loss_att 11.446867 loss_ctc 26.221821 loss_ctc_origin 19.336391 loss_ctc0 42.287819 history loss 24.285927 rank 0
2022-08-26 18:11:23,791 DEBUG CV Batch 217/600 loss 17.119358 loss_att 12.348721 loss_ctc 28.250843 loss_ctc_origin 17.164085 loss_ctc0 54.119949 history loss 24.124035 rank 0
2022-08-26 18:11:33,410 DEBUG CV Batch 217/700 loss 18.316965 loss_att 12.863069 loss_ctc 31.042723 loss_ctc_origin 17.191219 loss_ctc0 63.362896 history loss 23.774894 rank 0
2022-08-26 18:11:43,920 DEBUG CV Batch 217/800 loss 21.658737 loss_att 17.113289 loss_ctc 32.264778 loss_ctc_origin 16.948898 loss_ctc0 68.001831 history loss 23.737743 rank 0
2022-08-26 18:11:54,033 INFO Epoch 217 CV info cv_loss 23.822046425417945
2022-08-26 18:11:54,034 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/217.pt
2022-08-26 18:11:54,450 INFO Epoch 218 TRAIN info lr 0.0005679654985524243
2022-08-26 18:11:54,453 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 18:12:19,797 DEBUG TRAIN Batch 218/0 loss 49.214005 loss_att 35.102627 loss_ctc 82.140549 loss_ctc_origin 52.352276 loss_ctc0 151.646515 lr 0.00056796 rank 0
2022-08-26 18:12:48,277 DEBUG TRAIN Batch 218/100 loss 42.192188 loss_att 20.608536 loss_ctc 92.554047 loss_ctc_origin 48.460953 loss_ctc0 195.437927 lr 0.00056794 rank 0
2022-08-26 18:13:16,451 DEBUG TRAIN Batch 218/200 loss 19.863573 loss_att 10.674946 loss_ctc 41.303703 loss_ctc_origin 30.796366 loss_ctc0 65.820816 lr 0.00056792 rank 0
2022-08-26 18:13:21,810 WARNING NaN or Inf found in input tensor.
2022-08-26 18:13:44,530 DEBUG TRAIN Batch 218/300 loss 17.557812 loss_att 6.517299 loss_ctc 43.319012 loss_ctc_origin 27.656998 loss_ctc0 79.863708 lr 0.00056790 rank 0
2022-08-26 18:14:12,682 DEBUG TRAIN Batch 218/400 loss 23.192434 loss_att 9.662821 loss_ctc 54.761528 loss_ctc_origin 35.458572 loss_ctc0 99.801750 lr 0.00056787 rank 0
2022-08-26 18:14:40,512 DEBUG TRAIN Batch 218/500 loss 44.948425 loss_att 31.725836 loss_ctc 75.801132 loss_ctc_origin 54.831150 loss_ctc0 124.731094 lr 0.00056785 rank 0
2022-08-26 18:15:07,716 DEBUG TRAIN Batch 218/600 loss 56.528893 loss_att 33.238041 loss_ctc 110.874207 loss_ctc_origin 66.715942 loss_ctc0 213.910156 lr 0.00056783 rank 0
2022-08-26 18:15:35,879 DEBUG TRAIN Batch 218/700 loss 19.349001 loss_att 8.494051 loss_ctc 44.677216 loss_ctc_origin 32.628639 loss_ctc0 72.790558 lr 0.00056780 rank 0
2022-08-26 18:16:02,799 DEBUG TRAIN Batch 218/800 loss 19.469351 loss_att 8.885977 loss_ctc 44.163887 loss_ctc_origin 29.316910 loss_ctc0 78.806839 lr 0.00056778 rank 0
2022-08-26 18:16:30,630 DEBUG TRAIN Batch 218/900 loss 21.241636 loss_att 8.530804 loss_ctc 50.900246 loss_ctc_origin 33.097477 loss_ctc0 92.440033 lr 0.00056776 rank 0
2022-08-26 18:16:58,194 DEBUG TRAIN Batch 218/1000 loss 41.659019 loss_att 26.947590 loss_ctc 75.985687 loss_ctc_origin 51.888687 loss_ctc0 132.212006 lr 0.00056774 rank 0
2022-08-26 18:17:11,363 WARNING NaN or Inf found in input tensor.
2022-08-26 18:17:25,776 DEBUG TRAIN Batch 218/1100 loss 50.173737 loss_att 24.940784 loss_ctc 109.050621 loss_ctc_origin 62.623032 loss_ctc0 217.381653 lr 0.00056771 rank 0
2022-08-26 18:17:53,709 DEBUG TRAIN Batch 218/1200 loss 19.336817 loss_att 8.585861 loss_ctc 44.422379 loss_ctc_origin 32.716660 loss_ctc0 71.735725 lr 0.00056769 rank 0
2022-08-26 18:18:20,637 DEBUG TRAIN Batch 218/1300 loss 19.205105 loss_att 8.055115 loss_ctc 45.221748 loss_ctc_origin 29.243820 loss_ctc0 82.503578 lr 0.00056767 rank 0
2022-08-26 18:18:47,667 DEBUG TRAIN Batch 218/1400 loss 22.188194 loss_att 8.370512 loss_ctc 54.429451 loss_ctc_origin 37.403130 loss_ctc0 94.157532 lr 0.00056764 rank 0
2022-08-26 18:19:21,169 DEBUG TRAIN Batch 218/1500 loss 47.213966 loss_att 31.587940 loss_ctc 83.674690 loss_ctc_origin 57.464134 loss_ctc0 144.832657 lr 0.00056762 rank 0
2022-08-26 18:19:36,103 WARNING NaN or Inf found in input tensor.
2022-08-26 18:19:48,756 DEBUG TRAIN Batch 218/1600 loss 50.064026 loss_att 26.768452 loss_ctc 104.420364 loss_ctc_origin 60.749454 loss_ctc0 206.319153 lr 0.00056760 rank 0
2022-08-26 18:20:16,555 DEBUG TRAIN Batch 218/1700 loss 17.391336 loss_att 7.958116 loss_ctc 39.402184 loss_ctc_origin 27.286633 loss_ctc0 67.671791 lr 0.00056758 rank 0
2022-08-26 18:20:43,579 DEBUG TRAIN Batch 218/1800 loss 17.098503 loss_att 6.289944 loss_ctc 42.318474 loss_ctc_origin 26.704559 loss_ctc0 78.750931 lr 0.00056755 rank 0
2022-08-26 18:21:10,508 DEBUG TRAIN Batch 218/1900 loss 19.577293 loss_att 7.807961 loss_ctc 47.039070 loss_ctc_origin 30.161846 loss_ctc0 86.419258 lr 0.00056753 rank 0
2022-08-26 18:21:38,248 DEBUG TRAIN Batch 218/2000 loss 47.553574 loss_att 31.809792 loss_ctc 84.289062 loss_ctc_origin 56.157162 loss_ctc0 149.930145 lr 0.00056751 rank 0
2022-08-26 18:22:05,731 DEBUG TRAIN Batch 218/2100 loss 53.554169 loss_att 30.686323 loss_ctc 106.912468 loss_ctc_origin 60.222267 loss_ctc0 215.856262 lr 0.00056748 rank 0
2022-08-26 18:22:32,617 DEBUG TRAIN Batch 218/2200 loss 17.744869 loss_att 8.950691 loss_ctc 38.264618 loss_ctc_origin 26.124901 loss_ctc0 66.590622 lr 0.00056746 rank 0
2022-08-26 18:23:00,544 DEBUG TRAIN Batch 218/2300 loss 19.769829 loss_att 8.630694 loss_ctc 45.761143 loss_ctc_origin 32.665688 loss_ctc0 76.317207 lr 0.00056744 rank 0
2022-08-26 18:23:28,334 DEBUG TRAIN Batch 218/2400 loss 21.525795 loss_att 8.678760 loss_ctc 51.502213 loss_ctc_origin 32.012444 loss_ctc0 96.978340 lr 0.00056742 rank 0
2022-08-26 18:23:57,692 DEBUG TRAIN Batch 218/2500 loss 46.462154 loss_att 31.584995 loss_ctc 81.175522 loss_ctc_origin 53.667374 loss_ctc0 145.361206 lr 0.00056739 rank 0
2022-08-26 18:24:09,546 WARNING NaN or Inf found in input tensor.
2022-08-26 18:24:24,324 DEBUG TRAIN Batch 218/2600 loss 54.330238 loss_att 30.195311 loss_ctc 110.645065 loss_ctc_origin 63.828171 loss_ctc0 219.884476 lr 0.00056737 rank 0
2022-08-26 18:24:50,844 DEBUG TRAIN Batch 218/2700 loss 16.233109 loss_att 7.528718 loss_ctc 36.543350 loss_ctc_origin 24.769283 loss_ctc0 64.016174 lr 0.00056735 rank 0
2022-08-26 18:25:17,865 DEBUG TRAIN Batch 218/2800 loss 20.813356 loss_att 9.270522 loss_ctc 47.746635 loss_ctc_origin 31.225805 loss_ctc0 86.295242 lr 0.00056732 rank 0
2022-08-26 18:25:41,470 WARNING NaN or Inf found in input tensor.
2022-08-26 18:25:45,855 DEBUG TRAIN Batch 218/2900 loss 21.208122 loss_att 8.784857 loss_ctc 50.195744 loss_ctc_origin 31.587059 loss_ctc0 93.616005 lr 0.00056730 rank 0
2022-08-26 18:26:18,767 DEBUG TRAIN Batch 218/3000 loss 47.005341 loss_att 29.780676 loss_ctc 87.196213 loss_ctc_origin 53.960045 loss_ctc0 164.747253 lr 0.00056728 rank 0
2022-08-26 18:26:46,196 DEBUG TRAIN Batch 218/3100 loss 54.064480 loss_att 29.668781 loss_ctc 110.987778 loss_ctc_origin 66.323967 loss_ctc0 215.203323 lr 0.00056726 rank 0
2022-08-26 18:27:12,125 DEBUG TRAIN Batch 218/3200 loss 19.254133 loss_att 9.431923 loss_ctc 42.172623 loss_ctc_origin 30.817801 loss_ctc0 68.667206 lr 0.00056723 rank 0
2022-08-26 18:27:39,608 DEBUG TRAIN Batch 218/3300 loss 20.601797 loss_att 9.160803 loss_ctc 47.297447 loss_ctc_origin 33.082241 loss_ctc0 80.466263 lr 0.00056721 rank 0
2022-08-26 18:27:43,400 WARNING NaN or Inf found in input tensor.
2022-08-26 18:28:07,526 DEBUG TRAIN Batch 218/3400 loss 17.919701 loss_att 6.738503 loss_ctc 44.009159 loss_ctc_origin 23.543396 loss_ctc0 91.762604 lr 0.00056719 rank 0
2022-08-26 18:28:35,442 DEBUG TRAIN Batch 218/3500 loss 45.785362 loss_att 29.709818 loss_ctc 83.294968 loss_ctc_origin 51.313110 loss_ctc0 157.919281 lr 0.00056716 rank 0
2022-08-26 18:29:03,150 DEBUG TRAIN Batch 218/3600 loss 58.799316 loss_att 32.837074 loss_ctc 119.377876 loss_ctc_origin 64.453957 loss_ctc0 247.533676 lr 0.00056714 rank 0
2022-08-26 18:29:30,972 DEBUG TRAIN Batch 218/3700 loss 19.244152 loss_att 9.828497 loss_ctc 41.214012 loss_ctc_origin 28.817188 loss_ctc0 70.139931 lr 0.00056712 rank 0
2022-08-26 18:29:59,495 DEBUG TRAIN Batch 218/3800 loss 19.623161 loss_att 7.567784 loss_ctc 47.752373 loss_ctc_origin 32.396591 loss_ctc0 83.582520 lr 0.00056710 rank 0
2022-08-26 18:30:26,027 DEBUG TRAIN Batch 218/3900 loss 18.252457 loss_att 7.294730 loss_ctc 43.820488 loss_ctc_origin 26.745636 loss_ctc0 83.661804 lr 0.00056707 rank 0
2022-08-26 18:30:53,512 DEBUG TRAIN Batch 218/4000 loss 46.164730 loss_att 28.514557 loss_ctc 87.348465 loss_ctc_origin 53.954006 loss_ctc0 165.268875 lr 0.00056705 rank 0
2022-08-26 18:31:20,566 DEBUG TRAIN Batch 218/4100 loss 57.296562 loss_att 31.399265 loss_ctc 117.723587 loss_ctc_origin 64.406647 loss_ctc0 242.129791 lr 0.00056703 rank 0
2022-08-26 18:31:46,065 WARNING NaN or Inf found in input tensor.
2022-08-26 18:31:47,674 DEBUG TRAIN Batch 218/4200 loss 19.011543 loss_att 9.749715 loss_ctc 40.622475 loss_ctc_origin 28.951824 loss_ctc0 67.853981 lr 0.00056701 rank 0
2022-08-26 18:32:15,661 DEBUG TRAIN Batch 218/4300 loss 19.013792 loss_att 6.963045 loss_ctc 47.132202 loss_ctc_origin 30.445601 loss_ctc0 86.067596 lr 0.00056698 rank 0
2022-08-26 18:32:31,632 WARNING NaN or Inf found in input tensor.
2022-08-26 18:32:43,332 DEBUG TRAIN Batch 218/4400 loss 20.746937 loss_att 8.708662 loss_ctc 48.836246 loss_ctc_origin 31.152817 loss_ctc0 90.097580 lr 0.00056696 rank 0
2022-08-26 18:33:14,867 DEBUG TRAIN Batch 218/4500 loss 53.731304 loss_att 37.146294 loss_ctc 92.429657 loss_ctc_origin 57.469856 loss_ctc0 174.002518 lr 0.00056694 rank 0
2022-08-26 18:33:30,012 WARNING NaN or Inf found in input tensor.
2022-08-26 18:33:42,551 DEBUG TRAIN Batch 218/4600 loss 53.449173 loss_att 28.246277 loss_ctc 112.255920 loss_ctc_origin 57.197021 loss_ctc0 240.726685 lr 0.00056691 rank 0
2022-08-26 18:34:10,431 DEBUG TRAIN Batch 218/4700 loss 17.364147 loss_att 9.460960 loss_ctc 35.804916 loss_ctc_origin 25.184124 loss_ctc0 60.586758 lr 0.00056689 rank 0
2022-08-26 18:34:38,210 DEBUG TRAIN Batch 218/4800 loss 19.755812 loss_att 9.008826 loss_ctc 44.832111 loss_ctc_origin 30.083374 loss_ctc0 79.245834 lr 0.00056687 rank 0
2022-08-26 18:35:01,652 WARNING NaN or Inf found in input tensor.
2022-08-26 18:35:06,074 DEBUG TRAIN Batch 218/4900 loss 23.060741 loss_att 10.486598 loss_ctc 52.400406 loss_ctc_origin 33.747925 loss_ctc0 95.922867 lr 0.00056685 rank 0
2022-08-26 18:35:33,741 DEBUG TRAIN Batch 218/5000 loss 53.487328 loss_att 33.136086 loss_ctc 100.973557 loss_ctc_origin 68.762634 loss_ctc0 176.132370 lr 0.00056682 rank 0
2022-08-26 18:36:00,948 DEBUG TRAIN Batch 218/5100 loss 56.944366 loss_att 32.211845 loss_ctc 114.653564 loss_ctc_origin 64.660973 loss_ctc0 231.302948 lr 0.00056680 rank 0
2022-08-26 18:36:28,792 DEBUG TRAIN Batch 218/5200 loss 18.759338 loss_att 10.117714 loss_ctc 38.923126 loss_ctc_origin 27.914013 loss_ctc0 64.611061 lr 0.00056678 rank 0
2022-08-26 18:36:56,505 DEBUG TRAIN Batch 218/5300 loss 17.965626 loss_att 7.005061 loss_ctc 43.540279 loss_ctc_origin 28.394361 loss_ctc0 78.880753 lr 0.00056675 rank 0
2022-08-26 18:37:25,367 DEBUG TRAIN Batch 218/5400 loss 22.235889 loss_att 9.389141 loss_ctc 52.211632 loss_ctc_origin 34.537125 loss_ctc0 93.452148 lr 0.00056673 rank 0
2022-08-26 18:37:52,670 DEBUG TRAIN Batch 218/5500 loss 50.193401 loss_att 31.937160 loss_ctc 92.791290 loss_ctc_origin 60.648125 loss_ctc0 167.791992 lr 0.00056671 rank 0
2022-08-26 18:38:06,009 WARNING NaN or Inf found in input tensor.
2022-08-26 18:38:19,644 DEBUG TRAIN Batch 218/5600 loss 55.779640 loss_att 30.222977 loss_ctc 115.411850 loss_ctc_origin 66.760033 loss_ctc0 228.932739 lr 0.00056669 rank 0
2022-08-26 18:38:32,875 WARNING NaN or Inf found in input tensor.
2022-08-26 18:38:42,199 DEBUG CV Batch 218/0 loss 11.382435 loss_att 8.494379 loss_ctc 18.121233 loss_ctc_origin 11.635082 loss_ctc0 33.255585 history loss 10.712880 rank 0
2022-08-26 18:38:52,331 DEBUG CV Batch 218/100 loss 19.984081 loss_att 15.876002 loss_ctc 29.569603 loss_ctc_origin 19.617668 loss_ctc0 52.790787 history loss 25.596496 rank 0
2022-08-26 18:39:01,602 DEBUG CV Batch 218/200 loss 24.942886 loss_att 19.629387 loss_ctc 37.341049 loss_ctc_origin 26.783489 loss_ctc0 61.975365 history loss 26.874471 rank 0
2022-08-26 18:39:10,950 DEBUG CV Batch 218/300 loss 21.933582 loss_att 16.428148 loss_ctc 34.779594 loss_ctc_origin 19.361750 loss_ctc0 70.754562 history loss 26.062434 rank 0
2022-08-26 18:39:20,947 DEBUG CV Batch 218/400 loss 35.819611 loss_att 28.588539 loss_ctc 52.692108 loss_ctc_origin 35.070549 loss_ctc0 93.809074 history loss 24.418821 rank 0
2022-08-26 18:39:31,025 DEBUG CV Batch 218/500 loss 16.248146 loss_att 12.117764 loss_ctc 25.885706 loss_ctc_origin 18.885738 loss_ctc0 42.218964 history loss 24.105444 rank 0
2022-08-26 18:39:41,089 DEBUG CV Batch 218/600 loss 17.541853 loss_att 12.776581 loss_ctc 28.660820 loss_ctc_origin 18.042788 loss_ctc0 53.436226 history loss 23.960208 rank 0
2022-08-26 18:39:50,872 DEBUG CV Batch 218/700 loss 18.584248 loss_att 13.243217 loss_ctc 31.046658 loss_ctc_origin 17.119955 loss_ctc0 63.542294 history loss 23.646317 rank 0
2022-08-26 18:40:00,814 DEBUG CV Batch 218/800 loss 20.928047 loss_att 16.336941 loss_ctc 31.640627 loss_ctc_origin 16.093769 loss_ctc0 67.916626 history loss 23.618543 rank 0
2022-08-26 18:40:10,644 INFO Epoch 218 CV info cv_loss 23.711828692307016
2022-08-26 18:40:10,645 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/218.pt
2022-08-26 18:40:11,070 INFO Epoch 219 TRAIN info lr 0.0005666672900010286
2022-08-26 18:40:11,073 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 18:40:36,234 DEBUG TRAIN Batch 219/0 loss 51.061745 loss_att 33.649734 loss_ctc 91.689758 loss_ctc_origin 58.730732 loss_ctc0 168.594162 lr 0.00056667 rank 0
2022-08-26 18:41:02,569 DEBUG TRAIN Batch 219/100 loss 57.441910 loss_att 33.957687 loss_ctc 112.238434 loss_ctc_origin 64.276077 loss_ctc0 224.150604 lr 0.00056664 rank 0
2022-08-26 18:41:28,698 DEBUG TRAIN Batch 219/200 loss 22.856834 loss_att 11.904533 loss_ctc 48.412201 loss_ctc_origin 37.327751 loss_ctc0 74.275909 lr 0.00056662 rank 0
2022-08-26 18:41:55,622 DEBUG TRAIN Batch 219/300 loss 17.352999 loss_att 6.803240 loss_ctc 41.969101 loss_ctc_origin 28.808764 loss_ctc0 72.676559 lr 0.00056660 rank 0
2022-08-26 18:42:22,115 DEBUG TRAIN Batch 219/400 loss 18.479660 loss_att 7.587408 loss_ctc 43.894913 loss_ctc_origin 25.612919 loss_ctc0 86.552895 lr 0.00056658 rank 0
2022-08-26 18:42:50,386 DEBUG TRAIN Batch 219/500 loss 38.463615 loss_att 22.047230 loss_ctc 76.768517 loss_ctc_origin 49.959312 loss_ctc0 139.323318 lr 0.00056655 rank 0
2022-08-26 18:43:09,694 WARNING NaN or Inf found in input tensor.
2022-08-26 18:43:16,586 DEBUG TRAIN Batch 219/600 loss 54.968044 loss_att 27.746479 loss_ctc 118.485031 loss_ctc_origin 66.922707 loss_ctc0 238.797119 lr 0.00056653 rank 0
2022-08-26 18:43:43,375 DEBUG TRAIN Batch 219/700 loss 17.054253 loss_att 9.347558 loss_ctc 35.036537 loss_ctc_origin 23.582151 loss_ctc0 61.763439 lr 0.00056651 rank 0
2022-08-26 18:44:10,511 DEBUG TRAIN Batch 219/800 loss 20.000439 loss_att 7.759760 loss_ctc 48.562019 loss_ctc_origin 33.222321 loss_ctc0 84.354645 lr 0.00056648 rank 0
2022-08-26 18:44:38,324 DEBUG TRAIN Batch 219/900 loss 23.996410 loss_att 10.424428 loss_ctc 55.664368 loss_ctc_origin 38.643143 loss_ctc0 95.380562 lr 0.00056646 rank 0
2022-08-26 18:45:04,870 DEBUG TRAIN Batch 219/1000 loss 43.506317 loss_att 25.903181 loss_ctc 84.580292 loss_ctc_origin 52.411980 loss_ctc0 159.639679 lr 0.00056644 rank 0
2022-08-26 18:45:17,690 WARNING NaN or Inf found in input tensor.
2022-08-26 18:45:31,945 DEBUG TRAIN Batch 219/1100 loss 52.355289 loss_att 28.148739 loss_ctc 108.837234 loss_ctc_origin 57.212402 loss_ctc0 229.295166 lr 0.00056642 rank 0
2022-08-26 18:45:58,909 DEBUG TRAIN Batch 219/1200 loss 20.875446 loss_att 12.078394 loss_ctc 41.401901 loss_ctc_origin 31.055183 loss_ctc0 65.544235 lr 0.00056639 rank 0
2022-08-26 18:46:26,376 DEBUG TRAIN Batch 219/1300 loss 15.052118 loss_att 5.189176 loss_ctc 38.065651 loss_ctc_origin 20.854630 loss_ctc0 78.224693 lr 0.00056637 rank 0
2022-08-26 18:46:53,753 DEBUG TRAIN Batch 219/1400 loss 22.821684 loss_att 8.353666 loss_ctc 56.580391 loss_ctc_origin 36.758453 loss_ctc0 102.831573 lr 0.00056635 rank 0
2022-08-26 18:47:26,334 DEBUG TRAIN Batch 219/1500 loss 46.252018 loss_att 31.532452 loss_ctc 80.597672 loss_ctc_origin 53.258011 loss_ctc0 144.390198 lr 0.00056633 rank 0
2022-08-26 18:47:53,998 DEBUG TRAIN Batch 219/1600 loss 55.583069 loss_att 30.957575 loss_ctc 113.042542 loss_ctc_origin 65.750916 loss_ctc0 223.389648 lr 0.00056630 rank 0
2022-08-26 18:48:21,288 DEBUG TRAIN Batch 219/1700 loss 17.570627 loss_att 9.102587 loss_ctc 37.329388 loss_ctc_origin 25.293766 loss_ctc0 65.412506 lr 0.00056628 rank 0
2022-08-26 18:48:48,853 DEBUG TRAIN Batch 219/1800 loss 19.066349 loss_att 7.152555 loss_ctc 46.865204 loss_ctc_origin 29.605877 loss_ctc0 87.136963 lr 0.00056626 rank 0
2022-08-26 18:49:16,612 DEBUG TRAIN Batch 219/1900 loss 19.657757 loss_att 8.044432 loss_ctc 46.755516 loss_ctc_origin 28.954645 loss_ctc0 88.290886 lr 0.00056623 rank 0
2022-08-26 18:49:43,694 DEBUG TRAIN Batch 219/2000 loss 44.207825 loss_att 29.285427 loss_ctc 79.026749 loss_ctc_origin 48.252575 loss_ctc0 150.833160 lr 0.00056621 rank 0
2022-08-26 18:50:03,289 WARNING NaN or Inf found in input tensor.
2022-08-26 18:50:10,218 DEBUG TRAIN Batch 219/2100 loss 60.518982 loss_att 31.074135 loss_ctc 129.223618 loss_ctc_origin 78.441025 loss_ctc0 247.716309 lr 0.00056619 rank 0
2022-08-26 18:50:37,106 DEBUG TRAIN Batch 219/2200 loss 15.338554 loss_att 9.165530 loss_ctc 29.742275 loss_ctc_origin 18.199032 loss_ctc0 56.676506 lr 0.00056617 rank 0
2022-08-26 18:51:04,963 DEBUG TRAIN Batch 219/2300 loss 18.552599 loss_att 7.883122 loss_ctc 43.448044 loss_ctc_origin 28.219286 loss_ctc0 78.981812 lr 0.00056614 rank 0
2022-08-26 18:51:31,937 DEBUG TRAIN Batch 219/2400 loss 18.213375 loss_att 7.094235 loss_ctc 44.158031 loss_ctc_origin 27.187384 loss_ctc0 83.756210 lr 0.00056612 rank 0
2022-08-26 18:52:00,124 DEBUG TRAIN Batch 219/2500 loss 40.845078 loss_att 23.809969 loss_ctc 80.593658 loss_ctc_origin 49.769608 loss_ctc0 152.516449 lr 0.00056610 rank 0
2022-08-26 18:52:27,013 DEBUG TRAIN Batch 219/2600 loss 59.325539 loss_att 34.044403 loss_ctc 118.314850 loss_ctc_origin 63.181622 loss_ctc0 246.959045 lr 0.00056608 rank 0
2022-08-26 18:52:54,044 DEBUG TRAIN Batch 219/2700 loss 19.991026 loss_att 11.699691 loss_ctc 39.337475 loss_ctc_origin 30.285700 loss_ctc0 60.458282 lr 0.00056605 rank 0
2022-08-26 18:53:21,453 DEBUG TRAIN Batch 219/2800 loss 21.004930 loss_att 8.881638 loss_ctc 49.292614 loss_ctc_origin 35.459072 loss_ctc0 81.570877 lr 0.00056603 rank 0
2022-08-26 18:53:48,345 DEBUG TRAIN Batch 219/2900 loss 22.089680 loss_att 8.988266 loss_ctc 52.659645 loss_ctc_origin 33.354309 loss_ctc0 97.705429 lr 0.00056601 rank 0
2022-08-26 18:54:21,809 DEBUG TRAIN Batch 219/3000 loss 45.367439 loss_att 28.230789 loss_ctc 85.352951 loss_ctc_origin 50.875084 loss_ctc0 165.801300 lr 0.00056599 rank 0
2022-08-26 18:54:48,435 DEBUG TRAIN Batch 219/3100 loss 61.761543 loss_att 37.681362 loss_ctc 117.948624 loss_ctc_origin 69.642715 loss_ctc0 230.662399 lr 0.00056596 rank 0
2022-08-26 18:55:16,607 DEBUG TRAIN Batch 219/3200 loss 18.443121 loss_att 7.866910 loss_ctc 43.120945 loss_ctc_origin 28.942986 loss_ctc0 76.202850 lr 0.00056594 rank 0
2022-08-26 18:55:44,004 DEBUG TRAIN Batch 219/3300 loss 17.870338 loss_att 6.656193 loss_ctc 44.036674 loss_ctc_origin 28.805771 loss_ctc0 79.575447 lr 0.00056592 rank 0
2022-08-26 18:56:10,763 DEBUG TRAIN Batch 219/3400 loss 19.935272 loss_att 7.956260 loss_ctc 47.886299 loss_ctc_origin 27.613523 loss_ctc0 95.189438 lr 0.00056589 rank 0
2022-08-26 18:56:38,797 DEBUG TRAIN Batch 219/3500 loss 45.912945 loss_att 29.612396 loss_ctc 83.947556 loss_ctc_origin 55.266479 loss_ctc0 150.870056 lr 0.00056587 rank 0
2022-08-26 18:57:05,563 DEBUG TRAIN Batch 219/3600 loss 57.256927 loss_att 30.485321 loss_ctc 119.724014 loss_ctc_origin 69.339523 loss_ctc0 237.287811 lr 0.00056585 rank 0
2022-08-26 18:57:32,426 DEBUG TRAIN Batch 219/3700 loss 16.458977 loss_att 7.944881 loss_ctc 36.325195 loss_ctc_origin 22.841770 loss_ctc0 67.786514 lr 0.00056583 rank 0
2022-08-26 18:57:59,657 DEBUG TRAIN Batch 219/3800 loss 17.907291 loss_att 6.363480 loss_ctc 44.842850 loss_ctc_origin 29.994110 loss_ctc0 79.489914 lr 0.00056580 rank 0
2022-08-26 18:58:15,979 WARNING NaN or Inf found in input tensor.
2022-08-26 18:58:27,173 DEBUG TRAIN Batch 219/3900 loss 24.893236 loss_att 11.226941 loss_ctc 56.781258 loss_ctc_origin 38.262642 loss_ctc0 99.991356 lr 0.00056578 rank 0
2022-08-26 18:58:54,359 DEBUG TRAIN Batch 219/4000 loss 50.192749 loss_att 32.506908 loss_ctc 91.459717 loss_ctc_origin 63.080547 loss_ctc0 157.677780 lr 0.00056576 rank 0
2022-08-26 18:59:20,498 DEBUG TRAIN Batch 219/4100 loss 57.622993 loss_att 32.943794 loss_ctc 115.207794 loss_ctc_origin 67.286545 loss_ctc0 227.024048 lr 0.00056574 rank 0
2022-08-26 18:59:48,561 DEBUG TRAIN Batch 219/4200 loss 21.522480 loss_att 13.110312 loss_ctc 41.150871 loss_ctc_origin 33.046951 loss_ctc0 60.060013 lr 0.00056571 rank 0
2022-08-26 19:00:15,282 DEBUG TRAIN Batch 219/4300 loss 15.890720 loss_att 6.265072 loss_ctc 38.350567 loss_ctc_origin 23.247189 loss_ctc0 73.591782 lr 0.00056569 rank 0
2022-08-26 19:00:42,774 DEBUG TRAIN Batch 219/4400 loss 19.953096 loss_att 7.461065 loss_ctc 49.101170 loss_ctc_origin 30.935236 loss_ctc0 91.488342 lr 0.00056567 rank 0
2022-08-26 19:01:15,447 DEBUG TRAIN Batch 219/4500 loss 48.952766 loss_att 31.484413 loss_ctc 89.712250 loss_ctc_origin 56.733490 loss_ctc0 166.662689 lr 0.00056565 rank 0
2022-08-26 19:01:16,263 WARNING NaN or Inf found in input tensor.
2022-08-26 19:01:42,408 DEBUG TRAIN Batch 219/4600 loss 53.514011 loss_att 28.523968 loss_ctc 111.824112 loss_ctc_origin 57.634186 loss_ctc0 238.267242 lr 0.00056562 rank 0
2022-08-26 19:02:08,906 DEBUG TRAIN Batch 219/4700 loss 15.304029 loss_att 7.515133 loss_ctc 33.478115 loss_ctc_origin 19.843662 loss_ctc0 65.291840 lr 0.00056560 rank 0
2022-08-26 19:02:32,265 WARNING NaN or Inf found in input tensor.
2022-08-26 19:02:35,493 DEBUG TRAIN Batch 219/4800 loss 17.399784 loss_att 6.360692 loss_ctc 43.157665 loss_ctc_origin 28.990526 loss_ctc0 76.214325 lr 0.00056558 rank 0
2022-08-26 19:03:03,096 DEBUG TRAIN Batch 219/4900 loss 26.311970 loss_att 10.484648 loss_ctc 63.242382 loss_ctc_origin 46.079849 loss_ctc0 103.288292 lr 0.00056556 rank 0
2022-08-26 19:03:30,939 DEBUG TRAIN Batch 219/5000 loss 50.821224 loss_att 33.702866 loss_ctc 90.764061 loss_ctc_origin 59.838730 loss_ctc0 162.923157 lr 0.00056553 rank 0
2022-08-26 19:03:58,208 DEBUG TRAIN Batch 219/5100 loss 54.198009 loss_att 30.997009 loss_ctc 108.333672 loss_ctc_origin 65.158646 loss_ctc0 209.075394 lr 0.00056551 rank 0
2022-08-26 19:04:24,771 DEBUG TRAIN Batch 219/5200 loss 16.931858 loss_att 8.611693 loss_ctc 36.345573 loss_ctc_origin 25.568008 loss_ctc0 61.493225 lr 0.00056549 rank 0
2022-08-26 19:04:52,837 DEBUG TRAIN Batch 219/5300 loss 15.519945 loss_att 6.033926 loss_ctc 37.653992 loss_ctc_origin 23.278725 loss_ctc0 71.196274 lr 0.00056546 rank 0
2022-08-26 19:05:19,930 DEBUG TRAIN Batch 219/5400 loss 20.847939 loss_att 8.118456 loss_ctc 50.550064 loss_ctc_origin 30.653957 loss_ctc0 96.974319 lr 0.00056544 rank 0
2022-08-26 19:05:48,055 DEBUG TRAIN Batch 219/5500 loss 40.193588 loss_att 24.232635 loss_ctc 77.435814 loss_ctc_origin 41.110401 loss_ctc0 162.195099 lr 0.00056542 rank 0
2022-08-26 19:06:16,286 DEBUG TRAIN Batch 219/5600 loss 58.206528 loss_att 35.510071 loss_ctc 111.164917 loss_ctc_origin 62.845108 loss_ctc0 223.911133 lr 0.00056540 rank 0
2022-08-26 19:06:39,550 DEBUG CV Batch 219/0 loss 11.382278 loss_att 8.482320 loss_ctc 18.148849 loss_ctc_origin 11.724974 loss_ctc0 33.137894 history loss 10.712733 rank 0
2022-08-26 19:06:49,618 DEBUG CV Batch 219/100 loss 20.441769 loss_att 16.361450 loss_ctc 29.962505 loss_ctc_origin 20.083187 loss_ctc0 53.014252 history loss 26.381920 rank 0
2022-08-26 19:06:58,911 DEBUG CV Batch 219/200 loss 24.469261 loss_att 19.103474 loss_ctc 36.989426 loss_ctc_origin 26.215803 loss_ctc0 62.127876 history loss 27.655992 rank 0
2022-08-26 19:07:08,632 DEBUG CV Batch 219/300 loss 22.253128 loss_att 16.836470 loss_ctc 34.891994 loss_ctc_origin 19.224291 loss_ctc0 71.449966 history loss 26.757570 rank 0
2022-08-26 19:07:19,037 DEBUG CV Batch 219/400 loss 36.966385 loss_att 29.663620 loss_ctc 54.006172 loss_ctc_origin 36.623375 loss_ctc0 94.566025 history loss 25.028014 rank 0
2022-08-26 19:07:28,983 DEBUG CV Batch 219/500 loss 15.913172 loss_att 11.565136 loss_ctc 26.058588 loss_ctc_origin 19.309040 loss_ctc0 41.807533 history loss 24.673043 rank 0
2022-08-26 19:07:39,366 DEBUG CV Batch 219/600 loss 18.199203 loss_att 12.869341 loss_ctc 30.635548 loss_ctc_origin 20.687832 loss_ctc0 53.846882 history loss 24.518536 rank 0
2022-08-26 19:07:49,746 DEBUG CV Batch 219/700 loss 19.013416 loss_att 13.545906 loss_ctc 31.770941 loss_ctc_origin 18.325151 loss_ctc0 63.144447 history loss 24.190480 rank 0
2022-08-26 19:07:59,327 DEBUG CV Batch 219/800 loss 22.114656 loss_att 17.380390 loss_ctc 33.161278 loss_ctc_origin 17.801468 loss_ctc0 69.000824 history loss 24.181196 rank 0
2022-08-26 19:08:09,203 INFO Epoch 219 CV info cv_loss 24.265540088838083
2022-08-26 19:08:09,204 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/219.pt
2022-08-26 19:08:09,657 INFO Epoch 220 TRAIN info lr 0.0005653779429606319
2022-08-26 19:08:09,661 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 19:08:35,428 DEBUG TRAIN Batch 220/0 loss 54.715527 loss_att 35.156487 loss_ctc 100.353279 loss_ctc_origin 66.888870 loss_ctc0 178.436890 lr 0.00056538 rank 0
2022-08-26 19:09:02,836 DEBUG TRAIN Batch 220/100 loss 51.572136 loss_att 25.819128 loss_ctc 111.662476 loss_ctc_origin 57.662292 loss_ctc0 237.662872 lr 0.00056535 rank 0
2022-08-26 19:09:29,437 DEBUG TRAIN Batch 220/200 loss 18.396009 loss_att 9.349050 loss_ctc 39.505581 loss_ctc_origin 28.106098 loss_ctc0 66.104370 lr 0.00056533 rank 0
2022-08-26 19:09:57,082 DEBUG TRAIN Batch 220/300 loss 19.249825 loss_att 8.044218 loss_ctc 45.396240 loss_ctc_origin 30.267508 loss_ctc0 80.696602 lr 0.00056531 rank 0
2022-08-26 19:10:25,563 DEBUG TRAIN Batch 220/400 loss 17.542475 loss_att 5.928709 loss_ctc 44.641262 loss_ctc_origin 25.157028 loss_ctc0 90.104477 lr 0.00056529 rank 0
2022-08-26 19:10:53,368 DEBUG TRAIN Batch 220/500 loss 39.532528 loss_att 22.303736 loss_ctc 79.733047 loss_ctc_origin 47.576546 loss_ctc0 154.764877 lr 0.00056526 rank 0
2022-08-26 19:11:19,664 DEBUG TRAIN Batch 220/600 loss 52.459534 loss_att 26.419834 loss_ctc 113.218842 loss_ctc_origin 59.589489 loss_ctc0 238.354004 lr 0.00056524 rank 0
2022-08-26 19:11:46,377 DEBUG TRAIN Batch 220/700 loss 17.910803 loss_att 8.725857 loss_ctc 39.342346 loss_ctc_origin 28.667789 loss_ctc0 64.249649 lr 0.00056522 rank 0
2022-08-26 19:12:13,815 DEBUG TRAIN Batch 220/800 loss 18.700457 loss_att 6.956854 loss_ctc 46.102196 loss_ctc_origin 31.177486 loss_ctc0 80.926514 lr 0.00056520 rank 0
2022-08-26 19:12:41,965 DEBUG TRAIN Batch 220/900 loss 24.019505 loss_att 9.846535 loss_ctc 57.089764 loss_ctc_origin 38.760113 loss_ctc0 99.858948 lr 0.00056517 rank 0
2022-08-26 19:13:10,007 DEBUG TRAIN Batch 220/1000 loss 41.334126 loss_att 27.380913 loss_ctc 73.891617 loss_ctc_origin 46.073677 loss_ctc0 138.800156 lr 0.00056515 rank 0
2022-08-26 19:13:36,367 DEBUG TRAIN Batch 220/1100 loss 61.064678 loss_att 36.600876 loss_ctc 118.146881 loss_ctc_origin 69.963638 loss_ctc0 230.574463 lr 0.00056513 rank 0
2022-08-26 19:14:03,626 DEBUG TRAIN Batch 220/1200 loss 18.914879 loss_att 8.773859 loss_ctc 42.577255 loss_ctc_origin 31.154285 loss_ctc0 69.230858 lr 0.00056511 rank 0
2022-08-26 19:14:21,051 WARNING NaN or Inf found in input tensor.
2022-08-26 19:14:30,345 DEBUG TRAIN Batch 220/1300 loss 16.329130 loss_att 5.590531 loss_ctc 41.385860 loss_ctc_origin 26.350231 loss_ctc0 76.468994 lr 0.00056508 rank 0
2022-08-26 19:14:57,735 DEBUG TRAIN Batch 220/1400 loss 20.749071 loss_att 8.788510 loss_ctc 48.657043 loss_ctc_origin 30.894392 loss_ctc0 90.103226 lr 0.00056506 rank 0
2022-08-26 19:15:30,407 DEBUG TRAIN Batch 220/1500 loss 53.923470 loss_att 37.027130 loss_ctc 93.348267 loss_ctc_origin 57.880253 loss_ctc0 176.106949 lr 0.00056504 rank 0
2022-08-26 19:15:45,229 WARNING NaN or Inf found in input tensor.
2022-08-26 19:15:57,553 DEBUG TRAIN Batch 220/1600 loss 60.002899 loss_att 34.904385 loss_ctc 118.566101 loss_ctc_origin 65.702484 loss_ctc0 241.914536 lr 0.00056502 rank 0
2022-08-26 19:16:24,981 DEBUG TRAIN Batch 220/1700 loss 16.285854 loss_att 7.929080 loss_ctc 35.784992 loss_ctc_origin 23.602915 loss_ctc0 64.209839 lr 0.00056499 rank 0
2022-08-26 19:16:51,398 DEBUG TRAIN Batch 220/1800 loss 17.006798 loss_att 6.860988 loss_ctc 40.680351 loss_ctc_origin 25.488993 loss_ctc0 76.126854 lr 0.00056497 rank 0
2022-08-26 19:17:18,349 DEBUG TRAIN Batch 220/1900 loss 21.624496 loss_att 9.476708 loss_ctc 49.969337 loss_ctc_origin 29.456852 loss_ctc0 97.831802 lr 0.00056495 rank 0
2022-08-26 19:17:46,048 DEBUG TRAIN Batch 220/2000 loss 54.619217 loss_att 32.352322 loss_ctc 106.575294 loss_ctc_origin 71.503220 loss_ctc0 188.410126 lr 0.00056493 rank 0
2022-08-26 19:18:11,677 DEBUG TRAIN Batch 220/2100 loss 54.229729 loss_att 31.568851 loss_ctc 107.105103 loss_ctc_origin 56.366417 loss_ctc0 225.495361 lr 0.00056490 rank 0
2022-08-26 19:18:39,553 DEBUG TRAIN Batch 220/2200 loss 17.918259 loss_att 8.608531 loss_ctc 39.640961 loss_ctc_origin 27.438759 loss_ctc0 68.112762 lr 0.00056488 rank 0
2022-08-26 19:19:05,776 DEBUG TRAIN Batch 220/2300 loss 18.822689 loss_att 7.770593 loss_ctc 44.610916 loss_ctc_origin 29.400591 loss_ctc0 80.101677 lr 0.00056486 rank 0
2022-08-26 19:19:33,571 DEBUG TRAIN Batch 220/2400 loss 19.277157 loss_att 7.389474 loss_ctc 47.015083 loss_ctc_origin 25.152409 loss_ctc0 98.027985 lr 0.00056484 rank 0
2022-08-26 19:20:00,879 DEBUG TRAIN Batch 220/2500 loss 41.923698 loss_att 25.544043 loss_ctc 80.142899 loss_ctc_origin 47.309620 loss_ctc0 156.753876 lr 0.00056481 rank 0
2022-08-26 19:20:28,042 DEBUG TRAIN Batch 220/2600 loss 50.664413 loss_att 28.083742 loss_ctc 103.352646 loss_ctc_origin 58.829582 loss_ctc0 207.239807 lr 0.00056479 rank 0
2022-08-26 19:20:55,093 DEBUG TRAIN Batch 220/2700 loss 16.279392 loss_att 7.862537 loss_ctc 35.918720 loss_ctc_origin 24.655807 loss_ctc0 62.198845 lr 0.00056477 rank 0
2022-08-26 19:21:21,487 DEBUG TRAIN Batch 220/2800 loss 18.550631 loss_att 7.484606 loss_ctc 44.371353 loss_ctc_origin 29.081707 loss_ctc0 80.047195 lr 0.00056475 rank 0
2022-08-26 19:21:49,009 DEBUG TRAIN Batch 220/2900 loss 18.548214 loss_att 7.837515 loss_ctc 43.539841 loss_ctc_origin 26.378679 loss_ctc0 83.582550 lr 0.00056472 rank 0
2022-08-26 19:22:22,308 DEBUG TRAIN Batch 220/3000 loss 30.366749 loss_att 19.911135 loss_ctc 54.763184 loss_ctc_origin 33.559921 loss_ctc0 104.237457 lr 0.00056470 rank 0
2022-08-26 19:22:49,770 DEBUG TRAIN Batch 220/3100 loss 61.280113 loss_att 35.951553 loss_ctc 120.380096 loss_ctc_origin 66.484360 loss_ctc0 246.136810 lr 0.00056468 rank 0
2022-08-26 19:23:17,000 DEBUG TRAIN Batch 220/3200 loss 17.098217 loss_att 8.907511 loss_ctc 36.209862 loss_ctc_origin 23.332806 loss_ctc0 66.256325 lr 0.00056466 rank 0
2022-08-26 19:23:45,354 DEBUG TRAIN Batch 220/3300 loss 16.342932 loss_att 6.638594 loss_ctc 38.986385 loss_ctc_origin 23.498888 loss_ctc0 75.123878 lr 0.00056463 rank 0
2022-08-26 19:24:12,345 DEBUG TRAIN Batch 220/3400 loss 19.058685 loss_att 7.256735 loss_ctc 46.596565 loss_ctc_origin 28.859550 loss_ctc0 87.982925 lr 0.00056461 rank 0
2022-08-26 19:24:40,035 DEBUG TRAIN Batch 220/3500 loss 36.490746 loss_att 20.372868 loss_ctc 74.099121 loss_ctc_origin 41.520271 loss_ctc0 150.116425 lr 0.00056459 rank 0
2022-08-26 19:25:07,821 DEBUG TRAIN Batch 220/3600 loss 36.742752 loss_att 18.946144 loss_ctc 78.268173 loss_ctc_origin 34.814987 loss_ctc0 179.658951 lr 0.00056457 rank 0
2022-08-26 19:25:35,704 DEBUG TRAIN Batch 220/3700 loss 18.113270 loss_att 8.958172 loss_ctc 39.475163 loss_ctc_origin 27.737083 loss_ctc0 66.864014 lr 0.00056454 rank 0
2022-08-26 19:26:02,325 DEBUG TRAIN Batch 220/3800 loss 20.685213 loss_att 8.558024 loss_ctc 48.981987 loss_ctc_origin 33.267639 loss_ctc0 85.648788 lr 0.00056452 rank 0
2022-08-26 19:26:05,340 WARNING NaN or Inf found in input tensor.
2022-08-26 19:26:29,725 DEBUG TRAIN Batch 220/3900 loss 19.788462 loss_att 7.509059 loss_ctc 48.440399 loss_ctc_origin 30.685902 loss_ctc0 89.867554 lr 0.00056450 rank 0
2022-08-26 19:26:57,300 DEBUG TRAIN Batch 220/4000 loss 40.452843 loss_att 25.639431 loss_ctc 75.017464 loss_ctc_origin 48.674057 loss_ctc0 136.485413 lr 0.00056448 rank 0
2022-08-26 19:27:24,936 DEBUG TRAIN Batch 220/4100 loss 37.018284 loss_att 20.483406 loss_ctc 75.599670 loss_ctc_origin 39.484585 loss_ctc0 159.868195 lr 0.00056445 rank 0
2022-08-26 19:27:52,708 DEBUG TRAIN Batch 220/4200 loss 16.301731 loss_att 8.993255 loss_ctc 33.354843 loss_ctc_origin 21.923817 loss_ctc0 60.027241 lr 0.00056443 rank 0
2022-08-26 19:28:20,373 DEBUG TRAIN Batch 220/4300 loss 18.378660 loss_att 7.917161 loss_ctc 42.788826 loss_ctc_origin 28.658051 loss_ctc0 75.760635 lr 0.00056441 rank 0
2022-08-26 19:28:48,156 DEBUG TRAIN Batch 220/4400 loss 18.938492 loss_att 7.360033 loss_ctc 45.954895 loss_ctc_origin 26.358120 loss_ctc0 91.680710 lr 0.00056439 rank 0
2022-08-26 19:29:20,908 DEBUG TRAIN Batch 220/4500 loss 43.055283 loss_att 28.239265 loss_ctc 77.625999 loss_ctc_origin 49.815845 loss_ctc0 142.516357 lr 0.00056436 rank 0
2022-08-26 19:29:47,663 DEBUG TRAIN Batch 220/4600 loss 46.225563 loss_att 24.365614 loss_ctc 97.232117 loss_ctc_origin 54.295040 loss_ctc0 197.418625 lr 0.00056434 rank 0
2022-08-26 19:30:15,071 DEBUG TRAIN Batch 220/4700 loss 16.755480 loss_att 7.674689 loss_ctc 37.943989 loss_ctc_origin 27.384768 loss_ctc0 62.582172 lr 0.00056432 rank 0
2022-08-26 19:30:42,409 DEBUG TRAIN Batch 220/4800 loss 21.101080 loss_att 9.164368 loss_ctc 48.953407 loss_ctc_origin 35.442902 loss_ctc0 80.477913 lr 0.00056430 rank 0
2022-08-26 19:31:08,653 DEBUG TRAIN Batch 220/4900 loss 20.852158 loss_att 8.388437 loss_ctc 49.934174 loss_ctc_origin 32.096107 loss_ctc0 91.556320 lr 0.00056427 rank 0
2022-08-26 19:31:36,586 DEBUG TRAIN Batch 220/5000 loss 39.391907 loss_att 24.201283 loss_ctc 74.836700 loss_ctc_origin 46.333855 loss_ctc0 141.343338 lr 0.00056425 rank 0
2022-08-26 19:32:04,062 DEBUG TRAIN Batch 220/5100 loss 41.296715 loss_att 20.531343 loss_ctc 89.749237 loss_ctc_origin 48.521423 loss_ctc0 185.947464 lr 0.00056423 rank 0
2022-08-26 19:32:31,808 DEBUG TRAIN Batch 220/5200 loss 18.053322 loss_att 8.800681 loss_ctc 39.642818 loss_ctc_origin 28.404558 loss_ctc0 65.865425 lr 0.00056421 rank 0
2022-08-26 19:33:00,034 DEBUG TRAIN Batch 220/5300 loss 19.588923 loss_att 7.978459 loss_ctc 46.680000 loss_ctc_origin 31.713512 loss_ctc0 81.601807 lr 0.00056418 rank 0
2022-08-26 19:33:27,147 DEBUG TRAIN Batch 220/5400 loss 22.062981 loss_att 8.075261 loss_ctc 54.700989 loss_ctc_origin 36.468307 loss_ctc0 97.243904 lr 0.00056416 rank 0
2022-08-26 19:33:55,115 DEBUG TRAIN Batch 220/5500 loss 43.118671 loss_att 29.001606 loss_ctc 76.058487 loss_ctc_origin 46.805084 loss_ctc0 144.316437 lr 0.00056414 rank 0
2022-08-26 19:34:22,257 DEBUG TRAIN Batch 220/5600 loss 59.435581 loss_att 33.169479 loss_ctc 120.723145 loss_ctc_origin 62.839363 loss_ctc0 255.785309 lr 0.00056412 rank 0
2022-08-26 19:34:45,097 DEBUG CV Batch 220/0 loss 12.080605 loss_att 9.218610 loss_ctc 18.758591 loss_ctc_origin 11.963519 loss_ctc0 34.613754 history loss 11.369981 rank 0
2022-08-26 19:34:55,452 DEBUG CV Batch 220/100 loss 21.293861 loss_att 17.304291 loss_ctc 30.602854 loss_ctc_origin 20.790340 loss_ctc0 53.498718 history loss 27.545328 rank 0
2022-08-26 19:35:05,014 DEBUG CV Batch 220/200 loss 27.042860 loss_att 21.794249 loss_ctc 39.289619 loss_ctc_origin 29.018829 loss_ctc0 63.254795 history loss 29.073707 rank 0
2022-08-26 19:35:14,748 DEBUG CV Batch 220/300 loss 23.824570 loss_att 18.176235 loss_ctc 37.004013 loss_ctc_origin 21.993458 loss_ctc0 72.028633 history loss 28.153335 rank 0
2022-08-26 19:35:25,042 DEBUG CV Batch 220/400 loss 37.748192 loss_att 30.280853 loss_ctc 55.171989 loss_ctc_origin 37.479408 loss_ctc0 96.454666 history loss 26.214043 rank 0
2022-08-26 19:35:35,429 DEBUG CV Batch 220/500 loss 16.618900 loss_att 12.327449 loss_ctc 26.632286 loss_ctc_origin 19.840157 loss_ctc0 42.480587 history loss 25.763595 rank 0
2022-08-26 19:35:45,592 DEBUG CV Batch 220/600 loss 18.795986 loss_att 13.589957 loss_ctc 30.943384 loss_ctc_origin 20.973274 loss_ctc0 54.206970 history loss 25.574283 rank 0
2022-08-26 19:35:55,344 DEBUG CV Batch 220/700 loss 20.181438 loss_att 14.472376 loss_ctc 33.502586 loss_ctc_origin 20.163769 loss_ctc0 64.626495 history loss 25.205840 rank 0
2022-08-26 19:36:05,262 DEBUG CV Batch 220/800 loss 22.454121 loss_att 17.886982 loss_ctc 33.110779 loss_ctc_origin 17.610231 loss_ctc0 69.278717 history loss 25.168131 rank 0
2022-08-26 19:36:15,217 INFO Epoch 220 CV info cv_loss 25.228419688039676
2022-08-26 19:36:15,218 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/220.pt
2022-08-26 19:36:15,648 INFO Epoch 221 TRAIN info lr 0.0005640973570740696
2022-08-26 19:36:15,651 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 19:36:41,563 DEBUG TRAIN Batch 221/0 loss 50.836418 loss_att 31.197491 loss_ctc 96.660583 loss_ctc_origin 57.054420 loss_ctc0 189.074936 lr 0.00056410 rank 0
2022-08-26 19:37:08,233 DEBUG TRAIN Batch 221/100 loss 58.252251 loss_att 36.199947 loss_ctc 109.707626 loss_ctc_origin 60.162392 loss_ctc0 225.313187 lr 0.00056407 rank 0
2022-08-26 19:37:34,195 DEBUG TRAIN Batch 221/200 loss 20.268118 loss_att 9.465906 loss_ctc 45.473274 loss_ctc_origin 33.503128 loss_ctc0 73.403625 lr 0.00056405 rank 0
2022-08-26 19:38:00,477 DEBUG TRAIN Batch 221/300 loss 17.104176 loss_att 6.959013 loss_ctc 40.776222 loss_ctc_origin 26.174263 loss_ctc0 74.847458 lr 0.00056403 rank 0
2022-08-26 19:38:27,380 DEBUG TRAIN Batch 221/400 loss 22.722473 loss_att 9.263495 loss_ctc 54.126751 loss_ctc_origin 34.400791 loss_ctc0 100.153992 lr 0.00056401 rank 0
2022-08-26 19:38:54,340 DEBUG TRAIN Batch 221/500 loss 45.791218 loss_att 30.280968 loss_ctc 81.981804 loss_ctc_origin 47.522827 loss_ctc0 162.386078 lr 0.00056398 rank 0
2022-08-26 19:39:01,605 WARNING NaN or Inf found in input tensor.
2022-08-26 19:39:21,301 DEBUG TRAIN Batch 221/600 loss 55.018921 loss_att 30.775061 loss_ctc 111.587929 loss_ctc_origin 62.687160 loss_ctc0 225.689713 lr 0.00056396 rank 0
2022-08-26 19:39:48,119 DEBUG TRAIN Batch 221/700 loss 16.519936 loss_att 7.795696 loss_ctc 36.876492 loss_ctc_origin 24.271824 loss_ctc0 66.287384 lr 0.00056394 rank 0
2022-08-26 19:40:14,817 DEBUG TRAIN Batch 221/800 loss 20.114008 loss_att 8.403511 loss_ctc 47.438499 loss_ctc_origin 33.057384 loss_ctc0 80.994423 lr 0.00056392 rank 0
2022-08-26 19:40:41,041 DEBUG TRAIN Batch 221/900 loss 19.390205 loss_att 7.793617 loss_ctc 46.448910 loss_ctc_origin 27.748890 loss_ctc0 90.082283 lr 0.00056389 rank 0
2022-08-26 19:41:08,103 DEBUG TRAIN Batch 221/1000 loss 43.926353 loss_att 29.518976 loss_ctc 77.543564 loss_ctc_origin 50.180508 loss_ctc0 141.390686 lr 0.00056387 rank 0
2022-08-26 19:41:35,679 DEBUG TRAIN Batch 221/1100 loss 51.550278 loss_att 27.644772 loss_ctc 107.329788 loss_ctc_origin 52.497673 loss_ctc0 235.271378 lr 0.00056385 rank 0
2022-08-26 19:42:01,559 DEBUG TRAIN Batch 221/1200 loss 13.786768 loss_att 5.868743 loss_ctc 32.262157 loss_ctc_origin 17.869061 loss_ctc0 65.846046 lr 0.00056383 rank 0
2022-08-26 19:42:26,794 WARNING NaN or Inf found in input tensor.
2022-08-26 19:42:29,260 DEBUG TRAIN Batch 221/1300 loss 18.618904 loss_att 6.509396 loss_ctc 46.874420 loss_ctc_origin 31.339653 loss_ctc0 83.122208 lr 0.00056381 rank 0
2022-08-26 19:42:57,345 DEBUG TRAIN Batch 221/1400 loss 21.195181 loss_att 9.686844 loss_ctc 48.047962 loss_ctc_origin 29.971411 loss_ctc0 90.226578 lr 0.00056378 rank 0
2022-08-26 19:43:30,598 DEBUG TRAIN Batch 221/1500 loss 43.569275 loss_att 26.426376 loss_ctc 83.569366 loss_ctc_origin 53.041542 loss_ctc0 154.800949 lr 0.00056376 rank 0
2022-08-26 19:43:58,042 DEBUG TRAIN Batch 221/1600 loss 50.935768 loss_att 28.761787 loss_ctc 102.675049 loss_ctc_origin 57.136688 loss_ctc0 208.931213 lr 0.00056374 rank 0
2022-08-26 19:44:25,485 DEBUG TRAIN Batch 221/1700 loss 18.128748 loss_att 8.533670 loss_ctc 40.517258 loss_ctc_origin 26.998550 loss_ctc0 72.060913 lr 0.00056372 rank 0
2022-08-26 19:44:53,323 DEBUG TRAIN Batch 221/1800 loss 17.225401 loss_att 6.811264 loss_ctc 41.525055 loss_ctc_origin 25.439869 loss_ctc0 79.057159 lr 0.00056369 rank 0
2022-08-26 19:45:16,030 WARNING NaN or Inf found in input tensor.
2022-08-26 19:45:20,066 DEBUG TRAIN Batch 221/1900 loss 23.148369 loss_att 9.148995 loss_ctc 55.813568 loss_ctc_origin 38.210281 loss_ctc0 96.887909 lr 0.00056367 rank 0
2022-08-26 19:45:47,987 DEBUG TRAIN Batch 221/2000 loss 46.870575 loss_att 30.603642 loss_ctc 84.826752 loss_ctc_origin 54.625160 loss_ctc0 155.297150 lr 0.00056365 rank 0
2022-08-26 19:46:15,010 DEBUG TRAIN Batch 221/2100 loss 49.933075 loss_att 26.763098 loss_ctc 103.996353 loss_ctc_origin 55.540081 loss_ctc0 217.060989 lr 0.00056363 rank 0
2022-08-26 19:46:40,869 DEBUG TRAIN Batch 221/2200 loss 19.038904 loss_att 9.713673 loss_ctc 40.797775 loss_ctc_origin 28.813042 loss_ctc0 68.762161 lr 0.00056360 rank 0
2022-08-26 19:47:07,534 DEBUG TRAIN Batch 221/2300 loss 19.430822 loss_att 8.604940 loss_ctc 44.691216 loss_ctc_origin 30.057039 loss_ctc0 78.837631 lr 0.00056358 rank 0
2022-08-26 19:47:35,363 DEBUG TRAIN Batch 221/2400 loss 22.765442 loss_att 8.955964 loss_ctc 54.987556 loss_ctc_origin 36.860527 loss_ctc0 97.283958 lr 0.00056356 rank 0
2022-08-26 19:48:02,671 DEBUG TRAIN Batch 221/2500 loss 45.322922 loss_att 27.988098 loss_ctc 85.770844 loss_ctc_origin 52.389900 loss_ctc0 163.659729 lr 0.00056354 rank 0
2022-08-26 19:48:29,118 DEBUG TRAIN Batch 221/2600 loss 45.877361 loss_att 23.085068 loss_ctc 99.059372 loss_ctc_origin 45.642921 loss_ctc0 223.697754 lr 0.00056351 rank 0
2022-08-26 19:48:56,062 DEBUG TRAIN Batch 221/2700 loss 15.900816 loss_att 7.524174 loss_ctc 35.446316 loss_ctc_origin 22.521381 loss_ctc0 65.604492 lr 0.00056349 rank 0
2022-08-26 19:49:24,681 DEBUG TRAIN Batch 221/2800 loss 19.735874 loss_att 7.460265 loss_ctc 48.378963 loss_ctc_origin 33.074257 loss_ctc0 84.089943 lr 0.00056347 rank 0
2022-08-26 19:49:51,945 DEBUG TRAIN Batch 221/2900 loss 21.288227 loss_att 9.237810 loss_ctc 49.405869 loss_ctc_origin 32.401196 loss_ctc0 89.083435 lr 0.00056345 rank 0
2022-08-26 19:50:24,309 DEBUG TRAIN Batch 221/3000 loss 47.549713 loss_att 30.329620 loss_ctc 87.729935 loss_ctc_origin 56.375942 loss_ctc0 160.889252 lr 0.00056342 rank 0
2022-08-26 19:50:51,943 DEBUG TRAIN Batch 221/3100 loss 54.350342 loss_att 30.221416 loss_ctc 110.651161 loss_ctc_origin 65.381088 loss_ctc0 216.281311 lr 0.00056340 rank 0
2022-08-26 19:51:21,123 DEBUG TRAIN Batch 221/3200 loss 17.463947 loss_att 7.635013 loss_ctc 40.398125 loss_ctc_origin 27.971737 loss_ctc0 69.393036 lr 0.00056338 rank 0
2022-08-26 19:51:48,545 DEBUG TRAIN Batch 221/3300 loss 17.706066 loss_att 7.841694 loss_ctc 40.722931 loss_ctc_origin 26.408655 loss_ctc0 74.122910 lr 0.00056336 rank 0
2022-08-26 19:52:16,359 DEBUG TRAIN Batch 221/3400 loss 21.353519 loss_att 8.709805 loss_ctc 50.855518 loss_ctc_origin 31.775072 loss_ctc0 95.376556 lr 0.00056334 rank 0
2022-08-26 19:52:44,760 DEBUG TRAIN Batch 221/3500 loss 47.589016 loss_att 31.962074 loss_ctc 84.051880 loss_ctc_origin 54.740311 loss_ctc0 152.445526 lr 0.00056331 rank 0
2022-08-26 19:53:11,258 WARNING NaN or Inf found in input tensor.
2022-08-26 19:53:11,306 DEBUG TRAIN Batch 221/3600 loss nan loss_att 31.935190 loss_ctc nan loss_ctc_origin 66.027390 loss_ctc0 nan lr 0.00056329 rank 0
2022-08-26 19:53:38,232 DEBUG TRAIN Batch 221/3700 loss 19.438599 loss_att 11.341770 loss_ctc 38.331200 loss_ctc_origin 27.702381 loss_ctc0 63.131775 lr 0.00056327 rank 0
2022-08-26 19:54:05,664 DEBUG TRAIN Batch 221/3800 loss 18.571724 loss_att 6.797081 loss_ctc 46.045887 loss_ctc_origin 31.540894 loss_ctc0 79.890869 lr 0.00056325 rank 0
2022-08-26 19:54:33,701 DEBUG TRAIN Batch 221/3900 loss 19.959133 loss_att 8.100599 loss_ctc 47.629044 loss_ctc_origin 30.764156 loss_ctc0 86.980453 lr 0.00056322 rank 0
2022-08-26 19:55:01,601 DEBUG TRAIN Batch 221/4000 loss 42.627983 loss_att 25.777233 loss_ctc 81.946396 loss_ctc_origin 51.571404 loss_ctc0 152.821365 lr 0.00056320 rank 0
2022-08-26 19:55:28,891 DEBUG TRAIN Batch 221/4100 loss 49.807709 loss_att 25.151714 loss_ctc 107.338364 loss_ctc_origin 56.694580 loss_ctc0 225.507202 lr 0.00056318 rank 0
2022-08-26 19:55:56,586 DEBUG TRAIN Batch 221/4200 loss 19.116499 loss_att 9.129570 loss_ctc 42.419334 loss_ctc_origin 31.288664 loss_ctc0 68.390900 lr 0.00056316 rank 0
2022-08-26 19:56:25,911 DEBUG TRAIN Batch 221/4300 loss 18.435196 loss_att 6.891721 loss_ctc 45.369968 loss_ctc_origin 29.804298 loss_ctc0 81.689865 lr 0.00056313 rank 0
2022-08-26 19:56:49,014 WARNING NaN or Inf found in input tensor.
2022-08-26 19:56:53,320 DEBUG TRAIN Batch 221/4400 loss 17.159706 loss_att 6.412766 loss_ctc 42.235901 loss_ctc_origin 23.242243 loss_ctc0 86.554443 lr 0.00056311 rank 0
2022-08-26 19:57:26,734 DEBUG TRAIN Batch 221/4500 loss 48.080074 loss_att 33.186066 loss_ctc 82.832756 loss_ctc_origin 55.774345 loss_ctc0 145.969040 lr 0.00056309 rank 0
2022-08-26 19:57:34,683 WARNING NaN or Inf found in input tensor.
2022-08-26 19:57:54,832 DEBUG TRAIN Batch 221/4600 loss 55.287773 loss_att 31.071110 loss_ctc 111.793320 loss_ctc_origin 60.507530 loss_ctc0 231.460144 lr 0.00056307 rank 0
2022-08-26 19:58:22,443 DEBUG TRAIN Batch 221/4700 loss 18.011660 loss_att 9.562180 loss_ctc 37.727112 loss_ctc_origin 26.833557 loss_ctc0 63.145405 lr 0.00056304 rank 0
2022-08-26 19:58:27,956 WARNING NaN or Inf found in input tensor.
2022-08-26 19:58:49,604 DEBUG TRAIN Batch 221/4800 loss 16.801071 loss_att 6.958076 loss_ctc 39.768059 loss_ctc_origin 26.851349 loss_ctc0 69.907043 lr 0.00056302 rank 0
2022-08-26 19:59:17,624 DEBUG TRAIN Batch 221/4900 loss 20.468311 loss_att 8.545355 loss_ctc 48.288540 loss_ctc_origin 32.004086 loss_ctc0 86.285599 lr 0.00056300 rank 0
2022-08-26 19:59:45,988 DEBUG TRAIN Batch 221/5000 loss 49.500286 loss_att 32.675797 loss_ctc 88.757431 loss_ctc_origin 56.265980 loss_ctc0 164.570831 lr 0.00056298 rank 0
2022-08-26 20:00:13,203 DEBUG TRAIN Batch 221/5100 loss 59.210358 loss_att 33.912247 loss_ctc 118.239288 loss_ctc_origin 67.154137 loss_ctc0 237.437973 lr 0.00056296 rank 0
2022-08-26 20:00:40,070 DEBUG TRAIN Batch 221/5200 loss 17.703482 loss_att 9.723665 loss_ctc 36.323051 loss_ctc_origin 24.971760 loss_ctc0 62.809387 lr 0.00056293 rank 0
2022-08-26 20:01:07,115 DEBUG TRAIN Batch 221/5300 loss 17.218437 loss_att 7.216048 loss_ctc 40.557343 loss_ctc_origin 25.559597 loss_ctc0 75.552078 lr 0.00056291 rank 0
2022-08-26 20:01:34,604 DEBUG TRAIN Batch 221/5400 loss 21.087425 loss_att 7.496572 loss_ctc 52.799416 loss_ctc_origin 33.835617 loss_ctc0 97.048286 lr 0.00056289 rank 0
2022-08-26 20:02:02,378 DEBUG TRAIN Batch 221/5500 loss 48.995834 loss_att 31.775202 loss_ctc 89.177315 loss_ctc_origin 55.445892 loss_ctc0 167.883972 lr 0.00056287 rank 0
2022-08-26 20:02:28,934 DEBUG TRAIN Batch 221/5600 loss 62.590279 loss_att 39.468349 loss_ctc 116.541443 loss_ctc_origin 72.760986 loss_ctc0 218.695847 lr 0.00056284 rank 0
2022-08-26 20:02:50,872 DEBUG CV Batch 221/0 loss 11.099747 loss_att 7.894828 loss_ctc 18.577888 loss_ctc_origin 12.045956 loss_ctc0 33.819065 history loss 10.446820 rank 0
2022-08-26 20:03:01,166 DEBUG CV Batch 221/100 loss 20.584126 loss_att 16.417620 loss_ctc 30.305977 loss_ctc_origin 20.642502 loss_ctc0 52.854084 history loss 26.531856 rank 0
2022-08-26 20:03:10,577 DEBUG CV Batch 221/200 loss 25.339096 loss_att 19.597523 loss_ctc 38.736103 loss_ctc_origin 28.602306 loss_ctc0 62.381630 history loss 27.777461 rank 0
2022-08-26 20:03:20,477 DEBUG CV Batch 221/300 loss 22.289215 loss_att 17.006027 loss_ctc 34.616653 loss_ctc_origin 18.828011 loss_ctc0 71.456818 history loss 26.826142 rank 0
2022-08-26 20:03:30,342 DEBUG CV Batch 221/400 loss 36.187862 loss_att 28.469231 loss_ctc 54.198002 loss_ctc_origin 36.749119 loss_ctc0 94.912064 history loss 25.079759 rank 0
2022-08-26 20:03:40,318 DEBUG CV Batch 221/500 loss 16.603626 loss_att 12.441612 loss_ctc 26.314995 loss_ctc_origin 19.645441 loss_ctc0 41.877289 history loss 24.706428 rank 0
2022-08-26 20:03:50,582 DEBUG CV Batch 221/600 loss 17.886860 loss_att 12.795799 loss_ctc 29.765999 loss_ctc_origin 19.280993 loss_ctc0 54.231014 history loss 24.543365 rank 0
2022-08-26 20:04:00,087 DEBUG CV Batch 221/700 loss 18.109882 loss_att 12.454096 loss_ctc 31.306721 loss_ctc_origin 17.408718 loss_ctc0 63.735390 history loss 24.200476 rank 0
2022-08-26 20:04:10,222 DEBUG CV Batch 221/800 loss 21.641548 loss_att 16.795376 loss_ctc 32.949280 loss_ctc_origin 17.516491 loss_ctc0 68.959114 history loss 24.160275 rank 0
2022-08-26 20:04:20,084 INFO Epoch 221 CV info cv_loss 24.235966690754687
2022-08-26 20:04:20,085 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/221.pt
2022-08-26 20:04:20,513 INFO Epoch 222 TRAIN info lr 0.0005628254335681739
2022-08-26 20:04:20,517 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 20:04:45,992 DEBUG TRAIN Batch 222/0 loss 48.104439 loss_att 31.970764 loss_ctc 85.749672 loss_ctc_origin 55.276421 loss_ctc0 156.853928 lr 0.00056282 rank 0
2022-08-26 20:05:14,453 DEBUG TRAIN Batch 222/100 loss 61.922649 loss_att 35.755398 loss_ctc 122.979568 loss_ctc_origin 82.237625 loss_ctc0 218.044098 lr 0.00056280 rank 0
2022-08-26 20:05:42,110 DEBUG TRAIN Batch 222/200 loss 17.218315 loss_att 7.552564 loss_ctc 39.771736 loss_ctc_origin 26.904957 loss_ctc0 69.794220 lr 0.00056278 rank 0
2022-08-26 20:05:47,400 WARNING NaN or Inf found in input tensor.
2022-08-26 20:06:09,800 DEBUG TRAIN Batch 222/300 loss 17.570557 loss_att 7.318549 loss_ctc 41.491905 loss_ctc_origin 26.280756 loss_ctc0 76.984589 lr 0.00056276 rank 0
2022-08-26 20:06:37,892 DEBUG TRAIN Batch 222/400 loss 21.396601 loss_att 8.548868 loss_ctc 51.374641 loss_ctc_origin 30.999273 loss_ctc0 98.917160 lr 0.00056274 rank 0
2022-08-26 20:07:06,040 DEBUG TRAIN Batch 222/500 loss 50.909088 loss_att 33.562340 loss_ctc 91.384827 loss_ctc_origin 61.863781 loss_ctc0 160.267273 lr 0.00056271 rank 0
2022-08-26 20:07:13,819 WARNING NaN or Inf found in input tensor.
2022-08-26 20:07:25,815 WARNING NaN or Inf found in input tensor.
2022-08-26 20:07:32,826 DEBUG TRAIN Batch 222/600 loss 61.257523 loss_att 36.615768 loss_ctc 118.754951 loss_ctc_origin 71.410522 loss_ctc0 229.225281 lr 0.00056269 rank 0
2022-08-26 20:07:59,672 DEBUG TRAIN Batch 222/700 loss 18.534969 loss_att 8.815060 loss_ctc 41.214756 loss_ctc_origin 29.863461 loss_ctc0 67.701111 lr 0.00056267 rank 0
2022-08-26 20:08:27,642 DEBUG TRAIN Batch 222/800 loss 19.406191 loss_att 7.410772 loss_ctc 47.395500 loss_ctc_origin 33.443993 loss_ctc0 79.949005 lr 0.00056265 rank 0
2022-08-26 20:08:44,364 WARNING NaN or Inf found in input tensor.
2022-08-26 20:08:55,882 DEBUG TRAIN Batch 222/900 loss 21.461441 loss_att 8.551491 loss_ctc 51.584660 loss_ctc_origin 32.752819 loss_ctc0 95.525620 lr 0.00056262 rank 0
2022-08-26 20:09:23,482 DEBUG TRAIN Batch 222/1000 loss 56.883148 loss_att 36.810375 loss_ctc 103.719627 loss_ctc_origin 68.277359 loss_ctc0 186.418243 lr 0.00056260 rank 0
2022-08-26 20:09:51,456 DEBUG TRAIN Batch 222/1100 loss 58.826019 loss_att 33.719955 loss_ctc 117.406830 loss_ctc_origin 71.555832 loss_ctc0 224.392487 lr 0.00056258 rank 0
2022-08-26 20:10:18,315 DEBUG TRAIN Batch 222/1200 loss 20.226730 loss_att 12.145058 loss_ctc 39.083969 loss_ctc_origin 28.189369 loss_ctc0 64.504700 lr 0.00056256 rank 0
2022-08-26 20:10:45,014 DEBUG TRAIN Batch 222/1300 loss 15.458307 loss_att 5.880747 loss_ctc 37.805946 loss_ctc_origin 21.833471 loss_ctc0 75.075043 lr 0.00056254 rank 0
2022-08-26 20:11:12,513 DEBUG TRAIN Batch 222/1400 loss 15.896891 loss_att 5.609718 loss_ctc 39.900291 loss_ctc_origin 18.694069 loss_ctc0 89.381470 lr 0.00056251 rank 0
2022-08-26 20:11:45,200 DEBUG TRAIN Batch 222/1500 loss 40.471474 loss_att 24.386402 loss_ctc 78.003304 loss_ctc_origin 46.744114 loss_ctc0 150.941406 lr 0.00056249 rank 0
2022-08-26 20:12:12,118 DEBUG TRAIN Batch 222/1600 loss 58.039532 loss_att 31.628294 loss_ctc 119.665756 loss_ctc_origin 63.496254 loss_ctc0 250.727921 lr 0.00056247 rank 0
2022-08-26 20:12:39,805 DEBUG TRAIN Batch 222/1700 loss 21.167795 loss_att 11.244177 loss_ctc 44.322903 loss_ctc_origin 32.944839 loss_ctc0 70.871712 lr 0.00056245 rank 0
2022-08-26 20:13:07,827 DEBUG TRAIN Batch 222/1800 loss 16.276672 loss_att 6.335578 loss_ctc 39.472557 loss_ctc_origin 24.751007 loss_ctc0 73.822845 lr 0.00056242 rank 0
2022-08-26 20:13:35,316 DEBUG TRAIN Batch 222/1900 loss 21.092127 loss_att 8.397886 loss_ctc 50.712021 loss_ctc_origin 31.050480 loss_ctc0 96.588943 lr 0.00056240 rank 0
2022-08-26 20:14:03,458 DEBUG TRAIN Batch 222/2000 loss 46.804276 loss_att 31.032816 loss_ctc 83.604340 loss_ctc_origin 55.588394 loss_ctc0 148.974854 lr 0.00056238 rank 0
2022-08-26 20:14:30,649 WARNING NaN or Inf found in input tensor.
2022-08-26 20:14:30,691 DEBUG TRAIN Batch 222/2100 loss nan loss_att 30.608818 loss_ctc nan loss_ctc_origin 62.670166 loss_ctc0 nan lr 0.00056236 rank 0
2022-08-26 20:14:57,051 DEBUG TRAIN Batch 222/2200 loss 19.817917 loss_att 10.401309 loss_ctc 41.790001 loss_ctc_origin 30.548365 loss_ctc0 68.020477 lr 0.00056233 rank 0
2022-08-26 20:15:24,845 DEBUG TRAIN Batch 222/2300 loss 17.307295 loss_att 5.894372 loss_ctc 43.937447 loss_ctc_origin 29.237099 loss_ctc0 78.238251 lr 0.00056231 rank 0
2022-08-26 20:15:48,133 WARNING NaN or Inf found in input tensor.
2022-08-26 20:15:52,431 DEBUG TRAIN Batch 222/2400 loss 20.799294 loss_att 7.531738 loss_ctc 51.756920 loss_ctc_origin 34.068092 loss_ctc0 93.030846 lr 0.00056229 rank 0
2022-08-26 20:16:20,775 DEBUG TRAIN Batch 222/2500 loss 44.002190 loss_att 27.403460 loss_ctc 82.732559 loss_ctc_origin 51.439911 loss_ctc0 155.748749 lr 0.00056227 rank 0
2022-08-26 20:16:48,633 DEBUG TRAIN Batch 222/2600 loss 58.370121 loss_att 32.252552 loss_ctc 119.311111 loss_ctc_origin 72.295563 loss_ctc0 229.014069 lr 0.00056225 rank 0
2022-08-26 20:17:14,790 WARNING NaN or Inf found in input tensor.
2022-08-26 20:17:16,446 DEBUG TRAIN Batch 222/2700 loss 14.572369 loss_att 7.133433 loss_ctc 31.929884 loss_ctc_origin 20.661970 loss_ctc0 58.221680 lr 0.00056222 rank 0
2022-08-26 20:17:44,207 DEBUG TRAIN Batch 222/2800 loss 18.853481 loss_att 7.478428 loss_ctc 45.395271 loss_ctc_origin 29.463821 loss_ctc0 82.568649 lr 0.00056220 rank 0
2022-08-26 20:18:12,355 DEBUG TRAIN Batch 222/2900 loss 20.852989 loss_att 8.418068 loss_ctc 49.867805 loss_ctc_origin 29.446993 loss_ctc0 97.516365 lr 0.00056218 rank 0
2022-08-26 20:18:46,448 DEBUG TRAIN Batch 222/3000 loss 45.417992 loss_att 27.256529 loss_ctc 87.794724 loss_ctc_origin 54.431454 loss_ctc0 165.642365 lr 0.00056216 rank 0
2022-08-26 20:19:13,836 DEBUG TRAIN Batch 222/3100 loss 50.062401 loss_att 26.223984 loss_ctc 105.685364 loss_ctc_origin 53.247341 loss_ctc0 228.040741 lr 0.00056213 rank 0
2022-08-26 20:19:40,443 DEBUG TRAIN Batch 222/3200 loss 21.448868 loss_att 11.568985 loss_ctc 44.501926 loss_ctc_origin 32.035770 loss_ctc0 73.589622 lr 0.00056211 rank 0
2022-08-26 20:20:08,525 DEBUG TRAIN Batch 222/3300 loss 19.595596 loss_att 8.150360 loss_ctc 46.301147 loss_ctc_origin 29.794243 loss_ctc0 84.817261 lr 0.00056209 rank 0
2022-08-26 20:20:19,295 WARNING NaN or Inf found in input tensor.
2022-08-26 20:20:36,539 DEBUG TRAIN Batch 222/3400 loss 19.992384 loss_att 7.131411 loss_ctc 50.001320 loss_ctc_origin 32.087261 loss_ctc0 91.800781 lr 0.00056207 rank 0
2022-08-26 20:21:04,821 DEBUG TRAIN Batch 222/3500 loss 44.544189 loss_att 28.370399 loss_ctc 82.283035 loss_ctc_origin 47.306732 loss_ctc0 163.894394 lr 0.00056205 rank 0
2022-08-26 20:21:33,190 DEBUG TRAIN Batch 222/3600 loss 62.398106 loss_att 37.618546 loss_ctc 120.217072 loss_ctc_origin 73.537033 loss_ctc0 229.137146 lr 0.00056202 rank 0
2022-08-26 20:22:00,472 DEBUG TRAIN Batch 222/3700 loss 21.421711 loss_att 12.730003 loss_ctc 41.702362 loss_ctc_origin 30.549486 loss_ctc0 67.725739 lr 0.00056200 rank 0
2022-08-26 20:22:28,666 DEBUG TRAIN Batch 222/3800 loss 13.937761 loss_att 4.916084 loss_ctc 34.988342 loss_ctc_origin 20.522038 loss_ctc0 68.743057 lr 0.00056198 rank 0
2022-08-26 20:22:56,406 DEBUG TRAIN Batch 222/3900 loss 20.021809 loss_att 7.886800 loss_ctc 48.336826 loss_ctc_origin 30.243999 loss_ctc0 90.553421 lr 0.00056196 rank 0
2022-08-26 20:23:25,292 DEBUG TRAIN Batch 222/4000 loss 45.813763 loss_att 27.730383 loss_ctc 88.008308 loss_ctc_origin 56.899986 loss_ctc0 160.594391 lr 0.00056194 rank 0
2022-08-26 20:23:52,077 DEBUG TRAIN Batch 222/4100 loss 51.820660 loss_att 26.935316 loss_ctc 109.886459 loss_ctc_origin 58.944168 loss_ctc0 228.751801 lr 0.00056191 rank 0
2022-08-26 20:24:19,336 DEBUG TRAIN Batch 222/4200 loss 18.117241 loss_att 9.616380 loss_ctc 37.952579 loss_ctc_origin 26.932919 loss_ctc0 63.665123 lr 0.00056189 rank 0
2022-08-26 20:24:46,922 DEBUG TRAIN Batch 222/4300 loss 17.299347 loss_att 7.914196 loss_ctc 39.198029 loss_ctc_origin 25.398272 loss_ctc0 71.397453 lr 0.00056187 rank 0
2022-08-26 20:25:14,152 DEBUG TRAIN Batch 222/4400 loss 18.998219 loss_att 7.064075 loss_ctc 46.844551 loss_ctc_origin 29.172449 loss_ctc0 88.079453 lr 0.00056185 rank 0
2022-08-26 20:25:48,237 DEBUG TRAIN Batch 222/4500 loss 53.216637 loss_att 36.384209 loss_ctc 92.492294 loss_ctc_origin 65.070755 loss_ctc0 156.475876 lr 0.00056182 rank 0
2022-08-26 20:26:15,354 DEBUG TRAIN Batch 222/4600 loss 49.356308 loss_att 26.530968 loss_ctc 102.615433 loss_ctc_origin 51.585182 loss_ctc0 221.686005 lr 0.00056180 rank 0
2022-08-26 20:26:43,091 DEBUG TRAIN Batch 222/4700 loss 19.270884 loss_att 9.280266 loss_ctc 42.582321 loss_ctc_origin 32.184326 loss_ctc0 66.844307 lr 0.00056178 rank 0
2022-08-26 20:27:10,518 DEBUG TRAIN Batch 222/4800 loss 14.338889 loss_att 5.063775 loss_ctc 35.980820 loss_ctc_origin 21.858543 loss_ctc0 68.932800 lr 0.00056176 rank 0
2022-08-26 20:27:38,164 DEBUG TRAIN Batch 222/4900 loss 20.109226 loss_att 8.358741 loss_ctc 47.527023 loss_ctc_origin 28.487543 loss_ctc0 91.952477 lr 0.00056174 rank 0
2022-08-26 20:28:07,164 DEBUG TRAIN Batch 222/5000 loss 51.935841 loss_att 37.088081 loss_ctc 86.580612 loss_ctc_origin 59.119110 loss_ctc0 150.657455 lr 0.00056171 rank 0
2022-08-26 20:28:33,265 DEBUG TRAIN Batch 222/5100 loss 49.558182 loss_att 26.545202 loss_ctc 103.255135 loss_ctc_origin 59.265564 loss_ctc0 205.897461 lr 0.00056169 rank 0
2022-08-26 20:28:59,128 WARNING NaN or Inf found in input tensor.
2022-08-26 20:29:00,746 DEBUG TRAIN Batch 222/5200 loss 19.202505 loss_att 9.294187 loss_ctc 42.321915 loss_ctc_origin 31.573219 loss_ctc0 67.402199 lr 0.00056167 rank 0
2022-08-26 20:29:27,614 DEBUG TRAIN Batch 222/5300 loss 18.456932 loss_att 7.316596 loss_ctc 44.451050 loss_ctc_origin 30.175968 loss_ctc0 77.759567 lr 0.00056165 rank 0
2022-08-26 20:29:51,136 WARNING NaN or Inf found in input tensor.
2022-08-26 20:29:55,624 DEBUG TRAIN Batch 222/5400 loss 21.841986 loss_att 9.360609 loss_ctc 50.965195 loss_ctc_origin 33.315552 loss_ctc0 92.147690 lr 0.00056162 rank 0
2022-08-26 20:30:23,695 DEBUG TRAIN Batch 222/5500 loss 39.357109 loss_att 26.461967 loss_ctc 69.445778 loss_ctc_origin 40.833122 loss_ctc0 136.208649 lr 0.00056160 rank 0
2022-08-26 20:30:51,666 DEBUG TRAIN Batch 222/5600 loss 55.831940 loss_att 33.038578 loss_ctc 109.016449 loss_ctc_origin 65.746460 loss_ctc0 209.979767 lr 0.00056158 rank 0
2022-08-26 20:31:14,439 DEBUG CV Batch 222/0 loss 11.672599 loss_att 9.049696 loss_ctc 17.792706 loss_ctc_origin 11.210936 loss_ctc0 33.150169 history loss 10.985975 rank 0
2022-08-26 20:31:24,631 DEBUG CV Batch 222/100 loss 20.029678 loss_att 16.152933 loss_ctc 29.075420 loss_ctc_origin 19.159798 loss_ctc0 52.211868 history loss 25.551122 rank 0
2022-08-26 20:31:33,926 DEBUG CV Batch 222/200 loss 24.421616 loss_att 19.047775 loss_ctc 36.960579 loss_ctc_origin 26.465527 loss_ctc0 61.449036 history loss 26.819841 rank 0
2022-08-26 20:31:43,541 DEBUG CV Batch 222/300 loss 22.320690 loss_att 17.203056 loss_ctc 34.261833 loss_ctc_origin 18.773577 loss_ctc0 70.401093 history loss 25.978498 rank 0
2022-08-26 20:31:53,577 DEBUG CV Batch 222/400 loss 36.262039 loss_att 28.791542 loss_ctc 53.693203 loss_ctc_origin 36.522823 loss_ctc0 93.757423 history loss 24.348045 rank 0
2022-08-26 20:32:03,708 DEBUG CV Batch 222/500 loss 15.932682 loss_att 11.712183 loss_ctc 25.780510 loss_ctc_origin 18.793785 loss_ctc0 42.082870 history loss 24.015538 rank 0
2022-08-26 20:32:13,852 DEBUG CV Batch 222/600 loss 17.089275 loss_att 12.266088 loss_ctc 28.343380 loss_ctc_origin 17.809937 loss_ctc0 52.921417 history loss 23.853367 rank 0
2022-08-26 20:32:23,499 DEBUG CV Batch 222/700 loss 18.698280 loss_att 13.460586 loss_ctc 30.919563 loss_ctc_origin 17.060211 loss_ctc0 63.258057 history loss 23.523854 rank 0
2022-08-26 20:32:33,794 DEBUG CV Batch 222/800 loss 21.368979 loss_att 16.540655 loss_ctc 32.635063 loss_ctc_origin 17.213930 loss_ctc0 68.617699 history loss 23.489830 rank 0
2022-08-26 20:32:43,668 INFO Epoch 222 CV info cv_loss 23.57776292247217
2022-08-26 20:32:43,668 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/222.pt
2022-08-26 20:32:44,103 INFO Epoch 223 TRAIN info lr 0.0005615620752217744
2022-08-26 20:32:44,107 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 20:33:09,675 DEBUG TRAIN Batch 223/0 loss 46.943893 loss_att 29.338335 loss_ctc 88.023529 loss_ctc_origin 57.466194 loss_ctc0 159.323990 lr 0.00056156 rank 0
2022-08-26 20:33:38,037 DEBUG TRAIN Batch 223/100 loss 48.683342 loss_att 24.953943 loss_ctc 104.051933 loss_ctc_origin 54.164211 loss_ctc0 220.456604 lr 0.00056154 rank 0
2022-08-26 20:34:05,622 DEBUG TRAIN Batch 223/200 loss 19.081543 loss_att 8.398060 loss_ctc 44.009666 loss_ctc_origin 33.858166 loss_ctc0 67.696503 lr 0.00056152 rank 0
2022-08-26 20:34:32,405 DEBUG TRAIN Batch 223/300 loss 16.539930 loss_att 7.213307 loss_ctc 38.302048 loss_ctc_origin 24.689426 loss_ctc0 70.064819 lr 0.00056149 rank 0
2022-08-26 20:35:00,611 DEBUG TRAIN Batch 223/400 loss 22.421682 loss_att 9.012811 loss_ctc 53.709049 loss_ctc_origin 34.326942 loss_ctc0 98.933960 lr 0.00056147 rank 0
2022-08-26 20:35:27,620 DEBUG TRAIN Batch 223/500 loss 41.454536 loss_att 28.588995 loss_ctc 71.474136 loss_ctc_origin 45.623535 loss_ctc0 131.792191 lr 0.00056145 rank 0
2022-08-26 20:35:54,950 DEBUG TRAIN Batch 223/600 loss 54.701942 loss_att 31.113333 loss_ctc 109.742035 loss_ctc_origin 61.336929 loss_ctc0 222.687256 lr 0.00056143 rank 0
2022-08-26 20:36:23,552 DEBUG TRAIN Batch 223/700 loss 18.188879 loss_att 7.059801 loss_ctc 44.156723 loss_ctc_origin 31.985249 loss_ctc0 72.556831 lr 0.00056141 rank 0
2022-08-26 20:36:51,332 DEBUG TRAIN Batch 223/800 loss 20.891386 loss_att 8.176992 loss_ctc 50.558304 loss_ctc_origin 36.681641 loss_ctc0 82.937180 lr 0.00056138 rank 0
2022-08-26 20:37:19,174 DEBUG TRAIN Batch 223/900 loss 20.437840 loss_att 8.389344 loss_ctc 48.550991 loss_ctc_origin 30.875769 loss_ctc0 89.793175 lr 0.00056136 rank 0
2022-08-26 20:37:47,030 DEBUG TRAIN Batch 223/1000 loss 47.085716 loss_att 33.396309 loss_ctc 79.027664 loss_ctc_origin 50.944557 loss_ctc0 144.554901 lr 0.00056134 rank 0
2022-08-26 20:38:15,186 DEBUG TRAIN Batch 223/1100 loss 58.650146 loss_att 35.287140 loss_ctc 113.163818 loss_ctc_origin 69.739769 loss_ctc0 214.486572 lr 0.00056132 rank 0
2022-08-26 20:38:42,486 DEBUG TRAIN Batch 223/1200 loss 18.453362 loss_att 9.908514 loss_ctc 38.391335 loss_ctc_origin 26.808458 loss_ctc0 65.418045 lr 0.00056130 rank 0
2022-08-26 20:39:10,575 DEBUG TRAIN Batch 223/1300 loss 19.953657 loss_att 7.249604 loss_ctc 49.596447 loss_ctc_origin 35.032711 loss_ctc0 83.578491 lr 0.00056127 rank 0
2022-08-26 20:39:38,236 DEBUG TRAIN Batch 223/1400 loss 20.504690 loss_att 7.961782 loss_ctc 49.771477 loss_ctc_origin 30.980579 loss_ctc0 93.616905 lr 0.00056125 rank 0
2022-08-26 20:40:11,275 DEBUG TRAIN Batch 223/1500 loss 49.593788 loss_att 31.344212 loss_ctc 92.176132 loss_ctc_origin 62.172688 loss_ctc0 162.184143 lr 0.00056123 rank 0
2022-08-26 20:40:38,634 DEBUG TRAIN Batch 223/1600 loss 53.788483 loss_att 30.398062 loss_ctc 108.366135 loss_ctc_origin 63.340820 loss_ctc0 213.425171 lr 0.00056121 rank 0
2022-08-26 20:41:06,117 DEBUG TRAIN Batch 223/1700 loss 13.791201 loss_att 6.380943 loss_ctc 31.081799 loss_ctc_origin 17.786667 loss_ctc0 62.103771 lr 0.00056119 rank 0
2022-08-26 20:41:33,625 DEBUG TRAIN Batch 223/1800 loss 19.856184 loss_att 8.206146 loss_ctc 47.039604 loss_ctc_origin 31.954872 loss_ctc0 82.237312 lr 0.00056116 rank 0
2022-08-26 20:42:02,074 DEBUG TRAIN Batch 223/1900 loss 22.405495 loss_att 8.720396 loss_ctc 54.337391 loss_ctc_origin 37.219784 loss_ctc0 94.278473 lr 0.00056114 rank 0
2022-08-26 20:42:29,959 DEBUG TRAIN Batch 223/2000 loss 46.702179 loss_att 30.186720 loss_ctc 85.238258 loss_ctc_origin 52.420879 loss_ctc0 161.812134 lr 0.00056112 rank 0
2022-08-26 20:42:57,206 DEBUG TRAIN Batch 223/2100 loss 49.914871 loss_att 26.409201 loss_ctc 104.761429 loss_ctc_origin 56.685059 loss_ctc0 216.939606 lr 0.00056110 rank 0
2022-08-26 20:43:27,228 DEBUG TRAIN Batch 223/2200 loss 18.059490 loss_att 8.533917 loss_ctc 40.285828 loss_ctc_origin 28.412758 loss_ctc0 67.989655 lr 0.00056107 rank 0
2022-08-26 20:43:54,818 DEBUG TRAIN Batch 223/2300 loss 18.282593 loss_att 7.194189 loss_ctc 44.155533 loss_ctc_origin 28.179054 loss_ctc0 81.433975 lr 0.00056105 rank 0
2022-08-26 20:44:23,157 DEBUG TRAIN Batch 223/2400 loss 19.318619 loss_att 7.490469 loss_ctc 46.917629 loss_ctc_origin 27.708229 loss_ctc0 91.739563 lr 0.00056103 rank 0
2022-08-26 20:44:49,610 DEBUG TRAIN Batch 223/2500 loss 48.385231 loss_att 31.923038 loss_ctc 86.797012 loss_ctc_origin 54.364273 loss_ctc0 162.473419 lr 0.00056101 rank 0
2022-08-26 20:45:16,783 DEBUG TRAIN Batch 223/2600 loss 60.166107 loss_att 34.108261 loss_ctc 120.967743 loss_ctc_origin 76.052200 loss_ctc0 225.770676 lr 0.00056099 rank 0
2022-08-26 20:45:43,722 DEBUG TRAIN Batch 223/2700 loss 15.748735 loss_att 8.102158 loss_ctc 33.590752 loss_ctc_origin 21.061010 loss_ctc0 62.826809 lr 0.00056096 rank 0
2022-08-26 20:46:10,201 DEBUG TRAIN Batch 223/2800 loss 18.404739 loss_att 7.333717 loss_ctc 44.237122 loss_ctc_origin 28.507828 loss_ctc0 80.938805 lr 0.00056094 rank 0
2022-08-26 20:46:36,798 DEBUG TRAIN Batch 223/2900 loss 19.963881 loss_att 8.223547 loss_ctc 47.357990 loss_ctc_origin 30.145273 loss_ctc0 87.520996 lr 0.00056092 rank 0
2022-08-26 20:47:12,001 DEBUG TRAIN Batch 223/3000 loss 45.395775 loss_att 30.739103 loss_ctc 79.594666 loss_ctc_origin 54.555283 loss_ctc0 138.019897 lr 0.00056090 rank 0
2022-08-26 20:47:39,725 DEBUG TRAIN Batch 223/3100 loss 53.846397 loss_att 30.004782 loss_ctc 109.476837 loss_ctc_origin 67.008858 loss_ctc0 208.568771 lr 0.00056088 rank 0
2022-08-26 20:48:06,224 DEBUG TRAIN Batch 223/3200 loss 19.880753 loss_att 10.623837 loss_ctc 41.480217 loss_ctc_origin 30.701736 loss_ctc0 66.629997 lr 0.00056085 rank 0
2022-08-26 20:48:11,447 WARNING NaN or Inf found in input tensor.
2022-08-26 20:48:33,417 DEBUG TRAIN Batch 223/3300 loss 15.789981 loss_att 5.547348 loss_ctc 39.689457 loss_ctc_origin 25.666935 loss_ctc0 72.408676 lr 0.00056083 rank 0
2022-08-26 20:49:00,680 DEBUG TRAIN Batch 223/3400 loss 22.404308 loss_att 10.042353 loss_ctc 51.248867 loss_ctc_origin 32.313629 loss_ctc0 95.431091 lr 0.00056081 rank 0
2022-08-26 20:49:27,928 DEBUG TRAIN Batch 223/3500 loss 39.632851 loss_att 24.609285 loss_ctc 74.687836 loss_ctc_origin 46.703812 loss_ctc0 139.983871 lr 0.00056079 rank 0
2022-08-26 20:49:54,697 DEBUG TRAIN Batch 223/3600 loss 51.568291 loss_att 29.607754 loss_ctc 102.809547 loss_ctc_origin 58.150421 loss_ctc0 207.014160 lr 0.00056077 rank 0
2022-08-26 20:50:13,896 WARNING NaN or Inf found in input tensor.
2022-08-26 20:50:22,415 DEBUG TRAIN Batch 223/3700 loss 18.640991 loss_att 10.314207 loss_ctc 38.070148 loss_ctc_origin 26.972534 loss_ctc0 63.964581 lr 0.00056074 rank 0
2022-08-26 20:50:49,390 DEBUG TRAIN Batch 223/3800 loss 17.346342 loss_att 6.667481 loss_ctc 42.263680 loss_ctc_origin 27.425697 loss_ctc0 76.885635 lr 0.00056072 rank 0
2022-08-26 20:51:06,289 WARNING NaN or Inf found in input tensor.
2022-08-26 20:51:19,320 DEBUG TRAIN Batch 223/3900 loss 23.036592 loss_att 9.175838 loss_ctc 55.378353 loss_ctc_origin 39.051495 loss_ctc0 93.474350 lr 0.00056070 rank 0
2022-08-26 20:51:44,485 DEBUG TRAIN Batch 223/4000 loss 42.510040 loss_att 28.762062 loss_ctc 74.588661 loss_ctc_origin 43.923241 loss_ctc0 146.141296 lr 0.00056068 rank 0
2022-08-26 20:52:12,081 DEBUG TRAIN Batch 223/4100 loss 50.269089 loss_att 26.697056 loss_ctc 105.270493 loss_ctc_origin 55.867607 loss_ctc0 220.543884 lr 0.00056066 rank 0
2022-08-26 20:52:38,432 DEBUG TRAIN Batch 223/4200 loss 20.547262 loss_att 10.141100 loss_ctc 44.828308 loss_ctc_origin 31.721193 loss_ctc0 75.411575 lr 0.00056063 rank 0
2022-08-26 20:53:05,892 DEBUG TRAIN Batch 223/4300 loss 17.935331 loss_att 6.869306 loss_ctc 43.756058 loss_ctc_origin 26.416531 loss_ctc0 84.214951 lr 0.00056061 rank 0
2022-08-26 20:53:33,741 DEBUG TRAIN Batch 223/4400 loss 21.787151 loss_att 9.004309 loss_ctc 51.613785 loss_ctc_origin 35.337044 loss_ctc0 89.592850 lr 0.00056059 rank 0
2022-08-26 20:54:05,210 DEBUG TRAIN Batch 223/4500 loss 44.764656 loss_att 28.860102 loss_ctc 81.875275 loss_ctc_origin 53.532227 loss_ctc0 148.009048 lr 0.00056057 rank 0
2022-08-26 20:54:31,689 DEBUG TRAIN Batch 223/4600 loss 46.692734 loss_att 25.621456 loss_ctc 95.859039 loss_ctc_origin 50.698551 loss_ctc0 201.233490 lr 0.00056055 rank 0
2022-08-26 20:54:59,024 DEBUG TRAIN Batch 223/4700 loss 18.651770 loss_att 9.490278 loss_ctc 40.028580 loss_ctc_origin 28.222551 loss_ctc0 67.575974 lr 0.00056052 rank 0
2022-08-26 20:55:27,107 DEBUG TRAIN Batch 223/4800 loss 17.804729 loss_att 6.730169 loss_ctc 43.645370 loss_ctc_origin 26.577904 loss_ctc0 83.469460 lr 0.00056050 rank 0
2022-08-26 20:55:49,922 WARNING NaN or Inf found in input tensor.
2022-08-26 20:55:54,239 DEBUG TRAIN Batch 223/4900 loss 19.285515 loss_att 7.275595 loss_ctc 47.308659 loss_ctc_origin 29.023951 loss_ctc0 89.972977 lr 0.00056048 rank 0
2022-08-26 20:56:21,901 DEBUG TRAIN Batch 223/5000 loss 42.983704 loss_att 26.094038 loss_ctc 82.392914 loss_ctc_origin 52.674263 loss_ctc0 151.736450 lr 0.00056046 rank 0
2022-08-26 20:56:48,727 DEBUG TRAIN Batch 223/5100 loss 54.465805 loss_att 31.040346 loss_ctc 109.125198 loss_ctc_origin 68.141106 loss_ctc0 204.754761 lr 0.00056044 rank 0
2022-08-26 20:57:14,984 WARNING NaN or Inf found in input tensor.
2022-08-26 20:57:16,589 DEBUG TRAIN Batch 223/5200 loss 17.980696 loss_att 8.201609 loss_ctc 40.798565 loss_ctc_origin 27.969585 loss_ctc0 70.732849 lr 0.00056041 rank 0
2022-08-26 20:57:44,590 DEBUG TRAIN Batch 223/5300 loss 21.004679 loss_att 8.531212 loss_ctc 50.109436 loss_ctc_origin 37.041351 loss_ctc0 80.601639 lr 0.00056039 rank 0
2022-08-26 20:58:11,887 DEBUG TRAIN Batch 223/5400 loss 20.734013 loss_att 8.492876 loss_ctc 49.296665 loss_ctc_origin 29.298431 loss_ctc0 95.959206 lr 0.00056037 rank 0
2022-08-26 20:58:39,361 WARNING NaN or Inf found in input tensor.
2022-08-26 20:58:39,401 DEBUG TRAIN Batch 223/5500 loss inf loss_att 33.375618 loss_ctc inf loss_ctc_origin inf loss_ctc0 inf lr 0.00056035 rank 0
2022-08-26 20:59:05,924 DEBUG TRAIN Batch 223/5600 loss 49.499832 loss_att 30.153934 loss_ctc 94.640251 loss_ctc_origin 53.385586 loss_ctc0 190.901123 lr 0.00056033 rank 0
2022-08-26 20:59:27,328 DEBUG CV Batch 223/0 loss 11.480356 loss_att 8.291219 loss_ctc 18.921677 loss_ctc_origin 12.477242 loss_ctc0 33.958687 history loss 10.805041 rank 0
2022-08-26 20:59:37,676 DEBUG CV Batch 223/100 loss 21.170376 loss_att 17.442047 loss_ctc 29.869814 loss_ctc_origin 20.366051 loss_ctc0 52.045261 history loss 25.986082 rank 0
2022-08-26 20:59:47,073 DEBUG CV Batch 223/200 loss 24.506611 loss_att 19.032013 loss_ctc 37.280670 loss_ctc_origin 26.718182 loss_ctc0 61.926468 history loss 27.254681 rank 0
2022-08-26 20:59:56,916 DEBUG CV Batch 223/300 loss 22.816093 loss_att 17.545540 loss_ctc 35.114052 loss_ctc_origin 20.156548 loss_ctc0 70.014900 history loss 26.356178 rank 0
2022-08-26 21:00:07,261 DEBUG CV Batch 223/400 loss 35.784641 loss_att 28.409239 loss_ctc 52.993912 loss_ctc_origin 35.474762 loss_ctc0 93.871918 history loss 24.671665 rank 0
2022-08-26 21:00:17,384 DEBUG CV Batch 223/500 loss 16.932413 loss_att 13.071542 loss_ctc 25.941113 loss_ctc_origin 19.009747 loss_ctc0 42.114300 history loss 24.334895 rank 0
2022-08-26 21:00:27,890 DEBUG CV Batch 223/600 loss 17.239191 loss_att 12.226429 loss_ctc 28.935635 loss_ctc_origin 18.391451 loss_ctc0 53.538727 history loss 24.166368 rank 0
2022-08-26 21:00:37,781 DEBUG CV Batch 223/700 loss 19.093704 loss_att 13.999132 loss_ctc 30.981041 loss_ctc_origin 17.173391 loss_ctc0 63.198887 history loss 23.826738 rank 0
2022-08-26 21:00:47,925 DEBUG CV Batch 223/800 loss 21.311449 loss_att 16.551626 loss_ctc 32.417702 loss_ctc_origin 16.781013 loss_ctc0 68.903305 history loss 23.796595 rank 0
2022-08-26 21:00:57,875 INFO Epoch 223 CV info cv_loss 23.87953194235943
2022-08-26 21:00:57,875 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/223.pt
2022-08-26 21:00:58,354 INFO Epoch 224 TRAIN info lr 0.0005603071863344849
2022-08-26 21:00:58,358 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 21:01:24,335 DEBUG TRAIN Batch 224/0 loss 46.711578 loss_att 31.630037 loss_ctc 81.901840 loss_ctc_origin 57.216980 loss_ctc0 139.499847 lr 0.00056031 rank 0
2022-08-26 21:01:51,854 DEBUG TRAIN Batch 224/100 loss 56.000854 loss_att 34.607239 loss_ctc 105.919281 loss_ctc_origin 65.823402 loss_ctc0 199.476334 lr 0.00056028 rank 0
2022-08-26 21:01:58,130 WARNING NaN or Inf found in input tensor.
2022-08-26 21:02:19,511 DEBUG TRAIN Batch 224/200 loss 17.016226 loss_att 8.081054 loss_ctc 37.864960 loss_ctc_origin 27.031452 loss_ctc0 63.143135 lr 0.00056026 rank 0
2022-08-26 21:02:47,690 DEBUG TRAIN Batch 224/300 loss 16.340660 loss_att 5.985508 loss_ctc 40.502678 loss_ctc_origin 24.645845 loss_ctc0 77.501953 lr 0.00056024 rank 0
2022-08-26 21:03:16,266 DEBUG TRAIN Batch 224/400 loss 18.677134 loss_att 8.040934 loss_ctc 43.494930 loss_ctc_origin 25.911758 loss_ctc0 84.522324 lr 0.00056022 rank 0
2022-08-26 21:03:45,064 DEBUG TRAIN Batch 224/500 loss 41.483688 loss_att 28.000547 loss_ctc 72.944351 loss_ctc_origin 49.515686 loss_ctc0 127.611237 lr 0.00056020 rank 0
2022-08-26 21:04:13,311 DEBUG TRAIN Batch 224/600 loss 46.361015 loss_att 22.598850 loss_ctc 101.806068 loss_ctc_origin 58.582687 loss_ctc0 202.660614 lr 0.00056017 rank 0
2022-08-26 21:04:40,389 DEBUG TRAIN Batch 224/700 loss 20.490303 loss_att 11.732056 loss_ctc 40.926208 loss_ctc_origin 29.733994 loss_ctc0 67.041382 lr 0.00056015 rank 0
2022-08-26 21:05:07,876 DEBUG TRAIN Batch 224/800 loss 18.943211 loss_att 7.771173 loss_ctc 45.011299 loss_ctc_origin 30.604340 loss_ctc0 78.627541 lr 0.00056013 rank 0
2022-08-26 21:05:34,781 DEBUG TRAIN Batch 224/900 loss 23.483862 loss_att 10.020355 loss_ctc 54.898708 loss_ctc_origin 39.073967 loss_ctc0 91.823105 lr 0.00056011 rank 0
2022-08-26 21:05:56,625 WARNING NaN or Inf found in input tensor.
2022-08-26 21:06:02,784 DEBUG TRAIN Batch 224/1000 loss 45.454033 loss_att 29.226509 loss_ctc 83.318253 loss_ctc_origin 53.959084 loss_ctc0 151.822968 lr 0.00056009 rank 0
2022-08-26 21:06:30,368 DEBUG TRAIN Batch 224/1100 loss 47.733856 loss_att 24.645496 loss_ctc 101.606705 loss_ctc_origin 51.195381 loss_ctc0 219.233109 lr 0.00056006 rank 0
2022-08-26 21:06:57,405 DEBUG TRAIN Batch 224/1200 loss 20.646879 loss_att 10.977848 loss_ctc 43.207951 loss_ctc_origin 32.494942 loss_ctc0 68.204971 lr 0.00056004 rank 0
2022-08-26 21:07:25,260 DEBUG TRAIN Batch 224/1300 loss 18.101654 loss_att 7.739062 loss_ctc 42.281033 loss_ctc_origin 26.079603 loss_ctc0 80.084366 lr 0.00056002 rank 0
2022-08-26 21:07:48,030 WARNING NaN or Inf found in input tensor.
2022-08-26 21:07:52,435 DEBUG TRAIN Batch 224/1400 loss 16.902304 loss_att 6.025058 loss_ctc 42.282543 loss_ctc_origin 24.117172 loss_ctc0 84.668404 lr 0.00056000 rank 0
2022-08-26 21:08:25,960 DEBUG TRAIN Batch 224/1500 loss 43.851757 loss_att 26.123405 loss_ctc 85.217911 loss_ctc_origin 51.710911 loss_ctc0 163.400909 lr 0.00055998 rank 0
2022-08-26 21:08:53,639 DEBUG TRAIN Batch 224/1600 loss 54.239933 loss_att 31.736790 loss_ctc 106.747261 loss_ctc_origin 60.618168 loss_ctc0 214.381805 lr 0.00055995 rank 0
2022-08-26 21:09:07,124 WARNING NaN or Inf found in input tensor.
2022-08-26 21:09:20,967 DEBUG TRAIN Batch 224/1700 loss 18.741455 loss_att 9.565248 loss_ctc 40.152603 loss_ctc_origin 28.434391 loss_ctc0 67.495087 lr 0.00055993 rank 0
2022-08-26 21:09:26,313 WARNING NaN or Inf found in input tensor.
2022-08-26 21:09:48,571 DEBUG TRAIN Batch 224/1800 loss 18.345600 loss_att 6.778905 loss_ctc 45.334549 loss_ctc_origin 30.067825 loss_ctc0 80.956894 lr 0.00055991 rank 0
2022-08-26 21:09:52,280 WARNING NaN or Inf found in input tensor.
2022-08-26 21:10:16,044 DEBUG TRAIN Batch 224/1900 loss 22.567738 loss_att 9.478718 loss_ctc 53.108780 loss_ctc_origin 35.496689 loss_ctc0 94.203659 lr 0.00055989 rank 0
2022-08-26 21:10:44,081 DEBUG TRAIN Batch 224/2000 loss 43.539482 loss_att 28.347351 loss_ctc 78.987793 loss_ctc_origin 50.427105 loss_ctc0 145.629395 lr 0.00055987 rank 0
2022-08-26 21:11:10,998 DEBUG TRAIN Batch 224/2100 loss 48.663689 loss_att 26.238077 loss_ctc 100.990105 loss_ctc_origin 59.430496 loss_ctc0 197.962524 lr 0.00055985 rank 0
2022-08-26 21:11:38,535 DEBUG TRAIN Batch 224/2200 loss 15.809116 loss_att 6.932930 loss_ctc 36.520218 loss_ctc_origin 23.196844 loss_ctc0 67.608078 lr 0.00055982 rank 0
2022-08-26 21:12:05,610 DEBUG TRAIN Batch 224/2300 loss 18.167824 loss_att 6.944393 loss_ctc 44.355827 loss_ctc_origin 29.394339 loss_ctc0 79.265976 lr 0.00055980 rank 0
2022-08-26 21:12:32,043 DEBUG TRAIN Batch 224/2400 loss 22.295599 loss_att 8.618977 loss_ctc 54.207718 loss_ctc_origin 32.453163 loss_ctc0 104.968338 lr 0.00055978 rank 0
2022-08-26 21:12:59,945 DEBUG TRAIN Batch 224/2500 loss 43.142403 loss_att 28.717718 loss_ctc 76.800003 loss_ctc_origin 48.791283 loss_ctc0 142.153687 lr 0.00055976 rank 0
2022-08-26 21:13:27,044 DEBUG TRAIN Batch 224/2600 loss 26.935646 loss_att 13.708064 loss_ctc 57.799999 loss_ctc_origin 27.134241 loss_ctc0 129.353424 lr 0.00055974 rank 0
2022-08-26 21:13:53,877 DEBUG TRAIN Batch 224/2700 loss 17.003933 loss_att 7.323508 loss_ctc 39.591591 loss_ctc_origin 29.847334 loss_ctc0 62.328186 lr 0.00055971 rank 0
2022-08-26 21:14:05,442 WARNING NaN or Inf found in input tensor.
2022-08-26 21:14:22,213 DEBUG TRAIN Batch 224/2800 loss 21.437744 loss_att 9.159292 loss_ctc 50.087467 loss_ctc_origin 36.620152 loss_ctc0 81.511200 lr 0.00055969 rank 0
2022-08-26 21:14:44,892 WARNING NaN or Inf found in input tensor.
2022-08-26 21:14:49,214 DEBUG TRAIN Batch 224/2900 loss 19.938105 loss_att 8.426082 loss_ctc 46.799488 loss_ctc_origin 27.118443 loss_ctc0 92.721924 lr 0.00055967 rank 0
2022-08-26 21:15:22,573 DEBUG TRAIN Batch 224/3000 loss 44.107712 loss_att 27.883623 loss_ctc 81.963913 loss_ctc_origin 52.147247 loss_ctc0 151.536133 lr 0.00055965 rank 0
2022-08-26 21:15:50,555 DEBUG TRAIN Batch 224/3100 loss 48.744457 loss_att 27.549229 loss_ctc 98.199989 loss_ctc_origin 60.218033 loss_ctc0 186.824554 lr 0.00055963 rank 0
2022-08-26 21:16:18,683 DEBUG TRAIN Batch 224/3200 loss 18.459049 loss_att 8.621382 loss_ctc 41.413609 loss_ctc_origin 28.108452 loss_ctc0 72.458969 lr 0.00055960 rank 0
2022-08-26 21:16:45,983 DEBUG TRAIN Batch 224/3300 loss 16.346638 loss_att 5.895350 loss_ctc 40.732971 loss_ctc_origin 26.146795 loss_ctc0 74.767380 lr 0.00055958 rank 0
2022-08-26 21:17:13,673 DEBUG TRAIN Batch 224/3400 loss 17.564186 loss_att 6.984225 loss_ctc 42.250763 loss_ctc_origin 23.726608 loss_ctc0 85.473785 lr 0.00055956 rank 0
2022-08-26 21:17:41,667 DEBUG TRAIN Batch 224/3500 loss 41.230087 loss_att 24.652939 loss_ctc 79.910103 loss_ctc_origin 51.180294 loss_ctc0 146.946320 lr 0.00055954 rank 0
2022-08-26 21:17:49,382 WARNING NaN or Inf found in input tensor.
2022-08-26 21:18:09,636 DEBUG TRAIN Batch 224/3600 loss 48.040462 loss_att 26.583048 loss_ctc 98.107758 loss_ctc_origin 59.105427 loss_ctc0 189.113190 lr 0.00055952 rank 0
2022-08-26 21:18:35,852 WARNING NaN or Inf found in input tensor.
2022-08-26 21:18:37,453 DEBUG TRAIN Batch 224/3700 loss 19.588314 loss_att 9.351062 loss_ctc 43.475235 loss_ctc_origin 32.881275 loss_ctc0 68.194473 lr 0.00055949 rank 0
2022-08-26 21:19:05,150 DEBUG TRAIN Batch 224/3800 loss 18.067116 loss_att 6.825149 loss_ctc 44.298370 loss_ctc_origin 26.703617 loss_ctc0 85.352783 lr 0.00055947 rank 0
2022-08-26 21:19:32,875 DEBUG TRAIN Batch 224/3900 loss 21.755098 loss_att 9.179749 loss_ctc 51.097580 loss_ctc_origin 34.476692 loss_ctc0 89.879654 lr 0.00055945 rank 0
2022-08-26 21:20:01,698 DEBUG TRAIN Batch 224/4000 loss 39.328442 loss_att 22.323799 loss_ctc 79.005936 loss_ctc_origin 52.191174 loss_ctc0 141.573700 lr 0.00055943 rank 0
2022-08-26 21:20:28,511 DEBUG TRAIN Batch 224/4100 loss 46.534370 loss_att 26.265583 loss_ctc 93.828201 loss_ctc_origin 56.560471 loss_ctc0 180.786255 lr 0.00055941 rank 0
2022-08-26 21:20:56,224 DEBUG TRAIN Batch 224/4200 loss 17.451923 loss_att 7.840222 loss_ctc 39.879223 loss_ctc_origin 27.325140 loss_ctc0 69.172081 lr 0.00055939 rank 0
2022-08-26 21:21:24,652 DEBUG TRAIN Batch 224/4300 loss 16.562326 loss_att 6.898863 loss_ctc 39.110405 loss_ctc_origin 24.896030 loss_ctc0 72.277283 lr 0.00055936 rank 0
2022-08-26 21:21:53,029 DEBUG TRAIN Batch 224/4400 loss 21.140656 loss_att 7.931509 loss_ctc 51.961994 loss_ctc_origin 33.373611 loss_ctc0 95.334885 lr 0.00055934 rank 0
2022-08-26 21:22:15,611 WARNING NaN or Inf found in input tensor.
2022-08-26 21:22:27,699 DEBUG TRAIN Batch 224/4500 loss 43.432259 loss_att 28.945873 loss_ctc 77.233826 loss_ctc_origin 50.355301 loss_ctc0 139.950378 lr 0.00055932 rank 0
2022-08-26 21:22:28,506 WARNING NaN or Inf found in input tensor.
2022-08-26 21:22:55,192 DEBUG TRAIN Batch 224/4600 loss 38.258827 loss_att 19.821917 loss_ctc 81.278290 loss_ctc_origin 39.194016 loss_ctc0 179.474915 lr 0.00055930 rank 0
2022-08-26 21:23:22,865 DEBUG TRAIN Batch 224/4700 loss 17.823097 loss_att 8.865881 loss_ctc 38.723267 loss_ctc_origin 27.391312 loss_ctc0 65.164490 lr 0.00055928 rank 0
2022-08-26 21:23:51,142 DEBUG TRAIN Batch 224/4800 loss 18.243393 loss_att 8.253208 loss_ctc 41.553825 loss_ctc_origin 26.443607 loss_ctc0 76.810997 lr 0.00055925 rank 0
2022-08-26 21:24:19,155 DEBUG TRAIN Batch 224/4900 loss 21.154789 loss_att 8.311934 loss_ctc 51.121452 loss_ctc_origin 32.097610 loss_ctc0 95.510414 lr 0.00055923 rank 0
2022-08-26 21:24:46,398 DEBUG TRAIN Batch 224/5000 loss 40.362331 loss_att 27.941967 loss_ctc 69.343185 loss_ctc_origin 48.661968 loss_ctc0 117.599365 lr 0.00055921 rank 0
2022-08-26 21:25:13,928 DEBUG TRAIN Batch 224/5100 loss 43.376522 loss_att 23.488810 loss_ctc 89.781181 loss_ctc_origin 55.696823 loss_ctc0 169.311356 lr 0.00055919 rank 0
2022-08-26 21:25:42,264 DEBUG TRAIN Batch 224/5200 loss 16.180847 loss_att 8.295087 loss_ctc 34.580956 loss_ctc_origin 23.033268 loss_ctc0 61.525562 lr 0.00055917 rank 0
2022-08-26 21:26:09,598 DEBUG TRAIN Batch 224/5300 loss 19.777538 loss_att 8.483427 loss_ctc 46.130463 loss_ctc_origin 31.269165 loss_ctc0 80.806831 lr 0.00055914 rank 0
2022-08-26 21:26:37,556 DEBUG TRAIN Batch 224/5400 loss 20.497002 loss_att 8.626672 loss_ctc 48.194435 loss_ctc_origin 28.570150 loss_ctc0 93.984421 lr 0.00055912 rank 0
2022-08-26 21:26:40,186 WARNING NaN or Inf found in input tensor.
2022-08-26 21:27:06,231 DEBUG TRAIN Batch 224/5500 loss 34.755959 loss_att 21.606127 loss_ctc 65.438889 loss_ctc_origin 42.709259 loss_ctc0 118.474686 lr 0.00055910 rank 0
2022-08-26 21:27:33,937 DEBUG TRAIN Batch 224/5600 loss 37.934589 loss_att 20.575647 loss_ctc 78.438782 loss_ctc_origin 39.796600 loss_ctc0 168.603882 lr 0.00055908 rank 0
2022-08-26 21:27:57,251 DEBUG CV Batch 224/0 loss 11.682822 loss_att 8.630201 loss_ctc 18.805603 loss_ctc_origin 12.106030 loss_ctc0 34.437943 history loss 10.995597 rank 0
2022-08-26 21:28:07,858 DEBUG CV Batch 224/100 loss 20.030560 loss_att 15.978794 loss_ctc 29.484678 loss_ctc_origin 19.435280 loss_ctc0 52.933273 history loss 26.092959 rank 0
2022-08-26 21:28:17,198 DEBUG CV Batch 224/200 loss 24.827843 loss_att 19.254753 loss_ctc 37.831718 loss_ctc_origin 27.621975 loss_ctc0 61.654449 history loss 27.279989 rank 0
2022-08-26 21:28:27,038 DEBUG CV Batch 224/300 loss 21.961349 loss_att 16.902023 loss_ctc 33.766441 loss_ctc_origin 18.330515 loss_ctc0 69.783600 history loss 26.371471 rank 0
2022-08-26 21:28:37,305 DEBUG CV Batch 224/400 loss 36.811806 loss_att 29.214554 loss_ctc 54.538719 loss_ctc_origin 37.913502 loss_ctc0 93.330887 history loss 24.675666 rank 0
2022-08-26 21:28:47,883 DEBUG CV Batch 224/500 loss 15.180138 loss_att 10.880153 loss_ctc 25.213432 loss_ctc_origin 18.168873 loss_ctc0 41.650734 history loss 24.316928 rank 0
2022-08-26 21:28:58,417 DEBUG CV Batch 224/600 loss 16.902992 loss_att 12.134415 loss_ctc 28.029671 loss_ctc_origin 17.251541 loss_ctc0 53.178635 history loss 24.142008 rank 0
2022-08-26 21:29:07,860 DEBUG CV Batch 224/700 loss 18.407223 loss_att 13.055712 loss_ctc 30.894079 loss_ctc_origin 17.060883 loss_ctc0 63.171535 history loss 23.779954 rank 0
2022-08-26 21:29:17,826 DEBUG CV Batch 224/800 loss 21.809700 loss_att 17.231411 loss_ctc 32.492371 loss_ctc_origin 17.212128 loss_ctc0 68.146263 history loss 23.736596 rank 0
2022-08-26 21:29:27,634 INFO Epoch 224 CV info cv_loss 23.81643710945509
2022-08-26 21:29:27,634 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/224.pt
2022-08-26 21:29:28,092 INFO Epoch 225 TRAIN info lr 0.0005590606726962529
2022-08-26 21:29:28,096 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 21:29:54,459 DEBUG TRAIN Batch 225/0 loss 32.482918 loss_att 22.356798 loss_ctc 56.110535 loss_ctc_origin 35.272816 loss_ctc0 104.731873 lr 0.00055906 rank 0
2022-08-26 21:30:21,847 DEBUG TRAIN Batch 225/100 loss 47.035969 loss_att 29.052105 loss_ctc 88.998314 loss_ctc_origin 49.936584 loss_ctc0 180.142349 lr 0.00055904 rank 0
2022-08-26 21:30:49,263 DEBUG TRAIN Batch 225/200 loss 16.774755 loss_att 8.757144 loss_ctc 35.482513 loss_ctc_origin 23.777113 loss_ctc0 62.795124 lr 0.00055902 rank 0
2022-08-26 21:31:16,525 DEBUG TRAIN Batch 225/300 loss 16.342094 loss_att 6.506639 loss_ctc 39.291492 loss_ctc_origin 21.376656 loss_ctc0 81.092773 lr 0.00055899 rank 0
2022-08-26 21:31:44,410 DEBUG TRAIN Batch 225/400 loss 23.646503 loss_att 9.855337 loss_ctc 55.825890 loss_ctc_origin 38.229034 loss_ctc0 96.885216 lr 0.00055897 rank 0
2022-08-26 21:32:12,155 DEBUG TRAIN Batch 225/500 loss 48.953392 loss_att 33.998466 loss_ctc 83.848221 loss_ctc_origin 55.692932 loss_ctc0 149.543884 lr 0.00055895 rank 0
2022-08-26 21:32:38,694 DEBUG TRAIN Batch 225/600 loss 43.105419 loss_att 24.321600 loss_ctc 86.934326 loss_ctc_origin 46.531990 loss_ctc0 181.206451 lr 0.00055893 rank 0
2022-08-26 21:33:05,620 DEBUG TRAIN Batch 225/700 loss 17.123016 loss_att 9.577751 loss_ctc 34.728638 loss_ctc_origin 23.501089 loss_ctc0 60.926254 lr 0.00055891 rank 0
2022-08-26 21:33:23,888 WARNING NaN or Inf found in input tensor.
2022-08-26 21:33:33,384 DEBUG TRAIN Batch 225/800 loss 18.819351 loss_att 7.038960 loss_ctc 46.306931 loss_ctc_origin 31.551540 loss_ctc0 80.736176 lr 0.00055889 rank 0
2022-08-26 21:34:01,450 DEBUG TRAIN Batch 225/900 loss 17.338335 loss_att 6.786801 loss_ctc 41.958580 loss_ctc_origin 26.860388 loss_ctc0 77.187698 lr 0.00055886 rank 0
2022-08-26 21:34:04,116 WARNING NaN or Inf found in input tensor.
2022-08-26 21:34:30,036 DEBUG TRAIN Batch 225/1000 loss 40.928329 loss_att 23.272552 loss_ctc 82.125137 loss_ctc_origin 45.335236 loss_ctc0 167.968231 lr 0.00055884 rank 0
2022-08-26 21:34:57,065 DEBUG TRAIN Batch 225/1100 loss 50.502701 loss_att 28.906614 loss_ctc 100.893570 loss_ctc_origin 54.116074 loss_ctc0 210.041046 lr 0.00055882 rank 0
2022-08-26 21:35:24,458 DEBUG TRAIN Batch 225/1200 loss 18.520176 loss_att 9.877464 loss_ctc 38.686501 loss_ctc_origin 26.957413 loss_ctc0 66.054367 lr 0.00055880 rank 0
2022-08-26 21:35:53,631 DEBUG TRAIN Batch 225/1300 loss 17.549751 loss_att 6.396754 loss_ctc 43.573406 loss_ctc_origin 29.206020 loss_ctc0 77.097305 lr 0.00055878 rank 0
2022-08-26 21:36:21,477 DEBUG TRAIN Batch 225/1400 loss 17.880594 loss_att 6.762090 loss_ctc 43.823769 loss_ctc_origin 25.063711 loss_ctc0 87.597229 lr 0.00055875 rank 0
2022-08-26 21:36:54,867 DEBUG TRAIN Batch 225/1500 loss 49.504204 loss_att 35.675533 loss_ctc 81.771088 loss_ctc_origin 56.781872 loss_ctc0 140.079254 lr 0.00055873 rank 0
2022-08-26 21:37:22,932 DEBUG TRAIN Batch 225/1600 loss 49.267731 loss_att 25.869057 loss_ctc 103.864632 loss_ctc_origin 57.689369 loss_ctc0 211.606903 lr 0.00055871 rank 0
2022-08-26 21:37:50,117 DEBUG TRAIN Batch 225/1700 loss 18.969179 loss_att 8.536104 loss_ctc 43.313019 loss_ctc_origin 31.961370 loss_ctc0 69.800201 lr 0.00055869 rank 0
2022-08-26 21:38:17,677 DEBUG TRAIN Batch 225/1800 loss 19.092674 loss_att 8.529282 loss_ctc 43.740593 loss_ctc_origin 28.677603 loss_ctc0 78.887566 lr 0.00055867 rank 0
2022-08-26 21:38:40,793 WARNING NaN or Inf found in input tensor.
2022-08-26 21:38:45,101 DEBUG TRAIN Batch 225/1900 loss 18.697401 loss_att 6.339745 loss_ctc 47.531929 loss_ctc_origin 29.183237 loss_ctc0 90.345535 lr 0.00055865 rank 0
2022-08-26 21:39:13,475 DEBUG TRAIN Batch 225/2000 loss 36.912437 loss_att 22.545780 loss_ctc 70.434639 loss_ctc_origin 43.394943 loss_ctc0 133.527267 lr 0.00055862 rank 0
2022-08-26 21:39:41,410 DEBUG TRAIN Batch 225/2100 loss 51.961308 loss_att 30.465580 loss_ctc 102.118004 loss_ctc_origin 58.583786 loss_ctc0 203.697845 lr 0.00055860 rank 0
2022-08-26 21:40:08,057 DEBUG TRAIN Batch 225/2200 loss 18.977987 loss_att 10.185245 loss_ctc 39.494385 loss_ctc_origin 29.115498 loss_ctc0 63.711796 lr 0.00055858 rank 0
2022-08-26 21:40:35,759 DEBUG TRAIN Batch 225/2300 loss 19.878613 loss_att 7.990443 loss_ctc 47.617676 loss_ctc_origin 33.639740 loss_ctc0 80.232849 lr 0.00055856 rank 0
2022-08-26 21:41:04,167 DEBUG TRAIN Batch 225/2400 loss 23.376789 loss_att 8.761033 loss_ctc 57.480221 loss_ctc_origin 40.876331 loss_ctc0 96.222626 lr 0.00055854 rank 0
2022-08-26 21:41:32,448 DEBUG TRAIN Batch 225/2500 loss 41.646790 loss_att 26.249901 loss_ctc 77.572868 loss_ctc_origin 47.006462 loss_ctc0 148.894485 lr 0.00055851 rank 0
2022-08-26 21:41:59,361 DEBUG TRAIN Batch 225/2600 loss 53.303780 loss_att 30.982162 loss_ctc 105.387558 loss_ctc_origin 62.244690 loss_ctc0 206.054260 lr 0.00055849 rank 0
2022-08-26 21:42:27,188 DEBUG TRAIN Batch 225/2700 loss 17.891880 loss_att 9.071126 loss_ctc 38.473640 loss_ctc_origin 27.563902 loss_ctc0 63.929703 lr 0.00055847 rank 0
2022-08-26 21:42:54,973 DEBUG TRAIN Batch 225/2800 loss 20.237240 loss_att 9.562520 loss_ctc 45.144920 loss_ctc_origin 31.769312 loss_ctc0 76.354675 lr 0.00055845 rank 0
2022-08-26 21:43:22,128 DEBUG TRAIN Batch 225/2900 loss 24.337358 loss_att 10.002407 loss_ctc 57.785576 loss_ctc_origin 41.539227 loss_ctc0 95.693726 lr 0.00055843 rank 0
2022-08-26 21:43:54,774 DEBUG TRAIN Batch 225/3000 loss 40.494041 loss_att 24.443550 loss_ctc 77.945190 loss_ctc_origin 47.921326 loss_ctc0 148.000885 lr 0.00055841 rank 0
2022-08-26 21:44:23,009 DEBUG TRAIN Batch 225/3100 loss 45.949371 loss_att 24.330551 loss_ctc 96.393280 loss_ctc_origin 50.371902 loss_ctc0 203.776489 lr 0.00055838 rank 0
2022-08-26 21:44:50,476 DEBUG TRAIN Batch 225/3200 loss 16.393776 loss_att 7.518751 loss_ctc 37.102165 loss_ctc_origin 25.327126 loss_ctc0 64.577255 lr 0.00055836 rank 0
2022-08-26 21:45:18,037 DEBUG TRAIN Batch 225/3300 loss 21.449766 loss_att 8.621550 loss_ctc 51.382271 loss_ctc_origin 36.698860 loss_ctc0 85.643570 lr 0.00055834 rank 0
2022-08-26 21:45:40,984 WARNING NaN or Inf found in input tensor.
2022-08-26 21:45:45,289 DEBUG TRAIN Batch 225/3400 loss 21.755791 loss_att 9.274982 loss_ctc 50.877678 loss_ctc_origin 33.277523 loss_ctc0 91.944710 lr 0.00055832 rank 0
2022-08-26 21:46:13,108 DEBUG TRAIN Batch 225/3500 loss 38.506378 loss_att 24.682440 loss_ctc 70.762238 loss_ctc_origin 41.837894 loss_ctc0 138.252380 lr 0.00055830 rank 0
2022-08-26 21:46:40,539 DEBUG TRAIN Batch 225/3600 loss 54.040173 loss_att 33.836636 loss_ctc 101.181755 loss_ctc_origin 67.597137 loss_ctc0 179.545853 lr 0.00055828 rank 0
2022-08-26 21:47:06,193 WARNING NaN or Inf found in input tensor.
2022-08-26 21:47:07,720 DEBUG TRAIN Batch 225/3700 loss 20.395908 loss_att 10.067472 loss_ctc 44.495590 loss_ctc_origin 31.984516 loss_ctc0 73.688095 lr 0.00055825 rank 0
2022-08-26 21:47:35,170 DEBUG TRAIN Batch 225/3800 loss 17.161505 loss_att 7.094188 loss_ctc 40.651909 loss_ctc_origin 26.152237 loss_ctc0 74.484474 lr 0.00055823 rank 0
2022-08-26 21:48:03,250 DEBUG TRAIN Batch 225/3900 loss 21.371632 loss_att 7.701458 loss_ctc 53.268703 loss_ctc_origin 33.999908 loss_ctc0 98.229218 lr 0.00055821 rank 0
2022-08-26 21:48:31,199 DEBUG TRAIN Batch 225/4000 loss 46.611553 loss_att 30.928329 loss_ctc 83.205742 loss_ctc_origin 56.696133 loss_ctc0 145.061493 lr 0.00055819 rank 0
2022-08-26 21:48:45,236 WARNING NaN or Inf found in input tensor.
2022-08-26 21:48:59,285 DEBUG TRAIN Batch 225/4100 loss 48.898994 loss_att 28.923023 loss_ctc 95.509598 loss_ctc_origin 55.348091 loss_ctc0 189.219757 lr 0.00055817 rank 0
2022-08-26 21:49:26,752 DEBUG TRAIN Batch 225/4200 loss 20.079554 loss_att 8.315283 loss_ctc 47.529518 loss_ctc_origin 35.718544 loss_ctc0 75.088455 lr 0.00055814 rank 0
2022-08-26 21:49:54,199 DEBUG TRAIN Batch 225/4300 loss 18.241117 loss_att 8.878061 loss_ctc 40.088249 loss_ctc_origin 26.759907 loss_ctc0 71.187721 lr 0.00055812 rank 0
2022-08-26 21:50:23,162 DEBUG TRAIN Batch 225/4400 loss 21.762108 loss_att 8.071980 loss_ctc 53.705738 loss_ctc_origin 31.682165 loss_ctc0 105.094070 lr 0.00055810 rank 0
2022-08-26 21:50:54,695 DEBUG TRAIN Batch 225/4500 loss 44.903976 loss_att 27.917799 loss_ctc 84.538391 loss_ctc_origin 55.699692 loss_ctc0 151.828674 lr 0.00055808 rank 0
2022-08-26 21:51:02,731 WARNING NaN or Inf found in input tensor.
2022-08-26 21:51:22,213 DEBUG TRAIN Batch 225/4600 loss 49.750645 loss_att 27.360359 loss_ctc 101.994644 loss_ctc_origin 58.708389 loss_ctc0 202.995911 lr 0.00055806 rank 0
2022-08-26 21:51:49,440 DEBUG TRAIN Batch 225/4700 loss 20.674660 loss_att 11.717405 loss_ctc 41.574917 loss_ctc_origin 29.644394 loss_ctc0 69.412804 lr 0.00055804 rank 0
2022-08-26 21:52:17,101 DEBUG TRAIN Batch 225/4800 loss 15.369108 loss_att 5.817848 loss_ctc 37.655380 loss_ctc_origin 19.101952 loss_ctc0 80.946716 lr 0.00055801 rank 0
2022-08-26 21:52:44,384 DEBUG TRAIN Batch 225/4900 loss 19.387203 loss_att 7.876545 loss_ctc 46.245407 loss_ctc_origin 29.040787 loss_ctc0 86.389511 lr 0.00055799 rank 0
2022-08-26 21:53:12,775 DEBUG TRAIN Batch 225/5000 loss 50.003681 loss_att 33.883041 loss_ctc 87.618507 loss_ctc_origin 61.489914 loss_ctc0 148.585220 lr 0.00055797 rank 0
2022-08-26 21:53:40,322 DEBUG TRAIN Batch 225/5100 loss 57.350800 loss_att 36.548431 loss_ctc 105.889648 loss_ctc_origin 67.487564 loss_ctc0 195.494522 lr 0.00055795 rank 0
2022-08-26 21:54:08,418 DEBUG TRAIN Batch 225/5200 loss 19.107363 loss_att 9.517207 loss_ctc 41.484390 loss_ctc_origin 29.123493 loss_ctc0 70.326477 lr 0.00055793 rank 0
2022-08-26 21:54:34,470 DEBUG TRAIN Batch 225/5300 loss 16.613838 loss_att 6.328713 loss_ctc 40.612461 loss_ctc_origin 27.021286 loss_ctc0 72.325203 lr 0.00055791 rank 0
2022-08-26 21:55:01,576 DEBUG TRAIN Batch 225/5400 loss 19.483799 loss_att 7.163980 loss_ctc 48.230045 loss_ctc_origin 28.003992 loss_ctc0 95.424164 lr 0.00055788 rank 0
2022-08-26 21:55:30,429 DEBUG TRAIN Batch 225/5500 loss 46.210121 loss_att 28.609013 loss_ctc 87.279373 loss_ctc_origin 55.744717 loss_ctc0 160.860245 lr 0.00055786 rank 0
2022-08-26 21:55:57,891 DEBUG TRAIN Batch 225/5600 loss 48.800865 loss_att 26.914486 loss_ctc 99.869080 loss_ctc_origin 56.182816 loss_ctc0 201.803680 lr 0.00055784 rank 0
2022-08-26 21:56:20,585 DEBUG CV Batch 225/0 loss 12.152822 loss_att 9.581654 loss_ctc 18.152216 loss_ctc_origin 11.604137 loss_ctc0 33.431065 history loss 11.437951 rank 0
2022-08-26 21:56:31,151 DEBUG CV Batch 225/100 loss 20.076862 loss_att 15.994707 loss_ctc 29.601891 loss_ctc_origin 19.472363 loss_ctc0 53.237453 history loss 25.776175 rank 0
2022-08-26 21:56:40,915 DEBUG CV Batch 225/200 loss 25.011509 loss_att 19.712330 loss_ctc 37.376255 loss_ctc_origin 26.614408 loss_ctc0 62.487228 history loss 27.230465 rank 0
2022-08-26 21:56:50,876 DEBUG CV Batch 225/300 loss 22.696606 loss_att 17.376850 loss_ctc 35.109367 loss_ctc_origin 19.776464 loss_ctc0 70.886139 history loss 26.300132 rank 0
2022-08-26 21:57:01,164 DEBUG CV Batch 225/400 loss 35.884338 loss_att 28.519121 loss_ctc 53.069847 loss_ctc_origin 35.823570 loss_ctc0 93.311165 history loss 24.626028 rank 0
2022-08-26 21:57:11,590 DEBUG CV Batch 225/500 loss 16.557793 loss_att 12.161180 loss_ctc 26.816559 loss_ctc_origin 20.473774 loss_ctc0 41.616394 history loss 24.293625 rank 0
2022-08-26 21:57:22,209 DEBUG CV Batch 225/600 loss 17.143169 loss_att 12.254908 loss_ctc 28.549118 loss_ctc_origin 18.012581 loss_ctc0 53.134373 history loss 24.147230 rank 0
2022-08-26 21:57:32,259 DEBUG CV Batch 225/700 loss 18.355906 loss_att 12.916310 loss_ctc 31.048294 loss_ctc_origin 17.226603 loss_ctc0 63.298912 history loss 23.822296 rank 0
2022-08-26 21:57:42,615 DEBUG CV Batch 225/800 loss 21.416943 loss_att 16.397148 loss_ctc 33.129795 loss_ctc_origin 17.903988 loss_ctc0 68.656677 history loss 23.780333 rank 0
2022-08-26 21:57:53,053 INFO Epoch 225 CV info cv_loss 23.8921304919627
2022-08-26 21:57:53,053 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/225.pt
2022-08-26 21:57:53,507 INFO Epoch 226 TRAIN info lr 0.0005578224415576527
2022-08-26 21:57:53,511 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 21:58:19,267 DEBUG TRAIN Batch 226/0 loss 38.654873 loss_att 23.502136 loss_ctc 74.011261 loss_ctc_origin 47.320045 loss_ctc0 136.290771 lr 0.00055782 rank 0
2022-08-26 21:58:47,083 DEBUG TRAIN Batch 226/100 loss 51.301819 loss_att 29.608662 loss_ctc 101.919189 loss_ctc_origin 58.250843 loss_ctc0 203.811981 lr 0.00055780 rank 0
2022-08-26 21:59:14,385 DEBUG TRAIN Batch 226/200 loss 15.168407 loss_att 6.360438 loss_ctc 35.720337 loss_ctc_origin 24.020584 loss_ctc0 63.019764 lr 0.00055778 rank 0
2022-08-26 21:59:41,741 DEBUG TRAIN Batch 226/300 loss 17.938166 loss_att 7.255567 loss_ctc 42.864227 loss_ctc_origin 28.359236 loss_ctc0 76.709213 lr 0.00055776 rank 0
2022-08-26 22:00:08,651 DEBUG TRAIN Batch 226/400 loss 19.793320 loss_att 7.600467 loss_ctc 48.243309 loss_ctc_origin 30.059612 loss_ctc0 90.671921 lr 0.00055773 rank 0
2022-08-26 22:00:35,069 DEBUG TRAIN Batch 226/500 loss 42.577370 loss_att 26.768917 loss_ctc 79.463768 loss_ctc_origin 51.370899 loss_ctc0 145.013794 lr 0.00055771 rank 0
2022-08-26 22:00:42,191 WARNING NaN or Inf found in input tensor.
2022-08-26 22:01:02,000 DEBUG TRAIN Batch 226/600 loss 53.181839 loss_att 30.005795 loss_ctc 107.259277 loss_ctc_origin 69.351349 loss_ctc0 195.711105 lr 0.00055769 rank 0
2022-08-26 22:01:29,161 DEBUG TRAIN Batch 226/700 loss 14.727501 loss_att 6.756821 loss_ctc 33.325752 loss_ctc_origin 20.937828 loss_ctc0 62.230911 lr 0.00055767 rank 0
2022-08-26 22:01:56,043 DEBUG TRAIN Batch 226/800 loss 19.216824 loss_att 7.516879 loss_ctc 46.516693 loss_ctc_origin 32.833759 loss_ctc0 78.443535 lr 0.00055765 rank 0
2022-08-26 22:02:23,979 DEBUG TRAIN Batch 226/900 loss 23.182943 loss_att 8.917890 loss_ctc 56.468067 loss_ctc_origin 37.967159 loss_ctc0 99.636848 lr 0.00055763 rank 0
2022-08-26 22:02:51,998 DEBUG TRAIN Batch 226/1000 loss 48.210266 loss_att 29.713440 loss_ctc 91.369522 loss_ctc_origin 59.177406 loss_ctc0 166.484467 lr 0.00055760 rank 0
2022-08-26 22:03:19,344 DEBUG TRAIN Batch 226/1100 loss 57.279190 loss_att 33.085072 loss_ctc 113.732124 loss_ctc_origin 66.759773 loss_ctc0 223.334274 lr 0.00055758 rank 0
2022-08-26 22:03:46,512 DEBUG TRAIN Batch 226/1200 loss 17.333673 loss_att 8.176461 loss_ctc 38.700500 loss_ctc_origin 26.910677 loss_ctc0 66.210098 lr 0.00055756 rank 0
2022-08-26 22:03:58,019 WARNING NaN or Inf found in input tensor.
2022-08-26 22:04:14,283 DEBUG TRAIN Batch 226/1300 loss 15.409128 loss_att 5.549723 loss_ctc 38.414406 loss_ctc_origin 22.687321 loss_ctc0 75.110931 lr 0.00055754 rank 0
2022-08-26 22:04:41,896 DEBUG TRAIN Batch 226/1400 loss 22.859840 loss_att 9.250857 loss_ctc 54.614128 loss_ctc_origin 35.609848 loss_ctc0 98.957451 lr 0.00055752 rank 0
2022-08-26 22:05:15,938 DEBUG TRAIN Batch 226/1500 loss 45.544071 loss_att 28.574623 loss_ctc 85.139450 loss_ctc_origin 53.879128 loss_ctc0 158.080215 lr 0.00055750 rank 0
2022-08-26 22:05:43,965 DEBUG TRAIN Batch 226/1600 loss 46.992825 loss_att 27.052872 loss_ctc 93.519379 loss_ctc_origin 53.227898 loss_ctc0 187.532822 lr 0.00055747 rank 0
2022-08-26 22:06:11,447 DEBUG TRAIN Batch 226/1700 loss 19.438528 loss_att 10.306365 loss_ctc 40.746906 loss_ctc_origin 32.050438 loss_ctc0 61.038666 lr 0.00055745 rank 0
2022-08-26 22:06:39,542 DEBUG TRAIN Batch 226/1800 loss 19.892256 loss_att 8.107897 loss_ctc 47.389091 loss_ctc_origin 32.438534 loss_ctc0 82.273727 lr 0.00055743 rank 0
2022-08-26 22:07:07,638 DEBUG TRAIN Batch 226/1900 loss 22.399773 loss_att 9.104218 loss_ctc 53.422737 loss_ctc_origin 35.909637 loss_ctc0 94.286629 lr 0.00055741 rank 0
2022-08-26 22:07:35,699 DEBUG TRAIN Batch 226/2000 loss 46.378811 loss_att 30.281862 loss_ctc 83.938354 loss_ctc_origin 53.291809 loss_ctc0 155.446945 lr 0.00055739 rank 0
2022-08-26 22:08:03,160 DEBUG TRAIN Batch 226/2100 loss 45.536236 loss_att 24.837019 loss_ctc 93.834404 loss_ctc_origin 47.856258 loss_ctc0 201.116730 lr 0.00055737 rank 0
2022-08-26 22:08:30,826 DEBUG TRAIN Batch 226/2200 loss 18.195932 loss_att 8.388643 loss_ctc 41.079605 loss_ctc_origin 29.398735 loss_ctc0 68.334961 lr 0.00055734 rank 0
2022-08-26 22:08:57,234 DEBUG TRAIN Batch 226/2300 loss 16.433907 loss_att 6.371419 loss_ctc 39.913040 loss_ctc_origin 26.502689 loss_ctc0 71.203850 lr 0.00055732 rank 0
2022-08-26 22:09:23,530 DEBUG TRAIN Batch 226/2400 loss 19.991898 loss_att 7.892991 loss_ctc 48.222679 loss_ctc_origin 30.114334 loss_ctc0 90.475479 lr 0.00055730 rank 0
2022-08-26 22:09:51,851 DEBUG TRAIN Batch 226/2500 loss 44.963043 loss_att 31.232254 loss_ctc 77.001549 loss_ctc_origin 52.577900 loss_ctc0 133.990051 lr 0.00055728 rank 0
2022-08-26 22:10:18,510 DEBUG TRAIN Batch 226/2600 loss 46.806679 loss_att 26.383188 loss_ctc 94.461479 loss_ctc_origin 53.929276 loss_ctc0 189.036621 lr 0.00055726 rank 0
2022-08-26 22:10:45,477 DEBUG TRAIN Batch 226/2700 loss 19.618927 loss_att 10.516673 loss_ctc 40.857521 loss_ctc_origin 28.094934 loss_ctc0 70.636894 lr 0.00055724 rank 0
2022-08-26 22:11:12,625 DEBUG TRAIN Batch 226/2800 loss 22.891764 loss_att 10.520432 loss_ctc 51.758202 loss_ctc_origin 38.421104 loss_ctc0 82.878082 lr 0.00055722 rank 0
2022-08-26 22:11:40,263 DEBUG TRAIN Batch 226/2900 loss 21.255743 loss_att 9.371727 loss_ctc 48.985111 loss_ctc_origin 32.149006 loss_ctc0 88.269356 lr 0.00055719 rank 0
2022-08-26 22:12:14,841 DEBUG TRAIN Batch 226/3000 loss 53.956581 loss_att 36.871964 loss_ctc 93.820694 loss_ctc_origin 70.982956 loss_ctc0 147.108734 lr 0.00055717 rank 0
2022-08-26 22:12:42,325 DEBUG TRAIN Batch 226/3100 loss 47.736824 loss_att 27.515539 loss_ctc 94.919823 loss_ctc_origin 54.500763 loss_ctc0 189.230957 lr 0.00055715 rank 0
2022-08-26 22:13:09,614 DEBUG TRAIN Batch 226/3200 loss 21.196144 loss_att 11.563637 loss_ctc 43.671989 loss_ctc_origin 33.603889 loss_ctc0 67.164230 lr 0.00055713 rank 0
2022-08-26 22:13:36,390 DEBUG TRAIN Batch 226/3300 loss 16.546556 loss_att 6.950166 loss_ctc 38.938133 loss_ctc_origin 22.946404 loss_ctc0 76.252167 lr 0.00055711 rank 0
2022-08-26 22:14:00,070 WARNING NaN or Inf found in input tensor.
2022-08-26 22:14:04,522 DEBUG TRAIN Batch 226/3400 loss 24.127319 loss_att 9.696060 loss_ctc 57.800259 loss_ctc_origin 40.351467 loss_ctc0 98.514099 lr 0.00055709 rank 0
2022-08-26 22:14:32,355 DEBUG TRAIN Batch 226/3500 loss 41.192841 loss_att 28.187691 loss_ctc 71.538193 loss_ctc_origin 48.459034 loss_ctc0 125.389557 lr 0.00055706 rank 0
2022-08-26 22:14:59,931 DEBUG TRAIN Batch 226/3600 loss 46.449993 loss_att 23.295166 loss_ctc 100.477921 loss_ctc_origin 58.064957 loss_ctc0 199.441513 lr 0.00055704 rank 0
2022-08-26 22:15:27,308 DEBUG TRAIN Batch 226/3700 loss 22.002899 loss_att 11.779654 loss_ctc 45.857140 loss_ctc_origin 35.570953 loss_ctc0 69.858246 lr 0.00055702 rank 0
2022-08-26 22:15:55,088 DEBUG TRAIN Batch 226/3800 loss 20.126331 loss_att 9.656773 loss_ctc 44.555298 loss_ctc_origin 31.946901 loss_ctc0 73.974892 lr 0.00055700 rank 0
2022-08-26 22:16:22,746 DEBUG TRAIN Batch 226/3900 loss 21.542439 loss_att 8.099835 loss_ctc 52.908508 loss_ctc_origin 35.836494 loss_ctc0 92.743195 lr 0.00055698 rank 0
2022-08-26 22:16:50,773 DEBUG TRAIN Batch 226/4000 loss 45.773056 loss_att 28.448208 loss_ctc 86.197701 loss_ctc_origin 57.991142 loss_ctc0 152.013000 lr 0.00055696 rank 0
2022-08-26 22:17:12,121 WARNING NaN or Inf found in input tensor.
2022-08-26 22:17:18,879 DEBUG TRAIN Batch 226/4100 loss 52.005852 loss_att 28.533590 loss_ctc 106.774467 loss_ctc_origin 63.950005 loss_ctc0 206.698212 lr 0.00055693 rank 0
2022-08-26 22:17:44,511 WARNING NaN or Inf found in input tensor.
2022-08-26 22:17:46,018 DEBUG TRAIN Batch 226/4200 loss 21.370480 loss_att 12.249052 loss_ctc 42.653809 loss_ctc_origin 31.964619 loss_ctc0 67.595245 lr 0.00055691 rank 0
2022-08-26 22:18:13,880 DEBUG TRAIN Batch 226/4300 loss 20.586128 loss_att 8.588766 loss_ctc 48.579975 loss_ctc_origin 33.355518 loss_ctc0 84.103706 lr 0.00055689 rank 0
2022-08-26 22:18:41,005 DEBUG TRAIN Batch 226/4400 loss 18.992109 loss_att 7.719998 loss_ctc 45.293701 loss_ctc_origin 28.919983 loss_ctc0 83.499031 lr 0.00055687 rank 0
2022-08-26 22:19:15,660 DEBUG TRAIN Batch 226/4500 loss 53.364235 loss_att 35.306473 loss_ctc 95.499008 loss_ctc_origin 68.967117 loss_ctc0 157.406769 lr 0.00055685 rank 0
2022-08-26 22:19:42,969 DEBUG TRAIN Batch 226/4600 loss 54.114563 loss_att 33.268791 loss_ctc 102.754700 loss_ctc_origin 59.959324 loss_ctc0 202.610580 lr 0.00055683 rank 0
2022-08-26 22:20:10,511 DEBUG TRAIN Batch 226/4700 loss 17.738979 loss_att 9.823654 loss_ctc 36.208069 loss_ctc_origin 24.912876 loss_ctc0 62.563526 lr 0.00055680 rank 0
2022-08-26 22:20:37,727 DEBUG TRAIN Batch 226/4800 loss 21.422201 loss_att 9.719368 loss_ctc 48.728809 loss_ctc_origin 33.802700 loss_ctc0 83.556396 lr 0.00055678 rank 0
2022-08-26 22:21:05,082 DEBUG TRAIN Batch 226/4900 loss 27.804741 loss_att 12.035617 loss_ctc 64.599358 loss_ctc_origin 46.503494 loss_ctc0 106.823044 lr 0.00055676 rank 0
2022-08-26 22:21:33,789 DEBUG TRAIN Batch 226/5000 loss 41.879097 loss_att 23.187208 loss_ctc 85.493500 loss_ctc_origin 49.107006 loss_ctc0 170.395325 lr 0.00055674 rank 0
2022-08-26 22:22:01,130 DEBUG TRAIN Batch 226/5100 loss 51.901909 loss_att 28.375877 loss_ctc 106.795982 loss_ctc_origin 65.676300 loss_ctc0 202.741913 lr 0.00055672 rank 0
2022-08-26 22:22:29,069 DEBUG TRAIN Batch 226/5200 loss 19.993412 loss_att 9.428843 loss_ctc 44.644073 loss_ctc_origin 34.983311 loss_ctc0 67.185852 lr 0.00055670 rank 0
2022-08-26 22:22:56,387 DEBUG TRAIN Batch 226/5300 loss 19.759262 loss_att 8.776161 loss_ctc 45.386494 loss_ctc_origin 29.914246 loss_ctc0 81.488403 lr 0.00055668 rank 0
2022-08-26 22:23:24,935 DEBUG TRAIN Batch 226/5400 loss 19.428457 loss_att 7.670572 loss_ctc 46.863518 loss_ctc_origin 28.659447 loss_ctc0 89.339684 lr 0.00055665 rank 0
2022-08-26 22:23:52,388 DEBUG TRAIN Batch 226/5500 loss 49.577286 loss_att 33.300461 loss_ctc 87.556541 loss_ctc_origin 53.878624 loss_ctc0 166.138351 lr 0.00055663 rank 0
2022-08-26 22:24:19,478 DEBUG TRAIN Batch 226/5600 loss 54.228447 loss_att 31.952564 loss_ctc 106.205513 loss_ctc_origin 65.139801 loss_ctc0 202.025513 lr 0.00055661 rank 0
2022-08-26 22:24:41,580 DEBUG CV Batch 226/0 loss 12.212754 loss_att 9.010578 loss_ctc 19.684498 loss_ctc_origin 12.990993 loss_ctc0 35.302673 history loss 11.494357 rank 0
2022-08-26 22:24:52,059 DEBUG CV Batch 226/100 loss 21.751656 loss_att 17.406986 loss_ctc 31.889217 loss_ctc_origin 22.313324 loss_ctc0 54.232967 history loss 27.847818 rank 0
2022-08-26 22:25:02,229 DEBUG CV Batch 226/200 loss 26.932098 loss_att 21.641312 loss_ctc 39.277267 loss_ctc_origin 29.294445 loss_ctc0 62.570522 history loss 29.230989 rank 0
2022-08-26 22:25:12,534 DEBUG CV Batch 226/300 loss 24.035828 loss_att 18.584736 loss_ctc 36.755047 loss_ctc_origin 21.373905 loss_ctc0 72.644379 history loss 28.309891 rank 0
2022-08-26 22:25:21,845 DEBUG CV Batch 226/400 loss 38.452858 loss_att 30.652241 loss_ctc 56.654297 loss_ctc_origin 40.088829 loss_ctc0 95.307045 history loss 26.437599 rank 0
2022-08-26 22:25:32,521 DEBUG CV Batch 226/500 loss 17.455170 loss_att 12.841697 loss_ctc 28.219940 loss_ctc_origin 21.973286 loss_ctc0 42.795464 history loss 26.097330 rank 0
2022-08-26 22:25:42,798 DEBUG CV Batch 226/600 loss 18.041977 loss_att 12.706086 loss_ctc 30.492386 loss_ctc_origin 19.834637 loss_ctc0 55.360458 history loss 25.988868 rank 0
2022-08-26 22:25:52,909 DEBUG CV Batch 226/700 loss 20.165066 loss_att 14.453206 loss_ctc 33.492741 loss_ctc_origin 20.400883 loss_ctc0 64.040405 history loss 25.610469 rank 0
2022-08-26 22:26:02,862 DEBUG CV Batch 226/800 loss 22.932449 loss_att 18.080559 loss_ctc 34.253529 loss_ctc_origin 19.160316 loss_ctc0 69.471024 history loss 25.563049 rank 0
2022-08-26 22:26:12,795 INFO Epoch 226 CV info cv_loss 25.627716800393884
2022-08-26 22:26:12,795 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/226.pt
2022-08-26 22:26:13,267 INFO Epoch 227 TRAIN info lr 0.0005565924016008975
2022-08-26 22:26:13,270 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 22:26:39,485 DEBUG TRAIN Batch 227/0 loss 44.709114 loss_att 27.929157 loss_ctc 83.862350 loss_ctc_origin 55.642994 loss_ctc0 149.707520 lr 0.00055659 rank 0
2022-08-26 22:27:06,952 DEBUG TRAIN Batch 227/100 loss 48.593292 loss_att 28.540958 loss_ctc 95.382065 loss_ctc_origin 55.880436 loss_ctc0 187.552521 lr 0.00055657 rank 0
2022-08-26 22:27:18,592 WARNING NaN or Inf found in input tensor.
2022-08-26 22:27:34,213 DEBUG TRAIN Batch 227/200 loss 18.101780 loss_att 9.973276 loss_ctc 37.068291 loss_ctc_origin 23.820408 loss_ctc0 67.980011 lr 0.00055655 rank 0
2022-08-26 22:28:02,532 DEBUG TRAIN Batch 227/300 loss 23.186874 loss_att 8.857188 loss_ctc 56.622810 loss_ctc_origin 42.130844 loss_ctc0 90.437401 lr 0.00055653 rank 0
2022-08-26 22:28:30,823 DEBUG TRAIN Batch 227/400 loss 21.688284 loss_att 9.981506 loss_ctc 49.004097 loss_ctc_origin 30.763283 loss_ctc0 91.566002 lr 0.00055651 rank 0
2022-08-26 22:28:58,707 DEBUG TRAIN Batch 227/500 loss 50.236916 loss_att 33.151051 loss_ctc 90.103943 loss_ctc_origin 62.247284 loss_ctc0 155.102829 lr 0.00055648 rank 0
2022-08-26 22:28:59,354 WARNING NaN or Inf found in input tensor.
2022-08-26 22:29:26,051 DEBUG TRAIN Batch 227/600 loss 52.572021 loss_att 29.042553 loss_ctc 107.474106 loss_ctc_origin 65.386566 loss_ctc0 205.678345 lr 0.00055646 rank 0
2022-08-26 22:29:51,856 WARNING NaN or Inf found in input tensor.
2022-08-26 22:29:53,337 DEBUG TRAIN Batch 227/700 loss 16.636065 loss_att 7.266872 loss_ctc 38.497513 loss_ctc_origin 26.385786 loss_ctc0 66.758209 lr 0.00055644 rank 0
2022-08-26 22:30:21,563 DEBUG TRAIN Batch 227/800 loss 15.013461 loss_att 5.857255 loss_ctc 36.377941 loss_ctc_origin 22.302828 loss_ctc0 69.219864 lr 0.00055642 rank 0
2022-08-26 22:30:51,538 DEBUG TRAIN Batch 227/900 loss 22.003210 loss_att 9.127514 loss_ctc 52.046497 loss_ctc_origin 33.059769 loss_ctc0 96.348862 lr 0.00055640 rank 0
2022-08-26 22:31:18,132 DEBUG TRAIN Batch 227/1000 loss 40.457752 loss_att 25.515610 loss_ctc 75.322754 loss_ctc_origin 47.344948 loss_ctc0 140.604279 lr 0.00055638 rank 0
2022-08-26 22:31:45,822 DEBUG TRAIN Batch 227/1100 loss 52.450638 loss_att 30.528372 loss_ctc 103.602585 loss_ctc_origin 68.057137 loss_ctc0 186.541962 lr 0.00055635 rank 0
2022-08-26 22:32:13,482 DEBUG TRAIN Batch 227/1200 loss 21.624634 loss_att 12.884998 loss_ctc 42.017113 loss_ctc_origin 30.891281 loss_ctc0 67.977379 lr 0.00055633 rank 0
2022-08-26 22:32:43,641 DEBUG TRAIN Batch 227/1300 loss 20.482235 loss_att 8.071654 loss_ctc 49.440254 loss_ctc_origin 34.398453 loss_ctc0 84.537781 lr 0.00055631 rank 0
2022-08-26 22:33:10,436 DEBUG TRAIN Batch 227/1400 loss 20.336731 loss_att 7.876982 loss_ctc 49.409477 loss_ctc_origin 32.306210 loss_ctc0 89.317101 lr 0.00055629 rank 0
2022-08-26 22:33:44,231 DEBUG TRAIN Batch 227/1500 loss 46.160889 loss_att 31.122971 loss_ctc 81.249359 loss_ctc_origin 53.043098 loss_ctc0 147.063965 lr 0.00055627 rank 0
2022-08-26 22:33:51,785 WARNING NaN or Inf found in input tensor.
2022-08-26 22:34:12,163 DEBUG TRAIN Batch 227/1600 loss 50.989647 loss_att 28.224422 loss_ctc 104.108505 loss_ctc_origin 61.896965 loss_ctc0 202.602081 lr 0.00055625 rank 0
2022-08-26 22:34:38,927 DEBUG TRAIN Batch 227/1700 loss 17.302706 loss_att 9.028370 loss_ctc 36.609489 loss_ctc_origin 25.828362 loss_ctc0 61.765453 lr 0.00055623 rank 0
2022-08-26 22:34:44,855 WARNING NaN or Inf found in input tensor.
2022-08-26 22:35:07,070 DEBUG TRAIN Batch 227/1800 loss 19.848232 loss_att 7.540911 loss_ctc 48.565315 loss_ctc_origin 34.583397 loss_ctc0 81.189781 lr 0.00055620 rank 0
2022-08-26 22:35:34,124 DEBUG TRAIN Batch 227/1900 loss 17.532095 loss_att 6.180895 loss_ctc 44.018227 loss_ctc_origin 25.613503 loss_ctc0 86.962585 lr 0.00055618 rank 0
2022-08-26 22:35:36,771 WARNING NaN or Inf found in input tensor.
2022-08-26 22:36:02,510 DEBUG TRAIN Batch 227/2000 loss 42.713696 loss_att 27.313915 loss_ctc 78.646515 loss_ctc_origin 49.580441 loss_ctc0 146.467346 lr 0.00055616 rank 0
2022-08-26 22:36:29,782 DEBUG TRAIN Batch 227/2100 loss 50.212044 loss_att 27.136147 loss_ctc 104.055801 loss_ctc_origin 59.254360 loss_ctc0 208.592514 lr 0.00055614 rank 0
2022-08-26 22:36:56,665 DEBUG TRAIN Batch 227/2200 loss 21.213657 loss_att 9.869587 loss_ctc 47.683151 loss_ctc_origin 37.027145 loss_ctc0 72.547165 lr 0.00055612 rank 0
2022-08-26 22:37:24,376 DEBUG TRAIN Batch 227/2300 loss 13.753351 loss_att 5.614867 loss_ctc 32.743149 loss_ctc_origin 17.958176 loss_ctc0 67.241425 lr 0.00055610 rank 0
2022-08-26 22:37:52,355 DEBUG TRAIN Batch 227/2400 loss 21.822105 loss_att 8.737875 loss_ctc 52.351974 loss_ctc_origin 33.670525 loss_ctc0 95.942017 lr 0.00055607 rank 0
2022-08-26 22:38:21,303 DEBUG TRAIN Batch 227/2500 loss 43.811356 loss_att 27.187775 loss_ctc 82.599701 loss_ctc_origin 49.345436 loss_ctc0 160.192978 lr 0.00055605 rank 0
2022-08-26 22:38:47,272 DEBUG TRAIN Batch 227/2600 loss 50.750786 loss_att 30.096588 loss_ctc 98.943901 loss_ctc_origin 54.988068 loss_ctc0 201.507507 lr 0.00055603 rank 0
2022-08-26 22:39:14,639 DEBUG TRAIN Batch 227/2700 loss 16.202047 loss_att 6.819984 loss_ctc 38.093529 loss_ctc_origin 26.288078 loss_ctc0 65.639572 lr 0.00055601 rank 0
2022-08-26 22:39:41,964 DEBUG TRAIN Batch 227/2800 loss 17.023663 loss_att 7.223037 loss_ctc 39.891785 loss_ctc_origin 25.912785 loss_ctc0 72.509453 lr 0.00055599 rank 0
2022-08-26 22:40:09,546 DEBUG TRAIN Batch 227/2900 loss 18.190042 loss_att 6.428928 loss_ctc 45.632641 loss_ctc_origin 28.136000 loss_ctc0 86.458130 lr 0.00055597 rank 0
2022-08-26 22:40:44,158 DEBUG TRAIN Batch 227/3000 loss 51.654030 loss_att 34.870499 loss_ctc 90.815605 loss_ctc_origin 63.039711 loss_ctc0 155.626022 lr 0.00055595 rank 0
2022-08-26 22:41:11,462 DEBUG TRAIN Batch 227/3100 loss 53.624519 loss_att 31.012003 loss_ctc 106.387047 loss_ctc_origin 63.975143 loss_ctc0 205.348145 lr 0.00055592 rank 0
2022-08-26 22:41:39,086 DEBUG TRAIN Batch 227/3200 loss 21.810461 loss_att 9.638489 loss_ctc 50.211727 loss_ctc_origin 40.200233 loss_ctc0 73.571877 lr 0.00055590 rank 0
2022-08-26 22:42:07,313 DEBUG TRAIN Batch 227/3300 loss 19.472137 loss_att 7.619420 loss_ctc 47.128479 loss_ctc_origin 32.222393 loss_ctc0 81.909348 lr 0.00055588 rank 0
2022-08-26 22:42:33,970 DEBUG TRAIN Batch 227/3400 loss 24.713562 loss_att 10.583568 loss_ctc 57.683548 loss_ctc_origin 39.756023 loss_ctc0 99.514435 lr 0.00055586 rank 0
2022-08-26 22:43:02,359 DEBUG TRAIN Batch 227/3500 loss 49.486000 loss_att 32.855301 loss_ctc 88.290955 loss_ctc_origin 61.012711 loss_ctc0 151.940186 lr 0.00055584 rank 0
2022-08-26 22:43:29,396 DEBUG TRAIN Batch 227/3600 loss 44.751373 loss_att 23.423153 loss_ctc 94.517212 loss_ctc_origin 51.812859 loss_ctc0 194.160706 lr 0.00055582 rank 0
2022-08-26 22:43:55,629 DEBUG TRAIN Batch 227/3700 loss 20.932819 loss_att 12.070652 loss_ctc 41.611206 loss_ctc_origin 30.455338 loss_ctc0 67.641563 lr 0.00055580 rank 0
2022-08-26 22:44:14,352 WARNING NaN or Inf found in input tensor.
2022-08-26 22:44:23,893 DEBUG TRAIN Batch 227/3800 loss 15.740396 loss_att 5.680984 loss_ctc 39.212357 loss_ctc_origin 24.008713 loss_ctc0 74.687531 lr 0.00055577 rank 0
2022-08-26 22:44:52,146 DEBUG TRAIN Batch 227/3900 loss 19.831787 loss_att 7.885118 loss_ctc 47.707344 loss_ctc_origin 28.882698 loss_ctc0 91.631516 lr 0.00055575 rank 0
2022-08-26 22:45:19,669 DEBUG TRAIN Batch 227/4000 loss 43.814957 loss_att 30.856453 loss_ctc 74.051460 loss_ctc_origin 48.388054 loss_ctc0 133.932739 lr 0.00055573 rank 0
2022-08-26 22:45:48,354 DEBUG TRAIN Batch 227/4100 loss 47.814468 loss_att 25.798706 loss_ctc 99.184570 loss_ctc_origin 60.172462 loss_ctc0 190.212814 lr 0.00055571 rank 0
2022-08-26 22:46:17,038 DEBUG TRAIN Batch 227/4200 loss 16.800148 loss_att 7.783510 loss_ctc 37.838966 loss_ctc_origin 24.504629 loss_ctc0 68.952423 lr 0.00055569 rank 0
2022-08-26 22:46:43,534 DEBUG TRAIN Batch 227/4300 loss 17.886049 loss_att 6.951235 loss_ctc 43.400612 loss_ctc_origin 25.345390 loss_ctc0 85.529449 lr 0.00055567 rank 0
2022-08-26 22:47:11,539 DEBUG TRAIN Batch 227/4400 loss 20.273804 loss_att 8.325541 loss_ctc 48.153084 loss_ctc_origin 28.310852 loss_ctc0 94.451630 lr 0.00055565 rank 0
2022-08-26 22:47:45,827 DEBUG TRAIN Batch 227/4500 loss 36.169670 loss_att 23.587086 loss_ctc 65.529030 loss_ctc_origin 44.263229 loss_ctc0 115.149231 lr 0.00055562 rank 0
2022-08-26 22:48:13,606 DEBUG TRAIN Batch 227/4600 loss 60.297173 loss_att 34.021049 loss_ctc 121.608116 loss_ctc_origin 69.388039 loss_ctc0 243.454956 lr 0.00055560 rank 0
2022-08-26 22:48:40,506 DEBUG TRAIN Batch 227/4700 loss 18.452240 loss_att 8.203379 loss_ctc 42.366249 loss_ctc_origin 31.700577 loss_ctc0 67.252815 lr 0.00055558 rank 0
2022-08-26 22:49:07,568 DEBUG TRAIN Batch 227/4800 loss 19.973955 loss_att 7.763184 loss_ctc 48.465752 loss_ctc_origin 36.924217 loss_ctc0 75.396004 lr 0.00055556 rank 0
2022-08-26 22:49:34,462 DEBUG TRAIN Batch 227/4900 loss 20.697395 loss_att 8.422529 loss_ctc 49.338745 loss_ctc_origin 30.206024 loss_ctc0 93.981750 lr 0.00055554 rank 0
2022-08-26 22:50:02,816 DEBUG TRAIN Batch 227/5000 loss 57.528320 loss_att 39.457840 loss_ctc 99.692772 loss_ctc_origin 68.383423 loss_ctc0 172.747910 lr 0.00055552 rank 0
2022-08-26 22:50:03,444 WARNING NaN or Inf found in input tensor.
2022-08-26 22:50:30,052 DEBUG TRAIN Batch 227/5100 loss 64.592896 loss_att 36.993450 loss_ctc 128.991608 loss_ctc_origin 75.963806 loss_ctc0 252.723114 lr 0.00055550 rank 0
2022-08-26 22:50:57,976 DEBUG TRAIN Batch 227/5200 loss 21.854078 loss_att 10.910932 loss_ctc 47.388084 loss_ctc_origin 36.248871 loss_ctc0 73.379593 lr 0.00055547 rank 0
2022-08-26 22:51:25,154 DEBUG TRAIN Batch 227/5300 loss 18.728451 loss_att 7.266805 loss_ctc 45.472290 loss_ctc_origin 31.020426 loss_ctc0 79.193298 lr 0.00055545 rank 0
2022-08-26 22:51:53,539 DEBUG TRAIN Batch 227/5400 loss 20.459358 loss_att 8.456223 loss_ctc 48.466671 loss_ctc_origin 30.503483 loss_ctc0 90.380775 lr 0.00055543 rank 0
2022-08-26 22:52:21,397 DEBUG TRAIN Batch 227/5500 loss 50.773663 loss_att 32.141544 loss_ctc 94.248604 loss_ctc_origin 60.085423 loss_ctc0 173.962692 lr 0.00055541 rank 0
2022-08-26 22:52:47,272 DEBUG TRAIN Batch 227/5600 loss 57.556931 loss_att 32.642586 loss_ctc 115.690399 loss_ctc_origin 67.922623 loss_ctc0 227.148529 lr 0.00055539 rank 0
2022-08-26 22:53:08,529 DEBUG CV Batch 227/0 loss 11.659475 loss_att 8.595280 loss_ctc 18.809265 loss_ctc_origin 12.346734 loss_ctc0 33.888508 history loss 10.973624 rank 0
2022-08-26 22:53:18,209 DEBUG CV Batch 227/100 loss 20.669762 loss_att 16.649624 loss_ctc 30.050079 loss_ctc_origin 20.317646 loss_ctc0 52.759090 history loss 26.257316 rank 0
2022-08-26 22:53:27,146 DEBUG CV Batch 227/200 loss 26.078884 loss_att 20.398693 loss_ctc 39.332664 loss_ctc_origin 29.334179 loss_ctc0 62.662468 history loss 27.706251 rank 0
2022-08-26 22:53:36,345 DEBUG CV Batch 227/300 loss 22.772415 loss_att 17.203770 loss_ctc 35.765923 loss_ctc_origin 20.312481 loss_ctc0 71.823944 history loss 26.816766 rank 0
2022-08-26 22:53:45,973 DEBUG CV Batch 227/400 loss 37.471966 loss_att 29.719366 loss_ctc 55.561359 loss_ctc_origin 38.694908 loss_ctc0 94.916412 history loss 25.146668 rank 0
2022-08-26 22:53:55,665 DEBUG CV Batch 227/500 loss 17.163671 loss_att 12.704971 loss_ctc 27.567305 loss_ctc_origin 21.051926 loss_ctc0 42.769852 history loss 24.846485 rank 0
2022-08-26 22:54:05,133 DEBUG CV Batch 227/600 loss 17.478756 loss_att 12.431076 loss_ctc 29.256672 loss_ctc_origin 18.385132 loss_ctc0 54.623600 history loss 24.739034 rank 0
2022-08-26 22:54:15,092 DEBUG CV Batch 227/700 loss 18.585682 loss_att 12.911500 loss_ctc 31.825439 loss_ctc_origin 18.437101 loss_ctc0 63.064888 history loss 24.419331 rank 0
2022-08-26 22:54:25,714 DEBUG CV Batch 227/800 loss 21.377928 loss_att 16.348581 loss_ctc 33.113068 loss_ctc_origin 17.843288 loss_ctc0 68.742546 history loss 24.358911 rank 0
2022-08-26 22:54:35,866 INFO Epoch 227 CV info cv_loss 24.43447563707633
2022-08-26 22:54:35,867 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/227.pt
2022-08-26 22:54:36,343 INFO Epoch 228 TRAIN info lr 0.0005553704629115526
2022-08-26 22:54:36,346 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 22:55:02,537 DEBUG TRAIN Batch 228/0 loss 56.525631 loss_att 35.737614 loss_ctc 105.031006 loss_ctc_origin 70.553772 loss_ctc0 185.477875 lr 0.00055537 rank 0
2022-08-26 22:55:30,795 DEBUG TRAIN Batch 228/100 loss 61.270046 loss_att 34.997749 loss_ctc 122.572067 loss_ctc_origin 71.586395 loss_ctc0 241.538635 lr 0.00055535 rank 0
2022-08-26 22:55:58,268 DEBUG TRAIN Batch 228/200 loss 17.753933 loss_att 9.499295 loss_ctc 37.014751 loss_ctc_origin 25.539864 loss_ctc0 63.789486 lr 0.00055533 rank 0
2022-08-26 22:56:25,478 DEBUG TRAIN Batch 228/300 loss 17.847776 loss_att 6.704849 loss_ctc 43.847939 loss_ctc_origin 28.419920 loss_ctc0 79.846642 lr 0.00055531 rank 0
2022-08-26 22:56:51,993 DEBUG TRAIN Batch 228/400 loss 21.991232 loss_att 8.943740 loss_ctc 52.435379 loss_ctc_origin 32.420071 loss_ctc0 99.137764 lr 0.00055528 rank 0
2022-08-26 22:57:20,144 DEBUG TRAIN Batch 228/500 loss 51.999512 loss_att 32.904339 loss_ctc 96.554909 loss_ctc_origin 60.442093 loss_ctc0 180.818146 lr 0.00055526 rank 0
2022-08-26 22:57:47,753 DEBUG TRAIN Batch 228/600 loss 57.156593 loss_att 30.851860 loss_ctc 118.534302 loss_ctc_origin 67.076828 loss_ctc0 238.601746 lr 0.00055524 rank 0
2022-08-26 22:58:15,154 DEBUG TRAIN Batch 228/700 loss 18.026423 loss_att 9.089209 loss_ctc 38.879921 loss_ctc_origin 28.330793 loss_ctc0 63.494560 lr 0.00055522 rank 0
2022-08-26 22:58:42,450 DEBUG TRAIN Batch 228/800 loss 19.191805 loss_att 7.570869 loss_ctc 46.307320 loss_ctc_origin 30.436277 loss_ctc0 83.339752 lr 0.00055520 rank 0
2022-08-26 22:59:10,124 DEBUG TRAIN Batch 228/900 loss 19.391979 loss_att 7.043972 loss_ctc 48.203995 loss_ctc_origin 29.759968 loss_ctc0 91.240051 lr 0.00055518 rank 0
2022-08-26 22:59:25,612 WARNING NaN or Inf found in input tensor.
2022-08-26 22:59:26,354 WARNING NaN or Inf found in input tensor.
2022-08-26 22:59:37,940 DEBUG TRAIN Batch 228/1000 loss 49.644485 loss_att 31.028358 loss_ctc 93.082115 loss_ctc_origin 56.461273 loss_ctc0 178.530731 lr 0.00055516 rank 0
2022-08-26 22:59:52,384 WARNING NaN or Inf found in input tensor.
2022-08-26 23:00:05,249 DEBUG TRAIN Batch 228/1100 loss 55.590347 loss_att 28.288410 loss_ctc 119.294861 loss_ctc_origin 61.440269 loss_ctc0 254.288910 lr 0.00055513 rank 0
2022-08-26 23:00:33,528 DEBUG TRAIN Batch 228/1200 loss 17.305506 loss_att 9.476475 loss_ctc 35.573246 loss_ctc_origin 25.293400 loss_ctc0 59.559555 lr 0.00055511 rank 0
2022-08-26 23:01:01,640 DEBUG TRAIN Batch 228/1300 loss 19.513052 loss_att 7.628284 loss_ctc 47.244175 loss_ctc_origin 34.678581 loss_ctc0 76.563889 lr 0.00055509 rank 0
2022-08-26 23:01:28,405 DEBUG TRAIN Batch 228/1400 loss 22.098797 loss_att 9.345024 loss_ctc 51.857597 loss_ctc_origin 33.527184 loss_ctc0 94.628555 lr 0.00055507 rank 0
2022-08-26 23:02:03,778 DEBUG TRAIN Batch 228/1500 loss 50.256493 loss_att 33.282261 loss_ctc 89.863037 loss_ctc_origin 60.440372 loss_ctc0 158.515915 lr 0.00055505 rank 0
2022-08-26 23:02:31,243 DEBUG TRAIN Batch 228/1600 loss 60.393494 loss_att 36.000206 loss_ctc 117.311172 loss_ctc_origin 68.684296 loss_ctc0 230.773865 lr 0.00055503 rank 0
2022-08-26 23:02:58,216 DEBUG TRAIN Batch 228/1700 loss 18.583719 loss_att 8.213066 loss_ctc 42.781906 loss_ctc_origin 30.484064 loss_ctc0 71.476868 lr 0.00055501 rank 0
2022-08-26 23:03:26,606 DEBUG TRAIN Batch 228/1800 loss 21.248940 loss_att 7.734143 loss_ctc 52.783466 loss_ctc_origin 38.015507 loss_ctc0 87.242035 lr 0.00055498 rank 0
2022-08-26 23:03:54,131 DEBUG TRAIN Batch 228/1900 loss 23.250351 loss_att 9.923500 loss_ctc 54.346336 loss_ctc_origin 34.830605 loss_ctc0 99.883049 lr 0.00055496 rank 0
2022-08-26 23:04:23,528 DEBUG TRAIN Batch 228/2000 loss 50.197281 loss_att 33.693810 loss_ctc 88.705368 loss_ctc_origin 61.338951 loss_ctc0 152.560349 lr 0.00055494 rank 0
2022-08-26 23:04:50,842 WARNING NaN or Inf found in input tensor.
2022-08-26 23:04:50,880 DEBUG TRAIN Batch 228/2100 loss nan loss_att 36.691044 loss_ctc nan loss_ctc_origin 66.883606 loss_ctc0 nan lr 0.00055492 rank 0
2022-08-26 23:05:18,580 DEBUG TRAIN Batch 228/2200 loss 18.709633 loss_att 10.387753 loss_ctc 38.127350 loss_ctc_origin 26.445076 loss_ctc0 65.385994 lr 0.00055490 rank 0
2022-08-26 23:05:46,572 DEBUG TRAIN Batch 228/2300 loss 18.356493 loss_att 7.463039 loss_ctc 43.774551 loss_ctc_origin 30.984079 loss_ctc0 73.618973 lr 0.00055488 rank 0
2022-08-26 23:06:15,136 DEBUG TRAIN Batch 228/2400 loss 20.522306 loss_att 7.679003 loss_ctc 50.490013 loss_ctc_origin 31.632286 loss_ctc0 94.491371 lr 0.00055486 rank 0
2022-08-26 23:06:44,174 DEBUG TRAIN Batch 228/2500 loss 51.584663 loss_att 33.264275 loss_ctc 94.332230 loss_ctc_origin 61.137825 loss_ctc0 171.785828 lr 0.00055484 rank 0
2022-08-26 23:07:12,022 DEBUG TRAIN Batch 228/2600 loss 63.237770 loss_att 38.958710 loss_ctc 119.888916 loss_ctc_origin 70.716698 loss_ctc0 234.624084 lr 0.00055481 rank 0
2022-08-26 23:07:39,350 DEBUG TRAIN Batch 228/2700 loss 19.435688 loss_att 9.308134 loss_ctc 43.066643 loss_ctc_origin 31.643145 loss_ctc0 69.721466 lr 0.00055479 rank 0
2022-08-26 23:08:07,474 DEBUG TRAIN Batch 228/2800 loss 18.732952 loss_att 7.961457 loss_ctc 43.866440 loss_ctc_origin 29.693798 loss_ctc0 76.935936 lr 0.00055477 rank 0
2022-08-26 23:08:34,727 DEBUG TRAIN Batch 228/2900 loss 20.083195 loss_att 7.266029 loss_ctc 49.989914 loss_ctc_origin 32.264263 loss_ctc0 91.349762 lr 0.00055475 rank 0
2022-08-26 23:09:09,160 DEBUG TRAIN Batch 228/3000 loss 49.302696 loss_att 29.816551 loss_ctc 94.770370 loss_ctc_origin 62.365208 loss_ctc0 170.382401 lr 0.00055473 rank 0
2022-08-26 23:09:37,709 DEBUG TRAIN Batch 228/3100 loss 61.165325 loss_att 35.018841 loss_ctc 122.173782 loss_ctc_origin 67.552994 loss_ctc0 249.622284 lr 0.00055471 rank 0
2022-08-26 23:10:05,065 DEBUG TRAIN Batch 228/3200 loss 21.672720 loss_att 11.096191 loss_ctc 46.351284 loss_ctc_origin 33.217789 loss_ctc0 76.996109 lr 0.00055469 rank 0
2022-08-26 23:10:33,593 DEBUG TRAIN Batch 228/3300 loss 18.141119 loss_att 6.365005 loss_ctc 45.618713 loss_ctc_origin 31.070354 loss_ctc0 79.564880 lr 0.00055466 rank 0
2022-08-26 23:11:02,091 DEBUG TRAIN Batch 228/3400 loss 25.829792 loss_att 11.376049 loss_ctc 59.555191 loss_ctc_origin 42.446045 loss_ctc0 99.476532 lr 0.00055464 rank 0
2022-08-26 23:11:04,754 WARNING NaN or Inf found in input tensor.
2022-08-26 23:11:30,226 DEBUG TRAIN Batch 228/3500 loss 49.757256 loss_att 31.517906 loss_ctc 92.315735 loss_ctc_origin 62.603329 loss_ctc0 161.644669 lr 0.00055462 rank 0
2022-08-26 23:11:37,514 WARNING NaN or Inf found in input tensor.
2022-08-26 23:11:57,925 DEBUG TRAIN Batch 228/3600 loss 53.464378 loss_att 27.028130 loss_ctc 115.148941 loss_ctc_origin 59.421333 loss_ctc0 245.180023 lr 0.00055460 rank 0
2022-08-26 23:12:25,157 DEBUG TRAIN Batch 228/3700 loss 18.150887 loss_att 8.091128 loss_ctc 41.623650 loss_ctc_origin 30.029739 loss_ctc0 68.676102 lr 0.00055458 rank 0
2022-08-26 23:12:51,769 DEBUG TRAIN Batch 228/3800 loss 16.149347 loss_att 6.341903 loss_ctc 39.033382 loss_ctc_origin 23.138159 loss_ctc0 76.122238 lr 0.00055456 rank 0
2022-08-26 23:13:20,830 DEBUG TRAIN Batch 228/3900 loss 20.695173 loss_att 8.253665 loss_ctc 49.725357 loss_ctc_origin 30.304855 loss_ctc0 95.039856 lr 0.00055454 rank 0
2022-08-26 23:13:36,285 WARNING NaN or Inf found in input tensor.
2022-08-26 23:13:48,824 DEBUG TRAIN Batch 228/4000 loss 53.936340 loss_att 34.814072 loss_ctc 98.554955 loss_ctc_origin 67.588684 loss_ctc0 170.809586 lr 0.00055452 rank 0
2022-08-26 23:14:16,087 DEBUG TRAIN Batch 228/4100 loss 59.333752 loss_att 36.005718 loss_ctc 113.765823 loss_ctc_origin 70.461746 loss_ctc0 214.808640 lr 0.00055449 rank 0
2022-08-26 23:14:43,398 DEBUG TRAIN Batch 228/4200 loss 21.652363 loss_att 11.743953 loss_ctc 44.771980 loss_ctc_origin 34.394073 loss_ctc0 68.987091 lr 0.00055447 rank 0
2022-08-26 23:15:11,948 DEBUG TRAIN Batch 228/4300 loss 19.345711 loss_att 8.002373 loss_ctc 45.813499 loss_ctc_origin 31.388512 loss_ctc0 79.471802 lr 0.00055445 rank 0
2022-08-26 23:15:34,843 WARNING NaN or Inf found in input tensor.
2022-08-26 23:15:39,232 DEBUG TRAIN Batch 228/4400 loss 19.129208 loss_att 7.928037 loss_ctc 45.265274 loss_ctc_origin 30.645935 loss_ctc0 79.377060 lr 0.00055443 rank 0
2022-08-26 23:15:59,090 WARNING NaN or Inf found in input tensor.
2022-08-26 23:16:12,026 DEBUG TRAIN Batch 228/4500 loss 49.261242 loss_att 33.421349 loss_ctc 86.220993 loss_ctc_origin 57.019699 loss_ctc0 154.357330 lr 0.00055441 rank 0
2022-08-26 23:16:40,199 DEBUG TRAIN Batch 228/4600 loss 61.445198 loss_att 39.867592 loss_ctc 111.792938 loss_ctc_origin 68.950775 loss_ctc0 211.757996 lr 0.00055439 rank 0
2022-08-26 23:17:07,991 DEBUG TRAIN Batch 228/4700 loss 20.419996 loss_att 11.575338 loss_ctc 41.057529 loss_ctc_origin 30.503567 loss_ctc0 65.683441 lr 0.00055437 rank 0
2022-08-26 23:17:36,185 DEBUG TRAIN Batch 228/4800 loss 19.796829 loss_att 8.005474 loss_ctc 47.309990 loss_ctc_origin 32.962112 loss_ctc0 80.788361 lr 0.00055434 rank 0
2022-08-26 23:18:03,574 DEBUG TRAIN Batch 228/4900 loss 21.059959 loss_att 8.271318 loss_ctc 50.900124 loss_ctc_origin 32.761421 loss_ctc0 93.223755 lr 0.00055432 rank 0
2022-08-26 23:18:31,013 DEBUG TRAIN Batch 228/5000 loss 50.257336 loss_att 33.817657 loss_ctc 88.616585 loss_ctc_origin 59.648819 loss_ctc0 156.208038 lr 0.00055430 rank 0
2022-08-26 23:18:38,580 WARNING NaN or Inf found in input tensor.
2022-08-26 23:18:58,020 DEBUG TRAIN Batch 228/5100 loss 53.514633 loss_att 30.491051 loss_ctc 107.236328 loss_ctc_origin 59.683777 loss_ctc0 218.192245 lr 0.00055428 rank 0
2022-08-26 23:19:24,781 DEBUG TRAIN Batch 228/5200 loss 17.896046 loss_att 8.291252 loss_ctc 40.307228 loss_ctc_origin 29.408184 loss_ctc0 65.738335 lr 0.00055426 rank 0
2022-08-26 23:19:52,963 DEBUG TRAIN Batch 228/5300 loss 18.515642 loss_att 7.670301 loss_ctc 43.821434 loss_ctc_origin 29.909779 loss_ctc0 76.281967 lr 0.00055424 rank 0
2022-08-26 23:20:19,522 DEBUG TRAIN Batch 228/5400 loss 20.583363 loss_att 8.054226 loss_ctc 49.818016 loss_ctc_origin 32.030724 loss_ctc0 91.321693 lr 0.00055422 rank 0
2022-08-26 23:20:48,260 DEBUG TRAIN Batch 228/5500 loss 46.162315 loss_att 30.917149 loss_ctc 81.734360 loss_ctc_origin 48.777103 loss_ctc0 158.634644 lr 0.00055420 rank 0
2022-08-26 23:21:15,054 DEBUG TRAIN Batch 228/5600 loss 58.046970 loss_att 33.008755 loss_ctc 116.469467 loss_ctc_origin 73.426247 loss_ctc0 216.903625 lr 0.00055417 rank 0
2022-08-26 23:21:36,648 DEBUG CV Batch 228/0 loss 12.322145 loss_att 9.562398 loss_ctc 18.761553 loss_ctc_origin 12.328096 loss_ctc0 33.772949 history loss 11.597312 rank 0
2022-08-26 23:21:46,359 DEBUG CV Batch 228/100 loss 21.879564 loss_att 17.763363 loss_ctc 31.484034 loss_ctc_origin 22.220161 loss_ctc0 53.099735 history loss 27.257114 rank 0
2022-08-26 23:21:55,165 DEBUG CV Batch 228/200 loss 26.950817 loss_att 21.516815 loss_ctc 39.630157 loss_ctc_origin 29.852497 loss_ctc0 62.444691 history loss 28.906100 rank 0
2022-08-26 23:22:03,996 DEBUG CV Batch 228/300 loss 22.431038 loss_att 17.233089 loss_ctc 34.559586 loss_ctc_origin 18.968208 loss_ctc0 70.939461 history loss 28.010055 rank 0
2022-08-26 23:22:13,737 DEBUG CV Batch 228/400 loss 38.266365 loss_att 31.154778 loss_ctc 54.860069 loss_ctc_origin 37.787483 loss_ctc0 94.696106 history loss 26.179107 rank 0
2022-08-26 23:22:23,334 DEBUG CV Batch 228/500 loss 17.900806 loss_att 13.663931 loss_ctc 27.786852 loss_ctc_origin 21.303284 loss_ctc0 42.915176 history loss 25.778866 rank 0
2022-08-26 23:22:32,643 DEBUG CV Batch 228/600 loss 18.070953 loss_att 12.979654 loss_ctc 29.950653 loss_ctc_origin 19.110783 loss_ctc0 55.243687 history loss 25.586647 rank 0
2022-08-26 23:22:41,810 DEBUG CV Batch 228/700 loss 21.020407 loss_att 15.464348 loss_ctc 33.984543 loss_ctc_origin 21.088192 loss_ctc0 64.076019 history loss 25.246108 rank 0
2022-08-26 23:22:51,437 DEBUG CV Batch 228/800 loss 22.636490 loss_att 17.910225 loss_ctc 33.664444 loss_ctc_origin 18.646530 loss_ctc0 68.706238 history loss 25.147199 rank 0
2022-08-26 23:23:01,081 INFO Epoch 228 CV info cv_loss 25.205655865121088
2022-08-26 23:23:01,081 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/228.pt
2022-08-26 23:23:01,514 INFO Epoch 229 TRAIN info lr 0.0005541565369509284
2022-08-26 23:23:01,517 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 23:23:27,472 DEBUG TRAIN Batch 229/0 loss 49.166954 loss_att 31.757723 loss_ctc 89.788498 loss_ctc_origin 60.937141 loss_ctc0 157.108337 lr 0.00055416 rank 0
2022-08-26 23:23:55,300 DEBUG TRAIN Batch 229/100 loss 54.132450 loss_att 29.549801 loss_ctc 111.491959 loss_ctc_origin 64.201553 loss_ctc0 221.836243 lr 0.00055413 rank 0
2022-08-26 23:24:22,033 DEBUG TRAIN Batch 229/200 loss 23.803139 loss_att 10.607195 loss_ctc 54.593670 loss_ctc_origin 43.723236 loss_ctc0 79.958015 lr 0.00055411 rank 0
2022-08-26 23:24:49,672 DEBUG TRAIN Batch 229/300 loss 20.674536 loss_att 8.783524 loss_ctc 48.420227 loss_ctc_origin 33.899170 loss_ctc0 82.302696 lr 0.00055409 rank 0
2022-08-26 23:25:13,106 WARNING NaN or Inf found in input tensor.
2022-08-26 23:25:17,254 DEBUG TRAIN Batch 229/400 loss 21.553150 loss_att 7.946877 loss_ctc 53.301117 loss_ctc_origin 35.290985 loss_ctc0 95.324753 lr 0.00055407 rank 0
2022-08-26 23:25:45,826 DEBUG TRAIN Batch 229/500 loss 49.519371 loss_att 32.635197 loss_ctc 88.915771 loss_ctc_origin 53.590660 loss_ctc0 171.341034 lr 0.00055405 rank 0
2022-08-26 23:25:53,240 WARNING NaN or Inf found in input tensor.
2022-08-26 23:26:12,850 DEBUG TRAIN Batch 229/600 loss 57.992516 loss_att 33.638359 loss_ctc 114.818871 loss_ctc_origin 68.515778 loss_ctc0 222.859406 lr 0.00055403 rank 0
2022-08-26 23:26:40,000 DEBUG TRAIN Batch 229/700 loss 20.641636 loss_att 10.063095 loss_ctc 45.324894 loss_ctc_origin 36.210140 loss_ctc0 66.592651 lr 0.00055401 rank 0
2022-08-26 23:27:07,951 DEBUG TRAIN Batch 229/800 loss 19.988266 loss_att 8.060410 loss_ctc 47.819931 loss_ctc_origin 32.582245 loss_ctc0 83.374535 lr 0.00055399 rank 0
2022-08-26 23:27:35,696 DEBUG TRAIN Batch 229/900 loss 21.907713 loss_att 8.466867 loss_ctc 53.269684 loss_ctc_origin 34.882454 loss_ctc0 96.173218 lr 0.00055396 rank 0
2022-08-26 23:28:04,881 DEBUG TRAIN Batch 229/1000 loss 40.070019 loss_att 22.741652 loss_ctc 80.502869 loss_ctc_origin 47.256844 loss_ctc0 158.076935 lr 0.00055394 rank 0
2022-08-26 23:28:24,139 WARNING NaN or Inf found in input tensor.
2022-08-26 23:28:30,916 DEBUG TRAIN Batch 229/1100 loss 65.905869 loss_att 39.590595 loss_ctc 127.308182 loss_ctc_origin 84.080490 loss_ctc0 228.172775 lr 0.00055392 rank 0
2022-08-26 23:28:58,262 DEBUG TRAIN Batch 229/1200 loss 18.829491 loss_att 9.381144 loss_ctc 40.875633 loss_ctc_origin 28.692366 loss_ctc0 69.303253 lr 0.00055390 rank 0
2022-08-26 23:29:26,871 DEBUG TRAIN Batch 229/1300 loss 19.380409 loss_att 7.762839 loss_ctc 46.488068 loss_ctc_origin 31.703100 loss_ctc0 80.986328 lr 0.00055388 rank 0
2022-08-26 23:29:54,325 DEBUG TRAIN Batch 229/1400 loss 24.104088 loss_att 8.970123 loss_ctc 59.416672 loss_ctc_origin 43.862171 loss_ctc0 95.710510 lr 0.00055386 rank 0
2022-08-26 23:30:27,500 DEBUG TRAIN Batch 229/1500 loss 45.077213 loss_att 27.210239 loss_ctc 86.766815 loss_ctc_origin 51.688232 loss_ctc0 168.616821 lr 0.00055384 rank 0
2022-08-26 23:30:55,152 DEBUG TRAIN Batch 229/1600 loss 56.247124 loss_att 29.740004 loss_ctc 118.097069 loss_ctc_origin 69.622673 loss_ctc0 231.203995 lr 0.00055382 rank 0
2022-08-26 23:31:10,217 WARNING NaN or Inf found in input tensor.
2022-08-26 23:31:22,821 DEBUG TRAIN Batch 229/1700 loss 19.347950 loss_att 10.702195 loss_ctc 39.521374 loss_ctc_origin 30.279522 loss_ctc0 61.085690 lr 0.00055379 rank 0
2022-08-26 23:31:50,943 DEBUG TRAIN Batch 229/1800 loss 20.019449 loss_att 7.976547 loss_ctc 48.119553 loss_ctc_origin 34.926537 loss_ctc0 78.903259 lr 0.00055377 rank 0
2022-08-26 23:32:18,738 DEBUG TRAIN Batch 229/1900 loss 21.566113 loss_att 9.011003 loss_ctc 50.861366 loss_ctc_origin 29.225182 loss_ctc0 101.345795 lr 0.00055375 rank 0
2022-08-26 23:32:47,090 DEBUG TRAIN Batch 229/2000 loss 46.805485 loss_att 31.345430 loss_ctc 82.878944 loss_ctc_origin 56.638252 loss_ctc0 144.107224 lr 0.00055373 rank 0
2022-08-26 23:33:15,146 DEBUG TRAIN Batch 229/2100 loss 51.266151 loss_att 28.073963 loss_ctc 105.381264 loss_ctc_origin 59.405853 loss_ctc0 212.657227 lr 0.00055371 rank 0
2022-08-26 23:33:42,789 DEBUG TRAIN Batch 229/2200 loss 19.279655 loss_att 9.033119 loss_ctc 43.188236 loss_ctc_origin 32.230034 loss_ctc0 68.757370 lr 0.00055369 rank 0
2022-08-26 23:34:11,372 DEBUG TRAIN Batch 229/2300 loss 17.233141 loss_att 6.362516 loss_ctc 42.597927 loss_ctc_origin 27.860407 loss_ctc0 76.985474 lr 0.00055367 rank 0
2022-08-26 23:34:40,406 DEBUG TRAIN Batch 229/2400 loss 20.889946 loss_att 8.778571 loss_ctc 49.149822 loss_ctc_origin 32.114288 loss_ctc0 88.899399 lr 0.00055365 rank 0
2022-08-26 23:35:06,717 DEBUG TRAIN Batch 229/2500 loss 52.822861 loss_att 33.417572 loss_ctc 98.101868 loss_ctc_origin 67.139397 loss_ctc0 170.347626 lr 0.00055362 rank 0
2022-08-26 23:35:34,968 DEBUG TRAIN Batch 229/2600 loss 46.926895 loss_att 23.234001 loss_ctc 102.210312 loss_ctc_origin 51.039555 loss_ctc0 221.608719 lr 0.00055360 rank 0
2022-08-26 23:36:00,655 DEBUG TRAIN Batch 229/2700 loss 17.272549 loss_att 9.674339 loss_ctc 35.001705 loss_ctc_origin 23.584539 loss_ctc0 61.641754 lr 0.00055358 rank 0
2022-08-26 23:36:29,447 DEBUG TRAIN Batch 229/2800 loss 18.911865 loss_att 7.627367 loss_ctc 45.242363 loss_ctc_origin 30.860027 loss_ctc0 78.801147 lr 0.00055356 rank 0
2022-08-26 23:36:57,170 DEBUG TRAIN Batch 229/2900 loss 19.599955 loss_att 8.010721 loss_ctc 46.641499 loss_ctc_origin 29.967085 loss_ctc0 85.548462 lr 0.00055354 rank 0
2022-08-26 23:37:31,531 DEBUG TRAIN Batch 229/3000 loss 50.078079 loss_att 33.826530 loss_ctc 87.998360 loss_ctc_origin 62.409672 loss_ctc0 147.705292 lr 0.00055352 rank 0
2022-08-26 23:37:59,790 DEBUG TRAIN Batch 229/3100 loss 52.487396 loss_att 28.444878 loss_ctc 108.586601 loss_ctc_origin 62.858376 loss_ctc0 215.285797 lr 0.00055350 rank 0
2022-08-26 23:38:27,230 DEBUG TRAIN Batch 229/3200 loss 17.500416 loss_att 9.550400 loss_ctc 36.050449 loss_ctc_origin 23.528358 loss_ctc0 65.268661 lr 0.00055348 rank 0
2022-08-26 23:38:54,213 DEBUG TRAIN Batch 229/3300 loss 17.999714 loss_att 7.081847 loss_ctc 43.474731 loss_ctc_origin 27.535238 loss_ctc0 80.666885 lr 0.00055346 rank 0
2022-08-26 23:39:21,088 DEBUG TRAIN Batch 229/3400 loss 22.264132 loss_att 8.530946 loss_ctc 54.308228 loss_ctc_origin 32.169228 loss_ctc0 105.965881 lr 0.00055343 rank 0
2022-08-26 23:39:49,142 DEBUG TRAIN Batch 229/3500 loss 57.688705 loss_att 40.715725 loss_ctc 97.292320 loss_ctc_origin 65.252823 loss_ctc0 172.051147 lr 0.00055341 rank 0
2022-08-26 23:40:14,891 DEBUG TRAIN Batch 229/3600 loss 56.433762 loss_att 30.703966 loss_ctc 116.469940 loss_ctc_origin 70.039337 loss_ctc0 224.808014 lr 0.00055339 rank 0
2022-08-26 23:40:43,008 DEBUG TRAIN Batch 229/3700 loss 21.909941 loss_att 11.359969 loss_ctc 46.526539 loss_ctc_origin 34.136246 loss_ctc0 75.437218 lr 0.00055337 rank 0
2022-08-26 23:41:10,050 DEBUG TRAIN Batch 229/3800 loss 22.522453 loss_att 9.946565 loss_ctc 51.866196 loss_ctc_origin 37.785629 loss_ctc0 84.720848 lr 0.00055335 rank 0
2022-08-26 23:41:38,279 DEBUG TRAIN Batch 229/3900 loss 23.163893 loss_att 9.183889 loss_ctc 55.783897 loss_ctc_origin 38.028664 loss_ctc0 97.212769 lr 0.00055333 rank 0
2022-08-26 23:42:06,663 DEBUG TRAIN Batch 229/4000 loss 46.121338 loss_att 30.070362 loss_ctc 83.573608 loss_ctc_origin 53.094513 loss_ctc0 154.691498 lr 0.00055331 rank 0
2022-08-26 23:42:33,544 DEBUG TRAIN Batch 229/4100 loss 49.657234 loss_att 24.202339 loss_ctc 109.051979 loss_ctc_origin 52.737625 loss_ctc0 240.452133 lr 0.00055329 rank 0
2022-08-26 23:42:59,695 WARNING NaN or Inf found in input tensor.
2022-08-26 23:43:01,332 DEBUG TRAIN Batch 229/4200 loss 20.290161 loss_att 9.507866 loss_ctc 45.448853 loss_ctc_origin 33.025875 loss_ctc0 74.435806 lr 0.00055326 rank 0
2022-08-26 23:43:30,913 DEBUG TRAIN Batch 229/4300 loss 17.533480 loss_att 6.899825 loss_ctc 42.345337 loss_ctc_origin 28.500061 loss_ctc0 74.650986 lr 0.00055324 rank 0
2022-08-26 23:43:58,004 DEBUG TRAIN Batch 229/4400 loss 18.637205 loss_att 7.919238 loss_ctc 43.645794 loss_ctc_origin 25.962955 loss_ctc0 84.905746 lr 0.00055322 rank 0
2022-08-26 23:44:32,183 DEBUG TRAIN Batch 229/4500 loss 53.205315 loss_att 35.156311 loss_ctc 95.319656 loss_ctc_origin 64.118195 loss_ctc0 168.123077 lr 0.00055320 rank 0
2022-08-26 23:45:00,065 DEBUG TRAIN Batch 229/4600 loss 53.083290 loss_att 29.326542 loss_ctc 108.515701 loss_ctc_origin 58.810654 loss_ctc0 224.494125 lr 0.00055318 rank 0
2022-08-26 23:45:27,573 DEBUG TRAIN Batch 229/4700 loss 20.562355 loss_att 10.437220 loss_ctc 44.187672 loss_ctc_origin 32.843712 loss_ctc0 70.656906 lr 0.00055316 rank 0
2022-08-26 23:45:55,099 DEBUG TRAIN Batch 229/4800 loss 17.289404 loss_att 7.171979 loss_ctc 40.896729 loss_ctc_origin 26.214972 loss_ctc0 75.154160 lr 0.00055314 rank 0
2022-08-26 23:46:23,192 DEBUG TRAIN Batch 229/4900 loss 21.253902 loss_att 8.726654 loss_ctc 50.484142 loss_ctc_origin 32.979015 loss_ctc0 91.329437 lr 0.00055312 rank 0
2022-08-26 23:46:53,221 DEBUG TRAIN Batch 229/5000 loss 43.957840 loss_att 29.522930 loss_ctc 77.639297 loss_ctc_origin 49.885780 loss_ctc0 142.397522 lr 0.00055310 rank 0
2022-08-26 23:47:19,622 DEBUG TRAIN Batch 229/5100 loss 52.783813 loss_att 29.244728 loss_ctc 107.708344 loss_ctc_origin 64.854889 loss_ctc0 207.699738 lr 0.00055307 rank 0
2022-08-26 23:47:45,669 WARNING NaN or Inf found in input tensor.
2022-08-26 23:47:47,104 DEBUG TRAIN Batch 229/5200 loss 17.391376 loss_att 8.906990 loss_ctc 37.188278 loss_ctc_origin 27.060089 loss_ctc0 60.820721 lr 0.00055305 rank 0
2022-08-26 23:48:14,680 DEBUG TRAIN Batch 229/5300 loss 19.568789 loss_att 7.753242 loss_ctc 47.138397 loss_ctc_origin 31.770996 loss_ctc0 82.995667 lr 0.00055303 rank 0
2022-08-26 23:48:41,905 DEBUG TRAIN Batch 229/5400 loss 23.123392 loss_att 9.183815 loss_ctc 55.649071 loss_ctc_origin 36.367363 loss_ctc0 100.639717 lr 0.00055301 rank 0
2022-08-26 23:49:08,694 DEBUG TRAIN Batch 229/5500 loss 45.899632 loss_att 31.676584 loss_ctc 79.086739 loss_ctc_origin 53.708836 loss_ctc0 138.301849 lr 0.00055299 rank 0
2022-08-26 23:49:29,929 WARNING NaN or Inf found in input tensor.
2022-08-26 23:49:36,292 DEBUG TRAIN Batch 229/5600 loss 48.267487 loss_att 28.834511 loss_ctc 93.611099 loss_ctc_origin 54.069092 loss_ctc0 185.875778 lr 0.00055297 rank 0
2022-08-26 23:49:57,753 DEBUG CV Batch 229/0 loss 11.781064 loss_att 8.795572 loss_ctc 18.747211 loss_ctc_origin 12.369817 loss_ctc0 33.627800 history loss 11.088060 rank 0
2022-08-26 23:50:07,849 DEBUG CV Batch 229/100 loss 20.406597 loss_att 16.526785 loss_ctc 29.459492 loss_ctc_origin 19.923588 loss_ctc0 51.709930 history loss 26.224409 rank 0
2022-08-26 23:50:17,104 DEBUG CV Batch 229/200 loss 24.534550 loss_att 19.222775 loss_ctc 36.928688 loss_ctc_origin 26.416393 loss_ctc0 61.457378 history loss 27.535944 rank 0
2022-08-26 23:50:26,297 DEBUG CV Batch 229/300 loss 22.530758 loss_att 16.997002 loss_ctc 35.442852 loss_ctc_origin 20.275394 loss_ctc0 70.833588 history loss 26.643468 rank 0
2022-08-26 23:50:36,224 DEBUG CV Batch 229/400 loss 37.343475 loss_att 29.836437 loss_ctc 54.859901 loss_ctc_origin 37.878288 loss_ctc0 94.483673 history loss 24.939570 rank 0
2022-08-26 23:50:46,194 DEBUG CV Batch 229/500 loss 16.395002 loss_att 12.080319 loss_ctc 26.462593 loss_ctc_origin 19.760242 loss_ctc0 42.101410 history loss 24.594636 rank 0
2022-08-26 23:50:56,601 DEBUG CV Batch 229/600 loss 17.488581 loss_att 12.717379 loss_ctc 28.621386 loss_ctc_origin 17.922985 loss_ctc0 53.584320 history loss 24.426708 rank 0
2022-08-26 23:51:06,685 DEBUG CV Batch 229/700 loss 19.614349 loss_att 14.215924 loss_ctc 32.210674 loss_ctc_origin 19.062248 loss_ctc0 62.890331 history loss 24.092069 rank 0
2022-08-26 23:51:17,364 DEBUG CV Batch 229/800 loss 21.678766 loss_att 16.580202 loss_ctc 33.575417 loss_ctc_origin 18.494759 loss_ctc0 68.763611 history loss 24.036797 rank 0
2022-08-26 23:51:27,290 INFO Epoch 229 CV info cv_loss 24.135289356015754
2022-08-26 23:51:27,291 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/229.pt
2022-08-26 23:51:27,755 INFO Epoch 230 TRAIN info lr 0.0005529505365291336
2022-08-26 23:51:27,759 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-26 23:51:52,993 DEBUG TRAIN Batch 230/0 loss 41.337727 loss_att 26.799454 loss_ctc 75.260361 loss_ctc_origin 47.462349 loss_ctc0 140.122375 lr 0.00055295 rank 0
2022-08-26 23:52:20,224 DEBUG TRAIN Batch 230/100 loss 52.545712 loss_att 30.187565 loss_ctc 104.714722 loss_ctc_origin 69.545830 loss_ctc0 186.775452 lr 0.00055293 rank 0
2022-08-26 23:52:47,726 DEBUG TRAIN Batch 230/200 loss 18.718393 loss_att 9.680075 loss_ctc 39.807804 loss_ctc_origin 27.927479 loss_ctc0 67.528564 lr 0.00055291 rank 0
2022-08-26 23:53:15,346 DEBUG TRAIN Batch 230/300 loss 19.268642 loss_att 6.985766 loss_ctc 47.928688 loss_ctc_origin 35.577446 loss_ctc0 76.748245 lr 0.00055289 rank 0
2022-08-26 23:53:42,827 DEBUG TRAIN Batch 230/400 loss 23.518793 loss_att 9.356791 loss_ctc 56.563461 loss_ctc_origin 40.674736 loss_ctc0 93.637146 lr 0.00055287 rank 0
2022-08-26 23:54:12,343 DEBUG TRAIN Batch 230/500 loss 53.119904 loss_att 36.346439 loss_ctc 92.257980 loss_ctc_origin 59.861176 loss_ctc0 167.850525 lr 0.00055284 rank 0
2022-08-26 23:54:39,673 DEBUG TRAIN Batch 230/600 loss 52.952637 loss_att 32.094830 loss_ctc 101.620850 loss_ctc_origin 60.737198 loss_ctc0 197.016022 lr 0.00055282 rank 0
2022-08-26 23:55:06,874 DEBUG TRAIN Batch 230/700 loss 18.742247 loss_att 9.624341 loss_ctc 40.017357 loss_ctc_origin 28.876390 loss_ctc0 66.012947 lr 0.00055280 rank 0
2022-08-26 23:55:35,525 DEBUG TRAIN Batch 230/800 loss 19.253450 loss_att 7.718461 loss_ctc 46.168427 loss_ctc_origin 28.988831 loss_ctc0 86.254150 lr 0.00055278 rank 0
2022-08-26 23:56:03,762 DEBUG TRAIN Batch 230/900 loss 17.697060 loss_att 6.563644 loss_ctc 43.675030 loss_ctc_origin 25.051592 loss_ctc0 87.129715 lr 0.00055276 rank 0
2022-08-26 23:56:32,253 DEBUG TRAIN Batch 230/1000 loss 45.416496 loss_att 27.008404 loss_ctc 88.368713 loss_ctc_origin 59.636063 loss_ctc0 155.411545 lr 0.00055274 rank 0
2022-08-26 23:56:45,974 WARNING NaN or Inf found in input tensor.
2022-08-26 23:56:59,911 DEBUG TRAIN Batch 230/1100 loss 53.250122 loss_att 30.010874 loss_ctc 107.475037 loss_ctc_origin 62.005108 loss_ctc0 213.571533 lr 0.00055272 rank 0
2022-08-26 23:57:26,717 DEBUG TRAIN Batch 230/1200 loss 18.168159 loss_att 9.643375 loss_ctc 38.059319 loss_ctc_origin 25.941193 loss_ctc0 66.334953 lr 0.00055270 rank 0
2022-08-26 23:57:54,229 DEBUG TRAIN Batch 230/1300 loss 18.764088 loss_att 7.849588 loss_ctc 44.231247 loss_ctc_origin 28.760853 loss_ctc0 80.328827 lr 0.00055268 rank 0
2022-08-26 23:58:21,216 DEBUG TRAIN Batch 230/1400 loss 21.525169 loss_att 8.745270 loss_ctc 51.344929 loss_ctc_origin 34.234882 loss_ctc0 91.268372 lr 0.00055265 rank 0
2022-08-26 23:58:55,520 DEBUG TRAIN Batch 230/1500 loss 51.923401 loss_att 33.701008 loss_ctc 94.442314 loss_ctc_origin 56.107666 loss_ctc0 183.889832 lr 0.00055263 rank 0
2022-08-26 23:59:22,765 DEBUG TRAIN Batch 230/1600 loss 55.436958 loss_att 31.038788 loss_ctc 112.366020 loss_ctc_origin 69.927879 loss_ctc0 211.388336 lr 0.00055261 rank 0
2022-08-26 23:59:50,433 DEBUG TRAIN Batch 230/1700 loss 17.887184 loss_att 9.563141 loss_ctc 37.309952 loss_ctc_origin 24.940777 loss_ctc0 66.171356 lr 0.00055259 rank 0
2022-08-27 00:00:18,449 DEBUG TRAIN Batch 230/1800 loss 17.297573 loss_att 6.378753 loss_ctc 42.774822 loss_ctc_origin 28.568981 loss_ctc0 75.921783 lr 0.00055257 rank 0
2022-08-27 00:00:46,710 DEBUG TRAIN Batch 230/1900 loss 20.787672 loss_att 8.506315 loss_ctc 49.444168 loss_ctc_origin 28.599972 loss_ctc0 98.080627 lr 0.00055255 rank 0
2022-08-27 00:01:14,923 DEBUG TRAIN Batch 230/2000 loss 46.112236 loss_att 26.586365 loss_ctc 91.672600 loss_ctc_origin 59.733406 loss_ctc0 166.197372 lr 0.00055253 rank 0
2022-08-27 00:01:43,076 DEBUG TRAIN Batch 230/2100 loss 51.594822 loss_att 27.165445 loss_ctc 108.596695 loss_ctc_origin 61.740059 loss_ctc0 217.928848 lr 0.00055251 rank 0
2022-08-27 00:02:11,688 DEBUG TRAIN Batch 230/2200 loss 19.623741 loss_att 10.332174 loss_ctc 41.304066 loss_ctc_origin 30.649822 loss_ctc0 66.163963 lr 0.00055249 rank 0
2022-08-27 00:02:38,214 DEBUG TRAIN Batch 230/2300 loss 20.138668 loss_att 7.978116 loss_ctc 48.513290 loss_ctc_origin 31.808510 loss_ctc0 87.491104 lr 0.00055246 rank 0
2022-08-27 00:03:06,787 DEBUG TRAIN Batch 230/2400 loss 24.307114 loss_att 10.057497 loss_ctc 57.556221 loss_ctc_origin 38.616508 loss_ctc0 101.748886 lr 0.00055244 rank 0
2022-08-27 00:03:33,837 DEBUG TRAIN Batch 230/2500 loss 47.241898 loss_att 30.739563 loss_ctc 85.747345 loss_ctc_origin 56.564621 loss_ctc0 153.840363 lr 0.00055242 rank 0
2022-08-27 00:04:01,229 DEBUG TRAIN Batch 230/2600 loss 58.530285 loss_att 37.012367 loss_ctc 108.738754 loss_ctc_origin 70.411530 loss_ctc0 198.168930 lr 0.00055240 rank 0
2022-08-27 00:04:28,588 DEBUG TRAIN Batch 230/2700 loss 17.135572 loss_att 7.852843 loss_ctc 38.795273 loss_ctc_origin 26.784250 loss_ctc0 66.820984 lr 0.00055238 rank 0
2022-08-27 00:04:56,882 DEBUG TRAIN Batch 230/2800 loss 19.604620 loss_att 8.127271 loss_ctc 46.385101 loss_ctc_origin 30.570175 loss_ctc0 83.286591 lr 0.00055236 rank 0
2022-08-27 00:05:24,427 DEBUG TRAIN Batch 230/2900 loss 21.977654 loss_att 8.412869 loss_ctc 53.628819 loss_ctc_origin 33.382469 loss_ctc0 100.870300 lr 0.00055234 rank 0
2022-08-27 00:05:58,636 DEBUG TRAIN Batch 230/3000 loss 52.461079 loss_att 35.275871 loss_ctc 92.559891 loss_ctc_origin 61.057041 loss_ctc0 166.066528 lr 0.00055232 rank 0
2022-08-27 00:06:25,569 DEBUG TRAIN Batch 230/3100 loss 47.996368 loss_att 27.494637 loss_ctc 95.833740 loss_ctc_origin 56.969246 loss_ctc0 186.517548 lr 0.00055230 rank 0
2022-08-27 00:06:50,697 WARNING NaN or Inf found in input tensor.
2022-08-27 00:06:52,324 DEBUG TRAIN Batch 230/3200 loss 18.038401 loss_att 10.133232 loss_ctc 36.483795 loss_ctc_origin 24.510599 loss_ctc0 64.421242 lr 0.00055227 rank 0
2022-08-27 00:06:57,695 WARNING NaN or Inf found in input tensor.
2022-08-27 00:07:19,431 DEBUG TRAIN Batch 230/3300 loss 16.349770 loss_att 5.903536 loss_ctc 40.724312 loss_ctc_origin 26.059654 loss_ctc0 74.941833 lr 0.00055225 rank 0
2022-08-27 00:07:46,359 DEBUG TRAIN Batch 230/3400 loss 21.125504 loss_att 8.763025 loss_ctc 49.971283 loss_ctc_origin 30.086735 loss_ctc0 96.368561 lr 0.00055223 rank 0
2022-08-27 00:07:48,876 WARNING NaN or Inf found in input tensor.
2022-08-27 00:08:14,550 DEBUG TRAIN Batch 230/3500 loss 48.676392 loss_att 33.470863 loss_ctc 84.155960 loss_ctc_origin 58.357704 loss_ctc0 144.351898 lr 0.00055221 rank 0
2022-08-27 00:08:41,911 DEBUG TRAIN Batch 230/3600 loss 50.618561 loss_att 30.678705 loss_ctc 97.144890 loss_ctc_origin 57.186245 loss_ctc0 190.381714 lr 0.00055219 rank 0
2022-08-27 00:09:10,748 DEBUG TRAIN Batch 230/3700 loss 17.782164 loss_att 9.406928 loss_ctc 37.324379 loss_ctc_origin 26.562719 loss_ctc0 62.434917 lr 0.00055217 rank 0
2022-08-27 00:09:37,427 DEBUG TRAIN Batch 230/3800 loss 21.620481 loss_att 8.497649 loss_ctc 52.240421 loss_ctc_origin 37.453758 loss_ctc0 86.742630 lr 0.00055215 rank 0
2022-08-27 00:10:05,205 DEBUG TRAIN Batch 230/3900 loss 23.604544 loss_att 9.958586 loss_ctc 55.445110 loss_ctc_origin 38.336143 loss_ctc0 95.366028 lr 0.00055213 rank 0
2022-08-27 00:10:33,842 DEBUG TRAIN Batch 230/4000 loss 40.611038 loss_att 24.681770 loss_ctc 77.779327 loss_ctc_origin 44.521301 loss_ctc0 155.381378 lr 0.00055211 rank 0
2022-08-27 00:10:59,893 DEBUG TRAIN Batch 230/4100 loss 47.504112 loss_att 26.981834 loss_ctc 95.389420 loss_ctc_origin 56.677876 loss_ctc0 185.716370 lr 0.00055209 rank 0
2022-08-27 00:11:27,363 DEBUG TRAIN Batch 230/4200 loss 18.828972 loss_att 10.828924 loss_ctc 37.495747 loss_ctc_origin 25.631447 loss_ctc0 65.179108 lr 0.00055206 rank 0
2022-08-27 00:11:37,685 WARNING NaN or Inf found in input tensor.
2022-08-27 00:11:54,504 DEBUG TRAIN Batch 230/4300 loss 21.204649 loss_att 8.466026 loss_ctc 50.928101 loss_ctc_origin 36.755844 loss_ctc0 83.996696 lr 0.00055204 rank 0
2022-08-27 00:12:21,589 DEBUG TRAIN Batch 230/4400 loss 24.408497 loss_att 9.767982 loss_ctc 58.569695 loss_ctc_origin 39.749058 loss_ctc0 102.484512 lr 0.00055202 rank 0
2022-08-27 00:12:56,360 DEBUG TRAIN Batch 230/4500 loss 43.651108 loss_att 27.755657 loss_ctc 80.740494 loss_ctc_origin 50.037872 loss_ctc0 152.379944 lr 0.00055200 rank 0
2022-08-27 00:13:23,925 DEBUG TRAIN Batch 230/4600 loss 46.361641 loss_att 25.202629 loss_ctc 95.732658 loss_ctc_origin 51.953674 loss_ctc0 197.883606 lr 0.00055198 rank 0
2022-08-27 00:13:51,576 DEBUG TRAIN Batch 230/4700 loss 16.341339 loss_att 8.034483 loss_ctc 35.724003 loss_ctc_origin 24.155359 loss_ctc0 62.717503 lr 0.00055196 rank 0
2022-08-27 00:14:19,008 DEBUG TRAIN Batch 230/4800 loss 20.278988 loss_att 8.582355 loss_ctc 47.571125 loss_ctc_origin 31.751583 loss_ctc0 84.483383 lr 0.00055194 rank 0
2022-08-27 00:14:46,737 DEBUG TRAIN Batch 230/4900 loss 22.202250 loss_att 7.982977 loss_ctc 55.380554 loss_ctc_origin 36.850548 loss_ctc0 98.617233 lr 0.00055192 rank 0
2022-08-27 00:15:15,663 DEBUG TRAIN Batch 230/5000 loss 49.225990 loss_att 33.915024 loss_ctc 84.951584 loss_ctc_origin 56.421875 loss_ctc0 151.520889 lr 0.00055190 rank 0
2022-08-27 00:15:42,831 DEBUG TRAIN Batch 230/5100 loss 45.741917 loss_att 26.713213 loss_ctc 90.142220 loss_ctc_origin 48.986092 loss_ctc0 186.173172 lr 0.00055188 rank 0
2022-08-27 00:16:11,702 DEBUG TRAIN Batch 230/5200 loss 22.187311 loss_att 10.596252 loss_ctc 49.233112 loss_ctc_origin 35.698677 loss_ctc0 80.813461 lr 0.00055185 rank 0
2022-08-27 00:16:39,674 DEBUG TRAIN Batch 230/5300 loss 18.266987 loss_att 6.926373 loss_ctc 44.728420 loss_ctc_origin 29.230703 loss_ctc0 80.889755 lr 0.00055183 rank 0
2022-08-27 00:17:08,575 DEBUG TRAIN Batch 230/5400 loss 18.586838 loss_att 6.618524 loss_ctc 46.512901 loss_ctc_origin 25.137571 loss_ctc0 96.388672 lr 0.00055181 rank 0
2022-08-27 00:17:36,905 DEBUG TRAIN Batch 230/5500 loss 45.503925 loss_att 30.579285 loss_ctc 80.328087 loss_ctc_origin 51.655975 loss_ctc0 147.229675 lr 0.00055179 rank 0
2022-08-27 00:18:05,452 DEBUG TRAIN Batch 230/5600 loss 46.193279 loss_att 20.353962 loss_ctc 106.485016 loss_ctc_origin 57.283478 loss_ctc0 221.288605 lr 0.00055177 rank 0
2022-08-27 00:18:27,425 DEBUG CV Batch 230/0 loss 12.230400 loss_att 9.212749 loss_ctc 19.271587 loss_ctc_origin 13.088991 loss_ctc0 33.697647 history loss 11.510965 rank 0
2022-08-27 00:18:37,337 DEBUG CV Batch 230/100 loss 21.079044 loss_att 17.443977 loss_ctc 29.560867 loss_ctc_origin 19.521534 loss_ctc0 52.985977 history loss 26.606702 rank 0
2022-08-27 00:18:48,057 DEBUG CV Batch 230/200 loss 25.561571 loss_att 20.361582 loss_ctc 37.694878 loss_ctc_origin 27.219265 loss_ctc0 62.137978 history loss 27.887728 rank 0
2022-08-27 00:18:58,681 DEBUG CV Batch 230/300 loss 22.330818 loss_att 16.992512 loss_ctc 34.786861 loss_ctc_origin 19.189966 loss_ctc0 71.179619 history loss 27.029577 rank 0
2022-08-27 00:19:07,593 DEBUG CV Batch 230/400 loss 37.382156 loss_att 30.127810 loss_ctc 54.308960 loss_ctc_origin 36.876896 loss_ctc0 94.983765 history loss 25.292386 rank 0
2022-08-27 00:19:16,400 DEBUG CV Batch 230/500 loss 16.007862 loss_att 11.594561 loss_ctc 26.305565 loss_ctc_origin 19.603842 loss_ctc0 41.942917 history loss 24.909867 rank 0
2022-08-27 00:19:24,924 DEBUG CV Batch 230/600 loss 18.368765 loss_att 13.315027 loss_ctc 30.160820 loss_ctc_origin 20.112453 loss_ctc0 53.607002 history loss 24.707969 rank 0
2022-08-27 00:19:33,823 DEBUG CV Batch 230/700 loss 18.694809 loss_att 13.530546 loss_ctc 30.744755 loss_ctc_origin 16.789551 loss_ctc0 63.306892 history loss 24.355443 rank 0
2022-08-27 00:19:43,328 DEBUG CV Batch 230/800 loss 21.670010 loss_att 16.901749 loss_ctc 32.795952 loss_ctc_origin 17.709877 loss_ctc0 67.996788 history loss 24.309726 rank 0
2022-08-27 00:19:52,835 INFO Epoch 230 CV info cv_loss 24.40122922363622
2022-08-27 00:19:52,835 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/230.pt
2022-08-27 00:19:53,285 INFO Epoch 231 TRAIN info lr 0.0005517523757787723
2022-08-27 00:19:53,289 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-27 00:20:19,000 DEBUG TRAIN Batch 231/0 loss 43.498032 loss_att 28.522093 loss_ctc 78.441879 loss_ctc_origin 50.030426 loss_ctc0 144.735260 lr 0.00055175 rank 0
2022-08-27 00:20:26,748 WARNING NaN or Inf found in input tensor.
2022-08-27 00:20:46,612 DEBUG TRAIN Batch 231/100 loss 55.234570 loss_att 30.011433 loss_ctc 114.088547 loss_ctc_origin 74.241219 loss_ctc0 207.065628 lr 0.00055173 rank 0
2022-08-27 00:21:13,505 DEBUG TRAIN Batch 231/200 loss 20.919617 loss_att 12.452762 loss_ctc 40.675606 loss_ctc_origin 29.333538 loss_ctc0 67.140427 lr 0.00055171 rank 0
2022-08-27 00:21:41,061 DEBUG TRAIN Batch 231/300 loss 20.575714 loss_att 8.579967 loss_ctc 48.565788 loss_ctc_origin 34.180126 loss_ctc0 82.132324 lr 0.00055169 rank 0
2022-08-27 00:22:09,270 DEBUG TRAIN Batch 231/400 loss 21.229706 loss_att 8.244496 loss_ctc 51.528526 loss_ctc_origin 31.960941 loss_ctc0 97.186234 lr 0.00055167 rank 0
2022-08-27 00:22:37,445 DEBUG TRAIN Batch 231/500 loss 42.278214 loss_att 26.781509 loss_ctc 78.437180 loss_ctc_origin 52.240536 loss_ctc0 139.562683 lr 0.00055165 rank 0
2022-08-27 00:23:05,132 DEBUG TRAIN Batch 231/600 loss 39.902309 loss_att 20.373446 loss_ctc 85.469658 loss_ctc_origin 41.976402 loss_ctc0 186.953903 lr 0.00055163 rank 0
2022-08-27 00:23:31,916 DEBUG TRAIN Batch 231/700 loss 17.404659 loss_att 9.225792 loss_ctc 36.488686 loss_ctc_origin 26.225334 loss_ctc0 60.436504 lr 0.00055160 rank 0
2022-08-27 00:23:59,612 DEBUG TRAIN Batch 231/800 loss 17.291279 loss_att 6.628619 loss_ctc 42.170815 loss_ctc_origin 24.443180 loss_ctc0 83.535286 lr 0.00055158 rank 0
2022-08-27 00:24:21,917 WARNING NaN or Inf found in input tensor.
2022-08-27 00:24:25,906 DEBUG TRAIN Batch 231/900 loss 20.992296 loss_att 8.948223 loss_ctc 49.095131 loss_ctc_origin 32.827881 loss_ctc0 87.052048 lr 0.00055156 rank 0
2022-08-27 00:24:28,359 WARNING NaN or Inf found in input tensor.
2022-08-27 00:24:55,395 DEBUG TRAIN Batch 231/1000 loss 46.903717 loss_att 30.447876 loss_ctc 85.300682 loss_ctc_origin 56.947868 loss_ctc0 151.457245 lr 0.00055154 rank 0
2022-08-27 00:25:07,676 WARNING NaN or Inf found in input tensor.
2022-08-27 00:25:22,242 DEBUG TRAIN Batch 231/1100 loss 45.420780 loss_att 23.348877 loss_ctc 96.921883 loss_ctc_origin 53.286961 loss_ctc0 198.736694 lr 0.00055152 rank 0
2022-08-27 00:25:48,556 DEBUG TRAIN Batch 231/1200 loss 18.803398 loss_att 10.974096 loss_ctc 37.071770 loss_ctc_origin 26.635698 loss_ctc0 61.422592 lr 0.00055150 rank 0
2022-08-27 00:26:16,265 DEBUG TRAIN Batch 231/1300 loss 20.122700 loss_att 8.353233 loss_ctc 47.584785 loss_ctc_origin 32.068298 loss_ctc0 83.789917 lr 0.00055148 rank 0
2022-08-27 00:26:44,168 DEBUG TRAIN Batch 231/1400 loss 20.001047 loss_att 7.665401 loss_ctc 48.784218 loss_ctc_origin 32.299286 loss_ctc0 87.249062 lr 0.00055146 rank 0
2022-08-27 00:27:19,577 DEBUG TRAIN Batch 231/1500 loss 56.083363 loss_att 36.452698 loss_ctc 101.888245 loss_ctc_origin 69.108765 loss_ctc0 178.373688 lr 0.00055144 rank 0
2022-08-27 00:27:47,475 DEBUG TRAIN Batch 231/1600 loss 51.429314 loss_att 27.030781 loss_ctc 108.359215 loss_ctc_origin 64.138535 loss_ctc0 211.540802 lr 0.00055142 rank 0
2022-08-27 00:28:14,471 DEBUG TRAIN Batch 231/1700 loss 17.839417 loss_att 8.543679 loss_ctc 39.529472 loss_ctc_origin 27.613386 loss_ctc0 67.333664 lr 0.00055139 rank 0
2022-08-27 00:28:41,975 DEBUG TRAIN Batch 231/1800 loss 19.656784 loss_att 7.905503 loss_ctc 47.076439 loss_ctc_origin 32.435364 loss_ctc0 81.238937 lr 0.00055137 rank 0
2022-08-27 00:29:10,673 DEBUG TRAIN Batch 231/1900 loss 24.111433 loss_att 10.168804 loss_ctc 56.644234 loss_ctc_origin 38.498337 loss_ctc0 98.984657 lr 0.00055135 rank 0
2022-08-27 00:29:39,002 DEBUG TRAIN Batch 231/2000 loss 45.821465 loss_att 30.137798 loss_ctc 82.416687 loss_ctc_origin 55.773811 loss_ctc0 144.583405 lr 0.00055133 rank 0
2022-08-27 00:30:06,272 DEBUG TRAIN Batch 231/2100 loss 52.929161 loss_att 31.089952 loss_ctc 103.887314 loss_ctc_origin 63.774826 loss_ctc0 197.483124 lr 0.00055131 rank 0
2022-08-27 00:30:34,686 DEBUG TRAIN Batch 231/2200 loss 21.514585 loss_att 10.692995 loss_ctc 46.764961 loss_ctc_origin 34.403999 loss_ctc0 75.607208 lr 0.00055129 rank 0
2022-08-27 00:31:01,668 DEBUG TRAIN Batch 231/2300 loss 21.099646 loss_att 8.086678 loss_ctc 51.463238 loss_ctc_origin 37.079437 loss_ctc0 85.025436 lr 0.00055127 rank 0
2022-08-27 00:31:05,347 WARNING NaN or Inf found in input tensor.
2022-08-27 00:31:28,752 DEBUG TRAIN Batch 231/2400 loss 19.594677 loss_att 7.673648 loss_ctc 47.410408 loss_ctc_origin 28.486370 loss_ctc0 91.566498 lr 0.00055125 rank 0
2022-08-27 00:31:57,655 DEBUG TRAIN Batch 231/2500 loss 39.858849 loss_att 23.748838 loss_ctc 77.448868 loss_ctc_origin 50.534298 loss_ctc0 140.249512 lr 0.00055123 rank 0
2022-08-27 00:32:23,180 DEBUG TRAIN Batch 231/2600 loss 47.818649 loss_att 25.488354 loss_ctc 99.922676 loss_ctc_origin 55.797558 loss_ctc0 202.881287 lr 0.00055121 rank 0
2022-08-27 00:32:49,985 DEBUG TRAIN Batch 231/2700 loss 18.475811 loss_att 7.828786 loss_ctc 43.318863 loss_ctc_origin 32.178703 loss_ctc0 69.312561 lr 0.00055119 rank 0
2022-08-27 00:33:18,181 DEBUG TRAIN Batch 231/2800 loss 19.791697 loss_att 7.957243 loss_ctc 47.405422 loss_ctc_origin 33.137062 loss_ctc0 80.698257 lr 0.00055116 rank 0
2022-08-27 00:33:34,918 WARNING NaN or Inf found in input tensor.
2022-08-27 00:33:42,121 WARNING NaN or Inf found in input tensor.
2022-08-27 00:33:46,373 DEBUG TRAIN Batch 231/2900 loss 21.664419 loss_att 8.609295 loss_ctc 52.126373 loss_ctc_origin 33.424099 loss_ctc0 95.765015 lr 0.00055114 rank 0
2022-08-27 00:34:19,780 DEBUG TRAIN Batch 231/3000 loss 45.481285 loss_att 30.463440 loss_ctc 80.522919 loss_ctc_origin 55.775345 loss_ctc0 138.267273 lr 0.00055112 rank 0
2022-08-27 00:34:47,453 DEBUG TRAIN Batch 231/3100 loss 44.373955 loss_att 24.665449 loss_ctc 90.360458 loss_ctc_origin 46.143700 loss_ctc0 193.532883 lr 0.00055110 rank 0
2022-08-27 00:35:15,189 DEBUG TRAIN Batch 231/3200 loss 16.112339 loss_att 7.130742 loss_ctc 37.069397 loss_ctc_origin 25.631306 loss_ctc0 63.758282 lr 0.00055108 rank 0
2022-08-27 00:35:43,336 DEBUG TRAIN Batch 231/3300 loss 19.296143 loss_att 7.773137 loss_ctc 46.183151 loss_ctc_origin 31.712975 loss_ctc0 79.946899 lr 0.00055106 rank 0
2022-08-27 00:36:10,295 DEBUG TRAIN Batch 231/3400 loss 22.465345 loss_att 8.509702 loss_ctc 55.028515 loss_ctc_origin 37.100147 loss_ctc0 96.861374 lr 0.00055104 rank 0
2022-08-27 00:36:39,011 DEBUG TRAIN Batch 231/3500 loss 55.895741 loss_att 36.822491 loss_ctc 100.399986 loss_ctc_origin 63.763245 loss_ctc0 185.885712 lr 0.00055102 rank 0
2022-08-27 00:37:05,615 DEBUG TRAIN Batch 231/3600 loss 60.516426 loss_att 32.447372 loss_ctc 126.010895 loss_ctc_origin 66.330597 loss_ctc0 265.264923 lr 0.00055100 rank 0
2022-08-27 00:37:33,314 DEBUG TRAIN Batch 231/3700 loss 20.786324 loss_att 11.442162 loss_ctc 42.589371 loss_ctc_origin 33.886036 loss_ctc0 62.897156 lr 0.00055098 rank 0
2022-08-27 00:38:01,418 DEBUG TRAIN Batch 231/3800 loss 17.024939 loss_att 6.691355 loss_ctc 41.136635 loss_ctc_origin 27.111521 loss_ctc0 73.861893 lr 0.00055096 rank 0
2022-08-27 00:38:28,131 DEBUG TRAIN Batch 231/3900 loss 20.890022 loss_att 8.581312 loss_ctc 49.610344 loss_ctc_origin 30.676973 loss_ctc0 93.788208 lr 0.00055093 rank 0
2022-08-27 00:38:57,572 DEBUG TRAIN Batch 231/4000 loss 41.522346 loss_att 26.339283 loss_ctc 76.949493 loss_ctc_origin 42.180866 loss_ctc0 158.076294 lr 0.00055091 rank 0
2022-08-27 00:39:24,123 DEBUG TRAIN Batch 231/4100 loss 49.926537 loss_att 27.190132 loss_ctc 102.978149 loss_ctc_origin 53.808258 loss_ctc0 217.707901 lr 0.00055089 rank 0
2022-08-27 00:39:50,821 DEBUG TRAIN Batch 231/4200 loss 21.951488 loss_att 10.103434 loss_ctc 49.596951 loss_ctc_origin 39.174812 loss_ctc0 73.915268 lr 0.00055087 rank 0
2022-08-27 00:40:19,263 DEBUG TRAIN Batch 231/4300 loss 17.549828 loss_att 7.013524 loss_ctc 42.134537 loss_ctc_origin 26.555199 loss_ctc0 78.486320 lr 0.00055085 rank 0
2022-08-27 00:40:46,998 DEBUG TRAIN Batch 231/4400 loss 19.565468 loss_att 7.137436 loss_ctc 48.564209 loss_ctc_origin 28.137001 loss_ctc0 96.227684 lr 0.00055083 rank 0
2022-08-27 00:41:20,708 DEBUG TRAIN Batch 231/4500 loss 49.831673 loss_att 30.712698 loss_ctc 94.442612 loss_ctc_origin 60.895908 loss_ctc0 172.718231 lr 0.00055081 rank 0
2022-08-27 00:41:35,268 WARNING NaN or Inf found in input tensor.
2022-08-27 00:41:48,366 DEBUG TRAIN Batch 231/4600 loss 58.060715 loss_att 30.745754 loss_ctc 121.795609 loss_ctc_origin 72.013718 loss_ctc0 237.953339 lr 0.00055079 rank 0
2022-08-27 00:42:16,159 DEBUG TRAIN Batch 231/4700 loss 19.324081 loss_att 10.516297 loss_ctc 39.875576 loss_ctc_origin 30.008293 loss_ctc0 62.899239 lr 0.00055077 rank 0
2022-08-27 00:42:44,161 DEBUG TRAIN Batch 231/4800 loss 17.932003 loss_att 6.720822 loss_ctc 44.091423 loss_ctc_origin 29.993454 loss_ctc0 76.986687 lr 0.00055075 rank 0
2022-08-27 00:43:11,725 DEBUG TRAIN Batch 231/4900 loss 22.414717 loss_att 8.509478 loss_ctc 54.860271 loss_ctc_origin 36.123768 loss_ctc0 98.578781 lr 0.00055073 rank 0
2022-08-27 00:43:39,913 DEBUG TRAIN Batch 231/5000 loss 45.270859 loss_att 30.501944 loss_ctc 79.731667 loss_ctc_origin 51.260178 loss_ctc0 146.165146 lr 0.00055070 rank 0
2022-08-27 00:44:06,179 WARNING NaN or Inf found in input tensor.
2022-08-27 00:44:06,974 DEBUG TRAIN Batch 231/5100 loss 50.301708 loss_att 27.912249 loss_ctc 102.543777 loss_ctc_origin 59.123917 loss_ctc0 203.856796 lr 0.00055068 rank 0
2022-08-27 00:44:35,526 DEBUG TRAIN Batch 231/5200 loss 17.288786 loss_att 9.083018 loss_ctc 36.435577 loss_ctc_origin 24.507000 loss_ctc0 64.268921 lr 0.00055066 rank 0
2022-08-27 00:45:03,219 DEBUG TRAIN Batch 231/5300 loss 17.063148 loss_att 6.159175 loss_ctc 42.505749 loss_ctc_origin 27.073076 loss_ctc0 78.515320 lr 0.00055064 rank 0
2022-08-27 00:45:31,723 DEBUG TRAIN Batch 231/5400 loss 19.309238 loss_att 7.780904 loss_ctc 46.208687 loss_ctc_origin 28.746161 loss_ctc0 86.954582 lr 0.00055062 rank 0
2022-08-27 00:45:58,681 DEBUG TRAIN Batch 231/5500 loss 40.658737 loss_att 24.617554 loss_ctc 78.088165 loss_ctc_origin 54.108139 loss_ctc0 134.041565 lr 0.00055060 rank 0
2022-08-27 00:46:27,890 DEBUG TRAIN Batch 231/5600 loss 52.906731 loss_att 31.695091 loss_ctc 102.400551 loss_ctc_origin 57.601536 loss_ctc0 206.931580 lr 0.00055058 rank 0
2022-08-27 00:46:35,097 WARNING NaN or Inf found in input tensor.
2022-08-27 00:46:53,407 DEBUG CV Batch 231/0 loss 11.540005 loss_att 8.480237 loss_ctc 18.679462 loss_ctc_origin 12.154812 loss_ctc0 33.903645 history loss 10.861181 rank 0
2022-08-27 00:47:03,025 DEBUG CV Batch 231/100 loss 21.907352 loss_att 18.444176 loss_ctc 29.988092 loss_ctc_origin 20.010139 loss_ctc0 53.269981 history loss 26.543928 rank 0
2022-08-27 00:47:11,970 DEBUG CV Batch 231/200 loss 24.967987 loss_att 19.770878 loss_ctc 37.094574 loss_ctc_origin 26.262024 loss_ctc0 62.370514 history loss 28.019930 rank 0
2022-08-27 00:47:21,061 DEBUG CV Batch 231/300 loss 22.317596 loss_att 17.104351 loss_ctc 34.481834 loss_ctc_origin 18.887476 loss_ctc0 70.868675 history loss 27.085158 rank 0
2022-08-27 00:47:30,365 DEBUG CV Batch 231/400 loss 37.841782 loss_att 30.424812 loss_ctc 55.148041 loss_ctc_origin 37.559753 loss_ctc0 96.187378 history loss 25.285464 rank 0
2022-08-27 00:47:40,030 DEBUG CV Batch 231/500 loss 16.316795 loss_att 12.362345 loss_ctc 25.543846 loss_ctc_origin 18.512112 loss_ctc0 41.951225 history loss 24.879328 rank 0
2022-08-27 00:47:49,574 DEBUG CV Batch 231/600 loss 18.489325 loss_att 13.072121 loss_ctc 31.129467 loss_ctc_origin 21.142010 loss_ctc0 54.433529 history loss 24.684312 rank 0
2022-08-27 00:47:59,024 DEBUG CV Batch 231/700 loss 20.126768 loss_att 14.751339 loss_ctc 32.669434 loss_ctc_origin 19.445602 loss_ctc0 63.525032 history loss 24.352038 rank 0
2022-08-27 00:48:08,627 DEBUG CV Batch 231/800 loss 21.890741 loss_att 17.143597 loss_ctc 32.967411 loss_ctc_origin 17.620485 loss_ctc0 68.776901 history loss 24.308856 rank 0
2022-08-27 00:48:18,028 INFO Epoch 231 CV info cv_loss 24.389293726835014
2022-08-27 00:48:18,028 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/231.pt
2022-08-27 00:48:18,588 INFO Epoch 232 TRAIN info lr 0.000550561970129264
2022-08-27 00:48:18,591 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-27 00:48:45,352 DEBUG TRAIN Batch 232/0 loss 47.574890 loss_att 32.278202 loss_ctc 83.267159 loss_ctc_origin 55.433544 loss_ctc0 148.212250 lr 0.00055056 rank 0
2022-08-27 00:49:13,451 DEBUG TRAIN Batch 232/100 loss 53.260273 loss_att 29.768181 loss_ctc 108.075150 loss_ctc_origin 59.800262 loss_ctc0 220.716537 lr 0.00055054 rank 0
2022-08-27 00:49:40,423 DEBUG TRAIN Batch 232/200 loss 17.495913 loss_att 8.302856 loss_ctc 38.946377 loss_ctc_origin 27.354321 loss_ctc0 65.994507 lr 0.00055052 rank 0
2022-08-27 00:50:08,248 DEBUG TRAIN Batch 232/300 loss 21.723801 loss_att 9.942177 loss_ctc 49.214256 loss_ctc_origin 36.846523 loss_ctc0 78.072296 lr 0.00055050 rank 0
2022-08-27 00:50:36,284 DEBUG TRAIN Batch 232/400 loss 24.719381 loss_att 10.985144 loss_ctc 56.765938 loss_ctc_origin 41.095184 loss_ctc0 93.331024 lr 0.00055048 rank 0
2022-08-27 00:51:04,320 DEBUG TRAIN Batch 232/500 loss 46.589577 loss_att 31.752449 loss_ctc 81.209541 loss_ctc_origin 50.434906 loss_ctc0 153.017029 lr 0.00055046 rank 0
2022-08-27 00:51:31,076 DEBUG TRAIN Batch 232/600 loss 50.745438 loss_att 26.902180 loss_ctc 106.379707 loss_ctc_origin 58.080040 loss_ctc0 219.078918 lr 0.00055044 rank 0
2022-08-27 00:51:59,656 DEBUG TRAIN Batch 232/700 loss 21.289291 loss_att 9.969477 loss_ctc 47.702194 loss_ctc_origin 36.576931 loss_ctc0 73.661140 lr 0.00055042 rank 0
2022-08-27 00:52:29,428 DEBUG TRAIN Batch 232/800 loss 25.535988 loss_att 10.884542 loss_ctc 59.722687 loss_ctc_origin 47.921593 loss_ctc0 87.258583 lr 0.00055039 rank 0
2022-08-27 00:52:51,203 WARNING NaN or Inf found in input tensor.
2022-08-27 00:52:55,802 DEBUG TRAIN Batch 232/900 loss 26.029438 loss_att 11.132856 loss_ctc 60.788128 loss_ctc_origin 45.624458 loss_ctc0 96.170021 lr 0.00055037 rank 0
2022-08-27 00:53:23,344 DEBUG TRAIN Batch 232/1000 loss 48.987152 loss_att 33.632839 loss_ctc 84.813873 loss_ctc_origin 53.151684 loss_ctc0 158.692322 lr 0.00055035 rank 0
2022-08-27 00:53:51,488 WARNING NaN or Inf found in input tensor.
2022-08-27 00:53:51,528 DEBUG TRAIN Batch 232/1100 loss nan loss_att 37.163235 loss_ctc nan loss_ctc_origin 63.023739 loss_ctc0 nan lr 0.00055033 rank 0
2022-08-27 00:54:09,512 WARNING NaN or Inf found in input tensor.
2022-08-27 00:54:19,228 DEBUG TRAIN Batch 232/1200 loss 18.450871 loss_att 8.448450 loss_ctc 41.789852 loss_ctc_origin 30.225536 loss_ctc0 68.773254 lr 0.00055031 rank 0
2022-08-27 00:54:47,183 DEBUG TRAIN Batch 232/1300 loss 25.081614 loss_att 12.244600 loss_ctc 55.034641 loss_ctc_origin 40.677879 loss_ctc0 88.533745 lr 0.00055029 rank 0
2022-08-27 00:55:14,676 DEBUG TRAIN Batch 232/1400 loss 26.876736 loss_att 11.669675 loss_ctc 62.359871 loss_ctc_origin 45.955547 loss_ctc0 100.636627 lr 0.00055027 rank 0
2022-08-27 00:55:49,050 DEBUG TRAIN Batch 232/1500 loss 50.275700 loss_att 32.342739 loss_ctc 92.119270 loss_ctc_origin 64.144745 loss_ctc0 157.393158 lr 0.00055025 rank 0
2022-08-27 00:56:16,470 DEBUG TRAIN Batch 232/1600 loss 50.240665 loss_att 27.078424 loss_ctc 104.285889 loss_ctc_origin 55.207886 loss_ctc0 218.801208 lr 0.00055023 rank 0
2022-08-27 00:56:44,196 DEBUG TRAIN Batch 232/1700 loss 22.916988 loss_att 11.848546 loss_ctc 48.743347 loss_ctc_origin 38.905540 loss_ctc0 71.698227 lr 0.00055021 rank 0
2022-08-27 00:57:11,569 DEBUG TRAIN Batch 232/1800 loss 20.093161 loss_att 8.576355 loss_ctc 46.965706 loss_ctc_origin 33.281860 loss_ctc0 78.894669 lr 0.00055019 rank 0
2022-08-27 00:57:39,242 DEBUG TRAIN Batch 232/1900 loss 24.691273 loss_att 10.275555 loss_ctc 58.327946 loss_ctc_origin 41.561363 loss_ctc0 97.449966 lr 0.00055017 rank 0
2022-08-27 00:58:07,856 DEBUG TRAIN Batch 232/2000 loss 52.232468 loss_att 33.997688 loss_ctc 94.780273 loss_ctc_origin 59.636230 loss_ctc0 176.783020 lr 0.00055014 rank 0
2022-08-27 00:58:34,308 DEBUG TRAIN Batch 232/2100 loss 62.965973 loss_att 35.101456 loss_ctc 127.983177 loss_ctc_origin 71.713432 loss_ctc0 259.279236 lr 0.00055012 rank 0
2022-08-27 00:59:01,734 DEBUG TRAIN Batch 232/2200 loss 21.122086 loss_att 10.036984 loss_ctc 46.987320 loss_ctc_origin 36.786682 loss_ctc0 70.788803 lr 0.00055010 rank 0
2022-08-27 00:59:29,692 DEBUG TRAIN Batch 232/2300 loss 18.825905 loss_att 8.315104 loss_ctc 43.351109 loss_ctc_origin 28.464640 loss_ctc0 78.086205 lr 0.00055008 rank 0
2022-08-27 00:59:58,231 DEBUG TRAIN Batch 232/2400 loss 24.113134 loss_att 9.182796 loss_ctc 58.950584 loss_ctc_origin 42.303780 loss_ctc0 97.793121 lr 0.00055006 rank 0
2022-08-27 01:00:25,721 DEBUG TRAIN Batch 232/2500 loss 47.233253 loss_att 29.408772 loss_ctc 88.823715 loss_ctc_origin 61.227013 loss_ctc0 153.216019 lr 0.00055004 rank 0
2022-08-27 01:00:54,275 DEBUG TRAIN Batch 232/2600 loss 55.312428 loss_att 30.154064 loss_ctc 114.015266 loss_ctc_origin 63.276226 loss_ctc0 232.406342 lr 0.00055002 rank 0
2022-08-27 01:01:20,339 WARNING NaN or Inf found in input tensor.
2022-08-27 01:01:21,767 DEBUG TRAIN Batch 232/2700 loss 19.494720 loss_att 10.221446 loss_ctc 41.132362 loss_ctc_origin 29.450665 loss_ctc0 68.389664 lr 0.00055000 rank 0
2022-08-27 01:01:50,639 DEBUG TRAIN Batch 232/2800 loss 24.271107 loss_att 10.532188 loss_ctc 56.328579 loss_ctc_origin 42.408760 loss_ctc0 88.808151 lr 0.00054998 rank 0
2022-08-27 01:02:18,209 DEBUG TRAIN Batch 232/2900 loss 18.341261 loss_att 7.110584 loss_ctc 44.546169 loss_ctc_origin 24.719589 loss_ctc0 90.808182 lr 0.00054996 rank 0
2022-08-27 01:02:53,244 DEBUG TRAIN Batch 232/3000 loss 54.483894 loss_att 34.186760 loss_ctc 101.843872 loss_ctc_origin 64.345856 loss_ctc0 189.339233 lr 0.00054994 rank 0
2022-08-27 01:03:21,195 DEBUG TRAIN Batch 232/3100 loss 51.181038 loss_att 28.242878 loss_ctc 104.703407 loss_ctc_origin 63.091900 loss_ctc0 201.796921 lr 0.00054992 rank 0
2022-08-27 01:03:48,598 DEBUG TRAIN Batch 232/3200 loss 22.781065 loss_att 11.130207 loss_ctc 49.966400 loss_ctc_origin 39.957512 loss_ctc0 73.320473 lr 0.00054989 rank 0
2022-08-27 01:04:16,492 DEBUG TRAIN Batch 232/3300 loss 19.457888 loss_att 9.024380 loss_ctc 43.802738 loss_ctc_origin 30.302547 loss_ctc0 75.303185 lr 0.00054987 rank 0
2022-08-27 01:04:43,940 DEBUG TRAIN Batch 232/3400 loss 22.001446 loss_att 8.005307 loss_ctc 54.659096 loss_ctc_origin 37.422775 loss_ctc0 94.877182 lr 0.00054985 rank 0
2022-08-27 01:05:12,166 DEBUG TRAIN Batch 232/3500 loss 49.717049 loss_att 33.924221 loss_ctc 86.566971 loss_ctc_origin 58.483566 loss_ctc0 152.094910 lr 0.00054983 rank 0
2022-08-27 01:05:39,816 DEBUG TRAIN Batch 232/3600 loss 51.136887 loss_att 28.415451 loss_ctc 104.153564 loss_ctc_origin 54.788116 loss_ctc0 219.339584 lr 0.00054981 rank 0
2022-08-27 01:06:07,192 DEBUG TRAIN Batch 232/3700 loss 20.312111 loss_att 10.796326 loss_ctc 42.515606 loss_ctc_origin 31.073952 loss_ctc0 69.212799 lr 0.00054979 rank 0
2022-08-27 01:06:35,547 DEBUG TRAIN Batch 232/3800 loss 15.429514 loss_att 5.702373 loss_ctc 38.126175 loss_ctc_origin 21.830410 loss_ctc0 76.149628 lr 0.00054977 rank 0
2022-08-27 01:07:03,248 DEBUG TRAIN Batch 232/3900 loss 27.998686 loss_att 12.102089 loss_ctc 65.090744 loss_ctc_origin 48.049927 loss_ctc0 104.852646 lr 0.00054975 rank 0
2022-08-27 01:07:31,142 DEBUG TRAIN Batch 232/4000 loss 45.063286 loss_att 28.380352 loss_ctc 83.990128 loss_ctc_origin 54.274376 loss_ctc0 153.326874 lr 0.00054973 rank 0
2022-08-27 01:07:58,887 WARNING NaN or Inf found in input tensor.
2022-08-27 01:07:58,926 DEBUG TRAIN Batch 232/4100 loss nan loss_att 26.230854 loss_ctc nan loss_ctc_origin 58.470116 loss_ctc0 nan lr 0.00054971 rank 0
2022-08-27 01:08:25,710 DEBUG TRAIN Batch 232/4200 loss 17.726757 loss_att 9.366795 loss_ctc 37.233337 loss_ctc_origin 25.740410 loss_ctc0 64.050171 lr 0.00054969 rank 0
2022-08-27 01:08:53,333 DEBUG TRAIN Batch 232/4300 loss 19.893946 loss_att 7.801111 loss_ctc 48.110558 loss_ctc_origin 33.861992 loss_ctc0 81.357208 lr 0.00054967 rank 0
2022-08-27 01:09:21,220 DEBUG TRAIN Batch 232/4400 loss 18.620800 loss_att 7.183276 loss_ctc 45.308357 loss_ctc_origin 27.494730 loss_ctc0 86.873474 lr 0.00054965 rank 0
2022-08-27 01:09:53,217 DEBUG TRAIN Batch 232/4500 loss 46.698311 loss_att 31.719418 loss_ctc 81.649055 loss_ctc_origin 52.708260 loss_ctc0 149.177567 lr 0.00054962 rank 0
2022-08-27 01:10:07,048 WARNING NaN or Inf found in input tensor.
2022-08-27 01:10:20,323 DEBUG TRAIN Batch 232/4600 loss 58.352921 loss_att 37.226326 loss_ctc 107.648315 loss_ctc_origin 66.708725 loss_ctc0 203.174042 lr 0.00054960 rank 0
2022-08-27 01:10:48,107 DEBUG TRAIN Batch 232/4700 loss 17.484453 loss_att 7.868491 loss_ctc 39.921700 loss_ctc_origin 27.088327 loss_ctc0 69.866241 lr 0.00054958 rank 0
2022-08-27 01:11:16,267 DEBUG TRAIN Batch 232/4800 loss 19.979650 loss_att 8.866873 loss_ctc 45.909462 loss_ctc_origin 31.473793 loss_ctc0 79.592697 lr 0.00054956 rank 0
2022-08-27 01:11:43,532 DEBUG TRAIN Batch 232/4900 loss 19.678246 loss_att 7.339670 loss_ctc 48.468254 loss_ctc_origin 31.167641 loss_ctc0 88.836349 lr 0.00054954 rank 0
2022-08-27 01:12:11,835 DEBUG TRAIN Batch 232/5000 loss 37.590317 loss_att 23.106060 loss_ctc 71.386917 loss_ctc_origin 42.507278 loss_ctc0 138.772736 lr 0.00054952 rank 0
2022-08-27 01:12:39,200 DEBUG TRAIN Batch 232/5100 loss 42.383541 loss_att 21.818405 loss_ctc 90.368851 loss_ctc_origin 46.099567 loss_ctc0 193.663849 lr 0.00054950 rank 0
2022-08-27 01:13:06,280 DEBUG TRAIN Batch 232/5200 loss 19.845291 loss_att 9.783855 loss_ctc 43.321972 loss_ctc_origin 33.823280 loss_ctc0 65.485580 lr 0.00054948 rank 0
2022-08-27 01:13:33,327 DEBUG TRAIN Batch 232/5300 loss 21.157015 loss_att 8.422595 loss_ctc 50.870663 loss_ctc_origin 36.992439 loss_ctc0 83.253181 lr 0.00054946 rank 0
2022-08-27 01:14:00,821 DEBUG TRAIN Batch 232/5400 loss 20.544106 loss_att 8.343653 loss_ctc 49.011826 loss_ctc_origin 28.223011 loss_ctc0 97.519066 lr 0.00054944 rank 0
2022-08-27 01:14:29,267 DEBUG TRAIN Batch 232/5500 loss 52.109657 loss_att 35.725677 loss_ctc 90.338943 loss_ctc_origin 59.302368 loss_ctc0 162.757614 lr 0.00054942 rank 0
2022-08-27 01:14:56,567 DEBUG TRAIN Batch 232/5600 loss 53.359783 loss_att 26.682091 loss_ctc 115.607727 loss_ctc_origin 67.567352 loss_ctc0 227.701920 lr 0.00054940 rank 0
2022-08-27 01:15:17,890 DEBUG CV Batch 232/0 loss 11.677267 loss_att 8.610736 loss_ctc 18.832504 loss_ctc_origin 12.331287 loss_ctc0 34.002014 history loss 10.990369 rank 0
2022-08-27 01:15:27,425 DEBUG CV Batch 232/100 loss 21.778194 loss_att 17.868299 loss_ctc 30.901279 loss_ctc_origin 21.303417 loss_ctc0 53.296288 history loss 26.429971 rank 0
2022-08-27 01:15:36,146 DEBUG CV Batch 232/200 loss 24.570808 loss_att 19.231865 loss_ctc 37.028343 loss_ctc_origin 26.410414 loss_ctc0 61.803509 history loss 27.802900 rank 0
2022-08-27 01:15:45,230 DEBUG CV Batch 232/300 loss 23.876362 loss_att 18.154503 loss_ctc 37.227364 loss_ctc_origin 22.558697 loss_ctc0 71.454254 history loss 26.979990 rank 0
2022-08-27 01:15:54,747 DEBUG CV Batch 232/400 loss 38.370899 loss_att 30.903408 loss_ctc 55.795044 loss_ctc_origin 38.896709 loss_ctc0 95.224487 history loss 25.296115 rank 0
2022-08-27 01:16:04,074 DEBUG CV Batch 232/500 loss 16.558273 loss_att 12.173988 loss_ctc 26.788271 loss_ctc_origin 20.184853 loss_ctc0 42.196247 history loss 24.940775 rank 0
2022-08-27 01:16:13,664 DEBUG CV Batch 232/600 loss 18.513573 loss_att 13.347497 loss_ctc 30.567753 loss_ctc_origin 20.609297 loss_ctc0 53.804150 history loss 24.784292 rank 0
2022-08-27 01:16:22,684 DEBUG CV Batch 232/700 loss 19.321947 loss_att 14.069971 loss_ctc 31.576557 loss_ctc_origin 17.863091 loss_ctc0 63.574650 history loss 24.462034 rank 0
2022-08-27 01:16:31,919 DEBUG CV Batch 232/800 loss 22.508682 loss_att 17.588686 loss_ctc 33.988670 loss_ctc_origin 18.996384 loss_ctc0 68.970673 history loss 24.422198 rank 0
2022-08-27 01:16:41,608 INFO Epoch 232 CV info cv_loss 24.516731044406907
2022-08-27 01:16:41,608 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/232.pt
2022-08-27 01:16:42,051 INFO Epoch 233 TRAIN info lr 0.00054937923628177
2022-08-27 01:16:42,055 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-27 01:17:08,482 DEBUG TRAIN Batch 233/0 loss 48.703041 loss_att 29.768002 loss_ctc 92.884804 loss_ctc_origin 57.233200 loss_ctc0 176.071869 lr 0.00054938 rank 0
2022-08-27 01:17:36,471 DEBUG TRAIN Batch 233/100 loss 54.777779 loss_att 32.285362 loss_ctc 107.260086 loss_ctc_origin 60.508453 loss_ctc0 216.347244 lr 0.00054936 rank 0
2022-08-27 01:18:02,401 WARNING NaN or Inf found in input tensor.
2022-08-27 01:18:04,101 DEBUG TRAIN Batch 233/200 loss 19.404425 loss_att 9.926804 loss_ctc 41.518875 loss_ctc_origin 31.006718 loss_ctc0 66.047241 lr 0.00054934 rank 0
2022-08-27 01:18:31,809 DEBUG TRAIN Batch 233/300 loss 19.486748 loss_att 7.922286 loss_ctc 46.470490 loss_ctc_origin 31.119183 loss_ctc0 82.290192 lr 0.00054932 rank 0
2022-08-27 01:18:42,514 WARNING NaN or Inf found in input tensor.
2022-08-27 01:18:59,720 DEBUG TRAIN Batch 233/400 loss 18.357117 loss_att 7.855028 loss_ctc 42.861992 loss_ctc_origin 22.801231 loss_ctc0 89.670433 lr 0.00054930 rank 0
2022-08-27 01:19:28,374 DEBUG TRAIN Batch 233/500 loss 46.342216 loss_att 29.934515 loss_ctc 84.626846 loss_ctc_origin 48.255020 loss_ctc0 169.494415 lr 0.00054927 rank 0
2022-08-27 01:19:54,624 DEBUG TRAIN Batch 233/600 loss 57.780109 loss_att 32.409008 loss_ctc 116.979340 loss_ctc_origin 68.167084 loss_ctc0 230.874603 lr 0.00054925 rank 0
2022-08-27 01:20:21,081 DEBUG TRAIN Batch 233/700 loss 18.367649 loss_att 9.554272 loss_ctc 38.932194 loss_ctc_origin 28.908695 loss_ctc0 62.320354 lr 0.00054923 rank 0
2022-08-27 01:20:48,521 DEBUG TRAIN Batch 233/800 loss 17.017422 loss_att 6.412038 loss_ctc 41.763321 loss_ctc_origin 28.941772 loss_ctc0 71.680267 lr 0.00054921 rank 0
2022-08-27 01:21:17,226 DEBUG TRAIN Batch 233/900 loss 22.056490 loss_att 9.065016 loss_ctc 52.369930 loss_ctc_origin 34.514023 loss_ctc0 94.033714 lr 0.00054919 rank 0
2022-08-27 01:21:45,008 DEBUG TRAIN Batch 233/1000 loss 29.491659 loss_att 16.195221 loss_ctc 60.516682 loss_ctc_origin 33.651375 loss_ctc0 123.202393 lr 0.00054917 rank 0
2022-08-27 01:22:12,914 DEBUG TRAIN Batch 233/1100 loss 40.562138 loss_att 20.860540 loss_ctc 86.532532 loss_ctc_origin 45.676960 loss_ctc0 181.862198 lr 0.00054915 rank 0
2022-08-27 01:22:41,496 DEBUG TRAIN Batch 233/1200 loss 15.290609 loss_att 7.534045 loss_ctc 33.389259 loss_ctc_origin 21.369991 loss_ctc0 61.434216 lr 0.00054913 rank 0
2022-08-27 01:23:10,110 DEBUG TRAIN Batch 233/1300 loss 16.530409 loss_att 6.263113 loss_ctc 40.487427 loss_ctc_origin 24.695688 loss_ctc0 77.334808 lr 0.00054911 rank 0
2022-08-27 01:23:26,870 WARNING NaN or Inf found in input tensor.
2022-08-27 01:23:38,019 DEBUG TRAIN Batch 233/1400 loss 20.207052 loss_att 6.794930 loss_ctc 51.501999 loss_ctc_origin 32.622379 loss_ctc0 95.554451 lr 0.00054909 rank 0
2022-08-27 01:24:12,485 DEBUG TRAIN Batch 233/1500 loss 48.278782 loss_att 32.593628 loss_ctc 84.877472 loss_ctc_origin 52.609268 loss_ctc0 160.169922 lr 0.00054907 rank 0
2022-08-27 01:24:39,937 DEBUG TRAIN Batch 233/1600 loss 52.467346 loss_att 28.892090 loss_ctc 107.476273 loss_ctc_origin 61.039909 loss_ctc0 215.827774 lr 0.00054905 rank 0
2022-08-27 01:25:06,908 DEBUG TRAIN Batch 233/1700 loss 18.042955 loss_att 9.153282 loss_ctc 38.785526 loss_ctc_origin 26.416122 loss_ctc0 67.647469 lr 0.00054903 rank 0
2022-08-27 01:25:34,622 DEBUG TRAIN Batch 233/1800 loss 21.282227 loss_att 8.450796 loss_ctc 51.222229 loss_ctc_origin 34.281746 loss_ctc0 90.750015 lr 0.00054901 rank 0
2022-08-27 01:26:01,623 DEBUG TRAIN Batch 233/1900 loss 18.449728 loss_att 6.925807 loss_ctc 45.338875 loss_ctc_origin 26.470560 loss_ctc0 89.364937 lr 0.00054899 rank 0
2022-08-27 01:26:29,783 DEBUG TRAIN Batch 233/2000 loss 37.938652 loss_att 22.739973 loss_ctc 73.402229 loss_ctc_origin 44.101921 loss_ctc0 141.769623 lr 0.00054896 rank 0
2022-08-27 01:26:37,035 WARNING NaN or Inf found in input tensor.
2022-08-27 01:26:56,573 DEBUG TRAIN Batch 233/2100 loss 45.373077 loss_att 23.023670 loss_ctc 97.521683 loss_ctc_origin 47.718498 loss_ctc0 213.729111 lr 0.00054894 rank 0
2022-08-27 01:27:23,961 DEBUG TRAIN Batch 233/2200 loss 19.306583 loss_att 10.187124 loss_ctc 40.585320 loss_ctc_origin 30.625650 loss_ctc0 63.824547 lr 0.00054892 rank 0
2022-08-27 01:27:52,477 DEBUG TRAIN Batch 233/2300 loss 21.648003 loss_att 7.887603 loss_ctc 53.755600 loss_ctc_origin 39.067390 loss_ctc0 88.028091 lr 0.00054890 rank 0
2022-08-27 01:28:19,842 DEBUG TRAIN Batch 233/2400 loss 21.210356 loss_att 8.778738 loss_ctc 50.217461 loss_ctc_origin 31.537674 loss_ctc0 93.803627 lr 0.00054888 rank 0
2022-08-27 01:28:47,304 DEBUG TRAIN Batch 233/2500 loss 43.710270 loss_att 28.642208 loss_ctc 78.869080 loss_ctc_origin 51.147865 loss_ctc0 143.551895 lr 0.00054886 rank 0
2022-08-27 01:29:00,312 WARNING NaN or Inf found in input tensor.
2022-08-27 01:29:14,743 DEBUG TRAIN Batch 233/2600 loss 48.959602 loss_att 27.157631 loss_ctc 99.830872 loss_ctc_origin 52.138115 loss_ctc0 211.113953 lr 0.00054884 rank 0
2022-08-27 01:29:31,168 WARNING NaN or Inf found in input tensor.
2022-08-27 01:29:41,171 DEBUG TRAIN Batch 233/2700 loss 16.358301 loss_att 8.207952 loss_ctc 35.375778 loss_ctc_origin 22.678463 loss_ctc0 65.002853 lr 0.00054882 rank 0
2022-08-27 01:30:08,606 DEBUG TRAIN Batch 233/2800 loss 19.098873 loss_att 7.943631 loss_ctc 45.127769 loss_ctc_origin 31.208496 loss_ctc0 77.606064 lr 0.00054880 rank 0
2022-08-27 01:30:35,448 DEBUG TRAIN Batch 233/2900 loss 16.398819 loss_att 5.897196 loss_ctc 40.902603 loss_ctc_origin 20.770943 loss_ctc0 87.876480 lr 0.00054878 rank 0
2022-08-27 01:31:09,842 DEBUG TRAIN Batch 233/3000 loss 46.959194 loss_att 31.186419 loss_ctc 83.762337 loss_ctc_origin 58.232361 loss_ctc0 143.332275 lr 0.00054876 rank 0
2022-08-27 01:31:37,789 DEBUG TRAIN Batch 233/3100 loss 51.179482 loss_att 28.989464 loss_ctc 102.956192 loss_ctc_origin 62.325756 loss_ctc0 197.760544 lr 0.00054874 rank 0
2022-08-27 01:32:06,262 DEBUG TRAIN Batch 233/3200 loss 17.587944 loss_att 9.207934 loss_ctc 37.141304 loss_ctc_origin 26.030083 loss_ctc0 63.067490 lr 0.00054872 rank 0
2022-08-27 01:32:18,331 WARNING NaN or Inf found in input tensor.
2022-08-27 01:32:33,306 DEBUG TRAIN Batch 233/3300 loss 18.019043 loss_att 7.474016 loss_ctc 42.624107 loss_ctc_origin 28.607071 loss_ctc0 75.330528 lr 0.00054870 rank 0
2022-08-27 01:33:01,358 DEBUG TRAIN Batch 233/3400 loss 24.314772 loss_att 9.619001 loss_ctc 58.604897 loss_ctc_origin 41.160248 loss_ctc0 99.309067 lr 0.00054868 rank 0
2022-08-27 01:33:30,070 DEBUG TRAIN Batch 233/3500 loss 44.864456 loss_att 27.702190 loss_ctc 84.909737 loss_ctc_origin 55.471741 loss_ctc0 153.598389 lr 0.00054865 rank 0
2022-08-27 01:33:55,344 DEBUG TRAIN Batch 233/3600 loss 49.402702 loss_att 25.098984 loss_ctc 106.111374 loss_ctc_origin 55.653740 loss_ctc0 223.845840 lr 0.00054863 rank 0
2022-08-27 01:34:23,005 DEBUG TRAIN Batch 233/3700 loss 17.064779 loss_att 8.042674 loss_ctc 38.116356 loss_ctc_origin 27.968863 loss_ctc0 61.793842 lr 0.00054861 rank 0
2022-08-27 01:34:52,302 DEBUG TRAIN Batch 233/3800 loss 19.372498 loss_att 8.105764 loss_ctc 45.661541 loss_ctc_origin 30.083963 loss_ctc0 82.009216 lr 0.00054859 rank 0
2022-08-27 01:35:20,366 DEBUG TRAIN Batch 233/3900 loss 19.855095 loss_att 7.715213 loss_ctc 48.181488 loss_ctc_origin 29.394606 loss_ctc0 92.017540 lr 0.00054857 rank 0
2022-08-27 01:35:48,349 DEBUG TRAIN Batch 233/4000 loss 44.299278 loss_att 30.659893 loss_ctc 76.124512 loss_ctc_origin 50.819122 loss_ctc0 135.170410 lr 0.00054855 rank 0
2022-08-27 01:36:16,848 DEBUG TRAIN Batch 233/4100 loss 52.748573 loss_att 31.105103 loss_ctc 103.250000 loss_ctc_origin 59.917107 loss_ctc0 204.360062 lr 0.00054853 rank 0
2022-08-27 01:36:44,015 DEBUG TRAIN Batch 233/4200 loss 17.431303 loss_att 9.088905 loss_ctc 36.896896 loss_ctc_origin 25.303593 loss_ctc0 63.947937 lr 0.00054851 rank 0
2022-08-27 01:37:10,966 DEBUG TRAIN Batch 233/4300 loss 15.839090 loss_att 6.303144 loss_ctc 38.089630 loss_ctc_origin 23.610842 loss_ctc0 71.873459 lr 0.00054849 rank 0
2022-08-27 01:37:34,703 WARNING NaN or Inf found in input tensor.
2022-08-27 01:37:39,036 DEBUG TRAIN Batch 233/4400 loss 21.267464 loss_att 8.503206 loss_ctc 51.050728 loss_ctc_origin 34.952156 loss_ctc0 88.614059 lr 0.00054847 rank 0
2022-08-27 01:38:12,433 DEBUG TRAIN Batch 233/4500 loss 48.946602 loss_att 32.648258 loss_ctc 86.976067 loss_ctc_origin 58.438644 loss_ctc0 153.563385 lr 0.00054845 rank 0
2022-08-27 01:38:39,650 DEBUG TRAIN Batch 233/4600 loss 49.824753 loss_att 26.945240 loss_ctc 103.210281 loss_ctc_origin 57.585632 loss_ctc0 209.667786 lr 0.00054843 rank 0
2022-08-27 01:39:07,681 DEBUG TRAIN Batch 233/4700 loss 20.883718 loss_att 10.139046 loss_ctc 45.954620 loss_ctc_origin 33.713326 loss_ctc0 74.517647 lr 0.00054841 rank 0
2022-08-27 01:39:35,392 DEBUG TRAIN Batch 233/4800 loss 20.472672 loss_att 8.596724 loss_ctc 48.183216 loss_ctc_origin 35.350288 loss_ctc0 78.126717 lr 0.00054839 rank 0
2022-08-27 01:40:02,547 DEBUG TRAIN Batch 233/4900 loss 21.465595 loss_att 8.832026 loss_ctc 50.943924 loss_ctc_origin 35.350685 loss_ctc0 87.328140 lr 0.00054837 rank 0
2022-08-27 01:40:30,651 DEBUG TRAIN Batch 233/5000 loss 54.137913 loss_att 36.545441 loss_ctc 95.187012 loss_ctc_origin 62.880032 loss_ctc0 170.569977 lr 0.00054835 rank 0
2022-08-27 01:40:57,160 DEBUG TRAIN Batch 233/5100 loss 59.101479 loss_att 33.598545 loss_ctc 118.608322 loss_ctc_origin 68.287178 loss_ctc0 236.024323 lr 0.00054832 rank 0
2022-08-27 01:41:25,160 DEBUG TRAIN Batch 233/5200 loss 16.599598 loss_att 8.221806 loss_ctc 36.147778 loss_ctc_origin 24.175312 loss_ctc0 64.083527 lr 0.00054830 rank 0
2022-08-27 01:41:30,249 WARNING NaN or Inf found in input tensor.
2022-08-27 01:41:53,656 DEBUG TRAIN Batch 233/5300 loss 17.578468 loss_att 7.192863 loss_ctc 41.811546 loss_ctc_origin 26.770706 loss_ctc0 76.906830 lr 0.00054828 rank 0
2022-08-27 01:42:20,977 DEBUG TRAIN Batch 233/5400 loss 22.059929 loss_att 8.262234 loss_ctc 54.254547 loss_ctc_origin 33.244667 loss_ctc0 103.277603 lr 0.00054826 rank 0
2022-08-27 01:42:49,050 DEBUG TRAIN Batch 233/5500 loss 50.729385 loss_att 33.706039 loss_ctc 90.450531 loss_ctc_origin 56.840397 loss_ctc0 168.874161 lr 0.00054824 rank 0
2022-08-27 01:43:17,512 DEBUG TRAIN Batch 233/5600 loss 60.414688 loss_att 38.648445 loss_ctc 111.202576 loss_ctc_origin 73.166466 loss_ctc0 199.953476 lr 0.00054822 rank 0
2022-08-27 01:43:39,134 DEBUG CV Batch 233/0 loss 12.028348 loss_att 9.079672 loss_ctc 18.908592 loss_ctc_origin 12.596052 loss_ctc0 33.637852 history loss 11.320798 rank 0
2022-08-27 01:43:48,788 DEBUG CV Batch 233/100 loss 20.378803 loss_att 16.892305 loss_ctc 28.513964 loss_ctc_origin 18.120796 loss_ctc0 52.764687 history loss 26.405746 rank 0
2022-08-27 01:43:57,613 DEBUG CV Batch 233/200 loss 25.389156 loss_att 19.956642 loss_ctc 38.065025 loss_ctc_origin 27.687954 loss_ctc0 62.278198 history loss 27.683203 rank 0
2022-08-27 01:44:06,754 DEBUG CV Batch 233/300 loss 21.963200 loss_att 16.393486 loss_ctc 34.959198 loss_ctc_origin 19.811031 loss_ctc0 70.304924 history loss 26.784295 rank 0
2022-08-27 01:44:16,140 DEBUG CV Batch 233/400 loss 37.785355 loss_att 30.280777 loss_ctc 55.296032 loss_ctc_origin 38.488800 loss_ctc0 94.512901 history loss 25.094362 rank 0
2022-08-27 01:44:25,832 DEBUG CV Batch 233/500 loss 15.981918 loss_att 12.094438 loss_ctc 25.052704 loss_ctc_origin 17.804047 loss_ctc0 41.966236 history loss 24.756033 rank 0
2022-08-27 01:44:35,531 DEBUG CV Batch 233/600 loss 17.986137 loss_att 12.732283 loss_ctc 30.245127 loss_ctc_origin 20.373919 loss_ctc0 53.277946 history loss 24.590716 rank 0
2022-08-27 01:44:44,427 DEBUG CV Batch 233/700 loss 19.232853 loss_att 13.895121 loss_ctc 31.687559 loss_ctc_origin 18.128420 loss_ctc0 63.325550 history loss 24.246261 rank 0
2022-08-27 01:44:54,060 DEBUG CV Batch 233/800 loss 22.719025 loss_att 18.077246 loss_ctc 33.549843 loss_ctc_origin 18.597643 loss_ctc0 68.438309 history loss 24.195978 rank 0
2022-08-27 01:45:03,657 INFO Epoch 233 CV info cv_loss 24.279356163495116
2022-08-27 01:45:03,658 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/233.pt
2022-08-27 01:45:04,113 INFO Epoch 234 TRAIN info lr 0.0005482040921847121
2022-08-27 01:45:04,117 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-27 01:45:30,249 DEBUG TRAIN Batch 234/0 loss 48.133530 loss_att 30.132206 loss_ctc 90.136612 loss_ctc_origin 63.939606 loss_ctc0 151.262939 lr 0.00054820 rank 0
2022-08-27 01:45:58,081 DEBUG TRAIN Batch 234/100 loss 58.883263 loss_att 33.699715 loss_ctc 117.644867 loss_ctc_origin 70.470871 loss_ctc0 227.717499 lr 0.00054818 rank 0
2022-08-27 01:46:25,956 DEBUG TRAIN Batch 234/200 loss 17.340219 loss_att 8.603027 loss_ctc 37.726997 loss_ctc_origin 25.503191 loss_ctc0 66.249207 lr 0.00054816 rank 0
2022-08-27 01:46:54,176 DEBUG TRAIN Batch 234/300 loss 14.750267 loss_att 5.404499 loss_ctc 36.557060 loss_ctc_origin 20.726837 loss_ctc0 73.494240 lr 0.00054814 rank 0
2022-08-27 01:47:21,935 DEBUG TRAIN Batch 234/400 loss 20.621939 loss_att 8.497896 loss_ctc 48.911369 loss_ctc_origin 28.713526 loss_ctc0 96.039673 lr 0.00054812 rank 0
2022-08-27 01:47:50,543 DEBUG TRAIN Batch 234/500 loss 45.686752 loss_att 28.526833 loss_ctc 85.726570 loss_ctc_origin 54.508350 loss_ctc0 158.569077 lr 0.00054810 rank 0
2022-08-27 01:48:18,145 DEBUG TRAIN Batch 234/600 loss 44.585190 loss_att 23.354778 loss_ctc 94.122818 loss_ctc_origin 50.342365 loss_ctc0 196.277222 lr 0.00054808 rank 0
2022-08-27 01:48:46,002 DEBUG TRAIN Batch 234/700 loss 19.154692 loss_att 9.082268 loss_ctc 42.657013 loss_ctc_origin 32.630100 loss_ctc0 66.053131 lr 0.00054806 rank 0
2022-08-27 01:48:51,313 WARNING NaN or Inf found in input tensor.
2022-08-27 01:49:11,885 DEBUG TRAIN Batch 234/800 loss 19.621063 loss_att 7.278990 loss_ctc 48.419228 loss_ctc_origin 33.162613 loss_ctc0 84.017998 lr 0.00054804 rank 0
2022-08-27 01:49:36,061 WARNING NaN or Inf found in input tensor.
2022-08-27 01:49:40,844 DEBUG TRAIN Batch 234/900 loss 20.219070 loss_att 8.370701 loss_ctc 47.865265 loss_ctc_origin 28.337971 loss_ctc0 93.428947 lr 0.00054802 rank 0
2022-08-27 01:50:08,993 DEBUG TRAIN Batch 234/1000 loss 40.788715 loss_att 26.447542 loss_ctc 74.251450 loss_ctc_origin 44.553131 loss_ctc0 143.547531 lr 0.00054800 rank 0
2022-08-27 01:50:36,060 DEBUG TRAIN Batch 234/1100 loss 48.255646 loss_att 26.967175 loss_ctc 97.928734 loss_ctc_origin 50.420647 loss_ctc0 208.780930 lr 0.00054798 rank 0
2022-08-27 01:51:04,572 DEBUG TRAIN Batch 234/1200 loss 17.677944 loss_att 7.868320 loss_ctc 40.567066 loss_ctc_origin 27.070400 loss_ctc0 72.059288 lr 0.00054796 rank 0
2022-08-27 01:51:30,614 DEBUG TRAIN Batch 234/1300 loss 19.321192 loss_att 7.908629 loss_ctc 45.950504 loss_ctc_origin 34.055992 loss_ctc0 73.704369 lr 0.00054794 rank 0
2022-08-27 01:51:58,528 DEBUG TRAIN Batch 234/1400 loss 25.129992 loss_att 10.572073 loss_ctc 59.098465 loss_ctc_origin 41.632851 loss_ctc0 99.851555 lr 0.00054792 rank 0
2022-08-27 01:52:30,132 DEBUG TRAIN Batch 234/1500 loss 33.864067 loss_att 21.177998 loss_ctc 63.464897 loss_ctc_origin 37.468979 loss_ctc0 124.122040 lr 0.00054789 rank 0
2022-08-27 01:52:56,582 DEBUG TRAIN Batch 234/1600 loss 44.834446 loss_att 21.634356 loss_ctc 98.967987 loss_ctc_origin 49.949982 loss_ctc0 213.343323 lr 0.00054787 rank 0
2022-08-27 01:53:22,729 DEBUG TRAIN Batch 234/1700 loss 22.928473 loss_att 10.324759 loss_ctc 52.337135 loss_ctc_origin 40.040955 loss_ctc0 81.028214 lr 0.00054785 rank 0
2022-08-27 01:53:48,952 DEBUG TRAIN Batch 234/1800 loss 17.344469 loss_att 6.208160 loss_ctc 43.329189 loss_ctc_origin 27.910404 loss_ctc0 79.306351 lr 0.00054783 rank 0
2022-08-27 01:54:15,745 DEBUG TRAIN Batch 234/1900 loss 20.359303 loss_att 8.218161 loss_ctc 48.688633 loss_ctc_origin 29.441168 loss_ctc0 93.599380 lr 0.00054781 rank 0
2022-08-27 01:54:43,653 DEBUG TRAIN Batch 234/2000 loss 47.235603 loss_att 32.591938 loss_ctc 81.404160 loss_ctc_origin 53.453255 loss_ctc0 146.622925 lr 0.00054779 rank 0
2022-08-27 01:54:51,087 WARNING NaN or Inf found in input tensor.
2022-08-27 01:55:09,768 DEBUG TRAIN Batch 234/2100 loss 56.632118 loss_att 35.872482 loss_ctc 105.071274 loss_ctc_origin 65.535851 loss_ctc0 197.320587 lr 0.00054777 rank 0
2022-08-27 01:55:38,500 DEBUG TRAIN Batch 234/2200 loss 21.055805 loss_att 11.415948 loss_ctc 43.548805 loss_ctc_origin 30.086716 loss_ctc0 74.960350 lr 0.00054775 rank 0
2022-08-27 01:56:05,955 DEBUG TRAIN Batch 234/2300 loss 18.875011 loss_att 7.775470 loss_ctc 44.773937 loss_ctc_origin 30.316221 loss_ctc0 78.508606 lr 0.00054773 rank 0
2022-08-27 01:56:33,117 DEBUG TRAIN Batch 234/2400 loss 19.380957 loss_att 8.439057 loss_ctc 44.912052 loss_ctc_origin 26.864525 loss_ctc0 87.022949 lr 0.00054771 rank 0
2022-08-27 01:57:00,311 DEBUG TRAIN Batch 234/2500 loss 44.971313 loss_att 28.795290 loss_ctc 82.715370 loss_ctc_origin 58.874035 loss_ctc0 138.345154 lr 0.00054769 rank 0
2022-08-27 01:57:28,627 DEBUG TRAIN Batch 234/2600 loss 46.869247 loss_att 27.157393 loss_ctc 92.863571 loss_ctc_origin 55.243851 loss_ctc0 180.642914 lr 0.00054767 rank 0
2022-08-27 01:57:55,539 DEBUG TRAIN Batch 234/2700 loss 19.725227 loss_att 10.066824 loss_ctc 42.261497 loss_ctc_origin 29.669586 loss_ctc0 71.642632 lr 0.00054765 rank 0
2022-08-27 01:58:25,048 DEBUG TRAIN Batch 234/2800 loss 18.648943 loss_att 7.956505 loss_ctc 43.597961 loss_ctc_origin 28.585075 loss_ctc0 78.628036 lr 0.00054763 rank 0
2022-08-27 01:58:47,862 WARNING NaN or Inf found in input tensor.
2022-08-27 01:58:51,854 DEBUG TRAIN Batch 234/2900 loss 17.661869 loss_att 6.613985 loss_ctc 43.440266 loss_ctc_origin 25.701630 loss_ctc0 84.830414 lr 0.00054761 rank 0
2022-08-27 01:59:26,920 DEBUG TRAIN Batch 234/3000 loss 49.915485 loss_att 33.870850 loss_ctc 87.352966 loss_ctc_origin 57.875053 loss_ctc0 156.134766 lr 0.00054759 rank 0
2022-08-27 01:59:54,703 DEBUG TRAIN Batch 234/3100 loss 42.855728 loss_att 22.558783 loss_ctc 90.215271 loss_ctc_origin 46.158493 loss_ctc0 193.014435 lr 0.00054757 rank 0
2022-08-27 02:00:22,127 DEBUG TRAIN Batch 234/3200 loss 19.943535 loss_att 10.058174 loss_ctc 43.009373 loss_ctc_origin 30.866978 loss_ctc0 71.341629 lr 0.00054755 rank 0
2022-08-27 02:00:34,183 WARNING NaN or Inf found in input tensor.
2022-08-27 02:00:48,673 DEBUG TRAIN Batch 234/3300 loss 17.065411 loss_att 6.234590 loss_ctc 42.337322 loss_ctc_origin 25.638073 loss_ctc0 81.302231 lr 0.00054752 rank 0
2022-08-27 02:01:16,226 DEBUG TRAIN Batch 234/3400 loss 18.840790 loss_att 7.652739 loss_ctc 44.946243 loss_ctc_origin 26.356775 loss_ctc0 88.321671 lr 0.00054750 rank 0
2022-08-27 02:01:43,860 DEBUG TRAIN Batch 234/3500 loss 48.433880 loss_att 31.732548 loss_ctc 87.403648 loss_ctc_origin 57.632812 loss_ctc0 156.868927 lr 0.00054748 rank 0
2022-08-27 02:02:11,628 DEBUG TRAIN Batch 234/3600 loss 48.752571 loss_att 26.703609 loss_ctc 100.200150 loss_ctc_origin 52.659523 loss_ctc0 211.128265 lr 0.00054746 rank 0
2022-08-27 02:02:39,177 DEBUG TRAIN Batch 234/3700 loss 22.274921 loss_att 12.237177 loss_ctc 45.696327 loss_ctc_origin 33.473671 loss_ctc0 74.215858 lr 0.00054744 rank 0
2022-08-27 02:02:44,768 WARNING NaN or Inf found in input tensor.
2022-08-27 02:03:06,846 DEBUG TRAIN Batch 234/3800 loss 20.375340 loss_att 8.210144 loss_ctc 48.760796 loss_ctc_origin 34.534416 loss_ctc0 81.955673 lr 0.00054742 rank 0
2022-08-27 02:03:36,389 DEBUG TRAIN Batch 234/3900 loss 19.304577 loss_att 8.674055 loss_ctc 44.109123 loss_ctc_origin 24.013685 loss_ctc0 90.998474 lr 0.00054740 rank 0
2022-08-27 02:04:04,044 DEBUG TRAIN Batch 234/4000 loss 44.728531 loss_att 29.430119 loss_ctc 80.424835 loss_ctc_origin 53.136559 loss_ctc0 144.097458 lr 0.00054738 rank 0
2022-08-27 02:04:18,151 WARNING NaN or Inf found in input tensor.
2022-08-27 02:04:31,705 DEBUG TRAIN Batch 234/4100 loss 52.511780 loss_att 28.331970 loss_ctc 108.931335 loss_ctc_origin 62.833954 loss_ctc0 216.491898 lr 0.00054736 rank 0
2022-08-27 02:04:58,249 DEBUG TRAIN Batch 234/4200 loss 18.690136 loss_att 7.700700 loss_ctc 44.332153 loss_ctc_origin 30.151161 loss_ctc0 77.421143 lr 0.00054734 rank 0
2022-08-27 02:05:27,215 DEBUG TRAIN Batch 234/4300 loss 19.750401 loss_att 7.715626 loss_ctc 47.831543 loss_ctc_origin 32.993347 loss_ctc0 82.453995 lr 0.00054732 rank 0
2022-08-27 02:05:54,496 DEBUG TRAIN Batch 234/4400 loss 21.072416 loss_att 8.496093 loss_ctc 50.417171 loss_ctc_origin 32.937679 loss_ctc0 91.202652 lr 0.00054730 rank 0
2022-08-27 02:06:28,779 DEBUG TRAIN Batch 234/4500 loss 36.516541 loss_att 23.488029 loss_ctc 66.916397 loss_ctc_origin 40.839561 loss_ctc0 127.762352 lr 0.00054728 rank 0
2022-08-27 02:06:36,347 WARNING NaN or Inf found in input tensor.
2022-08-27 02:06:56,763 DEBUG TRAIN Batch 234/4600 loss 50.928646 loss_att 29.876753 loss_ctc 100.049728 loss_ctc_origin 56.079895 loss_ctc0 202.645996 lr 0.00054726 rank 0
2022-08-27 02:07:24,472 DEBUG TRAIN Batch 234/4700 loss 21.220383 loss_att 9.755986 loss_ctc 47.970638 loss_ctc_origin 36.619812 loss_ctc0 74.455902 lr 0.00054724 rank 0
2022-08-27 02:07:52,529 DEBUG TRAIN Batch 234/4800 loss 13.688738 loss_att 5.489595 loss_ctc 32.820068 loss_ctc_origin 17.155602 loss_ctc0 69.370491 lr 0.00054722 rank 0
2022-08-27 02:08:19,614 DEBUG TRAIN Batch 234/4900 loss 19.771502 loss_att 8.026378 loss_ctc 47.176788 loss_ctc_origin 28.966709 loss_ctc0 89.666977 lr 0.00054720 rank 0
2022-08-27 02:08:47,425 DEBUG TRAIN Batch 234/5000 loss 44.961884 loss_att 28.460949 loss_ctc 83.464058 loss_ctc_origin 50.112106 loss_ctc0 161.285278 lr 0.00054718 rank 0
2022-08-27 02:09:15,646 DEBUG TRAIN Batch 234/5100 loss 46.307671 loss_att 23.106527 loss_ctc 100.443680 loss_ctc_origin 59.538242 loss_ctc0 195.889679 lr 0.00054716 rank 0
2022-08-27 02:09:42,463 DEBUG TRAIN Batch 234/5200 loss 18.454662 loss_att 8.759495 loss_ctc 41.076721 loss_ctc_origin 28.342306 loss_ctc0 70.790359 lr 0.00054714 rank 0
2022-08-27 02:10:10,450 DEBUG TRAIN Batch 234/5300 loss 17.517487 loss_att 8.088722 loss_ctc 39.517937 loss_ctc_origin 26.139675 loss_ctc0 70.733879 lr 0.00054712 rank 0
2022-08-27 02:10:26,454 WARNING NaN or Inf found in input tensor.
2022-08-27 02:10:39,157 DEBUG TRAIN Batch 234/5400 loss 21.999357 loss_att 9.011364 loss_ctc 52.304672 loss_ctc_origin 33.905048 loss_ctc0 95.237122 lr 0.00054709 rank 0
2022-08-27 02:11:04,515 DEBUG TRAIN Batch 234/5500 loss 40.953339 loss_att 24.133686 loss_ctc 80.199196 loss_ctc_origin 48.221558 loss_ctc0 154.813690 lr 0.00054707 rank 0
2022-08-27 02:11:05,190 WARNING NaN or Inf found in input tensor.
2022-08-27 02:11:29,207 DEBUG TRAIN Batch 234/5600 loss 53.491196 loss_att 32.754078 loss_ctc 101.877808 loss_ctc_origin 65.360336 loss_ctc0 187.085236 lr 0.00054705 rank 0
2022-08-27 02:11:50,233 DEBUG CV Batch 234/0 loss 11.414721 loss_att 8.565391 loss_ctc 18.063160 loss_ctc_origin 11.813858 loss_ctc0 32.644867 history loss 10.743267 rank 0
2022-08-27 02:11:59,885 DEBUG CV Batch 234/100 loss 20.369972 loss_att 16.485842 loss_ctc 29.432945 loss_ctc_origin 19.356659 loss_ctc0 52.944283 history loss 25.742452 rank 0
2022-08-27 02:12:08,766 DEBUG CV Batch 234/200 loss 24.301167 loss_att 19.180197 loss_ctc 36.250092 loss_ctc_origin 25.396820 loss_ctc0 61.574402 history loss 27.218124 rank 0
2022-08-27 02:12:17,648 DEBUG CV Batch 234/300 loss 21.709961 loss_att 16.248386 loss_ctc 34.453632 loss_ctc_origin 19.092258 loss_ctc0 70.296829 history loss 26.318672 rank 0
2022-08-27 02:12:27,276 DEBUG CV Batch 234/400 loss 36.469566 loss_att 29.003822 loss_ctc 53.889641 loss_ctc_origin 36.328819 loss_ctc0 94.864883 history loss 24.642738 rank 0
2022-08-27 02:12:36,961 DEBUG CV Batch 234/500 loss 15.387367 loss_att 10.949930 loss_ctc 25.741386 loss_ctc_origin 18.669563 loss_ctc0 42.242302 history loss 24.329291 rank 0
2022-08-27 02:12:46,515 DEBUG CV Batch 234/600 loss 18.205627 loss_att 13.087876 loss_ctc 30.147041 loss_ctc_origin 20.310730 loss_ctc0 53.098431 history loss 24.180128 rank 0
2022-08-27 02:12:55,716 DEBUG CV Batch 234/700 loss 18.778805 loss_att 13.403172 loss_ctc 31.321945 loss_ctc_origin 17.738388 loss_ctc0 63.016914 history loss 23.844939 rank 0
2022-08-27 02:13:05,179 DEBUG CV Batch 234/800 loss 21.461143 loss_att 16.949699 loss_ctc 31.987850 loss_ctc_origin 16.586325 loss_ctc0 67.924736 history loss 23.803758 rank 0
2022-08-27 02:13:14,400 INFO Epoch 234 CV info cv_loss 23.894663014281793
2022-08-27 02:13:14,401 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/234.pt
2022-08-27 02:13:14,845 INFO Epoch 235 TRAIN info lr 0.0005470364570098617
2022-08-27 02:13:14,848 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-27 02:13:41,131 DEBUG TRAIN Batch 235/0 loss 40.588409 loss_att 24.768538 loss_ctc 77.501442 loss_ctc_origin 49.438862 loss_ctc0 142.980789 lr 0.00054704 rank 0
2022-08-27 02:13:41,962 WARNING NaN or Inf found in input tensor.
2022-08-27 02:14:09,195 DEBUG TRAIN Batch 235/100 loss 49.107880 loss_att 28.996614 loss_ctc 96.034164 loss_ctc_origin 54.903244 loss_ctc0 192.006302 lr 0.00054702 rank 0
2022-08-27 02:14:37,355 DEBUG TRAIN Batch 235/200 loss 20.849770 loss_att 9.069252 loss_ctc 48.337639 loss_ctc_origin 37.659851 loss_ctc0 73.252480 lr 0.00054699 rank 0
2022-08-27 02:15:05,236 DEBUG TRAIN Batch 235/300 loss 17.448032 loss_att 6.589726 loss_ctc 42.784077 loss_ctc_origin 29.055733 loss_ctc0 74.816879 lr 0.00054697 rank 0
2022-08-27 02:15:33,608 DEBUG TRAIN Batch 235/400 loss 23.317768 loss_att 10.702807 loss_ctc 52.752678 loss_ctc_origin 34.260601 loss_ctc0 95.900848 lr 0.00054695 rank 0
2022-08-27 02:15:36,305 WARNING NaN or Inf found in input tensor.
2022-08-27 02:16:02,597 DEBUG TRAIN Batch 235/500 loss 37.847042 loss_att 23.346054 loss_ctc 71.682678 loss_ctc_origin 44.253525 loss_ctc0 135.684021 lr 0.00054693 rank 0
2022-08-27 02:16:30,377 DEBUG TRAIN Batch 235/600 loss 42.357246 loss_att 19.664576 loss_ctc 95.306808 loss_ctc_origin 47.501137 loss_ctc0 206.853363 lr 0.00054691 rank 0
2022-08-27 02:16:59,720 DEBUG TRAIN Batch 235/700 loss 17.891781 loss_att 9.192556 loss_ctc 38.189968 loss_ctc_origin 24.832760 loss_ctc0 69.356789 lr 0.00054689 rank 0
2022-08-27 02:17:27,247 DEBUG TRAIN Batch 235/800 loss 16.022526 loss_att 5.763133 loss_ctc 39.961109 loss_ctc_origin 23.205811 loss_ctc0 79.056808 lr 0.00054687 rank 0
2022-08-27 02:17:54,613 DEBUG TRAIN Batch 235/900 loss 19.258041 loss_att 7.844648 loss_ctc 45.889290 loss_ctc_origin 26.894936 loss_ctc0 90.209450 lr 0.00054685 rank 0
2022-08-27 02:18:22,377 DEBUG TRAIN Batch 235/1000 loss 37.871265 loss_att 22.674372 loss_ctc 73.330681 loss_ctc_origin 45.351967 loss_ctc0 138.614349 lr 0.00054683 rank 0
2022-08-27 02:18:49,391 DEBUG TRAIN Batch 235/1100 loss 46.041985 loss_att 25.375992 loss_ctc 94.262642 loss_ctc_origin 51.875343 loss_ctc0 193.166336 lr 0.00054681 rank 0
2022-08-27 02:19:17,056 DEBUG TRAIN Batch 235/1200 loss 17.838093 loss_att 10.272298 loss_ctc 35.491611 loss_ctc_origin 25.172817 loss_ctc0 59.568798 lr 0.00054679 rank 0
2022-08-27 02:19:45,291 DEBUG TRAIN Batch 235/1300 loss 18.835796 loss_att 7.722679 loss_ctc 44.766403 loss_ctc_origin 30.322550 loss_ctc0 78.468719 lr 0.00054677 rank 0
2022-08-27 02:20:12,659 DEBUG TRAIN Batch 235/1400 loss 21.387476 loss_att 9.508586 loss_ctc 49.104881 loss_ctc_origin 31.204323 loss_ctc0 90.872841 lr 0.00054675 rank 0
2022-08-27 02:20:45,507 DEBUG TRAIN Batch 235/1500 loss 39.181744 loss_att 24.884258 loss_ctc 72.542542 loss_ctc_origin 42.344139 loss_ctc0 143.005463 lr 0.00054673 rank 0
2022-08-27 02:21:13,012 DEBUG TRAIN Batch 235/1600 loss 54.336864 loss_att 32.341579 loss_ctc 105.659195 loss_ctc_origin 58.209038 loss_ctc0 216.376221 lr 0.00054671 rank 0
2022-08-27 02:21:40,821 DEBUG TRAIN Batch 235/1700 loss 21.292988 loss_att 9.788322 loss_ctc 48.137203 loss_ctc_origin 35.159973 loss_ctc0 78.417404 lr 0.00054669 rank 0
2022-08-27 02:22:08,511 DEBUG TRAIN Batch 235/1800 loss 21.630627 loss_att 8.614050 loss_ctc 52.002640 loss_ctc_origin 39.700279 loss_ctc0 80.708153 lr 0.00054667 rank 0
2022-08-27 02:22:36,531 DEBUG TRAIN Batch 235/1900 loss 20.163824 loss_att 8.223856 loss_ctc 48.023750 loss_ctc_origin 30.918213 loss_ctc0 87.936668 lr 0.00054665 rank 0
2022-08-27 02:23:04,636 DEBUG TRAIN Batch 235/2000 loss 52.275024 loss_att 35.360203 loss_ctc 91.742935 loss_ctc_origin 59.561699 loss_ctc0 166.832489 lr 0.00054663 rank 0
2022-08-27 02:23:32,248 DEBUG TRAIN Batch 235/2100 loss 47.300385 loss_att 22.533768 loss_ctc 105.089157 loss_ctc_origin 54.627441 loss_ctc0 222.833130 lr 0.00054661 rank 0
2022-08-27 02:23:59,058 WARNING NaN or Inf found in input tensor.
2022-08-27 02:24:00,609 DEBUG TRAIN Batch 235/2200 loss 22.345934 loss_att 12.640383 loss_ctc 44.992218 loss_ctc_origin 33.122444 loss_ctc0 72.688354 lr 0.00054659 rank 0
2022-08-27 02:24:28,347 DEBUG TRAIN Batch 235/2300 loss 21.382269 loss_att 9.030162 loss_ctc 50.203850 loss_ctc_origin 35.582932 loss_ctc0 84.319313 lr 0.00054657 rank 0
2022-08-27 02:24:45,403 WARNING NaN or Inf found in input tensor.
2022-08-27 02:24:56,292 DEBUG TRAIN Batch 235/2400 loss 20.862799 loss_att 7.677335 loss_ctc 51.628880 loss_ctc_origin 32.880188 loss_ctc0 95.375824 lr 0.00054655 rank 0
2022-08-27 02:25:25,104 DEBUG TRAIN Batch 235/2500 loss 49.595879 loss_att 31.949776 loss_ctc 90.770111 loss_ctc_origin 60.128094 loss_ctc0 162.268143 lr 0.00054652 rank 0
2022-08-27 02:25:52,718 DEBUG TRAIN Batch 235/2600 loss 51.933613 loss_att 28.045496 loss_ctc 107.672546 loss_ctc_origin 56.219543 loss_ctc0 227.729553 lr 0.00054650 rank 0
2022-08-27 02:26:19,918 DEBUG TRAIN Batch 235/2700 loss 18.788860 loss_att 9.594490 loss_ctc 40.242386 loss_ctc_origin 28.787088 loss_ctc0 66.971420 lr 0.00054648 rank 0
2022-08-27 02:26:47,986 DEBUG TRAIN Batch 235/2800 loss 18.466946 loss_att 8.064945 loss_ctc 42.738277 loss_ctc_origin 28.894121 loss_ctc0 75.041306 lr 0.00054646 rank 0
2022-08-27 02:27:04,930 WARNING NaN or Inf found in input tensor.
2022-08-27 02:27:17,169 DEBUG TRAIN Batch 235/2900 loss 21.556625 loss_att 8.727746 loss_ctc 51.490677 loss_ctc_origin 35.383289 loss_ctc0 89.074585 lr 0.00054644 rank 0
2022-08-27 02:27:48,677 DEBUG TRAIN Batch 235/3000 loss 48.206993 loss_att 29.822289 loss_ctc 91.104630 loss_ctc_origin 59.279327 loss_ctc0 165.363678 lr 0.00054642 rank 0
2022-08-27 02:27:56,268 WARNING NaN or Inf found in input tensor.
2022-08-27 02:28:16,508 DEBUG TRAIN Batch 235/3100 loss 54.111164 loss_att 30.473682 loss_ctc 109.265289 loss_ctc_origin 60.958218 loss_ctc0 221.981781 lr 0.00054640 rank 0
2022-08-27 02:28:42,220 WARNING NaN or Inf found in input tensor.
2022-08-27 02:28:43,976 DEBUG TRAIN Batch 235/3200 loss 19.277504 loss_att 11.134225 loss_ctc 38.278488 loss_ctc_origin 26.962196 loss_ctc0 64.683167 lr 0.00054638 rank 0
2022-08-27 02:29:11,757 DEBUG TRAIN Batch 235/3300 loss 17.025482 loss_att 7.242353 loss_ctc 39.852783 loss_ctc_origin 25.420044 loss_ctc0 73.529175 lr 0.00054636 rank 0
2022-08-27 02:29:39,133 DEBUG TRAIN Batch 235/3400 loss 17.901531 loss_att 6.833693 loss_ctc 43.726486 loss_ctc_origin 26.743076 loss_ctc0 83.354446 lr 0.00054634 rank 0
2022-08-27 02:30:07,201 DEBUG TRAIN Batch 235/3500 loss 42.652573 loss_att 27.122330 loss_ctc 78.889809 loss_ctc_origin 46.679100 loss_ctc0 154.048126 lr 0.00054632 rank 0
2022-08-27 02:30:35,126 DEBUG TRAIN Batch 235/3600 loss 56.788277 loss_att 32.428223 loss_ctc 113.628403 loss_ctc_origin 64.089828 loss_ctc0 229.218384 lr 0.00054630 rank 0
2022-08-27 02:31:00,365 WARNING NaN or Inf found in input tensor.
2022-08-27 02:31:01,968 DEBUG TRAIN Batch 235/3700 loss 18.526512 loss_att 9.473942 loss_ctc 39.649178 loss_ctc_origin 28.190632 loss_ctc0 66.385788 lr 0.00054628 rank 0
2022-08-27 02:31:29,399 DEBUG TRAIN Batch 235/3800 loss 19.111649 loss_att 7.651332 loss_ctc 45.852386 loss_ctc_origin 28.437405 loss_ctc0 86.487343 lr 0.00054626 rank 0
2022-08-27 02:31:56,534 DEBUG TRAIN Batch 235/3900 loss 16.903198 loss_att 6.847806 loss_ctc 40.365776 loss_ctc_origin 23.062851 loss_ctc0 80.739273 lr 0.00054624 rank 0
2022-08-27 02:32:25,634 DEBUG TRAIN Batch 235/4000 loss 39.910877 loss_att 25.829224 loss_ctc 72.768066 loss_ctc_origin 39.433506 loss_ctc0 150.548691 lr 0.00054622 rank 0
2022-08-27 02:32:54,112 DEBUG TRAIN Batch 235/4100 loss 58.474236 loss_att 35.364449 loss_ctc 112.397064 loss_ctc_origin 65.839630 loss_ctc0 221.031067 lr 0.00054620 rank 0
2022-08-27 02:33:19,403 DEBUG TRAIN Batch 235/4200 loss 18.978405 loss_att 9.503466 loss_ctc 41.086594 loss_ctc_origin 31.048691 loss_ctc0 64.508362 lr 0.00054618 rank 0
2022-08-27 02:33:47,814 DEBUG TRAIN Batch 235/4300 loss 16.244257 loss_att 6.041916 loss_ctc 40.049717 loss_ctc_origin 25.842434 loss_ctc0 73.200043 lr 0.00054616 rank 0
2022-08-27 02:34:15,437 DEBUG TRAIN Batch 235/4400 loss 21.354607 loss_att 7.669781 loss_ctc 53.285866 loss_ctc_origin 34.647755 loss_ctc0 96.774796 lr 0.00054614 rank 0
2022-08-27 02:34:49,705 DEBUG TRAIN Batch 235/4500 loss 43.080662 loss_att 28.285694 loss_ctc 77.602249 loss_ctc_origin 50.716644 loss_ctc0 140.335327 lr 0.00054612 rank 0
2022-08-27 02:35:17,438 DEBUG TRAIN Batch 235/4600 loss 46.477158 loss_att 23.021603 loss_ctc 101.206779 loss_ctc_origin 54.258072 loss_ctc0 210.753769 lr 0.00054610 rank 0
2022-08-27 02:35:44,659 DEBUG TRAIN Batch 235/4700 loss 19.419010 loss_att 10.433784 loss_ctc 40.384537 loss_ctc_origin 28.157978 loss_ctc0 68.913162 lr 0.00054608 rank 0
2022-08-27 02:36:11,823 DEBUG TRAIN Batch 235/4800 loss 16.903536 loss_att 7.127035 loss_ctc 39.715370 loss_ctc_origin 26.037537 loss_ctc0 71.630325 lr 0.00054606 rank 0
2022-08-27 02:36:39,954 DEBUG TRAIN Batch 235/4900 loss 26.214256 loss_att 11.489220 loss_ctc 60.572670 loss_ctc_origin 42.225239 loss_ctc0 103.383339 lr 0.00054604 rank 0
2022-08-27 02:37:09,759 DEBUG TRAIN Batch 235/5000 loss 46.674114 loss_att 32.677227 loss_ctc 79.333519 loss_ctc_origin 49.986401 loss_ctc0 147.810135 lr 0.00054602 rank 0
2022-08-27 02:37:36,187 DEBUG TRAIN Batch 235/5100 loss 46.148384 loss_att 21.546812 loss_ctc 103.552048 loss_ctc_origin 54.359337 loss_ctc0 218.335022 lr 0.00054600 rank 0
2022-08-27 02:38:03,108 DEBUG TRAIN Batch 235/5200 loss 25.017506 loss_att 11.689137 loss_ctc 56.117027 loss_ctc_origin 44.446747 loss_ctc0 83.347672 lr 0.00054597 rank 0
2022-08-27 02:38:29,100 DEBUG TRAIN Batch 235/5300 loss 20.915487 loss_att 9.477760 loss_ctc 47.603516 loss_ctc_origin 32.706108 loss_ctc0 82.364120 lr 0.00054595 rank 0
2022-08-27 02:38:51,801 WARNING NaN or Inf found in input tensor.
2022-08-27 02:38:56,363 DEBUG TRAIN Batch 235/5400 loss 23.443790 loss_att 10.041037 loss_ctc 54.716881 loss_ctc_origin 36.392944 loss_ctc0 97.472733 lr 0.00054593 rank 0
2022-08-27 02:39:24,353 DEBUG TRAIN Batch 235/5500 loss 37.857689 loss_att 24.399246 loss_ctc 69.260719 loss_ctc_origin 41.845528 loss_ctc0 133.229492 lr 0.00054591 rank 0
2022-08-27 02:39:50,230 DEBUG TRAIN Batch 235/5600 loss 40.233894 loss_att 19.578939 loss_ctc 88.428795 loss_ctc_origin 41.387959 loss_ctc0 198.190750 lr 0.00054589 rank 0
2022-08-27 02:40:15,032 DEBUG CV Batch 235/0 loss 11.270071 loss_att 8.266134 loss_ctc 18.279257 loss_ctc_origin 11.608088 loss_ctc0 33.845318 history loss 10.607126 rank 0
2022-08-27 02:40:24,687 DEBUG CV Batch 235/100 loss 20.499199 loss_att 16.613800 loss_ctc 29.565128 loss_ctc_origin 19.508617 loss_ctc0 53.030323 history loss 25.728044 rank 0
2022-08-27 02:40:33,290 DEBUG CV Batch 235/200 loss 24.133171 loss_att 19.038773 loss_ctc 36.020103 loss_ctc_origin 25.413040 loss_ctc0 60.769917 history loss 26.939483 rank 0
2022-08-27 02:40:42,376 DEBUG CV Batch 235/300 loss 21.471924 loss_att 16.063656 loss_ctc 34.091217 loss_ctc_origin 18.382797 loss_ctc0 70.744202 history loss 26.012112 rank 0
2022-08-27 02:40:52,050 DEBUG CV Batch 235/400 loss 36.850739 loss_att 30.015793 loss_ctc 52.798950 loss_ctc_origin 35.400570 loss_ctc0 93.395172 history loss 24.338544 rank 0
2022-08-27 02:41:01,365 DEBUG CV Batch 235/500 loss 16.136908 loss_att 12.015364 loss_ctc 25.753841 loss_ctc_origin 18.875240 loss_ctc0 41.803905 history loss 23.989727 rank 0
2022-08-27 02:41:10,638 DEBUG CV Batch 235/600 loss 17.271690 loss_att 12.438379 loss_ctc 28.549419 loss_ctc_origin 18.183266 loss_ctc0 52.737106 history loss 23.814963 rank 0
2022-08-27 02:41:19,489 DEBUG CV Batch 235/700 loss 18.211943 loss_att 12.983878 loss_ctc 30.410759 loss_ctc_origin 16.355923 loss_ctc0 63.205379 history loss 23.484031 rank 0
2022-08-27 02:41:28,790 DEBUG CV Batch 235/800 loss 20.808151 loss_att 16.068279 loss_ctc 31.867849 loss_ctc_origin 16.117706 loss_ctc0 68.618179 history loss 23.448197 rank 0
2022-08-27 02:41:39,142 INFO Epoch 235 CV info cv_loss 23.54596281208063
2022-08-27 02:41:39,142 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/235.pt
2022-08-27 02:41:39,590 INFO Epoch 236 TRAIN info lr 0.0005458762511289898
2022-08-27 02:41:39,594 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-27 02:42:04,541 DEBUG TRAIN Batch 236/0 loss 32.401184 loss_att 18.271198 loss_ctc 65.371147 loss_ctc_origin 38.865395 loss_ctc0 127.217903 lr 0.00054588 rank 0
2022-08-27 02:42:32,527 DEBUG TRAIN Batch 236/100 loss 48.794571 loss_att 29.131035 loss_ctc 94.676147 loss_ctc_origin 51.627380 loss_ctc0 195.123276 lr 0.00054586 rank 0
2022-08-27 02:43:00,245 DEBUG TRAIN Batch 236/200 loss 18.490925 loss_att 8.666527 loss_ctc 41.414520 loss_ctc_origin 29.723570 loss_ctc0 68.693405 lr 0.00054583 rank 0
2022-08-27 02:43:28,286 DEBUG TRAIN Batch 236/300 loss 18.200005 loss_att 7.446610 loss_ctc 43.291252 loss_ctc_origin 28.592571 loss_ctc0 77.588181 lr 0.00054581 rank 0
2022-08-27 02:43:55,837 DEBUG TRAIN Batch 236/400 loss 17.870201 loss_att 6.530033 loss_ctc 44.330589 loss_ctc_origin 26.803364 loss_ctc0 85.227440 lr 0.00054579 rank 0
2022-08-27 02:44:23,957 DEBUG TRAIN Batch 236/500 loss 32.623978 loss_att 20.521940 loss_ctc 60.862057 loss_ctc_origin 39.818127 loss_ctc0 109.964554 lr 0.00054577 rank 0
2022-08-27 02:44:52,136 DEBUG TRAIN Batch 236/600 loss 44.701221 loss_att 24.444550 loss_ctc 91.966782 loss_ctc_origin 52.735970 loss_ctc0 183.505356 lr 0.00054575 rank 0
2022-08-27 02:45:19,978 DEBUG TRAIN Batch 236/700 loss 23.279160 loss_att 13.465286 loss_ctc 46.178200 loss_ctc_origin 36.974091 loss_ctc0 67.654457 lr 0.00054573 rank 0
2022-08-27 02:45:47,400 DEBUG TRAIN Batch 236/800 loss 20.850580 loss_att 7.973960 loss_ctc 50.896027 loss_ctc_origin 36.045441 loss_ctc0 85.547386 lr 0.00054571 rank 0
2022-08-27 02:46:15,368 DEBUG TRAIN Batch 236/900 loss 23.543970 loss_att 9.938251 loss_ctc 55.290646 loss_ctc_origin 36.372166 loss_ctc0 99.433762 lr 0.00054569 rank 0
2022-08-27 02:46:44,493 DEBUG TRAIN Batch 236/1000 loss 38.814117 loss_att 26.834969 loss_ctc 66.765457 loss_ctc_origin 43.154381 loss_ctc0 121.857956 lr 0.00054567 rank 0
2022-08-27 02:47:04,582 WARNING NaN or Inf found in input tensor.
2022-08-27 02:47:11,866 DEBUG TRAIN Batch 236/1100 loss 46.826942 loss_att 28.109081 loss_ctc 90.501938 loss_ctc_origin 54.892902 loss_ctc0 173.589676 lr 0.00054565 rank 0
2022-08-27 02:47:39,928 DEBUG TRAIN Batch 236/1200 loss 17.806454 loss_att 8.595026 loss_ctc 39.299782 loss_ctc_origin 28.426533 loss_ctc0 64.670692 lr 0.00054563 rank 0
2022-08-27 02:48:07,862 DEBUG TRAIN Batch 236/1300 loss 17.990311 loss_att 7.868942 loss_ctc 41.606834 loss_ctc_origin 24.804295 loss_ctc0 80.812759 lr 0.00054561 rank 0
2022-08-27 02:48:36,010 DEBUG TRAIN Batch 236/1400 loss 18.997665 loss_att 7.332227 loss_ctc 46.217022 loss_ctc_origin 28.040108 loss_ctc0 88.629822 lr 0.00054559 rank 0
2022-08-27 02:49:11,154 DEBUG TRAIN Batch 236/1500 loss 38.982925 loss_att 25.803619 loss_ctc 69.734650 loss_ctc_origin 44.029106 loss_ctc0 129.714264 lr 0.00054557 rank 0
2022-08-27 02:49:39,112 DEBUG TRAIN Batch 236/1600 loss 39.088371 loss_att 19.340837 loss_ctc 85.165947 loss_ctc_origin 42.384560 loss_ctc0 184.989182 lr 0.00054555 rank 0
2022-08-27 02:50:06,050 DEBUG TRAIN Batch 236/1700 loss 21.614386 loss_att 10.327648 loss_ctc 47.950104 loss_ctc_origin 35.310452 loss_ctc0 77.442619 lr 0.00054553 rank 0
2022-08-27 02:50:34,140 DEBUG TRAIN Batch 236/1800 loss 19.694368 loss_att 7.880940 loss_ctc 47.259033 loss_ctc_origin 31.971123 loss_ctc0 82.930817 lr 0.00054551 rank 0
2022-08-27 02:51:03,089 DEBUG TRAIN Batch 236/1900 loss 20.595699 loss_att 8.454079 loss_ctc 48.926144 loss_ctc_origin 28.571024 loss_ctc0 96.421425 lr 0.00054549 rank 0
2022-08-27 02:51:29,927 DEBUG TRAIN Batch 236/2000 loss 41.465942 loss_att 28.202263 loss_ctc 72.414536 loss_ctc_origin 48.158081 loss_ctc0 129.012939 lr 0.00054547 rank 0
2022-08-27 02:51:56,006 DEBUG TRAIN Batch 236/2100 loss 41.302315 loss_att 22.484131 loss_ctc 85.211403 loss_ctc_origin 47.762650 loss_ctc0 172.591827 lr 0.00054545 rank 0
2022-08-27 02:52:23,852 DEBUG TRAIN Batch 236/2200 loss 19.393953 loss_att 10.790833 loss_ctc 39.467903 loss_ctc_origin 28.728100 loss_ctc0 64.527451 lr 0.00054543 rank 0
2022-08-27 02:52:52,206 DEBUG TRAIN Batch 236/2300 loss 17.332630 loss_att 6.851125 loss_ctc 41.789474 loss_ctc_origin 24.284922 loss_ctc0 82.633423 lr 0.00054541 rank 0
2022-08-27 02:53:18,500 DEBUG TRAIN Batch 236/2400 loss 17.457600 loss_att 6.229473 loss_ctc 43.656563 loss_ctc_origin 26.271912 loss_ctc0 84.220757 lr 0.00054539 rank 0
2022-08-27 02:53:47,307 DEBUG TRAIN Batch 236/2500 loss 38.182480 loss_att 24.393282 loss_ctc 70.357285 loss_ctc_origin 43.711166 loss_ctc0 132.531570 lr 0.00054537 rank 0
2022-08-27 02:54:12,893 DEBUG TRAIN Batch 236/2600 loss 44.712227 loss_att 23.957148 loss_ctc 93.140747 loss_ctc_origin 54.202927 loss_ctc0 183.995667 lr 0.00054535 rank 0
2022-08-27 02:54:42,686 DEBUG TRAIN Batch 236/2700 loss 18.031628 loss_att 7.959710 loss_ctc 41.532768 loss_ctc_origin 30.229321 loss_ctc0 67.907486 lr 0.00054533 rank 0
2022-08-27 02:55:10,014 DEBUG TRAIN Batch 236/2800 loss 14.570345 loss_att 5.251689 loss_ctc 36.313873 loss_ctc_origin 20.666248 loss_ctc0 72.824989 lr 0.00054531 rank 0
2022-08-27 02:55:37,924 DEBUG TRAIN Batch 236/2900 loss 17.812660 loss_att 5.813643 loss_ctc 45.810360 loss_ctc_origin 26.656662 loss_ctc0 90.502319 lr 0.00054529 rank 0
2022-08-27 02:56:11,024 DEBUG TRAIN Batch 236/3000 loss 45.677078 loss_att 31.280479 loss_ctc 79.269142 loss_ctc_origin 51.189789 loss_ctc0 144.787628 lr 0.00054527 rank 0
2022-08-27 02:56:18,739 WARNING NaN or Inf found in input tensor.
2022-08-27 02:56:39,437 DEBUG TRAIN Batch 236/3100 loss 61.420967 loss_att 38.600273 loss_ctc 114.669250 loss_ctc_origin 68.935852 loss_ctc0 221.380493 lr 0.00054525 rank 0
2022-08-27 02:57:06,809 DEBUG TRAIN Batch 236/3200 loss 18.843418 loss_att 9.382343 loss_ctc 40.919254 loss_ctc_origin 28.607042 loss_ctc0 69.647751 lr 0.00054523 rank 0
2022-08-27 02:57:34,457 DEBUG TRAIN Batch 236/3300 loss 16.531641 loss_att 7.092666 loss_ctc 38.555916 loss_ctc_origin 25.597292 loss_ctc0 68.792709 lr 0.00054521 rank 0
2022-08-27 02:57:44,907 WARNING NaN or Inf found in input tensor.
2022-08-27 02:58:01,902 DEBUG TRAIN Batch 236/3400 loss 21.501585 loss_att 8.524743 loss_ctc 51.780884 loss_ctc_origin 32.944210 loss_ctc0 95.733116 lr 0.00054519 rank 0
2022-08-27 02:58:29,872 DEBUG TRAIN Batch 236/3500 loss 54.195717 loss_att 36.475147 loss_ctc 95.543716 loss_ctc_origin 63.523941 loss_ctc0 170.256516 lr 0.00054517 rank 0
2022-08-27 02:58:57,730 DEBUG TRAIN Batch 236/3600 loss 52.567627 loss_att 28.415865 loss_ctc 108.921738 loss_ctc_origin 53.381084 loss_ctc0 238.516571 lr 0.00054514 rank 0
2022-08-27 02:59:25,674 DEBUG TRAIN Batch 236/3700 loss 18.395365 loss_att 9.893091 loss_ctc 38.234001 loss_ctc_origin 25.524429 loss_ctc0 67.889664 lr 0.00054512 rank 0
2022-08-27 02:59:53,330 DEBUG TRAIN Batch 236/3800 loss 17.993984 loss_att 7.206729 loss_ctc 43.164246 loss_ctc_origin 28.222387 loss_ctc0 78.028580 lr 0.00054510 rank 0
2022-08-27 03:00:10,171 WARNING NaN or Inf found in input tensor.
2022-08-27 03:00:21,412 DEBUG TRAIN Batch 236/3900 loss 23.065952 loss_att 9.373510 loss_ctc 55.014984 loss_ctc_origin 34.684250 loss_ctc0 102.453369 lr 0.00054508 rank 0
2022-08-27 03:00:24,002 WARNING NaN or Inf found in input tensor.
2022-08-27 03:00:49,769 DEBUG TRAIN Batch 236/4000 loss 46.841698 loss_att 31.017670 loss_ctc 83.764435 loss_ctc_origin 55.250412 loss_ctc0 150.297134 lr 0.00054506 rank 0
2022-08-27 03:01:10,745 WARNING NaN or Inf found in input tensor.
2022-08-27 03:01:17,494 DEBUG TRAIN Batch 236/4100 loss 53.414536 loss_att 27.190660 loss_ctc 114.603569 loss_ctc_origin 53.326057 loss_ctc0 257.584412 lr 0.00054504 rank 0
2022-08-27 03:01:44,504 DEBUG TRAIN Batch 236/4200 loss 17.331936 loss_att 8.746124 loss_ctc 37.365498 loss_ctc_origin 24.721527 loss_ctc0 66.868095 lr 0.00054502 rank 0
2022-08-27 03:01:57,069 WARNING NaN or Inf found in input tensor.
2022-08-27 03:02:13,311 DEBUG TRAIN Batch 236/4300 loss 17.684834 loss_att 6.861414 loss_ctc 42.939476 loss_ctc_origin 28.255980 loss_ctc0 77.200958 lr 0.00054500 rank 0
2022-08-27 03:02:41,167 DEBUG TRAIN Batch 236/4400 loss 19.943954 loss_att 8.243507 loss_ctc 47.244999 loss_ctc_origin 29.454351 loss_ctc0 88.756508 lr 0.00054498 rank 0
2022-08-27 03:03:15,753 DEBUG TRAIN Batch 236/4500 loss 49.860039 loss_att 31.514477 loss_ctc 92.666351 loss_ctc_origin 55.826103 loss_ctc0 178.626923 lr 0.00054496 rank 0
2022-08-27 03:03:43,447 DEBUG TRAIN Batch 236/4600 loss 55.375477 loss_att 30.747982 loss_ctc 112.839630 loss_ctc_origin 58.763374 loss_ctc0 239.017563 lr 0.00054494 rank 0
2022-08-27 03:04:09,902 WARNING NaN or Inf found in input tensor.
2022-08-27 03:04:11,449 DEBUG TRAIN Batch 236/4700 loss 17.907249 loss_att 9.261091 loss_ctc 38.081615 loss_ctc_origin 25.461452 loss_ctc0 67.528656 lr 0.00054492 rank 0
2022-08-27 03:04:39,844 DEBUG TRAIN Batch 236/4800 loss 17.916876 loss_att 6.442286 loss_ctc 44.690918 loss_ctc_origin 28.581314 loss_ctc0 82.279991 lr 0.00054490 rank 0
2022-08-27 03:05:07,522 DEBUG TRAIN Batch 236/4900 loss 20.777908 loss_att 7.594704 loss_ctc 51.538719 loss_ctc_origin 33.735470 loss_ctc0 93.079628 lr 0.00054488 rank 0
2022-08-27 03:05:36,600 DEBUG TRAIN Batch 236/5000 loss 50.273933 loss_att 32.468987 loss_ctc 91.818810 loss_ctc_origin 61.480911 loss_ctc0 162.607239 lr 0.00054486 rank 0
2022-08-27 03:06:03,140 DEBUG TRAIN Batch 236/5100 loss 48.726601 loss_att 27.553316 loss_ctc 98.130920 loss_ctc_origin 54.703587 loss_ctc0 199.461365 lr 0.00054484 rank 0
2022-08-27 03:06:22,613 WARNING NaN or Inf found in input tensor.
2022-08-27 03:06:32,300 DEBUG TRAIN Batch 236/5200 loss 18.774014 loss_att 9.420496 loss_ctc 40.598885 loss_ctc_origin 27.868866 loss_ctc0 70.302254 lr 0.00054482 rank 0
2022-08-27 03:06:59,091 DEBUG TRAIN Batch 236/5300 loss 20.398191 loss_att 8.693420 loss_ctc 47.709320 loss_ctc_origin 35.626770 loss_ctc0 75.901947 lr 0.00054480 rank 0
2022-08-27 03:07:26,121 DEBUG TRAIN Batch 236/5400 loss 17.201597 loss_att 6.430402 loss_ctc 42.334385 loss_ctc_origin 25.239391 loss_ctc0 82.222702 lr 0.00054478 rank 0
2022-08-27 03:07:53,144 DEBUG TRAIN Batch 236/5500 loss 53.186966 loss_att 37.287163 loss_ctc 90.286514 loss_ctc_origin 62.323322 loss_ctc0 155.533951 lr 0.00054476 rank 0
2022-08-27 03:08:14,290 WARNING NaN or Inf found in input tensor.
2022-08-27 03:08:21,345 DEBUG TRAIN Batch 236/5600 loss 47.032074 loss_att 23.647320 loss_ctc 101.596504 loss_ctc_origin 56.805862 loss_ctc0 206.108002 lr 0.00054474 rank 0
2022-08-27 03:08:43,463 DEBUG CV Batch 236/0 loss 11.585893 loss_att 8.744972 loss_ctc 18.214706 loss_ctc_origin 11.790909 loss_ctc0 33.203568 history loss 10.904370 rank 0
2022-08-27 03:08:53,592 DEBUG CV Batch 236/100 loss 20.398903 loss_att 16.790115 loss_ctc 28.819405 loss_ctc_origin 18.777605 loss_ctc0 52.250267 history loss 25.888797 rank 0
2022-08-27 03:09:02,664 DEBUG CV Batch 236/200 loss 24.661325 loss_att 19.206530 loss_ctc 37.389183 loss_ctc_origin 27.446918 loss_ctc0 60.587807 history loss 27.133365 rank 0
2022-08-27 03:09:11,862 DEBUG CV Batch 236/300 loss 21.785816 loss_att 16.761292 loss_ctc 33.509705 loss_ctc_origin 17.822075 loss_ctc0 70.114166 history loss 26.192428 rank 0
2022-08-27 03:09:21,792 DEBUG CV Batch 236/400 loss 36.832909 loss_att 29.866650 loss_ctc 53.087517 loss_ctc_origin 35.883518 loss_ctc0 93.230179 history loss 24.504423 rank 0
2022-08-27 03:09:31,521 DEBUG CV Batch 236/500 loss 15.872746 loss_att 11.844244 loss_ctc 25.272579 loss_ctc_origin 18.113306 loss_ctc0 41.977547 history loss 24.195920 rank 0
2022-08-27 03:09:40,918 DEBUG CV Batch 236/600 loss 17.624605 loss_att 12.532199 loss_ctc 29.506886 loss_ctc_origin 19.443346 loss_ctc0 52.988472 history loss 24.016541 rank 0
2022-08-27 03:09:50,049 DEBUG CV Batch 236/700 loss 18.789505 loss_att 13.391753 loss_ctc 31.384254 loss_ctc_origin 17.917099 loss_ctc0 62.807613 history loss 23.679621 rank 0
2022-08-27 03:09:59,659 DEBUG CV Batch 236/800 loss 21.675968 loss_att 16.692894 loss_ctc 33.303146 loss_ctc_origin 18.167854 loss_ctc0 68.618820 history loss 23.650672 rank 0
2022-08-27 03:10:09,127 INFO Epoch 236 CV info cv_loss 23.759721286433138
2022-08-27 03:10:09,127 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/236.pt
2022-08-27 03:10:09,573 INFO Epoch 237 TRAIN info lr 0.0005447233960910572
2022-08-27 03:10:09,577 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-27 03:10:35,502 DEBUG TRAIN Batch 237/0 loss 49.589462 loss_att 33.631027 loss_ctc 86.825806 loss_ctc_origin 58.343025 loss_ctc0 153.285614 lr 0.00054472 rank 0
2022-08-27 03:11:03,982 DEBUG TRAIN Batch 237/100 loss 49.475334 loss_att 28.151857 loss_ctc 99.230110 loss_ctc_origin 61.450958 loss_ctc0 187.381454 lr 0.00054470 rank 0
2022-08-27 03:11:31,402 DEBUG TRAIN Batch 237/200 loss 16.070641 loss_att 7.886312 loss_ctc 35.167404 loss_ctc_origin 23.658646 loss_ctc0 62.021175 lr 0.00054468 rank 0
2022-08-27 03:11:59,491 DEBUG TRAIN Batch 237/300 loss 18.251188 loss_att 6.774899 loss_ctc 45.029198 loss_ctc_origin 29.411804 loss_ctc0 81.469772 lr 0.00054466 rank 0
2022-08-27 03:12:26,881 DEBUG TRAIN Batch 237/400 loss 19.843163 loss_att 7.731752 loss_ctc 48.103119 loss_ctc_origin 26.474808 loss_ctc0 98.569168 lr 0.00054464 rank 0
2022-08-27 03:12:55,864 DEBUG TRAIN Batch 237/500 loss 53.090576 loss_att 36.981766 loss_ctc 90.677795 loss_ctc_origin 62.915565 loss_ctc0 155.456329 lr 0.00054462 rank 0
2022-08-27 03:13:23,643 DEBUG TRAIN Batch 237/600 loss 50.455887 loss_att 27.428799 loss_ctc 104.185760 loss_ctc_origin 60.829918 loss_ctc0 205.349380 lr 0.00054460 rank 0
2022-08-27 03:13:51,869 DEBUG TRAIN Batch 237/700 loss 17.313389 loss_att 8.474982 loss_ctc 37.936337 loss_ctc_origin 27.503139 loss_ctc0 62.280464 lr 0.00054458 rank 0
2022-08-27 03:14:19,374 DEBUG TRAIN Batch 237/800 loss 19.395164 loss_att 8.090379 loss_ctc 45.772999 loss_ctc_origin 31.892590 loss_ctc0 78.160622 lr 0.00054456 rank 0
2022-08-27 03:14:42,598 WARNING NaN or Inf found in input tensor.
2022-08-27 03:14:46,779 DEBUG TRAIN Batch 237/900 loss 19.325035 loss_att 8.028271 loss_ctc 45.684147 loss_ctc_origin 27.624290 loss_ctc0 87.823807 lr 0.00054454 rank 0
2022-08-27 03:15:14,890 DEBUG TRAIN Batch 237/1000 loss 48.261353 loss_att 32.551514 loss_ctc 84.917648 loss_ctc_origin 56.625061 loss_ctc0 150.933685 lr 0.00054452 rank 0
2022-08-27 03:15:42,978 DEBUG TRAIN Batch 237/1100 loss 44.372704 loss_att 22.601650 loss_ctc 95.171822 loss_ctc_origin 53.982956 loss_ctc0 191.279175 lr 0.00054450 rank 0
2022-08-27 03:16:11,506 DEBUG TRAIN Batch 237/1200 loss 18.285082 loss_att 9.053857 loss_ctc 39.824604 loss_ctc_origin 29.904331 loss_ctc0 62.971909 lr 0.00054448 rank 0
2022-08-27 03:16:39,459 DEBUG TRAIN Batch 237/1300 loss 13.939000 loss_att 5.432650 loss_ctc 33.787151 loss_ctc_origin 18.744244 loss_ctc0 68.887268 lr 0.00054446 rank 0
2022-08-27 03:17:06,433 DEBUG TRAIN Batch 237/1400 loss 18.863419 loss_att 7.237596 loss_ctc 45.990341 loss_ctc_origin 26.633278 loss_ctc0 91.156815 lr 0.00054444 rank 0
2022-08-27 03:17:15,787 WARNING NaN or Inf found in input tensor.
2022-08-27 03:17:41,769 DEBUG TRAIN Batch 237/1500 loss 51.719444 loss_att 33.005077 loss_ctc 95.386292 loss_ctc_origin 65.710129 loss_ctc0 164.630676 lr 0.00054442 rank 0
2022-08-27 03:18:09,321 DEBUG TRAIN Batch 237/1600 loss 51.327690 loss_att 27.586905 loss_ctc 106.722855 loss_ctc_origin 49.931717 loss_ctc0 239.235489 lr 0.00054440 rank 0
2022-08-27 03:18:37,160 DEBUG TRAIN Batch 237/1700 loss 16.771500 loss_att 7.745965 loss_ctc 37.831081 loss_ctc_origin 24.896614 loss_ctc0 68.011505 lr 0.00054438 rank 0
2022-08-27 03:19:04,855 DEBUG TRAIN Batch 237/1800 loss 15.370548 loss_att 6.639549 loss_ctc 35.742878 loss_ctc_origin 20.276331 loss_ctc0 71.831482 lr 0.00054436 rank 0
2022-08-27 03:19:32,735 DEBUG TRAIN Batch 237/1900 loss 19.706776 loss_att 7.620857 loss_ctc 47.907249 loss_ctc_origin 30.086290 loss_ctc0 89.489487 lr 0.00054434 rank 0
2022-08-27 03:20:02,024 DEBUG TRAIN Batch 237/2000 loss 50.158596 loss_att 32.294128 loss_ctc 91.842346 loss_ctc_origin 56.972317 loss_ctc0 173.205719 lr 0.00054432 rank 0
2022-08-27 03:20:29,166 DEBUG TRAIN Batch 237/2100 loss 54.396309 loss_att 29.305037 loss_ctc 112.942612 loss_ctc_origin 69.534843 loss_ctc0 214.227386 lr 0.00054430 rank 0
2022-08-27 03:20:55,730 DEBUG TRAIN Batch 237/2200 loss 20.312122 loss_att 11.128443 loss_ctc 41.740707 loss_ctc_origin 30.184334 loss_ctc0 68.705582 lr 0.00054428 rank 0
2022-08-27 03:21:24,081 DEBUG TRAIN Batch 237/2300 loss 17.500507 loss_att 6.553659 loss_ctc 43.043148 loss_ctc_origin 27.624695 loss_ctc0 79.019539 lr 0.00054426 rank 0
2022-08-27 03:21:47,290 WARNING NaN or Inf found in input tensor.
2022-08-27 03:21:51,659 DEBUG TRAIN Batch 237/2400 loss 19.030445 loss_att 7.466264 loss_ctc 46.013527 loss_ctc_origin 27.533405 loss_ctc0 89.133797 lr 0.00054424 rank 0
2022-08-27 03:22:19,465 DEBUG TRAIN Batch 237/2500 loss 45.105114 loss_att 27.606901 loss_ctc 85.934273 loss_ctc_origin 50.112770 loss_ctc0 169.517776 lr 0.00054422 rank 0
2022-08-27 03:22:32,690 WARNING NaN or Inf found in input tensor.
2022-08-27 03:22:39,525 WARNING NaN or Inf found in input tensor.
2022-08-27 03:22:46,446 WARNING NaN or Inf found in input tensor.
2022-08-27 03:22:46,487 DEBUG TRAIN Batch 237/2600 loss nan loss_att 28.288567 loss_ctc nan loss_ctc_origin 56.645416 loss_ctc0 nan lr 0.00054420 rank 0
2022-08-27 03:23:13,345 DEBUG TRAIN Batch 237/2700 loss 18.193151 loss_att 9.090094 loss_ctc 39.433617 loss_ctc_origin 28.499920 loss_ctc0 64.945572 lr 0.00054418 rank 0
2022-08-27 03:23:41,170 DEBUG TRAIN Batch 237/2800 loss 19.399046 loss_att 7.339774 loss_ctc 47.537346 loss_ctc_origin 31.946268 loss_ctc0 83.916519 lr 0.00054416 rank 0
2022-08-27 03:24:08,802 DEBUG TRAIN Batch 237/2900 loss 19.342329 loss_att 6.760245 loss_ctc 48.700523 loss_ctc_origin 30.812031 loss_ctc0 90.440338 lr 0.00054414 rank 0
2022-08-27 03:24:42,834 DEBUG TRAIN Batch 237/3000 loss 51.181499 loss_att 34.873207 loss_ctc 89.234177 loss_ctc_origin 57.282532 loss_ctc0 163.788025 lr 0.00054412 rank 0
2022-08-27 03:25:11,097 DEBUG TRAIN Batch 237/3100 loss 54.081329 loss_att 30.631248 loss_ctc 108.798172 loss_ctc_origin 57.843201 loss_ctc0 227.693085 lr 0.00054410 rank 0
2022-08-27 03:25:38,715 DEBUG TRAIN Batch 237/3200 loss 19.629986 loss_att 10.915037 loss_ctc 39.964867 loss_ctc_origin 27.294584 loss_ctc0 69.528862 lr 0.00054408 rank 0
2022-08-27 03:25:43,798 WARNING NaN or Inf found in input tensor.
2022-08-27 03:26:06,458 DEBUG TRAIN Batch 237/3300 loss 15.867676 loss_att 6.073416 loss_ctc 38.720951 loss_ctc_origin 24.456364 loss_ctc0 72.004990 lr 0.00054406 rank 0
2022-08-27 03:26:30,088 WARNING NaN or Inf found in input tensor.
2022-08-27 03:26:34,284 DEBUG TRAIN Batch 237/3400 loss 17.328991 loss_att 7.588101 loss_ctc 40.057732 loss_ctc_origin 22.543411 loss_ctc0 80.924477 lr 0.00054404 rank 0
2022-08-27 03:27:02,872 DEBUG TRAIN Batch 237/3500 loss 42.825424 loss_att 30.353893 loss_ctc 71.925659 loss_ctc_origin 47.709930 loss_ctc0 128.429016 lr 0.00054402 rank 0
2022-08-27 03:27:30,886 WARNING NaN or Inf found in input tensor.
2022-08-27 03:27:30,926 DEBUG TRAIN Batch 237/3600 loss inf loss_att 31.609146 loss_ctc inf loss_ctc_origin inf loss_ctc0 198.695999 lr 0.00054400 rank 0
2022-08-27 03:27:58,410 DEBUG TRAIN Batch 237/3700 loss 21.730120 loss_att 9.442551 loss_ctc 50.401112 loss_ctc_origin 40.920273 loss_ctc0 72.523071 lr 0.00054398 rank 0
2022-08-27 03:28:25,853 DEBUG TRAIN Batch 237/3800 loss 17.535595 loss_att 6.498884 loss_ctc 43.287918 loss_ctc_origin 26.467907 loss_ctc0 82.534607 lr 0.00054396 rank 0
2022-08-27 03:28:53,833 DEBUG TRAIN Batch 237/3900 loss 19.167944 loss_att 7.455890 loss_ctc 46.496067 loss_ctc_origin 27.066219 loss_ctc0 91.832375 lr 0.00054394 rank 0
2022-08-27 03:29:09,607 WARNING NaN or Inf found in input tensor.
2022-08-27 03:29:22,288 DEBUG TRAIN Batch 237/4000 loss 47.397491 loss_att 31.653051 loss_ctc 84.134521 loss_ctc_origin 58.149551 loss_ctc0 144.766113 lr 0.00054392 rank 0
2022-08-27 03:29:49,908 DEBUG TRAIN Batch 237/4100 loss 52.563732 loss_att 29.716713 loss_ctc 105.873444 loss_ctc_origin 62.935688 loss_ctc0 206.061523 lr 0.00054390 rank 0
2022-08-27 03:30:19,644 DEBUG TRAIN Batch 237/4200 loss 20.097530 loss_att 11.482461 loss_ctc 40.199356 loss_ctc_origin 28.820431 loss_ctc0 66.750183 lr 0.00054388 rank 0
2022-08-27 03:30:49,284 DEBUG TRAIN Batch 237/4300 loss 17.628452 loss_att 6.739648 loss_ctc 43.035664 loss_ctc_origin 26.164549 loss_ctc0 82.401596 lr 0.00054386 rank 0
2022-08-27 03:31:15,373 DEBUG TRAIN Batch 237/4400 loss 20.314831 loss_att 7.440047 loss_ctc 50.355995 loss_ctc_origin 31.894934 loss_ctc0 93.431793 lr 0.00054384 rank 0
2022-08-27 03:31:49,957 DEBUG TRAIN Batch 237/4500 loss 41.726814 loss_att 26.680252 loss_ctc 76.835464 loss_ctc_origin 50.683880 loss_ctc0 137.855835 lr 0.00054382 rank 0
2022-08-27 03:31:50,778 WARNING NaN or Inf found in input tensor.
2022-08-27 03:32:16,956 DEBUG TRAIN Batch 237/4600 loss 54.992138 loss_att 29.488863 loss_ctc 114.499779 loss_ctc_origin 64.920097 loss_ctc0 230.185684 lr 0.00054380 rank 0
2022-08-27 03:32:44,741 DEBUG TRAIN Batch 237/4700 loss 13.715797 loss_att 6.072474 loss_ctc 31.550217 loss_ctc_origin 18.236685 loss_ctc0 62.615128 lr 0.00054378 rank 0
2022-08-27 03:33:12,664 DEBUG TRAIN Batch 237/4800 loss 16.597715 loss_att 5.982651 loss_ctc 41.366196 loss_ctc_origin 26.274319 loss_ctc0 76.580582 lr 0.00054376 rank 0
2022-08-27 03:33:41,439 DEBUG TRAIN Batch 237/4900 loss 19.204836 loss_att 7.195800 loss_ctc 47.225918 loss_ctc_origin 28.242029 loss_ctc0 91.521652 lr 0.00054374 rank 0
2022-08-27 03:34:10,902 DEBUG TRAIN Batch 237/5000 loss 44.324829 loss_att 28.884605 loss_ctc 80.352020 loss_ctc_origin 52.069790 loss_ctc0 146.343872 lr 0.00054372 rank 0
2022-08-27 03:34:40,117 DEBUG TRAIN Batch 237/5100 loss 53.721771 loss_att 32.127205 loss_ctc 104.109093 loss_ctc_origin 64.968971 loss_ctc0 195.436035 lr 0.00054370 rank 0
2022-08-27 03:35:07,458 DEBUG TRAIN Batch 237/5200 loss 16.028149 loss_att 7.100085 loss_ctc 36.860298 loss_ctc_origin 23.166084 loss_ctc0 68.813469 lr 0.00054368 rank 0
2022-08-27 03:35:34,196 DEBUG TRAIN Batch 237/5300 loss 18.017429 loss_att 7.449433 loss_ctc 42.676083 loss_ctc_origin 26.568396 loss_ctc0 80.260681 lr 0.00054365 rank 0
2022-08-27 03:36:02,747 DEBUG TRAIN Batch 237/5400 loss 19.253790 loss_att 7.207428 loss_ctc 47.361965 loss_ctc_origin 26.410770 loss_ctc0 96.248085 lr 0.00054363 rank 0
2022-08-27 03:36:30,933 DEBUG TRAIN Batch 237/5500 loss 29.329510 loss_att 18.160374 loss_ctc 55.390823 loss_ctc_origin 35.087875 loss_ctc0 102.764359 lr 0.00054361 rank 0
2022-08-27 03:36:58,941 DEBUG TRAIN Batch 237/5600 loss 35.359035 loss_att 21.253357 loss_ctc 68.272285 loss_ctc_origin 39.294960 loss_ctc0 135.886047 lr 0.00054359 rank 0
2022-08-27 03:37:22,453 DEBUG CV Batch 237/0 loss 11.600418 loss_att 8.798822 loss_ctc 18.137474 loss_ctc_origin 11.588930 loss_ctc0 33.417412 history loss 10.918041 rank 0
2022-08-27 03:37:32,023 DEBUG CV Batch 237/100 loss 19.810532 loss_att 16.043247 loss_ctc 28.600863 loss_ctc_origin 18.257908 loss_ctc0 52.734421 history loss 25.520718 rank 0
2022-08-27 03:37:40,838 DEBUG CV Batch 237/200 loss 23.492599 loss_att 18.113573 loss_ctc 36.043663 loss_ctc_origin 25.293427 loss_ctc0 61.127541 history loss 26.635631 rank 0
2022-08-27 03:37:49,840 DEBUG CV Batch 237/300 loss 21.328934 loss_att 16.276669 loss_ctc 33.117554 loss_ctc_origin 17.328358 loss_ctc0 69.959015 history loss 25.683325 rank 0
2022-08-27 03:37:59,264 DEBUG CV Batch 237/400 loss 37.121082 loss_att 30.008228 loss_ctc 53.717735 loss_ctc_origin 36.451515 loss_ctc0 94.005585 history loss 24.035175 rank 0
2022-08-27 03:38:09,124 DEBUG CV Batch 237/500 loss 16.119473 loss_att 11.952145 loss_ctc 25.843239 loss_ctc_origin 19.016901 loss_ctc0 41.771362 history loss 23.734397 rank 0
2022-08-27 03:38:18,653 DEBUG CV Batch 237/600 loss 17.786926 loss_att 12.596129 loss_ctc 29.898787 loss_ctc_origin 19.836952 loss_ctc0 53.376396 history loss 23.583991 rank 0
2022-08-27 03:38:27,719 DEBUG CV Batch 237/700 loss 17.622879 loss_att 12.607585 loss_ctc 29.325232 loss_ctc_origin 15.193003 loss_ctc0 62.300430 history loss 23.249362 rank 0
2022-08-27 03:38:37,172 DEBUG CV Batch 237/800 loss 20.754951 loss_att 15.723608 loss_ctc 32.494755 loss_ctc_origin 17.321310 loss_ctc0 67.899460 history loss 23.211030 rank 0
2022-08-27 03:38:46,688 INFO Epoch 237 CV info cv_loss 23.29921312319506
2022-08-27 03:38:46,688 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/237.pt
2022-08-27 03:38:47,130 INFO Epoch 238 TRAIN info lr 0.0005435778145999335
2022-08-27 03:38:47,133 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-27 03:39:12,988 DEBUG TRAIN Batch 238/0 loss 24.393812 loss_att 15.426123 loss_ctc 45.318420 loss_ctc_origin 29.626625 loss_ctc0 81.932602 lr 0.00054358 rank 0
2022-08-27 03:39:40,869 DEBUG TRAIN Batch 238/100 loss 43.993378 loss_att 23.080841 loss_ctc 92.789291 loss_ctc_origin 50.344208 loss_ctc0 191.827835 lr 0.00054356 rank 0
2022-08-27 03:40:06,875 WARNING NaN or Inf found in input tensor.
2022-08-27 03:40:08,427 DEBUG TRAIN Batch 238/200 loss 19.938091 loss_att 10.325266 loss_ctc 42.368011 loss_ctc_origin 32.625481 loss_ctc0 65.100586 lr 0.00054354 rank 0
2022-08-27 03:40:35,820 DEBUG TRAIN Batch 238/300 loss 18.436064 loss_att 6.949108 loss_ctc 45.238960 loss_ctc_origin 27.392813 loss_ctc0 86.879974 lr 0.00054352 rank 0
2022-08-27 03:41:03,080 DEBUG TRAIN Batch 238/400 loss 18.747456 loss_att 6.941289 loss_ctc 46.295174 loss_ctc_origin 26.500851 loss_ctc0 92.481918 lr 0.00054350 rank 0
2022-08-27 03:41:31,915 DEBUG TRAIN Batch 238/500 loss 39.521332 loss_att 24.331495 loss_ctc 74.964279 loss_ctc_origin 39.399185 loss_ctc0 157.949478 lr 0.00054348 rank 0
2022-08-27 03:41:39,703 WARNING NaN or Inf found in input tensor.
2022-08-27 03:41:58,077 DEBUG TRAIN Batch 238/600 loss 49.746601 loss_att 27.052376 loss_ctc 102.699791 loss_ctc_origin 52.611084 loss_ctc0 219.573441 lr 0.00054346 rank 0
2022-08-27 03:42:25,956 DEBUG TRAIN Batch 238/700 loss 15.034060 loss_att 7.142021 loss_ctc 33.448814 loss_ctc_origin 21.276722 loss_ctc0 61.850357 lr 0.00054344 rank 0
2022-08-27 03:42:54,052 DEBUG TRAIN Batch 238/800 loss 17.688416 loss_att 7.529805 loss_ctc 41.391838 loss_ctc_origin 27.225992 loss_ctc0 74.445465 lr 0.00054342 rank 0
2022-08-27 03:43:21,229 DEBUG TRAIN Batch 238/900 loss 18.265194 loss_att 7.055939 loss_ctc 44.420124 loss_ctc_origin 27.516609 loss_ctc0 83.861656 lr 0.00054340 rank 0
2022-08-27 03:43:48,274 DEBUG TRAIN Batch 238/1000 loss 47.406525 loss_att 29.515472 loss_ctc 89.152306 loss_ctc_origin 52.593063 loss_ctc0 174.457199 lr 0.00054338 rank 0
2022-08-27 03:44:15,537 DEBUG TRAIN Batch 238/1100 loss 47.932690 loss_att 24.036917 loss_ctc 103.689491 loss_ctc_origin 53.917152 loss_ctc0 219.824951 lr 0.00054336 rank 0
2022-08-27 03:44:42,734 DEBUG TRAIN Batch 238/1200 loss 19.800259 loss_att 8.489560 loss_ctc 46.191887 loss_ctc_origin 34.145309 loss_ctc0 74.300560 lr 0.00054334 rank 0
2022-08-27 03:45:09,773 DEBUG TRAIN Batch 238/1300 loss 17.671637 loss_att 7.497663 loss_ctc 41.410904 loss_ctc_origin 29.752048 loss_ctc0 68.614899 lr 0.00054332 rank 0
2022-08-27 03:45:19,425 WARNING NaN or Inf found in input tensor.
2022-08-27 03:45:36,589 DEBUG TRAIN Batch 238/1400 loss 23.157129 loss_att 9.881142 loss_ctc 54.134430 loss_ctc_origin 34.542168 loss_ctc0 99.849701 lr 0.00054330 rank 0
2022-08-27 03:46:09,519 DEBUG TRAIN Batch 238/1500 loss 46.194519 loss_att 28.913618 loss_ctc 86.516624 loss_ctc_origin 53.384319 loss_ctc0 163.825333 lr 0.00054328 rank 0
2022-08-27 03:46:35,513 DEBUG TRAIN Batch 238/1600 loss 47.951591 loss_att 25.650023 loss_ctc 99.988586 loss_ctc_origin 59.108856 loss_ctc0 195.374603 lr 0.00054326 rank 0
2022-08-27 03:47:02,320 DEBUG TRAIN Batch 238/1700 loss 19.327593 loss_att 9.526283 loss_ctc 42.197315 loss_ctc_origin 33.019409 loss_ctc0 63.612427 lr 0.00054324 rank 0
2022-08-27 03:47:08,469 WARNING NaN or Inf found in input tensor.
2022-08-27 03:47:28,195 DEBUG TRAIN Batch 238/1800 loss 17.833740 loss_att 7.706724 loss_ctc 41.463444 loss_ctc_origin 27.113600 loss_ctc0 74.946411 lr 0.00054322 rank 0
2022-08-27 03:47:57,155 DEBUG TRAIN Batch 238/1900 loss 21.372841 loss_att 7.856957 loss_ctc 52.909897 loss_ctc_origin 32.533150 loss_ctc0 100.455643 lr 0.00054320 rank 0
2022-08-27 03:47:59,819 WARNING NaN or Inf found in input tensor.
2022-08-27 03:48:24,206 DEBUG TRAIN Batch 238/2000 loss 56.540279 loss_att 35.863098 loss_ctc 104.787033 loss_ctc_origin 73.062592 loss_ctc0 178.810730 lr 0.00054318 rank 0
2022-08-27 03:48:51,268 DEBUG TRAIN Batch 238/2100 loss 49.602993 loss_att 26.964897 loss_ctc 102.425217 loss_ctc_origin 59.496819 loss_ctc0 202.591461 lr 0.00054316 rank 0
2022-08-27 03:49:18,173 DEBUG TRAIN Batch 238/2200 loss 20.714012 loss_att 11.191143 loss_ctc 42.934040 loss_ctc_origin 32.948425 loss_ctc0 66.233803 lr 0.00054314 rank 0
2022-08-27 03:49:44,253 DEBUG TRAIN Batch 238/2300 loss 17.825148 loss_att 7.049663 loss_ctc 42.967945 loss_ctc_origin 29.456013 loss_ctc0 74.495781 lr 0.00054312 rank 0
2022-08-27 03:50:11,876 DEBUG TRAIN Batch 238/2400 loss 19.588539 loss_att 6.644287 loss_ctc 49.791794 loss_ctc_origin 30.546680 loss_ctc0 94.697067 lr 0.00054310 rank 0
2022-08-27 03:50:39,864 DEBUG TRAIN Batch 238/2500 loss 40.223667 loss_att 22.712212 loss_ctc 81.083725 loss_ctc_origin 46.011436 loss_ctc0 162.919067 lr 0.00054308 rank 0
2022-08-27 03:51:07,972 DEBUG TRAIN Batch 238/2600 loss 53.676247 loss_att 32.267269 loss_ctc 103.630524 loss_ctc_origin 59.811390 loss_ctc0 205.875153 lr 0.00054306 rank 0
2022-08-27 03:51:33,941 DEBUG TRAIN Batch 238/2700 loss 19.261610 loss_att 10.128721 loss_ctc 40.571686 loss_ctc_origin 29.254112 loss_ctc0 66.979362 lr 0.00054304 rank 0
2022-08-27 03:51:47,069 WARNING NaN or Inf found in input tensor.
2022-08-27 03:52:02,897 DEBUG TRAIN Batch 238/2800 loss 16.392021 loss_att 6.058357 loss_ctc 40.503906 loss_ctc_origin 24.438265 loss_ctc0 77.990395 lr 0.00054302 rank 0
2022-08-27 03:52:31,646 DEBUG TRAIN Batch 238/2900 loss 20.565256 loss_att 7.766180 loss_ctc 50.429764 loss_ctc_origin 31.508884 loss_ctc0 94.578484 lr 0.00054300 rank 0
2022-08-27 03:52:47,014 WARNING NaN or Inf found in input tensor.
2022-08-27 03:53:06,340 DEBUG TRAIN Batch 238/3000 loss 57.718384 loss_att 41.229347 loss_ctc 96.192810 loss_ctc_origin 63.690823 loss_ctc0 172.030777 lr 0.00054298 rank 0
2022-08-27 03:53:20,689 WARNING NaN or Inf found in input tensor.
2022-08-27 03:53:34,192 DEBUG TRAIN Batch 238/3100 loss 54.788818 loss_att 28.863453 loss_ctc 115.281334 loss_ctc_origin 61.419743 loss_ctc0 240.958374 lr 0.00054296 rank 0
2022-08-27 03:54:01,386 DEBUG TRAIN Batch 238/3200 loss 18.199318 loss_att 10.083469 loss_ctc 37.136295 loss_ctc_origin 25.723125 loss_ctc0 63.767025 lr 0.00054294 rank 0
2022-08-27 03:54:28,389 DEBUG TRAIN Batch 238/3300 loss 16.284389 loss_att 6.009772 loss_ctc 40.258499 loss_ctc_origin 23.297077 loss_ctc0 79.835144 lr 0.00054292 rank 0
2022-08-27 03:54:38,565 WARNING NaN or Inf found in input tensor.
2022-08-27 03:54:56,530 DEBUG TRAIN Batch 238/3400 loss 20.103310 loss_att 7.744024 loss_ctc 48.941639 loss_ctc_origin 30.203091 loss_ctc0 92.664917 lr 0.00054290 rank 0
2022-08-27 03:55:24,083 DEBUG TRAIN Batch 238/3500 loss 49.093521 loss_att 31.686665 loss_ctc 89.709518 loss_ctc_origin 53.858585 loss_ctc0 173.361694 lr 0.00054288 rank 0
2022-08-27 03:55:51,678 DEBUG TRAIN Batch 238/3600 loss 54.266384 loss_att 27.935715 loss_ctc 115.704605 loss_ctc_origin 57.032684 loss_ctc0 252.605743 lr 0.00054286 rank 0
2022-08-27 03:56:18,641 DEBUG TRAIN Batch 238/3700 loss 14.954161 loss_att 6.761939 loss_ctc 34.069344 loss_ctc_origin 21.989197 loss_ctc0 62.256344 lr 0.00054284 rank 0
2022-08-27 03:56:46,299 DEBUG TRAIN Batch 238/3800 loss 16.179150 loss_att 5.933584 loss_ctc 40.085468 loss_ctc_origin 24.058916 loss_ctc0 77.480751 lr 0.00054282 rank 0
2022-08-27 03:57:08,795 WARNING NaN or Inf found in input tensor.
2022-08-27 03:57:13,153 DEBUG TRAIN Batch 238/3900 loss 21.094740 loss_att 8.074364 loss_ctc 51.475616 loss_ctc_origin 30.896461 loss_ctc0 99.493645 lr 0.00054280 rank 0
2022-08-27 03:57:42,266 DEBUG TRAIN Batch 238/4000 loss 52.398247 loss_att 33.782516 loss_ctc 95.834946 loss_ctc_origin 63.129204 loss_ctc0 172.148346 lr 0.00054278 rank 0
2022-08-27 03:58:01,761 WARNING NaN or Inf found in input tensor.
2022-08-27 03:58:08,344 DEBUG TRAIN Batch 238/4100 loss 50.507374 loss_att 24.103840 loss_ctc 112.115616 loss_ctc_origin 54.674973 loss_ctc0 246.143753 lr 0.00054276 rank 0
2022-08-27 03:58:35,837 DEBUG TRAIN Batch 238/4200 loss 15.685177 loss_att 7.365728 loss_ctc 35.097221 loss_ctc_origin 22.074072 loss_ctc0 65.484573 lr 0.00054274 rank 0
2022-08-27 03:58:47,740 WARNING NaN or Inf found in input tensor.
2022-08-27 03:59:04,365 DEBUG TRAIN Batch 238/4300 loss 20.266916 loss_att 8.459200 loss_ctc 47.818256 loss_ctc_origin 35.297798 loss_ctc0 77.032661 lr 0.00054272 rank 0
2022-08-27 03:59:32,983 DEBUG TRAIN Batch 238/4400 loss 19.940393 loss_att 7.846518 loss_ctc 48.159431 loss_ctc_origin 29.238016 loss_ctc0 92.309387 lr 0.00054270 rank 0
2022-08-27 04:00:05,016 DEBUG TRAIN Batch 238/4500 loss 40.877563 loss_att 25.775345 loss_ctc 76.116074 loss_ctc_origin 46.385490 loss_ctc0 145.487442 lr 0.00054268 rank 0
2022-08-27 04:00:32,774 DEBUG TRAIN Batch 238/4600 loss 52.875744 loss_att 28.777956 loss_ctc 109.103912 loss_ctc_origin 52.478119 loss_ctc0 241.230759 lr 0.00054266 rank 0
2022-08-27 04:00:58,916 WARNING NaN or Inf found in input tensor.
2022-08-27 04:01:00,420 DEBUG TRAIN Batch 238/4700 loss 14.945095 loss_att 7.383200 loss_ctc 32.589516 loss_ctc_origin 21.208038 loss_ctc0 59.146290 lr 0.00054264 rank 0
2022-08-27 04:01:28,833 DEBUG TRAIN Batch 238/4800 loss 17.755322 loss_att 5.936391 loss_ctc 45.332821 loss_ctc_origin 30.204128 loss_ctc0 80.633102 lr 0.00054262 rank 0
2022-08-27 04:01:52,752 WARNING NaN or Inf found in input tensor.
2022-08-27 04:01:57,267 DEBUG TRAIN Batch 238/4900 loss 16.448685 loss_att 5.878402 loss_ctc 41.112679 loss_ctc_origin 22.985523 loss_ctc0 83.409363 lr 0.00054260 rank 0
2022-08-27 04:02:25,167 DEBUG TRAIN Batch 238/5000 loss 45.053329 loss_att 29.882744 loss_ctc 80.451355 loss_ctc_origin 52.873589 loss_ctc0 144.799454 lr 0.00054258 rank 0
2022-08-27 04:02:52,561 DEBUG TRAIN Batch 238/5100 loss 51.007408 loss_att 29.432549 loss_ctc 101.348747 loss_ctc_origin 58.476353 loss_ctc0 201.384338 lr 0.00054256 rank 0
2022-08-27 04:03:17,890 WARNING NaN or Inf found in input tensor.
2022-08-27 04:03:19,309 DEBUG TRAIN Batch 238/5200 loss 15.505831 loss_att 7.341666 loss_ctc 34.555550 loss_ctc_origin 24.205919 loss_ctc0 58.704681 lr 0.00054254 rank 0
2022-08-27 04:03:47,476 DEBUG TRAIN Batch 238/5300 loss 17.635353 loss_att 6.935726 loss_ctc 42.601151 loss_ctc_origin 27.503403 loss_ctc0 77.829224 lr 0.00054252 rank 0
2022-08-27 04:04:15,643 DEBUG TRAIN Batch 238/5400 loss 20.514328 loss_att 7.790192 loss_ctc 50.203979 loss_ctc_origin 32.203323 loss_ctc0 92.205505 lr 0.00054250 rank 0
2022-08-27 04:04:43,209 DEBUG TRAIN Batch 238/5500 loss 43.865555 loss_att 27.150963 loss_ctc 82.866272 loss_ctc_origin 50.634247 loss_ctc0 158.074310 lr 0.00054248 rank 0
2022-08-27 04:05:10,757 DEBUG TRAIN Batch 238/5600 loss 47.528896 loss_att 23.614828 loss_ctc 103.328384 loss_ctc_origin 55.387276 loss_ctc0 215.190979 lr 0.00054246 rank 0
2022-08-27 04:05:33,418 DEBUG CV Batch 238/0 loss 11.081392 loss_att 8.301645 loss_ctc 17.567471 loss_ctc_origin 10.745733 loss_ctc0 33.484856 history loss 10.429546 rank 0
2022-08-27 04:05:43,107 DEBUG CV Batch 238/100 loss 20.497101 loss_att 16.726711 loss_ctc 29.294674 loss_ctc_origin 19.203146 loss_ctc0 52.841568 history loss 25.483328 rank 0
2022-08-27 04:05:52,116 DEBUG CV Batch 238/200 loss 23.866531 loss_att 18.051346 loss_ctc 37.435303 loss_ctc_origin 26.924023 loss_ctc0 61.961628 history loss 26.769584 rank 0
2022-08-27 04:06:00,992 DEBUG CV Batch 238/300 loss 21.437206 loss_att 16.149693 loss_ctc 33.774738 loss_ctc_origin 17.966797 loss_ctc0 70.659935 history loss 25.868881 rank 0
2022-08-27 04:06:10,475 DEBUG CV Batch 238/400 loss 37.244190 loss_att 30.098255 loss_ctc 53.918037 loss_ctc_origin 36.553299 loss_ctc0 94.435753 history loss 24.255534 rank 0
2022-08-27 04:06:20,743 DEBUG CV Batch 238/500 loss 16.234840 loss_att 12.260735 loss_ctc 25.507755 loss_ctc_origin 18.467861 loss_ctc0 41.934174 history loss 23.967055 rank 0
2022-08-27 04:06:31,211 DEBUG CV Batch 238/600 loss 18.167168 loss_att 12.940549 loss_ctc 30.362616 loss_ctc_origin 20.418962 loss_ctc0 53.564472 history loss 23.815699 rank 0
2022-08-27 04:06:40,497 DEBUG CV Batch 238/700 loss 17.997765 loss_att 12.677483 loss_ctc 30.411755 loss_ctc_origin 16.428726 loss_ctc0 63.038822 history loss 23.490738 rank 0
2022-08-27 04:06:49,148 DEBUG CV Batch 238/800 loss 21.155437 loss_att 16.237564 loss_ctc 32.630474 loss_ctc_origin 17.367113 loss_ctc0 68.244980 history loss 23.467265 rank 0
2022-08-27 04:06:57,689 INFO Epoch 238 CV info cv_loss 23.583446342663695
2022-08-27 04:06:57,689 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/238.pt
2022-08-27 04:06:58,107 INFO Epoch 239 TRAIN info lr 0.0005424394304926289
2022-08-27 04:06:58,110 INFO using accumulate grad, new batch size is 4 times larger than before
2022-08-27 04:07:23,846 DEBUG TRAIN Batch 239/0 loss 50.089249 loss_att 31.470449 loss_ctc 93.533112 loss_ctc_origin 64.246857 loss_ctc0 161.867722 lr 0.00054244 rank 0
2022-08-27 04:07:52,022 DEBUG TRAIN Batch 239/100 loss 45.194138 loss_att 23.181067 loss_ctc 96.557968 loss_ctc_origin 50.860130 loss_ctc0 203.186249 lr 0.00054242 rank 0
2022-08-27 04:08:19,509 DEBUG TRAIN Batch 239/200 loss 20.552864 loss_att 9.968773 loss_ctc 45.249073 loss_ctc_origin 35.091484 loss_ctc0 68.950111 lr 0.00054240 rank 0
2022-08-27 04:08:46,978 DEBUG TRAIN Batch 239/300 loss 19.458149 loss_att 6.847333 loss_ctc 48.883385 loss_ctc_origin 35.385746 loss_ctc0 80.377869 lr 0.00054238 rank 0
2022-08-27 04:09:14,178 DEBUG TRAIN Batch 239/400 loss 20.423176 loss_att 7.883249 loss_ctc 49.683006 loss_ctc_origin 31.351400 loss_ctc0 92.456741 lr 0.00054236 rank 0
2022-08-27 04:09:43,937 DEBUG TRAIN Batch 239/500 loss 40.277321 loss_att 22.680511 loss_ctc 81.336540 loss_ctc_origin 47.286804 loss_ctc0 160.785919 lr 0.00054234 rank 0
2022-08-27 04:10:11,744 DEBUG TRAIN Batch 239/600 loss 54.540016 loss_att 30.847656 loss_ctc 109.822189 loss_ctc_origin 57.523487 loss_ctc0 231.852478 lr 0.00054232 rank 0
2022-08-27 04:10:40,747 DEBUG TRAIN Batch 239/700 loss 18.330809 loss_att 8.312499 loss_ctc 41.706863 loss_ctc_origin 28.984747 loss_ctc0 71.391800 lr 0.00054230 rank 0
2022-08-27 04:11:07,040 DEBUG TRAIN Batch 239/800 loss 20.495464 loss_att 7.454063 loss_ctc 50.925396 loss_ctc_origin 35.640862 loss_ctc0 86.589310 lr 0.00054228 rank 0
2022-08-27 04:11:22,882 WARNING NaN or Inf found in input tensor.
2022-08-27 04:11:33,958 DEBUG TRAIN Batch 239/900 loss 22.495239 loss_att 8.839565 loss_ctc 54.358471 loss_ctc_origin 36.357246 loss_ctc0 96.361328 lr 0.00054226 rank 0
2022-08-27 04:12:02,998 DEBUG TRAIN Batch 239/1000 loss 44.945869 loss_att 27.290051 loss_ctc 86.142776 loss_ctc_origin 56.251083 loss_ctc0 155.890045 lr 0.00054224 rank 0
2022-08-27 04:12:30,162 DEBUG TRAIN Batch 239/1100 loss 50.992638 loss_att 28.712317 loss_ctc 102.980042 loss_ctc_origin 55.927578 loss_ctc0 212.769104 lr 0.00054222 rank 0
2022-08-27 04:12:58,739 DEBUG TRAIN Batch 239/1200 loss 16.091492 loss_att 7.824067 loss_ctc 35.382149 loss_ctc_origin 22.912525 loss_ctc0 64.477936 lr 0.00054220 rank 0
2022-08-27 04:13:28,401 DEBUG TRAIN Batch 239/1300 loss 20.037483 loss_att 7.962754 loss_ctc 48.211849 loss_ctc_origin 31.297972 loss_ctc0 87.677559 lr 0.00054218 rank 0
2022-08-27 04:13:54,426 DEBUG TRAIN Batch 239/1400 loss 17.390011 loss_att 7.263538 loss_ctc 41.018444 loss_ctc_origin 21.113384 loss_ctc0 87.463585 lr 0.00054216 rank 0
2022-08-27 04:14:28,560 DEBUG TRAIN Batch 239/1500 loss 44.005913 loss_att 27.309536 loss_ctc 82.964127 loss_ctc_origin 55.720078 loss_ctc0 146.533585 lr 0.00054214 rank 0
2022-08-27 04:14:56,713 DEBUG TRAIN Batch 239/1600 loss 42.268944 loss_att 22.289883 loss_ctc 88.886749 loss_ctc_origin 46.719162 loss_ctc0 187.277786 lr 0.00054212 rank 0
2022-08-27 04:15:22,291 WARNING NaN or Inf found in input tensor.
2022-08-27 04:15:23,924 DEBUG TRAIN Batch 239/1700 loss 18.666889 loss_att 9.036576 loss_ctc 41.137619 loss_ctc_origin 29.452011 loss_ctc0 68.404037 lr 0.00054210 rank 0
2022-08-27 04:15:51,053 DEBUG TRAIN Batch 239/1800 loss 15.151908 loss_att 5.554934 loss_ctc 37.544846 loss_ctc_origin 22.547842 loss_ctc0 72.537857 lr 0.00054208 rank 0
2022-08-27 04:16:18,209 DEBUG TRAIN Batch 239/1900 loss 17.700792 loss_att 6.318186 loss_ctc 44.260204 loss_ctc_origin 26.234024 loss_ctc0 86.321289 lr 0.00054206 rank 0
2022-08-27 04:16:46,563 DEBUG TRAIN Batch 239/2000 loss 46.091755 loss_att 29.026379 loss_ctc 85.910965 loss_ctc_origin 59.475967 loss_ctc0 147.592636 lr 0.00054204 rank 0
2022-08-27 04:17:14,153 DEBUG TRAIN Batch 239/2100 loss 46.556725 loss_att 21.874451 loss_ctc 104.148697 loss_ctc_origin 50.898388 loss_ctc0 228.399414 lr 0.00054202 rank 0
2022-08-27 04:17:42,269 DEBUG TRAIN Batch 239/2200 loss 18.760242 loss_att 8.846549 loss_ctc 41.892189 loss_ctc_origin 31.323374 loss_ctc0 66.552750 lr 0.00054200 rank 0
2022-08-27 04:18:09,939 DEBUG TRAIN Batch 239/2300 loss 22.373884 loss_att 7.538543 loss_ctc 56.989681 loss_ctc_origin 40.287777 loss_ctc0 95.960793 lr 0.00054198 rank 0
2022-08-27 04:18:37,884 DEBUG TRAIN Batch 239/2400 loss 20.614546 loss_att 7.700644 loss_ctc 50.746983 loss_ctc_origin 33.890980 loss_ctc0 90.077652 lr 0.00054196 rank 0
2022-08-27 04:19:06,081 DEBUG TRAIN Batch 239/2500 loss 43.826767 loss_att 28.838881 loss_ctc 78.798508 loss_ctc_origin 52.704643 loss_ctc0 139.684174 lr 0.00054194 rank 0
2022-08-27 04:19:33,016 DEBUG TRAIN Batch 239/2600 loss 40.862999 loss_att 23.169098 loss_ctc 82.148766 loss_ctc_origin 42.346817 loss_ctc0 175.019974 lr 0.00054192 rank 0
2022-08-27 04:19:58,917 DEBUG TRAIN Batch 239/2700 loss 21.604321 loss_att 13.703432 loss_ctc 40.039722 loss_ctc_origin 29.504942 loss_ctc0 64.620872 lr 0.00054190 rank 0
2022-08-27 04:20:27,930 DEBUG TRAIN Batch 239/2800 loss 19.132895 loss_att 7.602796 loss_ctc 46.036457 loss_ctc_origin 32.116035 loss_ctc0 78.517441 lr 0.00054188 rank 0
2022-08-27 04:20:54,966 DEBUG TRAIN Batch 239/2900 loss 17.811466 loss_att 6.909647 loss_ctc 43.249039 loss_ctc_origin 24.132568 loss_ctc0 87.854141 lr 0.00054186 rank 0
2022-08-27 04:21:28,554 DEBUG TRAIN Batch 239/3000 loss 42.132599 loss_att 26.240114 loss_ctc 79.215057 loss_ctc_origin 47.746853 loss_ctc0 152.640869 lr 0.00054184 rank 0
2022-08-27 04:21:56,877 DEBUG TRAIN Batch 239/3100 loss 43.103256 loss_att 21.762550 loss_ctc 92.898239 loss_ctc_origin 46.450867 loss_ctc0 201.275421 lr 0.00054182 rank 0
2022-08-27 04:22:24,103 DEBUG TRAIN Batch 239/3200 loss 18.374796 loss_att 8.699136 loss_ctc 40.951332 loss_ctc_origin 28.590183 loss_ctc0 69.794006 lr 0.00054180 rank 0
2022-08-27 04:22:52,397 DEBUG TRAIN Batch 239/3300 loss 20.997292 loss_att 7.984569 loss_ctc 51.360306 loss_ctc_origin 37.512672 loss_ctc0 83.671448 lr 0.00054178 rank 0
2022-08-27 04:23:20,062 DEBUG TRAIN Batch 239/3400 loss 17.783678 loss_att 6.459300 loss_ctc 44.207226 loss_ctc_origin 24.382687 loss_ctc0 90.464478 lr 0.00054176 rank 0
2022-08-27 04:23:49,271 DEBUG TRAIN Batch 239/3500 loss 38.695213 loss_att 24.683838 loss_ctc 71.388420 loss_ctc_origin 41.215393 loss_ctc0 141.792145 lr 0.00054174 rank 0
2022-08-27 04:24:16,835 DEBUG TRAIN Batch 239/3600 loss 46.419891 loss_att 24.136074 loss_ctc 98.415466 loss_ctc_origin 52.229004 loss_ctc0 206.183868 lr 0.00054172 rank 0
2022-08-27 04:24:23,603 WARNING NaN or Inf found in input tensor.
2022-08-27 04:24:42,834 WARNING NaN or Inf found in input tensor.
2022-08-27 04:24:44,535 DEBUG TRAIN Batch 239/3700 loss 22.132559 loss_att 11.638594 loss_ctc 46.618477 loss_ctc_origin 35.852806 loss_ctc0 71.738373 lr 0.00054170 rank 0
2022-08-27 04:25:11,120 DEBUG TRAIN Batch 239/3800 loss 20.536627 loss_att 8.136452 loss_ctc 49.470367 loss_ctc_origin 33.519028 loss_ctc0 86.690155 lr 0.00054168 rank 0
2022-08-27 04:25:39,829 DEBUG TRAIN Batch 239/3900 loss 19.856974 loss_att 7.983568 loss_ctc 47.561584 loss_ctc_origin 29.239607 loss_ctc0 90.312859 lr 0.00054166 rank 0
2022-08-27 04:26:07,069 DEBUG TRAIN Batch 239/4000 loss 40.046951 loss_att 25.865494 loss_ctc 73.137016 loss_ctc_origin 49.056221 loss_ctc0 129.325531 lr 0.00054164 rank 0
2022-08-27 04:26:34,248 DEBUG TRAIN Batch 239/4100 loss 47.617203 loss_att 26.643126 loss_ctc 96.556702 loss_ctc_origin 55.117676 loss_ctc0 193.247757 lr 0.00054162 rank 0
2022-08-27 04:27:00,977 DEBUG TRAIN Batch 239/4200 loss 16.803770 loss_att 8.002092 loss_ctc 37.341015 loss_ctc_origin 24.309998 loss_ctc0 67.746719 lr 0.00054160 rank 0
2022-08-27 04:27:28,872 DEBUG TRAIN Batch 239/4300 loss 15.112982 loss_att 5.219089 loss_ctc 38.198730 loss_ctc_origin 19.526028 loss_ctc0 81.768372 lr 0.00054158 rank 0
2022-08-27 04:27:56,007 DEBUG TRAIN Batch 239/4400 loss 21.703991 loss_att 8.817244 loss_ctc 51.773064 loss_ctc_origin 33.862209 loss_ctc0 93.565048 lr 0.00054156 rank 0
2022-08-27 04:28:30,236 DEBUG TRAIN Batch 239/4500 loss 42.929325 loss_att 26.724823 loss_ctc 80.739822 loss_ctc_origin 48.701481 loss_ctc0 155.495941 lr 0.00054154 rank 0
2022-08-27 04:28:58,260 DEBUG TRAIN Batch 239/4600 loss 41.963577 loss_att 23.653790 loss_ctc 84.686417 loss_ctc_origin 47.652664 loss_ctc0 171.098511 lr 0.00054152 rank 0
2022-08-27 04:29:25,313 DEBUG TRAIN Batch 239/4700 loss 17.822176 loss_att 8.486605 loss_ctc 39.605175 loss_ctc_origin 25.608187 loss_ctc0 72.264816 lr 0.00054150 rank 0
2022-08-27 04:29:53,620 DEBUG TRAIN Batch 239/4800 loss 15.876144 loss_att 6.307925 loss_ctc 38.201988 loss_ctc_origin 21.956146 loss_ctc0 76.108948 lr 0.00054148 rank 0
2022-08-27 04:30:17,152 WARNING NaN or Inf found in input tensor.
2022-08-27 04:30:21,436 DEBUG TRAIN Batch 239/4900 loss 22.000105 loss_att 8.901953 loss_ctc 52.562462 loss_ctc_origin 34.466408 loss_ctc0 94.786591 lr 0.00054146 rank 0
2022-08-27 04:30:50,505 DEBUG TRAIN Batch 239/5000 loss 42.061668 loss_att 25.518860 loss_ctc 80.661560 loss_ctc_origin 46.679939 loss_ctc0 159.951996 lr 0.00054144 rank 0
2022-08-27 04:30:51,266 WARNING NaN or Inf found in input tensor.
2022-08-27 04:31:17,682 DEBUG TRAIN Batch 239/5100 loss 36.445503 loss_att 17.745911 loss_ctc 80.077881 loss_ctc_origin 39.066395 loss_ctc0 175.771347 lr 0.00054142 rank 0
2022-08-27 04:31:45,277 DEBUG TRAIN Batch 239/5200 loss 15.158145 loss_att 6.765225 loss_ctc 34.741623 loss_ctc_origin 21.088251 loss_ctc0 66.599487 lr 0.00054140 rank 0
2022-08-27 04:32:12,824 DEBUG TRAIN Batch 239/5300 loss 16.955011 loss_att 6.769526 loss_ctc 40.721142 loss_ctc_origin 24.280935 loss_ctc0 79.081619 lr 0.00054138 rank 0
2022-08-27 04:32:40,205 DEBUG TRAIN Batch 239/5400 loss 22.349255 loss_att 8.490520 loss_ctc 54.686302 loss_ctc_origin 34.560776 loss_ctc0 101.645851 lr 0.00054136 rank 0
2022-08-27 04:33:07,780 DEBUG TRAIN Batch 239/5500 loss 47.921703 loss_att 31.699266 loss_ctc 85.774055 loss_ctc_origin 54.897854 loss_ctc0 157.818527 lr 0.00054134 rank 0
2022-08-27 04:33:35,696 DEBUG TRAIN Batch 239/5600 loss 40.207005 loss_att 21.033415 loss_ctc 84.945374 loss_ctc_origin 44.206665 loss_ctc0 180.002350 lr 0.00054132 rank 0
2022-08-27 04:33:58,160 DEBUG CV Batch 239/0 loss 11.565043 loss_att 8.594389 loss_ctc 18.496571 loss_ctc_origin 12.092330 loss_ctc0 33.439800 history loss 10.884747 rank 0
2022-08-27 04:34:07,844 DEBUG CV Batch 239/100 loss 21.607979 loss_att 17.886600 loss_ctc 30.291197 loss_ctc_origin 20.479427 loss_ctc0 53.185326 history loss 26.011408 rank 0
2022-08-27 04:34:16,783 DEBUG CV Batch 239/200 loss 24.151245 loss_att 18.536362 loss_ctc 37.252640 loss_ctc_origin 26.869015 loss_ctc0 61.481094 history loss 27.279200 rank 0
2022-08-27 04:34:26,088 DEBUG CV Batch 239/300 loss 21.857841 loss_att 16.403496 loss_ctc 34.584648 loss_ctc_origin 19.071617 loss_ctc0 70.781723 history loss 26.388999 rank 0
2022-08-27 04:34:35,885 DEBUG CV Batch 239/400 loss 37.778465 loss_att 30.651905 loss_ctc 54.407112 loss_ctc_origin 37.395042 loss_ctc0 94.101944 history loss 24.674984 rank 0
2022-08-27 04:34:45,735 DEBUG CV Batch 239/500 loss 16.265997 loss_att 12.146616 loss_ctc 25.877884 loss_ctc_origin 18.875732 loss_ctc0 42.216240 history loss 24.343246 rank 0
2022-08-27 04:34:56,224 DEBUG CV Batch 239/600 loss 17.987690 loss_att 13.203588 loss_ctc 29.150597 loss_ctc_origin 18.941813 loss_ctc0 52.971092 history loss 24.173851 rank 0
2022-08-27 04:35:06,769 DEBUG CV Batch 239/700 loss 18.979925 loss_att 13.700942 loss_ctc 31.297552 loss_ctc_origin 17.551474 loss_ctc0 63.371735 history loss 23.835546 rank 0
2022-08-27 04:35:16,157 DEBUG CV Batch 239/800 loss 21.618917 loss_att 16.923281 loss_ctc 32.575401 loss_ctc_origin 17.082279 loss_ctc0 68.726013 history loss 23.808861 rank 0
2022-08-27 04:35:24,599 INFO Epoch 239 CV info cv_loss 23.896902922934313
2022-08-27 04:35:24,599 INFO Checkpoint: save to checkpoint exp/card7_conformer_embedding_out3_pinyin_0.3_out/239.pt
run.sh: line 161: syntax error near unexpected token `then'
run.sh: line 161: `{stop_stage} -ge 5 ]; then'
